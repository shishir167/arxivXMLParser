<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2016-03-09T00:39:10Z</responseDate>
<request verb="ListRecords" resumptionToken="1122234|6001">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1900</identifier>
 <datestamp>2009-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1900</id><created>2009-01-13</created><updated>2009-04-30</updated><authors><author><keyname>Willett</keyname><forenames>Rebecca M.</forenames></author><author><keyname>Raginsky</keyname><forenames>Maxim</forenames></author></authors><title>Performance bounds on compressed sensing with Poisson noise</title><categories>cs.IT math.IT</categories><comments>5 pages; to appear in Proc. ISIT 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes performance bounds for compressed sensing in the
presence of Poisson noise when the underlying signal, a vector of Poisson
intensities, is sparse or compressible (admits a sparse approximation). The
signal-independent and bounded noise models used in the literature to analyze
the performance of compressed sensing do not accurately model the effects of
Poisson noise. However, Poisson noise is an appropriate noise model for a
variety of applications, including low-light imaging, where sensing hardware is
large or expensive, and limiting the number of measurements collected is
important. In this paper, we describe how a feasible positivity-preserving
sensing matrix can be constructed, and then analyze the performance of a
compressed sensing reconstruction approach for Poisson data that minimizes an
objective function consisting of a negative Poisson log likelihood term and a
penalty term which could be used as a measure of signal sparsity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1904</identifier>
 <datestamp>2009-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1904</id><created>2009-01-13</created><authors><author><keyname>Raginsky</keyname><forenames>Maxim</forenames></author></authors><title>Joint universal lossy coding and identification of stationary mixing
  sources with general alphabets</title><categories>cs.IT cs.LG math.IT</categories><comments>16 pages, 1 figure; accepted to IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of joint universal variable-rate lossy coding and
identification for parametric classes of stationary $\beta$-mixing sources with
general (Polish) alphabets. Compression performance is measured in terms of
Lagrangians, while identification performance is measured by the variational
distance between the true source and the estimated source. Provided that the
sources are mixing at a sufficiently fast rate and satisfy certain smoothness
and Vapnik-Chervonenkis learnability conditions, it is shown that, for bounded
metric distortions, there exist universal schemes for joint lossy compression
and identification whose Lagrangian redundancies converge to zero as $\sqrt{V_n
\log n /n}$ as the block length $n$ tends to infinity, where $V_n$ is the
Vapnik-Chervonenkis dimension of a certain class of decision regions defined by
the $n$-dimensional marginal distributions of the sources; furthermore, for
each $n$, the decoder can identify $n$-dimensional marginal of the active
source up to a ball of radius $O(\sqrt{V_n\log n/n})$ in variational distance,
eventually with probability one. The results are supplemented by several
examples of parametric sources satisfying the regularity conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1905</identifier>
 <datestamp>2009-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1905</id><created>2009-01-13</created><updated>2009-04-30</updated><authors><author><keyname>Raginsky</keyname><forenames>Maxim</forenames></author></authors><title>Achievability results for statistical learning under communication
  constraints</title><categories>cs.IT cs.LG math.IT</categories><comments>5 pages; to appear in Proc. ISIT 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of statistical learning is to construct an accurate predictor of
a random variable as a function of a correlated random variable on the basis of
an i.i.d. training sample from their joint distribution. Allowable predictors
are constrained to lie in some specified class, and the goal is to approach
asymptotically the performance of the best predictor in the class. We consider
two settings in which the learning agent only has access to rate-limited
descriptions of the training data, and present information-theoretic bounds on
the predictor performance achievable in the presence of these communication
constraints. Our proofs do not assume any separation structure between
compression and learning and rely on a new class of operational criteria
specifically tailored to joint design of encoders and learning algorithms in
rate-constrained settings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1906</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1906</id><created>2009-01-13</created><authors><author><keyname>Cieslinski</keyname><forenames>Jan L.</forenames></author><author><keyname>Ratkiewicz</keyname><forenames>Boguslaw</forenames></author></authors><title>How to improve the accuracy of the discrete gradient method in the
  one-dimensional case</title><categories>cs.NA</categories><comments>7 pages plus 7 figures</comments><acm-class>G.1.7</acm-class><doi>10.1103/PhysRevE.81.016704</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new numerical scheme for one dimensional dynamical systems. This
is a modification of the discrete gradient method and keeps its advantages,
including the stability and the conservation of the energy integral. However,
its accuracy is higher by several orders of magnitude.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1908</identifier>
 <datestamp>2013-03-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1908</id><created>2009-01-13</created><authors><author><keyname>Collette</keyname><forenames>Sebastien</forenames></author><author><keyname>Dujmovic</keyname><forenames>Vida</forenames></author><author><keyname>Iacono</keyname><forenames>John</forenames></author><author><keyname>Langerman</keyname><forenames>Stefan</forenames></author><author><keyname>Morin</keyname><forenames>Pat</forenames></author></authors><title>Entropy, Triangulation, and Point Location in Planar Subdivisions</title><categories>cs.CG cs.DS</categories><comments>19 pages, 4 figures, lots of formulas</comments><acm-class>I.3.5; E.1</acm-class><journal-ref>ACM Transactions on Algorithms (TALG), Volume 8 Issue 3, July 2012
  Article No. 29</journal-ref><doi>10.1145/2229163.2229173</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A data structure is presented for point location in connected planar
subdivisions when the distribution of queries is known in advance. The data
structure has an expected query time that is within a constant factor of
optimal. More specifically, an algorithm is presented that preprocesses a
connected planar subdivision G of size n and a query distribution D to produce
a point location data structure for G. The expected number of point-line
comparisons performed by this data structure, when the queries are distributed
according to D, is H + O(H^{2/3}+1) where H=H(G,D) is a lower bound on the
expected number of point-line comparisons performed by any linear decision tree
for point location in G under the query distribution D. The preprocessing
algorithm runs in O(n log n) time and produces a data structure of size O(n).
These results are obtained by creating a Steiner triangulation of G that has
near-minimum entropy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1924</identifier>
 <datestamp>2010-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1924</id><created>2009-01-13</created><updated>2010-03-22</updated><authors><author><keyname>Jing</keyname><forenames>Zhenhai</forenames></author><author><keyname>Bai</keyname><forenames>Baoming</forenames></author><author><keyname>Ma</keyname><forenames>Xiao</forenames></author><author><keyname>Li</keyname><forenames>Ying</forenames></author></authors><title>Interference Avoidance Game in the Gaussian Interference Channel:
  Sub-Optimal and Optimal Schemes</title><categories>cs.IT math.IT</categories><comments>18 pages, 3 figures</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This paper considers a distributed interference avoidance problem employing
frequency assignment in the Gaussian interference channel (IC). We divide the
common channel into several subchannels and each user chooses the subchannel
with less amount of interference from other users as the transmit channel. This
mechanism named interference avoidance in this paper can be modeled as a
competitive game model. And a completely autonomous distributed iterative
algorithm called Tdistributed interference avoidance algorithm (DIA) is adopted
to achieve the Nash equilibriumT (NE) of the game. Due to the self-optimum, DIA
is a sub-optimal algorithm. Therefore, through introducing an optimal
compensation into the competitive game model, we successfully develop a
compensation-based game model to approximate the optimal interference avoidance
problem. Moreover, an optimal algorithm called iterative optimal interference
avoidance algorithm (IOIA) is proposed to reach the optimality of the
interference avoidance scheme. We analyze the implementation complexities of
the two algorithms. We also give the proof on the convergence of the proposed
algorithms. The performance upper bound and lower bound are also derived for
the proposed algorithms. The simulation results show that IOIA does reach the
optimality under condition of interference avoidance mechanism.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1936</identifier>
 <datestamp>2009-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1936</id><created>2009-01-14</created><authors><author><keyname>Jaber</keyname><forenames>Rayyan G.</forenames></author><author><keyname>Andrews</keyname><forenames>Jeffrey G.</forenames></author></authors><title>A Lower Bound on the Capacity of Wireless Erasure Networks with Random
  Node Locations</title><categories>cs.IT cs.NI math.IT math.PR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a lower bound on the capacity of wireless ad hoc erasure
networks is derived in closed form in the canonical case where $n$ nodes are
uniformly and independently distributed in the unit area square. The bound
holds almost surely and is asymptotically tight. We assume all nodes have fixed
transmit power and hence two nodes should be within a specified distance $r_n$
of each other to overcome noise. In this context, interference determines
outages, so we model each transmitter-receiver pair as an erasure channel with
a broadcast constraint, i.e. each node can transmit only one signal across all
its outgoing links. A lower bound of $\Theta(n r_n)$ for the capacity of this
class of networks is derived. If the broadcast constraint is relaxed and each
node can send distinct signals on distinct outgoing links, we show that the
gain is a function of $r_n$ and the link erasure probabilities, and is at most
a constant if the link erasure probabilities grow sufficiently large with $n$.
Finally, the case where the erasure probabilities are themselves random
variables, for example due to randomness in geometry or channels, is analyzed.
We prove somewhat surprisingly that in this setting, variability in erasure
probabilities increases network capacity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1945</identifier>
 <datestamp>2009-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1945</id><created>2009-01-14</created><authors><author><keyname>Fliess</keyname><forenames>Michel</forenames><affiliation>LIX, INRIA Saclay - Ile de France</affiliation></author><author><keyname>Join</keyname><forenames>C&#xe9;dric</forenames><affiliation>INRIA Saclay - Ile de France, CRAN</affiliation></author></authors><title>A mathematical proof of the existence of trends in financial time series</title><categories>q-fin.ST cs.CE math.CA math.PR q-fin.CP stat.AP</categories><proxy>ccsd inria-00352834</proxy><journal-ref>Systems Theory: Modelling, Analysis and Control (2009) 43-62</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We are settling a longstanding quarrel in quantitative finance by proving the
existence of trends in financial time series thanks to a theorem due to P.
Cartier and Y. Perrin, which is expressed in the language of nonstandard
analysis (Integration over finite sets, F. &amp; M. Diener (Eds): Nonstandard
Analysis in Practice, Springer, 1995, pp. 195--204). Those trends, which might
coexist with some altered random walk paradigm and efficient market hypothesis,
seem nevertheless difficult to reconcile with the celebrated Black-Scholes
model. They are estimated via recent techniques stemming from control and
signal theory. Several quite convincing computer simulations on the forecast of
various financial quantities are depicted. We conclude by discussing the r\^ole
of probability theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1954</identifier>
 <datestamp>2009-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1954</id><created>2009-01-14</created><updated>2009-02-23</updated><authors><author><keyname>Ngo</keyname><forenames>Hien Quoc</forenames></author><author><keyname>Quek</keyname><forenames>Tony Q. S.</forenames></author><author><keyname>Shin</keyname><forenames>Hyundong</forenames></author></authors><title>Two-Way Relay Channels: Error Exponents and Resource Allocation</title><categories>cs.IT math.IT</categories><comments>30 pages, 9 figures, submitted to IEEE Transactions on Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a two-way relay network, two terminals exchange information over a shared
wireless half-duplex channel with the help of a relay. Due to its fundamental
and practical importance, there has been an increasing interest in this
channel. However, surprisingly, there has been little work that characterizes
the fundamental tradeoff between the communication reliability and transmission
rate across all signal-to-noise ratios. In this paper, we consider
amplify-and-forward (AF) two-way relaying due to its simplicity. We first
derive the random coding error exponent for the link in each direction. From
the exponent expression, the capacity and cutoff rate for each link are also
deduced. We then put forth the notion of the bottleneck error exponent, which
is the worst exponent decay between the two links, to give us insight into the
fundamental tradeoff between the rate pair and information-exchange reliability
of the two terminals. As applications of the error exponent analysis, we
present two optimal resource allocations to maximize the bottleneck error
exponent: i) the optimal rate allocation under a sum-rate constraint and its
closed-form quasi-optimal solution that requires only knowledge of the capacity
and cutoff rate of each link; and ii) the optimal power allocation under a
total power constraint, which is formulated as a quasi-convex optimization
problem. Numerical results verify our analysis and the effectiveness of the
optimal rate and power allocations in maximizing the bottleneck error exponent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1964</identifier>
 <datestamp>2009-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1964</id><created>2009-01-14</created><updated>2009-07-09</updated><authors><author><keyname>Lee</keyname><forenames>Jungwon</forenames></author><author><keyname>Toumpakaris</keyname><forenames>Dimitris</forenames></author><author><keyname>Lou</keyname><forenames>Hui-Ling</forenames></author></authors><title>Optimal Detector for Channels with Non-Gaussian Interference</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The detection problem in the Gaussian interference channel is addressed, when
transmitters employ non-Gaussian schemes designed for the single-user Gaussian
channel. A structure consisting of a separate symbol-by-symbol detector and a
hard decoder is considered. Given this structure, an optimal detector is
presented that is compared to an interferenceunaware conventional detector, an
interference-aware successive interference cancellation (SIC) detector, and a
minimum-distance detector. It is demonstrated analytically and by simulation
that the optimal detector outperforms both the conventional and the SIC
detector, and that it attains decreasing symbol error rates even in the
presence of strong interference. Moreover, the minimum-distance detector
performs almost as well as the optimal detector in most scenarios and is
significantly less complex.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1971</identifier>
 <datestamp>2009-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1971</id><created>2009-01-14</created><authors><author><keyname>Shieh</keyname><forenames>Min-Zheng</forenames></author><author><keyname>Tsai</keyname><forenames>Shi-Chun</forenames></author></authors><title>Decoding Frequency Permutation Arrays under Infinite norm</title><categories>cs.IT math.IT</categories><comments>Submitted to ISIT 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A frequency permutation array (FPA) of length $n=m\lambda$ and distance $d$
is a set of permutations on a multiset over $m$ symbols, where each symbol
appears exactly $\lambda$ times and the distance between any two elements in
the array is at least $d$. FPA generalizes the notion of permutation array. In
this paper, under the distance metric $\ell_\infty$-norm, we first prove lower
and upper bounds on the size of FPA. Then we give a construction of FPA with
efficient encoding and decoding capabilities. Moreover, we show our design is
locally decodable, i.e., we can decode a message bit by reading at most
$\lambda+1$ symbols, which has an interesting application for private
information retrieval.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1988</identifier>
 <datestamp>2009-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1988</id><created>2009-01-14</created><updated>2009-04-05</updated><authors><author><keyname>Oohama</keyname><forenames>Yasutada</forenames></author></authors><title>Many-Help-One Problem for Gaussian Sources with a Tree Structure on
  their Correlation</title><categories>cs.IT math.IT</categories><comments>17 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider the separate coding problem for $L+1$ correlated
Gaussian memoryless sources. We deal with the case where $L$ separately encoded
data of sources work as side information at the decoder for the reconstruction
of the remaining source. The determination problem of the rate distortion
region for this system is the so called many-help-one problem and has been
known as a highly challenging problem. The author determined the rate
distortion region in the case where the $L$ sources working as partial side
information are conditionally independent if the remaining source we wish to
reconstruct is given. This condition on the correlation is called the CI
condition. In this paper we extend the author's previous result to the case
where $L+1$ sources satisfy a kind of tree structure on their correlation. We
call this tree structure of information sources the TS condition, which
contains the CI condition as a special case. In this paper we derive an
explicit outer bound of the rate distortion region when information sources
satisfy the TS condition. We further derive an explicit sufficient condtion for
this outer bound to be tight. In particular, we determine the sum rate part of
the rate distortion region for the case where information sources satisfy the
TS condition. For some class of Gaussian sources with the TS condition we
derive an explicit recursive formula of this sum rate part.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2042</identifier>
 <datestamp>2009-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2042</id><created>2009-01-14</created><updated>2009-01-19</updated><authors><author><keyname>Jorswieck</keyname><forenames>Eduard</forenames></author><author><keyname>Mittelbach</keyname><forenames>Martin</forenames></author></authors><title>Average Capacity Analysis of Continuous-Time Frequency-Selective
  Rayleigh Fading Channels with Correlated Scattering Using Majorization</title><categories>cs.IT math.IT</categories><comments>5 pages, 3 figures, submitted to ISIT 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Correlated scattering occurs naturally in frequency-selective fading channels
and its impact on the performance needs to be understood. In particular, we
answer the question whether the uncorrelated scattering model leads to an
optimistic or pessimistic estimation of the actual average capacity. In the
paper, we use majorization for functions to show that the average rate with
perfectly informed receiver is largest for uncorrelated scattering if the
transmitter is uninformed. If the transmitter knows the channel statistics, it
can exploit this knowledge. We show that for small SNR, the behavior is
opposite, uncorrelated scattering leads to a lower bound on the average
capacity. Finally, we provide an example of the theoretical results for an
attenuated Ornstein-Uhlenbeck process including illustrations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2062</identifier>
 <datestamp>2009-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2062</id><created>2009-01-14</created><updated>2009-04-30</updated><authors><author><keyname>Chen</keyname><forenames>Yanling</forenames></author><author><keyname>Vinck</keyname><forenames>Han</forenames></author></authors><title>Notes on Reed-Muller Codes</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the Reed-Muller (RM) codes. For the first order RM
code, we prove that it is unique in the sense that any linear code with the
same length, dimension and minimum distance must be the first order RM code;
For the second order RM code, we give a constructive linear sub-code family for
the case when m is even. This is an extension of Corollary 17 of Ch. 15 in the
coding book by MacWilliams and Sloane. Furthermore, we show that the specified
sub-codes of length &lt;= 256 have minimum distance equal to the upper bound or
the best known lower bound for all linear codes of the same length and
dimension. As another interesting result, we derive an additive commutative
group of the symplectic matrices with full rank.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2068</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2068</id><created>2009-01-14</created><updated>2009-01-26</updated><authors><author><keyname>Srba</keyname><forenames>Ji&#x159;&#xed;</forenames></author></authors><title>Beyond Language Equivalence on Visibly Pushdown Automata</title><categories>cs.CC cs.LO</categories><comments>Final version of paper, accepted by LMCS</comments><acm-class>F.4.3</acm-class><journal-ref>Logical Methods in Computer Science, Volume 5, Issue 1 (January
  26, 2009) lmcs:756</journal-ref><doi>10.2168/LMCS-5(1:2)2009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study (bi)simulation-like preorder/equivalence checking on the class of
visibly pushdown automata and its natural subclasses visibly BPA (Basic Process
Algebra) and visibly one-counter automata. We describe generic methods for
proving complexity upper and lower bounds for a number of studied preorders and
equivalences like simulation, completed simulation, ready simulation, 2-nested
simulation preorders/equivalences and bisimulation equivalence. Our main
results are that all the mentioned equivalences and preorders are
EXPTIME-complete on visibly pushdown automata, PSPACE-complete on visibly
one-counter automata and P-complete on visibly BPA. Our PSPACE lower bound for
visibly one-counter automata improves also the previously known DP-hardness
results for ordinary one-counter automata and one-counter nets. Finally, we
study regularity checking problems for visibly pushdown automata and show that
they can be decided in polynomial time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2069</identifier>
 <datestamp>2009-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2069</id><created>2009-01-14</created><authors><author><keyname>Kirwan</keyname><forenames>Edmund</forenames></author></authors><title>Encapsulation theory: the transformation equations of absolute
  information hiding</title><categories>cs.SE</categories><comments>31 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes how the maximum potential number of edges of an
encapsulated graph varies as the graph is transformed, that is, as nodes are
created and modified. The equations governing these changes of maximum
potential number of edges caused by the transformations are derived and briefly
analysed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2082</identifier>
 <datestamp>2009-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2082</id><created>2009-01-14</created><updated>2009-01-15</updated><authors><author><keyname>Avestimehr</keyname><forenames>Salman</forenames></author><author><keyname>Caire</keyname><forenames>Giuseppe</forenames></author><author><keyname>Tse</keyname><forenames>David</forenames></author></authors><title>On Source-Channel Separation in Networks</title><categories>cs.IT math.IT</categories><comments>This paper has been withdrawn</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2090</identifier>
 <datestamp>2009-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2090</id><created>2009-01-14</created><updated>2009-03-06</updated><authors><author><keyname>Sassatelli</keyname><forenames>Lucile</forenames></author><author><keyname>Chilappagari</keyname><forenames>Shashi Kiran</forenames></author><author><keyname>Vasic</keyname><forenames>Bane</forenames></author><author><keyname>Declercq</keyname><forenames>David</forenames></author></authors><title>Two-Bit Message Passing Decoders for LDPC Codes Over the Binary
  Symmetric Channel</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Transactions on Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider quantized decoding of LDPC codes on the binary
symmetric channel. The binary message passing algorithms, while allowing
extremely fast hardware implementation, are not very attractive from the
perspective of performance. More complex decoders such as the ones based on
belief propagation exhibit superior performance but lead to slower decoders.
The approach in this paper is to consider message passing decoders that have
larger message alphabet (thereby providing performance improvement) as well as
low complexity (thereby ensuring fast decoding). We propose a class of
message-passing decoders whose messages are represented by two bits. The
thresholds for various decoders in this class are derived using density
evolution. The problem of correcting a fixed number of errors assumes
significance in the error floor region. For a specific decoder, the sufficient
conditions for correcting all patterns with up to three errors are derived. By
comparing these conditions and thresholds to the similar ones when Gallager B
decoder is used, we emphasize the advantage of decoding on a higher number of
bits, even if the channel observation is still one bit.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2094</identifier>
 <datestamp>2009-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2094</id><created>2009-01-14</created><authors><author><keyname>Rachlin</keyname><forenames>Yaron</forenames></author><author><keyname>Negi</keyname><forenames>Rohit</forenames></author><author><keyname>Khosla</keyname><forenames>Pradeep</forenames></author></authors><title>The Sensing Capacity of Sensor Networks</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory, November 2006</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper demonstrates fundamental limits of sensor networks for detection
problems where the number of hypotheses is exponentially large. Such problems
characterize many important applications including detection and classification
of targets in a geographical area using a network of sensors, and detecting
complex substances with a chemical sensor array. We refer to such applications
as largescale detection problems. Using the insight that these problems share
fundamental similarities with the problem of communicating over a noisy
channel, we define a quantity called the sensing capacity and lower bound it
for a number of sensor network models. The sensing capacity expression differs
significantly from the channel capacity due to the fact that a fixed sensor
configuration encodes all states of the environment. As a result, codewords are
dependent and non-identically distributed. The sensing capacity provides a
bound on the minimal number of sensors required to detect the state of an
environment to within a desired accuracy. The results differ significantly from
classical detection theory, and provide an ntriguing connection between sensor
networks and communications. In addition, we discuss the insight that sensing
capacity provides for the problem of sensor selection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2120</identifier>
 <datestamp>2011-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2120</id><created>2009-01-14</created><updated>2011-07-22</updated><authors><author><keyname>Cheraghchi</keyname><forenames>Mahdi</forenames></author><author><keyname>Didier</keyname><forenames>Frederic</forenames></author><author><keyname>Shokrollahi</keyname><forenames>Amin</forenames></author></authors><title>Invertible Extractors and Wiretap Protocols</title><categories>cs.IT math.IT</categories><comments>Full version. A preliminary summary of this work appears (under the
  same title) in proceedings of the 2009 IEEE International Symposium on
  Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A wiretap protocol is a pair of randomized encoding and decoding functions
such that knowledge of a bounded fraction of the encoding of a message reveals
essentially no information about the message, while knowledge of the entire
encoding reveals the message using the decoder. In this paper we study the
notion of efficiently invertible extractors and show that a wiretap protocol
can be constructed from such an extractor. We will then construct invertible
extractors for symbol-fixing, affine, and general sources and apply them to
create wiretap protocols with asymptotically optimal trade-offs between their
rate (ratio of the length of the message versus its encoding) and resilience
(ratio of the observed positions of the encoding and the length of the
encoding). We will then apply our results to create wiretap protocols for
challenging communication problems, such as active intruders who change
portions of the encoding, network coding, and intruders observing arbitrary
boolean functions of the encoding.
  As a by-product of our constructions we obtain new explicit extractors for a
restricted family of affine sources over large fields (that in particular
generalizes the notion of symbol-fixing sources) which is of independent
interest. These extractors are able to extract the entire source entropy with
zero error.
  Keywords: Wiretap Channel, Extractors, Network Coding, Active Intrusion,
Exposure Resilient Cryptography.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2130</identifier>
 <datestamp>2009-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2130</id><created>2009-01-14</created><updated>2009-05-27</updated><authors><author><keyname>Krzakala</keyname><forenames>Florent</forenames></author><author><keyname>Zdeborov&#xe1;</keyname><forenames>Lenka</forenames></author></authors><title>Hiding Quiet Solutions in Random Constraint Satisfaction Problems</title><categories>cond-mat.stat-mech cond-mat.dis-nn cs.AI cs.CC</categories><comments>4 pages, 3 figures</comments><journal-ref>Phys. Rev. Lett. 102, 238701 (2009)</journal-ref><doi>10.1103/PhysRevLett.102.238701</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study constraint satisfaction problems on the so-called 'planted' random
ensemble. We show that for a certain class of problems, e.g. graph coloring,
many of the properties of the usual random ensemble are quantitatively
identical in the planted random ensemble. We study the structural phase
transitions, and the easy/hard/easy pattern in the average computational
complexity. We also discuss the finite temperature phase diagram, finding a
close connection with the liquid/glass/solid phenomenology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2140</identifier>
 <datestamp>2011-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2140</id><created>2009-01-14</created><authors><author><keyname>Elkouss</keyname><forenames>David</forenames></author><author><keyname>Leverrier</keyname><forenames>Anthony</forenames></author><author><keyname>All&#xe9;aume</keyname><forenames>Romain</forenames></author><author><keyname>Boutros</keyname><forenames>Joseph</forenames></author></authors><title>Efficient reconciliation protocol for discrete-variable quantum key
  distribution</title><categories>cs.IT math.IT quant-ph</categories><doi>10.1109/ISIT.2009.5205475</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reconciliation is an essential part of any secret-key agreement protocol and
hence of a Quantum Key Distribution (QKD) protocol, where two legitimate
parties are given correlated data and want to agree on a common string in the
presence of an adversary, while revealing a minimum amount of information.
  In this paper, we show that for discrete-variable QKD protocols, this problem
can be advantageously solved with Low Density Parity Check (LDPC) codes
optimized for the BSC. In particular, we demonstrate that our method leads to a
significant improvement of the achievable secret key rate, with respect to
earlier interactive reconciliation methods used in QKD.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2143</identifier>
 <datestamp>2009-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2143</id><created>2009-01-14</created><authors><author><keyname>Chang</keyname><forenames>Christopher S.</forenames></author><author><keyname>Klimesh</keyname><forenames>Matthew A.</forenames></author></authors><title>Coding for Parallel Links to Maximize Expected Decodable-Message Value</title><categories>cs.IT math.IT</categories><comments>7 pages, submitted to ISIT2009</comments><msc-class>68P30</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Future communication scenarios for NASA spacecraft may involve multiple
communication links and relay nodes, so that there is essentially a network in
which there may be multiple paths from a sender to a destination. The
availability of individual links may be uncertain. In this paper, scenarios are
considered in which the goal is to maximize a payoff that assigns weight based
on the worth of data and the probability of successful transmission. Ideally,
the choice of what information to send over the various links will provide
protection of high value data when many links are unavailable, yet result in
communication of significant additional data when most links are available.
Here the focus is on the simple network of multiple parallel links, where the
links have known capacities and outage probabilities. Given a set of simple
inter-link codes, linear programming can be used to find the optimal
timesharing strategy among these codes. Some observations are made about the
problem of determining all potentially useful codes, and techniques to assist
in such determination are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2147</identifier>
 <datestamp>2009-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2147</id><created>2009-01-14</created><authors><author><keyname>Ardestanizadeh</keyname><forenames>Ehsan</forenames></author><author><keyname>Cheraghchi</keyname><forenames>Mahdi</forenames></author><author><keyname>Shokrollahi</keyname><forenames>Amin</forenames></author></authors><title>Bit Precision Analysis for Compressed Sensing</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the stability of some reconstruction algorithms for
compressed sensing in terms of the bit precision. Considering the fact that
practical digital systems deal with discretized signals, we motivate the
importance of the total number of accurate bits needed from the measurement
outcomes in addition to the number of measurements. It is shown that if one
uses a $2k \times n$ Vandermonde matrix with roots on the unit circle as the
measurement matrix, $O(\ell + k \log(n/k))$ bits of precision per measurement
are sufficient to reconstruct a $k$-sparse signal $x \in \R^n$ with dynamic
range (i.e., the absolute ratio between the largest and the smallest nonzero
coefficients) at most $2^\ell$ within $\ell$ bits of precision, hence
identifying its correct support. Finally, we obtain an upper bound on the total
number of required bits when the measurement matrix satisfies a restricted
isometry property, which is in particular the case for random Fourier and
Gaussian matrices. For very sparse signals, the upper bound on the number of
required bits for Vandermonde matrices is shown to be better than this general
upper bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2151</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2151</id><created>2009-01-14</created><authors><author><keyname>Sun</keyname><forenames>Yudong</forenames></author><author><keyname>Danila</keyname><forenames>Bogdan</forenames></author><author><keyname>Josic</keyname><forenames>Kresimir</forenames></author><author><keyname>Bassler</keyname><forenames>Kevin E.</forenames></author></authors><title>Improved community structure detection using a modified fine tuning
  strategy</title><categories>cs.CY cond-mat.stat-mech cs.DS physics.comp-ph physics.soc-ph q-bio.QM</categories><comments>6 pages, 3 figures, 1 table</comments><doi>10.1209/0295-5075/86/28004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The community structure of a complex network can be determined by finding the
partitioning of its nodes that maximizes modularity. Many of the proposed
algorithms for doing this work by recursively bisecting the network. We show
that this unduely constrains their results, leading to a bias in the size of
the communities they find and limiting their effectivness. To solve this
problem, we propose adding a step to the existing algorithms that does not
increase the order of their computational complexity. We show that, if this
step is combined with a commonly used method, the identified constraint and
resulting bias are removed, and its ability to find the optimal partitioning is
improved. The effectiveness of this combined algorithm is also demonstrated by
using it on real-world example networks. For a number of these examples, it
achieves the best results of any known algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2160</identifier>
 <datestamp>2009-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2160</id><created>2009-01-14</created><authors><author><keyname>Ganti</keyname><forenames>Radha Krishna</forenames></author><author><keyname>Haenggi</keyname><forenames>Martin</forenames></author></authors><title>Analysis of Uncoordinated Opportunistic Two-Hop Wireless Ad Hoc Systems</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a time-slotted two-hop wireless system in which the sources
transmit to the relays in the even time slots (first hop) and the relays
forward the packets to the destinations in the odd time slots (second hop).
Each source may connect to multiple relays in the first hop. In the presence of
interference and without tight coordination of the relays, it is not clear
which relays should transmit the packet. We propose four decentralized methods
of relay selection, some based on location information and others based on the
received signal strength (RSS). We provide a complete analytical
characterization of these methods using tools from stochastic geometry. We use
simulation results to compare these methods in terms of end-to-end success
probability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2164</identifier>
 <datestamp>2009-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2164</id><created>2009-01-14</created><authors><author><keyname>Nagpal</keyname><forenames>Vinayak</forenames></author><author><keyname>Pawar</keyname><forenames>Sameer</forenames></author><author><keyname>Tse</keyname><forenames>David</forenames></author><author><keyname>Nikolic</keyname><forenames>Borivoje</forenames></author></authors><title>Cooperative Multiplexing in the Multiple Antenna Half Duplex Relay
  Channel</title><categories>cs.IT math.IT</categories><comments>5 pages, 5 figures submitted to ISIT 2009</comments><journal-ref>Information Theory, 2009. ISIT 2009. IEEE International Symposium
  on, vol., no., pp.1438-1442, June 28 2009-July 3 2009</journal-ref><doi>10.1109/ISIT.2009.5205885</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cooperation between terminals has been proposed to improve the reliability
and throughput of wireless communication. While recent work has shown that
relay cooperation provides increased diversity, increased multiplexing gain
over that offered by direct link has largely been unexplored. In this work we
show that cooperative multiplexing gain can be achieved by using a half duplex
relay. We capture relative distances between terminals in the high SNR
diversity multiplexing tradeoff (DMT) framework. The DMT performance is then
characterized for a network having a single antenna half-duplex relay between a
single-antenna source and two-antenna destination. Our results show that the
achievable multiplexing gain using cooperation can be greater than that of the
direct link and is a function of the relative distance between source and relay
compared to the destination. Moreover, for multiplexing gains less than 1, a
simple scheme of the relay listening 1/3 of the time and transmitting 2/3 of
the time can achieve the 2 by 2 MIMO DMT.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2166</identifier>
 <datestamp>2009-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2166</id><created>2009-01-14</created><authors><author><keyname>Tiu</keyname><forenames>Alwen</forenames></author></authors><title>A Trace Based Bisimulation for the Spi Calculus</title><categories>cs.CR cs.LO</categories><comments>This is a revised and extended version of a conference paper
  presented at APLAS 2007</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A notion of open bisimulation is formulated for the spi calculus, an
extension of the pi-calculus with cryptographic primitives. In this
formulation, open bisimulation is indexed by pairs of symbolic traces, which
represent the history of interactions between the environment with the pairs of
processes being checked for bisimilarity. The use of symbolic traces allows for
a symbolic treatment of bound input in bisimulation checking which avoids
quantification over input values. Open bisimilarity is shown to be sound with
respect to testing equivalence, and futher, it is shown to be an equivalence
relation on processes and a congruence relation on finite processes. As far as
we know, this is the first formulation of open bisimulation for the spi
calculus for which the congruence result is proved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2192</identifier>
 <datestamp>2009-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2192</id><created>2009-01-15</created><updated>2009-11-07</updated><authors><author><keyname>Shi</keyname><forenames>Hongsong</forenames></author><author><keyname>Jiang</keyname><forenames>Shaoquan</forenames></author><author><keyname>Safavi-Naini</keyname><forenames>Rei</forenames></author><author><keyname>Tuhin</keyname><forenames>Mohammed Ashraful</forenames></author></authors><title>On Optimal Secure Message Transmission by Public Discussion</title><categories>cs.CR cs.IT math.IT</categories><comments>An extended abstract of the older version was published in ISIT'09.
  The new version is polished in the writing style while some new results are
  also added</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a secure message transmission (SMT) scenario a sender wants to send a
message in a private and reliable way to a receiver. Sender and receiver are
connected by $n$ vertex disjoint paths, referred to as wires, $t$ of which can
be controlled by an adaptive adversary with unlimited computational resources.
In Eurocrypt 2008, Garay and Ostrovsky considered an SMT scenario where sender
and receiver have access to a public discussion channel and showed that secure
and reliable communication is possible when $n \geq t+1$. In this paper we will
show that a secure protocol requires at least 3 rounds of communication and 2
rounds invocation of the public channel and hence give a complete answer to the
open question raised by Garay and Ostrovsky. We also describe a round optimal
protocol that has \emph{constant} transmission rate over the public channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2194</identifier>
 <datestamp>2009-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2194</id><created>2009-01-15</created><authors><author><keyname>Zhang</keyname><forenames>Rui</forenames></author><author><keyname>Cioffi</keyname><forenames>John</forenames></author></authors><title>Iterative Spectrum Shaping with Opportunistic Multiuser Detection</title><categories>cs.IT math.IT</categories><comments>7 figures, 24 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies a new decentralized resource allocation strategy, named
iterative spectrum shaping (ISS), for the multi-carrier-based multiuser
communication system, where two coexisting users independently and sequentially
update transmit power allocations over parallel subcarriers to maximize their
individual transmit rates. Unlike the conventional iterative water-filling
(IWF) algorithm that applies the single-user detection (SD) at each user's
receiver by treating the interference from the other user as additional noise,
the proposed ISS algorithm applies multiuser detection techniques to decode
both the desired user's and interference user's messages if it is feasible,
thus termed as opportunistic multiuser detection (OMD). Two encoding methods
are considered for ISS: One is carrier independent encoding where independent
codewords are modulated by different subcarriers for which different decoding
methods can be applied; the other is carrier joint encoding where a single
codeword is modulated by all the subcarriers for which a single decoder is
applied. For each encoding method, this paper presents the associated optimal
user power and rate allocation strategy at each iteration of transmit
adaptation. It is shown that under many circumstances the proposed ISS
algorithm employing OMD is able to achieve substantial throughput gains over
the conventional IWF algorithm employing SD for decentralized spectrum sharing.
Applications of ISS in cognitive radio communication systems are also
discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2198</identifier>
 <datestamp>2009-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2198</id><created>2009-01-15</created><authors><author><keyname>Rai</keyname><forenames>Brijesh Kumar</forenames></author><author><keyname>Dey</keyname><forenames>Bikash Kumar</forenames></author></authors><title>Feasible alphabets for communicating the sum of sources over a network</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider directed acyclic {\em sum-networks} with $m$ sources and $n$
terminals where the sources generate symbols from an arbitrary alphabet field
$F$, and the terminals need to recover the sum of the sources over $F$. We show
that for any co-finite set of primes, there is a sum-network which is solvable
only over fields of characteristics belonging to that set. We further construct
a sum-network where a scalar solution exists over all fields other than the
binary field $F_2$. We also show that a sum-network is solvable over a field if
and only if its reverse network is solvable over the same field.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2204</identifier>
 <datestamp>2009-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2204</id><created>2009-01-15</created><updated>2009-05-23</updated><authors><author><keyname>Mori</keyname><forenames>Ryuhei</forenames></author><author><keyname>Tanaka</keyname><forenames>Toshiyuki</forenames></author><author><keyname>Kasai</keyname><forenames>Kenta</forenames></author><author><keyname>Sakaniwa</keyname><forenames>Kohichi</forenames></author></authors><title>Finite-Length Analysis of Irregular Expurgated LDPC Codes under Finite
  Number of Iterations</title><categories>cs.IT math.IT</categories><comments>5 pages, 3 figures, submitted to ISIT2009; revised</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Communication over the binary erasure channel (BEC) using low-density
parity-check (LDPC) codes and belief propagation (BP) decoding is considered.
The average bit error probability of an irregular LDPC code ensemble after a
fixed number of iterations converges to a limit, which is calculated via
density evolution, as the blocklength $n$ tends to infinity. The difference
between the bit error probability with blocklength $n$ and the
large-blocklength limit behaves asymptotically like $\alpha/n$, where the
coefficient $\alpha$ depends on the ensemble, the number of iterations and the
erasure probability of the BEC\null. In [1], $\alpha$ is calculated for regular
ensembles. In this paper, $\alpha$ for irregular expurgated ensembles is
derived. It is demonstrated that convergence of numerical estimates of $\alpha$
to the analytic result is significantly fast for irregular unexpurgated
ensembles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2207</identifier>
 <datestamp>2009-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2207</id><created>2009-01-15</created><updated>2009-05-23</updated><authors><author><keyname>Mori</keyname><forenames>Ryuhei</forenames></author><author><keyname>Tanaka</keyname><forenames>Toshiyuki</forenames></author></authors><title>Performance and Construction of Polar Codes on Symmetric Binary-Input
  Memoryless Channels</title><categories>cs.IT math.IT</categories><comments>5 pages, 3 figures, submitted to ISIT2009; revised</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Channel polarization is a method of constructing capacity achieving codes for
symmetric binary-input discrete memoryless channels (B-DMCs) [1]. In the
original paper, the construction complexity is exponential in the blocklength.
In this paper, a new construction method for arbitrary symmetric binary
memoryless channel (B-MC) with linear complexity in the blocklength is
proposed. Furthermore, new upper and lower bounds of the block error
probability of polar codes are derived for the BEC and the arbitrary symmetric
B-MC, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2216</identifier>
 <datestamp>2009-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2216</id><created>2009-01-15</created><authors><author><keyname>Mukherjee</keyname><forenames>Animesh</forenames></author><author><keyname>Choudhury</keyname><forenames>Monojit</forenames></author><author><keyname>Kannan</keyname><forenames>Ravi</forenames></author></authors><title>Discovering Global Patterns in Linguistic Networks through Spectral
  Analysis: A Case Study of the Consonant Inventories</title><categories>cs.CL physics.data-an</categories><comments>In the proceedings of EACL 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent research has shown that language and the socio-cognitive phenomena
associated with it can be aptly modeled and visualized through networks of
linguistic entities. However, most of the existing works on linguistic networks
focus only on the local properties of the networks. This study is an attempt to
analyze the structure of languages via a purely structural technique, namely
spectral analysis, which is ideally suited for discovering the global
correlations in a network. Application of this technique to PhoNet, the
co-occurrence network of consonants, not only reveals several natural
linguistic principles governing the structure of the consonant inventories, but
is also able to quantify their relative importance. We believe that this
powerful technique can be successfully applied, in general, to study the
structure of natural languages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2218</identifier>
 <datestamp>2009-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2218</id><created>2009-01-15</created><authors><author><keyname>Yassaee</keyname><forenames>Mohammad Hossein</forenames></author><author><keyname>Aref</keyname><forenames>Mohammad Reza</forenames></author></authors><title>Slepian-Wolf Coding over Cooperative Networks</title><categories>cs.IT math.IT</categories><comments>5 pages, submitted to ISIT 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present sufficient conditions for multicasting a set of correlated sources
over cooperative networks. We propose joint source-Wyner-Ziv
encoding/sliding-window decoding scheme, in which each receiver considers an
ordered partition of other nodes. Subject to this scheme, we obtain a set of
feasibility constraints for each ordered partition. We consolidate the results
of different ordered partitions by utilizing a result of geometrical approach
to obtain the sufficient conditions. We observe that these sufficient
conditions are indeed necessary conditions for Aref networks. As a consequence
of the main result, we obtain an achievable rate region for networks with
multicast demands. Also, we deduce an achievability result for two-way relay
networks, in which two nodes want to communicate over a relay network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2224</identifier>
 <datestamp>2010-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2224</id><created>2009-01-15</created><updated>2010-08-02</updated><authors><author><keyname>Savinov</keyname><forenames>Alexandr</forenames></author></authors><title>Concept-Oriented Model and Query Language</title><categories>cs.DB</categories><comments>45 pages, 18 figures, Submitted to ACM Transactions on Database
  Systems (TODS)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a new approach to data modeling, called the concept-oriented
model (COM), and a novel concept-oriented query language (COQL). The model is
based on three principles: duality principle postulates that any element is a
couple consisting of one identity and one entity, inclusion principle
postulates that any element has a super-element, and order principle assumes
that any element has a number of greater elements within a partially ordered
set. Concept-oriented query language is based on a new data modeling construct,
called concept, inclusion relation between concepts, and concept partial
ordering in which greater concepts are represented by their field types. It is
demonstrated how COM and COQL can be used to solve three general data modeling
tasks: logical navigation, multidimensional analysis and inference. Logical
navigation is based on two operations of projection and de-projection.
Multidimensional analysis uses product operation for producing a cube from
level concepts chosen along the chosen dimension paths. Inference is defined as
a two-step procedure where input constraints are first propagated downwards
using de-projection and then the constrained result is propagated upwards using
projection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2270</identifier>
 <datestamp>2009-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2270</id><created>2009-01-15</created><authors><author><keyname>Morelos-Zaragoza</keyname><forenames>Robert</forenames></author></authors><title>A Plotkin-Alamouti Superposition Coding Scheme for Cooperative
  Broadcasting in Wireless Networks</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with superposition coding for cooperative broadcasting in
the case of two coordinated source nodes, as introduced in the seminal work of
Bergmans and Cover in 1974. A scheme is introduced for two classes of
destination (or relay) nodes: Close nodes and far nodes, as ranked by their
spatial distances to the pair of transmitting nodes. Two linear codes are
combined using the (u,u+v)-construction devised by Plotkin to construct
two-level linear unequal error protection (LUEP) codes. However, instead of
binary addition of subcode codewords in the source encoder, here modulated
subcode sequences are combined at the destination (or relay) nodes antennae.
Bergmans and Cover referred to this as over-the-air mixing. In the case of
Rayleigh fading, additional diversity order as well as robustness to channel
estimation errors are obtained when source nodes transmit pairs of coded
sequences in accordance to Alamouti's transmit diversity scheme. We refer to
this combination as a Plotkin-Alamouti scheme and study its performance over
AWGN and Rayleigh fading channels with a properly partitioned QPSK
constellation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2310</identifier>
 <datestamp>2009-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2310</id><created>2009-01-15</created><authors><author><keyname>Barker</keyname><forenames>Adam</forenames></author><author><keyname>van Hemert</keyname><forenames>Jano I.</forenames></author><author><keyname>Baldock</keyname><forenames>Richard A.</forenames></author><author><keyname>Atkinson</keyname><forenames>Malcolm P.</forenames></author></authors><title>An e-Infrastructure for Collaborative Research in Human Embryo
  Development</title><categories>cs.DC cs.SE</categories><comments>Summary of the EU-funded DGEMap project: 6 pages, 6 figures</comments><acm-class>C.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Within the context of the EU Design Study Developmental Gene Expression Map,
we identify a set of challenges when facilitating collaborative research on
early human embryo development. These challenges bring forth requirements, for
which we have identified solutions and technology. We summarise our solutions
and demonstrate how they integrate to form an e-infrastructure to support
collaborative research in this area of developmental biology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2321</identifier>
 <datestamp>2009-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2321</id><created>2009-01-15</created><updated>2009-04-10</updated><authors><author><keyname>D&#x119;bowski</keyname><forenames>&#x141;ukasz</forenames></author></authors><title>The Redundancy of a Computable Code on a Noncomputable Distribution</title><categories>stat.ML cs.IT math.IT</categories><comments>5 pages; an intro to a longer article</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce new definitions of universal and superuniversal computable
codes, which are based on a code's ability to approximate Kolmogorov complexity
within the prescribed margin for all individual sequences from a given set.
Such sets of sequences may be singled out almost surely with respect to certain
probability measures. Consider a measure parameterized with a real parameter
and put an arbitrary prior on the parameter. The Bayesian measure is the
expectation of the parameterized measure with respect to the prior. It appears
that a modified Shannon-Fano code for any computable Bayesian measure, which we
call the Bayesian code, is superuniversal on a set of parameterized
measure-almost all sequences for prior-almost every parameter. According to
this result, in the typical setting of mathematical statistics no computable
code enjoys redundancy which is ultimately much less than that of the Bayesian
code. Thus we introduce another characteristic of computable codes: The
catch-up time is the length of data for which the code length drops below the
Kolmogorov complexity plus the prescribed margin. Some codes may have smaller
catch-up times than Bayesian codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2333</identifier>
 <datestamp>2009-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2333</id><created>2009-01-15</created><updated>2009-12-15</updated><authors><author><keyname>Ni</keyname><forenames>Jian</forenames></author><author><keyname>Tan</keyname><forenames>Bo</forenames></author><author><keyname>Srikant</keyname><forenames>R.</forenames></author></authors><title>Q-CSMA: Queue-Length Based CSMA/CA Algorithms for Achieving Maximum
  Throughput and Low Delay in Wireless Networks</title><categories>cs.NI cs.IT math.IT</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, it has been shown that CSMA-type random access algorithms can
achieve the maximum possible throughput in ad hoc wireless networks. However,
these algorithms assume an idealized continuous-time CSMA protocol where
collisions can never occur. In addition, simulation results indicate that the
delay performance of these algorithms can be quite bad. On the other hand,
although some simple heuristics (such as distributed approximations of greedy
maximal scheduling) can yield much better delay performance for a large set of
arrival rates, they may only achieve a fraction of the capacity region in
general. In this paper, we propose a discrete-time version of the CSMA
algorithm. Central to our results is a discrete-time distributed randomized
algorithm which is based on a generalization of the so-called Glauber dynamics
from statistical physics, where multiple links are allowed to update their
states in a single time slot. The algorithm generates collision-free
transmission schedules while explicitly taking collisions into account during
the control phase of the protocol, thus relaxing the perfect CSMA assumption.
More importantly, the algorithm allows us to incorporate mechanisms which lead
to very good delay performance while retaining the throughput-optimality
property. It also resolves the hidden and exposed terminal problems associated
with wireless networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2349</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2349</id><created>2009-01-15</created><updated>2009-11-11</updated><authors><author><keyname>Altmann</keyname><forenames>Eduardo G.</forenames></author><author><keyname>Pierrehumbert</keyname><forenames>Janet B.</forenames></author><author><keyname>Motter</keyname><forenames>Adilson E.</forenames></author></authors><title>Beyond word frequency: Bursts, lulls, and scaling in the temporal
  distributions of words</title><categories>cs.CL cond-mat.dis-nn physics.data-an physics.soc-ph</categories><journal-ref>PLoS ONE 4 (11): e7678 (2009)</journal-ref><doi>10.1371/journal.pone.0007678</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Background: Zipf's discovery that word frequency distributions obey a power
law established parallels between biological and physical processes, and
language, laying the groundwork for a complex systems perspective on human
communication. More recent research has also identified scaling regularities in
the dynamics underlying the successive occurrences of events, suggesting the
possibility of similar findings for language as well.
  Methodology/Principal Findings: By considering frequent words in USENET
discussion groups and in disparate databases where the language has different
levels of formality, here we show that the distributions of distances between
successive occurrences of the same word display bursty deviations from a
Poisson process and are well characterized by a stretched exponential (Weibull)
scaling. The extent of this deviation depends strongly on semantic type -- a
measure of the logicality of each word -- and less strongly on frequency. We
develop a generative model of this behavior that fully determines the dynamics
of word usage.
  Conclusions/Significance: Recurrence patterns of words are well described by
a stretched exponential distribution of recurrence times, an empirical scaling
that cannot be anticipated from Zipf's law. Because the use of words provides a
uniquely precise and powerful lens on human thought and activity, our findings
also have implications for other overt manifestations of collective human
dynamics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2356</identifier>
 <datestamp>2009-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2356</id><created>2009-01-15</created><updated>2009-01-28</updated><authors><author><keyname>Ma</keyname><forenames>Nan</forenames></author><author><keyname>Ishwar</keyname><forenames>Prakash</forenames></author><author><keyname>Gupta</keyname><forenames>Piyush</forenames></author></authors><title>Information-Theoretic Bounds for Multiround Function Computation in
  Collocated Networks</title><categories>cs.IT math.IT</categories><comments>9 pages. A 5-page version without appendices was submitted to IEEE
  International Symposium on Information Theory (ISIT), 2009. This version
  contains complete proofs as appendices</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the limits of communication efficiency for function computation in
collocated networks within the framework of multi-terminal block source coding
theory. With the goal of computing a desired function of sources at a sink,
nodes interact with each other through a sequence of error-free, network-wide
broadcasts of finite-rate messages. For any function of independent sources, we
derive a computable characterization of the set of all feasible message coding
rates - the rate region - in terms of single-letter information measures. We
show that when computing symmetric functions of binary sources, the sink will
inevitably learn certain additional information which is not demanded in
computing the function. This conceptual understanding leads to new improved
bounds for the minimum sum-rate. The new bounds are shown to be orderwise
better than those based on cut-sets as the network scales. The scaling law of
the minimum sum-rate is explored for different classes of symmetric functions
and source parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2367</identifier>
 <datestamp>2009-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2367</id><created>2009-01-15</created><updated>2009-01-17</updated><authors><author><keyname>Jalali</keyname><forenames>Shirin</forenames></author><author><keyname>Montanari</keyname><forenames>Andrea</forenames></author><author><keyname>Weissman</keyname><forenames>Tsachy</forenames></author></authors><title>An Implementable Scheme for Universal Lossy Compression of Discrete
  Markov Sources</title><categories>cs.IT math.IT</categories><comments>10 pages, 2 figures, Data Compression Conference (DCC) 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new lossy compressor for discrete sources. For coding a source
sequence $x^n$, the encoder starts by assigning a certain cost to each
reconstruction sequence. It then finds the reconstruction that minimizes this
cost and describes it losslessly to the decoder via a universal lossless
compressor. The cost of a sequence is given by a linear combination of its
empirical probabilities of some order $k+1$ and its distortion relative to the
source sequence. The linear structure of the cost in the empirical count matrix
allows the encoder to employ a Viterbi-like algorithm for obtaining the
minimizing reconstruction sequence simply. We identify a choice of coefficients
for the linear combination in the cost function which ensures that the
algorithm universally achieves the optimum rate-distortion performance of any
Markov source in the limit of large $n$, provided $k$ is increased as $o(\log
n)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2370</identifier>
 <datestamp>2009-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2370</id><created>2009-01-16</created><updated>2009-05-22</updated><authors><author><keyname>Hussami</keyname><forenames>Nadine</forenames></author><author><keyname>Korada</keyname><forenames>Satish Babu</forenames></author><author><keyname>Urbanke</keyname><forenames>Rudiger</forenames></author></authors><title>Performance of Polar Codes for Channel and Source Coding</title><categories>cs.IT math.IT</categories><comments>accepted in ISIT 2009, Figure 5 is different from the previous
  version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Polar codes, introduced recently by Ar\i kan, are the first family of codes
known to achieve capacity of symmetric channels using a low complexity
successive cancellation decoder. Although these codes, combined with successive
cancellation, are optimal in this respect, their finite-length performance is
not record breaking. We discuss several techniques through which their
finite-length performance can be improved. We also study the performance of
these codes in the context of source coding, both lossless and lossy, in the
single-user context as well as for distributed applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2376</identifier>
 <datestamp>2009-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2376</id><created>2009-01-15</created><authors><author><keyname>Watanabe</keyname><forenames>Sumio</forenames></author></authors><title>A Limit Theorem in Singular Regression Problem</title><categories>cs.LG</categories><comments>16 pages</comments><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  In statistical problems, a set of parameterized probability distributions is
used to estimate the true probability distribution. If Fisher information
matrix at the true distribution is singular, then it has been left unknown what
we can estimate about the true distribution from random samples. In this paper,
we study a singular regression problem and prove a limit theorem which shows
the relation between the singular regression problem and two birational
invariants, a real log canonical threshold and a singular fluctuation. The
obtained theorem has an important application to statistics, because it enables
us to estimate the generalization error from the training error without any
knowledge of the true probability distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2391</identifier>
 <datestamp>2009-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2391</id><created>2009-01-15</created><authors><author><keyname>Zeng</keyname><forenames>Xiangyong</forenames></author><author><keyname>Hu</keyname><forenames>Lei</forenames></author><author><keyname>Jiang</keyname><forenames>Wenfeng</forenames></author><author><keyname>Yue</keyname><forenames>Qin</forenames></author><author><keyname>Cao</keyname><forenames>Xiwang</forenames></author></authors><title>Weight Distribution of A p-ary Cyclic Code</title><categories>cs.IT cs.DM math.IT</categories><comments>15 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For an odd prime $p$ and two positive integers $n\geq 3$ and $k$ with
$\frac{n}{{\rm gcd}(n,k)}$ being odd, the paper determines the weight
distribution of a $p$-ary cyclic code $\mathcal{C}$ over $\mathbb{F}_{p}$ with
nonzeros $\alpha^{-1}$, $\alpha^{-(p^k+1)}$ and $\alpha^{-(p^{3k}+1)}$, where
$\alpha$ is a primitive element of $\mathbb{F}_{p^n}$
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2396</identifier>
 <datestamp>2009-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2396</id><created>2009-01-16</created><authors><author><keyname>Bursalioglu</keyname><forenames>Ozgun Y.</forenames></author><author><keyname>Fresia</keyname><forenames>Maria</forenames></author><author><keyname>Caire</keyname><forenames>Giuseppe</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Joint Source-Channel Coding at the Application Layer for Parallel
  Gaussian Sources</title><categories>cs.IT math.IT</categories><comments>5 pages, 4 figures, submitted to ISIT-09</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper the multicasting of independent parallel Gaussian sources over
a binary erasure broadcasted channel is considered. Multiresolution embedded
quantizer and layered joint source-channel coding schemes are used in order to
serve simultaneously several users at different channel capacities. The convex
nature of the rate-distortion function, computed by means of reverse
water-filling, allows us to solve relevant convex optimization problems
corresponding to different performance criteria. Then, layered joint
source-channel codes are constructed based on the concatenation of embedded
scalar quantizers with binary rateless encoders.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2399</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2399</id><created>2009-01-16</created><updated>2009-02-19</updated><authors><author><keyname>Blum</keyname><forenames>William</forenames></author><author><keyname>Ong</keyname><forenames>C. -H. Luke</forenames></author></authors><title>The Safe Lambda Calculus</title><categories>cs.PL cs.GT</categories><acm-class>F.3.2; F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 5, Issue 1 (February
  19, 2009) lmcs:1145</journal-ref><doi>10.2168/LMCS-5(1:3)2009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Safety is a syntactic condition of higher-order grammars that constrains
occurrences of variables in the production rules according to their
type-theoretic order. In this paper, we introduce the safe lambda calculus,
which is obtained by transposing (and generalizing) the safety condition to the
setting of the simply-typed lambda calculus. In contrast to the original
definition of safety, our calculus does not constrain types (to be
homogeneous). We show that in the safe lambda calculus, there is no need to
rename bound variables when performing substitution, as variable capture is
guaranteed not to happen. We also propose an adequate notion of beta-reduction
that preserves safety. In the same vein as Schwichtenberg's 1976
characterization of the simply-typed lambda calculus, we show that the numeric
functions representable in the safe lambda calculus are exactly the
multivariate polynomials; thus conditional is not definable. We also give a
characterization of representable word functions. We then study the complexity
of deciding beta-eta equality of two safe simply-typed terms and show that this
problem is PSPACE-hard. Finally we give a game-semantic analysis of safety: We
show that safe terms are denoted by `P-incrementally justified strategies'.
Consequently pointers in the game semantics of safe lambda-terms are only
necessary from order 4 onwards.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2401</identifier>
 <datestamp>2009-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2401</id><created>2009-01-16</created><updated>2009-05-29</updated><authors><author><keyname>Huh</keyname><forenames>Hoon</forenames></author><author><keyname>Papadopoulos</keyname><forenames>Haralabos</forenames></author><author><keyname>Caire</keyname><forenames>Giuseppe</forenames></author></authors><title>MIMO Broadcast Channel Optimization under General Linear Constraints</title><categories>cs.IT math.IT</categories><comments>accepted for ISIT 2009, replaced by the camera-ready version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The optimization of the transmit parameters (power allocation and steering
vectors) for the MIMO BC under general linear constraints is treated under the
optimal DPC coding strategy and the simple suboptimal linear zero-forcing
beamforming strategy. In the case of DPC, we show that &quot;SINR duality&quot; and
&quot;min-max duality&quot; yield the same dual MAC problem, and compare two alternatives
for its efficient solution. In the case of zero-forcing beamforming, we provide
a new efficient algorithm based on the direct optimization of a generalized
inverse matrix. In both cases, the algorithms presented here address the
problems in the most general form and can be applied to special cases
previously considered, such as per-antenna and per-group of antennas power
constraints, &quot;forbidden interference direction&quot; constraints, or any combination
thereof.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2410</identifier>
 <datestamp>2011-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2410</id><created>2009-01-16</created><updated>2011-08-18</updated><authors><author><keyname>Goseling</keyname><forenames>Jasper</forenames></author><author><keyname>Matsumoto</keyname><forenames>Ruytaroh</forenames></author><author><keyname>Uyematsu</keyname><forenames>Tomohiko</forenames></author><author><keyname>Weber</keyname><forenames>Jos H.</forenames></author></authors><title>On the Energy Benefit of Network Coding for Wireless Multiple Unicast</title><categories>cs.IT math.IT</categories><journal-ref>EURASIP Journal on Wireless Communications and Networking, Vol.
  2010 (2010), Art.ID 605421</journal-ref><doi>10.1155/2010/605421</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the energy savings that can be obtained by employing network
coding instead of plain routing in wireless multiple unicast problems. We
establish lower bounds on the benefit of network coding, defined as the maximum
of the ratio of the minimum energy required by routing and network coding
solutions, where the maximum is over all configurations. It is shown that if
coding and routing solutions are using the same transmission range, the benefit
in $d$-dimensional networks is at least $2d/\lfloor\sqrt{d}\rfloor$. Moreover,
it is shown that if the transmission range can be optimized for routing and
coding individually, the benefit in 2-dimensional networks is at least 3. Our
results imply that codes following a \emph{decode-and-recombine} strategy are
not always optimal regarding energy efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2416</identifier>
 <datestamp>2009-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2416</id><created>2009-01-16</created><authors><author><keyname>Gemmeke</keyname><forenames>J. F.</forenames></author><author><keyname>Cranen</keyname><forenames>B.</forenames></author></authors><title>TR01: Time-continuous Sparse Imputation</title><categories>cs.SD</categories><comments>9 pages, 5 figures, Technical Report</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An effective way to increase the noise robustness of automatic speech
recognition is to label noisy speech features as either reliable or unreliable
(missing) prior to decoding, and to replace the missing ones by clean speech
estimates. We present a novel method to obtain such clean speech estimates.
Unlike previous imputation frameworks which work on a frame-by-frame basis, our
method focuses on exploiting information from a large time-context. Using a
sliding window approach, denoised speech representations are constructed using
a sparse representation of the reliable features in an overcomplete basis of
fixed-length exemplar fragments. We demonstrate the potential of our approach
with experiments on the AURORA-2 connected digit database.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2434</identifier>
 <datestamp>2009-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2434</id><created>2009-01-16</created><authors><author><keyname>Albasini</keyname><forenames>L. de Francesco</forenames></author><author><keyname>Sabadini</keyname><forenames>N.</forenames></author><author><keyname>Walters</keyname><forenames>R. F. C.</forenames></author></authors><title>The compositional construction of Markov processes</title><categories>cs.LO math.CT math.PR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe an algebra for composing automata in which the actions have
probabilities. We illustrate by showing how to calculate the probability of
reaching deadlock in k steps in a model of the classical Dining Philosopher
problem, and show, using the Perron-Frobenius Theorem, that this probability
tends to 1 as k tends to infinity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2461</identifier>
 <datestamp>2009-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2461</id><created>2009-01-16</created><authors><author><keyname>Breslav</keyname><forenames>Andrey</forenames></author></authors><title>Grammatic -- a tool for grammar definition reuse and modularity</title><categories>cs.PL cs.SE</categories><comments>Submitted to DSL'09</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Grammatic is a tool for grammar definition and manipulation aimed to improve
modularity and reuse of grammars and related development artifacts. It is
independent from parsing technology and any other details of target system
implementation. Grammatic provides a way for annotating grammars with arbitrary
metadata (like associativity attributes, semantic actions or anything else). It
might be used as a front-end for external tools like parser generators to make
their input grammars modular and reusable. This paper describes main principles
behind Grammatic and gives an overview of languages it provides and their
ability to separate concerns and define reusable modules. Also it presents
sketches of possible use cases for the tool.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2483</identifier>
 <datestamp>2009-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2483</id><created>2009-01-16</created><updated>2009-04-05</updated><authors><author><keyname>Silva</keyname><forenames>Danilo</forenames></author><author><keyname>Kschischang</keyname><forenames>Frank R.</forenames></author></authors><title>Fast Encoding and Decoding of Gabidulin Codes</title><categories>cs.IT math.IT</categories><comments>5 pages, 1 figure, to be published at ISIT 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Gabidulin codes are the rank-metric analogs of Reed-Solomon codes and have a
major role in practical error control for network coding. This paper presents
new encoding and decoding algorithms for Gabidulin codes based on
low-complexity normal bases. In addition, a new decoding algorithm is proposed
based on a transform-domain approach. Together, these represent the fastest
known algorithms for encoding and decoding Gabidulin codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2518</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2518</id><created>2009-01-16</created><updated>2009-04-08</updated><authors><author><keyname>Claessen</keyname><forenames>Koen</forenames></author><author><keyname>Roorda</keyname><forenames>Jan-Willem</forenames></author></authors><title>A Faithful Semantics for Generalised Symbolic Trajectory Evaluation</title><categories>cs.LO</categories><acm-class>B.6.3; F.3.2; F.4.3</acm-class><journal-ref>Logical Methods in Computer Science, Volume 5, Issue 2 (April 8,
  2009) lmcs:1028</journal-ref><doi>10.2168/LMCS-5(2:1)2009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Generalised Symbolic Trajectory Evaluation (GSTE) is a high-capacity formal
verification technique for hardware. GSTE uses abstraction, meaning that
details of the circuit behaviour are removed from the circuit model. A
semantics for GSTE can be used to predict and understand why certain circuit
properties can or cannot be proven by GSTE. Several semantics have been
described for GSTE. These semantics, however, are not faithful to the proving
power of GSTE-algorithms, that is, the GSTE-algorithms are incomplete with
respect to the semantics.
  The abstraction used in GSTE makes it hard to understand why a specific
property can, or cannot, be proven by GSTE. The semantics mentioned above
cannot help the user in doing so. The contribution of this paper is a faithful
semantics for GSTE. That is, we give a simple formal theory that deems a
property to be true if-and-only-if the property can be proven by a GSTE-model
checker. We prove that the GSTE algorithm is sound and complete with respect to
this semantics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2538</identifier>
 <datestamp>2009-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2538</id><created>2009-01-16</created><authors><author><keyname>Kountouris</keyname><forenames>Marios</forenames></author><author><keyname>Andrews</keyname><forenames>Jeffrey G.</forenames></author></authors><title>Capacity Scaling of SDMA in Wireless Ad Hoc Networks</title><categories>cs.IT math.IT</categories><comments>5 pages, submitted to ISIT 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider an ad hoc network in which each multi-antenna transmitter sends
independent streams to multiple receivers in a Poisson field of interferers. We
provide the outage probability and transmission capacity scaling laws, aiming
at investigating the fundamental limits of Space Division Multiple Access
(SDMA). We first show that super linear capacity scaling with the number of
receive/transmit antennas can be achieved using dirty paper coding.
Nevertheless, the potential benefits of multi-stream, multi-antenna
communications fall off quickly if linear precoding is employed, leading to
sublinear capacity growth in the case of single-antenna receivers. A key
finding is that receive antenna array processing is of vital importance in SDMA
ad hoc networks, as a means to cancel the increased residual interference and
boost the signal power through diversity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2545</identifier>
 <datestamp>2009-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2545</id><created>2009-01-16</created><authors><author><keyname>Wu</keyname><forenames>Yiyue</forenames></author><author><keyname>Davis</keyname><forenames>Linda M.</forenames></author><author><keyname>Calderbank</keyname><forenames>Robert</forenames></author></authors><title>On the Capacity of the Discrete-Time Channel with Uniform Output
  Quantization</title><categories>cs.IT math.IT</categories><comments>submitted to ISIT 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper provides new insight into the classical problem of determining
both the capacity of the discrete-time channel with uniform output quantization
and the capacity achieving input distribution. It builds on earlier work by
Gallager and Witsenhausen to provide a detailed analysis of two particular
quantization schemes. The first is saturation quantization where overflows are
mapped to the nearest quantization bin, and the second is wrapping quantization
where overflows are mapped to the nearest quantization bin after reduction by
some modulus. Both the capacity of wrapping quantization and the capacity
achieving input distribution are determined. When the additive noise is
gaussian and relatively small, the capacity of saturation quantization is shown
to be bounded below by that of wrapping quantization. In the limit of
arbitrarily many uniform quantization levels, it is shown that the difference
between the upper and lower bounds on capacity given by Ihara is only 0.26
bits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2586</identifier>
 <datestamp>2009-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2586</id><created>2009-01-16</created><authors><author><keyname>Nock</keyname><forenames>Richard</forenames></author><author><keyname>Magdalou</keyname><forenames>Brice</forenames></author><author><keyname>Sanz</keyname><forenames>Nicolas</forenames></author><author><keyname>Briys</keyname><forenames>Eric</forenames></author><author><keyname>Celimene</keyname><forenames>Fred</forenames></author><author><keyname>Nielsen</keyname><forenames>Frank</forenames></author></authors><title>Information geometries and Microeconomic Theories</title><categories>q-fin.GN cs.IT math.IT</categories><acm-class>J.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  More than thirty years ago, Charnes, Cooper and Schinnar (1976) established
an enlightening contact between economic production functions (EPFs) -- a
cornerstone of neoclassical economics -- and information theory, showing how a
generalization of the Cobb-Douglas production function encodes homogeneous
functions.
  As expected by Charnes \textit{et al.}, the contact turns out to be much
broader: we show how information geometry as pioneered by Amari and others
underpins static and dynamic descriptions of microeconomic cornerstones.
  We show that the most popular EPFs are fundamentally grounded in a very weak
axiomatization of economic transition costs between inputs. The strength of
this characterization is surprising, as it geometrically bonds altogether a
wealth of collateral economic notions
  -- advocating for applications in various economic fields --: among all, it
characterizes (i) Marshallian and Hicksian demands and their geometric duality,
(ii) Slutsky-type properties for the transformation paths, (iii) Roy-type
properties for their elementary variations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2588</identifier>
 <datestamp>2009-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2588</id><created>2009-01-16</created><authors><author><keyname>Ghozlan</keyname><forenames>Hassan</forenames></author><author><keyname>Mohasseb</keyname><forenames>Yahya</forenames></author><author><keyname>Gamal</keyname><forenames>Hesham El</forenames></author><author><keyname>Kramer</keyname><forenames>Gerhard</forenames></author></authors><title>The MIMO Wireless Switch: Relaying Can Increase the Multiplexing Gain</title><categories>cs.IT math.IT</categories><comments>5 pages, 3 figures, submitted to ISIT'09</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers an interference network composed of K half-duplex
single-antenna pairs of users who wish to establish bi-directional
communication with the aid of a multi-input-multi-output (MIMO) half-duplex
relay node. This channel is referred to as the &quot;MIMO Wireless Switch&quot; since,
for the sake of simplicity, our model assumes no direct link between the two
end nodes of each pair implying that all communication must go through the
relay node (i.e., the MIMO switch). Assuming a delay-limited scenario, the
fundamental limits in the high signal-to-noise ratio (SNR) regime is analyzed
using the diversity multiplexing tradeoff (DMT) framework. Our results sheds
light on the structure of optimal transmission schemes and the gain offered by
the relay node in two distinct cases, namely reciprocal and non-reciprocal
channels (between the relay and end-users). In particular, the existence of a
relay node, equipped with a sufficient number of antennas, is shown to increase
the multiplexing gain; as compared with the traditional fully connected K-pair
interference channel. To the best of our knowledge, this is the first known
example where adding a relay node results in enlarging the pre-log factor of
the sum rate. Moreover, for the case of reciprocal channels, it is shown that,
when the relay has a number of antennas at least equal to the sum of antennas
of all the users, static time allocation of decode and forward (DF) type
schemes is optimal. On the other hand, in the non-reciprocal scenario, we
establish the optimality of dynamic decode and forward in certain relevant
scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2606</identifier>
 <datestamp>2009-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2606</id><created>2009-01-16</created><authors><author><keyname>Peng</keyname><forenames>Yong</forenames></author><author><keyname>Rajan</keyname><forenames>Dinesh</forenames></author></authors><title>Capacity Bounds of Half-Duplex Gaussian Cooperative Interference Channel</title><categories>cs.IT math.IT</categories><comments>5 pages, 3 figures, submitted to IEEE ISIT 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate the half-duplex cooperative communication
scheme of a two user Gaussian interference channel. We develop achievable
region and outer bound for the case when the system allow either transmitter or
receiver cooperation. We show that by using our transmitter cooperation scheme,
there is significant capacity improvement compare to the previous results,
especially when the cooperation link is strong. Further, if the cooperation
channel gain is infinity, both our transmitter and receiver cooperation rates
achieve their respective outer bound. It is also shown that transmitter
cooperation provides larger achievable region than receiver cooperation under
the same channel and power conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2612</identifier>
 <datestamp>2009-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2612</id><created>2009-01-17</created><authors><author><keyname>Duchamp</keyname><forenames>G&#xe9;rard Henry Edmond</forenames><affiliation>LIPN</affiliation></author><author><keyname>Cheballah</keyname><forenames>H.</forenames><affiliation>LIPN</affiliation></author></authors><title>Some Open Problems in Combinatorial Physics</title><categories>cs.SC math.CO quant-ph</categories><proxy>ccsd hal-00353947</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We point out four problems which have arisen during the recent research in
the domain of Combinatorial Physics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2616</identifier>
 <datestamp>2009-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2616</id><created>2009-01-19</created><updated>2009-04-30</updated><authors><author><keyname>Khalil</keyname><forenames>Karim</forenames></author><author><keyname>Youssef</keyname><forenames>Moustafa</forenames></author><author><keyname>Koyluoglu</keyname><forenames>O. Ozan</forenames></author><author><keyname>Gamal</keyname><forenames>Hesham El</forenames></author></authors><title>On the Delay Limited Secrecy Capacity of Fading Channels</title><categories>cs.IT cs.CR math.IT</categories><comments>Proceedings of the 2009 IEEE International Symposium on Information
  Theory (ISIT 2009), Seoul, Korea, June 28-July 3, 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the delay limited secrecy capacity of the flat fading channel
is investigated under two different assumptions on the available transmitter
channel state information (CSI). The first scenario assumes perfect prior
knowledge of both the main and eavesdropper channel gains. Here, upper and
lower bounds on the secure delay limited capacity are derived and shown to be
tight in the high signal-to-noise ratio (SNR) regime (for a wide class of
channel distributions). In the second scenario, only the main channel CSI is
assumed to be available at the transmitter. Remarkably, under this assumption,
we establish the achievability of non-zero secure rate (for a wide class of
channel distributions) under a strict delay constraint. In the two cases, our
achievability arguments are based on a novel two-stage approach that overcomes
the secrecy outage phenomenon observed in earlier works.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2645</identifier>
 <datestamp>2009-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2645</id><created>2009-01-17</created><updated>2009-02-17</updated><authors><author><keyname>Habib</keyname><forenames>Michel</forenames><affiliation>LIAFA</affiliation></author><author><keyname>Limouzy</keyname><forenames>Vincent</forenames></author></authors><title>On some simplicial elimination schemes for chordal graphs</title><categories>cs.DS</categories><proxy>ccsd hal-00353959</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present here some results on particular elimination schemes for chordal
graphs, namely we show that for any chordal graph we can construct in linear
time a simplicial elimination scheme starting with a pending maximal clique
attached via a minimal separator maximal (resp. minimal) under inclusion among
all minimal separators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2665</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2665</id><created>2009-01-17</created><authors><author><keyname>Polizzi</keyname><forenames>Eric</forenames></author></authors><title>A Density Matrix-based Algorithm for Solving Eigenvalue Problems</title><categories>cs.CE cs.MS</categories><comments>7 pages, 3 figures</comments><doi>10.1103/PhysRevB.79.115112</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new numerical algorithm for solving the symmetric eigenvalue problem is
presented. The technique deviates fundamentally from the traditional Krylov
subspace iteration based techniques (Arnoldi and Lanczos algorithms) or other
Davidson-Jacobi techniques, and takes its inspiration from the contour
integration and density matrix representation in quantum mechanics. It will be
shown that this new algorithm - named FEAST - exhibits high efficiency,
robustness, accuracy and scalability on parallel architectures. Examples from
electronic structure calculations of Carbon nanotubes (CNT) are presented, and
numerical performances and capabilities are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2682</identifier>
 <datestamp>2009-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2682</id><created>2009-01-18</created><authors><author><keyname>Bickson</keyname><forenames>Danny</forenames></author><author><keyname>Hoch</keyname><forenames>Ezra N.</forenames></author><author><keyname>Avissar</keyname><forenames>Harel</forenames></author><author><keyname>Dolev</keyname><forenames>Danny</forenames></author></authors><title>Self-stabilizing Numerical Iterative Computation</title><categories>cs.NA cs.DC</categories><comments>Submitted to Theory of Computer Science (TCS) Journal</comments><report-no>TCS09</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many challenging tasks in sensor networks, including sensor calibration,
ranking of nodes, monitoring, event region detection, collaborative filtering,
collaborative signal processing, {\em etc.}, can be formulated as a problem of
solving a linear system of equations. Several recent works propose different
distributed algorithms for solving these problems, usually by using linear
iterative numerical methods.
  The main problem with previous approaches is that once the problem inputs
change during the process of computation, the computation may output unexpected
results. In real life settings, sensor measurements are subject to varying
environmental conditions and to measurement noise.
  We present a simple iterative scheme called SS-Iterative for solving systems
of linear equations, and examine its properties in the self-stabilizing
perspective. We analyze the behavior of the proposed scheme under changing
input sequences using two different assumptions on the input: a box bound, and
a probabilistic distribution.
  As a case study, we discuss the sensor calibration problem and provide
simulation results to support the applicability of our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2684</identifier>
 <datestamp>2010-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2684</id><created>2009-01-18</created><updated>2009-05-09</updated><authors><author><keyname>Bickson</keyname><forenames>Danny</forenames></author><author><keyname>Tock</keyname><forenames>Yoav</forenames></author><author><keyname>Zymnis</keyname><forenames>Argyris</forenames></author><author><keyname>Boyd</keyname><forenames>Stephen</forenames></author><author><keyname>Dolev</keyname><forenames>Danny</forenames></author></authors><title>Distributed Large Scale Network Utility Maximization</title><categories>cs.IT cs.DC math.IT math.OC</categories><comments>In the International Symposium on Information Theory (ISIT) 2009</comments><doi>10.1109/ISIT.2009.5205655</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent work by Zymnis et al. proposes an efficient primal-dual interior-point
method, using a truncated Newton method, for solving the network utility
maximization (NUM) problem. This method has shown superior performance relative
to the traditional dual-decomposition approach. Other recent work by Bickson et
al. shows how to compute efficiently and distributively the Newton step, which
is the main computational bottleneck of the Newton method, utilizing the
Gaussian belief propagation algorithm.
  In the current work, we combine both approaches to create an efficient
distributed algorithm for solving the NUM problem. Unlike the work of Zymnis,
which uses a centralized approach, our new algorithm is easily distributed.
Using an empirical evaluation we show that our new method outperforms previous
approaches, including the truncated Newton method and dual-decomposition
methods. As an additional contribution, this is the first work that evaluates
the performance of the Gaussian belief propagation algorithm vs. the
preconditioned conjugate gradient method, for a large scale problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2685</identifier>
 <datestamp>2009-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2685</id><created>2009-01-18</created><authors><author><keyname>Bickson</keyname><forenames>Danny</forenames></author><author><keyname>Gershinsky</keyname><forenames>Gidon</forenames></author><author><keyname>Hoch</keyname><forenames>Ezra N.</forenames></author><author><keyname>Shagin</keyname><forenames>Konstantin</forenames></author></authors><title>A Statistical Approach to Performance Monitoring in Soft Real-Time
  Distributed Systems</title><categories>cs.NI cs.DC</categories><comments>Submitted to the 29th Int'l Conference on Distributed Computing
  Systems (ICDCS 2009)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Soft real-time applications require timely delivery of messages conforming to
the soft real-time constraints. Satisfying such requirements is a complex task
both due to the volatile nature of distributed environments, as well as due to
numerous domain-specific factors that affect message latency. Prompt detection
of the root-cause of excessive message delay allows a distributed system to
react accordingly. This may significantly improve compliance with the required
timeliness constraints.
  In this work, we present a novel approach for distributed performance
monitoring of soft-real time distributed systems. We propose to employ recent
distributed algorithms from the statistical signal processing and learning
domains, and to utilize them in a different context of online performance
monitoring and root-cause analysis, for pinpointing the reasons for violation
of performance requirements. Our approach is general and can be used for
monitoring of any distributed system, and is not limited to the soft real-time
domain.
  We have implemented the proposed framework in TransFab, an IBM prototype of
soft real-time messaging fabric. In addition to root-cause analysis, the
framework includes facilities to resolve resource allocation problems, such as
memory and bandwidth deficiency. The experiments demonstrate that the system
can identify and resolve latency problems in a timely fashion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2687</identifier>
 <datestamp>2010-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2687</id><created>2009-01-18</created><updated>2010-04-12</updated><authors><author><keyname>Bickson</keyname><forenames>Danny</forenames></author><author><keyname>Hoch</keyname><forenames>Ezra N.</forenames></author><author><keyname>Naaman</keyname><forenames>Nir</forenames></author><author><keyname>Tock</keyname><forenames>Yoav</forenames></author></authors><title>A Hybrid Multicast-Unicast Infrastructure for Efficient
  Publish-Subscribe in Enterprise Networks</title><categories>cs.NI cs.DC</categories><journal-ref>SYSTOR 2010 - The 3rd Annual Haifa Experimental Systems
  Conference, Haifa, Israel, May 24-26, 2010</journal-ref><doi>10.1145/1815695.1815722</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the main challenges in building a large scale publish-subscribe
infrastructure in an enterprise network, is to provide the subscribers with the
required information, while minimizing the consumed host and network resources.
Typically, previous approaches utilize either IP multicast or point-to-point
unicast for efficient dissemination of the information.
  In this work, we propose a novel hybrid framework, which is a combination of
both multicast and unicast data dissemination. Our hybrid framework allows us
to take the advantages of both multicast and unicast, while avoiding their
drawbacks. We investigate several algorithms for computing the best mapping of
publishers' transmissions into multicast and unicast transport.
  Using extensive simulations, we show that our hybrid framework reduces
consumed host and network resources, outperforming traditional solutions. To
insure the subscribers interests closely resemble those of real-world settings,
our simulations are based on stock market data and on recorded IBM WebShpere
subscriptions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2689</identifier>
 <datestamp>2010-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2689</id><created>2009-01-18</created><authors><author><keyname>Bickson</keyname><forenames>Danny</forenames></author><author><keyname>Reinman</keyname><forenames>Tzachy</forenames></author><author><keyname>Dolev</keyname><forenames>Danny</forenames></author><author><keyname>Pinkas</keyname><forenames>Benny</forenames></author></authors><title>Peer-to-Peer Secure Multi-Party Numerical Computation Facing Malicious
  Adversaries</title><categories>cs.CR cs.NI</categories><comments>Submitted to Peer-to-Peer Networking and Applications Journal (PPNA)
  2009</comments><doi>10.1007/s12083-009-0051-9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an efficient framework for enabling secure multi-party numerical
computations in a Peer-to-Peer network. This problem arises in a range of
applications such as collaborative filtering, distributed computation of trust
and reputation, monitoring and other tasks, where the computing nodes is
expected to preserve the privacy of their inputs while performing a joint
computation of a certain function. Although there is a rich literature in the
field of distributed systems security concerning secure multi-party
computation, in practice it is hard to deploy those methods in very large scale
Peer-to-Peer networks. In this work, we try to bridge the gap between
theoretical algorithms in the security domain, and a practical Peer-to-Peer
deployment.
  We consider two security models. The first is the semi-honest model where
peers correctly follow the protocol, but try to reveal private information. We
provide three possible schemes for secure multi-party numerical computation for
this model and identify a single light-weight scheme which outperforms the
others. Using extensive simulation results over real Internet topologies, we
demonstrate that our scheme is scalable to very large networks, with up to
millions of nodes. The second model we consider is the malicious peers model,
where peers can behave arbitrarily, deliberately trying to affect the results
of the computation as well as compromising the privacy of other peers. For this
model we provide a fourth scheme to defend the execution of the computation
against the malicious peers. The proposed scheme has a higher complexity
relative to the semi-honest model. Overall, we provide the Peer-to-Peer network
designer a set of tools to choose from, based on the desired level of security.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2698</identifier>
 <datestamp>2009-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2698</id><created>2009-01-18</created><updated>2009-10-12</updated><authors><author><keyname>Sriperumbudur</keyname><forenames>Bharath K.</forenames></author><author><keyname>Fukumizu</keyname><forenames>Kenji</forenames></author><author><keyname>Gretton</keyname><forenames>Arthur</forenames></author><author><keyname>Sch&#xf6;lkopf</keyname><forenames>Bernhard</forenames></author><author><keyname>Lanckriet</keyname><forenames>Gert R. G.</forenames></author></authors><title>On integral probability metrics, \phi-divergences and binary
  classification</title><categories>cs.IT math.IT</categories><comments>18 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A class of distance measures on probabilities -- the integral probability
metrics (IPMs) -- is addressed: these include the Wasserstein distance, Dudley
metric, and Maximum Mean Discrepancy. IPMs have thus far mostly been used in
more abstract settings, for instance as theoretical tools in mass
transportation problems, and in metrizing the weak topology on the set of all
Borel probability measures defined on a metric space. Practical applications of
IPMs are less common, with some exceptions in the kernel machines literature.
The present work contributes a number of novel properties of IPMs, which should
contribute to making IPMs more widely used in practice, for instance in areas
where $\phi$-divergences are currently popular.
  First, to understand the relation between IPMs and $\phi$-divergences, the
necessary and sufficient conditions under which these classes intersect are
derived: the total variation distance is shown to be the only non-trivial
$\phi$-divergence that is also an IPM. This shows that IPMs are essentially
different from $\phi$-divergences. Second, empirical estimates of several IPMs
from finite i.i.d. samples are obtained, and their consistency and convergence
rates are analyzed. These estimators are shown to be easily computable, with
better rates of convergence than estimators of $\phi$-divergences. Third, a
novel interpretation is provided for IPMs by relating them to binary
classification, where it is shown that the IPM between class-conditional
distributions is the negative of the optimal risk associated with a binary
classifier. In addition, the smoothness of an appropriate binary classifier is
proved to be inversely related to the distance between the class-conditional
distributions, measured in terms of an IPM.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2703</identifier>
 <datestamp>2010-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2703</id><created>2009-01-18</created><updated>2010-09-17</updated><authors><author><keyname>Yakaryilmaz</keyname><forenames>Abuzer</forenames></author><author><keyname>Say</keyname><forenames>A. C. Cem</forenames></author></authors><title>Language recognition by generalized quantum finite automata with
  unbounded error (abstract &amp; poster)</title><categories>cs.CC</categories><comments>2 pages, poster presented at the 4th Workshop on Theory of Quantum
  Computation, Communication, and Cryptography (TQC2009)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this note, we generalize the results of arXiv:0901.2703v1 We show that all
one-way quantum finite automaton (QFA) models that are at least as general as
Kondacs-Watrous QFA's are equivalent in power to classical probabilistic finite
automata in this setting. Unlike their probabilistic counterparts, allowing the
tape head to stay put for some steps during its traversal of the input does
enlarge the class of languages recognized by such QFA's with unbounded error.
(Note that, the proof of Theorem 1 in the abstract was presented in the
previous version (arXiv:0901.2703v1).)
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2723</identifier>
 <datestamp>2009-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2723</id><created>2009-01-18</created><updated>2009-02-01</updated><authors><author><keyname>Young</keyname><forenames>A. P.</forenames></author></authors><title>Information science and technology as applications of the physics of
  signalling</title><categories>cs.OH</categories><comments>13 pages including 3 diagrams. The hypothesis, proposed, is explained
  from first principles, no directly-related work found in the literature</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Adopting the scientific method a theoretical model is proposed as foundation
for information science and technology, extending the existing theory of
signaling: a fact f becomes known in a physical system only following the
success of a test f, tests performed primarily by human sensors and applied to
(physical) phenomena within which further tests may be performed. Tests are
phenomena and classify phenomena. A phenomenon occupies both time and space,
facts and inferences having physical counterparts which are phenomena of
specified classes. Identifiers such as f are conventional, assigned by humans;
a fact (f', f'') reports the success of a test of generic class f', the outcome
f'' of the reported application classifying the successful test in more detail.
Facts then exist only within structures of a form dictated by constraints on
the structural design of tests. The model explains why responses of real time
systems are not uniquely predictable and why restrictions, on concurrency in
performing inferences within them, are needed. Improved methods, based on the
model and applicable throughout the software life-cycle, are summarised in the
paper. No report of similar work has been found in the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2731</identifier>
 <datestamp>2009-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2731</id><created>2009-01-18</created><authors><author><keyname>Friedmann</keyname><forenames>Oliver</forenames></author></authors><title>A Super-Polynomial Lower Bound for the Parity Game Strategy Improvement
  Algorithm as We Know it</title><categories>cs.GT</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This paper presents a new lower bound for the discrete strategy improvement
algorithm for solving parity games due to Voege and Jurdziski. First, we
informally show which structures are difficult to solve for the algorithm.
Second, we outline a family of games of quadratic size on which the algorithm
requires exponentially many strategy iterations, answering in the negative the
long-standing question whether this algorithm runs in polynomial time.
Additionally we note that the same family of games can be used to prove a
similar result w.r.t. the strategy improvement variant by Schewe.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2742</identifier>
 <datestamp>2009-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2742</id><created>2009-01-18</created><authors><author><keyname>Saeed</keyname><forenames>Fahad</forenames></author><author><keyname>Khokhar</keyname><forenames>Ashfaq</forenames></author></authors><title>Sample-Align-D: A High Performance Multiple Sequence Alignment System
  using Phylogenetic Sampling and Domain Decomposition</title><categories>cs.DC q-bio.GN q-bio.QM</categories><comments>12 pages, 8 figures, paper appeared in HICOMB, IPDPS 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multiple Sequence Alignment (MSA) is one of the most computationally
intensive tasks in Computational Biology. Existing best known solutions for
multiple sequence alignment take several hours (in some cases days) of
computation time to align, for example, 2000 homologous sequences of average
length 300. Inspired by the Sample Sort approach in parallel processing, in
this paper we propose a highly scalable multiprocessor solution for the MSA
problem in phylogenetically diverse sequences. Our method employs an
intelligent scheme to partition the set of sequences into smaller subsets using
kmer count based similarity index, referred to as k-mer rank. Each subset is
then independently aligned in parallel using any sequential approach. Further
fine tuning of the local alignments is achieved using constraints derived from
a global ancestor of the entire set. The proposed Sample-Align-D Algorithm has
been implemented on a cluster of workstations using MPI message passing
library. The accuracy of the proposed solution has been tested on standard
benchmarks such as PREFAB. The accuracy of the alignment produced by our
methods is comparable to that of well known sequential MSA techniques. We were
able to align 2000 randomly selected sequences from the Methanosarcina
acetivorans genome in less than 10 minutes using Sample-Align-D on a 16 node
cluster, compared to over 23 hours on sequential MUSCLE system running on a
single cluster node.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2747</identifier>
 <datestamp>2009-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2747</id><created>2009-01-18</created><authors><author><keyname>Saeed</keyname><forenames>Fahad</forenames></author><author><keyname>Khokhar</keyname><forenames>Ashfaq</forenames></author></authors><title>An Overview of Multiple Sequence Alignment Systems</title><categories>cs.DS q-bio.GN q-bio.QM</categories><comments>24 pages, 15 figures, Technical Report Parallel Algorithms &amp;
  Multimedia System Laboratory</comments><report-no>PAMS-05-2007</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An overview of current multiple alignment systems to date are described.The
useful algorithms, the procedures adopted and their limitations are
presented.We also present the quality of the alignments obtained and in which
cases(kind of alignments, kind of sequences etc) the particular systems are
useful.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2751</identifier>
 <datestamp>2009-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2751</id><created>2009-01-18</created><authors><author><keyname>Saeed</keyname><forenames>Fahad</forenames></author></authors><title>Pyro-Align: Sample-Align based Multiple Alignment system for
  Pyrosequencing Reads of Large Number</title><categories>cs.DS cs.DC q-bio.GN q-bio.QM</categories><comments>6 pages, 1 figure, Technical Report, Department of Biosystems Science
  and Engineering, ETH Zurich Switzerland</comments><report-no>DBSSE-08-2008</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pyro-Align is a multiple alignment program specifically designed for
pyrosequencing reads of huge number. Multiple sequence alignment is shown to be
NP-hard and heuristics are designed for approximate solutions. Multiple
sequence alignment of pyrosequenceing reads is complex mainly because of 2
factors. One being the huge number of reads, making the use of traditional
heuristics,that scale very poorly for large number, unsuitable. The second
reason is that the alignment cannot be performed arbitrarily, because the
position of the reads with respect to the original genome is important and has
to be taken into account.In this report we present a short description of the
multiple alignment system for pyrosequencing reads.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2764</identifier>
 <datestamp>2009-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2764</id><created>2009-01-19</created><authors><author><keyname>Vaze</keyname><forenames>Chinmay S.</forenames></author><author><keyname>Varanasi</keyname><forenames>Mahesh K.</forenames></author></authors><title>Dirty Paper Coding for Fading Channels with Partial Transmitter Side
  Information</title><categories>cs.IT math.IT</categories><comments>5 pages with 2 figures, presented at 42nd Asilomar Conference on
  Signals, Systems, and Computers, Pacific Grove, USA, Oct. 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of Dirty Paper Coding (DPC) over the Fading Dirty Paper Channel
(FDPC) Y = H(X + S)+Z, a more general version of Costa's channel, is studied
for the case in which there is partial and perfect knowledge of the fading
process H at the transmitter (CSIT) and the receiver (CSIR), respectively. A
key step in this problem is to determine the optimal inflation factor (under
Costa's choice of auxiliary random variable) when there is only partial CSIT.
Towards this end, two iterative numerical algorithms are proposed. Both of
these algorithms are seen to yield a good choice for the inflation factor.
Finally, the high-SNR (signal-to-noise ratio) behavior of the achievable rate
over the FDPC is dealt with. It is proved that FDPC (with t transmit and r
receive antennas) achieves the largest possible scaling factor of min(t,r) log
SNR even with no CSIT. Furthermore, in the high SNR regime, the optimality of
Costa's choice of auxiliary random variable is established even when there is
partial (or no) CSIT in the special case of FDPC with t &lt;= r. Using the
high-SNR scaling-law result of the FDPC (mentioned before), it is shown that a
DPC-based multi-user transmission strategy, unlike other beamforming-based
multi-user strategies, can achieve a single-user sum-rate scaling factor over
the multiple-input multiple-output Gaussian Broadcast Channel with partial (or
no) CSIT.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2768</identifier>
 <datestamp>2009-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2768</id><created>2009-01-19</created><authors><author><keyname>Barik</keyname><forenames>S.</forenames></author><author><keyname>Mohammed</keyname><forenames>Saif K.</forenames></author><author><keyname>Chockalingam</keyname><forenames>A.</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>FRFD MIMO Systems: Precoded V-BLAST with Limited Feedback Versus
  Non-orthogonal STBC MIMO</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Full-rate (FR) and full-diversity (FD) are attractive features in MIMO
systems. We refer to systems which achieve both FR and FD simultaneously as
FRFD systems. Non-orthogonal STBCs can achieve FRFD without feedback, but their
ML decoding complexities are high. V-BLAST without precoding achieves FR but
not FD. FRFD can be achieved in V-BLAST through precoding given full channel
state information at the transmitter (CSIT). However, with limited feedback
precoding, V-BLAST achieves FD, but with some rate loss. Our contribution in
this paper is two-fold: $i)$ we propose a limited feedback (LFB) precoding
scheme which achieves FRFD in $2\times 2$, $3\times 3$ and $4\times 4$ V-BLAST
systems (we refer to this scheme as FRFD-VBLAST-LFB scheme), and $ii)$
comparing the performances of the FRFD-VBLAST-LFB scheme and non-orthogonal
STBCs without feedback (e.g., Golden code, perfect codes) under ML decoding, we
show that in $2\times 2$ MIMO system with 4-QAM/16-QAM, FRFD-VBLAST-LFB scheme
outperforms the Golden code by about 0.6 dB; in $3\times 3$ and $4\times 4$
MIMO systems, the performance of FRFD-VBLAST-LFB scheme is comparable to the
performance of perfect codes. The FRFD-VBLAST-LFB scheme is attractive because
1) ML decoding becomes less complex compared to that of non-orthogonal STBCs,
2) the number of feedback bits required to achieve the above performance is
small, 3) in slow-fading, it is adequate to send feedback bits only
occasionally, and 4) in most practical wireless systems feedback channel is
often available (e.g., for adaptive modulation, rate/power control).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2771</identifier>
 <datestamp>2009-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2771</id><created>2009-01-19</created><authors><author><keyname>Gupta</keyname><forenames>Shalabh</forenames></author></authors><title>Automatic Analog Beamforming Transceiver for 60 GHz Radios</title><categories>cs.NI</categories><comments>Submitted to 2009 IEEE RFIC Symposium</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a transceiver architecture for automatic beamforming and
instantaneous setup of a multigigabit-per-second wireless link between two
millimeter wave radios. The retro-directive architecture eliminates necessity
of slow and complex digital algorithms required for searching and tracking the
directions of opposite end radios. Simulations predict &lt;5 micro-seconds setup
time for a 2-Gbps bidirectional 60-GHz communication link between two 10-meters
apart radios. The radios have 4-element arrayed antennas, and use QPSK
modulation with 1.5 GHz analog bandwidth.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2778</identifier>
 <datestamp>2011-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2778</id><created>2009-01-19</created><authors><author><keyname>Janovitz-Freireich</keyname><forenames>Itnuit</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Mourrain</keyname><forenames>Bernard</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Ronayi</keyname><forenames>Lajos</forenames></author><author><keyname>Szanto</keyname><forenames>Agnes</forenames></author></authors><title>On the Computation of Matrices of Traces and Radicals of Ideals</title><categories>cs.SC math.AC</categories><proxy>ccsd inria-00354120</proxy><journal-ref>Journal of Symbolic Computation 47, 1 (2012) 102-122</journal-ref><doi>10.1016/j.jsc.2011.08.020</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $f_1,...,f_s \in \mathbb{K}[x_1,...,x_m]$ be a system of polynomials
generating a zero-dimensional ideal $\I$, where $\mathbb{K}$ is an arbitrary
algebraically closed field. We study the computation of &quot;matrices of traces&quot;
for the factor algebra $\A := \CC[x_1, ..., x_m]/ \I$, i.e. matrices with
entries which are trace functions of the roots of $\I$. Such matrices of traces
in turn allow us to compute a system of multiplication matrices
$\{M_{x_i}|i=1,...,m\}$ of the radical $\sqrt{\I}$. We first propose a method
using Macaulay type resultant matrices of $f_1,...,f_s$ and a polynomial $J$ to
compute moment matrices, and in particular matrices of traces for $\A$. Here
$J$ is a polynomial generalizing the Jacobian. We prove bounds on the degrees
needed for the Macaulay matrix in the case when $\I$ has finitely many
projective roots in $\mathbb{P}^m_\CC$. We also extend previous results which
work only for the case where $\A$ is Gorenstein to the non-Gorenstein case. The
second proposed method uses Bezoutian matrices to compute matrices of traces of
$\A$. Here we need the assumption that $s=m$ and $f_1,...,f_m$ define an affine
complete intersection. This second method also works if we have higher
dimensional components at infinity. A new explicit description of the
generators of $\sqrt{\I}$ are given in terms of Bezoutians.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2804</identifier>
 <datestamp>2009-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2804</id><created>2009-01-19</created><updated>2009-06-11</updated><authors><author><keyname>Choo</keyname><forenames>Li-Chia</forenames></author><author><keyname>Wong</keyname><forenames>Kai-Kit</forenames></author></authors><title>The Secrecy Capacity for a 3-Receiver Broadcast Channel with Degraded
  Message Sets</title><categories>cs.IT math.IT</categories><comments>This paper has been withdrawn by the author</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn by the author due to some errors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2838</identifier>
 <datestamp>2009-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2838</id><created>2009-01-19</created><authors><author><keyname>Nozaki</keyname><forenames>Takayuki</forenames></author><author><keyname>Kasai</keyname><forenames>Kenta</forenames></author><author><keyname>Sakaniwa</keyname><forenames>Kohichi</forenames></author></authors><title>Analytical Solution of Covariance Evolution for Regular LDPC Codes</title><categories>cs.IT math.IT</categories><comments>5 pages, 3 figures, submitted to ISIT2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The covariance evolution is a system of differential equations with respect
to the covariance of the number of edges connecting to the nodes of each
residual degree. Solving the covariance evolution, we can derive distributions
of the number of check nodes of residual degree 1, which helps us to estimate
the block error probability for finite-length LDPC code. Amraoui et al.\
resorted to numerical computations to solve the covariance evolution. In this
paper, we give the analytical solution of the covariance evolution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2847</identifier>
 <datestamp>2009-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2847</id><created>2009-01-19</created><authors><author><keyname>Bouvel</keyname><forenames>Mathilde</forenames><affiliation>LIAFA</affiliation></author><author><keyname>Chauve</keyname><forenames>Cedric</forenames><affiliation>LIAFA</affiliation></author><author><keyname>Mishna</keyname><forenames>Marni</forenames><affiliation>LIAFA</affiliation></author><author><keyname>Rossin</keyname><forenames>Dominique</forenames><affiliation>LIAFA</affiliation></author></authors><title>Average-case analysis of perfect sorting by reversals</title><categories>math.CO cs.DS q-bio.QM</categories><proxy>ccsd hal-00354235</proxy><msc-class>05A05, 05A16, 05C90, 05C05</msc-class><journal-ref>CPM'09, Lille : France (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A sequence of reversals that takes a signed permutation to the identity is
perfect if at no step a common interval is broken. Determining a parsimonious
perfect sequence of reversals that sorts a signed permutation is NP-hard. Here
we show that, despite this worst-case analysis, with probability one, sorting
can be done in polynomial time. Further, we find asymptotic expressions for the
average length and number of reversals in commuting permutations, an
interesting sub-class of signed permutations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2850</identifier>
 <datestamp>2009-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2850</id><created>2009-01-19</created><authors><author><keyname>Baselice</keyname><forenames>Sabrina</forenames></author><author><keyname>Bonatti</keyname><forenames>Piero A.</forenames></author><author><keyname>Criscuolo</keyname><forenames>Giovanni</forenames></author></authors><title>On finitely recursive programs</title><categories>cs.AI cs.LO</categories><comments>26 pages, Preliminary version in Proc. of ICLP 2007, Best paper award</comments><journal-ref>Theory and Practice of Logic Programming, 9(2), 213-238, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Disjunctive finitary programs are a class of logic programs admitting
function symbols and hence infinite domains. They have very good computational
properties, for example ground queries are decidable while in the general case
the stable model semantics is highly undecidable. In this paper we prove that a
larger class of programs, called finitely recursive programs, preserves most of
the good properties of finitary programs under the stable model semantics,
namely: (i) finitely recursive programs enjoy a compactness property; (ii)
inconsistency checking and skeptical reasoning are semidecidable; (iii)
skeptical resolution is complete for normal finitely recursive programs.
Moreover, we show how to check inconsistency and answer skeptical queries using
finite subsets of the ground program instantiation. We achieve this by
extending the splitting sequence theorem by Lifschitz and Turner: We prove that
if the input program P is finitely recursive, then the partial stable models
determined by any smooth splitting omega-sequence converge to a stable model of
P.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2864</identifier>
 <datestamp>2010-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2864</id><created>2009-01-19</created><authors><author><keyname>Duursma</keyname><forenames>Iwan</forenames></author><author><keyname>Kirov</keyname><forenames>Radoslav</forenames></author></authors><title>An extension of the order bound for AG codes</title><categories>math.NT cs.IT math.AG math.IT</categories><comments>11 pages</comments><msc-class>14G50, 11T71, 94B</msc-class><doi>10.1007/978-3-642-02181-7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The most successful method to obtain lower bounds for the minimum distance of
an algebraic geometric code is the order bound, which generalizes the Feng-Rao
bound. We provide a significant extension of the bound that improves the order
bounds by Beelen and by Duursma and Park. We include an exhaustive numerical
comparison of the different bounds for 10168 two-point codes on the Suzuki
curve of genus g=124 over the field of 32 elements. Keywords: algebraic
geometric code, order bound, Suzuki curve.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2897</identifier>
 <datestamp>2009-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2897</id><created>2009-01-19</created><updated>2009-04-13</updated><authors><author><keyname>Gawrychowski</keyname><forenames>Pawel</forenames></author><author><keyname>Jez</keyname><forenames>Artur</forenames></author><author><keyname>Jez</keyname><forenames>Lukasz</forenames></author></authors><title>Online validation of the pi and pi' failure functions</title><categories>cs.DS</categories><comments>submitted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let pi_w denote the failure function of the Morris-Pratt algorithm for a word
w. In this paper we study the following problem: given an integer array
A[1..n], is there a word w over arbitrary alphabet such that A[i]=pi_w[i] for
all i? Moreover, what is the minimum required cardinality of the alphabet? We
give a real time linear algorithm for this problem in the unit-cost RAM model
with \Theta(log n) bits word size. Our algorithm returns a word w over minimal
alphabet such that pi_w = A as well and uses just o(n) words of memory. Then we
consider function pi' instead of pi and give an online O(n log n) algorithm for
this case. This is the first polynomial algorithm for online version of this
problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2900</identifier>
 <datestamp>2009-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2900</id><created>2009-01-19</created><authors><author><keyname>Gupta</keyname><forenames>Manoj</forenames><affiliation>Indian Institute of Technology Kanpur</affiliation></author><author><keyname>Sharma</keyname><forenames>Ankit</forenames><affiliation>Indian Institute of Technology Kanpur</affiliation></author></authors><title>An O(log(n)) Fully Dynamic Algorithm for Maximum matching in a tree</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we have developed a fully-dynamic algorithm for maintaining
cardinality of maximum-matching in a tree using the construction of top-trees.
The time complexities are as follows:
  1. Initialization Time: $O(n(log(n)))$ to build the Top-tree. 2. Update Time:
$O(log(n))$ 3. Query Time: O(1) to query the cardinality of maximum-matching
and $O(log(n))$ to find if a particular edge is matched.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2903</identifier>
 <datestamp>2010-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2903</id><created>2009-01-19</created><updated>2010-06-02</updated><authors><author><keyname>Teixeira</keyname><forenames>Andreia</forenames></author><author><keyname>Souto</keyname><forenames>Andre</forenames></author><author><keyname>Matos</keyname><forenames>Armando</forenames></author><author><keyname>Antunes</keyname><forenames>Luis</forenames></author></authors><title>Entropy Measures vs. Algorithmic Information</title><categories>cs.IT cs.CC math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Algorithmic entropy and Shannon entropy are two conceptually different
information measures, as the former is based on size of programs and the later
in probability distributions. However, it is known that, for any recursive
probability distribution, the expected value of algorithmic entropy equals its
Shannon entropy, up to a constant that depends only on the distribution. We
study if a similar relationship holds for R\'{e}nyi and Tsallis entropies of
order $\alpha$, showing that it only holds for R\'{e}nyi and Tsallis entropies
of order 1 (i.e., for Shannon entropy). Regarding a time bounded analogue
relationship, we show that, for distributions such that the cumulative
probability distribution is computable in time $t(n)$, the expected value of
time-bounded algorithmic entropy (where the alloted time is $nt(n)\log
(nt(n))$) is in the same range as the unbounded version. So, for these
distributions, Shannon entropy captures the notion of computationally
accessible information. We prove that, for universal time-bounded distribution
$\m^t(x)$, Tsallis and R\'{e}nyi entropies converge if and only if $\alpha$ is
greater than 1.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2906</identifier>
 <datestamp>2009-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2906</id><created>2009-01-19</created><authors><author><keyname>Matos</keyname><forenames>Armando</forenames></author><author><keyname>Teixeira</keyname><forenames>Andreia</forenames></author><author><keyname>Souto</keyname><forenames>Andre</forenames></author></authors><title>Measuring communication complexity using instance complexity with
  oracles</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We establish a connection between non-deterministic communication complexity
and instance complexity, a measure of information based on algorithmic entropy.
Let $\overline{x}$, $\overline{y}$ and $Y_1(\overline{x})$ be respectively the
input known by Alice, the input known by Bob, and the set of all values of $y$
such that $f(\overline{x},y)=1$; a string is a witness of the non-deterministic
communication protocol iff it is a program $p$ that &quot;corresponds exactly&quot; to
the instance complexity $\ic^{f,t}(\overline{y}:Y_1(\overline{x}))$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2911</identifier>
 <datestamp>2009-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2911</id><created>2009-01-19</created><authors><author><keyname>Ford</keyname><forenames>David K.</forenames></author></authors><title>Gibbs Free Energy Analysis of a Quantum Analog of the Classical Binary
  Symmetric Channel</title><categories>physics.gen-ph cond-mat.stat-mech cs.IT math.IT</categories><comments>6 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Gibbs free energy properties of a quantum {\it send, receive}
communications system are studied. The communications model resembles the
classical Ising model of spins on a lattice in that the joint state of the
quantum system is the product of sender and receiver states. However, the
system differs from the classical case in that the sender and receiver spin
states are quantum superposition states coupled by a Hamiltonian operator. A
basic understanding of these states is directly relevant to communications
theory and indirectly relevant to computation since the product states form a
basis for entangled states. Highlights of the study include an exact method for
decimation for quantum spins. The main result is that the minimum Gibbs free
energy of the quantum system in the product state is higher (lower capacity)
than a classical system with the same parameter values. The result is both
surprising and not. The channel characteristics of the quantum system in the
product state are markedly inferior to those of the classical Ising system.
Intuitively, it would seem that capacity should suffer as a result. Yet, one
would expect entangled states, built from product states, to have better
correlation properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2912</identifier>
 <datestamp>2009-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2912</id><created>2009-01-19</created><authors><author><keyname>Khajehnejad</keyname><forenames>M. Amin</forenames></author><author><keyname>Xu</keyname><forenames>Weiyu</forenames></author><author><keyname>Avestimehr</keyname><forenames>Salman</forenames></author><author><keyname>Hassibi</keyname><forenames>Babak</forenames></author></authors><title>Weighted $\ell_1$ Minimization for Sparse Recovery with Prior
  Information</title><categories>cs.IT math.IT</categories><comments>5 Pages, Submitted to ISIT 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study the compressed sensing problem of recovering a sparse
signal from a system of underdetermined linear equations when we have prior
information about the probability of each entry of the unknown signal being
nonzero. In particular, we focus on a model where the entries of the unknown
vector fall into two sets, each with a different probability of being nonzero.
We propose a weighted $\ell_1$ minimization recovery algorithm and analyze its
performance using a Grassman angle approach. We compute explicitly the
relationship between the system parameters (the weights, the number of
measurements, the size of the two sets, the probabilities of being non-zero) so
that an iid random Gaussian measurement matrix along with weighted $\ell_1$
minimization recovers almost all such sparse signals with overwhelming
probability as the problem dimension increases. This allows us to compute the
optimal weights. We also provide simulations to demonstrate the advantages of
the method over conventional $\ell_1$ optimization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2913</identifier>
 <datestamp>2009-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2913</id><created>2009-01-19</created><updated>2009-05-25</updated><authors><author><keyname>Kim</keyname><forenames>MinJi</forenames></author><author><keyname>Medard</keyname><forenames>Muriel</forenames></author><author><keyname>Barros</keyname><forenames>Joao</forenames></author><author><keyname>Koetter</keyname><forenames>Ralf</forenames></author></authors><title>An Algebraic Watchdog for Wireless Network Coding</title><categories>cs.NI cs.CR</categories><comments>5 pages, 4 figures, submitted to IEEE International Symposium on
  Information Theory (ISIT) 2009. This is the final version. The content has
  been changed to incorporate reviewer comments and recent results</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a scheme, called the &quot;algebraic watchdog&quot; for
wireless network coding, in which nodes can detect malicious behaviors
probabilistically, police their downstream neighbors locally using overheard
messages, and, thus, provide a secure global &quot;self-checking network&quot;. Unlike
traditional Byzantine detection protocols which are receiver-based, this
protocol gives the senders an active role in checking the node downstream. This
work is inspired by Marti et. al.'s watchdog-pathrater, which attempts to
detect and mitigate the effects of routing misbehavior.
  As the first building block of a such system, we focus on a two-hop network.
We present a graphical model to understand the inference process nodes execute
to police their downstream neighbors; as well as to compute, analyze, and
approximate the probabilities of misdetection and false detection. In addition,
we present an algebraic analysis of the performance using an hypothesis testing
framework, that provides exact formulae for probabilities of false detection
and misdetection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2922</identifier>
 <datestamp>2009-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2922</id><created>2009-01-19</created><authors><author><keyname>Li</keyname><forenames>Qiao</forenames></author><author><keyname>Negi</keyname><forenames>Rohit</forenames></author></authors><title>Scheduling in Multi-hop Wireless Networks with Priorities</title><categories>cs.IT math.IT</categories><comments>9 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider prioritized maximal scheduling in multi-hop
wireless networks, where the scheduler chooses a maximal independent set
greedily according to a sequence specified by certain priorities. We show that
if the probability distributions of the priorities are properly chosen, we can
achieve the optimal (maximum) stability region using an i.i.d random priority
assignment process, for any set of arrival processes that satisfy Law of Large
Numbers. The pre-computation of the priorities is, in general, NP-hard, but
there exists polynomial time approximation scheme (PTAS) to achieve any
fraction of the optimal stability region. We next focus on the simple case of
static priority and specify a greedy priority assignment algorithm, which can
achieve the same fraction of the optimal stability region as the state of art
result for Longest Queue First (LQF) schedulers. We also show that this
algorithm can be easily adapted to satisfy delay constraints in the large
deviations regime, and therefore, supports Quality of Service (QoS) for each
link.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2924</identifier>
 <datestamp>2009-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2924</id><created>2009-01-19</created><authors><author><keyname>Corral</keyname><forenames>Alvaro</forenames><affiliation>Centre de Recerca Matematica</affiliation></author><author><keyname>Ferrer-i-Cancho</keyname><forenames>Ramon</forenames><affiliation>U Politecnica Catalunya</affiliation></author><author><keyname>Boleda</keyname><forenames>Gemma</forenames><affiliation>U Politecnica Catalunya</affiliation></author><author><keyname>Diaz-Guilera</keyname><forenames>Albert</forenames><affiliation>U Barcelona</affiliation></author><author><keyname>.</keyname></author></authors><title>Universal Complex Structures in Written Language</title><categories>physics.soc-ph cs.CL</categories><comments>Short paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantitative linguistics has provided us with a number of empirical laws that
characterise the evolution of languages and competition amongst them. In terms
of language usage, one of the most influential results is Zipf's law of word
frequencies. Zipf's law appears to be universal, and may not even be unique to
human language. However, there is ongoing controversy over whether Zipf's law
is a good indicator of complexity. Here we present an alternative approach that
puts Zipf's law in the context of critical phenomena (the cornerstone of
complexity in physics) and establishes the presence of a large scale
&quot;attraction&quot; between successive repetitions of words. Moreover, this phenomenon
is scale-invariant and universal -- the pattern is independent of word
frequency and is observed in texts by different authors and written in
different languages. There is evidence, however, that the shape of the scaling
relation changes for words that play a key role in the text, implying the
existence of different &quot;universality classes&quot; in the repetition of words. These
behaviours exhibit striking parallels with complex catastrophic phenomena.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2934</identifier>
 <datestamp>2009-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2934</id><created>2009-01-19</created><authors><author><keyname>Peng</keyname><forenames>Yong</forenames></author><author><keyname>Rajan</keyname><forenames>Dinesh</forenames></author></authors><title>Noisy DPC and Application to a Cognitive Channel</title><categories>cs.IT math.IT</categories><comments>5 pages, 5 figures, submitted to IEEE ISIT 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we first consider a channel that is contaminated by two
independent Gaussian noises $S ~ N(0,Q)$ and $Z_0 ~ N(0,N_0)$. The capacity of
this channel is computed when independent noisy versions of $S$ are known to
the transmitter and/or receiver. It is shown that the channel capacity is
greater then the capacity when $S$ is completely unknown, but is less then the
capacity when $S$ is perfectly known at the transmitter or receiver. For
example, if there is one noisy version of $S$ known at the transmitter only,
the capacity is $0.5log(1+P/(Q(N_1/(Q+N_1))+N_0))$, where $P$ is the input
power constraint and $N_1$ is the power of the noise corrupting $S$. We then
consider a Gaussian cognitive interference channel (IC) and propose a causal
noisy dirty paper coding (DPC) strategy. We compute the achievable region using
this noisy DPC strategy and quantify the regions when it achieves the upper
bound on the rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2954</identifier>
 <datestamp>2009-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2954</id><created>2009-01-19</created><authors><author><keyname>Horie</keyname><forenames>Kenichi</forenames></author></authors><title>An Upper Limit of AC Huffman Code Length in JPEG Compression</title><categories>cs.IT cs.CC cs.CE cs.CV math.IT</categories><comments>US patent application 11/947936</comments><report-no>OIMC07P03556</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A strategy for computing upper code-length limits of AC Huffman codes for an
8x8 block in JPEG Baseline coding is developed. The method is based on a
geometric interpretation of the DCT, and the calculated limits are as close as
14% to the maximum code-lengths. The proposed strategy can be adapted to other
transform coding methods, e.g., MPEG 2 and 4 video compressions, to calculate
close upper code length limits for the respective processing blocks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3003</identifier>
 <datestamp>2013-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3003</id><created>2009-01-20</created><updated>2013-07-19</updated><authors><author><keyname>Bergstra</keyname><forenames>J. A.</forenames></author><author><keyname>Middelburg</keyname><forenames>C. A.</forenames></author></authors><title>Timed tuplix calculus and the Wesseling and van den Bergh equation</title><categories>q-fin.GN cs.LO</categories><comments>17 pages; phrasing improved, references updated; substantially
  improved; remarks added</comments><report-no>PRG0901</report-no><journal-ref>Scientific Annals of Computer Science 23(2):169--190, 2013</journal-ref><doi>10.7561/SACS.2013.2.169</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop an algebraic framework for the description and analysis of
financial behaviours, that is, behaviours that consist of transferring certain
amounts of money at planned times. To a large extent, analysis of financial
products amounts to analysis of such behaviours. We formalize the cumulative
interest compliant conservation requirement for financial products proposed by
Wesseling and van den Bergh by an equation in the framework developed and
define a notion of financial product behaviour using this formalization. We
also present some properties of financial product behaviours. The development
of the framework has been influenced by previous work on the process algebra
ACP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3012</identifier>
 <datestamp>2009-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3012</id><created>2009-01-20</created><updated>2009-02-04</updated><authors><author><keyname>Bergstra</keyname><forenames>J. A.</forenames></author><author><keyname>Middelburg</keyname><forenames>C. A.</forenames></author></authors><title>Meadow enriched ACP process algebras</title><categories>math.RA cs.LO</categories><comments>8 pages; correction in Table 3</comments><report-no>PRG0902</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce the notion of an ACP process algebra. The models of the axiom
system ACP are the origin of this notion. ACP process algebras have to do with
processes in which no data are involved. We also introduce the notion of a
meadow enriched ACP process algebra, which is a simple generalization of the
notion of an ACP process algebra to processes in which data are involved. In
meadow enriched ACP process algebras, the mathematical structure for data is a
meadow.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3017</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3017</id><created>2009-01-20</created><authors><author><keyname>Yadav</keyname><forenames>Nisha</forenames></author><author><keyname>Joglekar</keyname><forenames>Hrishikesh</forenames></author><author><keyname>Rao</keyname><forenames>Rajesh P. N.</forenames></author><author><keyname>Vahia</keyname><forenames>M. N.</forenames></author><author><keyname>Mahadevan</keyname><forenames>Iravatham</forenames></author><author><keyname>Adhikari</keyname><forenames>R.</forenames></author></authors><title>Statistical analysis of the Indus script using $n$-grams</title><categories>cs.CL</categories><doi>10.1371/journal.pone.0009506</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Indus script is one of the major undeciphered scripts of the ancient
world. The small size of the corpus, the absence of bilingual texts, and the
lack of definite knowledge of the underlying language has frustrated efforts at
decipherment since the discovery of the remains of the Indus civilisation.
Recently, some researchers have questioned the premise that the Indus script
encodes spoken language. Building on previous statistical approaches, we apply
the tools of statistical language processing, specifically $n$-gram Markov
chains, to analyse the Indus script for syntax. Our main results are that the
script has well-defined signs which begin and end texts, that there is
directionality and strong correlations in the sign order, and that there are
groups of signs which appear to have identical syntactic function. All these
require no {\it a priori} suppositions regarding the syntactic or semantic
content of the signs, but follow directly from the statistical analysis. Using
information theoretic measures, we find the information in the script to be
intermediate between that of a completely random and a completely fixed
ordering of signs. Our study reveals that the Indus script is a structured sign
system showing features of a formal language, but, at present, cannot
conclusively establish that it encodes {\it natural} language. Our $n$-gram
Markov model is useful for predicting signs which are missing or illegible in a
corpus of Indus texts. This work forms the basis for the development of a
stochastic grammar which can be used to explore the syntax of the Indus script
in greater detail.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3047</identifier>
 <datestamp>2009-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3047</id><created>2009-01-20</created><updated>2009-03-08</updated><authors><author><keyname>Kafri</keyname><forenames>Oded</forenames></author></authors><title>Entropy Principle in Direct Derivation of Benford's Law</title><categories>cs.DM physics.data-an</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The uneven distribution of digits in numerical data, known as Benford's law,
was discovered in 1881. Since then, this law has been shown to be correct in
copious numerical data relating to economics, physics and even prime numbers.
Although it attracts considerable attention, there is no a priori probabilistic
criterion when a data set should or should not obey the law. Here a general
criterion is suggested, namely that any file of digits in the Shannon limit
(namely, having maximum entropy) has a Benford's law distribution of digits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3056</identifier>
 <datestamp>2009-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3056</id><created>2009-01-20</created><updated>2009-07-14</updated><authors><author><keyname>Bayramoglu</keyname><forenames>M. F.</forenames></author><author><keyname>Y&#x131;lmaz</keyname><forenames>A. &#xd6;zg&#xfc;r</forenames></author></authors><title>Factorization of Joint Probability Mass Functions into Parity Check
  Interactions</title><categories>cs.IT cs.DM math.IT math.PR</categories><comments>5 pages, 1 figures, appeared in the proceedings of ISIT 2009; Changed
  content, more recent version than as appeared in the proceedings</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that any joint probability mass function (PMF) can be expressed as a
product of parity check factors and factors of degree one with the help of some
auxiliary variables, if the alphabet size is appropriate for defining a parity
check equation. In other words, marginalization of a joint PMF is equivalent to
a soft decoding task as long as a finite field can be constructed over the
alphabet of the PMF. In factor graph terminology this claim means that a factor
graph representing such a joint PMF always has an equivalent Tanner graph. We
provide a systematic method based on the Hilbert space of PMFs and orthogonal
projections for obtaining this factorization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3119</identifier>
 <datestamp>2011-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3119</id><created>2009-01-20</created><updated>2009-09-10</updated><authors><author><keyname>Cibulka</keyname><forenames>Josef</forenames></author></authors><title>Average number of flips in pancake sorting</title><categories>cs.DM</categories><comments>21 pages, new computational results for unburnt pancakes (up to n=19)</comments><journal-ref>Theor. Comput. Sci. 412, pp. 822-834 (2011)</journal-ref><doi>10.1016/j.tcs.2010.11.028</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We are given a stack of pancakes of different sizes and the only allowed
operation is to take several pancakes from top and flip them. The unburnt
version requires the pancakes to be sorted by their sizes at the end, while in
the burnt version they additionally need to be oriented burnt-side down. We
present an algorithm with the average number of flips, needed to sort a stack
of n burnt pancakes, equal to 7n/4+O(1) and a randomized algorithm for the
unburnt version with at most 17n/12+O(1) flips on average.
  In addition, we show that in the burnt version, the average number of flips
of any algorithm is at least n+\Omega(n/log n) and conjecture that some
algorithm can reach n+\Theta(n/log n).
  We also slightly increase the lower bound on g(n), the minimum number of
flips needed to sort the worst stack of n burnt pancakes. This bound, together
with the upper bound found by Heydari and Sudborough in 1997, gives the exact
number of flips to sort the previously conjectured worst stack -I_n for n=3 mod
4 and n&gt;=15. Finally we present exact values of f(n) up to n=19 and of g(n) up
to n=17 and disprove a conjecture of Cohen and Blum by showing that the burnt
stack -I_{15} is not the worst one for n=15.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3130</identifier>
 <datestamp>2009-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3130</id><created>2009-01-20</created><authors><author><keyname>Gursoy</keyname><forenames>Mustafa Cenk</forenames></author></authors><title>Secure Communication in the Low-SNR Regime: A Characterization of the
  Energy-Secrecy Tradeoff</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Secrecy capacity of a multiple-antenna wiretap channel is studied in the low
signal-to-noise ratio (SNR) regime. Expressions for the first and second
derivatives of the secrecy capacity with respect to SNR at SNR = 0 are derived.
Transmission strategies required to achieve these derivatives are identified.
In particular, it is shown that it is optimal in the low-SNR regime to transmit
in the maximum-eigenvalue eigenspace of H_m* H_m - N_m/N_e H_e* H_e where H_m
and H_e denote the channel matrices associated with the legitimate receiver and
eavesdropper, respectively, and N_m and N_e are the noise variances at the
receiver and eavesdropper, respectively. Energy efficiency is analyzed by
finding the minimum bit energy required for secure and reliable communications,
and the wideband slope. Increased bit energy requirements under secrecy
constraints are quantified. Finally, the impact of fading is investigated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3132</identifier>
 <datestamp>2009-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3132</id><created>2009-01-20</created><authors><author><keyname>Zhang</keyname><forenames>Junwei</forenames></author><author><keyname>Gursoy</keyname><forenames>Mustafa Cenk</forenames></author></authors><title>Low-SNR Analysis of Interference Channels under Secrecy Constraints</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the secrecy rates over weak Gaussian interference
channels for different transmission schemes. We focus on the low-SNR regime and
obtain the minimum bit energy E_b/N_0_min values, and the wideband slope
regions for both TDMA and multiplexed transmission schemes. We show that
secrecy constraints introduce a penalty in both the minimum bit energy and the
slope regions. Additionally, we identify under what conditions TDMA or
multiplexed transmission is optimal. Finally, we show that TDMA is more likely
to be optimal in the presence of secrecy constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3134</identifier>
 <datestamp>2009-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3134</id><created>2009-01-20</created><authors><author><keyname>Qiao</keyname><forenames>Deli</forenames></author><author><keyname>Gursoy</keyname><forenames>Mustafa Cenk</forenames></author><author><keyname>Velipasalar</keyname><forenames>Senem</forenames></author></authors><title>Energy Efficiency of Fixed-Rate Wireless Transmissions under Queueing
  Constraints and Channel Uncertainty</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Energy efficiency of fixed-rate transmissions is studied in the presence of
queueing constraints and channel uncertainty. It is assumed that neither the
transmitter nor the receiver has channel side information prior to
transmission. The channel coefficients are estimated at the receiver via
minimum mean-square-error (MMSE) estimation with the aid of training symbols.
It is further assumed that the system operates under statistical queueing
constraints in the form of limitations on buffer violation probabilities. The
optimal fraction of of power allocated to training is identified. Spectral
efficiency--bit energy tradeoff is analyzed in the low-power and wideband
regimes by employing the effective capacity formulation. In particular, it is
shown that the bit energy increases without bound in the low-power regime as
the average power vanishes. On the other hand, it is proven that the bit energy
diminishes to its minimum value in the wideband regime as the available
bandwidth increases. For this case, expressions for the minimum bit energy and
wideband slope are derived. Overall, energy costs of channel uncertainty and
queueing constraints are identified.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3150</identifier>
 <datestamp>2009-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3150</id><created>2009-01-20</created><updated>2009-09-17</updated><authors><author><keyname>Keshavan</keyname><forenames>Raghunandan H.</forenames></author><author><keyname>Montanari</keyname><forenames>Andrea</forenames></author><author><keyname>Oh</keyname><forenames>Sewoong</forenames></author></authors><title>Matrix Completion from a Few Entries</title><categories>cs.LG stat.ML</categories><comments>30 pages, 1 figure, journal version (v1, v2: Conference version ISIT
  2009)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let M be a random (alpha n) x n matrix of rank r&lt;&lt;n, and assume that a
uniformly random subset E of its entries is observed. We describe an efficient
algorithm that reconstructs M from |E| = O(rn) observed entries with relative
root mean square error RMSE &lt;= C(rn/|E|)^0.5 . Further, if r=O(1), M can be
reconstructed exactly from |E| = O(n log(n)) entries. These results apply
beyond random matrices to general low-rank incoherent matrices.
  This settles (in the case of bounded rank) a question left open by Candes and
Recht and improves over the guarantees for their reconstruction algorithm. The
complexity of our algorithm is O(|E|r log(n)), which opens the way to its use
for massive data sets. In the process of proving these statements, we obtain a
generalization of a celebrated result by Friedman-Kahn-Szemeredi and Feige-Ofek
on the spectrum of sparse random matrices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3170</identifier>
 <datestamp>2010-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3170</id><created>2009-01-21</created><updated>2009-10-29</updated><authors><author><keyname>Mazumdar</keyname><forenames>Arya</forenames></author><author><keyname>Roth</keyname><forenames>Ron M.</forenames></author><author><keyname>Vontobel</keyname><forenames>Pascal O.</forenames></author></authors><title>On linear balancing sets</title><categories>cs.IT cs.DM math.IT</categories><comments>The abstract of this paper appeared in the proc. of 2009
  International Symposium on Information Theory</comments><journal-ref>Advances in Mathematics of Communications (AMC), Vol. 4, Issue 3,
  pp. 345 - 361, August, 2010</journal-ref><doi>10.3934/amc.2010.4.345</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let n be an even positive integer and F be the field \GF(2). A word in F^n is
called balanced if its Hamming weight is n/2. A subset C \subseteq F^n$ is
called a balancing set if for every word y \in F^n there is a word x \in C such
that y + x is balanced. It is shown that most linear subspaces of F^n of
dimension slightly larger than 3/2\log_2(n) are balancing sets. A
generalization of this result to linear subspaces that are &quot;almost balancing&quot;
is also presented. On the other hand, it is shown that the problem of deciding
whether a given set of vectors in F^n spans a balancing set, is NP-hard. An
application of linear balancing sets is presented for designing efficient
error-correcting coding schemes in which the codewords are balanced.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3188</identifier>
 <datestamp>2009-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3188</id><created>2009-01-21</created><updated>2009-07-09</updated><authors><author><keyname>Currie</keyname><forenames>James</forenames></author><author><keyname>Rampersad</keyname><forenames>Narad</forenames></author></authors><title>Dejean's conjecture holds for n&gt;=27</title><categories>math.CO cs.FL</categories><comments>minor revisions</comments><msc-class>68R15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that Dejean's conjecture holds for n&gt;=27. This brings the final
resolution of the conjecture by the approach of Moulin Ollagnier within range
of the computationally feasible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3189</identifier>
 <datestamp>2009-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3189</id><created>2009-01-20</created><authors><author><keyname>Kautz</keyname><forenames>Steven M.</forenames></author><author><keyname>Lathrop</keyname><forenames>James I.</forenames></author></authors><title>Self-assembly of the discrete Sierpinski carpet and related fractals</title><categories>cs.OH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is well known that the discrete Sierpinski triangle can be defined as the
nonzero residues modulo 2 of Pascal's triangle, and that from this definition
one can easily construct a tileset with which the discrete Sierpinski triangle
self-assembles in Winfree's tile assembly model. In this paper we introduce an
infinite class of discrete self-similar fractals that are defined by the
residues modulo a prime p of the entries in a two-dimensional matrix obtained
from a simple recursive equation. We prove that every fractal in this class
self-assembles using a uniformly constructed tileset. As a special case we show
that the discrete Sierpinski carpet self-assembles using a set of 30 tiles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3192</identifier>
 <datestamp>2009-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3192</id><created>2009-01-21</created><authors><author><keyname>Zhang</keyname><forenames>Xiaolu</forenames></author><author><keyname>Tao</keyname><forenames>Meixia</forenames></author><author><keyname>Jiao</keyname><forenames>Wenhua</forenames></author><author><keyname>Ng</keyname><forenames>Chun Sum</forenames></author></authors><title>End-to-End Outage Minimization in OFDM Based Linear Relay Networks</title><categories>cs.IT math.IT</categories><comments>25 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-hop relaying is an economically efficient architecture for coverage
extension and throughput enhancement in future wireless networks. OFDM, on the
other hand, is a spectrally efficient physical layer modulation technique for
broadband transmission. As a natural consequence of combining OFDM with
multi-hop relaying, the allocation of per-hop subcarrier power and per-hop
transmission time is crucial in optimizing the network performance. This paper
is concerned with the end-to-end information outage in an OFDM based linear
relay network. Our goal is to find an optimal power and time adaptation policy
to minimize the outage probability under a long-term total power constraint. We
solve the problem in two steps. First, for any given channel realization, we
derive the minimum short-term power required to meet a target transmission
rate. We show that it can be obtained through two nested bisection loops. To
reduce computational complexity and signalling overhead, we also propose a
sub-optimal algorithm. In the second step, we determine a power threshold to
control the transmission on-off so that the long-term total power constraint is
satisfied. Numerical examples are provided to illustrate the performance of the
proposed power and time adaptation schemes with respect to other resource
adaptation schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3196</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3196</id><created>2009-01-21</created><updated>2009-04-23</updated><authors><author><keyname>Haddadi</keyname><forenames>Farzan</forenames></author><author><keyname>Malekmohammadi</keyname><forenames>Mohammadreza</forenames></author><author><keyname>Nayebi</keyname><forenames>Mohammad Mahdi</forenames></author><author><keyname>Aref</keyname><forenames>Mohammad Reza</forenames></author></authors><title>Statistical Performance Analysis of MDL Source Enumeration in Array
  Processing</title><categories>cs.IT math.IT</categories><comments>Accepted for publication in IEEE Transactions on Signal Processing,
  April 2009</comments><doi>10.1109/TSP.2009.2028207</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this correspondence, we focus on the performance analysis of the
widely-used minimum description length (MDL) source enumeration technique in
array processing. Unfortunately, available theoretical analysis exhibit
deviation from the simulation results. We present an accurate and insightful
performance analysis for the probability of missed detection. We also show that
the statistical performance of the MDL is approximately the same under both
deterministic and stochastic signal models. Simulation results show the
superiority of the proposed analysis over available results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3197</identifier>
 <datestamp>2010-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3197</id><created>2009-01-21</created><updated>2009-10-07</updated><authors><author><keyname>Bickson</keyname><forenames>Danny</forenames></author><author><keyname>Ihler</keyname><forenames>Alexander T.</forenames></author><author><keyname>Dolev</keyname><forenames>Danny</forenames></author></authors><title>A Low Density Lattice Decoder via Non-Parametric Belief Propagation</title><categories>cs.IT math.IT</categories><comments>Submitted for publication</comments><doi>10.1109/ALLERTON.2009.5394798</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The recent work of Sommer, Feder and Shalvi presented a new family of codes
called low density lattice codes (LDLC) that can be decoded efficiently and
approach the capacity of the AWGN channel. A linear time iterative decoding
scheme which is based on a message-passing formulation on a factor graph is
given.
  In the current work we report our theoretical findings regarding the relation
between the LDLC decoder and belief propagation. We show that the LDLC decoder
is an instance of non-parametric belief propagation and further connect it to
the Gaussian belief propagation algorithm. Our new results enable borrowing
knowledge from the non-parametric and Gaussian belief propagation domains into
the LDLC domain. Specifically, we give more general convergence conditions for
convergence of the LDLC decoder (under the same assumptions of the original
LDLC convergence analysis). We discuss how to extend the LDLC decoder from
Latin square to full rank, non-square matrices. We propose an efficient
construction of sparse generator matrix and its matching decoder. We report
preliminary experimental results which show our decoder has comparable symbol
to error rate compared to the original LDLC decoder.%
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3199</identifier>
 <datestamp>2009-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3199</id><created>2009-01-21</created><authors><author><keyname>Morvan</keyname><forenames>Michel</forenames><affiliation>LIP, Ixxi</affiliation></author><author><keyname>Sen&#xe9;</keyname><forenames>Sylvain</forenames><affiliation>IXXI, Timc</affiliation></author></authors><title>A Distributed Trust Diffusion Protocol for Ad Hoc Networks</title><categories>cs.NI</categories><proxy>ccsd hal-00353071</proxy><journal-ref>Second International Conference on Wireless and Mobile
  Communications, Bucarest : Roumanie (2006)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose and evaluate a distributed protocol to manage trust
diffusion in ad hoc networks. In this protocol, each node i maintains a \trust
value&quot; about an other node j which is computed both as a result of the
exchanges with node j itself and as a function of the opinion that other nodes
have about j. These two aspects are respectively weighted by a trust index that
measures the trust quality the node has in its own experiences and by a trust
index representing the trust the node has in the opinions of the other nodes.
Simulations have been realized to validate the robustness of this protocol
against three kinds of attacks: simple coalitions, Trojan attacks and detonator
attacks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3202</identifier>
 <datestamp>2009-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3202</id><created>2009-01-21</created><authors><author><keyname>Bach</keyname><forenames>Francis</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>Model-Consistent Sparse Estimation through the Bootstrap</title><categories>cs.LG stat.ML</categories><proxy>ccsd hal-00354771</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the least-square linear regression problem with regularization by
the $\ell^1$-norm, a problem usually referred to as the Lasso. In this paper,
we first present a detailed asymptotic analysis of model consistency of the
Lasso in low-dimensional settings. For various decays of the regularization
parameter, we compute asymptotic equivalents of the probability of correct
model selection. For a specific rate decay, we show that the Lasso selects all
the variables that should enter the model with probability tending to one
exponentially fast, while it selects all other variables with strictly positive
probability. We show that this property implies that if we run the Lasso for
several bootstrapped replications of a given sample, then intersecting the
supports of the Lasso bootstrap estimates leads to consistent model selection.
This novel variable selection procedure, referred to as the Bolasso, is
extended to high-dimensional settings by a provably consistent two-step
procedure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3257</identifier>
 <datestamp>2009-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3257</id><created>2009-01-21</created><updated>2009-01-21</updated><authors><author><keyname>Heimlicher</keyname><forenames>Simon</forenames></author><author><keyname>Karaliopoulos</keyname><forenames>Merkouris</forenames></author><author><keyname>Levy</keyname><forenames>Hanoch</forenames></author><author><keyname>Spyropoulos</keyname><forenames>Thrasyvoulos</forenames></author></authors><title>On Leveraging Partial Paths in Partially-Connected Networks</title><categories>cs.NI</categories><comments>Extended version of paper appearing at IEEE INFOCOM 2009, April
  20-25, Rio de Janeiro, Brazil</comments><report-no>TR-303</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mobile wireless network research focuses on scenarios at the extremes of the
network connectivity continuum where the probability of all nodes being
connected is either close to unity, assuming connected paths between all nodes
(mobile ad hoc networks), or it is close to zero, assuming no multi-hop paths
exist at all (delay-tolerant networks). In this paper, we argue that a sizable
fraction of networks lies between these extremes and is characterized by the
existence of partial paths, i.e. multi-hop path segments that allow forwarding
data closer to the destination even when no end-to-end path is available. A
fundamental issue in such networks is dealing with disruptions of end-to-end
paths. Under a stochastic model, we compare the performance of the established
end-to-end retransmission (ignoring partial paths), against a forwarding
mechanism that leverages partial paths to forward data closer to the
destination even during disruption periods. Perhaps surprisingly, the
alternative mechanism is not necessarily superior. However, under a stochastic
monotonicity condition between current v.s. future path length, which we
demonstrate to hold in typical network models, we manage to prove superiority
of the alternative mechanism in stochastic dominance terms. We believe that
this study could serve as a foundation to design more efficient data transfer
protocols for partially-connected networks, which could potentially help
reducing the gap between applications that can be supported over disconnected
networks and those requiring full connectivity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3291</identifier>
 <datestamp>2015-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3291</id><created>2009-01-21</created><authors><author><keyname>Drozdz</keyname><forenames>Stanislaw</forenames></author><author><keyname>Kwapien</keyname><forenames>Jaroslaw</forenames></author><author><keyname>Orczyk</keyname><forenames>Adam</forenames></author></authors><title>Approaching the linguistic complexity</title><categories>cs.CL physics.data-an</categories><comments>to be published in conference proceedings</comments><journal-ref>Complex Sciences, Lect. Notes ICST vol.4, 1044-1050 (Springer,
  2009)</journal-ref><doi>10.1007/978-3-642-02466-5_104</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze the rank-frequency distributions of words in selected English and
Polish texts. We compare scaling properties of these distributions in both
languages. We also study a few small corpora of Polish literary texts and find
that for a corpus consisting of texts written by different authors the basic
scaling regime is broken more strongly than in the case of comparable corpus
consisting of texts written by the same author. Similarly, for a corpus
consisting of texts translated into Polish from other languages the scaling
regime is broken more strongly than for a comparable corpus of native Polish
texts. Moreover, based on the British National Corpus, we consider the
rank-frequency distributions of the grammatically basic forms of words (lemmas)
tagged with their proper part of speech. We find that these distributions do
not scale if each part of speech is analyzed separately. The only part of
speech that independently develops a trace of scaling is verbs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3299</identifier>
 <datestamp>2010-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3299</id><created>2009-01-21</created><updated>2010-05-28</updated><authors><author><keyname>van Iersel</keyname><forenames>Leo</forenames></author><author><keyname>Mnich</keyname><forenames>Matthias</forenames></author></authors><title>Computing Rooted and Unrooted Maximum Consistent Supertrees</title><categories>cs.DM cs.DS</categories><comments>This paper has been withdrawn by the authors due to an error</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A chief problem in phylogenetics and database theory is the computation of a
maximum consistent tree from a set of rooted or unrooted trees. A standard
input are triplets, rooted binary trees on three leaves, or quartets, unrooted
binary trees on four leaves. We give exact algorithms constructing rooted and
unrooted maximum consistent supertrees in time O(2^n n^5 m^2 log(m)) for a set
of m triplets (quartets), each one distinctly leaf-labeled by some subset of n
labels. The algorithms extend to weighted triplets (quartets). We further
present fast exact algorithms for constructing rooted and unrooted maximum
consistent trees in polynomial space. Finally, for a set T of m rooted or
unrooted trees with maximum degree D and distinctly leaf-labeled by some subset
of a set L of n labels, we compute, in O(2^{mD} n^m m^5 n^6 log(m)) time, a
tree distinctly leaf-labeled by a maximum-size subset X of L that all trees in
T, when restricted to X, are consistent with.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3314</identifier>
 <datestamp>2009-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3314</id><created>2009-01-21</created><authors><author><keyname>Lapidoth</keyname><forenames>Amos</forenames></author><author><keyname>Tinguely</keyname><forenames>Stephan</forenames></author></authors><title>Sending a Bi-Variate Gaussian over a Gaussian MAC</title><categories>cs.IT math.IT</categories><comments>submitted to the IEEE Transactions on Information Theory</comments><acm-class>E.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the power versus distortion trade-off for the distributed
transmission of a memoryless bi-variate Gaussian source over a two-to-one
average-power limited Gaussian multiple-access channel. In this problem, each
of two separate transmitters observes a different component of a memoryless
bi-variate Gaussian source. The two transmitters then describe their source
component to a common receiver via an average-power constrained Gaussian
multiple-access channel. From the output of the multiple-access channel, the
receiver wishes to reconstruct each source component with the least possible
expected squared-error distortion. Our interest is in characterizing the
distortion pairs that are simultaneously achievable on the two source
components.
  We present sufficient conditions and necessary conditions for the
achievability of a distortion pair. These conditions are expressed as a
function of the channel signal-to-noise ratio (SNR) and of the source
correlation. In several cases the necessary conditions and sufficient
conditions are shown to agree. In particular, we show that if the channel SNR
is below a certain threshold, then an uncoded transmission scheme is optimal.
We also derive the precise high-SNR asymptotics of an optimal scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3348</identifier>
 <datestamp>2009-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3348</id><created>2009-01-21</created><authors><author><keyname>Ames</keyname><forenames>Brendan</forenames></author><author><keyname>Vavasis</keyname><forenames>Stephen</forenames></author></authors><title>Nuclear norm minimization for the planted clique and biclique problems</title><categories>cs.DS cs.NA</categories><acm-class>G.1.6; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problems of finding a maximum clique in a graph and finding a
maximum-edge biclique in a bipartite graph. Both problems are NP-hard. We write
both problems as matrix-rank minimization and then relax them using the nuclear
norm. This technique, which may be regarded as a generalization of compressive
sensing, has recently been shown to be an effective way to solve rank
optimization problems. In the special cases that the input graph has a planted
clique or biclique (i.e., a single large clique or biclique plus diversionary
edges), our algorithm successfully provides an exact solution to the original
instance. For each problem, we provide two analyses of when our algorithm
succeeds. In the first analysis, the diversionary edges are placed by an
adversary. In the second, they are placed at random. In the case of random
edges for the planted clique problem, we obtain the same bound as Alon,
Krivelevich and Sudakov as well as Feige and Krauthgamer, but we use different
techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3384</identifier>
 <datestamp>2010-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3384</id><created>2009-01-21</created><authors><author><keyname>Ham</keyname><forenames>Michael I.</forenames></author><author><keyname>Rodriguez</keyname><forenames>Marko A.</forenames></author></authors><title>A Boundary Approximation Algorithm for Distributed Sensor Networks</title><categories>cs.DC</categories><report-no>LA-UR-09-00111</report-no><acm-class>C.2.1</acm-class><journal-ref>International Journal of Sensor Networks, 8(1), pp. 41-46,
  ISSN:1748-1279, 2010</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We present an algorithm for boundary approximation in locally-linked sensor
networks that communicate with a remote monitoring station. Delaunay
triangulations and Voronoi diagrams are used to generate a sensor communication
network and define boundary segments between sensors, respectively. The
proposed algorithm reduces remote station communication by approximating
boundaries via a decentralized computation executed within the sensor network.
Moreover, the algorithm identifies boundaries based on differences between
neighboring sensor readings, and not absolute sensor values. An analysis of the
bandwidth consumption of the algorithm is presented and compared to two naive
approaches. The proposed algorithm reduces the amount of remote communication
(compared to the naive approaches) and becomes increasingly useful in networks
with more nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3403</identifier>
 <datestamp>2009-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3403</id><created>2009-01-21</created><authors><author><keyname>Baron</keyname><forenames>Dror</forenames></author><author><keyname>Duarte</keyname><forenames>Marco F.</forenames></author><author><keyname>Wakin</keyname><forenames>Michael B.</forenames></author><author><keyname>Sarvotham</keyname><forenames>Shriram</forenames></author><author><keyname>Baraniuk</keyname><forenames>Richard G.</forenames></author></authors><title>Distributed Compressive Sensing</title><categories>cs.IT math.IT</categories><comments>42 pages, 6 figures. Submitted November 27, 2005; Revised January 21,
  2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compressive sensing is a signal acquisition framework based on the revelation
that a small collection of linear projections of a sparse signal contains
enough information for stable recovery. In this paper we introduce a new theory
for distributed compressive sensing (DCS) that enables new distributed coding
algorithms for multi-signal ensembles that exploit both intra- and inter-signal
correlation structures. The DCS theory rests on a new concept that we term the
joint sparsity of a signal ensemble. Our theoretical contribution is to
characterize the fundamental performance limits of DCS recovery for jointly
sparse signal ensembles in the noiseless measurement setting; our result
connects single-signal, joint, and distributed (multi-encoder) compressive
sensing. To demonstrate the efficacy of our framework and to show that
additional challenges such as computational tractability can be addressed, we
study in detail three example models for jointly sparse signals. For these
models, we develop practical algorithms for joint recovery of multiple signals
from incoherent projections. In two of our three models, the results are
asymptotically best-possible, meaning that both the upper and lower bounds
match the performance of our practical algorithms. Moreover, simulations
indicate that the asymptotics take effect with just a moderate number of
signals. DCS is immediately applicable to a range of problems in sensor arrays
and networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3408</identifier>
 <datestamp>2009-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3408</id><created>2009-01-22</created><authors><author><keyname>Amini</keyname><forenames>Arash</forenames></author><author><keyname>Marvasti</keyname><forenames>Farokh</forenames></author></authors><title>Limits of Deterministic Compressed Sensing Considering Arbitrary
  Orthonormal Basis for Sparsity</title><categories>cs.IT math.IT</categories><comments>4 pages, submitted to SAMPTA2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is previously shown that proper random linear samples of a finite discrete
signal (vector) which has a sparse representation in an orthonormal basis make
it possible (with probability 1) to recover the original signal. Moreover, the
choice of the linear samples does not depend on the sparsity domain. In this
paper, we will show that the replacement of random linear samples with
deterministic functions of the signal (not necessarily linear) will not result
in unique reconstruction of k-sparse signals except for k=1. We will show that
there exist deterministic nonlinear sampling functions for unique
reconstruction of 1- sparse signals while deterministic linear samples fail to
do so.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3467</identifier>
 <datestamp>2009-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3467</id><created>2009-01-22</created><authors><author><keyname>Soro</keyname><forenames>Alexandre</forenames></author><author><keyname>Cunche</keyname><forenames>Mathieu</forenames></author><author><keyname>Lacan</keyname><forenames>Jerome</forenames></author><author><keyname>Roca</keyname><forenames>Vincent</forenames></author></authors><title>Erasure Codes with a Banded Structure for Hybrid Iterative-ML Decoding</title><categories>cs.IT math.IT</categories><comments>5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents new FEC codes for the erasure channel, LDPC-Band, that
have been designed so as to optimize a hybrid iterative-Maximum Likelihood (ML)
decoding. Indeed, these codes feature simultaneously a sparse parity check
matrix, which allows an efficient use of iterative LDPC decoding, and a
generator matrix with a band structure, which allows fast ML decoding on the
erasure channel. The combination of these two decoding algorithms leads to
erasure codes achieving a very good trade-off between complexity and erasure
correction capability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3475</identifier>
 <datestamp>2009-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3475</id><created>2009-01-22</created><authors><author><keyname>Park</keyname><forenames>In Sook</forenames></author></authors><title>Efficient decoding algorithm using triangularity of $\mbf{R}$ matrix of
  QR-decomposition</title><categories>cs.IT math.IT</categories><comments>This paper is submitted to IEEE transactions on Information theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An efficient decoding algorithm named `divided decoder' is proposed in this
paper. Divided decoding can be combined with any decoder using QR-decomposition
and offers different pairs of performance and complexity. Divided decoding
provides various combinations of two or more different searching algorithms.
Hence it makes flexibility in error rate and complexity for the algorithms
using it. We calculate diversity orders and upper bounds of error rates for
typical models when these models are solved by divided decodings with sphere
decoder, and discuss about the effects of divided decoding on complexity.
Simulation results of divided decodings combined with a sphere decoder
according to different splitting indices correspond to the theoretical
analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3482</identifier>
 <datestamp>2009-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3482</id><created>2009-01-22</created><authors><author><keyname>Francillon</keyname><forenames>Aur&#xe9;lien</forenames></author><author><keyname>Castelluccia</keyname><forenames>Claude</forenames></author></authors><title>Code injection attacks on harvard-architecture devices</title><categories>cs.CR</categories><proxy>ccsd inria-00355202</proxy><journal-ref>CCS '08: Proceedings of the 15th ACM conference on Computer and
  communications security (2008) 15--26</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Harvard architecture CPU design is common in the embedded world. Examples of
Harvard-based architecture devices are the Mica family of wireless sensors.
Mica motes have limited memory and can process only very small packets.
Stack-based buffer overflow techniques that inject code into the stack and then
execute it are therefore not applicable. It has been a common belief that code
injection is impossible on Harvard architectures. This paper presents a remote
code injection attack for Mica sensors. We show how to exploit program
vulnerabilities to permanently inject any piece of code into the program memory
of an Atmel AVR-based sensor. To our knowledge, this is the first result that
presents a code injection technique for such devices. Previous work only
succeeded in injecting data or performing transient attacks. Injecting
permanent code is more powerful since the attacker can gain full control of the
target sensor. We also show that this attack can be used to inject a worm that
can propagate through the wireless sensor network and possibly create a sensor
botnet. Our attack combines different techniques such as return oriented
programming and fake stack injection. We present implementation details and
suggest some counter-measures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3574</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3574</id><created>2009-01-23</created><updated>2009-03-04</updated><authors><author><keyname>Benzmueller</keyname><forenames>Christoph</forenames></author></authors><title>Automating Access Control Logics in Simple Type Theory with LEO-II</title><categories>cs.LO cs.AI</categories><comments>ii + 20 pages</comments><report-no>SEKI Report SR-2008-01</report-no><acm-class>F.1.1; I.2.2; I.2.3; I.2.4</acm-class><journal-ref>SEKI Report SR-2008-01 (ISSN 1437-4447), Saarland University, 2008</journal-ref><doi>10.1007/978-3-642-01244-0_34</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Garg and Abadi recently proved that prominent access control logics can be
translated in a sound and complete way into modal logic S4. We have previously
outlined how normal multimodal logics, including monomodal logics K and S4, can
be embedded in simple type theory (which is also known as higher-order logic)
and we have demonstrated that the higher-order theorem prover LEO-II can
automate reasoning in and about them. In this paper we combine these results
and describe a sound and complete embedding of different access control logics
in simple type theory. Employing this framework we show that the off the shelf
theorem prover LEO-II can be applied to automate reasoning in prominent access
control logics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3580</identifier>
 <datestamp>2009-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3580</id><created>2009-01-22</created><authors><author><keyname>Suh</keyname><forenames>Changho</forenames></author><author><keyname>Tse</keyname><forenames>David</forenames></author></authors><title>Feedback Capacity of the Gaussian Interference Channel to Within 1.7075
  Bits: the Symmetric Case</title><categories>cs.IT math.IT</categories><comments>submitted to the International Symposium and Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We characterize the symmetric capacity to within 1.7075 bits/s/Hz for the
two-user Gaussian interference channel with feedback. The result makes use of a
deterministic model to provide insights into the Gaussian channel. We derive a
new outer bound to show that a proposed achievable scheme can achieve the
symmetric capacity to within 1.7075 bits for all channel parameters. From this
result, we show that feedback provides unbounded gain, i.e., the gain becomes
arbitrarily large for certain channel parameters. It is a surprising result
because feedback has been so far known to provide only power gain (bounded
gain) in the context of multiple access channels and broadcast channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3585</identifier>
 <datestamp>2009-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3585</id><created>2009-01-23</created><authors><author><keyname>Benzmueller</keyname><forenames>Christoph</forenames></author><author><keyname>Sorge</keyname><forenames>Volker</forenames></author></authors><title>Resource Adaptive Agents in Interactive Theorem Proving</title><categories>cs.LO cs.AI</categories><comments>13 pages</comments><report-no>SR-99-02</report-no><acm-class>I.2.11; I.2.3; F.4.1; D.4.7; H.3.4</acm-class><journal-ref>SEKI Report (ISSN 1437-4447), Saarland University, 1999</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a resource adaptive agent mechanism which supports the user in
interactive theorem proving. The mechanism uses a two layered architecture of
agent societies to suggest appropriate commands together with possible command
argument instantiations. Experiments with this approach show that its
effectiveness can be further improved by introducing a resource concept. In
this paper we provide an abstract view on the overall mechanism, motivate the
necessity of an appropriate resource concept and discuss its realization within
the agent architecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3590</identifier>
 <datestamp>2014-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3590</id><created>2009-01-22</created><updated>2009-12-27</updated><authors><author><keyname>Shen</keyname><forenames>Chunhua</forenames></author><author><keyname>Li</keyname><forenames>Hanxi</forenames></author></authors><title>On the Dual Formulation of Boosting Algorithms</title><categories>cs.LG cs.CV</categories><comments>16 pages. To publish/Published in IEEE Transactions on Pattern
  Analysis and Machine Intelligence, 2010</comments><doi>10.1109/TPAMI.2010.47</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study boosting algorithms from a new perspective. We show that the
Lagrange dual problems of AdaBoost, LogitBoost and soft-margin LPBoost with
generalized hinge loss are all entropy maximization problems. By looking at the
dual problems of these boosting algorithms, we show that the success of
boosting algorithms can be understood in terms of maintaining a better margin
distribution by maximizing margins and at the same time controlling the margin
variance.We also theoretically prove that, approximately, AdaBoost maximizes
the average margin, instead of the minimum margin. The duality formulation also
enables us to develop column generation based optimization algorithms, which
are totally corrective. We show that they exhibit almost identical
classification results to that of standard stage-wise additive boosting
algorithms but with much faster convergence rates. Therefore fewer weak
classifiers are needed to build the ensemble using our proposed optimization
technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3596</identifier>
 <datestamp>2009-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3596</id><created>2009-01-22</created><authors><author><keyname>Chang</keyname><forenames>Cheng</forenames></author></authors><title>Joint source-channel with side information coding error exponents</title><categories>cs.IT math.IT</categories><comments>In preparation for IEEE Transactions on IT</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the upper and the lower bounds on the joint
source-channel coding error exponent with decoder side-information. The results
in the paper are non-trivial extensions of the Csiszar's classical paper [5].
Unlike the joint source-channel coding result in [5], it is not obvious whether
the lower bound and the upper bound are equivalent even if the channel coding
error exponent is known. For a class of channels, including the symmetric
channels, we apply a game-theoretic result to establish the existence of a
saddle point and hence prove that the lower and upper bounds are the same if
the channel coding error exponent is known. More interestingly, we show that
encoder side-information does not increase the error exponents in this case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3608</identifier>
 <datestamp>2009-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3608</id><created>2009-01-23</created><authors><author><keyname>Benzmueller</keyname><forenames>Christoph</forenames></author></authors><title>A remark on higher order RUE-resolution with EXTRUE</title><categories>cs.AI cs.LO</categories><comments>3 pages</comments><report-no>SR-02-05</report-no><acm-class>F.4.1; I.2.3</acm-class><journal-ref>SEKI Report (ISSN 1437-4447), Saarland University, 1999</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that a prominent counterexample for the completeness of first order
RUE-resolution does not apply to the higher order RUE-resolution approach
EXTRUE.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3611</identifier>
 <datestamp>2009-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3611</id><created>2009-01-23</created><authors><author><keyname>Fu</keyname><forenames>Liqun</forenames></author><author><keyname>Liew</keyname><forenames>Soung Chang</forenames></author><author><keyname>Huang</keyname><forenames>Jianwei</forenames></author></authors><title>Safe Carrier Sensing Range in CSMA Network under Physical Interference
  Model</title><categories>cs.NI</categories><comments>5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the setting of carrier-sensing range in 802.11
networks under the (cumulative) physical interference model. Specifically, we
identify a carrier-sensing range that will prevent collisions in 802.11
networks due to carrier-sensing failure under the physical interference model.
We find that the carrier-sensing range required under the physical interference
model must be larger than that required under the protocol (pairwise)
interference model by a multiplicative factor. For example, if the SINR
requirement is 10dB and the path-loss exponent is 4, the factor is 1.4.
Furthermore, given a fixed pathloss exponent of 4, the factor increases as the
SINR requirement increases. However, the limit of the factor is 1.84 as the
SINR requirement goes to infinity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3615</identifier>
 <datestamp>2009-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3615</id><created>2009-01-23</created><authors><author><keyname>Huang</keyname><forenames>Xiaofei</forenames></author></authors><title>A Constructive Generalization of Nash Equilibrium</title><categories>cs.GT cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a society of multiple individuals, if everybody is only interested in
maximizing his own payoff, will there exist any equilibrium for the society?
John Nash proved more than 50 years ago that an equilibrium always exists such
that nobody would benefit from unilaterally changing his strategy. Nash
Equilibrium is a central concept in game theory, which offers the mathematical
foundation for social science and economy. However, the original definition is
declarative without including a solution to find them. It has been found later
that it is computationally difficult to find a Nash equilibrium. Furthermore, a
Nash equilibrium may be unstable, sensitive to the smallest variation of payoff
functions. Making the situation worse, a society with selfish individuals can
have an enormous number of equilibria, making it extremely hard to find out the
global optimal one. This paper offers a constructive generalization of Nash
equilibrium to cover the case when the selfishness of individuals are reduced
to lower levels in a controllable way. It shows that the society has one and
only one equilibrium when the selfishness is reduced to a certain level. When
every individual follows the iterative, soft-decision optimization process
presented in this paper, the society converges to the unique equilibrium with
an exponential rate under any initial conditions. When it is a consensus
equilibrium at the same time, it must be the global optimum. The study of this
paper suggests that, to build a good, stable society (including the financial
market) for the benefit everyone in it, the pursuing of maximal payoff by each
individual should be controlled at some level either by voluntary good
citizenship or some proper regulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3619</identifier>
 <datestamp>2009-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3619</id><created>2009-01-23</created><authors><author><keyname>Blazy</keyname><forenames>Sandrine</forenames><affiliation>CEDRIC, INRIA Rocquencourt</affiliation></author><author><keyname>Leroy</keyname><forenames>Xavier</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>Mechanized semantics for the Clight subset of the C language</title><categories>cs.PL</categories><comments>Journal of Automated Reasoning (2009)</comments><proxy>ccsd inria-00352524</proxy><journal-ref>Journal of Automated Reasoning 43, 3 (2009) 263-288</journal-ref><doi>10.1007/s10817-009-9148-3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article presents the formal semantics of a large subset of the C
language called Clight. Clight includes pointer arithmetic, &quot;struct&quot; and
&quot;union&quot; types, C loops and structured &quot;switch&quot; statements. Clight is the source
language of the CompCert verified compiler. The formal semantics of Clight is a
big-step operational semantics that observes both terminating and diverging
executions and produces traces of input/output events. The formal semantics of
Clight is mechanized using the Coq proof assistant. In addition to the
semantics of Clight, this article describes its integration in the CompCert
verified compiler and several ways by which the semantics was validated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3620</identifier>
 <datestamp>2009-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3620</id><created>2009-01-23</created><authors><author><keyname>Chapurlat</keyname><forenames>Vincent</forenames><affiliation>LGI2P</affiliation></author><author><keyname>Foguem</keyname><forenames>Bernard Kamsu</forenames><affiliation>LGI2P</affiliation></author><author><keyname>Prunet</keyname><forenames>Fran&#xe7;ois</forenames><affiliation>LIRMM</affiliation></author></authors><title>Enterprise model verification and validation: an approach</title><categories>cs.SE</categories><proxy>ccsd hal-00354781</proxy><journal-ref>Annual Review in Control 27, 2 (2003) 185-197</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article presents a Verification and Validation approach which is used
here in order to complete the classical tool box the industrial user may
utilize in Enterprise Modeling and Integration domain. This approach, which has
been defined independently from any application domain is based on several
formal concepts and tools presented in this paper. These concepts are property
concepts, property reference matrix, properties graphs, enterprise modeling
domain ontology, conceptual graphs and formal reasoning mechanisms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3630</identifier>
 <datestamp>2009-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3630</id><created>2009-01-23</created><authors><author><keyname>Kudekar</keyname><forenames>Shrinivas</forenames></author><author><keyname>Macris</keyname><forenames>Nicolas</forenames></author></authors><title>Decay of Correlations in Low Density Parity Check Codes: Low Noise
  Regime</title><categories>cs.IT math.IT</categories><comments>5 pages, submitted to ISIT 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider transmission over a binary additive white gaussian noise channel
using a fixed low-density parity check code. We consider the posterior measure
over the code bits and the corresponding correlation between two codebits,
averaged over the noise realizations. We show that for low enough noise
variance this average correlation decays exponentially fast with the graph
distance between the code bits. One consequence of this result is that for low
enough noise variance the GEXIT functions (further averaged over a standard
code ensemble) of the belief propagation and optimal decoders are the same.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3657</identifier>
 <datestamp>2009-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3657</id><created>2009-01-23</created><authors><author><keyname>Bostan</keyname><forenames>Alin</forenames></author><author><keyname>Chowdhury</keyname><forenames>Muhammad</forenames></author><author><keyname>van der Hoeven</keyname><forenames>Joris</forenames></author><author><keyname>Schost</keyname><forenames>Eric</forenames></author></authors><title>Homotopy methods for multiplication modulo triangular sets</title><categories>cs.SC cs.DS</categories><acm-class>I.1.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the cost of multiplication modulo triangular families of
polynomials. Following previous work by Li, Moreno Maza and Schost, we propose
an algorithm that relies on homotopy and fast evaluation-interpolation
techniques. We obtain a quasi-linear time complexity for substantial families
of examples, for which no such result was known before. Applications are given
to notably addition of algebraic numbers in small characteristic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3692</identifier>
 <datestamp>2015-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3692</id><created>2009-01-23</created><updated>2009-07-15</updated><authors><author><keyname>Baumeister</keyname><forenames>Dorothea</forenames></author><author><keyname>Brandt</keyname><forenames>Felix</forenames></author><author><keyname>Fischer</keyname><forenames>Felix</forenames></author><author><keyname>Hoffmann</keyname><forenames>Jan</forenames></author><author><keyname>Rothe</keyname><forenames>Joerg</forenames></author></authors><title>The Complexity of Computing Minimal Unidirectional Covering Sets</title><categories>cs.CC cs.GT</categories><comments>27 pages, 7 figures</comments><journal-ref>Theory of Computing Systems 53(3), 2012</journal-ref><doi>10.1007/s00224-012-9437-9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a binary dominance relation on a set of alternatives, a common thread
in the social sciences is to identify subsets of alternatives that satisfy
certain notions of stability. Examples can be found in areas as diverse as
voting theory, game theory, and argumentation theory. Brandt and Fischer [BF08]
proved that it is NP-hard to decide whether an alternative is contained in some
inclusion-minimal upward or downward covering set. For both problems, we raise
this lower bound to the Theta_{2}^{p} level of the polynomial hierarchy and
provide a Sigma_{2}^{p} upper bound. Relatedly, we show that a variety of other
natural problems regarding minimal or minimum-size covering sets are hard or
complete for either of NP, coNP, and Theta_{2}^{p}. An important consequence of
our results is that neither minimal upward nor minimal downward covering sets
(even when guaranteed to exist) can be computed in polynomial time unless P=NP.
This sharply contrasts with Brandt and Fischer's result that minimal
bidirectional covering sets (i.e., sets that are both minimal upward and
minimal downward covering sets) are polynomial-time computable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3699</identifier>
 <datestamp>2009-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3699</id><created>2009-01-23</created><authors><author><keyname>Frieze</keyname><forenames>Alan</forenames></author><author><keyname>Melsted</keyname><forenames>Pall</forenames></author></authors><title>Randomly colouring simple hypergraphs</title><categories>cs.DM cs.DS</categories><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of constructing a (near) random proper $q$-colouring of
a simple k-uniform hypergraph with n vertices and maximum degree \Delta.
(Proper in that no edge is mono-coloured and simple in that two edges have
maximum intersection of size one). We give conditions on q,\Delta so that if
these conditions are satisfied, Glauber dynamics will converge in O(n\log n)
time from a random (improper) start. The interesting thing here is that for
k\geq 3 we can take q=o(\D).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3706</identifier>
 <datestamp>2010-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3706</id><created>2009-01-23</created><updated>2009-01-25</updated><authors><author><keyname>Brachat</keyname><forenames>Jerome</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Comon</keyname><forenames>Pierre</forenames><affiliation>I3S</affiliation></author><author><keyname>Mourrain</keyname><forenames>Bernard</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Tsigaridas</keyname><forenames>Elias</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author></authors><title>Symmetric tensor decomposition</title><categories>cs.SC math.AG</categories><proxy>ccsd inria-00355713</proxy><journal-ref>Linear Algebra and Applications 433, 11-12 (2010) 851?1872</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an algorithm for decomposing a symmetric tensor, of dimension n
and order d as a sum of rank-1 symmetric tensors, extending the algorithm of
Sylvester devised in 1886 for binary forms. We recall the correspondence
between the decomposition of a homogeneous polynomial in n variables of total
degree d as a sum of powers of linear forms (Waring's problem), incidence
properties on secant varieties of the Veronese Variety and the representation
of linear forms as a linear combination of evaluations at distinct points. Then
we reformulate Sylvester's approach from the dual point of view. Exploiting
this duality, we propose necessary and sufficient conditions for the existence
of such a decomposition of a given rank, using the properties of Hankel (and
quasi-Hankel) matrices, derived from multivariate polynomials and normal form
computations. This leads to the resolution of polynomial equations of small
degree in non-generic cases. We propose a new algorithm for symmetric tensor
decomposition, based on this characterization and on linear algebra
computations with these Hankel matrices. The impact of this contribution is
two-fold. First it permits an efficient computation of the decomposition of any
tensor of sub-generic rank, as opposed to widely used iterative algorithms with
unproved global convergence (e.g. Alternate Least Squares or gradient
descents). Second, it gives tools for understanding uniqueness conditions, and
for detecting the rank.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3751</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3751</id><created>2009-01-23</created><updated>2014-09-22</updated><authors><author><keyname>Lemire</keyname><forenames>Daniel</forenames></author><author><keyname>Kaser</keyname><forenames>Owen</forenames></author><author><keyname>Aouiche</keyname><forenames>Kamel</forenames></author></authors><title>Sorting improves word-aligned bitmap indexes</title><categories>cs.DB</categories><journal-ref>Data &amp; Knowledge Engineering, Volume 69, Issue 1, 2010, Pages 3-28</journal-ref><doi>10.1016/j.datak.2009.08.006</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bitmap indexes must be compressed to reduce input/output costs and minimize
CPU usage. To accelerate logical operations (AND, OR, XOR) over bitmaps, we use
techniques based on run-length encoding (RLE), such as Word-Aligned Hybrid
(WAH) compression. These techniques are sensitive to the order of the rows: a
simple lexicographical sort can divide the index size by 9 and make indexes
several times faster. We investigate row-reordering heuristics. Simply
permuting the columns of the table can increase the sorting efficiency by 40%.
Secondary contributions include efficient algorithms to construct and aggregate
bitmaps. The effect of word length is also reviewed by constructing 16-bit,
32-bit and 64-bit indexes. Using 64-bit CPUs, we find that 64-bit indexes are
slightly faster than 32-bit indexes despite being nearly twice as large.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3754</identifier>
 <datestamp>2009-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3754</id><created>2009-01-23</created><authors><author><keyname>Even-dar</keyname><forenames>Eyal</forenames></author><author><keyname>Mansour</keyname><forenames>Yishay</forenames></author><author><keyname>Mirrokni</keyname><forenames>Vahab</forenames></author><author><keyname>Muthukrishnan</keyname><forenames>S.</forenames></author><author><keyname>Nadav</keyname><forenames>Uri</forenames></author></authors><title>Bid Optimization in Broad-Match Ad auctions</title><categories>cs.GT cs.DS</categories><comments>World Wide Web Conference (WWW09), 10 pages, 2 figures</comments><acm-class>F.2; J.4; H.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ad auctions in sponsored search support ``broad match'' that allows an
advertiser to target a large number of queries while bidding only on a limited
number. While giving more expressiveness to advertisers, this feature makes it
challenging to optimize bids to maximize their returns: choosing to bid on a
query as a broad match because it provides high profit results in one bidding
for related queries which may yield low or even negative profits.
  We abstract and study the complexity of the {\em bid optimization problem}
which is to determine an advertiser's bids on a subset of keywords (possibly
using broad match) so that her profit is maximized. In the query language model
when the advertiser is allowed to bid on all queries as broad match, we present
an linear programming (LP)-based polynomial-time algorithm that gets the
optimal profit. In the model in which an advertiser can only bid on keywords,
ie., a subset of keywords as an exact or broad match, we show that this problem
is not approximable within any reasonable approximation factor unless P=NP. To
deal with this hardness result, we present a constant-factor approximation when
the optimal profit significantly exceeds the cost. This algorithm is based on
rounding a natural LP formulation of the problem. Finally, we study a budgeted
variant of the problem, and show that in the query language model, one can find
two budget constrained ad campaigns in polynomial time that implement the
optimal bidding strategy. Our results are the first to address bid optimization
under the broad match feature which is common in ad auctions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3761</identifier>
 <datestamp>2009-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3761</id><created>2009-01-23</created><authors><author><keyname>Brzozowski</keyname><forenames>J.</forenames></author><author><keyname>Grant</keyname><forenames>E.</forenames></author><author><keyname>Shallit</keyname><forenames>J.</forenames></author></authors><title>Closures in Formal Languages and Kuratowski's Theorem</title><categories>cs.CC cs.FL</categories><comments>submitted to DLT 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A famous theorem of Kuratowski states that in a topological space, at most 14
distinct sets can be produced by repeatedly applying the operations of closure
and complement to a given set. We re-examine this theorem in the setting of
formal languages, where closure is either Kleene closure or positive closure.
We classify languages according to the structure of the algebra they generate
under iterations of complement and closure. We show that there are precisely 9
such algebras in the case of positive closure, and 12 in the case of Kleene
closure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3762</identifier>
 <datestamp>2009-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3762</id><created>2009-01-23</created><updated>2009-06-18</updated><authors><author><keyname>Khan</keyname><forenames>Rubab</forenames></author><author><keyname>Chatterji</keyname><forenames>Shourov</forenames></author></authors><title>Enhancing the capabilities of LIGO time-frequency plane searches through
  clustering</title><categories>gr-qc astro-ph.IM cs.CV physics.data-an</categories><comments>17 pages, 6 figures. Submitted to CQG on Dec 12, 2008; accepted on
  June 18, 2009</comments><journal-ref>Class.Quant.Grav.26:155009,2009</journal-ref><doi>10.1088/0264-9381/26/15/155009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One class of gravitational wave signals LIGO is searching for consists of
short duration bursts of unknown waveforms. Potential sources include core
collapse supernovae, gamma ray burst progenitors, and mergers of binary black
holes or neutron stars. We present a density-based clustering algorithm to
improve the performance of time-frequency searches for such gravitational-wave
bursts when they are extended in time and/or frequency, and not sufficiently
well known to permit matched filtering. We have implemented this algorithm as
an extension to the QPipeline, a gravitational-wave data analysis pipeline for
the detection of bursts, which currently determines the statistical
significance of events based solely on the peak significance observed in
minimum uncertainty regions of the time-frequency plane. Density based
clustering improves the performance of such a search by considering the
aggregate significance of arbitrarily shaped regions in the time-frequency
plane and rejecting the isolated minimum uncertainty features expected from the
background detector noise. In this paper, we present test results for simulated
signals and demonstrate that density based clustering improves the performance
of the QPipeline for signals extended in time and/or frequency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3763</identifier>
 <datestamp>2009-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3763</id><created>2009-01-23</created><authors><author><keyname>Brzozowski</keyname><forenames>J.</forenames></author><author><keyname>Grant</keyname><forenames>E.</forenames></author><author><keyname>Shallit</keyname><forenames>J.</forenames></author></authors><title>Closures in Formal Languages: Concatenation, Separation, and Algorithms</title><categories>cs.CC cs.FL</categories><comments>submitted to DLT 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We continue our study of open and closed languages. We investigate how the
properties of being open and closed are preserved under concatenation. We
investigate analogues, in formal languages, of the separation axioms in
topological spaces; one of our main results is that there is a clopen partition
separating two words if and only if the words commute. We show that we can
decide in quadratic time if the language specified by a DFA is closed, but if
the language is specified by an NFA, the problem is PSPACE-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3769</identifier>
 <datestamp>2009-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3769</id><created>2009-01-23</created><authors><author><keyname>Beaudoin</keyname><forenames>William</forenames><affiliation>I3S</affiliation></author><author><keyname>Verel</keyname><forenames>S&#xe9;bastien</forenames><affiliation>I3S</affiliation></author><author><keyname>Collard</keyname><forenames>Philippe</forenames><affiliation>I3S</affiliation></author><author><keyname>Escazut</keyname><forenames>Cathy</forenames><affiliation>I3S</affiliation></author></authors><title>Deceptiveness and Neutrality - the ND family of fitness landscapes</title><categories>cs.AI</categories><comments>Genetic And Evolutionary Computation Conference, Seatle :
  \'Etats-Unis d'Am\'erique (2006)</comments><proxy>ccsd hal-00164694</proxy><doi>10.1145/1143997.1144091</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When a considerable number of mutations have no effects on fitness values,
the fitness landscape is said neutral. In order to study the interplay between
neutrality, which exists in many real-world applications, and performances of
metaheuristics, it is useful to design landscapes which make it possible to
tune precisely neutral degree distribution. Even though many neutral landscape
models have already been designed, none of them are general enough to create
landscapes with specific neutral degree distributions. We propose three steps
to design such landscapes: first using an algorithm we construct a landscape
whose distribution roughly fits the target one, then we use a simulated
annealing heuristic to bring closer the two distributions and finally we affect
fitness values to each neutral network. Then using this new family of fitness
landscapes we are able to highlight the interplay between deceptiveness and
neutrality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3795</identifier>
 <datestamp>2011-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3795</id><created>2009-01-23</created><updated>2010-01-26</updated><authors><author><keyname>Szajowski</keyname><forenames>Krzysztof</forenames></author></authors><title>On a random number of disorders</title><categories>math.PR cs.IT math.IT math.ST stat.TH</categories><comments>in Institute of Mathematics, Polish Academy of Science, Preprint no.
  702, 25 references, 34 pages</comments><msc-class>60G40, 60K99, 90D60</msc-class><journal-ref>Probability and Mathematical Statistics, vol. 31, Fasc. 1 (2011),
  pp. 17-45</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We register a random sequence which has the following properties: it has
three segments being the homogeneous Markov processes. Each segment has his own
one step transition probability law and the length of the segment is unknown
and random. It means that at two random successive moments (they can be equal
also and equal zero too) the source of observations is changed and the first
observation in new segment is chosen according to new transition probability
starting from the last state of the previous segment. In effect the number of
homogeneous segments is random. The transition probabilities of each process
are known and a priori distribution of the disorder moments is given. The
former research on such problem has been devoted to various questions
concerning the distribution changes. The random number of distributional
segments creates new problems in solutions with relation to analysis of the
model with deterministic number of segments. Two cases are presented in
details. In the first one the objectives is to stop on or between the disorder
moments while in the second one our objective is to find the strategy which
immediately detects the distribution changes. Both problems are reformulated to
optimal stopping of the observed sequences. The detailed analysis of the
problem is presented to show the form of optimal decision function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3809</identifier>
 <datestamp>2009-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3809</id><created>2009-01-23</created><authors><author><keyname>Chang</keyname><forenames>Cheng</forenames></author></authors><title>Interference channel capacity region for randomized fixed-composition
  codes</title><categories>cs.IT math.IT</categories><comments>In preparation for IEEE Transactions on IT</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The randomized fixe-composition with optimal decoding error exponents are
studied \cite{Raul_ISIT,Raul_journal} for the finite alphabet interference
channel (IFC) with two transmitter-receiver pairs. In this paper we investigate
the capacity region of the randomized fixed-composition coding scheme. A
complete characterization of the capacity region of the said coding scheme is
given. The inner bound is derived by showing the existence of a positive error
exponent within the capacity region. A simple universal decoding rule is given.
The tight outer bound is derived by extending a technique first developed in
\cite{Dueck_RC} for single input output channels to interference channels. It
is shown that even with a sophisticated time-sharing scheme among randomized
fixed-composition codes, the capacity region of the randomized
fixed-composition coding is not bigger than the known Han-Kobayashi
\cite{Han_Kobayashi} capacity region. This suggests that the average behavior
of random codes are not sufficient to get new capacity regions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3820</identifier>
 <datestamp>2009-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3820</id><created>2009-01-24</created><authors><author><keyname>Chang</keyname><forenames>Cheng</forenames></author></authors><title>On the rate distortion function of Bernoulli Gaussian sequences</title><categories>cs.IT math.IT</categories><comments>In preparation for IEEE Transactions on IT</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the rate distortion function of the i.i.d sequence of
multiplications of a Bernoulli $p$ random variable and a gaussian random
variable $\sim N(0,1)$. We use a new technique in the derivation of the lower
bound in which we establish the duality between channel coding and lossy source
coding in the strong sense. We improve the lower bound on the rate distortion
function over the best known lower bound by $p\log_2\frac{1}{p}$ if distortion
$D$ is small. This has some interesting implications on sparse signals where
$p$ is small since the known gap between the lower and upper bound is $H(p)$.
This improvement in the lower bound shows that the lower and upper bounds are
almost identical for sparse signals with small distortion because
$\lim\limits_{p\to 0}\frac{p\log_2\frac{1}{p}}{H(p)}=1$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3828</identifier>
 <datestamp>2009-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3828</id><created>2009-01-24</created><authors><author><keyname>Finkel</keyname><forenames>Olivier</forenames><affiliation>ELM</affiliation></author></authors><title>On Recognizable Languages of Infinite Pictures</title><categories>cs.LO cs.CC math.LO</categories><comments>An erratum is added at the end of the paper: The supremum of the set
  of Borel ranks of B\&quot;uchi recognizable languages of infinite pictures is not
  the first non recursive ordinal $\omega_1^{CK}$ but an ordinal $\gamma^1_2$
  which is strictly greater than the ordinal $\omega_1^{CK}$. This follows from
  a result proved by Kechris, Marker and Sami (JSL 1989)</comments><proxy>ccsd hal-00355793</proxy><journal-ref>International Journal of Foundations of Computer Science 15, 6
  (2004) 823-840</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a recent paper, Altenbernd, Thomas and W\&quot;ohrle have considered acceptance
of languages of infinite two-dimensional words (infinite pictures) by finite
tiling systems, with the usual acceptance conditions, such as the B\&quot;uchi and
Muller ones, firstly used for infinite words. The authors asked for comparing
the tiling system acceptance with an acceptance of pictures row by row using an
automaton model over ordinal words of length $\omega^2$. We give in this paper
a solution to this problem, showing that all languages of infinite pictures
which are accepted row by row by B\&quot;uchi or Choueka automata reading words of
length $\omega^2$ are B\&quot;uchi recognized by a finite tiling system, but the
converse is not true. We give also the answer to two other questions which were
raised by Altenbernd, Thomas and W\&quot;ohrle, showing that it is undecidable
whether a B\&quot;uchi recognizable language of infinite pictures is E-recognizable
(respectively, A-recognizable).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3839</identifier>
 <datestamp>2010-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3839</id><created>2009-01-24</created><authors><author><keyname>Goncalves</keyname><forenames>Bruno</forenames></author><author><keyname>Meiss</keyname><forenames>Mark R.</forenames></author><author><keyname>Ramasco</keyname><forenames>Jose J.</forenames></author><author><keyname>Flammini</keyname><forenames>Alessandro</forenames></author><author><keyname>Menczer</keyname><forenames>Filippo</forenames></author></authors><title>Remembering what we like: Toward an agent-based model of Web traffic</title><categories>cs.HC cs.CY cs.IR cs.MA physics.soc-ph</categories><comments>4 pages, 4 figures. Accepted in WSDM 2009 Late Breaking Results</comments><journal-ref>WSDM 2009 Late Breaking Results</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Analysis of aggregate Web traffic has shown that PageRank is a poor model of
how people actually navigate the Web. Using the empirical traffic patterns
generated by a thousand users over the course of two months, we characterize
the properties of Web traffic that cannot be reproduced by Markovian models, in
which destinations are independent of past decisions. In particular, we show
that the diversity of sites visited by individual users is smaller and more
broadly distributed than predicted by the PageRank model; that link traffic is
more broadly distributed than predicted; and that the time between consecutive
visits to the same site by a user is less broadly distributed than predicted.
To account for these discrepancies, we introduce a more realistic navigation
model in which agents maintain individual lists of bookmarks that are used as
teleportation targets. The model can also account for branching, a traffic
property caused by browser features such as tabs and the back button. The model
reproduces aggregate traffic patterns such as site popularity, while also
generating more accurate predictions of diversity, link traffic, and return
time distributions. This model for the first time allows us to capture the
extreme heterogeneity of aggregate traffic measurements while explaining the
more narrowly focused browsing patterns of individual users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3843</identifier>
 <datestamp>2009-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3843</id><created>2009-01-24</created><authors><author><keyname>Bostan</keyname><forenames>Alin</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Schost</keyname><forenames>&#xc9;ric</forenames></author></authors><title>Fast algorithms for differential equations in positive characteristic</title><categories>cs.SC</categories><proxy>ccsd inria-00355818</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address complexity issues for linear differential equations in
characteristic $p&gt;0$: resolution and computation of the $p$-curvature. For
these tasks, our main focus is on algorithms whose complexity behaves well with
respect to $p$. We prove bounds linear in $p$ on the degree of polynomial
solutions and propose algorithms for testing the existence of polynomial
solutions in sublinear time $\tilde{O}(p^{1/2})$, and for determining a whole
basis of the solution space in quasi-linear time $\tilde{O}(p)$; the
$\tilde{O}$ notation indicates that we hide logarithmic factors. We show that
for equations of arbitrary order, the $p$-curvature can be computed in
subquadratic time $\tilde{O}(p^{1.79})$, and that this can be improved to
$O(\log(p))$ for first order equations and to $\tilde{O}(p)$ for classes of
second order equations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3880</identifier>
 <datestamp>2013-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3880</id><created>2009-01-25</created><authors><author><keyname>Jeon</keyname><forenames>Sang-Woon</forenames></author><author><keyname>Chung</keyname><forenames>Sae-Young</forenames></author></authors><title>Capacity Scaling of Single-source Wireless Networks: Effect of Multiple
  Antennas</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE Transactions on Information Theory</comments><journal-ref>IEEE Transactions on Information Theory, vol. 58, no. 11, pp.
  6870-6878, Nov. 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a wireless network in which a single source node located at the
center of a unit area having $m$ antennas transmits messages to $n$ randomly
located destination nodes in the same area having a single antenna each. To
achieve the sum-rate proportional to $m$ by transmit beamforming, channel state
information (CSI) is essentially required at the transmitter (CSIT), which is
hard to obtain in practice because of the time-varying nature of the channels
and feedback overhead. We show that, even without CSIT, the achievable sum-rate
scales as $\Theta(m\log m)$ if a cooperation between receivers is allowed. By
deriving the cut-set upper bound, we also show that $\Theta(m\log m)$ scaling
is optimal. Specifically, for $n=\omega(m^2)$, the simple TDMA-based
quantize-and-forward is enough to achieve the capacity scaling. For
$n=\omega(m)$ and $n=\operatorname{O}(m^2)$, on the other hand, we apply the
hierarchical cooperation to achieve the capacity scaling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3882</identifier>
 <datestamp>2009-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3882</id><created>2009-01-25</created><authors><author><keyname>Shcherbina</keyname><forenames>Oleg</forenames></author></authors><title>Graph-based local elimination algorithms in discrete optimization</title><categories>cs.DM</categories><comments>32 pages, 8 figures</comments><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of this paper is to provide a review of structural decomposition
methods in discrete optimization and to give a unified framework in the form of
local elimination algorithms (LEA). This paper is organized as follows. Local
elimination algorithms for discrete optimization (DO) problems (DOPs) with
constraints are considered; a classification of dynamic programming
computational procedures is given. We introduce Elimination Game and
Elimination tree. Application of bucket elimination algorithm from constraint
satisfaction (CS) to solving DOPs is done. We consider different local
elimination schemes and related notions. Clustering that merges several
variables into single meta-variable defines a promising approach to solve DOPs.
This allows to create a quotient (condensed) graph and apply a local block
elimination algorithm. In order to describe a block elimination process, we
introduce Block Elimination Game. We discuss the connection of aforementioned
local elimination algorithmic schemes and a way of transforming the directed
acyclic graph (DAG) of computational LEA procedure to the tree decomposition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3902</identifier>
 <datestamp>2009-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3902</id><created>2009-01-25</created><authors><author><keyname>Gallot</keyname><forenames>Fabien</forenames><affiliation>LaBRI</affiliation></author><author><keyname>Lagadec</keyname><forenames>Owen</forenames><affiliation>LaBRI</affiliation></author><author><keyname>Desainte-Catherine</keyname><forenames>Myriam</forenames><affiliation>LaBRI</affiliation></author><author><keyname>Marchand</keyname><forenames>Sylvain</forenames><affiliation>LaBRI</affiliation></author></authors><title>iKlax: a New Musical Audio Format for Active Listening</title><categories>cs.SD</categories><proxy>ccsd hal-00351942</proxy><journal-ref>International Computer Music Conference (ICMC), Belfast : Irlande
  (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we are presenting a new model for interactive music. Unlike
most interactive systems, our model is based on file organization, but does not
require digital audio treatments. This model includes a definition of a
constraints system and its solver. The products of this project are intended
for the general public, inexperienced users, as well as professional musicians,
and will be distributed commercially. We are here presenting three products of
this project. The difficulty of this project is to design a technology and
software products for interactive music which must be easy to use by the
general public and by professional composers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3906</identifier>
 <datestamp>2009-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3906</id><created>2009-01-25</created><authors><author><keyname>de Guzman</keyname><forenames>Pablo Chico</forenames></author><author><keyname>Carro</keyname><forenames>Manuel</forenames></author><author><keyname>Hermenegildo</keyname><forenames>Manuel V.</forenames></author></authors><title>A Program Transformation for Continuation Call-Based Tabled Execution</title><categories>cs.PL</categories><comments>Part of the proceedings of CICLOPS 2008</comments><acm-class>D.1.6, D.3.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The advantages of tabled evaluation regarding program termination and
reduction of complexity are well known --as are the significant implementation,
portability, and maintenance efforts that some proposals (especially those
based on suspension) require. This implementation effort is reduced by program
transformation-based continuation call techniques, at some efficiency cost.
However, the traditional formulation of this proposal by Ramesh and Cheng
limits the interleaving of tabled and non-tabled predicates and thus cannot be
used as-is for arbitrary programs. In this paper we present a complete
translation for the continuation call technique which, using the runtime
support needed for the traditional proposal, solves these problems and makes it
possible to execute arbitrary tabled programs. We present performance results
which show that CCall offers a useful tradeoff that can be competitive with
state-of-the-art implementations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3910</identifier>
 <datestamp>2009-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3910</id><created>2009-01-25</created><authors><author><keyname>Lales</keyname><forenames>Charles</forenames><affiliation>LaBRI</affiliation></author><author><keyname>Parisey</keyname><forenames>N.</forenames><affiliation>LaBRI</affiliation></author><author><keyname>Mazat</keyname><forenames>Jean-Pierre</forenames><affiliation>LaBRI</affiliation></author><author><keyname>Beurton-Aimar</keyname><forenames>Marie</forenames><affiliation>LaBRI</affiliation></author></authors><title>Simulation of mitochondrial metabolism using multi-agents system</title><categories>q-bio.SC cs.MA q-bio.QM</categories><proxy>ccsd hal-00353471</proxy><journal-ref>AAMAS'05 (MAS*BIOMED'05), Utrecht : Pays-Bas (2005)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Metabolic pathways describe chains of enzymatic reactions. Their modelling is
a key point to understand living systems. An enzymatic reaction is an
interaction between one or several metabolites (substrates) and an enzyme
(simple protein or enzymatic complex build of several subunits). In our
Mitochondria in Silico Project, MitoScop, we study the metabolism of the
mitochondria, an intra-cellular organelle. Many ordinary differential equation
models are available in the literature. They well fit experimental results on
flux values inside the metabolic pathways, but many parameters are di$\pm$cult
to transcribe with such models: localization of enzymes, rules about the
reactions scheduler, etc Moreover, a model of a significant part of
mitochondrial metabolism could become very complex and contain more than 50
equations. In this context, the multi-agents systems appear as an alternative
to model the metabolic pathways. Firstly, we have looked after membrane design.
The mitochondria is a particular case because the inner mitochondrial space, ie
matricial space, is delimited by two membranes: the inner and the outer one. In
addition to matricial enzymes, other enzymes are located inside the membranes
or in the inter-membrane space. Analysis of mitochondrial metabolism must take
into account this kind of architecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3923</identifier>
 <datestamp>2009-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3923</id><created>2009-01-25</created><authors><author><keyname>Gupchup</keyname><forenames>Jayant</forenames></author><author><keyname>Terzis</keyname><forenames>Andreas</forenames></author><author><keyname>Burns</keyname><forenames>Randal</forenames></author><author><keyname>Szalay</keyname><forenames>Alex</forenames></author></authors><title>Model-Based Event Detection in Wireless Sensor Networks</title><categories>cs.NI cs.CV</categories><journal-ref>Workshop for Data Sharing and Interoperability on the World Wide
  Web (DSI 2007). April 2007, In Proceedings</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present an application of techniques from statistical signal
processing to the problem of event detection in wireless sensor networks used
for environmental monitoring. The proposed approach uses the well-established
Principal Component Analysis (PCA) technique to build a compact model of the
observed phenomena that is able to capture daily and seasonal trends in the
collected measurements. We then use the divergence between actual measurements
and model predictions to detect the existence of discrete events within the
collected data streams. Our preliminary results show that this event detection
mechanism is sensitive enough to detect the onset of rain events using the
temperature modality of a wireless sensor network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3924</identifier>
 <datestamp>2009-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3924</id><created>2009-01-25</created><authors><author><keyname>Eppstein</keyname><forenames>David</forenames></author><author><keyname>Mumford</keyname><forenames>Elena</forenames></author><author><keyname>Speckmann</keyname><forenames>Bettina</forenames></author><author><keyname>Verbeek</keyname><forenames>Kevin</forenames></author></authors><title>Area-Universal Rectangular Layouts</title><categories>cs.CG</categories><comments>19 pages, 16 figures</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A rectangular layout is a partition of a rectangle into a finite set of
interior-disjoint rectangles. Rectangular layouts appear in various
applications: as rectangular cartograms in cartography, as floorplans in
building architecture and VLSI design, and as graph drawings. Often areas are
associated with the rectangles of a rectangular layout and it might hence be
desirable if one rectangular layout can represent several area assignments. A
layout is area-universal if any assignment of areas to rectangles can be
realized by a combinatorially equivalent rectangular layout. We identify a
simple necessary and sufficient condition for a rectangular layout to be
area-universal: a rectangular layout is area-universal if and only if it is
one-sided. More generally, given any rectangular layout L and any assignment of
areas to its regions, we show that there can be at most one layout (up to
horizontal and vertical scaling) which is combinatorially equivalent to L and
achieves a given area assignment. We also investigate similar questions for
perimeter assignments. The adjacency requirements for the rectangles of a
rectangular layout can be specified in various ways, most commonly via the dual
graph of the layout. We show how to find an area-universal layout for a given
set of adjacency requirements whenever such a layout exists.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3929</identifier>
 <datestamp>2009-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3929</id><created>2009-01-25</created><updated>2009-07-31</updated><authors><author><keyname>Rodriguez</keyname><forenames>Marko A.</forenames></author><author><keyname>Watkins</keyname><forenames>Jennifer H.</forenames></author></authors><title>Revisiting the Age of Enlightenment from a Collective Decision Making
  Systems Perspective</title><categories>cs.CY cs.DL</categories><report-no>LA-UR-09-00324</report-no><acm-class>K.4.0</acm-class><journal-ref>First Monday, volume 14, number 8, ISSN:1396-0466, LA-UR-09-00324,
  University of Illinois at Chicago Library, August 2009</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The ideals of the eighteenth century's Age of Enlightenment are the
foundation of modern democracies. The era was characterized by thinkers who
promoted progressive social reforms that opposed the long-established
aristocracies and monarchies of the time. Prominent examples of such reforms
include the establishment of inalienable human rights, self-governing
republics, and market capitalism. Twenty-first century democratic nations can
benefit from revisiting the systems developed during the Enlightenment and
reframing them within the techno-social context of the Information Age. This
article explores the application of social algorithms that make use of Thomas
Paine's (English: 1737--1809) representatives, Adam Smith's (Scottish:
1723--1790) self-interested actors, and Marquis de Condorcet's (French:
1743--1794) optimal decision making groups. It is posited that
technology-enabled social algorithms can better realize the ideals articulated
during the Enlightenment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3939</identifier>
 <datestamp>2009-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3939</id><created>2009-01-25</created><authors><author><keyname>Tan</keyname><forenames>Qingzhao</forenames></author><author><keyname>Mitra</keyname><forenames>Prasenjit</forenames></author><author><keyname>Giles</keyname><forenames>C. Lee</forenames></author></authors><title>Effectively Searching Maps in Web Documents</title><categories>cs.DL cs.IR</categories><comments>12 pages, published in ECIR 2009</comments><acm-class>H.3.7</acm-class><journal-ref>ECIR2009</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Maps are an important source of information in archaeology and other
sciences. Users want to search for historical maps to determine recorded
history of the political geography of regions at different eras, to find out
where exactly archaeological artifacts were discovered, etc. Currently, they
have to use a generic search engine and add the term map along with other
keywords to search for maps. This crude method will generate a significant
number of false positives that the user will need to cull through to get the
desired results. To reduce their manual effort, we propose an automatic map
identification, indexing, and retrieval system that enables users to search and
retrieve maps appearing in a large corpus of digital documents using simple
keyword queries. We identify features that can help in distinguishing maps from
other figures in digital documents and show how a Support-Vector-Machine-based
classifier can be used to identify maps. We propose map-level-metadata e.g.,
captions, references to the maps in text, etc. and document-level metadata,
e.g., title, abstract, citations, how recent the publication is, etc. and show
how they can be automatically extracted and indexed. Our novel ranking
algorithm weights different metadata fields differently and also uses the
document-level metadata to help rank retrieved maps. Empirical evaluations show
which features should be selected and which metadata fields should be weighted
more. We also demonstrate improved retrieval results in comparison to
adaptations of existing methods for map retrieval. Our map search engine has
been deployed in an online map-search system that is part of the Blind-Review
digital library system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3948</identifier>
 <datestamp>2009-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3948</id><created>2009-01-26</created><authors><author><keyname>Soltanolkotabi</keyname><forenames>Mahdi</forenames></author><author><keyname>Amini</keyname><forenames>Arash</forenames></author><author><keyname>Marvasti</keyname><forenames>Farokh</forenames></author></authors><title>OFDM Channel Estimation Based on Adaptive Thresholding for Sparse Signal
  Detection</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless OFDM channels can be approximated by a time varying filter with
sparse time domain taps. Recent achievements in sparse signal processing such
as compressed sensing have facilitated the use of sparsity in estimation, which
improves the performance significantly. The problem of these sparse-based
methods is the need for a stable transformation matrix which is not fulfilled
in the current transmission setups. To assist the analog filtering at the
receiver, the transmitter leaves some of the subcarriers at both edges of the
bandwidth unused which results in an ill-conditioned DFT submatrix. To overcome
this difficulty we propose Adaptive Thresholding for Sparse Signal Detection
(ATSSD). Simulation results confirm that the proposed method works well in
time-invariant and specially time-varying channels where other methods may not
work as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3950</identifier>
 <datestamp>2009-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3950</id><created>2009-01-26</created><authors><author><keyname>Mishali</keyname><forenames>Moshe</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author><author><keyname>Tropp</keyname><forenames>Joel A.</forenames></author></authors><title>Efficient Sampling of Sparse Wideband Analog Signals</title><categories>cs.IT math.IT</categories><comments>13 pages, 5 figs, conference paper (see ref. below)</comments><report-no>CCIT Report #705, Oct. 2008, EE Dept., Technion Israel</report-no><journal-ref>Proc. of IEEEI, 25th convention, pp. 290-294, Dec. 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Periodic nonuniform sampling is a known method to sample spectrally sparse
signals below the Nyquist rate. This strategy relies on the implicit assumption
that the individual samplers are exposed to the entire frequency range. This
assumption becomes impractical for wideband sparse signals. The current paper
proposes an alternative sampling stage that does not require a full-band front
end. Instead, signals are captured with an analog front end that consists of a
bank of multipliers and lowpass filters whose cutoff is much lower than the
Nyquist rate. The problem of recovering the original signal from the low-rate
samples can be studied within the framework of compressive sampling. An
appropriate parameter selection ensures that the samples uniquely determine the
analog input. Moreover, the analog input can be stably reconstructed with
digital algorithms. Numerical experiments support the theoretical analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3984</identifier>
 <datestamp>2009-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3984</id><created>2009-01-26</created><updated>2009-05-06</updated><authors><author><keyname>Meier</keyname><forenames>Michael</forenames></author><author><keyname>Schmidt</keyname><forenames>Michael</forenames></author><author><keyname>Lausen</keyname><forenames>Georg</forenames></author></authors><title>Stop the Chase</title><categories>cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The chase procedure, an algorithm proposed 25+ years ago to fix constraint
violations in database instances, has been successfully applied in a variety of
contexts, such as query optimization, data exchange, and data integration. Its
practicability, however, is limited by the fact that - for an arbitrary set of
constraints - it might not terminate; even worse, chase termination is an
undecidable problem in general. In response, the database community has
proposed sufficient restrictions on top of the constraints that guarantee chase
termination on any database instance. In this paper, we propose a novel
sufficient termination condition, called inductive restriction, which strictly
generalizes previous conditions, but can be checked as efficiently.
Furthermore, we motivate and study the problem of data-dependent chase
termination and, as a key result, present sufficient termination conditions
w.r.t. fixed instances. They are strictly more general than inductive
restriction and might guarantee termination although the chase does not
terminate in the general case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3987</identifier>
 <datestamp>2009-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3987</id><created>2009-01-26</created><updated>2009-05-26</updated><authors><author><keyname>Ravanbakhsh</keyname><forenames>Mohammad</forenames></author><author><keyname>Diez</keyname><forenames>Angela I. Barbero</forenames></author><author><keyname>Ytrehus</keyname><forenames>Oyvind</forenames></author></authors><title>Improved Delay Estimates for a Queueing Model for Random Linear Coding
  for Unicast</title><categories>cs.IT math.IT</categories><comments>5 pages, 3 figures, accepted at the 2009 IEEE International Symposium
  on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider a lossy communication channel for unicast with zero-delay feedback.
For this communication scenario, a simple retransmission scheme is optimum with
respect to delay. An alternative approach is to use random linear coding in
automatic repeat-request (ARQ) mode. We extend the work of Shrader and
Ephremides, by deriving an expression for the delay of random linear coding
over field of infinite size. Simulation results for various field sizes are
also provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3990</identifier>
 <datestamp>2009-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3990</id><created>2009-01-26</created><authors><author><keyname>Jacquemin</keyname><forenames>Bernard</forenames><affiliation>LIMSI</affiliation></author><author><keyname>Ploux</keyname><forenames>Sabine</forenames><affiliation>L2C2</affiliation></author></authors><title>Du corpus au dictionnaire</title><categories>cs.CL cs.IR</categories><proxy>ccsd hal-00355962</proxy><journal-ref>Cahiers de Linguistique. Revue de sociolinguistique et de
  sociologie de la langue fran\c{c}aise 33, 1 (2008) 63-84</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article, we propose an automatic process to build multi-lingual
lexico-semantic resources. The goal of these resources is to browse
semantically textual information contained in texts of different languages.
This method uses a mathematical model called Atlas s\'emantiques in order to
represent the different senses of each word. It uses the linguistic relations
between words to create graphs that are projected into a semantic space. These
projections constitute semantic maps that denote the sense trends of each given
word. This model is fed with syntactic relations between words extracted from a
corpus. Therefore, the lexico-semantic resource produced describes all the
words and all their meanings observed in the corpus. The sense trends are
expressed by syntactic contexts, typical for a given meaning. The link between
each sense trend and the utterances used to build the sense trend are also
stored in an index. Thus all the instances of a word in a particular sense are
linked and can be browsed easily. And by using several corpora of different
languages, several resources are built that correspond with each other through
languages. It makes it possible to browse information through languages thanks
to syntactic contexts translations (even if some of them are partial).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4002</identifier>
 <datestamp>2009-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4002</id><created>2009-01-26</created><authors><author><keyname>Lucarelli</keyname><forenames>Giorgio</forenames></author><author><keyname>Milis</keyname><forenames>Ioannis</forenames></author><author><keyname>Paschos</keyname><forenames>Vangelis Th.</forenames></author></authors><title>Max Edge Coloring of Trees</title><categories>cs.DS</categories><comments>5 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the weighted generalization of the edge coloring problem where the
weight of each color class (matching) equals to the weight of its heaviest edge
and the goal is to minimize the sum of the colors' weights. We present a
3/2-approximation algorithm for trees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4004</identifier>
 <datestamp>2009-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4004</id><created>2009-01-26</created><authors><author><keyname>Estacio-Moreno</keyname><forenames>Alexander</forenames></author><author><keyname>Toussaint</keyname><forenames>Yannick</forenames></author><author><keyname>Bousquet</keyname><forenames>C&#xe9;dric</forenames></author></authors><title>Mining for adverse drug events with formal concept analysis</title><categories>cs.AI</categories><proxy>ccsd hal-00355978</proxy><journal-ref>Studies in health technology and informatics 136 (2008) 803-8</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The pharmacovigilance databases consist of several case reports involving
drugs and adverse events (AEs). Some methods are applied consistently to
highlight all signals, i.e. all statistically significant associations between
a drug and an AE. These methods are appropriate for verification of more
complex relationships involving one or several drug(s) and AE(s) (e.g;
syndromes or interactions) but do not address the identification of them. We
propose a method for the extraction of these relationships based on Formal
Concept Analysis (FCA) associated with disproportionality measures. This method
identifies all sets of drugs and AEs which are potential signals, syndromes or
interactions. Compared to a previous experience of disproportionality analysis
without FCA, the addition of FCA was more efficient for identifying false
positives related to concomitant drugs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4012</identifier>
 <datestamp>2011-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4012</id><created>2009-01-26</created><updated>2009-11-28</updated><authors><author><keyname>Fontanari</keyname><forenames>Jos&#xe9; F.</forenames></author><author><keyname>Cangelosi</keyname><forenames>Angelo</forenames></author></authors><title>Cross-situational and supervised learning in the emergence of
  communication</title><categories>cs.LG</categories><journal-ref>Interaction Studies: Social Behaviour and Communication in
  Biological and Artificial Systems, 12, 119-133 (2011)</journal-ref><doi>10.1075/is.12.1.05fon</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Scenarios for the emergence or bootstrap of a lexicon involve the repeated
interaction between at least two agents who must reach a consensus on how to
name N objects using H words. Here we consider minimal models of two types of
learning algorithms: cross-situational learning, in which the individuals
determine the meaning of a word by looking for something in common across all
observed uses of that word, and supervised operant conditioning learning, in
which there is strong feedback between individuals about the intended meaning
of the words. Despite the stark differences between these learning schemes, we
show that they yield the same communication accuracy in the realistic limits of
large N and H, which coincides with the result of the classical occupancy
problem of randomly assigning N objects to H words.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4016</identifier>
 <datestamp>2009-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4016</id><created>2009-01-24</created><updated>2009-01-26</updated><authors><author><keyname>Wilkerson</keyname><forenames>Daniel Shawcross</forenames></author></authors><title>A Proposal for Proquints: Identifiers that are Readable, Spellable, and
  Pronounceable</title><categories>cs.SE cs.CY cs.HC</categories><comments>Added a suggestion that &quot;0q-&quot; be used as the optional magic number
  prefix for proquint strings. Better to pick one standard than let people make
  up different solutions to this problem</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Identifiers (IDs) are pervasive throughout our modern life. We suggest that
these IDs would be easier to manage and remember if they were easily readable,
spellable, and pronounceable. As a solution to this problem we propose using
PRO-nouncable QUINT-uplets of alternating unambiguous consonants and vowels:
_proquints_.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4023</identifier>
 <datestamp>2009-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4023</id><created>2009-01-26</created><authors><author><keyname>Ryabko</keyname><forenames>Boris</forenames></author><author><keyname>Ryabko</keyname><forenames>Daniil</forenames></author></authors><title>Using Kolmogorov Complexity for Understanding Some Limitations on
  Steganography</title><categories>cs.CC cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently perfectly secure steganographic systems have been described for a
wide class of sources of covertexts. The speed of transmission of secret
information for these stegosystems is proportional to the length of the
covertext. In this work we show that there are sources of covertexts for which
such stegosystems do not exist. The key observation is that if the set of
possible covertexts has a maximal Kolmogorov complexity, then a high-speed
perfect stegosystem has to have complexity of the same order.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4032</identifier>
 <datestamp>2014-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4032</id><created>2009-01-26</created><authors><author><keyname>Mishra</keyname><forenames>Siddhartha</forenames><affiliation>University of Oslo</affiliation></author><author><keyname>Jaffr&#xe9;</keyname><forenames>J&#xe9;r&#xf4;me</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>On the upstream mobility scheme for two-phase flow in porous media</title><categories>cs.NA math.AP math.NA physics.class-ph</categories><comments>A preprint to be published in Computational Geosciences</comments><proxy>ccsd inria-00353627</proxy><report-no>RR-6789</report-no><journal-ref>Computational Geosciences 14 (2010) 105-124</journal-ref><doi>10.1007/s10596-009-9135-0</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When neglecting capillarity, two-phase incompressible flow in porous media is
modelled as a scalar nonlinear hyperbolic conservation law. A change in the
rock type results in a change of the flux function. Discretizing in
one-dimensional with a finite volume method, we investigate two numerical
fluxes, an extension of the Godunov flux and the upstream mobility flux, the
latter being widely used in hydrogeology and petroleum engineering. Then, in
the case of a changing rock type, one can give examples when the upstream
mobility flux does not give the right answer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4068</identifier>
 <datestamp>2009-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4068</id><created>2009-01-26</created><authors><author><keyname>Bandemer</keyname><forenames>Bernd</forenames></author><author><keyname>Vazquez-Vilar</keyname><forenames>Gonzalo</forenames></author><author><keyname>Gamal</keyname><forenames>Abbas El</forenames></author></authors><title>On the Sum Capacity of A Class of Cyclically Symmetric Deterministic
  Interference Channels</title><categories>cs.IT math.IT</categories><comments>5 pages; submitted to IEEE International Symposium on Information
  Theory (ISIT 2009)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Certain deterministic interference channels have been shown to accurately
model Gaussian interference channels in the asymptotic low-noise regime.
Motivated by this correspondence, we investigate a K user-pair, cyclically
symmetric, deterministic interference channel in which each receiver
experiences interference only from its neighboring transmitters (Wyner model).
We establish the sum capacity for a large set of channel parameters, thus
generalizing previous results for the 2-pair case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4080</identifier>
 <datestamp>2009-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4080</id><created>2009-01-26</created><authors><author><keyname>Bouajjani</keyname><forenames>Ahmed</forenames></author><author><keyname>Legay</keyname><forenames>Axel</forenames></author><author><keyname>Wolper</keyname><forenames>Pierre</forenames></author></authors><title>A Framework to Handle Linear Temporal Properties in (\omega-)Regular
  Model Checking</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Since the topic emerged several years ago, work on regular model checking has
mostly been devoted to the verification of state reachability and safety
properties. Though it was known that linear temporal properties could also be
checked within this framework, little has been done about working out the
corresponding details. This paper addresses this issue in the context of
regular model checking based on the encoding of states by finite or infinite
words. It works out the exact constructions to be used in both cases, and
proposes a partial solution to the problem resulting from the fact that
infinite computations of unbounded configurations might never contain the same
configuration twice, thus making cycle detection problematic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4081</identifier>
 <datestamp>2009-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4081</id><created>2009-01-26</created><authors><author><keyname>Zhang</keyname><forenames>Linlin</forenames><affiliation>LAHC</affiliation></author><author><keyname>Legrand</keyname><forenames>Anne Claire</forenames><affiliation>LAHC</affiliation></author><author><keyname>Fresse</keyname><forenames>Virginie</forenames><affiliation>LAHC</affiliation></author><author><keyname>Fischer</keyname><forenames>Viktor</forenames><affiliation>LAHC</affiliation></author></authors><title>Adaptive FPGA NoC-based Architecture for Multispectral Image Correlation</title><categories>cs.AR</categories><proxy>ccsd ujm-00353528</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An adaptive FPGA architecture based on the NoC (Network-on-Chip) approach is
used for the multispectral image correlation. This architecture must contain
several distance algorithms depending on the characteristics of spectral images
and the precision of the authentication. The analysis of distance algorithms is
required which bases on the algorithmic complexity, result precision, execution
time and the adaptability of the implementation. This paper presents the
comparison of these distance computation algorithms on one spectral database.
The result of a RGB algorithm implementation was discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4129</identifier>
 <datestamp>2011-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4129</id><created>2009-01-26</created><updated>2011-08-20</updated><authors><author><keyname>Smarandache</keyname><forenames>Roxana</forenames></author><author><keyname>Vontobel</keyname><forenames>Pascal O.</forenames></author></authors><title>Quasi-Cyclic LDPC Codes: Influence of Proto- and Tanner-Graph Structure
  on Minimum Hamming Distance Upper Bounds</title><categories>cs.IT cs.DM math.IT</categories><comments>To appear in IEEE Transactions on Information Theory. Changes
  compared to v1: some convolutional code results have been added; some
  incompleteness issues with some of the proofs have been corrected; a typo in
  one of the parity-check matrices has been corrected (i.e., an entry of H&quot;(x)
  in Example 28 of v1 needs to be changed so that d_min=56 as written there,
  cf. \hat H(x) in Example 29 of v2)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quasi-cyclic (QC) low-density parity-check (LDPC) codes are an important
instance of proto-graph-based LDPC codes. In this paper we present upper bounds
on the minimum Hamming distance of QC LDPC codes and study how these upper
bounds depend on graph structure parameters (like variable degrees, check node
degrees, girth) of the Tanner graph and of the underlying proto-graph.
Moreover, for several classes of proto-graphs we present explicit QC LDPC code
constructions that achieve (or come close to) the respective minimum Hamming
distance upper bounds. Because of the tight algebraic connection between QC
codes and convolutional codes, we can state similar results for the free
Hamming distance of convolutional codes. In fact, some QC code statements are
established by first proving the corresponding convolutional code statements
and then using a result by Tanner that says that the minimum Hamming distance
of a QC code is upper bounded by the free Hamming distance of the convolutional
code that is obtained by &quot;unwrapping&quot; the QC code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4134</identifier>
 <datestamp>2010-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4134</id><created>2009-01-26</created><updated>2010-03-02</updated><authors><author><keyname>Su</keyname><forenames>Han-I</forenames></author><author><keyname>Gamal</keyname><forenames>Abbas El</forenames></author></authors><title>Distributed Lossy Averaging</title><categories>cs.IT math.IT</categories><comments>25 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An information theoretic formulation of the distributed averaging problem
previously studied in computer science and control is presented. We assume a
network with m nodes each observing a WGN source. The nodes communicate and
perform local processing with the goal of computing the average of the sources
to within a prescribed mean squared error distortion. The network rate
distortion function R^*(D) for a 2-node network with correlated Gaussian
sources is established. A general cutset lower bound on R^*(D) is established
and shown to be achievable to within a factor of 2 via a centralized protocol
over a star network. A lower bound on the network rate distortion function for
distributed weighted-sum protocols, which is larger in order than the cutset
bound by a factor of log m is established. An upper bound on the network rate
distortion function for gossip-base weighted-sum protocols, which is only log
log m larger in order than the lower bound for a complete graph network, is
established. The results suggest that using distributed protocols results in a
factor of log m increase in order relative to centralized protocols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4137</identifier>
 <datestamp>2009-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4137</id><created>2009-01-26</created><authors><author><keyname>Hutter</keyname><forenames>Marcus</forenames></author></authors><title>Practical Robust Estimators for the Imprecise Dirichlet Model</title><categories>math.ST cs.LG stat.ML stat.TH</categories><comments>22 pages, 2 figures</comments><journal-ref>International Journal of Approximate Reasoning, 50:2 (2009) pages
  231-242</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Walley's Imprecise Dirichlet Model (IDM) for categorical i.i.d. data extends
the classical Dirichlet model to a set of priors. It overcomes several
fundamental problems which other approaches to uncertainty suffer from. Yet, to
be useful in practice, one needs efficient ways for computing the
imprecise=robust sets or intervals. The main objective of this work is to
derive exact, conservative, and approximate, robust and credible interval
estimates under the IDM for a large class of statistical estimators, including
the entropy and mutual information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4147</identifier>
 <datestamp>2009-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4147</id><created>2009-01-27</created><authors><author><keyname>Dideban</keyname><forenames>Abbas</forenames><affiliation>GIPSA-lab</affiliation></author><author><keyname>Alla</keyname><forenames>Hassane.</forenames><affiliation>GIPSA-lab</affiliation></author></authors><title>Determination of Minimal Sets of Control Places for Safe Petri Nets</title><categories>cs.IT math.IT</categories><comments>ACC07 American Control Conference, New-York : \'Etats-Unis
  d'Am\'erique (2007)</comments><proxy>ccsd hal-00356523</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Our objective is to design a controlled system with a simple method for
discrete event systems based on Petri nets. It is possible to construct the
Petri net model of a system and the specification separately. By synchronous
composition of both models, the desired functioning closed loop model is
deduced. Often uncontrollable transitions lead to forbidden states. The problem
of forbidden states is solved using linear constraints. A set of linear
constraints allows forbidding the reachability of these states. Generally, the
number of these so-called forbidden states and consequently the number of
constraints are large and lead to a great number of control places. A
systematic method to reduce the size and the number of constraints for safe
Petri Nets is given. By using a method based on the Petri nets invariants,
maximal permissive controllers are determined. The size of the controller is
close to the size of the specified model, and it can be implemented on a PLC in
a structural way.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4180</identifier>
 <datestamp>2015-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4180</id><created>2009-01-27</created><updated>2015-01-28</updated><authors><author><keyname>Kjos-Hanssen</keyname><forenames>Bj&#xf8;rn</forenames></author><author><keyname>Evangelista</keyname><forenames>Alberto J.</forenames></author></authors><title>Google distance between words</title><categories>cs.CL</categories><comments>Presented at Frontiers in Undergraduate Research, University of
  Connecticut, 2006</comments><acm-class>I.2.7</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cilibrasi and Vitanyi have demonstrated that it is possible to extract the
meaning of words from the world-wide web. To achieve this, they rely on the
number of webpages that are found through a Google search containing a given
word and they associate the page count to the probability that the word appears
on a webpage. Thus, conditional probabilities allow them to correlate one word
with another word's meaning. Furthermore, they have developed a similarity
distance function that gauges how closely related a pair of words is. We
present a specific counterexample to the triangle inequality for this
similarity distance function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4192</identifier>
 <datestamp>2010-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4192</id><created>2009-01-27</created><updated>2009-07-03</updated><authors><author><keyname>Johnson</keyname><forenames>Jason K.</forenames></author><author><keyname>Bickson</keyname><forenames>Danny</forenames></author><author><keyname>Dolev</keyname><forenames>Danny</forenames></author></authors><title>Fixing Convergence of Gaussian Belief Propagation</title><categories>cs.IT cs.LG math.IT stat.CO</categories><comments>In the IEEE International Symposium on Information Theory (ISIT)
  2009, Seoul, South Korea, July 2009</comments><doi>10.1109/ISIT.2009.5205777</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Gaussian belief propagation (GaBP) is an iterative message-passing algorithm
for inference in Gaussian graphical models. It is known that when GaBP
converges it converges to the correct MAP estimate of the Gaussian random
vector and simple sufficient conditions for its convergence have been
established. In this paper we develop a double-loop algorithm for forcing
convergence of GaBP. Our method computes the correct MAP estimate even in cases
where standard GaBP would not have converged. We further extend this
construction to compute least-squares solutions of over-constrained linear
systems. We believe that our construction has numerous applications, since the
GaBP algorithm is linked to solution of linear systems of equations, which is a
fundamental problem in computer science and engineering. As a case study, we
discuss the linear detection problem. We show that using our new construction,
we are able to force convergence of Montanari's linear detection algorithm, in
cases where it would originally fail. As a consequence, we are able to increase
significantly the number of users that can transmit concurrently.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4201</identifier>
 <datestamp>2009-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4201</id><created>2009-01-27</created><authors><author><keyname>Lugiez</keyname><forenames>Denis</forenames><affiliation>LIF</affiliation></author><author><keyname>Martin</keyname><forenames>St&#xe9;phane</forenames><affiliation>LIF</affiliation></author></authors><title>Peer to Peer Optimistic Collaborative Editing on XML-like trees</title><categories>cs.DS</categories><proxy>ccsd hal-00343484</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Collaborative editing consists in editing a common document shared by several
independent sites. This may give rise to conficts when two different users
perform simultaneous uncompatible operations. Centralized systems solve this
problem by using locks that prevent some modifications to occur and leave the
resolution of confict to users. On the contrary, peer to peer (P2P) editing
doesn't allow locks and the optimistic approach uses a Integration
Transformation IT that reconciliates the conficting operations and ensures
convergence (all copies are identical on each site). Two properties TP1 and
TP2, relating the set of allowed operations Op and the transformation IT, have
been shown to ensure the correctness of the process. The choice of the set Op
is crucial to define an integration operation that satisfies TP1 and TP2. Many
existing algorithms don't satisfy these properties and are indeed incorrect
i.e. convergence is not guaranteed. No algorithm enjoying both properties is
known for strings and little work has been done for XML trees in a pure P2P
framework (that doesn't use time-stamps for instance). We focus on editing
unranked unordered labeled trees, so-called XML-like trees that are considered
for instance in the Harmony pro ject. We show that no transformation satisfying
TP1 and TP2 can exist for a first set of operations but we show that TP1 and
TP2 hold for a richer set of operations. We show how to combine our approach
with any convergent editing process on strings (not necessarily based on
integration transformation) to get a convergent process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4205</identifier>
 <datestamp>2009-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4205</id><created>2009-01-27</created><authors><author><keyname>Edoukou</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>IML</affiliation></author><author><keyname>Hallez</keyname><forenames>Anja</forenames><affiliation>IML</affiliation></author><author><keyname>Rodier</keyname><forenames>Fran&#xe7;ois</forenames><affiliation>IML</affiliation></author><author><keyname>Storme</keyname><forenames>Leo</forenames></author></authors><title>On the small weight codewords of the functional codes C_2(Q), Q a
  non-singular quadric</title><categories>math.AG cs.IT math.IT</categories><proxy>ccsd hal-00356568</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the small weight codewords of the functional code C_2(Q), with Q a
non-singular quadric of PG(N,q). We prove that the small weight codewords
correspond to the intersections of Q with the singular quadrics of PG(N,q)
consisting of two hyperplanes. We also calculate the number of codewords having
these small weights.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4224</identifier>
 <datestamp>2009-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4224</id><created>2009-01-27</created><authors><author><keyname>Di Donato</keyname><forenames>Pasquale</forenames></author></authors><title>Geospatial semantics: beyond ontologies, towards an enactive approach</title><categories>cs.AI cs.DB</categories><comments>24 pages, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Current approaches to semantics in the geospatial domain are mainly based on
ontologies, but ontologies, since continue to build entirely on the symbolic
methodology, suffers from the classical problems, e.g. the symbol grounding
problem, affecting representational theories. We claim for an enactive approach
to semantics, where meaning is considered to be an emergent feature arising
context-dependently in action. Since representational theories are unable to
deal with context, a new formalism is required toward a contextual theory of
concepts. SCOP is considered a promising formalism in this sense and is briefly
described.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4267</identifier>
 <datestamp>2009-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4267</id><created>2009-01-27</created><authors><author><keyname>Jalden</keyname><forenames>Joakim</forenames></author><author><keyname>Elia</keyname><forenames>Petros</forenames></author></authors><title>LR-aided MMSE lattice decoding is DMT optimal for all approximately
  universal codes</title><categories>cs.IT math.IT</categories><comments>5 pages, submitted to ISIT 09</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Currently for the nt x nr MIMO channel, any explicitly constructed space-time
(ST) designs that achieve optimality with respect to the diversity multiplexing
tradeoff (DMT) are known to do so only when decoded using maximum likelihood
(ML) decoding, which may incur prohibitive decoding complexity. In this paper
we prove that MMSE regularized lattice decoding, as well as the computationally
efficient lattice reduction (LR) aided MMSE decoder, allows for efficient and
DMT optimal decoding of any approximately universal lattice-based code. The
result identifies for the first time an explicitly constructed encoder and a
computationally efficient decoder that achieve DMT optimality for all
multiplexing gains and all channel dimensions. The results hold irrespective of
the fading statistics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4272</identifier>
 <datestamp>2009-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4272</id><created>2009-01-27</created><authors><author><keyname>Hachemi</keyname><forenames>Khalid</forenames><affiliation>GIPSA-lab</affiliation></author><author><keyname>Alla</keyname><forenames>Hassane.</forenames><affiliation>GIPSA-lab</affiliation></author></authors><title>Dynamic Control of a Flow-Rack Automated Storage and Retrieval System</title><categories>cs.IT math.IT</categories><comments>CSCS 17 15th International Conference on Control Systems and Computer
  Science, Bucarest : Roumanie (2007)</comments><proxy>ccsd hal-00356502</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose a control scheme based on coloured Petri net (CPN)
for a flow-rack automated storage and retrieval system. The AS/RS is modelled
using Coloured Petri nets, the developed model has been used to capture and
provide the rack state. We introduce in the control system an optimization
module as a decision process which performs a real-time optimization working on
a discrete events time scale. The objective is to find bin locations for the
retrieval requests by minimizing the total number of retrieval cycles for a
batch of requests and thereby increase the system throughput. By solving the
optimization model, the proposed method gives according to customers request
and the rack state, the best bin locations for retrieval, i.e. allowing at the
same time to satisfy the customers request and carrying out the minimum of
retrieval cycles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4275</identifier>
 <datestamp>2009-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4275</id><created>2009-01-27</created><authors><author><keyname>Chang</keyname><forenames>Hyun Sung</forenames></author><author><keyname>Weiss</keyname><forenames>Yair</forenames></author><author><keyname>Freeman</keyname><forenames>William T.</forenames></author></authors><title>Informative Sensing</title><categories>cs.IT math.IT</categories><comments>26 pages; submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compressed sensing is a recent set of mathematical results showing that
sparse signals can be exactly reconstructed from a small number of linear
measurements. Interestingly, for ideal sparse signals with no measurement
noise, random measurements allow perfect reconstruction while measurements
based on principal component analysis (PCA) or independent component analysis
(ICA) do not. At the same time, for other signal and noise distributions, PCA
and ICA can significantly outperform random projections in terms of enabling
reconstruction from a small number of measurements. In this paper we ask: given
the distribution of signals we wish to measure, what are the optimal set of
linear projections for compressed sensing? We consider the problem of finding a
small number of linear projections that are maximally informative about the
signal. Formally, we use the InfoMax criterion and seek to maximize the mutual
information between the signal, x, and the (possibly noisy) projection y=Wx. We
show that in general the optimal projections are not the principal components
of the data nor random projections, but rather a seemingly novel set of
projections that capture what is still uncertain about the signal, given the
knowledge of distribution. We present analytic solutions for certain special
cases including natural images. In particular, for natural images, the
near-optimal projections are bandwise random, i.e., incoherent to the sparse
bases at a particular frequency band but with more weights on the
low-frequencies, which has a physical relation to the multi-resolution
representation of images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4322</identifier>
 <datestamp>2009-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4322</id><created>2009-01-27</created><authors><author><keyname>Leander</keyname><forenames>Gregor</forenames><affiliation>IML</affiliation></author><author><keyname>Rodier</keyname><forenames>Fran&#xe7;ois</forenames><affiliation>IML</affiliation></author></authors><title>Bounds on the degree of APN polynomials The Case of $x^{-1}+g(x)$</title><categories>math.AG cs.CR</categories><proxy>ccsd hal-00356562</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that functions $f:\f{2^m} \to \f{2^m}$ of the form
$f(x)=x^{-1}+g(x)$ where $g$ is any non-affine polynomial are APN on at most a
finite number of fields $\f{2^m}$. Furthermore we prove that when the degree of
$g$ is less then 7 such functions are APN only if $m \le 3$ where these
functions are equivalent to $x^3$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4323</identifier>
 <datestamp>2009-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4323</id><created>2009-01-26</created><authors><author><keyname>van der Hoeven</keyname><forenames>Joris</forenames></author><author><keyname>Lecerf</keyname><forenames>Gr&#xe9;goire</forenames></author></authors><title>On the bit-complexity of sparse polynomial multiplication</title><categories>cs.DS cs.MS</categories><acm-class>I.1.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present fast algorithms for the product of two multivariate
polynomials in sparse representation. The bit complexity of our algorithms are
studied in detail for various types of coefficients, and we derive new
complexity results for the power series multiplication in many variables. Our
algorithms are implemented and freely available within the Mathemagix software.
We show that their theoretical costs are well-reflected in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4375</identifier>
 <datestamp>2009-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4375</id><created>2009-01-27</created><authors><author><keyname>Bruza</keyname><forenames>P. D.</forenames></author><author><keyname>Kitto</keyname><forenames>K.</forenames></author><author><keyname>Nelson</keyname><forenames>D.</forenames></author><author><keyname>McEvoy</keyname><forenames>C.</forenames></author></authors><title>Extracting Spooky-activation-at-a-distance from Considerations of
  Entanglement</title><categories>physics.data-an cs.CL quant-ph</categories><comments>13 pages, 2 figures; To appear in Proceedings of the Third Quantum
  Interaction Symposium, Lecture Notes in Artificial Intelligence, vol 5494,
  Springer, 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Following an early claim by Nelson &amp; McEvoy \cite{Nelson:McEvoy:2007}
suggesting that word associations can display `spooky action at a distance
behaviour', a serious investigation of the potentially quantum nature of such
associations is currently underway. This paper presents a simple quantum model
of a word association system. It is shown that a quantum model of word
entanglement can recover aspects of both the Spreading Activation equation and
the Spooky-activation-at-a-distance equation, both of which are used to model
the activation level of words in human memory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4379</identifier>
 <datestamp>2012-06-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4379</id><created>2009-01-27</created><updated>2012-06-16</updated><authors><author><keyname>Nazer</keyname><forenames>Bobak</forenames></author><author><keyname>Gastpar</keyname><forenames>Michael</forenames></author><author><keyname>Jafar</keyname><forenames>Syed A.</forenames></author><author><keyname>Vishwanath</keyname><forenames>Sriram</forenames></author></authors><title>Ergodic Interference Alignment</title><categories>cs.IT math.IT</categories><comments>16 pages, 6 figure, To appear in IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper develops a new communication strategy, ergodic interference
alignment, for the K-user interference channel with time-varying fading. At any
particular time, each receiver will see a superposition of the transmitted
signals plus noise. The standard approach to such a scenario results in each
transmitter-receiver pair achieving a rate proportional to 1/K its
interference-free ergodic capacity. However, given two well-chosen time
indices, the channel coefficients from interfering users can be made to exactly
cancel. By adding up these two observations, each receiver can obtain its
desired signal without any interference. If the channel gains have independent,
uniform phases, this technique allows each user to achieve at least 1/2 its
interference-free ergodic capacity at any signal-to-noise ratio. Prior
interference alignment techniques were only able to attain this performance as
the signal-to-noise ratio tended to infinity. Extensions are given for the case
where each receiver wants a message from more than one transmitter as well as
the &quot;X channel&quot; case (with two receivers) where each transmitter has an
independent message for each receiver. Finally, it is shown how to generalize
this strategy beyond Gaussian channel models. For a class of finite field
interference channels, this approach yields the ergodic capacity region.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4400</identifier>
 <datestamp>2013-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4400</id><created>2009-01-28</created><updated>2009-01-28</updated><authors><author><keyname>Bihan</keyname><forenames>Frederic</forenames></author><author><keyname>Rojas</keyname><forenames>J. Maurice</forenames></author><author><keyname>Stella</keyname><forenames>Casey</forenames></author></authors><title>Faster Real Feasibility via Circuit Discriminants</title><categories>math.AG cs.CC math.OC</categories><comments>12 pages in double column ACM format. Submitted to a conference.
  Significantly improves and simplifies the algorithms and complexity lower
  bounds of arXiv:math/0411107 . Also presents a new complexity lower bound for
  A-discriminants. This version fixes many annoying typos</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that detecting real roots for honestly n-variate (n+2)-nomials (with
integer exponents and coefficients) can be done in time polynomial in the
sparse encoding for any fixed n. The best previous complexity bounds were
exponential in the sparse encoding, even for n fixed. We then give a
characterization of those functions k(n) such that the complexity of detecting
real roots for n-variate (n+k(n))-nomials transitions from P to NP-hardness as
n tends to infinity. Our proofs follow in large part from a new complexity
threshold for deciding the vanishing of A-discriminants of n-variate
(n+k(n))-nomials. Diophantine approximation, through linear forms in
logarithms, also arises as a key tool.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4404</identifier>
 <datestamp>2009-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4404</id><created>2009-01-28</created><authors><author><keyname>Horan</keyname><forenames>Peter</forenames></author><author><keyname>Carminati</keyname><forenames>John</forenames></author></authors><title>Performance of Buchberger's Improved Algorithm using Prime Based
  Ordering</title><categories>cs.SE cs.SC</categories><comments>10 pages, 2 tables, 4 refs</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Prime-based ordering which is proved to be admissible, is the encoding of
indeterminates in power-products with prime numbers and ordering them by using
the natural number order. Using Eiffel, four versions of Buchberger's improved
algorithm for obtaining Groebner Bases have been developed: two total degree
versions, representing power products as strings and the other two as integers
based on prime-based ordering. The versions are further distinguished by
implementing coefficients as 64-bit integers and as multiple-precision
integers. By using primebased power product coding, iterative or recursive
operations on power products are replaced with integer operations. It is found
that on a series of example polynomial sets, significant reductions in
computation time of 30% or more are almost always obtained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4417</identifier>
 <datestamp>2010-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4417</id><created>2009-01-28</created><updated>2010-02-12</updated><authors><author><keyname>Wild</keyname><forenames>Marcel</forenames></author></authors><title>A novel type of branch and bound for maximum independent set</title><categories>cs.DS cs.DM cs.MS</categories><comments>The section break up in v2 is improved, parts are trimmed, other
  parts added (e.g graphs with up to 3000 vertices are handled), the new title
  is more diplomatic. See the last page of version 1 for the missing figure on
  page 2 of version 2 (technical problems)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Several algorithms are presented. The standard algorithm generates all N
anticliques of a graph with v vertices in time O(N^v2). It can e.g. be adapted
to calculate the independence polynomial of G, to generate all maximum
cardinality anticliques, or just one maximum anticlique. The latter was
programmed using the Mathematica 6.0 code. For a random (45, 92)-graph G a
maximum anticlique of size 21 was found in 1.344 sec, whereas the &quot;hardwired&quot;
Mathematica command MaximumIndependentSet[G] clocked in at 155838 sec, which is
five orders of magnitude slower.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4420</identifier>
 <datestamp>2009-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4420</id><created>2009-01-28</created><authors><author><keyname>Sharma</keyname><forenames>Kamalesh Kumar</forenames></author></authors><title>Some Generalizations of the Capacity Theorem for AWGN Channels</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The channel capacity theorem for additive white Gaussian noise channel
(AWGN), widely known as the Shannon-Hartley Law, expresses the information
capacity of a channel bandlimited in the conventional Fourier domain in terms
of the signal-to-noise ratio in it. In this letter generalized versions of the
Shannon-Hartley Law using the linear canonical transform (LCT) are presented.
The channel capacity for AWGN channels is found to be a function of the LCT
parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4430</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4430</id><created>2009-01-28</created><updated>2009-04-20</updated><authors><author><keyname>Hansen</keyname><forenames>Helle Hvid</forenames></author><author><keyname>Kupke</keyname><forenames>Clemens</forenames></author><author><keyname>Pacuit</keyname><forenames>Eric</forenames></author></authors><title>Neighbourhood Structures: Bisimilarity and Basic Model Theory</title><categories>cs.LO</categories><comments>uses LMCS.cls (included), 2 figures (both ps and pdf)</comments><acm-class>F.1.1; F.3.2; F.4.1; I.2.4</acm-class><journal-ref>Logical Methods in Computer Science, Volume 5, Issue 2 (April 9,
  2009) lmcs:1167</journal-ref><doi>10.2168/LMCS-5(2:2)2009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Neighbourhood structures are the standard semantic tool used to reason about
non-normal modal logics. The logic of all neighbourhood models is called
classical modal logic. In coalgebraic terms, a neighbourhood frame is a
coalgebra for the contravariant powerset functor composed with itself, denoted
by 2^2. We use this coalgebraic modelling to derive notions of equivalence
between neighbourhood structures. 2^2-bisimilarity and behavioural equivalence
are well known coalgebraic concepts, and they are distinct, since 2^2 does not
preserve weak pullbacks. We introduce a third, intermediate notion whose
witnessing relations we call precocongruences (based on pushouts). We give
back-and-forth style characterisations for 2^2-bisimulations and
precocongruences, we show that on a single coalgebra, precocongruences capture
behavioural equivalence, and that between neighbourhood structures,
precocongruences are a better approximation of behavioural equivalence than
2^2-bisimulations. We also introduce a notion of modal saturation for
neighbourhood models, and investigate its relationship with definability and
image-finiteness. We prove a Hennessy-Milner theorem for modally saturated and
for image-finite neighbourhood models. Our main results are an analogue of Van
Benthem's characterisation theorem and a model-theoretic proof of Craig
interpolation for classical modal logic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4466</identifier>
 <datestamp>2010-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4466</id><created>2009-01-28</created><authors><author><keyname>Adamatzky</keyname><forenames>Andrew</forenames></author></authors><title>Physarum boats: If plasmodium sailed it would never leave a port</title><categories>cs.RO q-bio.CB</categories><acm-class>I.2.9; J.3</acm-class><journal-ref>Applied Bionics and Biomechanics, Volume 7, Issue 1 March 2010 ,
  pages 31 - 39</journal-ref><doi>10.1080/11762320902863890</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Plasmodium of \emph{Physarum polycephalum} is a single huge (visible by naked
eye) cell with myriad of nuclei. The plasmodium is a promising substrate for
non-classical, nature-inspired, computing devices. It is capable for
approximation of shortest path, computation of planar proximity graphs and
plane tessellations, primitive memory and decision-making. The unique
properties of the plasmodium make it an ideal candidate for a role of amorphous
biological robots with massive parallel information processing and distributed
inputs and outputs. We show that when adhered to light-weight object resting on
a water surface the plasmodium can propel the object by oscillating its
protoplasmic pseudopodia. In experimental laboratory conditions and
computational experiments we study phenomenology of the plasmodium-floater
system, and possible mechanisms of controlling motion of objects propelled by
on board plasmodium.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4467</identifier>
 <datestamp>2011-10-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4467</id><created>2009-01-28</created><updated>2011-10-07</updated><authors><author><keyname>Braunstein</keyname><forenames>Alfredo</forenames></author><author><keyname>Kayhan</keyname><forenames>Farbod</forenames></author><author><keyname>Zecchina</keyname><forenames>Riccardo</forenames></author></authors><title>Efficient LDPC Codes over GF(q) for Lossy Data Compression</title><categories>cs.IT math.IT</categories><comments>5 pages, 3 figures</comments><journal-ref>In: IEEE International Symposium on Information Theory, 2009. ISIT
  2009. Seul, Korea; 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider the lossy compression of a binary symmetric source.
We present a scheme that provides a low complexity lossy compressor with near
optimal empirical performance. The proposed scheme is based on b-reduced
ultra-sparse LDPC codes over GF(q). Encoding is performed by the Reinforced
Belief Propagation algorithm, a variant of Belief Propagation. The
computational complexity at the encoder is O(&lt;d&gt;.n.q.log q), where &lt;d&gt; is the
average degree of the check nodes. For our code ensemble, decoding can be
performed iteratively following the inverse steps of the leaf removal
algorithm. For a sparse parity-check matrix the number of needed operations is
O(n).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4496</identifier>
 <datestamp>2009-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4496</id><created>2009-01-28</created><authors><author><keyname>Brett</keyname><forenames>Andreas</forenames></author><author><keyname>Leicher</keyname><forenames>Andreas</forenames></author></authors><title>Ethemba Trusted Host EnvironmentMainly Based on Attestation</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ethemba provides a framework and demonstrator for TPM applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4551</identifier>
 <datestamp>2009-01-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4551</id><created>2009-01-28</created><authors><author><keyname>Chan</keyname><forenames>Terence</forenames></author><author><keyname>Cai</keyname><forenames>Ning</forenames></author><author><keyname>Grant</keyname><forenames>Alex</forenames></author></authors><title>Robust Key Agreement Schemes</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers a key agreement problem in which two parties aim to
agree on a key by exchanging messages in the presence of adversarial tampering.
The aim of the adversary is to disrupt the key agreement process, but there are
no secrecy constraints (i.e. we do not insist that the key is kept secret from
the adversary). The main results of the paper are coding schemes and bounds on
maximum key generation rates for this problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4571</identifier>
 <datestamp>2009-01-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4571</id><created>2009-01-28</created><authors><author><keyname>McCown</keyname><forenames>Frank</forenames></author><author><keyname>Nelson</keyname><forenames>Michael L.</forenames></author><author><keyname>Van de Sompel</keyname><forenames>Herbert</forenames></author></authors><title>Everyone is a Curator: Human-Assisted Preservation for ORE Aggregations</title><categories>cs.DL cs.IR</categories><comments>8 pages, 12 figures, accepted at DigCCurr 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Open Archives Initiative (OAI) has recently created the Object Reuse and
Exchange (ORE) project that defines Resource Maps (ReMs) for describing
aggregations of web resources. These aggregations are susceptible to many of
the same preservation challenges that face other web resources. In this paper,
we investigate how the aggregations of web resources can be preserved outside
of the typical repository environment and instead rely on the thousands of
interactive users in the web community and the Web Infrastructure (the
collection of web archives, search engines, and personal archiving services) to
facilitate preservation. Inspired by Web 2.0 services such as digg,
deli.cio.us, and Yahoo! Buzz, we have developed a lightweight system called
ReMember that attempts to harness the collective abilities of the web community
for preservation purposes instead of solely placing the burden of curatorial
responsibilities on a small number of experts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4591</identifier>
 <datestamp>2009-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4591</id><created>2009-01-29</created><authors><author><keyname>Aly</keyname><forenames>Salah A.</forenames></author><author><keyname>Kamal</keyname><forenames>Ahmed E.</forenames></author></authors><title>Network Coding-Based Protection Strategy Against Node Failures</title><categories>cs.IT cs.CR cs.NI math.IT</categories><comments>5 pages, 2 figures, accepted in ICC'09</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The enormous increase in the usage of communication networks has made
protection against node and link failures essential in the deployment of
reliable networks. To prevent loss of data due to node failures, a network
protection strategy is proposed that aims to withstand such failures.
Particularly, a protection strategy against any single node failure is designed
for a given network with a set of $n$ disjoint paths between senders and
receivers. Network coding and reduced capacity are deployed in this strategy
without adding extra working paths to the readily available connection paths.
This strategy is based on protection against node failures as protection
against multiple link failures. In addition, the encoding and decoding
operational aspects of the premeditated protection strategy are demonstrated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4612</identifier>
 <datestamp>2009-01-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4612</id><created>2009-01-29</created><authors><author><keyname>Thakor</keyname><forenames>Satyajit</forenames></author><author><keyname>Grant</keyname><forenames>Alex</forenames></author><author><keyname>Chan</keyname><forenames>Terence</forenames></author></authors><title>Network Coding Capacity: A Functional Dependence Bound</title><categories>cs.IT math.IT</categories><comments>5 pages, 2 figures, submitted to the International Symposium on
  Information Theory 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Explicit characterization and computation of the multi-source network coding
capacity region (or even bounds) is long standing open problem. In fact,
finding the capacity region requires determination of the set of all entropic
vectors $\Gamma^{*}$, which is known to be an extremely hard problem. On the
other hand, calculating the explicitly known linear programming bound is very
hard in practice due to an exponential growth in complexity as a function of
network size. We give a new, easily computable outer bound, based on
characterization of all functional dependencies in networks. We also show that
the proposed bound is tighter than some known bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4642</identifier>
 <datestamp>2009-01-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4642</id><created>2009-01-29</created><authors><author><keyname>Poroor</keyname><forenames>Jayaraj</forenames></author><author><keyname>Karunagaran</keyname><forenames>Sriram</forenames></author><author><keyname>Sundararajan</keyname><forenames>Sudharsan</forenames></author><author><keyname>Pillai</keyname><forenames>Ranjith</forenames></author></authors><title>Fast Dual-Radio Cross-Layer Handoffs in Multi-Hop Infrastructure-mode
  802.11 Wireless Networks for In-Vehicle Multimedia Infotainment</title><categories>cs.NI</categories><comments>Presented (oral) at IEEE Advanced Networking and Telecommunications,
  2008 (ANTS 2008) Conference (http://www.antsconference.org) held at Indian
  Institute of Technology, Mumbai. Awarded Best Paper (Honorable Mention)</comments><acm-class>C.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Minimizing handoff latency and achieving near-zero packet loss is critical
for delivering multimedia infotainment applications to fast-moving vehicles
that are likely to encounter frequent handoffs. In this paper, we propose a
dual-radio cross-layer handoff scheme for infrastructure-mode 802.11 Wireless
Networks that achieve this goal. We present performance results of an
implementation of our algorithm in a Linux-based On-Board-Unit prototype.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4643</identifier>
 <datestamp>2012-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4643</id><created>2009-01-29</created><updated>2009-12-27</updated><authors><author><keyname>Grossu</keyname><forenames>I. V.</forenames></author><author><keyname>Besliu</keyname><forenames>C.</forenames></author><author><keyname>Rusu</keyname><forenames>M. V.</forenames></author><author><keyname>Jipa</keyname><forenames>Al.</forenames></author><author><keyname>Bordeianu</keyname><forenames>C. C.</forenames></author><author><keyname>Felea</keyname><forenames>D.</forenames></author><author><keyname>Stan</keyname><forenames>E.</forenames></author><author><keyname>Esanu</keyname><forenames>T.</forenames></author></authors><title>Visual tool for estimating the fractal dimension of images</title><categories>physics.comp-ph cs.GR nlin.PS</categories><comments>A new version was accepted to Computer Physics Communications
  doi:10.1016/j.cpc.2009.12.005</comments><journal-ref>Computer Physics Communications 180 (2009) p.1999-2001; CPC,
  Volume 181, Issue 4, April 2010, Pages 831-832</journal-ref><doi>10.1016/j.cpc.2009.05.015</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work presents a new Visual Basic 6.0 application for estimating the
fractal dimension of images, based on an optimized version of the box-counting
algorithm. Following the attempt to separate the real information from noise,
we considered also the family of all band-pass filters with the same band-width
(specified as parameter). The fractal dimension can be thus represented as a
function of the pixel color code. The program was used for the study of
paintings cracks, as an additional tool which can help the critic to decide if
an artistic work is original or not. In its second version, the application was
extended for working also with csv files and three-dimensional images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4646</identifier>
 <datestamp>2009-01-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4646</id><created>2009-01-29</created><authors><author><keyname>Khan</keyname><forenames>Muhammad Mubashir</forenames></author><author><keyname>Hyder</keyname><forenames>Salahuddin</forenames></author><author><keyname>Pathan</keyname><forenames>Mahmood K</forenames></author><author><keyname>Sheikh</keyname><forenames>Kashif H</forenames></author></authors><title>A Quantum Key Distribution Network Through Single Mode Optical Fiber</title><categories>cs.CR</categories><comments>This paper has been submitted to the 2006 International Symposium on
  Collaborative Technologies and Systems (CTS 2006)May 14-17, 2006, Las Vegas,
  Nevada, USA</comments><journal-ref>Khan, M.M., et al., A Quantum Key Distribution Network through
  Single Mode Optical Fiber. Proceedings of the International Symposium on
  Collaborative Technologies and Systems, 2006: p. 386-391</journal-ref><doi>10.1109/CTS.2006.10</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantum key distribution (QKD) has been developed within the last decade that
is provably secure against arbitrary computing power, and even against quantum
computer attacks. Now there is a strong need of research to exploit this
technology in the existing communication networks. In this paper we have
presented various experimental results pertaining to QKD like Raw key rate and
Quantum bit error rate (QBER). We found these results over 25 km single mode
optical fiber. The experimental setup implemented the enhanced version of BB84
QKD protocol. Based upon the results obtained, we have presented a network
design which can be implemented for the realization of large scale QKD
networks. Furthermore, several new ideas are presented and discussed to
integrate the QKD technique in the classical communication networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4648</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4648</id><created>2009-01-29</created><authors><author><keyname>Haddadi</keyname><forenames>Farzan</forenames></author><author><keyname>Nayebi</keyname><forenames>Mohammad Mahdi</forenames></author><author><keyname>Aref</keyname><forenames>Mohammad Reza</forenames></author></authors><title>On The Positive Definiteness of Polarity Coincidence Correlation
  Coefficient Matrix</title><categories>cs.IT math.IT</categories><comments>IEEE Signal Processing Letters, Volume 15, pp. 73-76, 2008</comments><doi>10.1109/LSP.2007.911193</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Polarity coincidence correlator (PCC), when used to estimate the covariance
matrix on an element-by-element basis, may not yield a positive semi-definite
(PSD) estimate. Devlin et al. [1], claimed that element-wise PCC is not
guaranteed to be PSD in dimensions p&gt;3 for real signals. However, no
justification or proof was available on this issue. In this letter, it is
proved that for real signals with p&lt;=3 and for complex signals with p&lt;=2, a PSD
estimate is guaranteed. Counterexamples are presented for higher dimensions
which yield invalid covariance estimates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4664</identifier>
 <datestamp>2009-01-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4664</id><created>2009-01-29</created><authors><author><keyname>Bergstra</keyname><forenames>Jan A.</forenames></author><author><keyname>Bethke</keyname><forenames>I.</forenames></author></authors><title>Square root meadows</title><categories>cs.LO</categories><comments>9 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let Q_0 denote the rational numbers expanded to a meadow by totalizing
inversion such that 0^{-1}=0. Q_0 can be expanded by a total sign function s
that extracts the sign of a rational number. In this paper we discuss an
extension Q_0(s ,\sqrt) of the signed rationals in which every number has a
unique square root.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4694</identifier>
 <datestamp>2009-01-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4694</id><created>2009-01-29</created><authors><author><keyname>Chee</keyname><forenames>Yeow Meng</forenames></author><author><keyname>Ling</keyname><forenames>Alan C. H.</forenames></author></authors><title>Limit on the Addressability of Fault-Tolerant Nanowire Decoders</title><categories>cs.AR cs.DM cs.IT math.IT</categories><comments>9 pages, 4 figures</comments><journal-ref>IEEE Transactions on Computers, vol. 58, no. 1, pp. 60-68, 2009</journal-ref><doi>10.1109/TC.2008.130</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although prone to fabrication error, the nanowire crossbar is a promising
candidate component for next generation nanometer-scale circuits. In the
nanowire crossbar architecture, nanowires are addressed by controlling voltages
on the mesowires. For area efficiency, we are interested in the maximum number
of nanowires $N(m,e)$ that can be addressed by $m$ mesowires, in the face of up
to $e$ fabrication errors. Asymptotically tight bounds on $N(m,e)$ are
established in this paper. In particular, it is shown that $N(m,e) = \Theta(2^m
/ m^{e+1/2})$. Interesting observations are made on the equivalence between
this problem and the problem of constructing optimal EC/AUED codes,
superimposed distance codes, pooling designs, and diffbounded set systems.
Results in this paper also improve upon those in the EC/AUEC codes literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4723</identifier>
 <datestamp>2009-01-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4723</id><created>2009-01-29</created><authors><author><keyname>Barri&#xe8;re</keyname><forenames>Paul-Andr&#xe9;</forenames></author><author><keyname>Idier</keyname><forenames>J&#xe9;r&#xf4;me</forenames></author><author><keyname>Goussard</keyname><forenames>Yves</forenames></author><author><keyname>Laurin</keyname><forenames>Jean-Jacques</forenames></author></authors><title>On Algorithms Based on Joint Estimation of Currents and Contrast in
  Microwave Tomography</title><categories>math.NA cs.IT math.IT</categories><comments>12 pages, 12 figures, 5 tables</comments><msc-class>45Q05; 62G05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with improvements to the contrast source inversion method
which is widely used in microwave tomography. First, the method is reviewed and
weaknesses of both the criterion form and the optimization strategy are
underlined. Then, two new algorithms are proposed. Both of them are based on
the same criterion, similar but more robust than the one used in contrast
source inversion. The first technique keeps the main characteristics of the
contrast source inversion optimization scheme but is based on a better
exploitation of the conjugate gradient algorithm. The second technique is based
on a preconditioned conjugate gradient algorithm and performs simultaneous
updates of sets of unknowns that are normally processed sequentially. Both
techniques are shown to be more efficient than original contrast source
inversion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4727</identifier>
 <datestamp>2009-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4727</id><created>2009-01-29</created><updated>2009-10-05</updated><authors><author><keyname>Mossel</keyname><forenames>Elchanan</forenames></author></authors><title>Arrow's Impossibility Theorem Without Unanimity</title><categories>cs.GT cs.DM</categories><comments>Most of the new results in the Arxiv sumbission now appear in a
  follow up paper on quantitative Arrow's theorem</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Arrow's Impossibility Theorem states that any constitution which satisfies
Transitivity, Independence of Irrelevant Alternatives (IIA) and Unanimity is a
dictatorship. Wilson derived properties of constitutions satisfying
Transitivity and IIA for unrestricted domains where ties are allowed. In this
paper we consider the case where only strict preferences are allowed. In this
case we derive a new short proof of Arrow theorem and further obtain a new and
complete characterization of all functions satisfying Transitivity and IIA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4728</identifier>
 <datestamp>2009-01-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4728</id><created>2009-01-29</created><authors><author><keyname>Berwanger</keyname><forenames>Dietmar</forenames></author><author><keyname>Chatterjee</keyname><forenames>Krishnendu</forenames></author><author><keyname>De Wulf</keyname><forenames>Martin</forenames></author><author><keyname>Doyen</keyname><forenames>Laurent</forenames></author><author><keyname>Henzinger</keyname><forenames>Thomas A.</forenames></author></authors><title>Alpaga: A Tool for Solving Parity Games with Imperfect Information</title><categories>cs.GT cs.LO</categories><comments>11 pages, a shorter version to appear in TACAS 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Alpaga is a solver for two-player parity games with imperfect information.
Given the description of a game, it determines whether the first player can
ensure to win and, if so, it constructs a winning strategy. The tool provides a
symbolic implementation of a recent algorithm based on antichains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4747</identifier>
 <datestamp>2009-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4747</id><created>2009-01-29</created><updated>2009-05-18</updated><authors><author><keyname>Dumas</keyname><forenames>Jean-Guillaume</forenames><affiliation>LJK</affiliation></author><author><keyname>Pernet</keyname><forenames>Cl&#xe9;ment</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes / LIG Laboratoire d'Informatique de Grenoble</affiliation></author><author><keyname>Saunders</keyname><forenames>B. David</forenames><affiliation>CIS</affiliation></author></authors><title>On finding multiplicities of characteristic polynomial factors of
  black-box matrices</title><categories>cs.SC</categories><proxy>ccsd hal-00357262</proxy><journal-ref>(International Symposium on Symbolic and Algebraic Computation
  2009), S\'eoul : Cor\'ee, R\'epublique de (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present algorithms and heuristics to compute the characteristic polynomial
of a matrix given its minimal polynomial. The matrix is represented as a
black-box, i.e., by a function to compute its matrix-vector product. The
methods apply to matrices either over the integers or over a large enough
finite field. Experiments show that these methods perform efficiently in
practice. Combined in an adaptive strategy, these algorithms reach significant
speedups in practice for some integer matrices arising in an application from
graph theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4754</identifier>
 <datestamp>2009-01-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4754</id><created>2009-01-29</created><authors><author><keyname>Albasini</keyname><forenames>L. de Francesco</forenames></author><author><keyname>Sabadini</keyname><forenames>N.</forenames></author><author><keyname>Walters</keyname><forenames>R. F. C.</forenames></author></authors><title>An algebra of automata which includes both classical and quantum
  entities</title><categories>cs.LO math.CT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe an algebra for composing automata which includes both classical
and quantum entities and their communications. We illustrate by describing in
detail a quantum protocol.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4761</identifier>
 <datestamp>2009-01-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4761</id><created>2009-01-29</created><authors><author><keyname>Fournier-Viger</keyname><forenames>P.</forenames></author><author><keyname>Nkambou</keyname><forenames>R.</forenames></author><author><keyname>Nguifo</keyname><forenames>E. Mephu</forenames></author></authors><title>A Knowledge Discovery Framework for Learning Task Models from User
  Interactions in Intelligent Tutoring Systems</title><categories>cs.AI</categories><comments>Proceedings of the 7th Mexican International Conference on Artificial
  Intelligence (MICAI 2008), Springer, pp. 765-778</comments><doi>10.1007/978-3-540-88636-5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Domain experts should provide relevant domain knowledge to an Intelligent
Tutoring System (ITS) so that it can guide a learner during problemsolving
learning activities. However, for many ill-defined domains, the domain
knowledge is hard to define explicitly. In previous works, we showed how
sequential pattern mining can be used to extract a partial problem space from
logged user interactions, and how it can support tutoring services during
problem-solving exercises. This article describes an extension of this approach
to extract a problem space that is richer and more adapted for supporting
tutoring services. We combined sequential pattern mining with (1) dimensional
pattern mining (2) time intervals, (3) the automatic clustering of valued
actions and (4) closed sequences mining. Some tutoring services have been
implemented and an experiment has been conducted in a tutoring system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4762</identifier>
 <datestamp>2009-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4762</id><created>2009-01-29</created><authors><author><keyname>Barker</keyname><forenames>Adam</forenames></author></authors><title>Optimizing Service Orchestrations</title><categories>cs.DC cs.SE</categories><comments>12 pages, 13 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As the number of services and the size of data involved in workflows
increases, centralised orchestration techniques are reaching the limits of
scalability. In the classic orchestration model, all data passes through a
centralised engine, which results in unnecessary data transfer, wasted
bandwidth and the engine to become a bottleneck to the execution of a workflow.
  This paper presents and evaluates the Circulate architecture which maintains
the robustness and simplicity of centralised orchestration, but facilitates
choreography by allowing services to exchange data directly with one another.
Circulate could be realised within any existing workflow framework, in this
paper, we focus on WS-Circulate, a Web services based implementation.
  Taking inspiration from the Montage workflow, a number of common workflow
patterns (sequence, fan-in and fan-out), input to output data size
relationships and network configurations are identified and evaluated. The
performance analysis concludes that a substantial reduction in communication
overhead results in a 2-4 fold performance benefit across all patterns. An
end-to-end pattern through the Montage workflow results in an 8 fold
performance benefit and demonstrates how the advantage of using the Circulate
architecture increases as the complexity of a workflow grows.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4784</identifier>
 <datestamp>2013-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4784</id><created>2009-01-29</created><authors><author><keyname>Guerrero</keyname><forenames>Fabio G.</forenames></author></authors><title>On the Entropy of Written Spanish</title><categories>cs.CL cs.IT math.IT</categories><comments>Submitted to the IEEE Transactions on Information Theory</comments><journal-ref>Revista Colombiana de Estadistica (RCE), Vol. 35, No. 3, Dec.
  2012, pp 423-440</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper reports on results on the entropy of the Spanish language. They
are based on an analysis of natural language for n-word symbols (n = 1 to 18),
trigrams, digrams, and characters. The results obtained in this work are based
on the analysis of twelve different literary works in Spanish, as well as a
279917 word news file provided by the Spanish press agency EFE. Entropy values
are calculated by a direct method using computer processing and the probability
law of large numbers. Three samples of artificial Spanish language produced by
a first-order model software source are also analyzed and compared with natural
Spanish language.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4798</identifier>
 <datestamp>2010-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4798</id><created>2009-01-29</created><updated>2009-02-18</updated><authors><author><keyname>Parakh</keyname><forenames>Abhishek</forenames></author><author><keyname>Kak</keyname><forenames>Subhash</forenames></author></authors><title>Space Efficient Secret Sharing</title><categories>cs.CR</categories><comments>5 pages; with corrections</comments><journal-ref>4th Annual Computer Science Research Conference at the University
  of Oklahoma, April 18, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This note proposes a method of space efficient secret sharing in which k
secrets are mapped into n shares (n&gt;=k) of the same size. Since, n can be
chosen to be equal to k, the method is space efficient. This method may be
compared with conventional secret sharing schemes that divide a single secret
into n shares.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4814</identifier>
 <datestamp>2010-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4814</id><created>2009-01-29</created><authors><author><keyname>Parakh</keyname><forenames>Abhishek</forenames></author><author><keyname>Kak</keyname><forenames>Subhash</forenames></author></authors><title>Space Efficient Secret Sharing: A Recursive Approach</title><categories>cs.CR</categories><comments>8 pages</comments><report-no>Cryptology ePrint Archive: Report 2009/365</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a recursive secret sharing technique that distributes k-1
secrets of length b each into n shares such that each share is effectively of
length (n/(k-1))*b and any k pieces suffice for reconstructing all the k-1
secrets. Since n/(k-1) is near the optimal factor of n/k, and can be chosen to
be close to 1, the proposed technique is space efficient. Furthermore, each
share is information theoretically secure, i.e. it does not depend on any
unproven assumption of computational intractability. Such a recursive technique
has potential applications in secure and reliable storage of information on the
Web and in sensor networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4830</identifier>
 <datestamp>2009-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4830</id><created>2009-01-30</created><authors><author><keyname>Zhang</keyname><forenames>Lan</forenames></author><author><keyname>Zhang</keyname><forenames>Rui</forenames></author><author><keyname>Liang</keyname><forenames>Ying-Chang</forenames></author><author><keyname>Xin</keyname><forenames>Yan</forenames></author><author><keyname>Cui</keyname><forenames>Shuguang</forenames></author></authors><title>On the Relationship Between the Multi-antenna Secrecy Communications and
  Cognitive Radio Communications</title><categories>cs.IT math.IT</categories><comments>26 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the capacity of the multi-antenna or multiple-input
multiple-output (MIMO) secrecy channels with multiple eavesdroppers having
single/multiple antennas. It is known that the MIMO secrecy capacity is
achievable with the optimal transmit covariance matrix that maximizes the
minimum difference between the channel mutual information of the secrecy user
and those of the eavesdroppers. The MIMO secrecy capacity computation can thus
be formulated as a non-convex max-min problem, which cannot be solved
efficiently by standard convex optimization techniques. To handle this
difficulty, we explore a relationship between the MIMO secrecy channel and the
recently developed MIMO cognitive radio (CR) channel, in which the
multi-antenna secondary user transmits over the same spectrum simultaneously
with multiple primary users, subject to the received interference power
constraints at the primary users, or the so-called ``interference temperature
(IT)'' constraints. By constructing an auxiliary CR MIMO channel that has the
same channel responses as the MIMO secrecy channel, we prove that the optimal
transmit covariance matrix to achieve the secrecy capacity is the same as that
to achieve the CR spectrum sharing capacity with properly selected IT
constraints. Based on this relationship, several algorithms are proposed to
solve the non-convex secrecy capacity computation problem by transforming it
into a sequence of CR spectrum sharing capacity computation problems that are
convex. For the case with single-antenna eavesdroppers, the proposed algorithms
obtain the exact capacity of the MIMO secrecy channel, while for the case with
multi-antenna eavesdroppers, the proposed algorithms obtain both upper and
lower bounds on the MIMO secrecy capacity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4835</identifier>
 <datestamp>2010-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4835</id><created>2009-01-30</created><updated>2010-02-09</updated><authors><author><keyname>Chung</keyname><forenames>Yoo</forenames></author><author><keyname>Lee</keyname><forenames>Dongman</forenames></author></authors><title>A Mathematical Basis for the Chaining of Lossy Interface Adapters</title><categories>cs.DM cs.DC cs.SE</categories><comments>22 pages, 6 figures</comments><acm-class>D.2.12; F.2.2</acm-class><journal-ref>IET Software, 4(1):54-54, February 2010</journal-ref><doi>10.1049/iet-sen.2009.0019</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite providing similar functionality, multiple network services may
require the use of different interfaces to access the functionality, and this
problem will only get worse with the widespread deployment of ubiquitous
computing environments. One way around this problem is to use interface
adapters that adapt one interface into another. Chaining these adapters allows
flexible interface adaptation with fewer adapters, but the loss incurred due to
imperfect interface adaptation must be considered. This paper outlines a
mathematical basis for analyzing the chaining of lossy interface adapters. We
also show that the problem of finding an optimal interface adapter chain is
NP-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4846</identifier>
 <datestamp>2009-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4846</id><created>2009-01-30</created><updated>2009-06-20</updated><authors><author><keyname>Azzana</keyname><forenames>Youssef</forenames><affiliation>EI</affiliation></author><author><keyname>Chabchoub</keyname><forenames>Yousra</forenames><affiliation>INRIA</affiliation></author><author><keyname>Fricker</keyname><forenames>Christine</forenames><affiliation>FT R&amp;D</affiliation></author><author><keyname>Guillemin</keyname><forenames>Fabrice</forenames><affiliation>FT R&amp;D</affiliation></author><author><keyname>Robert</keyname><forenames>Philippe</forenames></author></authors><title>Adaptive algorithms for identifying large flows in IP traffic</title><categories>cs.NI</categories><proxy>ccsd inria-00357343</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose in this paper an on-line algorithm based on Bloom filters for
identifying large flows in IP traffic (a.k.a. elephants). Because of the large
number of small flows, hash tables of these algorithms have to be regularly
refreshed. Recognizing that the periodic erasure scheme usually used in the
technical literature turns out to be quite inefficient when using real traffic
traces over a long period of time, we introduce a simple adaptive scheme that
closely follows the variations of traffic. When tested against real traffic
traces, the proposed on-line algorithm performs well in the sense that the
detection ratio of long flows by the algorithm over a long time period is quite
high. Beyond the identification of elephants, this same class of algorithms is
applied to the closely related problem of detection of anomalies in IP traffic,
e.g., SYN flood due for instance to attacks. An algorithm for detecting SYN and
volume flood anomalies in Internet traffic is designed. Experiments show that
an anomaly is detected in less than one minute and the targeted destinations
are identified at the same time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4876</identifier>
 <datestamp>2009-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4876</id><created>2009-01-30</created><authors><author><keyname>Blockeel</keyname><forenames>Hendrik</forenames></author><author><keyname>Brijder</keyname><forenames>Robert</forenames></author></authors><title>Non-Confluent NLC Graph Grammar Inference by Compressing Disjoint
  Subgraphs</title><categories>cs.LG cs.DM</categories><comments>12 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Grammar inference deals with determining (preferable simple) models/grammars
consistent with a set of observations. There is a large body of research on
grammar inference within the theory of formal languages. However, there is
surprisingly little known on grammar inference for graph grammars. In this
paper we take a further step in this direction and work within the framework of
node label controlled (NLC) graph grammars. Specifically, we characterize,
given a set of disjoint and isomorphic subgraphs of a graph $G$, whether or not
there is a NLC graph grammar rule which can generate these subgraphs to obtain
$G$. This generalizes previous results by assuming that the set of isomorphic
subgraphs is disjoint instead of non-touching. This leads naturally to consider
the more involved ``non-confluent'' graph grammar rules.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4898</identifier>
 <datestamp>2009-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4898</id><created>2009-01-30</created><authors><author><keyname>Barros</keyname><forenames>Joao</forenames></author><author><keyname>Costa</keyname><forenames>Rui A.</forenames></author><author><keyname>Munaretto</keyname><forenames>Daniele</forenames></author><author><keyname>Widmer</keyname><forenames>Joerg</forenames></author></authors><title>Effective Delay Control in Online Network Coding</title><categories>cs.IT math.IT</categories><comments>9 pages, IEEE Infocom 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by streaming applications with stringent delay constraints, we
consider the design of online network coding algorithms with timely delivery
guarantees. Assuming that the sender is providing the same data to multiple
receivers over independent packet erasure channels, we focus on the case of
perfect feedback and heterogeneous erasure probabilities. Based on a general
analytical framework for evaluating the decoding delay, we show that existing
ARQ schemes fail to ensure that receivers with weak channels are able to
recover from packet losses within reasonable time. To overcome this problem, we
re-define the encoding rules in order to break the chains of linear
combinations that cannot be decoded after one of the packets is lost. Our
results show that sending uncoded packets at key times ensures that all the
receivers are able to meet specific delay requirements with very high
probability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4904</identifier>
 <datestamp>2014-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4904</id><created>2009-01-30</created><updated>2014-04-13</updated><authors><author><keyname>Nair</keyname><forenames>Rajiv</forenames></author><author><keyname>Nagarjuna</keyname><forenames>G.</forenames></author><author><keyname>Ray</keyname><forenames>Arnab K.</forenames></author></authors><title>Finite-size effects in the dependency networks of free and open-source
  software</title><categories>cs.OH physics.soc-ph</categories><comments>ReVTeX, 9 pages, 7 figures. Major revisions in Sections III and IV of
  this version. The bibliography has been updated</comments><journal-ref>Complex Systems, 23, 71, 2014</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a continuum model for the degree distribution of directed networks
in free and open-source software. The degree distributions of links in both the
in-directed and out-directed dependency networks follow Zipf's law for the
intermediate nodes, but the heavily linked nodes and the poorly linked nodes
deviate from this trend and exhibit finite-size effects. The finite-size
parameters make a quantitative distinction between the in-directed and
out-directed networks. For the out-degree distribution, the initial condition
for a dynamic evolution corresponds to the limiting count of the most heavily
liked nodes that the out-directed network can finally have. The number of nodes
contributing out-directed links grows with every generation of software
release, but this growth ultimately saturates towards a terminal value due to
the finiteness of semantic possibilities in the network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4934</identifier>
 <datestamp>2010-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4934</id><created>2009-01-30</created><updated>2010-10-04</updated><authors><author><keyname>Hewitt</keyname><forenames>Carl</forenames></author></authors><title>A historical perspective on developing foundations iInfo(TM) information
  systems: iConsult(TM) and iEntertain(TM) apps using iDescribers(TM)
  information integration for iOrgs(TM) information systems</title><categories>cs.DC cs.DB cs.LO</categories><comments>updated title and abstract</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Technology now at hand can integrate all kinds of digital information for
individuals, groups, and organizations so their information usefully links
together. iInfo(TM) information integration works by making connections
including examples like the following:
  - A statistical connection between &quot;being in a traffic jam&quot; and &quot;driving in
downtown Trenton between 5PM and 6PM on a weekday.&quot;
  - A terminological connection between &quot;MSR&quot; and &quot;Microsoft Research.&quot;
  - A causal connection between &quot;joining a group&quot; and &quot;being a member of the
group.&quot;
  - A syntactic connection between &quot;a pin dropped&quot; and &quot;a dropped pin.&quot;
  - A biological connection between &quot;a dolphin&quot; and &quot;a mammal&quot;.
  - A demographic connection between &quot;undocumented residents of California&quot; and
&quot;7% of the population of California.&quot;
  - A geographical connection between &quot;Leeds&quot; and &quot;England.&quot;
  - A temporal connection between &quot;turning on a computer&quot; and &quot;joining an
on-line discussion.&quot;
  By making these connections, iInfo offers tremendous value for individuals,
families, groups, and organizations in making more effective use of information
technology.
  In practice, integrated information is invariably pervasively inconsistent.
Therefore iInfo must be able to make connections even in the face of
inconsistency. The business of iInfo is not to make difficult decisions like
deciding the ultimate truth or probability of propositions. Instead it provides
means for processing information and carefully recording its provenance
including arguments (including arguments about arguments) for and against
propositions that is used by iConsult(TM) and iEntertain(TM) apps in iOrgs(TM)
Information Systems.
  A historical perspective on the above questions is highly pertinent to the
current quest to develop foundations for privacy-friendly client-cloud
computing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4953</identifier>
 <datestamp>2009-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4953</id><created>2009-01-30</created><authors><author><keyname>Hashimoto</keyname><forenames>Marcelo</forenames></author><author><keyname>Cesar</keyname><forenames>Roberto M.</forenames><suffix>Jr</suffix></author></authors><title>A Keygraph Classification Framework for Real-Time Object Detection</title><categories>cs.CV</categories><comments>9 pages, 23 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a new approach for keypoint-based object detection.
Traditional keypoint-based methods consist in classifying individual points and
using pose estimation to discard misclassifications. Since a single point
carries no relational features, such methods inherently restrict the usage of
structural information to the pose estimation phase. Therefore, the classifier
considers purely appearance-based feature vectors, thus requiring
computationally expensive feature extraction or complex probabilistic modelling
to achieve satisfactory robustness. In contrast, our approach consists in
classifying graphs of keypoints, which incorporates structural information
during the classification phase and allows the extraction of simpler feature
vectors that are naturally robust. In the present work, 3-vertices graphs have
been considered, though the methodology is general and larger order graphs may
be adopted. Successful experimental results obtained for real-time object
detection in video sequences are reported.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4963</identifier>
 <datestamp>2009-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4963</id><created>2009-01-30</created><authors><author><keyname>Faghihi</keyname><forenames>Usef</forenames></author><author><keyname>Fournier-Viger</keyname><forenames>Philippe</forenames></author><author><keyname>Nkambou</keyname><forenames>Roger</forenames></author><author><keyname>Poirier</keyname><forenames>Pierre</forenames></author><author><keyname>Mayers</keyname><forenames>Andre</forenames></author></authors><title>How Emotional Mechanism Helps Episodic Learning in a Cognitive Agent</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose the CTS (Concious Tutoring System) technology, a
biologically plausible cognitive agent based on human brain functions.This
agent is capable of learning and remembering events and any related information
such as corresponding procedures, stimuli and their emotional valences. Our
proposed episodic memory and episodic learning mechanism are closer to the
current multiple-trace theory in neuroscience, because they are inspired by it
[5] contrary to other mechanisms that are incorporated in cognitive agents.
This is because in our model emotions play a role in the encoding and
remembering of events. This allows the agent to improve its behavior by
remembering previously selected behaviors which are influenced by its emotional
mechanism. Moreover, the architecture incorporates a realistic memory
consolidation process based on a data mining algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0019</identifier>
 <datestamp>2009-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0019</id><created>2009-01-30</created><authors><author><keyname>Beyer</keyname><forenames>Dirk</forenames></author><author><keyname>Keremoglu</keyname><forenames>M. Erkan</forenames></author></authors><title>CPAchecker: A Tool for Configurable Software Verification</title><categories>cs.PL cs.SE</categories><comments>8 pages (6 without cover), 2 figures, 2 tables, tool paper, Web page:
  http://www.cs.sfu.ca/~dbeyer/CPAchecker</comments><report-no>SFU-CS-2009-02</report-no><acm-class>D.2.4; F.3.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Configurable software verification is a recent concept for expressing
different program analysis and model checking approaches in one single
formalism. This paper presents CPAchecker, a tool and framework that aims at
easy integration of new verification components. Every abstract domain,
together with the corresponding operations, is required to implement the
interface of configurable program analysis (CPA). The main algorithm is
configurable to perform a reachability analysis on arbitrary combinations of
existing CPAs. The major design goal during the development was to provide a
framework for developers that is flexible and easy to extend. We hope that
researchers find it convenient and productive to implement new verification
ideas and algorithms using this platform and that it advances the field by
making it easier to perform practical experiments. The tool is implemented in
Java and runs as command-line tool or as Eclipse plug-in. We evaluate the
efficiency of our tool on benchmarks from the software model checker BLAST. The
first released version of CPAchecker implements CPAs for predicate abstraction,
octagon, and explicit-value domains. Binaries and the source code of CPAchecker
are publicly available as free software.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0026</identifier>
 <datestamp>2014-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0026</id><created>2009-01-31</created><updated>2009-09-21</updated><authors><author><keyname>Tropp</keyname><forenames>Joel A.</forenames></author><author><keyname>Laska</keyname><forenames>Jason N.</forenames></author><author><keyname>Duarte</keyname><forenames>Marco F.</forenames></author><author><keyname>Romberg</keyname><forenames>Justin K.</forenames></author><author><keyname>Baraniuk</keyname><forenames>Richard G.</forenames></author></authors><title>Beyond Nyquist: Efficient Sampling of Sparse Bandlimited Signals</title><categories>cs.IT math.IT</categories><comments>24 pages, 8 figures</comments><journal-ref>IEEE Trans. Inform. Theory, Vol.56, num. 1, pp. 520-544, Jan. 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wideband analog signals push contemporary analog-to-digital conversion
systems to their performance limits. In many applications, however, sampling at
the Nyquist rate is inefficient because the signals of interest contain only a
small number of significant frequencies relative to the bandlimit, although the
locations of the frequencies may not be known a priori. For this type of sparse
signal, other sampling strategies are possible. This paper describes a new type
of data acquisition system, called a random demodulator, that is constructed
from robust, readily available components. Let K denote the total number of
frequencies in the signal, and let W denote its bandlimit in Hz. Simulations
suggest that the random demodulator requires just O(K log(W/K)) samples per
second to stably reconstruct the signal. This sampling rate is exponentially
lower than the Nyquist rate of W Hz. In contrast with Nyquist sampling, one
must use nonlinear methods, such as convex programming, to recover the signal
from the samples taken by the random demodulator. This paper provides a
detailed theoretical analysis of the system's performance that supports the
empirical observations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0043</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0043</id><created>2009-01-30</created><updated>2009-03-02</updated><authors><author><keyname>Benzmueller</keyname><forenames>Christoph</forenames></author><author><keyname>Brown</keyname><forenames>Chad E.</forenames></author><author><keyname>Kohlhase</keyname><forenames>Michael</forenames></author></authors><title>Cut-Simulation and Impredicativity</title><categories>cs.LO cs.AI</categories><comments>21 pages</comments><acm-class>F.4.1; I.2.3</acm-class><journal-ref>Logical Methods in Computer Science, Volume 5, Issue 1 (March 3,
  2009) lmcs:1144</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate cut-elimination and cut-simulation in impredicative
(higher-order) logics. We illustrate that adding simple axioms such as Leibniz
equations to a calculus for an impredicative logic -- in our case a sequent
calculus for classical type theory -- is like adding cut. The phenomenon
equally applies to prominent axioms like Boolean- and functional
extensionality, induction, choice, and description. This calls for the
development of calculi where these principles are built-in instead of being
treated axiomatically.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0047</identifier>
 <datestamp>2009-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0047</id><created>2009-01-30</created><authors><author><keyname>Amano</keyname><forenames>Kazuyuki</forenames></author></authors><title>Bounds on the Size of Small Depth Circuits for Approximating Majority</title><categories>cs.CC</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we show that for every constant $0 &lt; \epsilon &lt; 1/2$ and for
every constant $d \geq 2$, the minimum size of a depth $d$ Boolean circuit that
$\epsilon$-approximates Majority function on $n$ variables is
exp$(\Theta(n^{1/(2d-2)}))$. The lower bound for every $d \geq 2$ and the upper
bound for $d=2$ have been previously shown by O'Donnell and Wimmer [ICALP'07],
and the contribution of this paper is to give a matching upper bound for $d
\geq 3$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0056</identifier>
 <datestamp>2009-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0056</id><created>2009-01-31</created><authors><author><keyname>Okunoye</keyname><forenames>O. Babatunde</forenames></author></authors><title>An Alternative Cracking of The Genetic Code</title><categories>cs.OH</categories><comments>31 pages, 23 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We Propose 22 unique Solutions to the Genetic Code. An Alternative Cracking,
from the Perspective of a Mathematician.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0058</identifier>
 <datestamp>2009-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0058</id><created>2009-02-01</created><updated>2009-06-30</updated><authors><author><keyname>Rolland</keyname><forenames>Robert</forenames></author></authors><title>The second weight of generalized Reed-Muller codes in most cases</title><categories>cs.IT math.IT</categories><comments>This version corrects minor misprints and gives a more detailed proof
  of a combinatorial lemma</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The second weight of the Generalized Reed-Muller code of order $d$ over the
finite field with $q$ elements is now known for $d &lt;q$ and $d&gt;(n-1)(q-1)$. In
this paper, we determine the second weight for the other values of $d$ which
are not multiple of $q-1$ plus 1. For the special case $d=a(q-1)+1$ we give an
estimate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0084</identifier>
 <datestamp>2009-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0084</id><created>2009-02-02</created><updated>2009-05-25</updated><authors><author><keyname>Miled</keyname><forenames>Abdelwaheb</forenames></author></authors><title>On a problem of Frobenius in three numbers</title><categories>cs.DM</categories><comments>5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For three positive integers ai, aj, ak pairwise coprime, we present an
algorithm that find the least multiple of ai that is a positive linear
combination of aj, ak. The average running time of this algorithm is O(1).
Using this algorithm and the chinese remainder theorem leads to a direct
computation of the Frobenius number f(a1, a2, a3).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0101</identifier>
 <datestamp>2010-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0101</id><created>2009-02-02</created><updated>2009-04-10</updated><authors><author><keyname>Ummels</keyname><forenames>Michael</forenames></author><author><keyname>Wojtczak</keyname><forenames>Dominik</forenames></author></authors><title>The Complexity of Nash Equilibria in Simple Stochastic Multiplayer Games</title><categories>cs.GT cs.CC cs.LO</categories><comments>23 pages; revised version</comments><report-no>EDI-INF-RR-1323</report-no><doi>10.1007/978-3-642-02930-1_25</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyse the computational complexity of finding Nash equilibria in simple
stochastic multiplayer games. We show that restricting the search space to
equilibria whose payoffs fall into a certain interval may lead to
undecidability. In particular, we prove that the following problem is
undecidable: Given a game G, does there exist a pure-strategy Nash equilibrium
of G where player 0 wins with probability 1. Moreover, this problem remains
undecidable if it is restricted to strategies with (unbounded) finite memory.
However, if mixed strategies are allowed, decidability remains an open problem.
One way to obtain a provably decidable variant of the problem is restricting
the strategies to be positional or stationary. For the complexity of these two
problems, we obtain a common lower bound of NP and upper bounds of NP and
PSPACE respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0133</identifier>
 <datestamp>2009-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0133</id><created>2009-02-01</created><authors><author><keyname>Gagie</keyname><forenames>Travis</forenames></author></authors><title>New Algorithms and Lower Bounds for Sequential-Access Data Compression</title><categories>cs.IT math.IT</categories><comments>draft of PhD thesis</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This thesis concerns sequential-access data compression, i.e., by algorithms
that read the input one or more times from beginning to end. In one chapter we
consider adaptive prefix coding, for which we must read the input character by
character, outputting each character's self-delimiting codeword before reading
the next one. We show how to encode and decode each character in constant
worst-case time while producing an encoding whose length is worst-case optimal.
In another chapter we consider one-pass compression with memory bounded in
terms of the alphabet size and context length, and prove a nearly tight
tradeoff between the amount of memory we can use and the quality of the
compression we can achieve. In a third chapter we consider compression in the
read/write streams model, which allows us passes and memory both
polylogarithmic in the size of the input. We first show how to achieve
universal compression using only one pass over one stream. We then show that
one stream is not sufficient for achieving good grammar-based compression.
Finally, we show that two streams are necessary and sufficient for achieving
entropy-only bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0140</identifier>
 <datestamp>2009-05-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0140</id><created>2009-02-01</created><updated>2009-05-05</updated><authors><author><keyname>Ahn</keyname><forenames>Kook Jin</forenames></author><author><keyname>Guha</keyname><forenames>Sudipto</forenames></author></authors><title>Graph Sparsification in the Semi-streaming Model</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Analyzing massive data sets has been one of the key motivations for studying
streaming algorithms. In recent years, there has been significant progress in
analysing distributions in a streaming setting, but the progress on graph
problems has been limited. A main reason for this has been the existence of
linear space lower bounds for even simple problems such as determining the
connectedness of a graph. However, in many new scenarios that arise from social
and other interaction networks, the number of vertices is significantly less
than the number of edges. This has led to the formulation of the semi-streaming
model where we assume that the space is (near) linear in the number of vertices
(but not necessarily the edges), and the edges appear in an arbitrary (and
possibly adversarial) order.
  In this paper we focus on graph sparsification, which is one of the major
building blocks in a variety of graph algorithms. There has been a long history
of (non-streaming) sampling algorithms that provide sparse graph approximations
and it a natural question to ask if the sparsification can be achieved using a
small space, and in addition using a single pass over the data? The question is
interesting from the standpoint of both theory and practice and we answer the
question in the affirmative, by providing a one pass
$\tilde{O}(n/\epsilon^{2})$ space algorithm that produces a sparsification that
approximates each cut to a $(1+\epsilon)$ factor. We also show that $\Omega(n
\log \frac1\epsilon)$ space is necessary for a one pass streaming algorithm to
approximate the min-cut, improving upon the $\Omega(n)$ lower bound that arises
from lower bounds for testing connectivity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0189</identifier>
 <datestamp>2009-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0189</id><created>2009-02-01</created><updated>2009-07-20</updated><authors><author><keyname>Rezki</keyname><forenames>Zouheir</forenames></author><author><keyname>Gagnon</keyname><forenames>Francois</forenames></author><author><keyname>Bhargava</keyname><forenames>Vijay</forenames></author></authors><title>The Ergodic Capacity of The MIMO Wire-Tap Channel</title><categories>cs.IT math.IT</categories><comments>24 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn to provide a more rigorous proof of the
converse of Theorem 1 and Lemma 1 as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0221</identifier>
 <datestamp>2009-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0221</id><created>2009-02-02</created><updated>2009-09-14</updated><authors><author><keyname>Avanaki</keyname><forenames>Alireza</forenames></author></authors><title>Over-enhancement Reduction in Local Histogram Equalization using its
  Degrees of Freedom</title><categories>cs.CV cs.MM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A well-known issue of local (adaptive) histogram equalization (LHE) is
over-enhancement (i.e., generation of spurious details) in homogenous areas of
the image. In this paper, we show that the LHE problem has many solutions due
to the ambiguity in ranking pixels with the same intensity. The LHE solution
space can be searched for the images having the maximum PSNR or structural
similarity (SSIM) with the input image. As compared to the results of the prior
art, these solutions are more similar to the input image while offering the
same local contrast.
  Index Terms: histogram modification or specification, contrast enhancement
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0239</identifier>
 <datestamp>2009-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0239</id><created>2009-02-02</created><updated>2009-04-14</updated><authors><author><keyname>Czaja</keyname><forenames>Wojciech</forenames></author><author><keyname>Golda</keyname><forenames>Zdzislaw A.</forenames></author><author><keyname>Woszczyna</keyname><forenames>Andrzej</forenames></author></authors><title>The acoustic wave equation in the expanding universe. Sachs-Wolfe
  theorem</title><categories>cs.SC gr-qc physics.comp-ph</categories><comments>5 pages LaTeX, Some minor changes introduced</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper the acoustic field propagating in the early hot ($p=\epsilon/$)
universe of arbitrary space curvature ($K=0, \pm 1$) is considered. The field
equations are reduced to the d'Alembert equation in an auxiliary static
Roberson-Walker space-time. Symbolic computation in {\em Mathematica} is
applied.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0241</identifier>
 <datestamp>2009-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0241</id><created>2009-02-02</created><updated>2009-02-03</updated><authors><author><keyname>Alagoz</keyname><forenames>B. Baykant</forenames></author></authors><title>Hierarchical Triple-Modular Redundancy (H-TMR) Network For Digital
  Systems</title><categories>cs.OH</categories><comments>Proposition section was added</comments><journal-ref>OncuBilim Algorithm And Systems Labs. Vol.08, Art.No:05,(2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hierarchical application of Triple-Modular Redundancy (TMR) increases fault
tolerance of digital Integrated Circuit (IC). In this paper, a simple
probabilistic model was proposed for analysis of fault masking performance of
hierarchical TMR networks. Performance improvements obtained by second order
TMR network were theoretically compared with first order TMR network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0261</identifier>
 <datestamp>2011-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0261</id><created>2009-02-02</created><updated>2011-07-20</updated><authors><author><keyname>Yamakami</keyname><forenames>Tomoyuki</forenames></author></authors><title>Immunity and Pseudorandomness of Context-Free Languages</title><categories>cs.CC cs.FL</categories><comments>A4, 23 pages, 10 pt. A complete revision of the initial version that
  was posted in February 2009</comments><acm-class>F.4.3; F.1.1; F.1.3</acm-class><journal-ref>Theoretical Computer Science, vol. 412, pp.6432-6450, 2011</journal-ref><doi>10.1016/j.tcs.2011.07.013</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss the computational complexity of context-free languages,
concentrating on two well-known structural properties---immunity and
pseudorandomness. An infinite language is REG-immune (resp., CFL-immune) if it
contains no infinite subset that is a regular (resp., context-free) language.
We prove that (i) there is a context-free REG-immune language outside REG/n and
(ii) there is a REG-bi-immune language that can be computed deterministically
using logarithmic space. We also show that (iii) there is a CFL-simple set,
where a CFL-simple language is an infinite context-free language whose
complement is CFL-immune. Similar to the REG-immunity, a REG-primeimmune
language has no polynomially dense subsets that are also regular. We further
prove that (iv) there is a context-free language that is REG/n-bi-primeimmune.
Concerning pseudorandomness of context-free languages, we show that (v) CFL
contains REG/n-pseudorandom languages. Finally, we prove that (vi) against
REG/n, there exists an almost 1-1 pseudorandom generator computable in
nondeterministic pushdown automata equipped with a write-only output tape and
(vii) against REG, there is no almost 1-1 weakly pseudorandom generator
computable deterministically in linear time by a single-tape Turing machine.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0271</identifier>
 <datestamp>2009-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0271</id><created>2009-02-02</created><updated>2009-05-21</updated><authors><author><keyname>Duda</keyname><forenames>Jarek</forenames></author></authors><title>Asymmetric numeral systems</title><categories>cs.IT cs.CR math.GM math.IT</categories><comments>47 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper will be presented new approach to entropy coding: family of
generalizations of standard numeral systems which are optimal for encoding
sequence of equiprobable symbols, into asymmetric numeral systems - optimal for
freely chosen probability distributions of symbols. It has some similarities to
Range Coding but instead of encoding symbol in choosing a range, we spread
these ranges uniformly over the whole interval. This leads to simpler encoder -
instead of using two states to define range, we need only one. This approach is
very universal - we can obtain from extremely precise encoding (ABS) to
extremely fast with possibility to additionally encrypt the data (ANS). This
encryption uses the key to initialize random number generator, which is used to
calculate the coding tables. Such preinitialized encryption has additional
advantage: is resistant to brute force attack - to check a key we have to make
whole initialization. There will be also presented application for new approach
to error correction: after an error in each step we have chosen probability to
observe that something was wrong. There will be also presented application for
new approach to error correction: after an error in each step we have chosen
probability to observe that something was wrong. We can get near Shannon's
limit for any noise level this way with expected linear time of correction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0320</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0320</id><created>2009-02-02</created><updated>2010-09-29</updated><authors><author><keyname>Chernyak</keyname><forenames>Vladimir Y.</forenames><affiliation>Wayne State</affiliation></author><author><keyname>Chertkov</keyname><forenames>Michael</forenames><affiliation>LANL</affiliation></author></authors><title>Planar Graphical Models which are Easy</title><categories>cond-mat.stat-mech cond-mat.dis-nn cs.CC cs.IT math-ph math.IT math.MP</categories><comments>27 pages, 11 figures; misprints corrected</comments><report-no>LA-UR 09-00533</report-no><doi>10.1088/1742-5468/2010/11/P11007</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a rich family of binary variables statistical mechanics models on
a given planar graph which are equivalent to Gaussian Grassmann Graphical
models (free fermions) defined on the same graph. Calculation of the partition
function (weighted counting) for such a model is easy (of polynomial
complexity) as reducible to evaluation of a Pfaffian of a matrix of size equal
to twice the number of edges in the graph. In particular, this approach touches
upon Holographic Algorithms of Valiant and utilizes the Gauge Transformations
discussed in our previous works.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0322</identifier>
 <datestamp>2009-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0322</id><created>2009-02-02</created><authors><author><keyname>Jacob</keyname><forenames>Gregoire</forenames></author><author><keyname>Debar</keyname><forenames>Herve</forenames></author><author><keyname>Filiol</keyname><forenames>Eric</forenames></author></authors><title>Malware Detection using Attribute-Automata to parse Abstract Behavioral
  Descriptions</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most behavioral detectors of malware remain specific to a given language and
platform, mostly PE executables for Windows. The objective of this paper is to
define a generic approach for behavioral detection based on two layers
respectively responsible for abstraction and detection. The first abstraction
layer remains specific to a platform and a language. This first layer
interprets the collected instructions, API calls and arguments and classifies
these operations as well as the involved objects according to their purpose in
the malware lifecycle. The second detection layer remains generic and is
totally interoperable between the different abstraction components. This layer
relies on parallel automata parsing attribute-grammars where semantic rules are
used for object typing (object classification) and object binding (data-flow).
To feed detection and to experiment with our approach we have developed two
different abstraction components: one processing system call traces from native
code and one processing the VBScript interpreted language. The different
experimentations have provided promising detection rates, in particular for
script files (89%), with almost none false positives. In the case of process
traces, the detection rate remains significant (51%) but could be increased by
more sophisticated collection tools.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0337</identifier>
 <datestamp>2009-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0337</id><created>2009-02-02</created><authors><author><keyname>Huang</keyname><forenames>Kaibin</forenames></author><author><keyname>Lau</keyname><forenames>Vincent K. N.</forenames></author></authors><title>Stability and Delay of Zero-Forcing SDMA with Limited Feedback</title><categories>cs.IT math.IT</categories><comments>26 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the stability and queueing delay of Space Division
Multiple Access (SDMA) systems with bursty traffic, where zero-forcing
beamforming enables simultaneous transmission to multiple mobiles. Computing
beamforming vectors relies on quantized channel state information (CSI)
feedback (limited feedback) from mobiles. Define the stability region for SDMA
as the set of multiuser packet-arrival rates for which the steady-state queue
lengths are finite. Given perfect CSI feedback and equal power allocation over
scheduled queues, the stability region is proved to be a convex polytope having
the derived vertices. For any set of arrival rates in the stability region,
multiuser queues are shown to be stabilized by a joint queue-and-beamforming
control policy that maximizes the departure-rate-weighted sum of queue lengths.
The stability region for limited feedback is found to be the perfect-CSI region
multiplied by one minus a small factor. The required number of feedback bits
per mobile is proved to scale logarithmically with the inverse of the above
factor as well as linearly with the number of transmit antennas minus one. The
effects of limited feedback on queueing delay are also quantified. For Poisson
arrival processes, CSI quantization errors are shown to multiply average
queueing delay by a factor larger than one. This factor can be controlled by
adjusting the number of feedback bits per mobile following the derived
relationship. For general arrival processes, CSI errors are found to increase
Kingman's bound on the tail probability of the instantaneous delay by one plus
a small factor. The required number of feedback bits per mobile is shown to
scale logarithmically with this factor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0353</identifier>
 <datestamp>2009-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0353</id><created>2009-02-02</created><authors><author><keyname>Lee</keyname><forenames>Jon</forenames></author><author><keyname>Mirrokni</keyname><forenames>Vahab</forenames></author><author><keyname>Nagarjan</keyname><forenames>Viswanath</forenames></author><author><keyname>Sviridenko</keyname><forenames>Maxim</forenames></author></authors><title>Non-monotone submodular maximization under matroid and knapsack
  constraints</title><categories>cs.CC cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Submodular function maximization is a central problem in combinatorial
optimization, generalizing many important problems including Max Cut in
directed/undirected graphs and in hypergraphs, certain constraint satisfaction
problems, maximum entropy sampling, and maximum facility location problems.
Unlike submodular minimization, submodular maximization is NP-hard. For the
problem of maximizing a non-monotone submodular function, Feige, Mirrokni, and
Vondr\'ak recently developed a $2\over 5$-approximation algorithm \cite{FMV07},
however, their algorithms do not handle side constraints.} In this paper, we
give the first constant-factor approximation algorithm for maximizing any
non-negative submodular function subject to multiple matroid or knapsack
constraints. We emphasize that our results are for {\em non-monotone}
submodular functions. In particular, for any constant $k$, we present a
$({1\over k+2+{1\over k}+\epsilon})$-approximation for the submodular
maximization problem under $k$ matroid constraints, and a $({1\over
5}-\epsilon)$-approximation algorithm for this problem subject to $k$ knapsack
constraints ($\epsilon&gt;0$ is any constant). We improve the approximation
guarantee of our algorithm to ${1\over k+1+{1\over k-1}+\epsilon}$ for $k\ge 2$
partition matroid constraints. This idea also gives a $({1\over
k+\epsilon})$-approximation for maximizing a {\em monotone} submodular function
subject to $k\ge 2$ partition matroids, which improves over the previously best
known guarantee of $\frac{1}{k+1}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0354</identifier>
 <datestamp>2009-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0354</id><created>2009-02-02</created><authors><author><keyname>Kostina</keyname><forenames>Victoria</forenames></author><author><keyname>Loyka</keyname><forenames>Sergey</forenames></author></authors><title>Optimum Power and Rate Allocation for Coded V-BLAST</title><categories>cs.IT math.IT</categories><comments>accepted by ICC-09</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An analytical framework for minimizing the outage probability of a coded
spatial multiplexing system while keeping the rate close to the capacity is
developed. Based on this framework, specific strategies of optimum power and
rate allocation for the coded V-BLAST architecture are obtained and its
performance is analyzed. A fractional waterfilling algorithm, which is shown to
optimize both the capacity and the outage probability of the coded V-BLAST, is
proposed. Compact, closed-form expressions for the optimum allocation of the
average power are given. The uniform allocation of average power is shown to be
near optimum at moderate to high SNR for the coded V-BLAST with the average
rate allocation (when per-stream rates are set to match the per-stream
capacity). The results reported also apply to multiuser detection and channel
equalization relying on successive interference cancelation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0382</identifier>
 <datestamp>2009-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0382</id><created>2009-02-02</created><authors><author><keyname>Mirrokni</keyname><forenames>Vahab</forenames></author><author><keyname>Skopalik</keyname><forenames>Alexander</forenames></author></authors><title>On the complexity of Nash dynamics and Sink Equilibria</title><categories>cs.GT cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Studying Nash dynamics is an important approach for analyzing the outcome of
games with repeated selfish behavior of self-interested agents. Sink equilibria
has been introduced by Goemans, Mirrokni, and Vetta for studying social cost on
Nash dynamics over pure strategies in games. However, they do not address the
complexity of sink equilibria in these games. Recently, Fabrikant and
Papadimitriou initiated the study of the complexity of Nash dynamics in two
classes of games. In order to completely understand the complexity of Nash
dynamics in a variety of games, we study the following three questions for
various games: (i) given a state in game, can we verify if this state is in a
sink equilibrium or not? (ii) given an instance of a game, can we verify if
there exists any sink equilibrium other than pure Nash equilibria? and (iii)
given an instance of a game, can we verify if there exists a pure Nash
equilibrium (i.e, a sink equilibrium with one state)?
  In this paper, we almost answer all of the above questions for a variety of
classes of games with succinct representation, including anonymous games,
player-specific and weighted congestion games, valid-utility games, and
two-sided market games. In particular, for most of these problems, we show that
(i) it is PSPACE-complete to verify if a given state is in a sink equilibrium,
(ii) it is NP-hard to verify if there exists a pure Nash equilibrium in the
game or not, (iii) it is PSPACE-complete to verify if there exists any sink
equilibrium other than pure Nash equilibria. To solve these problems, we
illustrate general techniques that could be used to answer similar questions in
other classes of games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0392</identifier>
 <datestamp>2011-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0392</id><created>2009-02-02</created><updated>2011-09-21</updated><authors><author><keyname>Dimitrakakis</keyname><forenames>Christos</forenames></author></authors><title>Tree Exploration for Bayesian RL Exploration</title><categories>stat.ML cs.LG</categories><comments>13 pages, 1 figure. Slightly extended and corrected version (notation
  errors and lower bound calculation) of homonymous paper presented at the
  conference of Computational Intelligence for Modelling, Control and
  Automation 2008 (CIMCA'08)</comments><report-no>IAS-08-04</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Research in reinforcement learning has produced algorithms for optimal
decision making under uncertainty that fall within two main types. The first
employs a Bayesian framework, where optimality improves with increased
computational time. This is because the resulting planning task takes the form
of a dynamic programming problem on a belief tree with an infinite number of
states. The second type employs relatively simple algorithm which are shown to
suffer small regret within a distribution-free framework. This paper presents a
lower bound and a high probability upper bound on the optimal value function
for the nodes in the Bayesian belief tree, which are analogous to similar
bounds in POMDPs. The bounds are then used to create more efficient strategies
for exploring the tree. The resulting algorithms are compared with the
distribution-free algorithm UCB1, as well as a simpler baseline algorithm on
multi-armed bandit problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0417</identifier>
 <datestamp>2009-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0417</id><created>2009-02-02</created><updated>2009-04-20</updated><authors><author><keyname>Salmond</keyname><forenames>Daniel</forenames></author><author><keyname>Grant</keyname><forenames>Alex</forenames></author><author><keyname>Chan</keyname><forenames>Terence</forenames></author><author><keyname>Grivell</keyname><forenames>Ian</forenames></author></authors><title>Decoding Network Codes by Message Passing</title><categories>cs.IT math.IT</categories><comments>5 pages, submitted to ISIT 2009. Added an additional reference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we show how to construct a factor graph from a network code.
This provides a systematic framework for decoding using message passing
algorithms. The proposed message passing decoder exploits knowledge of the
underlying communications network topology to simplify decoding. For uniquely
decodeable linear network codes on networks with error-free links, only the
message supports (rather than the message values themselves) are required to be
passed. This proposed simplified support message algorithm is an instance of
the sum-product algorithm. Our message-passing framework provides a basis for
the design of network codes and control of network topology with a view toward
quantifiable complexity reduction in the sink terminals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0458</identifier>
 <datestamp>2009-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0458</id><created>2009-02-03</created><authors><author><keyname>Martin</keyname><forenames>Keith M.</forenames></author></authors><title>On the Applicability of Combinatorial Designs to Key Predistribution for
  Wireless Sensor Networks</title><categories>cs.CR cs.DM</categories><acm-class>E.3; G.2.1; C.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The constraints of lightweight distributed computing environments such as
wireless sensor networks lend themselves to the use of symmetric cryptography
to provide security services. The lack of central infrastructure after
deployment of such networks requires the necessary symmetric keys to be
predistributed to participating nodes. The rich mathematical structure of
combinatorial designs has resulted in the proposal of several key
predistribution schemes for wireless sensor networks based on designs. We
review and examine the appropriateness of combinatorial designs as a tool for
building key predistribution schemes suitable for such environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0465</identifier>
 <datestamp>2011-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0465</id><created>2009-02-03</created><updated>2011-04-07</updated><authors><author><keyname>Jiang</keyname><forenames>Bin</forenames></author><author><keyname>Liu</keyname><forenames>Xintao</forenames></author></authors><title>AxialGen: A Research Prototype for Automatically Generating the Axial
  Map</title><categories>cs.RO cs.CG</categories><comments>9 pages, 4 figures</comments><journal-ref>Proceedings of CUPUM 2009, the 11th International Conference on
  Computers in Urban Planning and Urban Management, Hong Kong, 16-18 June 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  AxialGen is a research prototype for automatically generating the axial map,
which consists of the least number of the longest visibility lines (or axial
lines) for representing individual linearly stretched parts of open space of an
urban environment. Open space is the space between closed spaces such as
buildings and street blocks. This paper aims to provide an accessible guide to
software AxialGen, and the underlying concepts and ideas. We concentrate on the
explanation and illustration of the key concept of bucket: its definition,
formation and how it is used in generating the axial map.
  Keywords: Bucket, visibility, medial axes, axial lines, isovists, axial map
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0469</identifier>
 <datestamp>2009-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0469</id><created>2009-02-03</created><updated>2009-04-20</updated><authors><author><keyname>Jacob</keyname><forenames>Gregoire</forenames></author><author><keyname>Filiol</keyname><forenames>Eric</forenames></author><author><keyname>Debar</keyname><forenames>Herve</forenames></author></authors><title>Formalization of malware through process calculi</title><categories>cs.CR</categories><comments>Corrected version from CSF reviews Shorter version submitted to
  ESORICS</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Since the seminal work from F. Cohen in the eighties, abstract virology has
seen the apparition of successive viral models, all based on Turing-equivalent
formalisms. But considering recent malware such as rootkits or k-ary codes,
these viral models only partially cover these evolved threats. The problem is
that Turing-equivalent models do not support interactive computations. New
models have thus appeared, offering support for these evolved malware, but
loosing the unified approach in the way. This article provides a basis for a
unified malware model founded on process algebras and in particular the
Join-Calculus. In terms of expressiveness, the new model supports the
fundamental definitions based on self-replication and adds support for
interactions, concurrency and non-termination allows the definition of more
complex behaviors. Evolved malware such as rootkits can now be thoroughly
modeled. In terms of detection and prevention, the fundamental results of
undecidability and isolation still hold. However the process-based model has
permitted to establish new results: identification of fragments from the
Join-Calculus where malware detection becomes decidable, formal definition of
the non-infection property, approximate solutions to restrict malware
propagation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0514</identifier>
 <datestamp>2009-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0514</id><created>2009-02-03</created><authors><author><keyname>Dixon</keyname><forenames>Lucas</forenames></author><author><keyname>Duncan</keyname><forenames>Ross</forenames></author></authors><title>Graphical Reasoning in Compact Closed Categories for Quantum Computation</title><categories>cs.SC cs.AI</categories><comments>21 pages, 9 figures. This is the journal version of the paper
  published at AISC</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compact closed categories provide a foundational formalism for a variety of
important domains, including quantum computation. These categories have a
natural visualisation as a form of graphs. We present a formalism for
equational reasoning about such graphs and develop this into a generic proof
system with a fixed logical kernel for equational reasoning about compact
closed categories. Automating this reasoning process is motivated by the slow
and error prone nature of manual graph manipulation. A salient feature of our
system is that it provides a formal and declarative account of derived results
that can include `ellipses'-style notation. We illustrate the framework by
instantiating it for a graphical language of quantum computation and show how
this can be used to perform symbolic computation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0524</identifier>
 <datestamp>2010-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0524</id><created>2009-02-03</created><updated>2010-04-24</updated><authors><author><keyname>Gujar</keyname><forenames>Sujit</forenames></author><author><keyname>Narahari</keyname><forenames>Y</forenames></author></authors><title>An Optimal Multi-Unit Combinatorial Procurement Auction with Single
  Minded Bidders</title><categories>cs.GT</categories><comments>8 Pages, Managing Complexity in Distributed World, MCDES 2008: IISc
  Centenary Conference of Division of Electrical Sciences Added 2 references in
  newer version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The current art in optimal combinatorial auctions is limited to handling the
case of single units of multiple items, with each bidder bidding on exactly one
bundle (single minded bidders). This paper extends the current art by proposing
an optimal auction for procuring multiple units of multiple items when the
bidders are single minded. The auction minimizes the cost of procurement while
satisfying Bayesian incentive compatibility and interim individual rationality.
Under appropriate regularity conditions, this optimal auction also satisfies
dominant strategy incentive compatibility.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0558</identifier>
 <datestamp>2009-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0558</id><created>2009-02-03</created><authors><author><keyname>Portoles-Comeras</keyname><forenames>Marc</forenames></author><author><keyname>Cabellos-Aparicio</keyname><forenames>Albert</forenames></author><author><keyname>Mangues-Bafalluy</keyname><forenames>Josep</forenames></author><author><keyname>Domingo-Pascual</keyname><forenames>Jordi</forenames></author></authors><title>Analysis of bandwidth measurement methodologies over WLAN systems</title><categories>cs.NI cs.PF</categories><comments>14 pages, 17 figures,</comments><acm-class>C.4; C.2.1; C.2.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  WLAN devices have become a fundamental component of nowadays network
deployments. However, even though traditional networking applications run
mostly unchanged over wireless links, the actual interaction between these
applications and the dynamics of wireless transmissions is not yet fully
understood. An important example of such applications are bandwidth estimation
tools. This area has become a mature research topic with well-developed
results. Unfortunately recent studies have shown that the application of these
results to WLAN links is not straightforward. The main reasons for this is that
the assumptions taken to develop bandwidth measurements tools do not hold any
longer in the presence of wireless links (e.g. non-FIFO scheduling). This paper
builds from these observations and its main goal is to analyze the interaction
between probe packets and WLAN transmissions in bandwidth estimation processes.
The paper proposes an analytical model that better accounts for the
particularities of WLAN links. The model is validated through extensive
experimentation and simulation and reveals that (1) the distribution of the
delay to transmit probing packets is not the same for the whole probing
sequence, this biases the measurements process and (2) existing tools and
techniques point at the achievable throughput rather than the available
bandwidth or the capacity, as previously assumed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0562</identifier>
 <datestamp>2010-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0562</id><created>2009-02-03</created><updated>2010-08-02</updated><authors><author><keyname>Cappellari</keyname><forenames>Lorenzo</forenames></author><author><keyname>De Giusti</keyname><forenames>Andrea</forenames></author></authors><title>A Unified Perspective on Parity- and Syndrome-Based Binary Data
  Compression Using Off-the-Shelf Turbo Codecs</title><categories>cs.IT math.IT</categories><comments>10 pages, 10 figures (11 graphic files organized with subfigures), 1
  table; completely reviewed with a focus on non-uniform sources; submitted to
  IEEE Trans. Commun</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of compressing memoryless binary data with or without
side information at the decoder. We review the parity- and the syndrome-based
approaches and discuss their theoretical limits, assuming that there exists a
virtual binary symmetric channel between the source and the side information,
and that the source is not necessarily uniformly distributed. We take a
factor-graph-based approach in order to devise how to take full advantage of
the ready-available iterative decoding procedures when turbo codes are
employed, in both a parity- or a syndrome-based fashion. We end up obtaining a
unified decoder formulation that holds both for error-free and for error-prone
encoder-to-decoder transmission over generic channels. To support the
theoretical results, the different compression systems analyzed in the paper
are also experimentally tested. They are compared against several different
approaches proposed in literature and shown to be competitive in a variety of
cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0606</identifier>
 <datestamp>2009-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0606</id><created>2009-02-03</created><authors><author><keyname>Serrano</keyname><forenames>M. Angeles</forenames></author><author><keyname>Flammini</keyname><forenames>Alessandro</forenames></author><author><keyname>Menczer</keyname><forenames>Filippo</forenames></author></authors><title>Beyond Zipf's law: Modeling the structure of human language</title><categories>cs.CL physics.soc-ph</categories><comments>9 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Human language, the most powerful communication system in history, is closely
associated with cognition. Written text is one of the fundamental
manifestations of language, and the study of its universal regularities can
give clues about how our brains process information and how we, as a society,
organize and share it. Still, only classical patterns such as Zipf's law have
been explored in depth. In contrast, other basic properties like the existence
of bursts of rare words in specific documents, the topical organization of
collections, or the sublinear growth of vocabulary size with the length of a
document, have only been studied one by one and mainly applying heuristic
methodologies rather than basic principles and general mechanisms. As a
consequence, there is a lack of understanding of linguistic processes as
complex emergent phenomena. Beyond Zipf's law for word frequencies, here we
focus on Heaps' law, burstiness, and the topicality of document collections,
which encode correlations within and across documents absent in random null
models. We introduce and validate a generative model that explains the
simultaneous emergence of all these patterns from simple rules. As a result, we
find a connection between the bursty nature of rare words and the topical
organization of texts and identify dynamic word ranking and memory across
documents as key mechanisms explaining the non trivial organization of written
text. Our research can have broad implications and practical applications in
computer science, cognitive science, and linguistics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0620</identifier>
 <datestamp>2009-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0620</id><created>2009-02-03</created><updated>2009-10-19</updated><authors><author><keyname>Lindner</keyname><forenames>Claudia</forenames></author><author><keyname>Rothe</keyname><forenames>Joerg</forenames></author></authors><title>Degrees of Guaranteed Envy-Freeness in Finite Bounded Cake-Cutting
  Protocols</title><categories>cs.GT</categories><comments>37 pages, 4 figures</comments><acm-class>I.2.1; F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cake-cutting protocols aim at dividing a ``cake'' (i.e., a divisible
resource) and assigning the resulting portions to several players in a way that
each of the players feels to have received a ``fair'' amount of the cake. An
important notion of fairness is envy-freeness: No player wishes to switch the
portion of the cake received with another player's portion. Despite intense
efforts in the past, it is still an open question whether there is a
\emph{finite bounded} envy-free cake-cutting protocol for an arbitrary number
of players, and even for four players. We introduce the notion of degree of
guaranteed envy-freeness (DGEF) as a measure of how good a cake-cutting
protocol can approximate the ideal of envy-freeness while keeping the protocol
finite bounded (trading being disregarded). We propose a new finite bounded
proportional protocol for any number n \geq 3 of players, and show that this
protocol has a DGEF of 1 + \lceil (n^2)/2 \rceil. This is the currently best
DGEF among known finite bounded cake-cutting protocols for an arbitrary number
of players. We will make the case that improving the DGEF even further is a
tough challenge, and determine, for comparison, the DGEF of selected known
finite bounded cake-cutting protocols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0657</identifier>
 <datestamp>2009-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0657</id><created>2009-02-03</created><authors><author><keyname>Taghavi</keyname><forenames>Mohammad H.</forenames></author><author><keyname>Shokrollahi</keyname><forenames>Amin</forenames></author><author><keyname>Siegel</keyname><forenames>Paul H.</forenames></author></authors><title>Efficient implementation of linear programming decoding</title><categories>cs.IT math.IT</categories><comments>44 pages, submitted to IEEE Transactions on Information Theory, Dec.
  2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While linear programming (LP) decoding provides more flexibility for
finite-length performance analysis than iterative message-passing (IMP)
decoding, it is computationally more complex to implement in its original form,
due to both the large size of the relaxed LP problem, and the inefficiency of
using general-purpose LP solvers. This paper explores ideas for fast LP
decoding of low-density parity-check (LDPC) codes. We first prove, by modifying
the previously reported Adaptive LP decoding scheme to allow removal of
unnecessary constraints, that LP decoding can be performed by solving a number
of LP problems that contain at most one linear constraint derived from each of
the parity-check constraints. By exploiting this property, we study a sparse
interior-point implementation for solving this sequence of linear programs.
Since the most complex part of each iteration of the interior-point algorithm
is the solution of a (usually ill-conditioned) system of linear equations for
finding the step direction, we propose a preconditioning algorithm to
facilitate iterative solution of such systems. The proposed preconditioning
algorithm is similar to the encoding procedure of LDPC codes, and we
demonstrate its effectiveness via both analytical methods and computer
simulation results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0668</identifier>
 <datestamp>2009-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0668</id><created>2009-02-04</created><authors><author><keyname>Gurevich</keyname><forenames>SHamgar</forenames><affiliation>UC Berkeley</affiliation></author><author><keyname>Hadani</keyname><forenames>Ronny</forenames><affiliation>U of Chicago</affiliation></author></authors><title>Application of the Weil representation: diagonalization of the discrete
  Fourier transform</title><categories>cs.IT cs.DM math.IT math.RT</categories><comments>To appear in the Proceedings of the Sixth Workshop on Lie Theory and
  Geometry, Cordoba, November 13 - 17, 2007 (Editors: C. S. Gordon, F.
  Grunewald, C. Olmos, J. A. Tirao, J. A. Wolf). Key word: Discrete Fourier
  transform; Weil representation; Canonical eigenvectors; Oscillator transform;
  Fast oscillator transform</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We survey a new application of the Weil representation to construct a
canonical basis of eigenvectors for the discrete Fourier transform (DFT). The
transition matrix from the standard basis to the canonical basis defines a
novel transform which we call the discrete oscillator transform (DOT for
short). In addition, we describe a fast algorithm for computing the DOT in
certain cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0673</identifier>
 <datestamp>2009-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0673</id><created>2009-02-04</created><authors><author><keyname>Argentini</keyname><forenames>Gianluca</forenames></author></authors><title>Optimal profiles in variable speed flows</title><categories>math.HO cs.CE math.OC physics.flu-dyn</categories><comments>5 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Where a 2D problem of optimal profile in variable speed flow is resolved in a
class of convex Bezier curves, using symbolic and numerical computations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0744</identifier>
 <datestamp>2009-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0744</id><created>2009-02-04</created><authors><author><keyname>Myers</keyname><forenames>James D.</forenames><affiliation>National Center for Supercomputing Applications, University of Illinois at Urbana-Champaign</affiliation></author><author><keyname>Futrelle</keyname><forenames>Joe</forenames><affiliation>National Center for Supercomputing Applications, University of Illinois at Urbana-Champaign</affiliation></author><author><keyname>Gaynor</keyname><forenames>Jeff</forenames><affiliation>National Center for Supercomputing Applications, University of Illinois at Urbana-Champaign</affiliation></author><author><keyname>Plutchak</keyname><forenames>Joel</forenames><affiliation>National Center for Supercomputing Applications, University of Illinois at Urbana-Champaign</affiliation></author><author><keyname>Bajcsy</keyname><forenames>Peter</forenames><affiliation>National Center for Supercomputing Applications, University of Illinois at Urbana-Champaign</affiliation></author><author><keyname>Kastner</keyname><forenames>Jason</forenames><affiliation>National Center for Supercomputing Applications, University of Illinois at Urbana-Champaign</affiliation></author><author><keyname>Kotwani</keyname><forenames>Kailash</forenames><affiliation>National Center for Supercomputing Applications, University of Illinois at Urbana-Champaign</affiliation></author><author><keyname>Lee</keyname><forenames>Jong Sung</forenames><affiliation>National Center for Supercomputing Applications, University of Illinois at Urbana-Champaign</affiliation></author><author><keyname>Marini</keyname><forenames>Luigi</forenames><affiliation>National Center for Supercomputing Applications, University of Illinois at Urbana-Champaign</affiliation></author><author><keyname>Kooper</keyname><forenames>Rob</forenames><affiliation>National Center for Supercomputing Applications, University of Illinois at Urbana-Champaign</affiliation></author><author><keyname>McGrath</keyname><forenames>Robert E.</forenames><affiliation>National Center for Supercomputing Applications, University of Illinois at Urbana-Champaign</affiliation></author><author><keyname>McLaren</keyname><forenames>Terry</forenames><affiliation>National Center for Supercomputing Applications, University of Illinois at Urbana-Champaign</affiliation></author><author><keyname>Rodriguez</keyname><forenames>Alejandro</forenames><affiliation>National Center for Supercomputing Applications, University of Illinois at Urbana-Champaign</affiliation></author><author><keyname>Liu</keyname><forenames>Yong</forenames><affiliation>National Center for Supercomputing Applications, University of Illinois at Urbana-Champaign</affiliation></author></authors><title>Embedding Data within Knowledge Spaces</title><categories>cs.AI cs.HC cs.IR</categories><comments>10 pages with 1 figure. Corrected incorrect transliteration in
  abstract</comments><acm-class>H.3.5; H.5.3; I.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The promise of e-Science will only be realized when data is discoverable,
accessible, and comprehensible within distributed teams, across disciplines,
and over the long-term--without reliance on out-of-band (non-digital) means. We
have developed the open-source Tupelo semantic content management framework and
are employing it to manage a wide range of e-Science entities (including data,
documents, workflows, people, and projects) and a broad range of metadata
(including provenance, social networks, geospatial relationships, temporal
relations, and domain descriptions). Tupelo couples the use of global
identifiers and resource description framework (RDF) statements with an
aggregatable content repository model to provide a unified space for securely
managing distributed heterogeneous content and relationships.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0746</identifier>
 <datestamp>2010-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0746</id><created>2009-02-04</created><updated>2010-01-06</updated><authors><author><keyname>Jaffr&#xe8;s-Runser</keyname><forenames>Katia</forenames></author><author><keyname>Comaniciu</keyname><forenames>Cristina</forenames></author><author><keyname>Gorce</keyname><forenames>Jean-Marie</forenames></author></authors><title>Interference and Congestion Aware Gradient Broadcasting Routing for
  Wireless Sensor Networks</title><categories>cs.NI</categories><comments>submitted to Eurasip Journal on Wireless Communications and
  Networking, special issue on Interference Management in Wireless
  Communication Systems: Theory and Applications in November 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the problem of reliable transmission of data through a
sensor network. We focus on networks rapidly deployed in harsh environments.
For these networks, important design requirements are fast data transmission
and rapid network setup, as well as minimized energy consumption for increased
network lifetime. We propose a novel broadcasting solution that accounts for
the interference impact and the congestion level of the channel, in order to
improve robustness, energy consumption and delay performance, compared to a
benchmark routing protocol, the GRAB algorithm. Three solutions are proposed:
P-GRAB, a probabilistic routing algorithm for interference mitigation, U-GRAB,
a utility-based algorithm that adjusts to real-time congestion and UP-GRAB, a
combination of P-GRAB and U-GRAB. It is shown that P-GRAB provides the best
performance for geometry-aware networks while the U-GRAB approach is the best
option for unreliable and unstable networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0755</identifier>
 <datestamp>2009-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0755</id><created>2009-02-04</created><authors><author><keyname>Constans</keyname><forenames>Pere</forenames></author></authors><title>A Simple Extraction Procedure for Bibliographical Author Field</title><categories>cs.DL</categories><acm-class>H.3.1; H.3.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A procedure for bibliographic author metadata extraction from scholarly texts
is presented. The author segments are identified based on capitalization and
line break patterns. Two main author layout templates, which can retrieve from
a varied set of title pages, are provided. Additionally, several disambiguating
rules are described.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0763</identifier>
 <datestamp>2009-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0763</id><created>2009-02-04</created><authors><author><keyname>Saha</keyname><forenames>Sourabh</forenames></author></authors><title>Genetic algorithm based optimization and post optimality analysis of
  multi-pass face milling</title><categories>cs.CE</categories><proxy>ccsd hal-00355828</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an optimization technique for the multi-pass face milling
process. Genetic algorithm (GA) is used to obtain the optimum cutting
parameters by minimizing the unit production cost for a given amount of
material removal. Cutting speed, feed and depth of cut for the finish and rough
passes are the cutting parameters. An equal depth of cut for roughing passes
has been considered. A lookup table containing the feasible combinations of
depth of cut in finish and rough passes is generated so as to reduce the number
of variables by one. The resulting mixed integer nonlinear optimization problem
is solved in a single step using GA. The entire technique is demonstrated in a
case study. Post optimality analysis of the example problem is done to develop
a strategy for optimizing without running GA again for different values of
total depth of cut.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0782</identifier>
 <datestamp>2010-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0782</id><created>2009-02-04</created><updated>2010-01-06</updated><authors><author><keyname>Jaffr&#xe8;s-Runser</keyname><forenames>Katia</forenames></author><author><keyname>Comaniciu</keyname><forenames>Cristina</forenames></author><author><keyname>Gorce</keyname><forenames>Jean-Marie</forenames></author></authors><title>A Multiobjective Optimization Framework for Routing in Wireless Ad Hoc
  Networks</title><categories>cs.NI cs.PF</categories><journal-ref>IEEE International Symposium on Conference Modeling and
  Optimization in Mobile, Ad Hoc, and Wireless Networks (WiOpt) 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless ad hoc networks are seldom characterized by one single performance
metric, yet the current literature lacks a flexible framework to assist in
characterizing the design tradeoffs in such networks. In this work, we address
this problem by proposing a new modeling framework for routing in ad hoc
networks, which used in conjunction with metaheuristic multiobjective search
algorithms, will result in a better understanding of network behavior and
performance when multiple criteria are relevant. Our approach is to take a
holistic view of the network that captures the cross-interactions among
interference management techniques implemented at various layers of the
protocol stack. The resulting framework is a complex multiobjective
optimization problem that can be efficiently solved through existing
multiobjective search techniques. In this contribution, we present the Pareto
optimal sets for an example sensor network when delay, robustness and energy
are considered. The aim of this paper is to present the framework and hence for
conciseness purposes, the multiobjective optimization search is not developed
herein.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0798</identifier>
 <datestamp>2009-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0798</id><created>2009-02-04</created><authors><author><keyname>Diaz-Aviles</keyname><forenames>Ernesto</forenames></author></authors><title>Alleviating Media Bias Through Intelligent Agent Blogging</title><categories>cs.AI</categories><acm-class>I.2.11; J.4; H.3</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Consumers of mass media must have a comprehensive, balanced and plural
selection of news to get an unbiased perspective; but achieving this goal can
be very challenging, laborious and time consuming. News stories development
over time, its (in)consistency, and different level of coverage across the
media outlets are challenges that a conscientious reader has to overcome in
order to alleviate bias.
  In this paper we present an intelligent agent framework currently
facilitating analysis of the main sources of on-line news in El Salvador. We
show how prior tools of text analysis and Web 2.0 technologies can be combined
with minimal manual intervention to help individuals on their rational decision
process, while holding media outlets accountable for their work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0822</identifier>
 <datestamp>2009-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0822</id><created>2009-02-04</created><authors><author><keyname>Wang</keyname><forenames>Ye</forenames></author><author><keyname>Ishwar</keyname><forenames>Prakash</forenames></author></authors><title>Bootstrapped Oblivious Transfer and Secure Two-Party Function
  Computation</title><categories>cs.CR cs.IT math.IT</categories><comments>5 pages, 2 figures. Submitted to 2009 IEEE International Symposium on
  Information Theory, Seoul, South Korea</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an information theoretic framework for the secure two-party
function computation (SFC) problem and introduce the notion of SFC capacity. We
study and extend string oblivious transfer (OT) to sample-wise OT. We propose
an efficient, perfectly private OT protocol utilizing the binary erasure
channel or source. We also propose the bootstrap string OT protocol which
provides disjoint (weakened) privacy while achieving a multiplicative increase
in rate, thus trading off security for rate. Finally, leveraging our OT
protocol, we construct a protocol for SFC and establish a general lower bound
on SFC capacity of the binary erasure channel and source.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0828</identifier>
 <datestamp>2009-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0828</id><created>2009-02-04</created><authors><author><keyname>Qin</keyname><forenames>Xiaolin</forenames></author><author><keyname>Feng</keyname><forenames>Yong</forenames></author><author><keyname>Chen</keyname><forenames>Jingwei</forenames></author><author><keyname>Zhang</keyname><forenames>Jingzhong</forenames></author></authors><title>Finding Exact Minimal Polynomial by Approximations</title><categories>cs.CC cs.SC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new algorithm for reconstructing an exact algebraic number from
its approximate value using an improved parameterized integer relation
construction method. Our result is consistent with the existence of error
controlling on obtaining an exact rational number from its approximation. The
algorithm is applicable for finding exact minimal polynomial by its approximate
root. This also enables us to provide an efficient method of converting the
rational approximation representation to the minimal polynomial representation,
and devise a simple algorithm to factor multivariate polynomials with rational
coefficients.
  Compared with other methods, this method has the numerical computation
advantage of high efficiency. The experimental results show that the method is
more efficient than \emph{identify} in \emph{Maple} 11 for obtaining an exact
algebraic number from its approximation. In this paper, we completely implement
how to obtain exact results by numerical approximate computations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0838</identifier>
 <datestamp>2012-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0838</id><created>2009-02-04</created><updated>2012-03-10</updated><authors><author><keyname>Jafar</keyname><forenames>Syed A.</forenames></author></authors><title>The Ergodic Capacity of Phase-Fading Interference Networks</title><categories>cs.IT math.IT</categories><comments>19 pages</comments><journal-ref>IEEE Transactions on Information Theory, Vol. 57, No. 12, Pages:
  7685-7694, December 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We identify the role of equal strength interference links as bottlenecks on
the ergodic sum capacity of a $K$ user phase-fading interference network, i.e.,
an interference network where the fading process is restricted primarily to
independent and uniform phase variations while the channel magnitudes are held
fixed across time. It is shown that even though there are $K(K-1)$ cross-links,
only about $K/2$ disjoint and equal strength interference links suffice to
determine the capacity of the network regardless of the strengths of the rest
of the cross channels. This scenario is called a \emph{minimal bottleneck
state}. It is shown that ergodic interference alignment is capacity optimal for
a network in a minimal bottleneck state. The results are applied to large
networks. It is shown that large networks are close to bottleneck states with a
high probability, so that ergodic interference alignment is close to optimal
for large networks. Limitations of the notion of bottleneck states are also
highlighted for channels where both the phase and the magnitudes vary with
time. It is shown through an example that for these channels, joint coding
across different bottleneck states makes it possible to circumvent the capacity
bottlenecks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0850</identifier>
 <datestamp>2009-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0850</id><created>2009-02-05</created><authors><author><keyname>Velasco</keyname><forenames>Pedro Pablo Perez</forenames></author><author><keyname>de Lara</keyname><forenames>Juan</forenames></author></authors><title>Matrix Graph Grammars and Monotone Complex Logics</title><categories>cs.DM</categories><comments>30 pages, 12 figures</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Graph transformation is concerned with the manipulation of graphs by means of
rules. Graph grammars have been traditionally studied using techniques from
category theory. In previous works, we introduced Matrix Graph Grammars (MGGs)
as a purely algebraic approach for the study of graph grammars and graph
dynamics, based on the representation of graphs by means of their adjacency
matrices. MGGs have been succesfully applied to problems such as applicability
of rule sequences, sequentialization and reachability, providing new analysis
techniques and generalizing and improving previous results.
  Our next objective is to generalize MGGs in order to approach computational
complexity theory and &quot;static&quot; properties of graphs out of the &quot;dynamics&quot; of
certain grammars. In the present work, we start building bridges between MGGs
and complexity by introducing what we call &quot;Monotone Complex Logic&quot;, which
allows establishing a (bijective) link between MGGs and complex analysis. We
use this logic to recast the formulation and basic building blocks of MGGs as
more proper geometric and analytic concepts (scalar products, norms,
distances). MGG rules can also be interpreted - via operators - as complex
numbers. Interestingly, the subset they define can be characterized as the
Sierpinski gasket.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0892</identifier>
 <datestamp>2011-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0892</id><created>2009-02-05</created><updated>2011-08-16</updated><authors><author><keyname>Flanagan</keyname><forenames>Mark F.</forenames></author></authors><title>A Unified Framework for Linear-Programming Based Communication Receivers</title><categories>cs.IT math.IT</categories><comments>13 pages, 6 figures. To appear in the IEEE Transactions on
  Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is shown that a large class of communication systems which admit a
sum-product algorithm (SPA) based receiver also admit a corresponding
linear-programming (LP) based receiver. The two receivers have a relationship
defined by the local structure of the underlying graphical model, and are
inhibited by the same phenomenon, which we call 'pseudoconfigurations'. This
concept is a generalization of the concept of 'pseudocodewords' for linear
codes. It is proved that the LP receiver has the 'maximum likelihood
certificate' property, and that the receiver output is the lowest cost
pseudoconfiguration. Equivalence of graph-cover pseudoconfigurations and
linear-programming pseudoconfigurations is also proved. A concept of 'system
pseudodistance' is defined which generalizes the existing concept of
pseudodistance for binary and nonbinary linear codes. It is demonstrated how
the LP design technique may be applied to the problem of joint equalization and
decoding of coded transmissions over a frequency selective channel, and a
simulation-based analysis of the error events of the resulting LP receiver is
also provided. For this particular application, the proposed LP receiver is
shown to be competitive with other receivers, and to be capable of
outperforming turbo equalization in bit and frame error rate performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0899</identifier>
 <datestamp>2009-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0899</id><created>2009-02-05</created><authors><author><keyname>Alenda</keyname><forenames>R&#xe9;gis</forenames><affiliation>LSIS</affiliation></author><author><keyname>Olivetti</keyname><forenames>Nicola</forenames><affiliation>LSIS</affiliation></author><author><keyname>Schwind</keyname><forenames>Camilla</forenames><affiliation>LIF</affiliation></author></authors><title>Comparative concept similarity over Minspaces: Axiomatisation and
  Tableaux Calculus</title><categories>cs.AI</categories><comments>25 pages</comments><proxy>ccsd hal-00358841</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the logic of comparative concept similarity $\CSL$ introduced by
Sheremet, Tishkovsky, Wolter and Zakharyaschev to capture a form of qualitative
similarity comparison. In this logic we can formulate assertions of the form &quot;
objects A are more similar to B than to C&quot;. The semantics of this logic is
defined by structures equipped by distance functions evaluating the similarity
degree of objects. We consider here the particular case of the semantics
induced by \emph{minspaces}, the latter being distance spaces where the minimum
of a set of distances always exists. It turns out that the semantics over
arbitrary minspaces can be equivalently specified in terms of preferential
structures, typical of conditional logics. We first give a direct
axiomatisation of this logic over Minspaces. We next define a decision
procedure in the form of a tableaux calculus. Both the calculus and the
axiomatisation take advantage of the reformulation of the semantics in terms of
preferential structures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0901</identifier>
 <datestamp>2009-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0901</id><created>2009-02-05</created><authors><author><keyname>Brouwers</keyname><forenames>Lisa</forenames></author><author><keyname>Camitz</keyname><forenames>Martin</forenames></author><author><keyname>Cakici</keyname><forenames>Baki</forenames></author><author><keyname>M&#xe4;kil&#xe4;</keyname><forenames>Kalle</forenames></author><author><keyname>Saretok</keyname><forenames>Paul</forenames></author></authors><title>MicroSim: Modeling the Swedish Population</title><categories>cs.OH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article presents a unique, large-scale and spatially explicit
microsimulation model that uses official anonymized register data collected
from all individuals living in Sweden. Individuals are connected to households
and workplaces and represent crucial links in the Swedish social contact
network. This enables significant policy experiments in the domain of epidemic
outbreaks. Development of the model started in 2004 at the Swedish Institute
for Infectious Disease Control (SMI) in Solna, Sweden with the goal of creating
a tool for testing the effects of intervention policies. These interventions
include mass vaccination, targeted vaccination, isolation and social
distancing. The model was initially designed for simulating smallpox outbreaks.
In 2006, it was modified to support simulations of pandemic influenza. All nine
millions members of the Swedish population are represented in the model. This
article is a technical description of the simulation model; the input data, the
simulation engine and the basic object types.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0919</identifier>
 <datestamp>2009-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0919</id><created>2009-02-05</created><authors><author><keyname>Ariba</keyname><forenames>Yassine</forenames><affiliation>LAAS</affiliation></author><author><keyname>Gouaisbaut</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>LAAS</affiliation></author><author><keyname>Labit</keyname><forenames>Yann</forenames><affiliation>LAAS</affiliation></author></authors><title>Multiple time-delays system modeling and control for router management</title><categories>cs.NI</categories><proxy>ccsd hal-00357762</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the overload problem of a single congested router in
TCP (Transmission Control Protocol) networks. To cope with the congestion
phenomenon, we design a feedback control based on a multiple time-delays model
of the set TCP/AQM (Active Queue Management). Indeed, using robust control
tools, especially in the quadratic separation framework, the TCP/AQM model is
rewritten as an intercon- nected system and a structured state feedback is
constructed to stabilize the network variables. Finally, we illustrate the
proposed methodology with a numerical example and simulations using NS-2
simulator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0920</identifier>
 <datestamp>2009-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0920</id><created>2009-02-05</created><authors><author><keyname>Ariba</keyname><forenames>Yassine</forenames><affiliation>LAAS</affiliation></author><author><keyname>Labit</keyname><forenames>Yann</forenames><affiliation>LAAS</affiliation></author><author><keyname>Gouaisbaut</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>LAAS</affiliation></author></authors><title>Design and performance evaluation of a state-space based AQM</title><categories>cs.NI</categories><proxy>ccsd hal-00357905</proxy><journal-ref>International Conference on Communication Theory, Reliability, and
  Quality of Service, Bucharest : Roumanie (2008)</journal-ref><doi>10.1109/CTRQ.2008.15</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent research has shown the link between congestion control in
communication networks and feedback control system. In this paper, the design
of an active queue management (AQM) which can be viewed as a controller, is
considered. Based on a state space representation of a linearized fluid flow
model of TCP, the AQM design is converted to a state feedback synthesis problem
for time delay systems. Finally, an example extracted from the literature and
simulations via a network simulator NS (under cross traffic conditions) support
our study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0922</identifier>
 <datestamp>2009-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0922</id><created>2009-02-05</created><authors><author><keyname>Labit</keyname><forenames>Yann</forenames><affiliation>LAAS</affiliation></author><author><keyname>Ariba</keyname><forenames>Yassine</forenames><affiliation>LAAS</affiliation></author><author><keyname>Gouaisbaut</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>LAAS</affiliation></author></authors><title>On Designing Lyapunov-Krasovskii Based AQM for Routers Supporting TCP
  Flows</title><categories>cs.NI</categories><proxy>ccsd hal-00357908</proxy><journal-ref>46th IEEE Conference on Decision and Control, New Orleans :
  \'Etats-Unis d'Am\'erique (2007)</journal-ref><doi>10.1109/CDC.2007.4434673</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For the last few years, we assist to a growing interest of designing AQM
(Active Queue Management) using control theory. In this paper, we focus on the
synthesis of an AQM based on the Lyapunov theory for time delay systems. With
the help of a recently developed Lyapunov-Krasovskii functional and using a
state space representation of a linearized fluid model of TCP, two robust AQMs
stabilizing the TCP model are constructed. Notice that our results are
constructive and the synthesis problem is reduced to a convex optimization
scheme expressed in terms of linear matrix inequalities (LMIs). Finally, an
example extracted from the literature and simulations via {\it NS simulator}
support our study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0924</identifier>
 <datestamp>2009-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0924</id><created>2009-02-05</created><authors><author><keyname>Jureta</keyname><forenames>Ivan</forenames></author><author><keyname>Mylopoulos</keyname><forenames>John</forenames></author><author><keyname>Faulkner</keyname><forenames>Stephane</forenames></author></authors><title>Towards a Theory of Requirements Elicitation: Acceptability Condition
  for the Relative Validity of Requirements</title><categories>cs.SE</categories><acm-class>D.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A requirements engineering artifact is valid relative to the stakeholders of
the system-to-be if they agree on the content of that artifact. Checking
relative validity involves a discussion between the stakeholders and the
requirements engineer. This paper proposes (i) a language for the
representation of information exchanged in a discussion about the relative
validity of an artifact; (ii) the acceptability condition, which, when it
verifies in a discussion captured in the proposed language, signals that the
relative validity holds for the discussed artifact and for the participants in
the discussion; and (iii) reasoning procedures to automatically check the
acceptability condition in a discussions captured by the proposed language.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0926</identifier>
 <datestamp>2009-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0926</id><created>2009-02-05</created><authors><author><keyname>Ariba</keyname><forenames>Yassine</forenames><affiliation>LAAS</affiliation></author><author><keyname>Gouaisbaut</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>LAAS</affiliation></author><author><keyname>Rahme</keyname><forenames>Sandy</forenames><affiliation>LAAS</affiliation></author><author><keyname>Labit</keyname><forenames>Yann</forenames><affiliation>LAAS</affiliation></author></authors><title>Robust control tools for traffic monitoring in TCP/AQM networks</title><categories>cs.NI</categories><proxy>ccsd hal-00357761</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Several studies have considered control theory tools for traffic control in
communication networks, as for example the congestion control issue in IP
(Internet Protocol) routers. In this paper, we propose to design a linear
observer for time-delay systems to address the traffic monitoring issue in
TCP/AQM (Transmission Control Protocol/Active Queue Management) networks. Due
to several propagation delays and the queueing delay, the set TCP/AQM is
modeled as a multiple delayed system of a particular form. Hence, appropriate
robust control tools as quadratic separation are adopted to construct a delay
dependent observer for TCP flows estimation. Note that, the developed mechanism
enables also the anomaly detection issue for a class of DoS (Denial of Service)
attacks. At last, simulations via the network simulator NS-2 and an emulation
experiment validate the proposed methodology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0947</identifier>
 <datestamp>2010-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0947</id><created>2009-02-05</created><updated>2010-04-12</updated><authors><author><keyname>Lapidoth</keyname><forenames>Amos</forenames></author><author><keyname>Wigger</keyname><forenames>Michele A.</forenames></author></authors><title>On the Gaussian MAC with Imperfect Feedback</title><categories>cs.IT math.IT</categories><comments>To appear in IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  New achievable rate regions are derived for the two-user additive white
Gaussian multiple-access channel with noisy feedback. The regions exhibit the
following two properties. Irrespective of the (finite) Gaussian feedback-noise
variances, the regions include rate points that lie outside the no-feedback
capacity region, and when the feedback-noise variances tend to 0 the regions
converge to the perfect-feedback capacity region. The new achievable regions
also apply to the partial-feedback setting where one of the transmitters has a
noisy feedback link and the other transmitter has no feedback at all. Again,
irrespective of the (finite) noise variance on the feedback link, the regions
include rate points that lie outside the no-feedback capacity region. Moreover,
in the case of perfect partial feedback, i.e., where the only feedback link is
noise-free, for certain channel parameters the new regions include rate points
that lie outside the Cover-Leung region. This answers in the negative the
question posed by van der Meulen as to whether the Cover-Leung region equals
the capacity region of the Gaussian multiple-access channel with perfect
partial feedback. Finally, we propose new achievable regions also for a setting
where the receiver is cognizant of the realizations of the noise sequences on
the feedback links.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0966</identifier>
 <datestamp>2009-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0966</id><created>2009-02-05</created><updated>2009-02-06</updated><authors><author><keyname>Bai</keyname><forenames>Dongwoon</forenames></author><author><keyname>Ghassemzadeh</keyname><forenames>Saeed S.</forenames></author><author><keyname>Miller</keyname><forenames>Robert R.</forenames></author><author><keyname>Tarokh</keyname><forenames>Vahid</forenames></author></authors><title>Beam Selection Gain Versus Antenna Selection Gain</title><categories>cs.IT math.IT</categories><comments>22 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider beam selection using a fixed beamforming network (FBN) at a base
station with $M$ array antennas. In our setting, a Butler matrix is deployed at
the RF stage to form $M$ beams, and then the best beam is selected for
transmission. We provide the proofs of the key properties of the noncentral
chi-square distribution and the following properties of the beam selection gain
verifying that beam selection is superior to antenna selection in Rician
channels with any $K$-factors. Furthermore, we find asymptotically tight
stochastic bounds of the beam selection gain, which yield approximate closed
form expressions of the expected selection gain and the ergodic capacity. Beam
selection has the order of growth of the ergodic capacity
$\mathnormal{\Theta}(\log(M))$ regardless of user location in contrast to
$\mathnormal{\Theta}(\log(\log(M)))$ for antenna selection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1033</identifier>
 <datestamp>2009-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1033</id><created>2009-02-06</created><authors><author><keyname>Raybaud</keyname><forenames>Sylvain</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Lavecchia</keyname><forenames>Caroline</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Langlois</keyname><forenames>David</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Sma&#xef;li</keyname><forenames>Kamel</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>New Confidence Measures for Statistical Machine Translation</title><categories>cs.CL</categories><proxy>ccsd inria-00333843</proxy><journal-ref>International Conference On Agents and Artificial Intelligence -
  ICAART 09 (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A confidence measure is able to estimate the reliability of an hypothesis
provided by a machine translation system. The problem of confidence measure can
be seen as a process of testing : we want to decide whether the most probable
sequence of words provided by the machine translation system is correct or not.
In the following we describe several original word-level confidence measures
for machine translation, based on mutual information, n-gram language model and
lexical features language model. We evaluate how well they perform individually
or together, and show that using a combination of confidence measures based on
mutual information yields a classification error rate as low as 25.1% with an
F-measure of 0.708.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1035</identifier>
 <datestamp>2009-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1035</id><created>2009-02-06</created><updated>2009-07-06</updated><authors><author><keyname>Touati</keyname><forenames>Sid</forenames><affiliation>PRISM</affiliation></author></authors><title>Towards a Statistical Methodology to Evaluate Program Speedups and their
  Optimisation Techniques</title><categories>cs.PF</categories><comments>12 pages</comments><proxy>ccsd hal-00356529</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The community of program optimisation and analysis, code performance
evaluation, parallelisation and optimising compilation has published since many
decades hundreds of research and engineering articles in major conferences and
journals. These articles study efficient algorithms, strategies and techniques
to accelerate programs execution times, or optimise other performance metrics
(MIPS, code size, energy/power, MFLOPS, etc.). Many speedups are published, but
nobody is able to reproduce them exactly. The non-reproducibility of our
research results is a dark point of the art, and we cannot be qualified as {\it
computer scientists} if we do not provide rigorous experimental methodology.
This article provides a first effort towards a correct statistical protocol for
analysing and measuring speedups. As we will see, some common mistakes are done
by the community inside published articles, explaining part of the
non-reproducibility of the results. Our current article is not sufficient by
its own to deliver a complete experimental methodology, further efforts must be
done by the community to decide about a common protocol for our future
experiences. Anyway, our community should take care about the aspect of
reproducibility of the results in the future.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1037</identifier>
 <datestamp>2009-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1037</id><created>2009-02-06</created><updated>2009-02-10</updated><authors><author><keyname>Ibrahimbegovic</keyname><forenames>A.</forenames></author><author><keyname>Knopf-Lenoir</keyname><forenames>C.</forenames></author><author><keyname>Kucerova</keyname><forenames>A.</forenames></author><author><keyname>Villon</keyname><forenames>P.</forenames></author></authors><title>Optimal design and optimal control of structures undergoing finite
  rotations and elastic deformations</title><categories>cs.NE cs.CE</categories><comments>35 pages, 11 figures</comments><acm-class>G.1.6; G.1.8</acm-class><journal-ref>International Journal for Numerical Methods in Engineering, 61
  (14), 2428-2460, 2004)</journal-ref><doi>10.1002/nme.1150</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we deal with the optimal design and optimal control of
structures undergoing large rotations. In other words, we show how to find the
corresponding initial configuration and the corresponding set of multiple load
parameters in order to recover a desired deformed configuration or some
desirable features of the deformed configuration as specified more precisely by
the objective or cost function. The model problem chosen to illustrate the
proposed optimal design and optimal control methodologies is the one of
geometrically exact beam. First, we present a non-standard formulation of the
optimal design and optimal control problems, relying on the method of Lagrange
multipliers in order to make the mechanics state variables independent from
either design or control variables and thus provide the most general basis for
developing the best possible solution procedure. Two different solution
procedures are then explored, one based on the diffuse approximation of
response function and gradient method and the other one based on genetic
algorithm. A number of numerical examples are given in order to illustrate both
the advantages and potential drawbacks of each of the presented procedures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1038</identifier>
 <datestamp>2009-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1038</id><created>2009-02-06</created><authors><author><keyname>Barbay</keyname><forenames>J&#xe9;r&#xe9;my</forenames><affiliation>DCC</affiliation></author><author><keyname>Navarro</keyname><forenames>Gonzalo</forenames><affiliation>DCC</affiliation></author></authors><title>Compressed Representations of Permutations, and Applications</title><categories>cs.DS</categories><proxy>ccsd inria-00358018</proxy><journal-ref>STACS 2009 (2009) 111-122</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We explore various techniques to compress a permutation $\pi$ over n
integers, taking advantage of ordered subsequences in $\pi$, while supporting
its application $\pi$(i) and the application of its inverse $\pi^{-1}(i)$ in
small time. Our compression schemes yield several interesting byproducts, in
many cases matching, improving or extending the best existing results on
applications such as the encoding of a permutation in order to support iterated
applications $\pi^k(i)$ of it, of integer functions, and of inverted lists and
suffix arrays.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1040</identifier>
 <datestamp>2009-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1040</id><created>2009-02-06</created><updated>2009-05-29</updated><authors><author><keyname>Courrieu</keyname><forenames>Pierre</forenames><affiliation>LPC</affiliation></author></authors><title>Fast solving of Weighted Pairing Least-Squares systems</title><categories>cs.MS cs.NE</categories><proxy>ccsd hal-00358125</proxy><journal-ref>Journal of Computational and Applied Mathematics 231, 1 (2009)
  39-48</journal-ref><doi>10.1016/j.cam.2009.01.016</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a generalization of the &quot;weighted least-squares&quot; (WLS),
named &quot;weighted pairing least-squares&quot; (WPLS), which uses a rectangular weight
matrix and is suitable for data alignment problems. Two fast solving methods,
suitable for solving full rank systems as well as rank deficient systems, are
studied. Computational experiments clearly show that the best method, in terms
of speed, accuracy, and numerical stability, is based on a special {1, 2,
3}-inverse, whose computation reduces to a very simple generalization of the
usual &quot;Cholesky factorization-backward substitution&quot; method for solving linear
systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1041</identifier>
 <datestamp>2009-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1041</id><created>2009-02-06</created><authors><author><keyname>Bienvenu</keyname><forenames>Laurent</forenames></author><author><keyname>Downey</keyname><forenames>Rod</forenames></author></authors><title>Kolmogorov Complexity and Solovay Functions</title><categories>cs.CC cs.IT math.IT math.LO</categories><proxy>ccsd inria-00359056</proxy><journal-ref>26th International Symposium on Theoretical Aspects of Computer
  Science STACS 2009 (2009) 147-158</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Solovay proved that there exists a computable upper bound f of the
prefix-free Kolmogorov complexity function K such that f (x) = K(x) for
infinitely many x. In this paper, we consider the class of computable functions
f such that K(x) &lt;= f (x)+O(1) for all x and f (x) &lt;= K(x) + O(1) for
infinitely many x, which we call Solovay functions. We show that Solovay
functions present interesting connections with randomness notions such as
Martin-L\&quot;of randomness and K-triviality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1042</identifier>
 <datestamp>2009-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1042</id><created>2009-02-06</created><authors><author><keyname>Bojanczyk</keyname><forenames>Mikolaj</forenames></author></authors><title>Weak Mso with the Unbounding Quantifier</title><categories>cs.FL cs.LO</categories><proxy>ccsd inria-00359061</proxy><journal-ref>26th International Symposium on Theoretical Aspects of Computer
  Science STACS 2009 (2009) 159-170</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new class of languages of infinite words is introduced, called the
max-regular languages, extending the class of $\omega$-regular languages. The
class has two equivalent descriptions: in terms of automata (a type of
deterministic counter automaton), and in terms of logic (weak monadic
second-order logic with a bounding quantifier). Effective translations between
the logic and automata are given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1043</identifier>
 <datestamp>2011-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1043</id><created>2009-02-06</created><updated>2011-03-01</updated><authors><author><keyname>Borradaile</keyname><forenames>Glencora</forenames><affiliation>MIT</affiliation></author><author><keyname>Demaine</keyname><forenames>Erik D.</forenames><affiliation>MIT</affiliation></author><author><keyname>Tazari</keyname><forenames>Siamak</forenames></author></authors><title>Polynomial-Time Approximation Schemes for Subset-Connectivity Problems
  in Bounded-Genus Graphs</title><categories>cs.DM cs.DS</categories><comments>Updated version from the conference (STACS) version</comments><proxy>ccsd inria-00359068</proxy><journal-ref>26th International Symposium on Theoretical Aspects of Computer
  Science STACS 2009 (2009) 171-182</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the first polynomial-time approximation schemes (PTASes) for the
following subset-connectivity problems in edge-weighted graphs of bounded
genus: Steiner tree, low-connectivity survivable-network design, and subset
TSP. The schemes run in O(n log n) time for graphs embedded on both orientable
and non-orientable surfaces. This work generalizes the PTAS frameworks of
Borradaile, Klein, and Mathieu from planar graphs to bounded-genus graphs: any
future problems shown to admit the required structure theorem for planar graphs
will similarly extend to bounded-genus graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1045</identifier>
 <datestamp>2009-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1045</id><created>2009-02-06</created><updated>2009-02-09</updated><authors><author><keyname>Iordjev</keyname><forenames>Krassimir Yankov</forenames></author><author><keyname>Kovachev</keyname><forenames>Dimiter Stoichkov</forenames></author></authors><title>On finding a particular class of combinatorial identities</title><categories>cs.DM</categories><comments>5 pages</comments><acm-class>G.2.1</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this paper, a class of combinatorial identities is proved. A method is
used which is based on the following rule: counting elements of a given set in
two ways and making equal the obtained results. This rule is known as &quot;counting
in two ways&quot;. The principle of inclusion and exclusion is used for obtaining a
class of (0,1)-matrices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1047</identifier>
 <datestamp>2009-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1047</id><created>2009-02-06</created><authors><author><keyname>Bousquet</keyname><forenames>Nicolas</forenames><affiliation>ENS Cachan</affiliation></author><author><keyname>Daligault</keyname><forenames>Jean</forenames><affiliation>LIRMM</affiliation></author><author><keyname>Thomasse</keyname><forenames>Stephan</forenames><affiliation>LIRMM</affiliation></author><author><keyname>Yeo</keyname><forenames>Anders</forenames></author></authors><title>A Polynomial Kernel For Multicut In Trees</title><categories>cs.DM</categories><proxy>ccsd inria-00359171</proxy><journal-ref>26th International Symposium on Theoretical Aspects of Computer
  Science STACS 2009 (2009) 183-194</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The MULTICUT IN TREES problem consists in deciding, given a tree, a set of
requests (i.e. paths in the tree) and an integer k, whether there exists a set
of k edges cutting all the requests. This problem was shown to be FPT by Guo
and Niedermeyer. They also provided an exponential kernel. They asked whether
this problem has a polynomial kernel. This question was also raised by Fellows.
We show that MULTICUT IN TREES has a polynomial kernel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1048</identifier>
 <datestamp>2009-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1048</id><created>2009-02-06</created><authors><author><keyname>Bassino</keyname><forenames>Fr&#xe9;d&#xe9;rique</forenames><affiliation>LIPN</affiliation></author><author><keyname>David</keyname><forenames>Julien</forenames><affiliation>IGM</affiliation></author><author><keyname>Nicaud</keyname><forenames>Cyril</forenames><affiliation>IGM</affiliation></author></authors><title>On the Average Complexity of Moore's State Minimization Algorithm</title><categories>cs.DS cs.CC</categories><proxy>ccsd inria-00359162</proxy><journal-ref>26th International Symposium on Theoretical Aspects of Computer
  Science STACS 2009 (2009) 123-134</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that, for any arbitrary finite alphabet and for the uniform
distribution over deterministic and accessible automata with n states, the
average complexity of Moore's state minimization algorithm is in O(n log n).
Moreover this bound is tight in the case of unary utomata.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1080</identifier>
 <datestamp>2009-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1080</id><created>2009-02-06</created><authors><author><keyname>Jeudy</keyname><forenames>Baptiste</forenames><affiliation>LAHC</affiliation></author><author><keyname>Largeron</keyname><forenames>Christine</forenames><affiliation>LAHC</affiliation></author><author><keyname>Jacquenet</keyname><forenames>Fran&#xe7;ois</forenames><affiliation>LAHC</affiliation></author></authors><title>A Model for Managing Collections of Patterns</title><categories>cs.AI</categories><proxy>ccsd ujm-00160027</proxy><journal-ref>ACM Symposium on Applied Computing, Seoul : Cor\'ee, R\'epublique
  de (2007)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Data mining algorithms are now able to efficiently deal with huge amount of
data. Various kinds of patterns may be discovered and may have some great
impact on the general development of knowledge. In many domains, end users may
want to have their data mined by data mining tools in order to extract patterns
that could impact their business. Nevertheless, those users are often
overwhelmed by the large quantity of patterns extracted in such a situation.
Moreover, some privacy issues, or some commercial one may lead the users not to
be able to mine the data by themselves. Thus, the users may not have the
possibility to perform many experiments integrating various constraints in
order to focus on specific patterns they would like to extract. Post processing
of patterns may be an answer to that drawback. Thus, in this paper we present a
framework that could allow end users to manage collections of patterns. We
propose to use an efficient data structure on which some algebraic operators
may be used in order to retrieve or access patterns in pattern bases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1104</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1104</id><created>2009-02-06</created><updated>2011-12-20</updated><authors><author><keyname>Banerji</keyname><forenames>Anirban</forenames></author><author><keyname>Magarkar</keyname><forenames>Aniket</forenames></author></authors><title>How happy is your web browsing? A model to quantify satisfaction of an
  Internet user, searching for desired information</title><categories>cs.HC</categories><journal-ref>Physica A: Statistical Mechanics and its Applications, 391:
  4215-4224, 2012</journal-ref><doi>10.1016/j.physa.2012.02.002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We feel happy when web-browsing operations provide us with necessary
information; otherwise, we feel bitter. How to measure this happiness (or
bitterness)? How does the profile of happiness grow and decay during the course
of web-browsing? We propose a probabilistic framework that models evolution of
user satisfaction, on top of his/her continuous frustration at not finding the
required information. It is found that the cumulative satisfaction profile of a
web-searching individual can be modeled effectively as the sum of random number
of random terms, where each term is mutually independent random variable,
originating from 'memoryless' Poisson flow. Evolution of satisfaction over the
entire time interval of user's browsing was modeled with auto-correlation
analysis. A utilitarian marker, magnitude of greater than unity of which
describe happy web-searching operations; and an empirical limit that connects
user's satisfaction with his frustration level - are proposed too. Presence of
pertinent information in the very first page of a web-site and magnitude of the
decay parameter of user satisfaction (frustration, irritation etc.), are found
to be two key aspects that dominate web-browser's psychology. The proposed
model employed different combination of decay parameter, searching time and
number of helpful web-sites. Obtained results are found to match the results
from three real-life case-studies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1169</identifier>
 <datestamp>2009-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1169</id><created>2009-02-06</created><authors><author><keyname>Gupta</keyname><forenames>Gagan Raj</forenames></author><author><keyname>Sanghavi</keyname><forenames>Sujay</forenames></author><author><keyname>Shroff</keyname><forenames>Ness B.</forenames></author></authors><title>Node Weighted Scheduling</title><categories>cs.NI cs.PF</categories><comments>To appear in Sigmetrics 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a new class of online policies for scheduling in
input-buffered crossbar switches. Our policies are throughput optimal for a
large class of arrival processes which satisfy strong-law of large numbers.
Given an initial configuration and no further arrivals, our policies drain all
packets in the system in the minimal amount of time (providing an online
alternative to the batch approach based on Birkhoff-VonNeumann decompositions).
We show that it is possible for policies in our class to be throughput optimal
even if they are not constrained to be maximal in every time slot.
  Most algorithms for switch scheduling take an edge based approach; in
contrast, we focus on scheduling (a large enough set of) the most congested
ports. This alternate approach allows for lower-complexity algorithms, and also
requires a non-standard technique to prove throughput-optimality. One algorithm
in our class, Maximum Vertex-weighted Matching (MVM) has worst-case complexity
similar to Max-size Matching, and in simulations shows slightly better delay
performance than Max-(edge)weighted-Matching (MWM).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1179</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1179</id><created>2009-02-08</created><updated>2009-02-27</updated><authors><author><keyname>Grohe</keyname><forenames>Martin</forenames></author><author><keyname>Schwandtner</keyname><forenames>Goetz</forenames></author></authors><title>The Complexity of Datalog on Linear Orders</title><categories>cs.LO cs.CC cs.DB</categories><comments>21 pages</comments><acm-class>F.4.1; D.3.2; H.2.3</acm-class><journal-ref>Logical Methods in Computer Science, Volume 5, Issue 1 (February
  27, 2009) lmcs:811</journal-ref><doi>10.2168/LMCS-5(1:4)2009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the program complexity of datalog on both finite and infinite linear
orders. Our main result states that on all linear orders with at least two
elements, the nonemptiness problem for datalog is EXPTIME-complete. While
containment of the nonemptiness problem in EXPTIME is known for finite linear
orders and actually for arbitrary finite structures, it is not obvious for
infinite linear orders. It sharply contrasts the situation on other infinite
structures; for example, the datalog nonemptiness problem on an infinite
successor structure is undecidable. We extend our upper bound results to
infinite linear orders with constants.
  As an application, we show that the datalog nonemptiness problem on Allen's
interval algebra is EXPTIME-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1182</identifier>
 <datestamp>2009-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1182</id><created>2009-02-06</created><authors><author><keyname>de G&#xe9;vigney</keyname><forenames>Olivier Durand</forenames></author><author><keyname>Meunier</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames></author><author><keyname>Popa</keyname><forenames>Christian</forenames></author><author><keyname>Reygner</keyname><forenames>Julien</forenames></author><author><keyname>Romero</keyname><forenames>Ayrin</forenames></author></authors><title>Directed paths on a tree: coloring, multicut and kernel</title><categories>cs.DM</categories><acm-class>G.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the present paper, we study algorithmic questions for the arc-intersection
graph of directed paths on a tree. Such graphs are known to be perfect (proved
by Monma and Wei in 1986). We present faster algorithms than all previously
known algorithms for solving the minimum coloring and the minimum clique cover
problems. They both run in $O(np)$ time, where $n$ is the number of vertices of
the tree and $p$ the number of paths. Another result is a polynomial algorithm
computing a kernel in the intersection graph, when its edges are oriented in a
clique-acyclic way. Indeed, such a kernel exists for any perfect graph by a
theorem of Boros and Gurvich. Such algorithms computing kernels are known only
for few classes of perfect graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1220</identifier>
 <datestamp>2009-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1220</id><created>2009-02-06</created><authors><author><keyname>Sankar</keyname><forenames>Lalitha</forenames></author><author><keyname>Liang</keyname><forenames>Yingbin</forenames></author><author><keyname>Mandayam</keyname><forenames>Narayan</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Opportunistic Communications in Fading Multiaccess Relay Channels</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE Trans. on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of optimal resource allocation is studied for ergodic fading
orthogonal multiaccess relay channels (MARCs) in which the users (sources)
communicate with a destination with the aid of a half-duplex relay that
transmits on a channel orthogonal to that used by the transmitting sources.
Under the assumption that the instantaneous fading state information is
available at all nodes, the maximum sum-rate and the optimal user and relay
power allocations (policies) are developed for a decode-and-forward (DF) relay.
With the observation that a DF relay results in two multiaccess channels, one
at the relay and the other at the destination, a single known lemma on the
sum-rate of two intersecting polymatroids is used to determine the DF sum-rate
and the optimal user and relay policies. The lemma also enables a broad
topological classification of fading MARCs into one of three types. The first
type is the set of partially clustered MARCs where a user is clustered either
with the relay or with the destination such that the users waterfill on their
bottle-neck links to the distant receiver. The second type is the set of
clustered MARCs where all users are either proximal to the relay or to the
destination such that opportunistic multiuser scheduling to one of the
receivers is optimal. The third type consists of arbitrarily clustered MARCs
which are a combination of the first two types, and for this type it is shown
that the optimal policies are opportunistic non-waterfilling solutions. The
analysis is extended to develop the rate region of a K-user orthogonal
half-duplex MARC. Finally, cutset outer bounds are used to show that DF
achieves the capacity region for a class of clustered orthogonal half-duplex
MARCs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1227</identifier>
 <datestamp>2009-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1227</id><created>2009-02-07</created><updated>2009-12-11</updated><authors><author><keyname>Achar</keyname><forenames>Avinash</forenames></author><author><keyname>Laxman</keyname><forenames>Srivatsan</forenames></author><author><keyname>Viswanathan</keyname><forenames>Raajay</forenames></author><author><keyname>Sastry</keyname><forenames>P. S.</forenames></author></authors><title>Discovering general partial orders in event streams</title><categories>cs.AI cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Frequent episode discovery is a popular framework for pattern discovery in
event streams. An episode is a partially ordered set of nodes with each node
associated with an event type. Efficient (and separate) algorithms exist for
episode discovery when the associated partial order is total (serial episode)
and trivial (parallel episode). In this paper, we propose efficient algorithms
for discovering frequent episodes with general partial orders. These algorithms
can be easily specialized to discover serial or parallel episodes. Also, the
algorithms are flexible enough to be specialized for mining in the space of
certain interesting subclasses of partial orders. We point out that there is an
inherent combinatorial explosion in frequent partial order mining and most
importantly, frequency alone is not a sufficient measure of interestingness. We
propose a new interestingness measure for general partial order episodes and a
discovery method based on this measure, for filtering out uninteresting partial
orders. Simulations demonstrate the effectiveness of our algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1232</identifier>
 <datestamp>2009-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1232</id><created>2009-02-07</created><authors><author><keyname>Chakraborty</keyname><forenames>Soubhik</forenames></author></authors><title>On Why and What of Randomness</title><categories>cs.OH</categories><comments>This article will definitely assist both teaching and research(esp on
  the interface of statistics and computing)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has several objectives. First, it separates randomness from
lawlessness and shows why even genuine randomness does not imply lawlessness.
Second, it separates the question -why should I call a phenomenon random? (and
answers it in part one) from the patent question -What is a random sequence?
-for which the answer lies in Kolmogorov complexity (which is explained in part
two). While answering the first question the note argues why there should be
four motivating factors for calling a phenomenon random: ontic, epistemic,
pseudo and telescopic, the first two depicting genuine randomness and the last
two false. Third, ontic and epistemic randomness have been distinguished from
ontic and epistemic probability. Fourth, it encourages students to be applied
statisticians and advises against becoming armchair theorists but this is
interestingly achieved by a straight application of telescopic randomness.
Overall, it tells (the teacher) not to jump to probability without explaining
randomness properly first and similarly advises the students to read (and
understand) randomness minutely before taking on probability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1253</identifier>
 <datestamp>2009-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1253</id><created>2009-02-07</created><authors><author><keyname>Boyer</keyname><forenames>Laurent</forenames><affiliation>LM-Savoie</affiliation></author><author><keyname>Theyssier</keyname><forenames>Guillaume</forenames><affiliation>LM-Savoie</affiliation></author></authors><title>On Local Symmetries And Universality In Cellular Autmata</title><categories>cs.DM math.DS</categories><proxy>ccsd inria-00359174</proxy><journal-ref>26th International Symposium on Theoretical Aspects of Computer
  Science STACS 2009 (2009) 195-206</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cellular automata (CA) are dynamical systems defined by a finite local rule
but they are studied for their global dynamics. They can exhibit a wide range
of complex behaviours and a celebrated result is the existence of
(intrinsically) universal CA, that is CA able to fully simulate any other CA.
In this paper, we show that the asymptotic density of universal cellular
automata is 1 in several families of CA defined by local symmetries. We extend
results previously established for captive cellular automata in two significant
ways. First, our results apply to well-known families of CA (e.g. the family of
outer-totalistic CA containing the Game of Life) and, second, we obtain such
density results with both increasing number of states and increasing
neighbourhood. Moreover, thanks to universality-preserving encodings, we show
that the universality problem remains undecidable in some of those families.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1254</identifier>
 <datestamp>2009-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1254</id><created>2009-02-07</created><authors><author><keyname>Cheraghchi</keyname><forenames>Mahdi</forenames><affiliation>EPFL</affiliation></author><author><keyname>Shokrollahi</keyname><forenames>Amin</forenames><affiliation>EPFL</affiliation></author></authors><title>Almost-Uniform Sampling of Points on High-Dimensional Algebraic
  Varieties</title><categories>cs.DS cs.CC</categories><proxy>ccsd inria-00359299</proxy><journal-ref>26th International Symposium on Theoretical Aspects of Computer
  Science STACS 2009 (2009) 277-288</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of uniform sampling of points on an algebraic
variety. Specifically, we develop a randomized algorithm that, given a small
set of multivariate polynomials over a sufficiently large finite field,
produces a common zero of the polynomials almost uniformly at random. The
statistical distance between the output distribution of the algorithm and the
uniform distribution on the set of common zeros is polynomially small in the
field size, and the running time of the algorithm is polynomial in the
description of the polynomials and their degrees provided that the number of
the polynomials is a constant.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1255</identifier>
 <datestamp>2009-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1255</id><created>2009-02-07</created><updated>2009-02-17</updated><authors><author><keyname>Chakraborty</keyname><forenames>Sourav</forenames></author><author><keyname>Fischer</keyname><forenames>Eldar</forenames></author><author><keyname>Matsliah</keyname><forenames>Arie</forenames></author><author><keyname>Yuster</keyname><forenames>Raphael</forenames></author></authors><title>Hardness and Algorithms for Rainbow Connectivity</title><categories>cs.CC cs.DM</categories><proxy>ccsd inria-00359276</proxy><journal-ref>26th International Symposium on Theoretical Aspects of Computer
  Science STACS 2009 (2009) 243-254</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An edge-colored graph G is rainbow connected if any two vertices are
connected by a path whose edges have distinct colors. The rainbow connectivity
of a connected graph G, denoted rc(G), is the smallest number of colors that
are needed in order to make G rainbow connected. In addition to being a natural
combinatorial problem, the rainbow connectivity problem is motivated by
applications in cellular networks. In this paper we give the first proof that
computing rc(G) is NP-Hard. In fact, we prove that it is already NP-Complete to
decide if rc(G) = 2, and also that it is NP-Complete to decide whether a given
edge-colored (with an unbounded number of colors) graph is rainbow connected.
On the positive side, we prove that for every $\epsilon$ &gt; 0, a connected graph
with minimum degree at least $\epsilon n$ has bounded rainbow connectivity,
where the bound depends only on $\epsilon$, and the corresponding coloring can
be constructed in polynomial time. Additional non-trivial upper bounds, as well
as open problems and conjectures are also pre sented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1256</identifier>
 <datestamp>2009-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1256</id><created>2009-02-07</created><authors><author><keyname>Bulatov</keyname><forenames>Andrei A.</forenames></author><author><keyname>Dalmau</keyname><forenames>Victor</forenames></author><author><keyname>Grohe</keyname><forenames>Martin</forenames></author><author><keyname>Marx</keyname><forenames>Daniel</forenames></author></authors><title>Enumerating Homomorphisms</title><categories>cs.CC cs.LO</categories><proxy>ccsd inria-00359270</proxy><journal-ref>26th International Symposium on Theoretical Aspects of Computer
  Science STACS 2009 (2009) 231-242</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The homomorphism problem for relational structures is an abstract way of
formulating constraint satisfaction problems (CSP) and various problems in
database theory. The decision version of the homomorphism problem received a
lot of attention in literature; in particular, the way the graph-theoretical
structure of the variables and constraints influences the complexity of the
problem is intensively studied. Here we study the problem of enumerating all
the solutions with polynomial delay from a similar point of view. It turns out
that the enumeration problem behaves very differently from the decision
version. We give evidence that it is unlikely that a characterization result
similar to the decision version can be obtained. Nevertheless, we show
nontrivial cases where enumeration can be done with polynomial delay.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1257</identifier>
 <datestamp>2010-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1257</id><created>2009-02-07</created><authors><author><keyname>Hirschowitz</keyname><forenames>Tom</forenames><affiliation>LM-Savoie</affiliation></author><author><keyname>Leroy</keyname><forenames>Xavier</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Wells</keyname><forenames>J. B.</forenames></author></authors><title>Compilation of extended recursion in call-by-value functional languages</title><categories>cs.PL</categories><comments>62 pages, uses pic</comments><proxy>ccsd hal-00359213</proxy><journal-ref>Higher-Order and Symbolic Computation 22, 1 (2009) 3-66</journal-ref><doi>10.1007/s10990-009-9042-z</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper formalizes and proves correct a compilation scheme for
mutually-recursive definitions in call-by-value functional languages. This
scheme supports a wider range of recursive definitions than previous methods.
We formalize our technique as a translation scheme to a lambda-calculus
featuring in-place update of memory blocks, and prove the translation to be
correct.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1258</identifier>
 <datestamp>2009-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1258</id><created>2009-02-07</created><authors><author><keyname>Jeudy</keyname><forenames>Baptiste</forenames><affiliation>LAHC</affiliation></author><author><keyname>Rioult</keyname><forenames>Fran&#xe7;ois</forenames><affiliation>GREYC</affiliation></author></authors><title>Extraction de concepts sous contraintes dans des donn\'ees d'expression
  de g\`enes</title><categories>cs.LG</categories><proxy>ccsd hal-00359222</proxy><journal-ref>Conf\'erence sur l'apprentissage automatique, Nice : France (2005)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a technique to extract constrained formal concepts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1259</identifier>
 <datestamp>2009-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1259</id><created>2009-02-07</created><authors><author><keyname>Jeudy</keyname><forenames>Baptiste</forenames><affiliation>LAHC, EURISE</affiliation></author><author><keyname>Rioult</keyname><forenames>Fran&#xe7;ois</forenames><affiliation>GREYC</affiliation></author></authors><title>Database Transposition for Constrained (Closed) Pattern Mining</title><categories>cs.LG</categories><proxy>ccsd ujm-00359284</proxy><journal-ref>Knowledge Discovery in Inductive Databases, Third International
  Workshop, KDID 2004, Pisa, Italy, Septembre 2004, Revised Selected and
  Invited Papers, Bart Goethals, Arno Siebes (Ed.) (2004) 89-107</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, different works proposed a new way to mine patterns in databases
with pathological size. For example, experiments in genome biology usually
provide databases with thousands of attributes (genes) but only tens of objects
(experiments). In this case, mining the &quot;transposed&quot; database runs through a
smaller search space, and the Galois connection allows to infer the closed
patterns of the original database. We focus here on constrained pattern mining
for those unusual databases and give a theoretical framework for database and
constraint transposition. We discuss the properties of constraint transposition
and look into classical constraints. We then address the problem of generating
the closed patterns of the original database satisfying the constraint,
starting from those mined in the &quot;transposed&quot; database. Finally, we show how to
generate all the patterns satisfying the constraint from the closed ones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1260</identifier>
 <datestamp>2009-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1260</id><created>2009-02-07</created><authors><author><keyname>Chan</keyname><forenames>Ho-Leung</forenames></author><author><keyname>Edmonds</keyname><forenames>Jeff</forenames></author><author><keyname>Lam</keyname><forenames>Tak-Wah</forenames></author><author><keyname>Lee</keyname><forenames>Lap-Kei</forenames></author><author><keyname>Marchetti-Spaccamela</keyname><forenames>Alberto</forenames></author><author><keyname>Pruhs</keyname><forenames>Kirk</forenames></author></authors><title>Nonclairvoyant Speed Scaling for Flow and Energy</title><categories>cs.DS</categories><proxy>ccsd inria-00359287</proxy><journal-ref>26th International Symposium on Theoretical Aspects of Computer
  Science STACS 2009 (2009) 255-264</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study online nonclairvoyant speed scaling to minimize total flow time plus
energy. We first consider the traditional model where the power function is P
(s) = s\^\propto. We give a nonclairvoyant algorithm that is shown to be
O(\propto\^3)-competitive. We then show an \Omega(\propto\^(1/3-\epsilon))
lower bound on the competitive ratio of any nonclairvoyant algorithm. We also
show that there are power functions for which no nonclairvoyant algorithm can
be O(1)-competitive.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1261</identifier>
 <datestamp>2009-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1261</id><created>2009-02-07</created><authors><author><keyname>Chepoi</keyname><forenames>Victor</forenames><affiliation>LIF</affiliation></author><author><keyname>Seston</keyname><forenames>M.</forenames><affiliation>LIF</affiliation></author></authors><title>An Approximation Algorithm for l\infty-Fitting Robinson Structures to
  Distances</title><categories>cs.DS cs.CC</categories><proxy>ccsd inria-00359296</proxy><journal-ref>26th International Symposium on Theoretical Aspects of Computer
  Science STACS 2009 (2009) 265-276</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a factor 16 approximation algorithm for the
following NP-hard distance fitting problem: given a finite set X and a distance
d on X, find a Robinsonian distance dR on X minimizing the l\infty-error ||d -
dR||\infty = maxx,y\epsilonX {|d(x, y) - dR(x, y)|}. A distance dR on a finite
set X is Robinsonian if its matrix can be symmetrically permuted so that its
elements do not decrease when moving away from the main diagonal along any row
or column. Robinsonian distances generalize ultrametrics, line distances and
occur in the seriation problems and in classification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1267</identifier>
 <datestamp>2009-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1267</id><created>2009-02-07</created><updated>2009-06-05</updated><authors><author><keyname>Wang</keyname><forenames>Zilong</forenames></author><author><keyname>Gong</keyname><forenames>Guang</forenames></author></authors><title>A Note on the Diagonalization of the Discrete Fourier Transform</title><categories>cs.IT cs.DM math.IT math.RT</categories><comments>12 pages, accepted by Applied and Computational Harmonic Analysis</comments><doi>10.1016/j.acha.2009.05.003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Following the approach developed by S. Gurevich and R. Hadani, an analytical
formula of the canonical basis of the DFT is given for the case $N=p$ where $p$
is a prime number and $p\equiv 1$ (mod 4).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1275</identifier>
 <datestamp>2009-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1275</id><created>2009-02-07</created><authors><author><keyname>Harsini</keyname><forenames>Jalil Seifali</forenames></author><author><keyname>Lahouti</keyname><forenames>Farshad</forenames></author></authors><title>Delay Performance Optimization for Multiuser Diversity Systems with
  Bursty-Traffic and Heterogeneous Wireless Links</title><categories>cs.IT math.IT</categories><comments>6 pages, 4 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a cross-layer approach for optimizing the delay
performance of a multiuser diversity system with heterogeneous block-fading
channels and a delay-sensitive bursty-traffic. We consider the downlink of a
time-slotted multiuser system employing opportunistic scheduling with fair
performance at the medium access (MAC) layer and adaptive modulation and coding
(AMC) with power control at the physical layer. Assuming individual user
buffers which temporarily store the arrival traffic of users at the MAC layer,
we first present a large deviations based statistical model to evaluate the
delay-bound violation of packets in the user buffers. Aiming at minimizing the
delay probability of the individual users, we then optimize the AMC and power
control module subject to a target packet-error rate constraint. In the case of
a quantized feedback channel, we also present a constant-power AMC based
opportunistic scheduling scheme. Numerical and simulation results are provided
to evaluate the delay performance of the proposed adaptation schemes in a
multiuser setup.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1278</identifier>
 <datestamp>2009-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1278</id><created>2009-02-08</created><authors><author><keyname>Aly</keyname><forenames>Salah A.</forenames></author><author><keyname>Kong</keyname><forenames>Zhenning</forenames></author><author><keyname>Soljanin</keyname><forenames>Emina</forenames></author></authors><title>Fountain Codes Based Distributed Storage Algorithms for Large-scale
  Wireless Sensor Networks</title><categories>cs.IT cs.DS cs.NI math.IT</categories><comments>A method to estimate the total number of nodes in a graph is
  presented in this 12 pages</comments><journal-ref>Proc. IEEE/ACM IPSN 2008, pp 171-182</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider large-scale sensor networks with n nodes, out of which k are in
possession, (e.g., have sensed or collected in some other way) k information
packets. In the scenarios in which network nodes are vulnerable because of, for
example, limited energy or a hostile environment, it is desirable to
disseminate the acquired information throughout the network so that each of the
n nodes stores one (possibly coded) packet and the original k source packets
can be recovered later in a computationally simple way from any (1 + \epsilon)k
nodes for some small \epsilon &gt; 0.
  We developed two distributed algorithms for solving this problem based on
simple random walks and Fountain codes. Unlike all previously developed
schemes, our solution is truly distributed, that is, nodes do not know n, k or
connectivity in the network, except in their own neighborhoods, and they do not
maintain any routing tables. In the first algorithm, all the sensors have the
knowledge of n and k. In the second algorithm, each sensor estimates these
parameters through the random walk dissemination. We present analysis of the
communication/transmission and encoding/decoding complexity of these two
algorithms, and provide extensive simulation results as well
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1284</identifier>
 <datestamp>2009-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1284</id><created>2009-02-07</created><updated>2009-06-02</updated><authors><author><keyname>Hsu</keyname><forenames>Daniel</forenames></author><author><keyname>Kakade</keyname><forenames>Sham M.</forenames></author><author><keyname>Langford</keyname><forenames>John</forenames></author><author><keyname>Zhang</keyname><forenames>Tong</forenames></author></authors><title>Multi-Label Prediction via Compressed Sensing</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider multi-label prediction problems with large output spaces under
the assumption of output sparsity -- that the target (label) vectors have small
support. We develop a general theory for a variant of the popular error
correcting output code scheme, using ideas from compressed sensing for
exploiting this sparsity. The method can be regarded as a simple reduction from
multi-label regression problems to binary regression problems. We show that the
number of subproblems need only be logarithmic in the total number of possible
labels, making this approach radically more efficient than others. We also
state and prove robustness guarantees for this method in the form of regret
transform bounds (in general), and also provide a more detailed analysis for
the linear prediction setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1299</identifier>
 <datestamp>2013-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1299</id><created>2009-02-08</created><authors><author><keyname>Kobayashi</keyname><forenames>Hirotada</forenames></author><author><keyname>Gall</keyname><forenames>Francois Le</forenames></author><author><keyname>Nishimura</keyname><forenames>Harumichi</forenames></author><author><keyname>Roetteler</keyname><forenames>Martin</forenames></author></authors><title>Perfect Quantum Network Communication Protocol Based on Classical
  Network Coding</title><categories>quant-ph cs.IT math.IT</categories><comments>LaTeX2e, 10 pages, 2 figures</comments><journal-ref>Proceedings 2010 IEEE International Symposium on Information
  Theory (ISIT 2010), pp. 2686-2690</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers a problem of quantum communication between parties that
are connected through a network of quantum channels. The model in this paper
assumes that there is no prior entanglement shared among any of the parties,
but that classical communication is free. The task is to perfectly transfer an
unknown quantum state from a source subsystem to a target subsystem, where both
source and target are formed by ordered sets of some of the nodes. It is proved
that a lower bound of the rate at which this quantum communication task is
possible is given by the classical min-cut max-flow theorem of network coding,
where the capacities in question are the quantum capacities of the edges of the
network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1351</identifier>
 <datestamp>2009-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1351</id><created>2009-02-08</created><authors><author><keyname>Fern&#xe1;ndez-C&#xf3;rdoba</keyname><forenames>C.</forenames></author><author><keyname>Phelps</keyname><forenames>K. T.</forenames></author></authors><title>On the minimum distance graph of an extended Preparata code</title><categories>cs.IT cs.DM math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The minimum distance graph of an extended Preparata code P(m) has vertices
corresponding to codewords and edges corresponding to pairs of codewords that
are distance 6 apart. The clique structure of this graph is investigated and it
is established that the minimum distance graphs of two extended Preparata codes
are isomorphic if and only if the codes are equivalent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1364</identifier>
 <datestamp>2009-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1364</id><created>2009-02-09</created><authors><author><keyname>Narayanaswamy</keyname><forenames>N. S.</forenames></author><author><keyname>Sadagopan</keyname><forenames>N.</forenames></author><author><keyname>Dubey</keyname><forenames>Apoorve</forenames></author></authors><title>A Note on Contractible Edges in Chordal Graphs</title><categories>cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Contraction of an edge merges its end points into a new vertex which is
adjacent to each neighbor of the end points of the edge. An edge in a
$k$-connected graph is {\em contractible} if its contraction does not result in
a graph of lower connectivity. We characterize contractible edges in chordal
graphs using properties of tree decompositions with respect to minimal vertex
separators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1378</identifier>
 <datestamp>2009-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1378</id><created>2009-02-09</created><authors><author><keyname>Emek</keyname><forenames>Yuval</forenames></author><author><keyname>Fraigniaud</keyname><forenames>Pierre</forenames></author><author><keyname>Korman</keyname><forenames>Amos</forenames></author><author><keyname>Rosen</keyname><forenames>Adi</forenames></author></authors><title>On the Additive Constant of the k-server Work Function Algorithm</title><categories>cs.DS</categories><comments>7 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the Work Function Algorithm for the k-server problem. We show
that if the Work Function Algorithm is c-competitive, then it is also strictly
(2c)-competitive. As a consequence of [Koutsoupias and Papadimitriou, JACM
1995] this also shows that the Work Function Algorithm is strictly
(4k-2)-competitive.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1394</identifier>
 <datestamp>2010-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1394</id><created>2009-02-09</created><updated>2010-02-01</updated><authors><author><keyname>Bianchi</keyname><forenames>Giuseppe</forenames></author><author><keyname>Melazzi</keyname><forenames>Nicola Blefari</forenames></author><author><keyname>Bracciale</keyname><forenames>Lorenzo</forenames></author><author><keyname>Piccolo</keyname><forenames>Francesca Lo</forenames></author><author><keyname>Salsano</keyname><forenames>Stefano</forenames></author></authors><title>Fundamental delay bounds in peer-to-peer chunk-based real-time streaming
  systems</title><categories>cs.PF cs.MM</categories><comments>8 pages, 5 figures</comments><journal-ref>Proceedings of 21st International Teletraffic Congress (ITC 21),
  2009</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper addresses the following foundational question: what is the maximum
theoretical delay performance achievable by an overlay peer-to-peer streaming
system where the streamed content is subdivided into chunks? As shown in this
paper, when posed for chunk-based systems, and as a consequence of the
store-and-forward way in which chunks are delivered across the network, this
question has a fundamentally different answer with respect to the case of
systems where the streamed content is distributed through one or more flows
(sub-streams). To circumvent the complexity emerging when directly dealing with
delay, we express performance in term of a convenient metric, called &quot;stream
diffusion metric&quot;. We show that it is directly related to the end-to-end
minimum delay achievable in a P2P streaming network. In a homogeneous scenario,
we derive a performance bound for such metric, and we show how this bound
relates to two fundamental parameters: the upload bandwidth available at each
node, and the number of neighbors a node may deliver chunks to. In this bound,
k-step Fibonacci sequences do emerge, and appear to set the fundamental laws
that characterize the optimal operation of chunk-based systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1400</identifier>
 <datestamp>2009-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1400</id><created>2009-02-09</created><authors><author><keyname>Demaine</keyname><forenames>Erik D.</forenames><affiliation>MIT</affiliation></author><author><keyname>Hajiaghayi</keyname><forenames>Mohammadtaghi</forenames><affiliation>MIT</affiliation></author><author><keyname>Mahini</keyname><forenames>Hamid</forenames></author><author><keyname>Zadimoghaddam</keyname><forenames>Morteza</forenames></author></authors><title>The Price of Anarchy in Cooperative Network Creation Games</title><categories>cs.GT</categories><proxy>ccsd inria-00359313</proxy><journal-ref>26th International Symposium on Theoretical Aspects of Computer
  Science STACS 2009 (2009) 301-312</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In general, the games are played on a host graph, where each node is a
selfish independent agent (player) and each edge has a fixed link creation cost
\alpha. Together the agents create a network (a subgraph of the host graph)
while selfishly minimizing the link creation costs plus the sum of the
distances to all other players (usage cost). In this paper, we pursue two
important facets of the network creation game. First, we study extensively a
natural version of the game, called the cooperative model, where nodes can
collaborate and share the cost of creating any edge in the host graph. We prove
the first nontrivial bounds in this model, establishing that the price of
anarchy is polylogarithmic in n for all values of &amp;#945; in complete host
graphs. This bound is the first result of this type for any version of the
network creation game; most previous general upper bounds are polynomial in n.
Interestingly, we also show that equilibrium graphs have polylogarithmic
diameter for the most natural range of \alpha (at most n polylg n). Second, we
study the impact of the natural assumption that the host graph is a general
graph, not necessarily complete. This model is a simple example of nonuniform
creation costs among the edges (effectively allowing weights of \alpha and
\infty). We prove the first assemblage of upper and lower bounds for this
context, stablishing nontrivial tight bounds for many ranges of \alpha, for
both the unilateral and cooperative versions of network creation. In
particular, we establish polynomial lower bounds for both versions and many
ranges of \alpha, even for this simple nonuniform cost model, which sharply
contrasts the conjectured constant bounds for these games in complete (uniform)
graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1475</identifier>
 <datestamp>2009-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1475</id><created>2009-02-09</created><updated>2009-05-09</updated><authors><author><keyname>Walter</keyname><forenames>Frank E.</forenames></author><author><keyname>Battiston</keyname><forenames>Stefano</forenames></author><author><keyname>Schweitzer</keyname><forenames>Frank</forenames></author></authors><title>Personalised and Dynamic Trust in Social Networks</title><categories>cs.CY cs.IR physics.soc-ph</categories><comments>Revised, added Empirical Validation, submitted to Recommender Systems
  2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel trust metric for social networks which is suitable for
application in recommender systems. It is personalised and dynamic and allows
to compute the indirect trust between two agents which are not neighbours based
on the direct trust between agents that are neighbours. In analogy to some
personalised versions of PageRank, this metric makes use of the concept of
feedback centrality and overcomes some of the limitations of other trust
metrics.In particular, it does not neglect cycles and other patterns
characterising social networks, as some other algorithms do. In order to apply
the metric to recommender systems, we propose a way to make trust dynamic over
time. We show by means of analytical approximations and computer simulations
that the metric has the desired properties. Finally, we carry out an empirical
validation on a dataset crawled from an Internet community and compare the
performance of a recommender system using our metric to one using collaborative
filtering.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1505</identifier>
 <datestamp>2010-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1505</id><created>2009-02-09</created><updated>2009-05-21</updated><authors><author><keyname>Ye</keyname><forenames>Deping</forenames></author></authors><title>On the Bures Volume of Separable Quantum States</title><categories>quant-ph cs.IT math.FA math.IT math.MG</categories><comments>27 pages. To appear in the Journal of Mathematical Physics</comments><journal-ref>JOURNAL OF MATHEMATICAL PHYSICS 50, 083502 (2009)</journal-ref><doi>10.1063/1.3187216</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We obtain two sided estimates for the Bures volume of an arbitrary subset of
the set of $N\times N$ density matrices, in terms of the Hilbert-Schmidt volume
of that subset. For general subsets, our results are essentially optimal (for
large $N$). As applications, we derive in particular nontrivial lower and upper
bounds for the Bures volume of sets of separable states and for sets of states
with positive partial transpose.
  PACS numbers: 02.40.Ft, 03.65.Db, 03.65.Ud, 03.67.Mn
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1587</identifier>
 <datestamp>2009-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1587</id><created>2009-02-10</created><authors><author><keyname>Finkel</keyname><forenames>Alain</forenames><affiliation>LSV</affiliation></author><author><keyname>Goubault-Larrecq</keyname><forenames>Jean</forenames><affiliation>LSV</affiliation></author></authors><title>Forward analysis for WSTS, Part I: Completions</title><categories>cs.LO</categories><proxy>ccsd inria-00359699</proxy><journal-ref>26th International Symposium on Theoretical Aspects of Computer
  Science - STACS 2009 (2009) 433-444</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Well-structured transition systems provide the right foundation to compute a
finite basis of the set of predecessors of the upward closure of a state. The
dual problem, to compute a finite representation of the set of successors of
the downward closure of a state, is harder: Until now, the theoretical
framework for manipulating downward-closed sets was missing. We answer this
problem, using insights from domain theory (dcpos and ideal completions), from
topology (sobrifications), and shed new light on the notion of adequate domains
of limits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1591</identifier>
 <datestamp>2009-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1591</id><created>2009-02-10</created><updated>2009-12-22</updated><authors><author><keyname>Minero</keyname><forenames>Paolo</forenames></author><author><keyname>Kim</keyname><forenames>Young-Han</forenames></author></authors><title>Correlated Sources over Broadcast Channels</title><categories>cs.IT math.IT</categories><comments>9 pages, 1 figure. Updated version, with proofs and minor changes</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of reliable transmission of correlated sources over the broadcast
channel, originally studied by Han and Costa, is revisited. An alternative
characterization of their sufficient condition for reliable transmission is
given, which includes results of Marton for channel coding over broadcast
channels and of Gray and Wyner for distributed source coding. A
``minimalistic'' coding scheme is presented, which is based on joint typicality
encoding and decoding, without requiring the use of Cover's superposition
coding, random hashing, and common part between two sources. The analysis of
the coding scheme is also conceptually simple and relies on a new multivariate
covering lemma and an application of the Fourier--Motzkin elimination
procedure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1602</identifier>
 <datestamp>2009-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1602</id><created>2009-02-10</created><authors><author><keyname>Aubrun</keyname><forenames>Nathalie</forenames><affiliation>IGM</affiliation></author><author><keyname>Sablik</keyname><forenames>Mathieu</forenames><affiliation>LATP</affiliation></author></authors><title>An Order on Sets of Tilings Corresponding to an Order on Languages</title><categories>cs.DM</categories><proxy>ccsd inria-00359625</proxy><journal-ref>26th International Symposium on Theoretical Aspects of Computer
  Science STACS 2009 (2009) 99-110</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditionally a tiling is defined with a finite number of finite forbidden
patterns. We can generalize this notion considering any set of patterns.
Generalized tilings defined in this way can be studied with a dynamical point
of view, leading to the notion of subshift. In this article we establish a
correspondence between an order on subshifts based on dynamical transformations
on them and an order on languages of forbidden patterns based on computability
properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1604</identifier>
 <datestamp>2009-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1604</id><created>2009-02-10</created><authors><author><keyname>Baykan</keyname><forenames>Eda</forenames><affiliation>EPFL</affiliation></author><author><keyname>Henzinger</keyname><forenames>Monika</forenames><affiliation>EPFL</affiliation></author><author><keyname>Keller</keyname><forenames>Stefan F.</forenames></author><author><keyname>De Castelberg</keyname><forenames>Sebastian</forenames></author><author><keyname>Kinzler</keyname><forenames>Markus</forenames></author></authors><title>A Comparison of Techniques for Sampling Web Pages</title><categories>cs.DS</categories><proxy>ccsd inria-00359670</proxy><journal-ref>26th International Symposium on Theoretical Aspects of Computer
  Science STACS 2009 (2009) 13-30</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As the World Wide Web is growing rapidly, it is getting increasingly
challenging to gather representative information about it. Instead of crawling
the web exhaustively one has to resort to other techniques like sampling to
determine the properties of the web. A uniform random sample of the web would
be useful to determine the percentage of web pages in a specific language, on a
topic or in a top level domain. Unfortunately, no approach has been shown to
sample the web pages in an unbiased way. Three promising web sampling
algorithms are based on random walks. They each have been evaluated
individually, but making a comparison on different data sets is not possible.
We directly compare these algorithms in this paper. We performed three random
walks on the web under the same conditions and analyzed their outcomes in
detail. We discuss the strengths and the weaknesses of each algorithm and
propose improvements based on experimental results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1605</identifier>
 <datestamp>2009-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1605</id><created>2009-02-10</created><authors><author><keyname>Schweikardt</keyname><forenames>Nicole</forenames></author></authors><title>Lower Bounds for Multi-Pass Processing of Multiple Data Streams</title><categories>cs.DS</categories><proxy>ccsd inria-00359686</proxy><journal-ref>26th International Symposium on Theoretical Aspects of Computer
  Science STACS 2009 (2009) 51-62</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper gives a brief overview of computation models for data stream
processing, and it introduces a new model for multi-pass processing of multiple
streams, the so-called mp2s-automata. Two algorithms for solving the set
disjointness problem wi th these automata are presented. The main technical
contribution of this paper is the proof of a lower bound on the size of memory
and the number of heads that are required for solvin g the set disjointness
problem with mp2s-automata.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1609</identifier>
 <datestamp>2009-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1609</id><created>2009-02-10</created><authors><author><keyname>Gronemeier</keyname><forenames>Andr&#xe9;</forenames></author></authors><title>Asymptotically Optimal Lower Bounds on the NIH-Multi-Party Information</title><categories>cs.CC</categories><proxy>ccsd inria-00359840</proxy><journal-ref>26th International Symposium on Theoretical Aspects of Computer
  Science STACS 2009 (2009) 505-516</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Here we prove an asymptotically optimal lower bound on the information
complexity of the k-party disjointness function with the unique intersection
promise, an important special case of the well known disjointness problem, and
the ANDk-function in the number in the hand model. Our (n/k) bound for
disjointness improves on an earlier (n/(k log k)) bound by Chakrabarti et al.
(2003), who obtained an asymptotically tight lower bound for one-way protocols,
but failed to do so for the general case. Our result eliminates both the gap
between the upper and the lower bound for unrestricted protocols and the gap
between the lower bounds for one-way protocols and unrestricted protocols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1610</identifier>
 <datestamp>2009-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1610</id><created>2009-02-10</created><authors><author><keyname>Di Cosmo</keyname><forenames>Roberto</forenames><affiliation>PPS</affiliation></author><author><keyname>Zacchiroli</keyname><forenames>Stefano</forenames><affiliation>PPS</affiliation></author><author><keyname>Trezentos</keyname><forenames>Paulo</forenames></author></authors><title>Package upgrades in FOSS distributions: details and challenges</title><categories>cs.SE cs.OS</categories><proxy>ccsd hal-00359847</proxy><journal-ref>International Workshop On Hot Topics In Software Upgrades
  Proceedings of the 1st International Workshop on Hot Topics in Software
  Upgrades, Nashville, Tennessee : \'Etats-Unis d'Am\'erique (2008)</journal-ref><doi>10.1145/1490283.1490292</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The upgrade problems faced by Free and Open Source Software distributions
have characteristics not easily found elsewhere. We describe the structure of
packages and their role in the upgrade process. We show that state of the art
package managers have shortcomings inhibiting their ability to cope with
frequent upgrade failures. We survey current countermeasures to such failures,
argue that they are not satisfactory, and sketch alternative solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1612</identifier>
 <datestamp>2009-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1612</id><created>2009-02-10</created><authors><author><keyname>Din</keyname><forenames>Mohab Safey El</forenames><affiliation>LIP6, INRIA Rocquencourt</affiliation></author><author><keyname>Schost</keyname><forenames>&#xc9;ric</forenames></author></authors><title>A baby steps/giant steps Monte Carlo algorithm for computing roadmaps in
  smooth compact real hypersurfaces</title><categories>cs.SC</categories><proxy>ccsd inria-00359748</proxy><report-no>RR-6832</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of constructing roadmaps of real algebraic sets. The
problem was introduced by Canny to answer connectivity questions and solve
motion planning problems. Given $s$ polynomial equations with rational
coefficients, of degree $D$ in $n$ variables, Canny's algorithm has a Monte
Carlo cost of $s^n\log(s) D^{O(n^2)}$ operations in $\mathbb{Q}$; a
deterministic version runs in time $s^n \log(s) D^{O(n^4)}$. The next
improvement was due to Basu, Pollack and Roy, with an algorithm of
deterministic cost $s^{d+1} D^{O(n^2)}$ for the more general problem of
computing roadmaps of semi-algebraic sets ($d \le n$ is the dimension of an
associated object). We give a Monte Carlo algorithm of complexity
$(nD)^{O(n^{1.5})}$ for the problem of computing a roadmap of a compact
hypersurface $V$ of degree $D$ in $n$ variables; we also have to assume that
$V$ has a finite number of singular points. Even under these extra assumptions,
no previous algorithm featured a cost better than $D^{O(n^2)}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1617</identifier>
 <datestamp>2009-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1617</id><created>2009-02-10</created><updated>2009-07-29</updated><authors><author><keyname>Goel</keyname><forenames>Ashish</forenames></author><author><keyname>Kapralov</keyname><forenames>Michael</forenames></author><author><keyname>Khanna</keyname><forenames>Sanjeev</forenames></author></authors><title>Perfect Matchings in \~O(n^{1.5}) Time in Regular Bipartite Graphs</title><categories>cs.DS cs.DM</categories><comments>Added analysis of the Hopcroft-Karp algorithm on the subsampled graph</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the well-studied problem of finding a perfect matching in
$d$-regular bipartite graphs with $2n$ vertices and $m = nd$ edges. While the
best-known algorithm for general bipartite graphs (due to Hopcroft and Karp)
takes $O(m \sqrt{n})$ time, in regular bipartite graphs, a perfect matching is
known to be computable in $O(m)$ time. Very recently, the $O(m)$ bound was
improved to $O(\min\{m, \frac{n^{2.5}\ln n}{d}\})$ expected time, an expression
that is bounded by $\tilde{O}(n^{1.75})$. In this paper, we further improve
this result by giving an $O(\min\{m, \frac{n^2\ln^3 n}{d}\})$ expected time
algorithm for finding a perfect matching in regular bipartite graphs; as a
function of $n$ alone, the algorithm takes expected time $O((n\ln n)^{1.5})$.
  To obtain this result, we design and analyze a two-stage sampling scheme that
reduces the problem of finding a perfect matching in a regular bipartite graph
to the same problem on a subsampled bipartite graph with $O(n\ln n)$ edges that
has a perfect matching with high probability. The matching is then recovered
using the Hopcroft-Karp algorithm. While the standard analysis of Hopcroft-Karp
gives us an $\tilde{O}(n^{1.5})$ running time, we present a tighter analysis
for our special case that results in the stronger $\tilde{O}(\min\{m,
\frac{n^2}{d} \})$ time mentioned earlier.
  Our proof of correctness of this sampling scheme uses a new correspondence
theorem between cuts and Hall's theorem ``witnesses'' for a perfect matching in
a bipartite graph that we prove. We believe this theorem may be of independent
interest; as another example application, we show that a perfect matching in
the support of an $n \times n$ doubly stochastic matrix with $m$ non-zero
entries can be found in expected time $\tilde{O}(m + n^{1.5})$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1629</identifier>
 <datestamp>2009-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1629</id><created>2009-02-10</created><authors><author><keyname>Hrstka</keyname><forenames>O.</forenames></author><author><keyname>Kucerova</keyname><forenames>A.</forenames></author></authors><title>Improvements of real coded genetic algorithms based on differential
  operators preventing premature convergence</title><categories>cs.NE cs.AI</categories><comments>23 pages, 2 figures, 4 tables</comments><acm-class>G.1.6</acm-class><journal-ref>Advances in Engineering Software, 35 (3-4), 237-246, 2004</journal-ref><doi>10.1016/S0965-9978(03)00113-3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents several types of evolutionary algorithms (EAs) used for
global optimization on real domains. The interest has been focused on
multimodal problems, where the difficulties of a premature convergence usually
occurs. First the standard genetic algorithm (SGA) using binary encoding of
real values and its unsatisfactory behavior with multimodal problems is briefly
reviewed together with some improvements of fighting premature convergence. Two
types of real encoded methods based on differential operators are examined in
detail: the differential evolution (DE), a very modern and effective method
firstly published by R. Storn and K. Price, and the simplified real-coded
differential genetic algorithm SADE proposed by the authors. In addition, an
improvement of the SADE method, called CERAF technology, enabling the
population of solutions to escape from local extremes, is examined. All methods
are tested on an identical set of objective functions and a systematic
comparison based on a reliable methodology is presented. It is confirmed that
real coded methods generally exhibit better behavior on real domains than the
binary algorithms, even when extended by several improvements. Furthermore, the
positive influence of the differential operators due to their possibility of
self-adaptation is demonstrated. From the reliability point of view, it seems
that the real encoded differential algorithm, improved by the technology
described in this paper, is a universal and reliable method capable of solving
all proposed test problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1634</identifier>
 <datestamp>2012-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1634</id><created>2009-02-10</created><updated>2012-06-27</updated><authors><author><keyname>Guerrini</keyname><forenames>Eleonora</forenames></author><author><keyname>Sala</keyname><forenames>Massimiliano</forenames></author></authors><title>A bound on the size of linear codes</title><categories>cs.IT math.IT</categories><comments>A new version of this article is now available</comments><msc-class>11T71,</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a bound on the size of linear codes. This bound is independent of
other known bounds, e.g. the Griesmer bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1647</identifier>
 <datestamp>2009-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1647</id><created>2009-02-10</created><authors><author><keyname>Hrstka</keyname><forenames>O.</forenames></author><author><keyname>Kucerova</keyname><forenames>A.</forenames></author><author><keyname>Leps</keyname><forenames>M.</forenames></author><author><keyname>Zeman</keyname><forenames>J.</forenames></author></authors><title>A competitive comparison of different types of evolutionary algorithms</title><categories>cs.NE cs.AI</categories><comments>25 pages, 8 figures, 5 tables</comments><acm-class>G.1.6</acm-class><journal-ref>Computers &amp; Structures, 81 (18-19), 1979-1990, 2003</journal-ref><doi>10.1016/S0045-7949(03)00217-7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents comparison of several stochastic optimization algorithms
developed by authors in their previous works for the solution of some problems
arising in Civil Engineering. The introduced optimization methods are: the
integer augmented simulated annealing (IASA), the real-coded augmented
simulated annealing (RASA), the differential evolution (DE) in its original
fashion developed by R. Storn and K. Price and simplified real-coded
differential genetic algorithm (SADE). Each of these methods was developed for
some specific optimization problem; namely the Chebychev trial polynomial
problem, the so called type 0 function and two engineering problems - the
reinforced concrete beam layout and the periodic unit cell problem
respectively. Detailed and extensive numerical tests were performed to examine
the stability and efficiency of proposed algorithms. The results of our
experiments suggest that the performance and robustness of RASA, IASA and SADE
methods are comparable, while the DE algorithm performs slightly worse. This
fact together with a small number of internal parameters promotes the SADE
method as the most robust for practical use.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1661</identifier>
 <datestamp>2009-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1661</id><created>2009-02-10</created><authors><author><keyname>Cygan</keyname><forenames>Marek</forenames></author><author><keyname>Pilipczuk</keyname><forenames>Marcin</forenames></author></authors><title>Even Faster Exact Bandwidth</title><categories>cs.CC cs.DS</categories><comments>Paper submitted to Transaction on Algorithms on 5th Nov 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We deal with exact algorithms for Bandwidth, a long studied NP-hard problem.
For a long time nothing better than the trivial O*(n!) exhaustive search was
known. In 2000, Feige an Kilian came up with a O*(10^n)-time algorithm.
Recently we presented algorithm that runs in O*(5^n) time and O*(2^n) space..
  In this paper we present a major modification to our algorithm which makes it
run in O(4.83^n) time with the cost of O*(4^n) space complexity. This
modification allowed us to perform Measure &amp; Conquer analysis for the time
complexity which was not used for such types of problems before.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1665</identifier>
 <datestamp>2009-06-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1665</id><created>2009-02-10</created><authors><author><keyname>Kucerova</keyname><forenames>A.</forenames></author><author><keyname>Brancherie</keyname><forenames>D.</forenames></author><author><keyname>Ibrahimbegovic</keyname><forenames>A.</forenames></author><author><keyname>Zeman</keyname><forenames>J.</forenames></author><author><keyname>Bittnar</keyname><forenames>Z.</forenames></author></authors><title>Novel anisotropic continuum-discrete damage model capable of
  representing localized failure of massive structures. Part II: identification
  from tests under heterogeneous stress field</title><categories>cs.NE cs.CE</categories><comments>18 pages, 12 figures, 6 tables</comments><acm-class>G.1.6; G.1.8</acm-class><journal-ref>Engineering Computations, 26(1/2), 128-144, 2009</journal-ref><doi>10.1108/02644400910924834</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Part I of this paper we have presented a simple model capable of
describing the localized failure of a massive structure. In this part, we
discuss the identification of the model parameters from two kinds of
experiments: a uniaxial tensile test and a three-point bending test. The former
is used only for illustration of material parameter response dependence, and we
focus mostly upon the latter, discussing the inverse optimization problem for
which the specimen is subjected to a heterogeneous stress field.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1690</identifier>
 <datestamp>2009-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1690</id><created>2009-02-10</created><authors><author><keyname>Kucerova</keyname><forenames>A.</forenames></author><author><keyname>Leps</keyname><forenames>M.</forenames></author><author><keyname>Zeman</keyname><forenames>J.</forenames></author></authors><title>Back analysis of microplane model parameters using soft computing
  methods</title><categories>cs.NE cs.AI</categories><comments>21 pages, 27 figures, 7 tables</comments><acm-class>I.2.6</acm-class><journal-ref>CAMES: Computer Assisted Mechanics and Engineering Sciences, 14
  (2), 219-242, 2007</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new procedure based on layered feed-forward neural networks for the
microplane material model parameters identification is proposed in the present
paper. Novelties are usage of the Latin Hypercube Sampling method for the
generation of training sets, a systematic employment of stochastic sensitivity
analysis and a genetic algorithm-based training of a neural network by an
evolutionary algorithm. Advantages and disadvantages of this approach together
with possible extensions are thoroughly discussed and analyzed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1693</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1693</id><created>2009-02-10</created><updated>2010-07-21</updated><authors><author><keyname>Bl&#xe4;ser</keyname><forenames>Markus</forenames></author><author><keyname>Hoffmann</keyname><forenames>Christian</forenames></author></authors><title>Fast Evaluation of Interlace Polynomials on Graphs of Bounded Treewidth</title><categories>cs.DS</categories><comments>v4: Minor error in Lemma 5.5 fixed, Section 6.6 added, minor
  improvements. 44 pages, 14 figures</comments><acm-class>F.2.1; F.2.2; G.2.1; G.2.2; I.1.2</acm-class><journal-ref>Algorithmica, 61(1):3-35, 2011</journal-ref><doi>10.1007/s00453-010-9439-4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the multivariate interlace polynomial introduced by Courcelle
(2008), which generalizes several interlace polynomials defined by Arratia,
Bollobas, and Sorkin (2004) and by Aigner and van der Holst (2004). We present
an algorithm to evaluate the multivariate interlace polynomial of a graph with
n vertices given a tree decomposition of the graph of width k. The best
previously known result (Courcelle 2008) employs a general logical framework
and leads to an algorithm with running time f(k)*n, where f(k) is doubly
exponential in k. Analyzing the GF(2)-rank of adjacency matrices in the context
of tree decompositions, we give a faster and more direct algorithm. Our
algorithm uses 2^{3k^2+O(k)}*n arithmetic operations and can be efficiently
implemented in parallel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1700</identifier>
 <datestamp>2010-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1700</id><created>2009-02-10</created><updated>2010-06-28</updated><authors><author><keyname>Charbit</keyname><forenames>Pierre</forenames></author><author><keyname>de Montgolfier</keyname><forenames>Fabien</forenames></author><author><keyname>Raffinot</keyname><forenames>Mathieu</forenames></author></authors><title>Linear Time Split Decomposition Revisited</title><categories>cs.DM cs.DS</categories><comments>18 pages, submitted</comments><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a family F of subsets of a ground set V, its orthogonal is defined to
be the family of subsets that do not overlap any element of F.
  Using this tool we revisit the problem of designing a simple linear time
algorithm for undirected graph split (also known as 1-join) decomposition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1734</identifier>
 <datestamp>2009-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1734</id><created>2009-02-10</created><authors><author><keyname>Saeed</keyname><forenames>Seyed</forenames></author><author><keyname>Rezaei</keyname><forenames>Changiz</forenames></author><author><keyname>Gharan</keyname><forenames>Shahab Oveis</forenames></author><author><keyname>Khandani</keyname><forenames>Amir K.</forenames></author></authors><title>A New Achievable Rate for the Gaussian Parallel Relay Channel</title><categories>cs.IT math.IT</categories><comments>22 pages, 9 figures, Submitted to Transaction on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Schein and Gallager introduced the Gaussian parallel relay channel in 2000.
They proposed the Amplify-and-Forward (AF) and the Decode-and-Forward (DF)
strategies for this channel. For a long time, the best known achievable rate
for this channel was based on the AF and DF with time sharing (AF-DF).
Recently, a Rematch-and-Forward (RF) scheme for the scenario in which different
amounts of bandwidth can be assigned to the first and second hops were
proposed.
  In this paper, we propose a \emph{Combined Amplify-and-Decode Forward (CADF)}
scheme for the Gaussian parallel relay channel. We prove that the CADF scheme
always gives a better achievable rate compared to the RF scheme, when there is
a bandwidth mismatch between the first hop and the second hop. Furthermore, for
the equal bandwidth case (Schein's setup), we show that the time sharing
between the CADF and the DF schemes (CADF-DF) leads to a better achievable rate
compared to the time sharing between the RF and the DF schemes (RF-DF) as well
as the AF-DF.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1735</identifier>
 <datestamp>2009-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1735</id><created>2009-02-10</created><authors><author><keyname>Els&#xe4;sser</keyname><forenames>Robert</forenames></author><author><keyname>Sauerwald</keyname><forenames>Thomas</forenames></author></authors><title>Cover Time and Broadcast Time</title><categories>cs.DS math.PR math.ST stat.TH</categories><proxy>ccsd inria-00359667</proxy><journal-ref>26th International Symposium on Theoretical Aspects of Computer
  Science STACS 2009 (2009) 373-384</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new technique for bounding the cover time of random walks by
relating it to the runtime of randomized broadcast. In particular, we strongly
confirm for dense graphs the intuition of Chandra et al. \cite{CRRST97} that
&quot;the cover time of the graph is an appropriate metric for the performance of
certain kinds of randomized broadcast algorithms&quot;. In more detail, our results
are as follows: For any graph $G=(V,E)$ of size $n$ and minimum degree
$\delta$, we have $\mathcal{R}(G)= \Oh(\frac{|E|}{\delta} \cdot \log n)$, where
$\mathcal{R}(G)$ denotes the quotient of the cover time and broadcast time.
This bound is tight for binary trees and tight up to logarithmic factors for
many graphs including hypercubes, expanders and lollipop graphs. For any
$\delta$-regular (or almost $\delta$-regular) graph $G$ it holds that
$\mathcal{R}(G) = \Omega(\frac{\delta^2}{n} \cdot \frac{1}{\log n})$. Together
with our upper bound on $\mathcal{R}(G)$, this lower bound strongly confirms
the intuition of Chandra et al. for graphs with minimum degree $\Theta(n)$,
since then the cover time equals the broadcast time multiplied by $n$
(neglecting logarithmic factors). Conversely, for any $\delta$ we construct
almost $\delta$-regular graphs that satisfy $\mathcal{R}(G) = \Oh(\max
\{\sqrt{n},\delta \} \cdot \log^2 n)$. Since any regular expander satisfies
$\mathcal{R}(G) = \Theta(n)$, the strong relationship given above does not hold
if $\delta$ is polynomially smaller than $n$. Our bounds also demonstrate that
the relationship between cover time and broadcast time is much stronger than
the known relationships between any of them and the mixing time (or the closely
related spectral gap).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1736</identifier>
 <datestamp>2009-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1736</id><created>2009-02-10</created><updated>2009-06-26</updated><authors><author><keyname>Chabchoub</keyname><forenames>Yousra</forenames><affiliation>INRIA</affiliation></author><author><keyname>Fricker</keyname><forenames>Christine</forenames><affiliation>INRIA</affiliation></author><author><keyname>Guillemin</keyname><forenames>Fabrice</forenames><affiliation>FT R&amp;D</affiliation></author><author><keyname>Robert</keyname><forenames>Philippe</forenames><affiliation>INRIA</affiliation></author></authors><title>On the Statistical Characterization of Flows in Internet Traffic with
  Application to Sampling</title><categories>cs.NI</categories><proxy>ccsd hal-00360266</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new method of estimating some statistical characteristics of TCP flows in
the Internet is developed in this paper. For this purpose, a new set of random
variables (referred to as observables) is defined. When dealing with sampled
traffic, these observables can easily be computed from sampled data. By
adopting a convenient mouse/elephant dichotomy also dependent on traffic, it is
shown how these variables give a reliable statistical representation of the
number of packets transmitted by large flows during successive time intervals
with an appropriate duration. A mathematical framework is developed to estimate
the accuracy of the method. As an application, it is shown how one can estimate
the number of large TCP flows when only sampled traffic is available. The
algorithm proposed is tested against experimental data collected from different
types of IP networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1737</identifier>
 <datestamp>2009-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1737</id><created>2009-02-10</created><authors><author><keyname>Franceschini</keyname><forenames>Gianni</forenames></author><author><keyname>Grossi</keyname><forenames>Roberto</forenames></author><author><keyname>Muthukrishnan</keyname><forenames>S.</forenames></author></authors><title>Optimal cache-aware suffix selection</title><categories>cs.DS cs.AR</categories><proxy>ccsd inria-00359742</proxy><journal-ref>26th International Symposium on Theoretical Aspects of Computer
  Science - STACS 2009 (2009) 457-468</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given string $S[1..N]$ and integer $k$, the {\em suffix selection} problem is
to determine the $k$th lexicographically smallest amongst the suffixes $S[i...
N]$, $1 \leq i \leq N$. We study the suffix selection problem in the
cache-aware model that captures two-level memory inherent in computing systems,
for a \emph{cache} of limited size $M$ and block size $B$. The complexity of
interest is the number of block transfers. We present an optimal suffix
selection algorithm in the cache-aware model, requiring $\Thetah{N/B}$ block
transfers, for any string $S$ over an unbounded alphabet (where characters can
only be compared), under the common tall-cache assumption (i.e.
$M=\Omegah{B^{1+\epsilon}}$, where $\epsilon&lt;1$). Our algorithm beats the
bottleneck bound for permuting an input array to the desired output array,
which holds for nearly any nontrivial problem in hierarchical memory models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1786</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1786</id><created>2009-02-10</created><updated>2009-02-11</updated><authors><author><keyname>Schlegel</keyname><forenames>Christian</forenames></author><author><keyname>Zhang</keyname><forenames>Shuai</forenames></author></authors><title>On the Dynamics of the Error Floor Behavior in (Regular) LDPC Codes</title><categories>cs.IT math.IT</categories><comments>15 pages, submitted to IEEE Trans. Inf. Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is shown that dominant trapping sets of regular LDPC codes, so called
absorption sets, undergo a two-phased dynamic behavior in the iterative
message-passing decoding algorithm. Using a linear dynamic model for the
iteration behavior of these sets, it is shown that they undergo an initial
geometric growth phase which stabilizes in a final bit-flipping behavior where
the algorithm reaches a fixed point. This analysis is shown to lead to very
accurate numerical calculations of the error floor bit error rates down to
error rates that are inaccessible by simulation. The topology of the dominant
absorption sets of an example code, the IEEE 802.3an (2048,1723) regular LDPC
code, are identified and tabulated using topological relationships in
combination with search algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1790</identifier>
 <datestamp>2009-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1790</id><created>2009-02-10</created><authors><author><keyname>Ellerman</keyname><forenames>David</forenames></author></authors><title>Counting Distinctions: On the Conceptual Foundations of Shannon's
  Information Theory</title><categories>cs.IT cs.LO math.IT math.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Categorical logic has shown that modern logic is essentially the logic of
subsets (or &quot;subobjects&quot;). Partitions are dual to subsets so there is a dual
logic of partitions where a &quot;distinction&quot; [an ordered pair of distinct elements
(u,u') from the universe U ] is dual to an &quot;element&quot;. An element being in a
subset is analogous to a partition p on U making a distinction, i.e., if u and
u' were in different blocks of p. Subset logic leads to finite probability
theory by taking the (Laplacian) probability as the normalized size of each
subset-event of a finite universe. The analogous step in the logic of
partitions is to assign to a partition the number of distinctions made by a
partition normalized by the total number of ordered pairs |UxU| from the finite
universe. That yields a notion of &quot;logical entropy&quot; for partitions and a
&quot;logical information theory.&quot; The logical theory directly counts the
(normalized) number of distinctions in a partition while Shannon's theory gives
the average number of binary partitions needed to make those same distinctions.
Thus the logical theory is seen as providing a conceptual underpinning for
Shannon's theory based on the logical notion of &quot;distinctions.&quot; (forthcoming in
Synthese)
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1792</identifier>
 <datestamp>2009-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1792</id><created>2009-02-10</created><updated>2009-10-11</updated><authors><author><keyname>Agrawal</keyname><forenames>Shipra</forenames></author><author><keyname>Ding</keyname><forenames>Yichuan</forenames></author><author><keyname>Saberi</keyname><forenames>Amin</forenames></author><author><keyname>Ye</keyname><forenames>Yinyu</forenames></author></authors><title>Correlation Robust Stochastic Optimization</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a robust model proposed by Scarf, 1958, for stochastic
optimization when only the marginal probabilities of (binary) random variables
are given, and the correlation between the random variables is unknown. In the
robust model, the objective is to minimize expected cost against worst possible
joint distribution with those marginals. We introduce the concept of
correlation gap to compare this model to the stochastic optimization model that
ignores correlations and minimizes expected cost under independent Bernoulli
distribution. We identify a class of functions, using concepts of summable cost
sharing schemes from game theory, for which the correlation gap is well-bounded
and the robust model can be approximated closely by the independent
distribution model. As a result, we derive efficient approximation factors for
many popular cost functions, like submodular functions, facility location, and
Steiner tree. As a byproduct, our analysis also yields some new results in the
areas of social welfare maximization and existence of Walrasian equilibria,
which may be of independent interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1809</identifier>
 <datestamp>2009-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1809</id><created>2009-02-11</created><updated>2009-11-16</updated><authors><author><keyname>Velasco</keyname><forenames>Pedro Pablo Perez</forenames></author><author><keyname>Jaramillo</keyname><forenames>Juan de Lara</forenames></author></authors><title>Matrix Graph Grammars with Application Conditions</title><categories>cs.DM</categories><comments>38 pages, 23 figures. This version is the one published in Fundamenta
  Informaticae. It incorporates all the comments and amendments from the
  referees</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In the Matrix approach to graph transformation we represent simple digraphs
and rules with Boolean matrices and vectors, and the rewriting is expressed
using Boolean operators only. In previous works, we developed analysis
techniques enabling the study of the applicability of rule sequences, their
independence, state reachability and the minimal graph able to fire a sequence.
  In the present paper we improve our framework in two ways. First, we make
explicit (in the form of a Boolean matrix) some negative implicit information
in rules. This matrix (called nihilation matrix) contains the elements that, if
present, forbid the application of the rule (i.e. potential dangling edges, or
newly added edges, which cannot be already present in the simple digraph).
Second, we introduce a novel notion of application condition, which combines
graph diagrams together with monadic second order logic. This allows for more
flexibility and expressivity than previous approaches, as well as more concise
conditions in certain cases. We demonstrate that these application conditions
can be embedded into rules (i.e. in the left hand side and the nihilation
matrix), and show that the applicability of a rule with arbitrary application
conditions is equivalent to the applicability of a sequence of plain rules
without application conditions. Therefore, the analysis of the former is
equivalent to the analysis of the latter, showing that in our framework no
additional results are needed for the study of application conditions.
Moreover, all analysis techniques of [21, 22] for the study of sequences can be
applied to application conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1834</identifier>
 <datestamp>2009-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1834</id><created>2009-02-11</created><authors><author><keyname>Devismes</keyname><forenames>St&#xe9;phane</forenames><affiliation>VERIMAG - IMAG</affiliation></author><author><keyname>Petit</keyname><forenames>Franck</forenames><affiliation>LIP, INRIA Rh&#xf4;ne-Alpes / LIP Laboratoire de l'Informatique du Parall&#xe9;lisme</affiliation></author><author><keyname>Tixeuil</keyname><forenames>S&#xe9;bastien</forenames><affiliation>LIP6</affiliation></author></authors><title>Optimal Probabilistic Ring Exploration by Asynchronous Oblivious Robots</title><categories>cs.DS cs.CC cs.DC cs.RO</categories><proxy>ccsd inria-00360305</proxy><report-no>RR-6838</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a team of $k$ identical, oblivious, asynchronous mobile robots
that are able to sense (\emph{i.e.}, view) their environment, yet are unable to
communicate, and evolve on a constrained path. Previous results in this weak
scenario show that initial symmetry yields high lower bounds when problems are
to be solved by \emph{deterministic} robots. In this paper, we initiate
research on probabilistic bounds and solutions in this context, and focus on
the \emph{exploration} problem of anonymous unoriented rings of any size. It is
known that $\Theta(\log n)$ robots are necessary and sufficient to solve the
problem with $k$ deterministic robots, provided that $k$ and $n$ are coprime.
By contrast, we show that \emph{four} identical probabilistic robots are
necessary and sufficient to solve the same problem, also removing the coprime
constraint. Our positive results are constructive.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1835</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1835</id><created>2009-02-11</created><updated>2011-12-13</updated><authors><author><keyname>Kratsch</keyname><forenames>Stefan</forenames></author></authors><title>Polynomial Kernelizations for MIN F^+Pi_1 and MAX NP</title><categories>cs.CC</categories><proxy>ccsd inria-00360229</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It has been observed in many places that constant-factor approximable
problems often admit polynomial or even linear problem kernels for their
decision versions, e.g., Vertex Cover, Feedback Vertex Set, and Triangle
Packing. While there exist examples like Bin Packing, which does not admit any
kernel unless P = NP, there apparently is a strong relation between these two
polynomial-time techniques. We add to this picture by showing that the natural
decision versions of all problems in two prominent classes of constant-factor
approximable problems, namely MIN F^+\Pi_1 and MAX NP, admit polynomial problem
kernels. Problems in MAX SNP, a subclass of MAX NP, are shown to admit kernels
with a linear base set, e.g., the set of vertices of a graph. This extends
results of Cai and Chen (JCSS 1997), stating that the standard
parameterizations of problems in MAX SNP and MIN F^+\Pi_1 are fixed-parameter
tractable, and complements recent research on problems that do not admit
polynomial kernelizations (Bodlaender et al. JCSS 2009).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1853</identifier>
 <datestamp>2009-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1853</id><created>2009-02-11</created><authors><author><keyname>Marvasti</keyname><forenames>F.</forenames></author><author><keyname>Amini</keyname><forenames>A.</forenames></author><author><keyname>Haddadi</keyname><forenames>F.</forenames></author><author><keyname>Soltanolkotabi</keyname><forenames>M.</forenames></author><author><keyname>Khalaj</keyname><forenames>B. H.</forenames></author><author><keyname>Aldroubi</keyname><forenames>A.</forenames></author><author><keyname>Holm</keyname><forenames>S.</forenames></author><author><keyname>Sanei</keyname><forenames>S.</forenames></author><author><keyname>Chambers</keyname><forenames>J.</forenames></author></authors><title>A Unified Approach to Sparse Signal Processing</title><categories>cs.IT math.IT</categories><comments>43 pages, 40 figures, 15 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A unified view of sparse signal processing is presented in tutorial form by
bringing together various fields. For each of these fields, various algorithms
and techniques, which have been developed to leverage sparsity, are described
succinctly. The common benefits of significant reduction in sampling rate and
processing manipulations are revealed.
  The key applications of sparse signal processing are sampling, coding,
spectral estimation, array processing, component analysis, and multipath
channel estimation. In terms of reconstruction algorithms, linkages are made
with random sampling, compressed sensing and rate of innovation. The redundancy
introduced by channel coding in finite/real Galois fields is then related to
sampling with similar reconstruction algorithms. The methods of Prony,
Pisarenko, and MUSIC are next discussed for sparse frequency domain
representations. Specifically, the relations of the approach of Prony to an
annihilating filter and Error Locator Polynomials in coding are emphasized; the
Pisarenko and MUSIC methods are further improvements of the Prony method. Such
spectral estimation methods is then related to multi-source location and DOA
estimation in array processing. The notions of sparse array beamforming and
sparse sensor networks are also introduced. Sparsity in unobservable source
signals is also shown to facilitate source separation in SCA; the algorithms
developed in this area are also widely used in compressed sensing. Finally, the
multipath channel estimation problem is shown to have a sparse formulation;
algorithms similar to sampling and coding are used to estimate OFDM channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1866</identifier>
 <datestamp>2009-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1866</id><created>2009-02-11</created><authors><author><keyname>Koiran</keyname><forenames>Pascal</forenames><affiliation>LIP</affiliation></author><author><keyname>Perifel</keyname><forenames>Sylvain</forenames><affiliation>LIAFA</affiliation></author></authors><title>A Superpolynomial Lower Bound on the Size of Uniform Non-constant-depth
  Threshold Circuits for the Permanent</title><categories>cs.CC</categories><comments>11 pages</comments><proxy>ccsd hal-00360507</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the permanent cannot be computed by DLOGTIME-uniform threshold
or arithmetic circuits of depth o(log log n) and polynomial size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1868</identifier>
 <datestamp>2009-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1868</id><created>2009-02-11</created><authors><author><keyname>Kuhn</keyname><forenames>Fabian</forenames><affiliation>CSAIL</affiliation></author></authors><title>Local Multicoloring Algorithms: Computing a Nearly-Optimal TDMA Schedule
  in Constant Time</title><categories>cs.DM cs.DS</categories><proxy>ccsd inria-00360237</proxy><journal-ref>26th International Symposium on Theoretical Aspects of Computer
  Science STACS 2009 (2009) 613-624</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The described multicoloring problem has direct applications in the context of
wireless ad hoc and sensor networks. In order to coordinate the access to the
shared wireless medium, the nodes of such a network need to employ some medium
access control (MAC) protocol. Typical MAC protocols control the access to the
shared channel by time (TDMA), frequency (FDMA), or code division multiple
access (CDMA) schemes. Many channel access schemes assign a fixed set of time
slots, frequencies, or (orthogonal) codes to the nodes of a network such that
nodes that interfere with each other receive disjoint sets of time slots,
frequencies, or code sets. Finding a valid assignment of time slots,
frequencies, or codes hence directly corresponds to computing a multicoloring
of a graph $G$. The scarcity of bandwidth, energy, and computing resources in
ad hoc and sensor networks, as well as the often highly dynamic nature of these
networks require that the multicoloring can be computed based on as little and
as local information as possible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1871</identifier>
 <datestamp>2009-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1871</id><created>2009-02-11</created><authors><author><keyname>Musumbu</keyname><forenames>Kaninda</forenames><affiliation>LaBRI</affiliation></author></authors><title>Abstraction and Refinement in Static Model-Checking</title><categories>cs.DS cs.SC</categories><proxy>ccsd hal-00360242</proxy><journal-ref>IEEE-Computer Society International Conference on Computer Science
  and Information Technology, ICCSIT-2008 (2008) 107 - 112</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  interpretation is a general methodology for building static analyses of
programs. It was introduced by P. and R. Cousot in \cite{cc}. We present, in
this paper, an application of a generic abstract interpretation to domain of
model-checking. Dynamic checking are usually easier to use, because the concept
are establishe d and wide well know. But they are usually limited to systems
whose states space is finite. In an other part, certain faults cannot be
detected dynamically, even by keeping track of the history of the states
space.Indeed, the classical problem of finding the right test cases is far from
trivial and limit the abilities of dynamic checkers further. Static checking
have the advantage that they work on a more abstract level than dynamic checker
and can verify system properties for all inputs. Problem, it is hard to
guarantee that a violation of a modeled property corresponds to a fault in the
concrete system. We propose an approach, in which we generate counter-examples
dynamically using the abstract interpretation techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1884</identifier>
 <datestamp>2009-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1884</id><created>2009-02-11</created><authors><author><keyname>Wittmann</keyname><forenames>Markus</forenames></author><author><keyname>Hager</keyname><forenames>Georg</forenames></author></authors><title>A Proof of Concept for Optimizing Task Parallelism by Locality Queues</title><categories>cs.PF cs.DC</categories><comments>8 pages, 2 figures</comments><acm-class>D.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Task parallelism as employed by the OpenMP task construct, although ideal for
tackling irregular problems or typical producer/consumer schemes, bears some
potential for performance bottlenecks if locality of data access is important,
which is typically the case for memory-bound code on ccNUMA systems. We present
a programming technique which ameliorates adverse effects of dynamic task
distribution by sorting tasks into locality queues, each of which is preferably
processed by threads that belong to the same locality domain. Dynamic
scheduling is fully preserved inside each domain, and is preferred over
possible load imbalance even if non-local access is required. The effectiveness
of the approach is demonstrated using a blocked six-point stencil solver as a
toy model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1891</identifier>
 <datestamp>2009-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1891</id><created>2009-02-11</created><authors><author><keyname>Vats</keyname><forenames>Nitin</forenames></author></authors><title>NNRU, a noncommutative analogue of NTRU</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  NTRU public key cryptosystem is well studied lattice-based Cryptosystem along
with Ajtai-Dwork and GGH systems. Underlying
  NTRU is a hard mathematical problem of finding short vectors in a certain
lattice. (Shamir 1997) presented a lattice-based attack by which he could find
the original secret key or alternate key. Shamir concluded if one designs a
variant of NTRU where the calculations involved during encryption and
decryption are non-commutative then the system will be secure against Lattice
based attack.This paper presents a new cryptosystem with above property and we
have proved that it is completely secure against Lattice based attack. It
operates in the non-commutative ring M=M_k Z[X]/(X^n - I_{k*k}, where M is a
matrix ring of k*k matrices of polynomials in R={Z}[X]/(X^n-1). Moreover We
have got speed improvement by a factor of O(k^{1.624) over NTRU for the same
bit of information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1911</identifier>
 <datestamp>2009-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1911</id><created>2009-02-11</created><authors><author><keyname>Zhuge</keyname><forenames>Hai</forenames></author><author><keyname>Zhang</keyname><forenames>Junsheng</forenames></author></authors><title>Topological Centrality and Its Applications</title><categories>cs.IR cs.AI</categories><comments>15 pages</comments><report-no>KGRC-2009-02</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent development of network structure analysis shows that it plays an
important role in characterizing complex system of many branches of sciences.
Different from previous network centrality measures, this paper proposes the
notion of topological centrality (TC) reflecting the topological positions of
nodes and edges in general networks, and proposes an approach to calculating
the topological centrality. The proposed topological centrality is then used to
discover communities and build the backbone network. Experiments and
applications on research network show the significance of the proposed
approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1942</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1942</id><created>2009-02-11</created><updated>2009-02-19</updated><authors><author><keyname>Elkies</keyname><forenames>Noam D.</forenames></author><author><keyname>Kominers</keyname><forenames>Scott D.</forenames></author></authors><title>On the Classification of Type II Codes of Length 24</title><categories>math.NT cs.DM cs.IT math.CO math.IT</categories><comments>5 pages; v2: fixed minor typos</comments><msc-class>94B05, 11H71</msc-class><journal-ref>SIAM Journal on Discrete Mathematics 23(4), (2010), 2173-2177</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a new, purely coding-theoretic proof of Koch's criterion on the
tetrad systems of Type II codes of length 24 using the theory of harmonic
weight enumerators. This approach is inspired by Venkov's approach to the
classification of the root systems of Type II lattices in R^{24}, and gives a
new instance of the analogy between lattices and codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1947</identifier>
 <datestamp>2009-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1947</id><created>2009-02-11</created><updated>2009-06-03</updated><authors><author><keyname>Penna</keyname><forenames>Federico</forenames></author><author><keyname>Garello</keyname><forenames>Roberto</forenames></author><author><keyname>Spirito</keyname><forenames>Maurizio A.</forenames></author></authors><title>Cooperative Spectrum Sensing based on the Limiting Eigenvalue Ratio
  Distribution in Wishart Matrices</title><categories>cs.IT math.IT</categories><comments>7 pages, 2 figures, submitted to IEEE Communications Letters</comments><journal-ref>Communications Letters, IEEE, vol.13, no.7, pp.507-509, July 2009</journal-ref><doi>10.1109/LCOMM.2009.090425</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent advances in random matrix theory have spurred the adoption of
eigenvalue-based detection techniques for cooperative spectrum sensing in
cognitive radio. Most of such techniques use the ratio between the largest and
the smallest eigenvalues of the received signal covariance matrix to infer the
presence or absence of the primary signal. The results derived so far in this
field are based on asymptotical assumptions, due to the difficulties in
characterizing the exact distribution of the eigenvalues ratio. By exploiting a
recent result on the limiting distribution of the smallest eigenvalue in
complex Wishart matrices, in this paper we derive an expression for the
limiting eigenvalue ratio distribution, which turns out to be much more
accurate than the previous approximations also in the non-asymptotical region.
This result is then straightforwardly applied to calculate the decision
threshold as a function of a target probability of false alarm. Numerical
simulations show that the proposed detection rule provides a substantial
performance improvement compared to the other eigenvalue-based algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1996</identifier>
 <datestamp>2009-02-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1996</id><created>2009-02-12</created><authors><author><keyname>Liu</keyname><forenames>Jiaping</forenames></author><author><keyname>Yi</keyname><forenames>Yung</forenames></author><author><keyname>Proutiere</keyname><forenames>Alexandre</forenames></author><author><keyname>Chiang</keyname><forenames>Mung</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Convergence and Tradeoff of Utility-Optimal CSMA</title><categories>cs.IT math.IT</categories><comments>6 pages, 1 figure, submitted to IEEE Communications Letters</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It has been recently suggested that in wireless networks, CSMA-based
distributed MAC algorithms could achieve optimal utility without any message
passing. We present the first proof of convergence of such adaptive CSMA
algorithms towards an arbitrarily tight approximation of utility-optimizing
schedule. We also briefly discuss the tradeoff between optimality at
equilibrium and short-term fairness practically achieved by such algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2036</identifier>
 <datestamp>2009-02-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2036</id><created>2009-02-12</created><authors><author><keyname>Kayvanrad</keyname><forenames>M. H.</forenames></author><author><keyname>Zonoobi</keyname><forenames>D.</forenames></author><author><keyname>Kassim</keyname><forenames>A. A.</forenames></author></authors><title>Modified Papoulis-Gerchberg algorithm for sparse signal recovery</title><categories>cs.IT math.IT</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by the well-known Papoulis-Gerchberg algorithm, an iterative
thresholding algorithm for recovery of sparse signals from few observations is
proposed. The sequence of iterates turns out to be similar to that of the
thresholded Landweber iterations, although not the same. The performance of the
proposed algorithm is experimentally evaluated and compared to other
state-of-the-art methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2072</identifier>
 <datestamp>2009-02-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2072</id><created>2009-02-12</created><authors><author><keyname>Schr&#xf6;der</keyname><forenames>Lutz</forenames></author><author><keyname>Pattinson</keyname><forenames>Dirk</forenames></author></authors><title>Strong Completeness of Coalgebraic Modal Logics</title><categories>cs.LO</categories><proxy>ccsd inria-00360132</proxy><journal-ref>26th International Symposium on Theoretical Aspects of Computer
  Science - STACS 2009 (2009) 433-444</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Canonical models are of central importance in modal logic, in particular as
they witness strong completeness and hence compactness. While the canonical
model construction is well understood for Kripke semantics, non-normal modal
logics often present subtle difficulties - up to the point that canonical
models may fail to exist, as is the case e.g. in most probabilistic logics.
Here, we present a generic canonical model construction in the semantic
framework of coalgebraic modal logic, which pinpoints coherence conditions
between syntax and semantics of modal logics that guarantee strong
completeness. We apply this method to reconstruct canonical model theorems that
are either known or folklore, and moreover instantiate our method to obtain new
strong completeness results. In particular, we prove strong completeness of
graded modal logic with finite multiplicities, and of the modal logic of exact
probabilities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2073</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2073</id><created>2009-02-12</created><updated>2009-05-25</updated><authors><author><keyname>Shkaravska</keyname><forenames>Olha</forenames></author><author><keyname>van Eekelen</keyname><forenames>Marko</forenames></author><author><keyname>van Kesteren</keyname><forenames>Ron</forenames></author></authors><title>Polynomial Size Analysis of First-Order Shapely Functions</title><categories>cs.LO cs.CC</categories><comments>35 pages, 1 figure</comments><acm-class>F.4.1; F.2.2; D.1.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 5, Issue 2 (May 25,
  2009) lmcs:1148</journal-ref><doi>10.2168/LMCS-5(2:10)2009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a size-aware type system for first-order shapely function
definitions. Here, a function definition is called shapely when the size of the
result is determined exactly by a polynomial in the sizes of the arguments.
Examples of shapely function definitions may be implementations of matrix
multiplication and the Cartesian product of two lists. The type system is
proved to be sound w.r.t. the operational semantics of the language. The type
checking problem is shown to be undecidable in general. We define a natural
syntactic restriction such that the type checking becomes decidable, even
though size polynomials are not necessarily linear or monotonic. Furthermore,
we have shown that the type-inference problem is at least semi-decidable (under
this restriction). We have implemented a procedure that combines run-time
testing and type-checking to automatically obtain size dependencies. It
terminates on total typable function definitions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2081</identifier>
 <datestamp>2014-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2081</id><created>2009-02-12</created><updated>2010-02-12</updated><authors><author><keyname>Yakaryilmaz</keyname><forenames>Abuzer</forenames></author><author><keyname>Say</keyname><forenames>A. C. Cem</forenames></author></authors><title>Languages recognized by nondeterministic quantum finite automata</title><categories>cs.CC</categories><comments>A new version with major revisions, 24 pages, latex</comments><journal-ref>Quantum Information &amp; Computation, Volume 10 Issue 9, September
  2010, Pages 747-770</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The nondeterministic quantum finite automaton (NQFA) is the only known case
where a one-way quantum finite automaton (QFA) model has been shown to be
strictly superior in terms of language recognition power to its probabilistic
counterpart. We give a characterization of the class of languages recognized by
NQFA's, demonstrating that it is equal to the class of exclusive stochastic
languages. We also characterize the class of languages that are recognized
necessarily by two-sided error by QFA's. It is shown that these classes remain
the same when the QFA's used in their definitions are replaced by several
different model variants that have appeared in the literature. We prove several
closure properties of the related classes. The ramifications of these results
about classical and quantum sublogarithmic space complexity classes are
examined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2104</identifier>
 <datestamp>2009-02-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2104</id><created>2009-02-12</created><authors><author><keyname>Goranko</keyname><forenames>Valentin</forenames></author><author><keyname>Shkatov</keyname><forenames>Dmitry</forenames></author></authors><title>Tableau-based decision procedure for full coalitional multiagent
  temporal-epistemic logic of linear tim</title><categories>cs.LO cs.MA</categories><comments>To appear in Proceedings of 8th International Conference on
  Autonomous Agents and Multiagent Systems (AAMAS 09)</comments><acm-class>F.4.1; I.2.4; I.2.11</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a tableau-based decision procedure for the full coalitional
multiagent temporal-epistemic logic of linear time CMATEL(CD+LT). It extends
LTL with operators of common and distributed knowledge for all coalitions of
agents. The tableau procedure runs in exponential time, matching the lower
bound obtained by Halpern and Vardi for a fragment of our logic, thus providing
a complexity-optimal decision procedure for CMATEL(CD+LT).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2108</identifier>
 <datestamp>2011-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2108</id><created>2009-02-12</created><updated>2011-08-30</updated><authors><author><keyname>Gripon</keyname><forenames>Vincent</forenames><affiliation>LIAFA</affiliation></author><author><keyname>Serre</keyname><forenames>Olivier</forenames><affiliation>LIAFA</affiliation></author></authors><title>Qualitative Concurrent Stochastic Games with Imperfect Information</title><categories>cs.FL cs.GT cs.LO</categories><comments>Automata, Languages and Programming, 36th International Colloquium,
  ICALP 2009, Rhodes: Greece (2009)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a model of games that combines concurrency, imperfect information
and stochastic aspects. Those are finite states games in which, at each round,
the two players choose, simultaneously and independently, an action. Then a
successor state is chosen accordingly to some fixed probability distribution
depending on the previous state and on the pair of actions chosen by the
players. Imperfect information is modeled as follows: both players have an
equivalence relation over states and, instead of observing the exact state,
they only know to which equivalence class it belongs. Therefore, if two partial
plays are indistinguishable by some player, he should behave the same in both
of them. We consider reachability (does the play eventually visit a final
state?) and B\&quot;uchi objective (does the play visit infinitely often a final
state?). Our main contribution is to prove that the following problem is
complete for 2-ExpTime: decide whether the first player has a strategy that
ensures her to almost-surely win against any possible strategy of her oponent.
We also characterise those strategies needed by the first player to
almost-surely win.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2125</identifier>
 <datestamp>2009-02-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2125</id><created>2009-02-12</created><authors><author><keyname>Goranko</keyname><forenames>Valentin</forenames></author><author><keyname>Shkatov</keyname><forenames>Dmitry</forenames></author></authors><title>Tableau-based procedure for deciding satisfiability in the full
  coalitional multiagent epistemic logic</title><categories>cs.LO cs.MA</categories><comments>Appeared in S. Artemov, A. Nerode (editors). Logical Foundations of
  Computer Science 2009. Lecture Notes in Computer Science. Vol. 5407.
  Springer, 2009. pp. 197--213</comments><acm-class>F.4.1; I.2.4; I.2.11</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the multiagent epistemic logic CMAELCD with operators for common and
distributed knowledge for all coalitions of agents. We introduce Hintikka
structures for this logic and prove that satisfiability in such structures is
equivalent to satisfiability in standard models. Using this result, we design
an incremental tableau based decision procedure for testing satisfiability in
CMAELCD.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2137</identifier>
 <datestamp>2009-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2137</id><created>2009-02-12</created><updated>2009-11-14</updated><authors><author><keyname>Leroy</keyname><forenames>Xavier</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>A formally verified compiler back-end</title><categories>cs.LO cs.PL</categories><proxy>ccsd inria-00360768</proxy><journal-ref>Journal of Automated Reasoning 43, 4 (2009) 363-446</journal-ref><doi>10.1007/s10817-009-9155-4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article describes the development and formal verification (proof of
semantic preservation) of a compiler back-end from Cminor (a simple imperative
intermediate language) to PowerPC assembly code, using the Coq proof assistant
both for programming the compiler and for proving its correctness. Such a
verified compiler is useful in the context of formal methods applied to the
certification of critical software: the verification of the compiler guarantees
that the safety properties proved on the source code hold for the executable
compiled code as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2140</identifier>
 <datestamp>2009-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2140</id><created>2009-02-12</created><authors><author><keyname>Hromkovic</keyname><forenames>Juraj</forenames></author><author><keyname>Schnitger</keyname><forenames>Georg</forenames></author></authors><title>Ambiguity and Communication</title><categories>cs.FL cs.CC</categories><proxy>ccsd inria-00360175</proxy><journal-ref>26th International Symposium on Theoretical Aspects of Computer
  Science STACS 2009 (2009) 553-564</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ambiguity of a nondeterministic finite automaton (NFA) N for input size n
is the maximal number of accepting computations of N for an input of size n.
For all k, r 2 N we construct languages Lr,k which can be recognized by NFA's
with size k poly(r) and ambiguity O(nk), but Lr,k has only NFA's with
exponential size, if ambiguity o(nk) is required. In particular, a hierarchy
for polynomial ambiguity is obtained, solving a long standing open problem
(Ravikumar and Ibarra, 1989, Leung, 1998).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2141</identifier>
 <datestamp>2009-02-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2141</id><created>2009-02-12</created><authors><author><keyname>Zimand</keyname><forenames>Marius</forenames></author></authors><title>Extracting the Kolmogorov Complexity of Strings and Sequences from
  Sources with Limited Independence</title><categories>cs.CC cs.IT math.IT</categories><proxy>ccsd inria-00360150</proxy><journal-ref>26th International Symposium on Theoretical Aspects of Computer
  Science - STACS 2009 (2009) 433-444</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An infinite binary sequence has randomness rate at least $\sigma$ if, for
almost every $n$, the Kolmogorov complexity of its prefix of length $n$ is at
least $\sigma n$. It is known that for every rational $\sigma \in (0,1)$, on
one hand, there exists sequences with randomness rate $\sigma$ that can not be
effectively transformed into a sequence with randomness rate higher than
$\sigma$ and, on the other hand, any two independent sequences with randomness
rate $\sigma$ can be transformed into a sequence with randomness rate higher
than $\sigma$. We show that the latter result holds even if the two input
sequences have linear dependency (which, informally speaking, means that all
prefixes of length $n$ of the two sequences have in common a constant fraction
of their information). The similar problem is studied for finite strings. It is
shown that from any two strings with sufficiently large Kolmogorov complexity
and sufficiently small dependence, one can effectively construct a string that
is random even conditioned by any one of the input strings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2146</identifier>
 <datestamp>2009-02-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2146</id><created>2009-02-12</created><authors><author><keyname>Ueno</keyname><forenames>Kenya</forenames></author></authors><title>A Stronger LP Bound for Formula Size Lower Bounds via Clique Constraints</title><categories>cs.CC</categories><proxy>ccsd inria-00360141</proxy><journal-ref>26th International Symposium on Theoretical Aspects of Computer
  Science - STACS 2009 (2009) 433-444</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new technique proving formula size lower bounds based on the
linear programming bound originally introduced by Karchmer, Kushilevitz and
Nisan [11] and the theory of stable set polytope. We apply it to majority
functions and prove their formula size lower bounds improved from the classical
result of Khrapchenko [13]. Moreover, we introduce a notion of unbalanced
recursive ternary majority functions motivated by a decomposition theory of
monotone self-dual functions and give integrally matching upper and lower
bounds of their formula size. We also show monotone formula size lower bounds
of balanced recursive ternary majority functions improved from the quantum
adversary bound of Laplante, Lee and Szegedy [15].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2149</identifier>
 <datestamp>2009-02-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2149</id><created>2009-02-12</created><authors><author><keyname>Fellows</keyname><forenames>Michael R.</forenames></author><author><keyname>Guo</keyname><forenames>Jiong</forenames></author><author><keyname>Moser</keyname><forenames>Hannes</forenames></author><author><keyname>Niedermeier</keyname><forenames>Rolf</forenames></author></authors><title>A Generalization of Nemhauser and Trotter's Local Optimization Theorem</title><categories>cs.CC cs.DM cs.DS</categories><proxy>ccsd inria-00360058</proxy><journal-ref>26th International Symposium on Theoretical Aspects of Computer
  Science STACS 2009 (2009) 409-420</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Nemhauser-Trotter local optimization theorem applies to the NP-hard
Vertex Cover problem and has applications in approximation as well as
parameterized algorithmics. We present a framework that generalizes Nemhauser
and Trotter's result to vertex deletion and graph packing problems, introducing
novel algorithmic strategies based on purely combinatorial arguments (not
referring to linear programming as the Nemhauser-Trotter result originally
did). We exhibit our framework using a generalization of Vertex Cover, called
Bounded- Degree Deletion, that has promise to become an important tool in the
analysis of gene and other biological networks. For some fixed d \geq 0,
Bounded-Degree Deletion asks to delete as few vertices as possible from a graph
in order to transform it into a graph with maximum vertex degree at most d.
Vertex Cover is the special case of d = 0. Our generalization of the
Nemhauser-Trotter theorem implies that Bounded-Degree Deletion has a problem
kernel with a linear number of vertices for every constant d. We also outline
an application of our extremal combinatorial approach to the problem of packing
stars with a bounded number of leaves. Finally, charting the border between
(parameterized) tractability and intractability for Bounded-Degree Deletion, we
provide a W[2]-hardness result for Bounded-Degree Deletion in case of unbounded
d-values.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2150</identifier>
 <datestamp>2009-02-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2150</id><created>2009-02-12</created><authors><author><keyname>Farzad</keyname><forenames>Babak</forenames></author><author><keyname>Lau</keyname><forenames>Lap Chi</forenames></author><author><keyname>Le</keyname><forenames>Van Bang</forenames></author><author><keyname>Tuy</keyname><forenames>Nguyen Ngoc</forenames></author></authors><title>Computing Graph Roots Without Short Cycles</title><categories>cs.DM cs.DS</categories><proxy>ccsd inria-00360037</proxy><journal-ref>26th International Symposium on Theoretical Aspects of Computer
  Science STACS 2009 (2009) 397-408</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graph G is the square of graph H if two vertices x, y have an edge in G if
and only if x, y are of distance at most two in H. Given H it is easy to
compute its square H2, however Motwani and Sudan proved that it is NP-complete
to determine if a given graph G is the square of some graph H (of girth 3). In
this paper we consider the characterization and recognition problems of graphs
that are squares of graphs of small girth, i.e. to determine if G = H2 for some
graph H of small girth. The main results are the following. - There is a graph
theoretical characterization for graphs that are squares of some graph of girth
at least 7. A corollary is that if a graph G has a square root H of girth at
least 7 then H is unique up to isomorphism. - There is a polynomial time
algorithm to recognize if G = H2 for some graph H of girth at least 6. - It is
NP-complete to recognize if G = H2 for some graph H of girth 4. These results
almost provide a dichotomy theorem for the complexity of the recognition
problem in terms of girth of the square roots. The algorithmic and graph
theoretical results generalize previous results on tree square roots, and
provide polynomial time algorithms to compute a graph square root of small
girth if it exists. Some open questions and conjectures will also be discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2152</identifier>
 <datestamp>2009-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2152</id><created>2009-02-12</created><authors><author><keyname>Schewe</keyname><forenames>Sven</forenames></author></authors><title>B\&quot;uchi complementation made tight</title><categories>cs.FL cs.CC</categories><proxy>ccsd inria-00360108</proxy><journal-ref>26th International Symposium on Theoretical Aspects of Computer
  Science - STACS 2009 (2009) 433-444</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The precise complexity of complementing B\&quot;uchi automata is an intriguing and
long standing problem. While optimal complementation techniques for finite
automata are simple - it suffices to determinize them using a simple subset
construction and to dualize the acceptance condition of the resulting automaton
- B\&quot;uchi complementation is more involved. Indeed, the construction of an
EXPTIME complementation procedure took a quarter of a century from the
introduction of B\&quot;uchi automata in the early 60s, and stepwise narrowing the
gap between the upper and lower bound to a simple exponent (of (6e)n for
B\&quot;uchi automata with n states) took four decades. While the distance between
the known upper (O'(0.96 n)n') and lower ('(0.76 n)n') bound on the required
number of states has meanwhile been significantly reduced, an exponential
factor remains between them. Also, the upper bound on the size of the
complement automaton is not linear in the bound of its state space. These gaps
are unsatisfactory from a theoretical point of view, but also because B\&quot;uchi
complementation is a useful tool in formal verification, in particular for the
language containment problem. This paper proposes a B\&quot;uchi complementation
algorithm whose complexity meets, modulo a quadratic (O(n2)) factor, the known
lower bound for B\&quot;uchi complementation. It thus improves over previous
constructions by an exponential factor and concludes the quest for optimal
B\&quot;uchi complementation algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2166</identifier>
 <datestamp>2009-02-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2166</id><created>2009-02-12</created><authors><author><keyname>Robson</keyname><forenames>John Michael</forenames><affiliation>LaBRI</affiliation></author></authors><title>Spanning Trees of Bounded Degree Graphs</title><categories>cs.DM cs.CC</categories><proxy>ccsd hal-00360110</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider lower bounds on the number of spanning trees of connected graphs
with degree bounded by $d$. The question is of interest because such bounds may
improve the analysis of the improvement produced by memorisation in the runtime
of exponential algorithms. The value of interest is the constant $\beta_d$ such
that all connected graphs with degree bounded by $d$ have at least
$\beta_d^\mu$ spanning trees where $\mu$ is the cyclomatic number or excess of
the graph, namely $m-n+1$. We conjecture that $\beta_d$ is achieved by the
complete graph $K_{d+1}$ but we have not proved this for any $d$ greater than
3. We give weaker lower bounds on $\beta_d$ for $d\le 11$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2183</identifier>
 <datestamp>2009-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2183</id><created>2009-02-12</created><updated>2009-06-29</updated><authors><author><keyname>Bollen</keyname><forenames>Johan</forenames></author><author><keyname>Van de Sompel</keyname><forenames>Herbert</forenames></author><author><keyname>Hagberg</keyname><forenames>Aric</forenames></author><author><keyname>Chute</keyname><forenames>Ryan</forenames></author></authors><title>A principal component analysis of 39 scientific impact measures</title><categories>cs.DL cs.CY</categories><journal-ref>Bollen J, Van de Sompel H, Hagberg A, Chute R, 2009 A Principal
  Component Analysis of 39 Scientific Impact Measures. PLoS ONE 4(6): e6022.
  (http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0006022)</journal-ref><doi>10.1371/journal.pone.0006022</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The impact of scientific publications has traditionally been expressed in
terms of citation counts. However, scientific activity has moved online over
the past decade. To better capture scientific impact in the digital era, a
variety of new impact measures has been proposed on the basis of social network
analysis and usage log data. Here we investigate how these new measures relate
to each other, and how accurately and completely they express scientific
impact. We performed a principal component analysis of the rankings produced by
39 existing and proposed measures of scholarly impact that were calculated on
the basis of both citation and usage log data. Our results indicate that the
notion of scientific impact is a multi-dimensional construct that can not be
adequately measured by any single indicator, although some measures are more
suitable than others. The commonly used citation Impact Factor is not
positioned at the core of this construct, but at its periphery, and should thus
be used with caution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2186</identifier>
 <datestamp>2009-02-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2186</id><created>2009-02-12</created><authors><author><keyname>Choi</keyname><forenames>Young Sang</forenames></author><author><keyname>Deyle</keyname><forenames>Travis</forenames></author><author><keyname>Kemp</keyname><forenames>Charles C.</forenames></author></authors><title>A List of Household Objects for Robotic Retrieval Prioritized by People
  with ALS (Version 092008)</title><categories>cs.RO cs.HC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This technical report is designed to serve as a citable reference for the
original prioritized object list that the Healthcare Robotics Lab at Georgia
Tech released on its website in September of 2008. It is also expected to serve
as the primary citable reference for the research associated with this list
until the publication of a detailed, peer-reviewed paper.
  The original prioritized list of object classes resulted from a needs
assessment involving 8 motor-impaired patients with amyotrophic lateral
sclerosis (ALS) and targeted, in-person interviews of 15 motor-impaired ALS
patients. All of these participants were drawn from the Emory ALS Center.
  The prioritized object list consists of 43 object classes ranked by how
important the participants considered each class to be for retrieval by an
assistive robot. We intend for this list to be used by researchers to inform
the design and benchmarking of robotic systems, especially research related to
autonomous mobile manipulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2187</identifier>
 <datestamp>2009-02-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2187</id><created>2009-02-12</created><authors><author><keyname>Lima</keyname><forenames>Joao Paulo</forenames></author><author><keyname>Teichrieb</keyname><forenames>Veronica</forenames></author><author><keyname>Kelner</keyname><forenames>Judith</forenames></author></authors><title>A Standalone Markerless 3D Tracker for Handheld Augmented Reality</title><categories>cs.CV cs.GR cs.MM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an implementation of a markerless tracking technique
targeted to the Windows Mobile Pocket PC platform. The primary aim of this work
is to allow the development of standalone augmented reality applications for
handheld devices based on natural feature tracking. In order to achieve this
goal, a subset of two computer vision libraries was ported to the Pocket PC
platform. They were also adapted to use fixed point math, with the purpose of
improving the overall performance of the routines. The port of these libraries
opens up the possibility of having other computer vision tasks being executed
on mobile platforms. A model based tracking approach that relies on edge
information was adopted. Since it does not require a high processing power, it
is suitable for constrained devices such as handhelds. The OpenGL ES graphics
library was used to perform computer vision tasks, taking advantage of existing
graphics hardware acceleration. An augmented reality application was created
using the implemented technique and evaluations were done regarding tracking
performance and accuracy
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2206</identifier>
 <datestamp>2010-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2206</id><created>2009-02-12</created><updated>2010-02-27</updated><authors><author><keyname>Weinberger</keyname><forenames>Kilian</forenames></author><author><keyname>Dasgupta</keyname><forenames>Anirban</forenames></author><author><keyname>Attenberg</keyname><forenames>Josh</forenames></author><author><keyname>Langford</keyname><forenames>John</forenames></author><author><keyname>Smola</keyname><forenames>Alex</forenames></author></authors><title>Feature Hashing for Large Scale Multitask Learning</title><categories>cs.AI</categories><comments>Fixed broken theorem</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Empirical evidence suggests that hashing is an effective strategy for
dimensionality reduction and practical nonparametric estimation. In this paper
we provide exponential tail bounds for feature hashing and show that the
interaction between random subspaces is negligible with high probability. We
demonstrate the feasibility of this approach with experimental results for a
new use case -- multitask learning with hundreds of thousands of tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2209</identifier>
 <datestamp>2009-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2209</id><created>2009-02-12</created><updated>2009-04-14</updated><authors><author><keyname>Durr</keyname><forenames>Christoph</forenames></author><author><keyname>Jez</keyname><forenames>Lukasz</forenames></author><author><keyname>Thang</keyname><forenames>Nguyen Kim</forenames></author></authors><title>Online Scheduling of Bounded Length Jobs to Maximize Throughput</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider an online scheduling problem, motivated by the issues present at
the joints of networks using ATM and TCP/IP. Namely, IP packets have to broken
down to small ATM cells and sent out before their deadlines, but cells
corresponding to different packets can be interwoven. More formally, we
consider the online scheduling problem with preemptions, where each job j is
revealed at release time r_j, has processing time p_j, deadline d_j and weight
w_j. A preempted job can be resumed at any time. The goal is to maximize the
total weight of all jobs completed on time. Our main result are as follows: we
prove that if all jobs have processing time exactly k, the deterministic
competitive ratio is between 2.598 and 5, and when the processing times are at
most k, the deterministic competitive ratio is Theta(k/log k).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2230</identifier>
 <datestamp>2009-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2230</id><created>2009-02-12</created><authors><author><keyname>Herda&#x11f;delen</keyname><forenames>Ama&#xe7;</forenames></author><author><keyname>Baroni</keyname><forenames>Marco</forenames></author></authors><title>BagPack: A general framework to represent semantic relations</title><categories>cs.CL cs.IR</categories><comments>Long paper presented at GEMS - Geometric Models of Natural Language
  Semantics, workshop held in conjunction with the 12th Conference of the
  European Chapter of the Association for Computational Linguistics (EACL-09),
  Athens, Greece</comments><acm-class>I.2.7; I.5.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a way to represent word pairs instantiating arbitrary semantic
relations that keeps track of the contexts in which the words in the pair occur
both together and independently. The resulting features are of sufficient
generality to allow us, with the help of a standard supervised machine learning
algorithm, to tackle a variety of unrelated semantic tasks with good results
and almost no task-specific tailoring.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2235</identifier>
 <datestamp>2009-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2235</id><created>2009-02-12</created><authors><author><keyname>Gluesing-Luerssen</keyname><forenames>Heide</forenames></author></authors><title>On Isometries for Convolutional Codes</title><categories>cs.IT math.IT</categories><comments>24 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we will discuss isometries and strong isometries for
convolutional codes. Isometries are weight-preserving module isomorphisms
whereas strong isometries are, in addition, degree-preserving. Special cases of
these maps are certain types of monomial transformations. We will show a form
of MacWilliams Equivalence Theorem, that is, each isometry between
convolutional codes is given by a monomial transformation. Examples show that
strong isometries cannot be characterized this way, but special attention paid
to the weight adjacency matrices allows for further descriptions. Various
distance parameters appearing in the literature on convolutional codes will be
discussed as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2260</identifier>
 <datestamp>2009-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2260</id><created>2009-02-13</created><authors><author><keyname>Liu</keyname><forenames>Chun-Hung</forenames></author><author><keyname>Xue</keyname><forenames>Feng</forenames></author><author><keyname>Andrews</keyname><forenames>Jeffrey G.</forenames></author></authors><title>Network Coding with Two-Way Relaying: Achievable Rate Regions and
  Diversity-Multiplexing Tradeoffs</title><categories>cs.IT math.IT</categories><comments>27 pages, 7 figures, submitted to IEEE trans. on wireless
  communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the fundamental characteristics of information exchange
via multihop network coding over two-way relaying in a wireless ad hoc network.
The end-to-end rate regions achieved by time-division multihop (TDMH),
MAC-layer network coding (MLNC) and PHY-layer network coding (PLNC) are first
characterized. It is shown that MLNC does not always achieve better rates than
TDMH, time sharing between TDMH and MLNC is able to achieve a larger rate
region, and PLNC dominates the rate regions achieved by TDMH and MLNC. An
opportunistic scheduling algorithm for MLNC and PLNC is then proposed to
stabilize the two-way relaying system for Poisson arrivals whenever the rate
pair is within the Shannon rate regions of MLNC and PLNC. To understand the
two-way transmission limits of multihop network coding, the sum-rate
optimization with or without certain traffic pattern and the end-to-end
diversity-multiplexing tradeoffs (DMTs) of two-way transmission over multiple
relay nodes are also analyzed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2300</identifier>
 <datestamp>2009-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2300</id><created>2009-02-13</created><updated>2009-12-15</updated><authors><author><keyname>Briquel</keyname><forenames>Ir&#xe9;n&#xe9;e</forenames><affiliation>LIP</affiliation></author><author><keyname>Koiran</keyname><forenames>Pascal</forenames><affiliation>LIP</affiliation></author></authors><title>A Dichotomy Theorem for Polynomial Evaluation</title><categories>cs.CC</categories><proxy>ccsd ensl-00360974</proxy><journal-ref>Dans Mathematical Foundations of Computer Science 2009 -
  Mathematical Foundations of Computer Science 2009, Novy Smokovec : Slovakia
  (Slovak Republic) (2009)</journal-ref><doi>10.1007/978-3-642-03816-7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A dichotomy theorem for counting problems due to Creignou and Hermann states
that or any nite set S of logical relations, the counting problem #SAT(S) is
either in FP, or #P-complete. In the present paper we show a dichotomy theorem
for polynomial evaluation. That is, we show that for a given set S, either
there exists a VNP-complete family of polynomials associated to S, or the
associated families of polynomials are all in VP. We give a concise
characterization of the sets S that give rise to &quot;easy&quot; and &quot;hard&quot; polynomials.
We also prove that several problems which were known to be #P-complete under
Turing reductions only are in fact #P-complete under many-one reductions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2316</identifier>
 <datestamp>2009-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2316</id><created>2009-02-13</created><updated>2009-02-20</updated><authors><author><keyname>Mogilnykh</keyname><forenames>Ivan Yu.</forenames></author></authors><title>On weak isometries of Preparata codes</title><categories>cs.IT math.IT</categories><comments>Submitted to Problems of Information Transmission on 11th of January
  2009</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Let C1 and C2 be codes with code distance d. Codes C1 and C2 are called
weakly isometric, if there exists a mapping J:C1-&gt;C2, such that for any x,y
from C1 the equality d(x,y)=d holds if and only if d(J(x),J(y))=d. Obviously
two codes are weakly isometric if and only if the minimal distance graphs of
these codes are isomorphic. In this paper we prove that Preparata codes of
length n&gt;=2^12 are weakly isometric if and only if these codes are equivalent.
The analogous result is obtained for punctured Preparata codes of length not
less than 2^10-1.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2345</identifier>
 <datestamp>2009-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2345</id><created>2009-02-13</created><authors><author><keyname>Afantenos</keyname><forenames>Stergos D.</forenames></author><author><keyname>Hernandez</keyname><forenames>Nicolas</forenames></author></authors><title>What's in a Message?</title><categories>cs.CL</categories><journal-ref>12th Conference of the European Chapter of the Association for
  Computational Linguistics (EACL 2009), workshop on Cognitive Aspects of
  Computational Language Acquisition. Athens, Greece</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present the first step in a larger series of experiments for
the induction of predicate/argument structures. The structures that we are
inducing are very similar to the conceptual structures that are used in Frame
Semantics (such as FrameNet). Those structures are called messages and they
were previously used in the context of a multi-document summarization system of
evolving events. The series of experiments that we are proposing are
essentially composed from two stages. In the first stage we are trying to
extract a representative vocabulary of words. This vocabulary is later used in
the second stage, during which we apply to it various clustering approaches in
order to identify the clusters of predicates and arguments--or frames and
semantic roles, to use the jargon of Frame Semantics. This paper presents in
detail and evaluates the first stage.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2362</identifier>
 <datestamp>2009-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2362</id><created>2009-02-13</created><authors><author><keyname>Roussel</keyname><forenames>Olivier</forenames></author><author><keyname>Lecoutre</keyname><forenames>Christophe</forenames></author></authors><title>XML Representation of Constraint Networks: Format XCSP 2.1</title><categories>cs.AI</categories><acm-class>H.5.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new extended format to represent constraint networks using XML.
This format allows us to represent constraints defined either in extension or
in intension. It also allows us to reference global constraints. Any instance
of the problems CSP (Constraint Satisfaction Problem), QCSP (Quantified CSP)
and WCSP (Weighted CSP) can be represented using this format.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2367</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2367</id><created>2009-02-13</created><updated>2010-06-22</updated><authors><author><keyname>Jacques</keyname><forenames>Laurent</forenames></author><author><keyname>Hammond</keyname><forenames>David K.</forenames></author><author><keyname>Fadili</keyname><forenames>M. Jalal</forenames></author></authors><title>Dequantizing Compressed Sensing: When Oversampling and Non-Gaussian
  Constraints Combine</title><categories>math.OC cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study the problem of recovering sparse or compressible
signals from uniformly quantized measurements. We present a new class of convex
optimization programs, or decoders, coined Basis Pursuit DeQuantizer of moment
$p$ (BPDQ$_p$), that model the quantization distortion more faithfully than the
commonly used Basis Pursuit DeNoise (BPDN) program. Our decoders proceed by
minimizing the sparsity of the signal to be reconstructed subject to a
data-fidelity constraint expressed in the $\ell_p$-norm of the residual error
for $2\leq p\leq \infty$.
  We show theoretically that, (i) the reconstruction error of these new
decoders is bounded if the sensing matrix satisfies an extended Restricted
Isometry Property involving the $\ell_p$ norm, and (ii), for Gaussian random
matrices and uniformly quantized measurements, BPDQ$_p$ performance exceeds
that of BPDN by dividing the reconstruction error due to quantization by
$\sqrt{p+1}$. This last effect happens with high probability when the number of
measurements exceeds a value growing with $p$, i.e. in an oversampled situation
compared to what is commonly required by BPDN = BPDQ$_2$. To demonstrate the
theoretical power of BPDQ$_p$, we report numerical simulations on signal and
image reconstruction problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2370</identifier>
 <datestamp>2009-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2370</id><created>2009-02-13</created><authors><author><keyname>Kramer</keyname><forenames>Gerhard</forenames><affiliation>Shitz</affiliation></author><author><keyname>Liang</keyname><forenames>Yingbin</forenames><affiliation>Shitz</affiliation></author><author><keyname>Shamai</keyname><forenames>Shlomo</forenames><affiliation>Shitz</affiliation></author></authors><title>Outer Bounds on the Admissible Source Region for Broadcast Channels with
  Dependent Sources</title><categories>cs.IT math.IT</categories><comments>4 pages, presented at the Information Theory and Applications
  Workshop, UCSD, San Diego, Feb. 8-13, 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Outer bounds on the admissible source region for broadcast channels with
dependent sources are developed and used to prove capacity results for several
classes of sources and channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2399</identifier>
 <datestamp>2009-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2399</id><created>2009-02-13</created><updated>2009-02-17</updated><authors><author><keyname>Brody</keyname><forenames>Joshua</forenames></author><author><keyname>Chakrabarti</keyname><forenames>Amit</forenames></author></authors><title>A Multi-Round Communication Lower Bound for Gap Hamming and Some
  Consequences</title><categories>cs.CC cs.DB cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Gap-Hamming-Distance problem arose in the context of proving space lower
bounds for a number of key problems in the data stream model. In this problem,
Alice and Bob have to decide whether the Hamming distance between their $n$-bit
input strings is large (i.e., at least $n/2 + \sqrt n$) or small (i.e., at most
$n/2 - \sqrt n$); they do not care if it is neither large nor small. This
$\Theta(\sqrt n)$ gap in the problem specification is crucial for capturing the
approximation allowed to a data stream algorithm.
  Thus far, for randomized communication, an $\Omega(n)$ lower bound on this
problem was known only in the one-way setting. We prove an $\Omega(n)$ lower
bound for randomized protocols that use any constant number of rounds.
  As a consequence we conclude, for instance, that $\epsilon$-approximately
counting the number of distinct elements in a data stream requires
$\Omega(1/\epsilon^2)$ space, even with multiple (a constant number of) passes
over the input stream. This extends earlier one-pass lower bounds, answering a
long-standing open question. We obtain similar results for approximating the
frequency moments and for approximating the empirical entropy of a data stream.
  In the process, we also obtain tight $n - \Theta(\sqrt{n}\log n)$ lower and
upper bounds on the one-way deterministic communication complexity of the
problem. Finally, we give a simple combinatorial proof of an $\Omega(n)$ lower
bound on the one-way randomized communication complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2407</identifier>
 <datestamp>2009-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2407</id><created>2009-02-13</created><authors><author><keyname>Bowen</keyname><forenames>Richard Strong</forenames></author><author><keyname>Chen</keyname><forenames>Bo</forenames></author><author><keyname>Orem</keyname><forenames>Hendrik</forenames></author><author><keyname>van Schaardenburg</keyname><forenames>Martijn</forenames></author></authors><title>Group-Theoretic Partial Matrix Multiplication</title><categories>cs.CC cs.SC</categories><comments>14 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A generalization of recent group-theoretic matrix multiplication algorithms
to an analogue of the theory of partial matrix multiplication is presented. We
demonstrate that the added flexibility of this approach can in some cases
improve upper bounds on the exponent of matrix multiplication yielded by
group-theoretic full matrix multiplication. The group theory behind our partial
matrix multiplication algorithms leads to the problem of maximizing a quantity
representing the &quot;fullness&quot; of a given partial matrix pattern. This problem is
shown to be NP-hard, and two algorithms, one optimal and another non-optimal
but polynomial-time, are given for solving it.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2415</identifier>
 <datestamp>2011-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2415</id><created>2009-02-14</created><updated>2011-11-22</updated><authors><author><keyname>Danila</keyname><forenames>Bogdan</forenames></author><author><keyname>Sun</keyname><forenames>Yudong</forenames></author><author><keyname>Bassler</keyname><forenames>Kevin E.</forenames></author></authors><title>Collectively optimal routing for congested traffic limited by link
  capacity</title><categories>physics.soc-ph cond-mat.dis-nn cond-mat.stat-mech cs.NI physics.comp-ph</categories><comments>7 pages, 4 figures</comments><journal-ref>Phys Rev E 80 (6) 066116, 2009</journal-ref><doi>10.1103/PhysRevE.80.066116</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the capacity of a complex network that models a city street grid
to support congested traffic can be optimized by using routes that collectively
minimize the maximum ratio of betweenness to capacity in any link. Networks
with a heterogeneous distribution of link capacities and with a heterogeneous
transport load are considered. We find that overall traffic congestion and
average travel times can be significantly reduced by a judicious use of slower,
smaller capacity links.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2420</identifier>
 <datestamp>2011-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2420</id><created>2009-02-13</created><updated>2011-07-20</updated><authors><author><keyname>Sterling</keyname><forenames>Aaron</forenames></author></authors><title>Self-Assembly as Graph Grammar as Distributed System</title><categories>cs.DC cs.NE</categories><comments>Withdrawn as I would like to polish it before making it public again.
  A two-page announcement of these results will appear in the proceedings of
  PODC 2009</comments><acm-class>F.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In 2004, Klavins et al. introduced the use of graph grammars to describe --
and to program -- systems of self-assembly. It turns out that these graph
grammars are a &quot;dual notion&quot; of a graph rewriting characterization of
distributed systems that was proposed by Degano and Montanari over twenty years
ago. By applying techniques obtained from this observation, we prove a
generalized version of Soloveichik and Winfree's theorem on local determinism,
and we also present a canonical method to simulate asynchronous
constant-size-message-passing models of distributed computing with systems of
self-assembly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2422</identifier>
 <datestamp>2009-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2422</id><created>2009-02-13</created><updated>2009-08-04</updated><authors><author><keyname>Sterling</keyname><forenames>Aaron</forenames></author></authors><title>A Time Lower Bound for Multiple Nucleation on a Surface</title><categories>cs.CC cs.DC</categories><comments>This is a major revision -- thanks to comments from two very helpful
  anonymous reviewers -- of &quot;A Limit to the Power of Multiple Nucleation,&quot;
  which appeared in DISC 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Majumder, Reif and Sahu have presented a stochastic model of reversible,
error-permitting, two-dimensional tile self-assembly, and showed that
restricted classes of tile assembly systems achieved equilibrium in (expected)
polynomial time. One open question they asked was how much computational power
would be added if the model permitted multiple nucleation, i.e., independent
groups of tiles growing before attaching to the original seed assembly. This
paper provides a partial answer, by proving that if a tile assembly model uses
only local binding rules, then it cannot use multiple nucleation on a surface
to solve certain &quot;simple&quot; problems in constant time (time independent of the
size of the surface). Moreover, this time bound applies to macroscale robotic
systems that assemble in a three-dimensional grid, not just to tile assembly
systems on a two-dimensional surface. The proof technique defines a new model
of distributed computing that simulates tile (and robotic) self-assembly.
Keywords: self-assembly, multiple nucleation, locally checkable labeling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2425</identifier>
 <datestamp>2009-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2425</id><created>2009-02-13</created><authors><author><keyname>Xiang</keyname><forenames>Biao</forenames></author><author><keyname>Chen</keyname><forenames>En-Hong</forenames></author><author><keyname>Zhou</keyname><forenames>Tao</forenames></author></authors><title>Finding Community Structure Based on Subgraph Similarity</title><categories>cs.NI cs.IR physics.soc-ph</categories><comments>ComplexNet2009, http://complenet09.diit.unict.it/index.html Will
  appear in &quot;Studies in Computational Intelligence&quot;</comments><journal-ref>Studies in Computational Intelligence 207 (2009) 73-81</journal-ref><doi>10.1007/978-3-642-01206-8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Community identification is a long-standing challenge in the modern network
science, especially for very large scale networks containing millions of nodes.
In this paper, we propose a new metric to quantify the structural similarity
between subgraphs, based on which an algorithm for community identification is
designed. Extensive empirical results on several real networks from disparate
fields has demonstrated that the present algorithm can provide the same level
of reliability, measure by modularity, while takes much shorter time than the
well-known fast algorithm proposed by Clauset, Newman and Moore (CNM). We
further propose a hybrid algorithm that can simultaneously enhance modularity
and save computational time compared with the CNM algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2436</identifier>
 <datestamp>2009-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2436</id><created>2009-02-14</created><authors><author><keyname>Nam</keyname><forenames>Wooseok</forenames></author><author><keyname>Chung</keyname><forenames>Sae-Young</forenames></author><author><keyname>Lee</keyname><forenames>Yong H.</forenames></author></authors><title>Nested Lattice Codes for Gaussian Relay Networks with Interference</title><categories>cs.IT math.IT</categories><comments>23 pages, 5 figures, submitted to IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a class of relay networks is considered. We assume that, at a
node, outgoing channels to its neighbors are orthogonal, while incoming signals
from neighbors can interfere with each other. We are interested in the
multicast capacity of these networks. As a subclass, we first focus on Gaussian
relay networks with interference and find an achievable rate using a lattice
coding scheme. It is shown that there is a constant gap between our achievable
rate and the information theoretic cut-set bound. This is similar to the recent
result by Avestimehr, Diggavi, and Tse, who showed such an approximate
characterization of the capacity of general Gaussian relay networks. However,
our achievability uses a structured code instead of a random one. Using the
same idea used in the Gaussian case, we also consider linear finite-field
symmetric networks with interference and characterize the capacity using a
linear coding scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2438</identifier>
 <datestamp>2009-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2438</id><created>2009-02-14</created><authors><author><keyname>Nam</keyname><forenames>Wooseok</forenames></author><author><keyname>Chung</keyname><forenames>Sae-Young</forenames></author><author><keyname>Lee</keyname><forenames>Yong H.</forenames></author></authors><title>Capacity of the Gaussian Two-way Relay Channel to within 1/2 Bit</title><categories>cs.IT math.IT</categories><comments>9 pages, 2 figures, submitted to IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a Gaussian two-way relay channel, where two source nodes
exchange messages with each other through a relay, is considered. We assume
that all nodes operate in full-duplex mode and there is no direct channel
between the source nodes. We propose an achievable scheme composed of nested
lattice codes for the uplink and structured binning for the downlink. We show
that the scheme achieves within 1/2 bit from the cut-set bound for all channel
parameters and becomes asymptotically optimal as the signal to noise ratios
increase.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2446</identifier>
 <datestamp>2011-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2446</id><created>2009-02-14</created><updated>2009-07-17</updated><authors><author><keyname>Frasca</keyname><forenames>Paolo</forenames></author><author><keyname>Mason</keyname><forenames>Paolo</forenames></author><author><keyname>Piccoli</keyname><forenames>Benedetto</forenames></author></authors><title>Detection of Gaussian signals via hexagonal sensor networks</title><categories>math.OC cs.SY</categories><comments>16 pages, 4 figures. Accepted. v1-current: corrected typos, added
  clarifications, updated and added references, extended intro and final
  remarks</comments><msc-class>93A14 (Primary) 94C15 68M14</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers a special case of the problem of identifying a static
scalar signal, depending on the location, using a planar network of sensors in
a distributed fashion. Motivated by the application to monitoring wild-fires
spreading and pollutants dispersion, we assume the signal to be Gaussian in
space. Using a network of sensors positioned to form a regular hexagonal
tessellation, we prove that each node can estimate the parameters of the
Gaussian from local measurements. Moreover, we study the sensitivity of these
estimates to additive errors affecting the measurements. Finally, we show how a
consensus algorithm can be designed to fuse the local estimates into a shared
global estimate, effectively compensating the measurement errors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2487</identifier>
 <datestamp>2009-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2487</id><created>2009-02-14</created><authors><author><keyname>Parakh</keyname><forenames>Abhishek</forenames></author><author><keyname>Kak</keyname><forenames>Subhash</forenames></author></authors><title>A Recursive Threshold Visual Cryptography Scheme</title><categories>cs.CR</categories><comments>8 pages</comments><report-no>Cryptology ePrint Archive, Report 2008/535</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a recursive hiding scheme for 2 out of 3 secret sharing.
In recursive hiding of secrets, the user encodes additional information about
smaller secrets in the shares of a larger secret without an expansion in the
size of the latter, thereby increasing the efficiency of secret sharing. We
present applications of our proposed protocol to images as well as text.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2501</identifier>
 <datestamp>2012-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2501</id><created>2009-02-14</created><authors><author><keyname>Hayes</keyname><forenames>Tom</forenames></author><author><keyname>Saia</keyname><forenames>Jared</forenames></author><author><keyname>Trehan</keyname><forenames>Amitabh</forenames></author></authors><title>The Forgiving Graph: A distributed data structure for low stretch under
  adversarial attack</title><categories>cs.DS cs.DC</categories><comments>Submitted to Principles of Distributed Computing (PODC) 2009</comments><acm-class>C.2.1; C.2.3; C.2.4; C.4; H.3.4</acm-class><journal-ref>Distributed Computing, 2012, Volume 25, Number 4, Pages 261-278</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of self-healing in peer-to-peer networks that are
under repeated attack by an omniscient adversary. We assume that, over a
sequence of rounds, an adversary either inserts a node with arbitrary
connections or deletes an arbitrary node from the network. The network responds
to each such change by quick &quot;repairs,&quot; which consist of adding or deleting a
small number of edges.
  These repairs essentially preserve closeness of nodes after adversarial
deletions, without increasing node degrees by too much, in the following sense.
At any point in the algorithm, nodes $v$ and $w$ whose distance would have been
$\ell$ in the graph formed by considering only the adversarial insertions (not
the adversarial deletions), will be at distance at most $\ell \log n$ in the
actual graph, where $n$ is the total number of vertices seen so far. Similarly,
at any point, a node $v$ whose degree would have been $d$ in the graph with
adversarial insertions only, will have degree at most 3d in the actual graph.
Our algorithm is completely distributed and has low latency and bandwidth
requirements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2504</identifier>
 <datestamp>2009-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2504</id><created>2009-02-15</created><authors><author><keyname>Molyneux</keyname><forenames>Richard</forenames></author></authors><title>Hyperset Approach to Semi-structured Databases and the Experimental
  Implementation of the Query Language Delta</title><categories>cs.DB</categories><comments>Technical Report (PhD thesis), University of Liverpool, England</comments><report-no>ULCS-09-003</report-no><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  This thesis presents practical suggestions towards the implementation of the
hyperset approach to semi-structured databases and the associated query
language Delta. This work can be characterised as part of a top-down approach
to semi-structured databases, from theory to practice. The main original part
of this work consisted in implementation of the hyperset Delta query language
to semi-structured databases, including worked example queries. In fact, the
goal was to demonstrate the practical details of this approach and language.
The required development of an extended, practical version of the language
based on the existing theoretical version, and the corresponding operational
semantics. Here we present detailed description of the most essential steps of
the implementation. Another crucial problem for this approach was to
demonstrate how to deal in reality with the concept of the equality relation
between (hyper)sets, which is computationally realised by the bisimulation
relation. In fact, this expensive procedure, especially in the case of
distributed semi-structured data, required some additional theoretical
considerations and practical suggestions for efficient implementation. To this
end the 'local/global' strategy for computing the bisimulation relation over
distributed semi-structured data was developed and its efficiency was
experimentally confirmed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2537</identifier>
 <datestamp>2011-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2537</id><created>2009-02-15</created><updated>2010-04-12</updated><authors><author><keyname>Ballard</keyname><forenames>Grey</forenames></author><author><keyname>Demmel</keyname><forenames>James</forenames></author><author><keyname>Holtz</keyname><forenames>Olga</forenames></author><author><keyname>Schwartz</keyname><forenames>Oded</forenames></author></authors><title>Communication-optimal Parallel and Sequential Cholesky Decomposition</title><categories>cs.NA cs.CC cs.DS math.NA</categories><comments>29 pages, 2 tables, 6 figures</comments><acm-class>F.2.1</acm-class><journal-ref>SIAM J. Sci. Comput. 32, (2010) pp. 3495-3523</journal-ref><doi>10.1137/090760969</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Numerical algorithms have two kinds of costs: arithmetic and communication,
by which we mean either moving data between levels of a memory hierarchy (in
the sequential case) or over a network connecting processors (in the parallel
case). Communication costs often dominate arithmetic costs, so it is of
interest to design algorithms minimizing communication. In this paper we first
extend known lower bounds on the communication cost (both for bandwidth and for
latency) of conventional (O(n^3)) matrix multiplication to Cholesky
factorization, which is used for solving dense symmetric positive definite
linear systems. Second, we compare the costs of various Cholesky decomposition
implementations to these lower bounds and identify the algorithms and data
structures that attain them. In the sequential case, we consider both the
two-level and hierarchical memory models. Combined with prior results in [13,
14, 15], this gives a set of communication-optimal algorithms for O(n^3)
implementations of the three basic factorizations of dense linear algebra: LU
with pivoting, QR and Cholesky. But it goes beyond this prior work on
sequential LU by optimizing communication for any number of levels of memory
hierarchy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2559</identifier>
 <datestamp>2009-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2559</id><created>2009-02-15</created><authors><author><keyname>Belmega</keyname><forenames>Elena Veronica</forenames></author><author><keyname>Lasaulce</keyname><forenames>Samson</forenames></author><author><keyname>Debbah</keyname><forenames>Merouane</forenames></author></authors><title>Power Allocation Games for MIMO Multiple Access Channels with
  Coordination</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Wireless Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A game theoretic approach is used to derive the optimal decentralized power
allocation (PA) in fast fading multiple access channels where the transmitters
and receiver are equipped with multiple antennas. The players (the mobile
terminals) are free to choose their PA in order to maximize their individual
transmission rates (in particular they can ignore some specified centralized
policies). A simple coordination mechanism between users is introduced. The
nature and influence of this mechanism is studied in detail. The coordination
signal indicates to the users the order in which the receiver applies
successive interference cancellation and the frequency at which this order is
used. Two different games are investigated: the users can either adapt their
temporal PA to their decoding rank at the receiver or optimize their spatial PA
between their transmit antennas. For both games a thorough analysis of the
existence, uniqueness and sum-rate efficiency of the network Nash equilibrium
is conducted. Analytical and simulation results are provided to assess the gap
between the decentralized network performance and its equivalent virtual
multiple input multiple output system, which is shown to be zero in some cases
and relatively small in general.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2621</identifier>
 <datestamp>2009-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2621</id><created>2009-02-16</created><authors><author><keyname>Breslav</keyname><forenames>Andrey</forenames></author></authors><title>Creating modular and reusable DSL textual syntax definitions with
  Grammatic/ANTLR</title><categories>cs.PL cs.SE</categories><comments>Submitted to PSI'09</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present Grammatic -- a tool for textual syntax definition.
Grammatic serves as a front-end for parser generators (and other tools) and
brings modularity and reuse to their development artifacts. It adapts
techniques for separation of concerns from Apsect-Oriented Programming to
grammars and uses templates for grammar reuse. We illustrate usage of Grammatic
by describing a case study: bringing separation of concerns to ANTLR parser
generator, which is achieved without a common time- and memory-consuming
technique of building an AST to separate semantic actions from a grammar
definition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2648</identifier>
 <datestamp>2009-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2648</id><created>2009-02-16</created><authors><author><keyname>Grossi</keyname><forenames>Roberto</forenames></author><author><keyname>Orlandi</keyname><forenames>Alessio</forenames></author><author><keyname>Raman</keyname><forenames>Rajeev</forenames></author><author><keyname>Rao</keyname><forenames>S. Srinivasa</forenames></author></authors><title>More Haste, Less Waste: Lowering the Redundancy in Fully Indexable
  Dictionaries</title><categories>cs.DS</categories><proxy>ccsd inria-00360601</proxy><journal-ref>26th International Symposium on Theoretical Aspects of Computer
  Science STACS 2009 (2009) 517-528</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of representing, in a compressed format, a bit-vector
$S$ of $m$ bits with $n$ 1s, supporting the following operations, where $b \in
\{0, 1 \}$: $rank_b(S,i)$ returns the number of occurrences of bit $b$ in the
prefix $S[1..i]$; $select_b(S,i)$ returns the position of the $i$th occurrence
of bit $b$ in $S$. Such a data structure is called \emph{fully indexable
dictionary (FID)} [Raman et al.,2007], and is at least as powerful as
predecessor data structures. Our focus is on space-efficient FIDs on the
\textsc{ram} model with word size $\Theta(\lg m)$ and constant time for all
operations, so that the time cost is independent of the input size. Given the
bitstring $S$ to be encoded, having length $m$ and containing $n$ ones, the
minimal amount of information that needs to be stored is $B(n,m) = \lceil \log
{{m}\choose{n}} \rceil$. The state of the art in building a FID for $S$ is
given in [Patrascu,2008] using $B(m,n)+O(m / ((\log m/ t) ^t)) + O(m^{3/4}) $
bits, to support the operations in $O(t)$ time. Here, we propose a parametric
data structure exhibiting a time/space trade-off such that, for any real
constants $0 &lt; \delta \leq 1/2$, $0 &lt; \eps \leq 1$, and integer $s &gt; 0$, it
uses \[ B(n,m) + O(n^{1+\delta} + n (\frac{m}{n^s})^\eps) \] bits and performs
all the operations in time $O(s\delta^{-1} + \eps^{-1})$. The improvement is
twofold: our redundancy can be lowered parametrically and, fixing $s = O(1)$,
we get a constant-time FID whose space is $B(n,m) + O(m^\eps/\poly{n})$ bits,
for sufficiently large $m$. This is a significant improvement compared to the
previous bounds for the general case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2649</identifier>
 <datestamp>2009-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2649</id><created>2009-02-16</created><authors><author><keyname>Hermelin</keyname><forenames>Danny</forenames><affiliation>CSAIL</affiliation></author><author><keyname>Landau</keyname><forenames>Gad M.</forenames><affiliation>CSAIL</affiliation></author><author><keyname>Landau</keyname><forenames>Shir</forenames><affiliation>CSAIL</affiliation></author><author><keyname>Weimann</keyname><forenames>Oren</forenames><affiliation>CSAIL</affiliation></author></authors><title>A Unified Algorithm for Accelerating Edit-Distance Computation via
  Text-Compression</title><categories>cs.CC cs.DS</categories><proxy>ccsd inria-00360821</proxy><journal-ref>26th International Symposium on Theoretical Aspects of Computer
  Science - STACS 2009 (2009) 529-540</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a unified framework for accelerating edit-distance computation
between two compressible strings using straight-line programs. For two strings
of total length $N$ having straight-line program representations of total size
$n$, we provide an algorithm running in $O(n^{1.4}N^{1.2})$ time for computing
the edit-distance of these two strings under any rational scoring function, and
an $O(n^{1.34}N^{1.34})$ time algorithm for arbitrary scoring functions. This
improves on a recent algorithm of Tiskin that runs in $O(nN^{1.5})$ time, and
works only for rational scoring functions. Also, in the last part of the paper,
we show how the classical four-russians technique can be incorporated into our
SLP edit-distance scheme, giving us a simple $\Omega(\lg N)$ speed-up in the
case of arbitrary scoring functions, for any pair of strings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2674</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2674</id><created>2009-02-16</created><updated>2010-02-03</updated><authors><author><keyname>Fortnow</keyname><forenames>Lance</forenames></author><author><keyname>Lutz</keyname><forenames>Jack H.</forenames></author><author><keyname>Mayordomo</keyname><forenames>Elvira</forenames></author></authors><title>Inseparability and Strong Hypotheses for Disjoint NP Pairs</title><categories>cs.CC</categories><acm-class>F.1.3</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This paper investigates the existence of inseparable disjoint pairs of NP
languages and related strong hypotheses in computational complexity. Our main
theorem says that, if NP does not have measure 0 in EXP, then there exist
disjoint pairs of NP languages that are P-inseparable, in fact
TIME(2^(n^k))-inseparable. We also relate these conditions to strong hypotheses
concerning randomness and genericity of disjoint pairs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2685</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2685</id><created>2009-02-16</created><updated>2009-06-09</updated><authors><author><keyname>Mo&#x15b;cicki</keyname><forenames>J. T.</forenames></author><author><keyname>Brochu</keyname><forenames>F.</forenames></author><author><keyname>Ebke</keyname><forenames>J.</forenames></author><author><keyname>Egede</keyname><forenames>U.</forenames></author><author><keyname>Elmsheuser</keyname><forenames>J.</forenames></author><author><keyname>Harrison</keyname><forenames>K.</forenames></author><author><keyname>Jones</keyname><forenames>R. W. L.</forenames></author><author><keyname>Lee</keyname><forenames>H. C.</forenames></author><author><keyname>Liko</keyname><forenames>D.</forenames></author><author><keyname>Maier</keyname><forenames>A.</forenames></author><author><keyname>Muraru</keyname><forenames>A.</forenames></author><author><keyname>Patrick</keyname><forenames>G. N.</forenames></author><author><keyname>Pajchel</keyname><forenames>K.</forenames></author><author><keyname>Reece</keyname><forenames>W.</forenames></author><author><keyname>Samset</keyname><forenames>B. H.</forenames></author><author><keyname>Slater</keyname><forenames>M. W.</forenames></author><author><keyname>Soroko</keyname><forenames>A.</forenames></author><author><keyname>Tan</keyname><forenames>C. L.</forenames></author><author><keyname>Vanderster</keyname><forenames>D. C.</forenames></author><author><keyname>Williams</keyname><forenames>M.</forenames></author></authors><title>Ganga: a tool for computational-task management and easy access to Grid
  resources</title><categories>cs.DC</categories><comments>Extended and clarified information on the Grid computing context for
  Ganga, supported job model etc. Additional minor corrections and
  clarifications. Updated the author list as agreed with the Ganga team</comments><acm-class>C.2.4; H.3.4; J.2; J.3</acm-class><doi>10.1016/j.cpc.2009.06.016</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present the computational task-management tool Ganga, which
allows for the specification, submission, bookkeeping and post-processing of
computational tasks on a wide set of distributed resources. Ganga has been
developed to solve a problem increasingly common in scientific projects, which
is that researchers must regularly switch between different processing systems,
each with its own command set, to complete their computational tasks. Ganga
provides a homogeneous environment for processing data on heterogeneous
resources. We give examples from High Energy Physics, demonstrating how an
analysis can be developed on a local system and then transparently moved to a
Grid system for processing of all available data. Ganga has an API that can be
used via an interactive interface, in scripts, or through a GUI. Specific
knowledge about types of tasks or computational resources is provided at
run-time through a plugin system, making new developments easy to integrate. We
give an overview of the Ganga architecture, give examples of current use, and
demonstrate how Ganga can be used in many different areas of science.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2692</identifier>
 <datestamp>2009-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2692</id><created>2009-02-16</created><authors><author><keyname>Djeumou</keyname><forenames>Brice</forenames><affiliation>LSS</affiliation></author><author><keyname>Lasaulce</keyname><forenames>Samson</forenames><affiliation>LSS</affiliation></author><author><keyname>Berthet</keyname><forenames>Antoine</forenames></author></authors><title>Combining coded signals with arbitrary modulations in orthogonal relay
  channels</title><categories>cs.IT math.IT</categories><proxy>ccsd hal-00361518</proxy><journal-ref>EURASIP Journal on Wireless Communications and Networking 2008,
  Article ID 287320, 4 pages (2008)</journal-ref><doi>10.1155/2008/287320</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a relay channel for which the following assumptions are made. (1)
The source-destination and relay-destination channels are orthogonal (frequency
division relay channel). (2) The relay implements the decode-and-forward
protocol. (3) The source and relay implement the same channel encoder, namely,
a onvolutional encoder. (4) They can use arbitrary and possibly different
modulations. In this framework, we derive the best combiner in the sense of the
maximum likelihood (ML) at the destination and the branch metrics of the
trellis associated with its channel decoder for the ML combiner and also for
the maximum ratio combiner (MRC), cooperative-MRC (C-MRC), and the minimum
mean-square error (MMSE) combiner.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2736</identifier>
 <datestamp>2009-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2736</id><created>2009-02-16</created><authors><author><keyname>Horn</keyname><forenames>Florian</forenames></author></authors><title>Random Fruits on the Zielonka Tree</title><categories>cs.GT cs.PF</categories><proxy>ccsd inria-00360829</proxy><journal-ref>26th International Symposium on Theoretical Aspects of Computer
  Science - STACS 2009 (2009) 541-552</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Stochastic games are a natural model for the synthesis of controllers
confronted to adversarial and/or random actions. In particular,
$\omega$-regular games of infinite length can represent reactive systems which
are not expected to reach a correct state, but rather to handle a continuous
stream of events. One critical resource in such applications is the memory used
by the controller. In this paper, we study the amount of memory that can be
saved through the use of randomisation in strategies, and present matching
upper and lower bounds for stochastic Muller games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2751</identifier>
 <datestamp>2009-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2751</id><created>2009-02-16</created><updated>2009-03-01</updated><authors><author><keyname>Mirbakhsh</keyname><forenames>Nima</forenames></author><author><keyname>Didandeh</keyname><forenames>Arman</forenames></author></authors><title>Object Classification by means of Multi-Feature Concept Learning in a
  Multi Expert-Agent System</title><categories>cs.MA cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Classification of some objects in classes of concepts is an essential and
even breathtaking task in many applications. A solution is discussed here based
on Multi-Agent systems. A kernel of some expert agents in several classes is to
consult a central agent decide among the classification problem of a certain
object. This kernel is moderated with the center agent, trying to manage the
querying agents for any decision problem by means of a data-header like feature
set. Agents have cooperation among concepts related to the classes of this
classification decision-making; and may affect on each others' results on a
certain query object in a multi-agent learning approach. This leads to an
online feature learning via the consulting trend. The performance is discussed
to be much better in comparison to some other prior trends while system's
message passing overload is decreased to less agents and the expertism helps
the performance and operability of system win the comparison.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2774</identifier>
 <datestamp>2015-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2774</id><created>2009-02-16</created><updated>2015-08-24</updated><authors><author><keyname>Yamakami</keyname><forenames>Tomoyuki</forenames></author></authors><title>Pseudorandom Generators Against Advised Context-Free Languages</title><categories>cs.FL cs.CC</categories><comments>A4, 10pt, 5 figures, 30 pages. This is the latest complete version,
  improving the readability</comments><acm-class>F.4.3; F.1.1; F.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pseudorandomness has played a central role in modern cryptography, finding
theoretical and practical applications to various fields of computer science. A
function that generates pseudorandom strings from shorter but truly random
seeds is known as a pseudorandom generator. Our generators are designed to fool
languages (or equivalently, Boolean-valued functions). In particular, our
generator fools advised context-free languages, namely, context-free languages
assisted by external information known as advice, and moreover our generator is
made almost one-to-one, stretching $n$-bit seeds to $n+1$ bits. We explicitly
construct such a pseudorandom generator, which is computed by a deterministic
Turing machine using logarithmic space and also belongs to CFLMV(2)/n---a
functional extension of the 2-conjunctive closure of CFL with the help of
appropriate deterministic advice. In contrast, we show that there is no almost
one-to-one pseudorandom generator against context-free languages if we demand
that it should be computed by a nondeterministic pushdown automaton equipped
with a write-only output tape. Our generator naturally extends known
pseudorandom generators against advised regular languages. Our proof of the
CFL/n-pseudorandomness of the generator is quite elementary, and in particular,
one part of the proof utilizes a special feature of the behaviors of
nondeterministic pushdown automata, called a swapping property, which is
interesting in its own right, generalizing the swapping lemma for context-free
languages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2783</identifier>
 <datestamp>2010-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2783</id><created>2009-02-16</created><updated>2010-01-08</updated><authors><author><keyname>Pourmohammad</keyname><forenames>Ali</forenames></author><author><keyname>Ahadi</keyname><forenames>Seyed Mohammad</forenames></author></authors><title>New Ica-Beamforming Method to Under-Determined BSS</title><categories>cs.SD</categories><comments>This paper has been withdrawn</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn by the author ali pourmohammad.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2788</identifier>
 <datestamp>2010-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2788</id><created>2009-02-16</created><updated>2010-01-08</updated><authors><author><keyname>Pourmohammad</keyname><forenames>Ali</forenames></author><author><keyname>Ahadi</keyname><forenames>Seyed Mohammad</forenames></author></authors><title>Using SLP Neural Network to Persian Handwritten Digits Recognition</title><categories>cs.CV</categories><comments>This paper has been withdrawn</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn by the author ali pourmohammad.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2795</identifier>
 <datestamp>2009-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2795</id><created>2009-02-16</created><authors><author><keyname>Chekuri</keyname><forenames>Chandra</forenames></author><author><keyname>Korula</keyname><forenames>Nitish</forenames></author></authors><title>A Graph Reduction Step Preserving Element-Connectivity and Applications</title><categories>cs.DS</categories><comments>23 pages, 6 figures</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given an undirected graph G=(V,E) and subset of terminals T \subseteq V, the
element-connectivity of two terminals u,v \in T is the maximum number of u-v
paths that are pairwise disjoint in both edges and non-terminals V \setminus T
(the paths need not be disjoint in terminals). Element-connectivity is more
general than edge-connectivity and less general than vertex-connectivity. Hind
and Oellermann gave a graph reduction step that preserves the global
element-connectivity of the graph. We show that this step also preserves local
connectivity, that is, all the pairwise element-connectivities of the
terminals. We give two applications of this reduction step to connectivity and
network design problems:
  1. Given a graph G and disjoint terminal sets T_1, T_2, ..., T_m, we seek a
maximum number of element-disjoint Steiner forests where each forest connects
each T_i. We prove that if each T_i is k-element-connected then there exist
\Omega(\frac{k}{\log h \log m}) element-disjoint Steiner forests, where h =
|\bigcup_i T_i|. If G is planar (or more generally, has fixed genus), we show
that there exist \Omega(k) Steiner forests. Our proofs are constructive, giving
poly-time algorithms to find these forests; these are the first non-trivial
algorithms for packing element-disjoint Steiner Forests.
  2. We give a very short and intuitive proof of a spider-decomposition theorem
of Chuzhoy and Khanna in the context of the single-sink k-vertex-connectivity
problem; this yields a simple and alternative analysis of an O(k \log n)
approximation.
  Our results highlight the effectiveness of the element-connectivity reduction
step; we believe it will find more applications in the future.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2851</identifier>
 <datestamp>2012-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2851</id><created>2009-02-17</created><updated>2012-02-29</updated><authors><author><keyname>Dieudonn&#xe9;</keyname><forenames>Yoann</forenames><affiliation>MIS</affiliation></author><author><keyname>Petit</keyname><forenames>Franck</forenames><affiliation>LIP6</affiliation></author><author><keyname>Villain</keyname><forenames>Vincent</forenames><affiliation>MIS</affiliation></author></authors><title>Leader Election Problem Versus Pattern Formation Problem</title><categories>cs.DC cs.MA</categories><proxy>ccsd inria-00361916</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Leader election and arbitrary pattern formation are funda- mental tasks for a
set of autonomous mobile robots. The former consists in distinguishing a unique
robot, called the leader. The latter aims in arranging the robots in the plane
to form any given pattern. The solv- ability of both these tasks turns out to
be necessary in order to achieve more complex tasks. In this paper, we study
the relationship between these two tasks in a model, called CORDA, wherein the
robots are weak in several aspects. In particular, they are fully asynchronous
and they have no direct means of communication. They cannot remember any
previous observation nor computation performed in any previous step. Such
robots are said to be oblivious. The robots are also uniform and anonymous,
i.e, they all have the same program using no global parameter (such as an
identity) allowing to differentiate any of them. Moreover, we assume that none
of them share any kind of common coordinate mechanism or common sense of
direction and we discuss the influence of a common handedness (i.e.,
chirality). In such a system, Flochini et al. proved in [11] that it is
possible to elect a leader for n \geq 3 robots if it is possible to form any
pattern for n \geq 3. In this paper, we show that the converse is true for n
\geq 4 when the robots share a common handedness and for n \geq 5 when they do
not. Thus, we deduce that with chirality (resp. without chirality) both
problems are equivalent for n \geq 4 (resp. n \geq 5) in CORDA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2853</identifier>
 <datestamp>2010-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2853</id><created>2009-02-17</created><updated>2010-03-04</updated><authors><author><keyname>Poinsot</keyname><forenames>Laurent</forenames><affiliation>LIPN</affiliation></author><author><keyname>Duchamp</keyname><forenames>G&#xe9;rard</forenames><affiliation>LIPN</affiliation></author></authors><title>A formal calculus on the Riordan near algebra</title><categories>cs.SC math.CO</categories><comments>29 p</comments><proxy>ccsd hal-00361379</proxy><journal-ref>Advances and Applications in Discrete Mathematics 6, 1 (2010)
  11-44</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Riordan group is the semi-direct product of a multiplicative group of
invertible series and a group, under substitution, of non units. The Riordan
near algebra, as introduced in this paper, is the Cartesian product of the
algebra of formal power series and its principal ideal of non units, equipped
with a product that extends the multiplication of the Riordan group. The later
is naturally embedded as a subgroup of units into the former. In this paper, we
prove the existence of a formal calculus on the Riordan algebra. This formal
calculus plays a role similar to those of holomorphic calculi in the Banach or
Fr\'echet algebras setting, but without the constraint of a radius of
convergence. Using this calculus, we define \emph{en passant} a notion of
generalized powers in the Riordan group.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2859</identifier>
 <datestamp>2009-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2859</id><created>2009-02-17</created><authors><author><keyname>Bergstra</keyname><forenames>J. A.</forenames></author><author><keyname>Middelburg</keyname><forenames>C. A.</forenames></author></authors><title>Transmission protocols for instruction streams</title><categories>cs.PL cs.DC</categories><comments>13 pages</comments><report-no>PRG0903</report-no><acm-class>D.2.1; D.2.4; F.1.1; F.3.1</acm-class><journal-ref>In ICTAC 2009, pages 127--139. Springer-Verlag, LNCS 5684, 2009</journal-ref><doi>10.1007/978-3-642-03466-4_8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Threads as considered in thread algebra model behaviours to be controlled by
some execution environment: upon each action performed by a thread, a reply
from its execution environment -- which takes the action as an instruction to
be processed -- determines how the thread proceeds. In this paper, we are
concerned with the case where the execution environment is remote: we describe
and analyse some transmission protocols for passing instructions from a thread
to a remote execution environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2866</identifier>
 <datestamp>2009-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2866</id><created>2009-02-17</created><updated>2009-04-30</updated><authors><author><keyname>Cattuto</keyname><forenames>Ciro</forenames><affiliation>CPT</affiliation></author><author><keyname>Barrat</keyname><forenames>Alain</forenames><affiliation>CPT</affiliation></author><author><keyname>Baldassarri</keyname><forenames>Andrea</forenames><affiliation>LPT</affiliation></author><author><keyname>Schehr</keyname><forenames>G.</forenames><affiliation>LPT</affiliation></author><author><keyname>Loreto</keyname><forenames>Vittorio</forenames></author></authors><title>Collective dynamics of social annotation</title><categories>cs.CY cond-mat.stat-mech physics.soc-ph</categories><proxy>ccsd hal-00361199</proxy><journal-ref>Proceeding of the national academy of sciences 106 (2009) 10511</journal-ref><doi>10.1073/pnas.0901136106</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The enormous increase of popularity and use of the WWW has led in the recent
years to important changes in the ways people communicate. An interesting
example of this fact is provided by the now very popular social annotation
systems, through which users annotate resources (such as web pages or digital
photographs) with text keywords dubbed tags. Understanding the rich emerging
structures resulting from the uncoordinated actions of users calls for an
interdisciplinary effort. In particular concepts borrowed from statistical
physics, such as random walks, and the complex networks framework, can
effectively contribute to the mathematical modeling of social annotation
systems. Here we show that the process of social annotation can be seen as a
collective but uncoordinated exploration of an underlying semantic space,
pictured as a graph, through a series of random walks. This modeling framework
reproduces several aspects, so far unexplained, of social annotation, among
which the peculiar growth of the size of the vocabulary used by the community
and its complex network structure that represents an externalization of
semantic structures grounded in cognition and typically hard to access.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2871</identifier>
 <datestamp>2009-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2871</id><created>2009-02-17</created><authors><author><keyname>Musumbu</keyname><forenames>Kaninda</forenames><affiliation>LaBRI</affiliation></author></authors><title>The Semantics of Kalah Game</title><categories>cs.AI</categories><proxy>ccsd hal-00362005</proxy><journal-ref>ACM International conference Proceeding series, ISBN 0-9544145-6-X
  (2005) 191 - 196</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The present work consisted in developing a plateau game. There are the
traditional ones (monopoly, cluedo, ect.) but those which interest us leave
less place at the chance (luck) than to the strategy such that the chess game.
Kallah is an old African game, its rules are simple but the strategies to be
used are very complex to implement. Of course, they are based on a strongly
mathematical basis as in the film &quot;Rain-Man&quot; where one can see that gambling
can be payed with strategies based on mathematical theories. The Artificial
Intelligence gives the possibility &quot;of thinking&quot; to a machine and, therefore,
allows it to make decisions. In our work, we use it to give the means to the
computer choosing its best movement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2917</identifier>
 <datestamp>2009-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2917</id><created>2009-02-17</created><authors><author><keyname>Hesse</keyname><forenames>Matthias</forenames><affiliation>I3S</affiliation></author><author><keyname>Lebrun</keyname><forenames>Jerome</forenames><affiliation>I3S</affiliation></author><author><keyname>Deneire</keyname><forenames>Luc</forenames><affiliation>I3S</affiliation></author></authors><title>Full Rate L2-Orthogonal Space-Time CPM for Three Antennas</title><categories>cs.IT math.IT</categories><proxy>ccsd inria-00362141</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To combine the power efficiency of Continuous Phase Modulation (CPM) with
enhanced performance in fading environments, some authors have suggested to use
CPM in combination with Space-Time Codes (STC). Recently, we have proposed a
CPM ST-coding scheme based on L2-orthogonality for two transmitting antennas.
In this paper we extend this approach to the three antennas case. We
analytically derive a family of coding schemes which we call Parallel Code
(PC). This code family has full rate and we prove that the proposed coding
scheme achieves full diversity as confirmed by accompanying simulations. We
detail an example of the proposed ST codes that can be interpreted as a
conventional CPM scheme with different alphabet sets for the different transmit
antennas which results in a simplified implementation. Thanks to
L2-orthogonality, the decoding complexity, usually exponentially proportional
to the number of transmitting antennas, is reduced to linear complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2948</identifier>
 <datestamp>2009-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2948</id><created>2009-02-17</created><authors><author><keyname>Hesse</keyname><forenames>Matthias</forenames><affiliation>I3S</affiliation></author><author><keyname>Lebrun</keyname><forenames>Jerome</forenames><affiliation>I3S</affiliation></author><author><keyname>Deneire</keyname><forenames>Luc</forenames><affiliation>I3S</affiliation></author></authors><title>Optimized L2-Orthogonal STC CPM for 3 Antennas</title><categories>cs.IT math.IT</categories><proxy>ccsd inria-00362167</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we introduce further our recently designed family of L2
orthogonal Space-Time codes for CPM. With their advantage of maintaining both
the constant envelope properties of CPM, the diversity of Space-Time codes and
moreover orthogonality, and thus reduced decoding complexity, these codes are
also full rate, even for more than two transmitting antennas. The issue of
power efficiency for these codes is first dealt with by proving that the
inherent increase in bandwidth in these systems is quite moderate. It is then
detailed how the initial state of the code influences the coding gain and has
to be optimized. For the two and three antennas case, we determine the optimal
values by computer simulations and show how the coding gain and therewith the
bit error performance are significantly improved by this optimization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2953</identifier>
 <datestamp>2009-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2953</id><created>2009-02-17</created><authors><author><keyname>Lu</keyname><forenames>Shiyong</forenames></author><author><keyname>Huang</keyname><forenames>Rong</forenames></author><author><keyname>Chebotko</keyname><forenames>Artem</forenames></author><author><keyname>Deng</keyname><forenames>Yu</forenames></author><author><keyname>Fotouhi</keyname><forenames>Farshad</forenames></author></authors><title>ImageSpace: An Environment for Image Ontology Management</title><categories>cs.DL cs.DB cs.MM cs.SE</categories><comments>Appeared in the International Journal of Information Theories and
  Applications (IJITA), 11(2), pp. 127-134, 2004</comments><journal-ref>International Journal of Information Theories and Applications
  (IJITA), 11(2), pp. 127-134, 2004</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  More and more researchers have realized that ontologies will play a critical
role in the development of the Semantic Web, the next generation Web in which
content is not only consumable by humans, but also by software agents. The
development of tools to support ontology management including creation,
visualization, annotation, database storage, and retrieval is thus extremely
important. We have developed ImageSpace, an image ontology creation and
annotation tool that features (1) full support for the standard web ontology
language DAML+OIL; (2) image ontology creation, visualization, image annotation
and display in one integrated framework; (3) ontology consistency assurance;
and (4) storing ontologies and annotations in relational databases. It is
expected that the availability of such a tool will greatly facilitate the
creation of image repositories as islands of the Semantic Web.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2969</identifier>
 <datestamp>2013-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2969</id><created>2009-02-17</created><updated>2010-02-26</updated><authors><author><keyname>Japaridze</keyname><forenames>Giorgi</forenames></author></authors><title>Ptarithmetic</title><categories>cs.LO cs.AI cs.CC</categories><comments>Substantially better versions are on their way. Hence the present
  article probably will not be published</comments><acm-class>F.1.1; F.1.2; F.1.3</acm-class><journal-ref>The Baltic International Yearbook on Cognition, Logic and
  Communication 8 (2013), Article 5, pp. 1-186</journal-ref><doi>10.4148/1944-3676.1074</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The present article introduces ptarithmetic (short for &quot;polynomial time
arithmetic&quot;) -- a formal number theory similar to the well known Peano
arithmetic, but based on the recently born computability logic (see
http://www.cis.upenn.edu/~giorgi/cl.html) instead of classical logic. The
formulas of ptarithmetic represent interactive computational problems rather
than just true/false statements, and their &quot;truth&quot; is understood as existence
of a polynomial time solution. The system of ptarithmetic elaborated in this
article is shown to be sound and complete. Sound in the sense that every
theorem T of the system represents an interactive number-theoretic
computational problem with a polynomial time solution and, furthermore, such a
solution can be effectively extracted from a proof of T. And complete in the
sense that every interactive number-theoretic problem with a polynomial time
solution is represented by some theorem T of the system.
  The paper is self-contained, and can be read without any previous familiarity
with computability logic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2975</identifier>
 <datestamp>2009-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2975</id><created>2009-02-17</created><authors><author><keyname>Wirth</keyname><forenames>Claus-Peter</forenames></author><author><keyname>Lunde</keyname><forenames>Ruediger</forenames></author></authors><title>Writing Positive/Negative-Conditional Equations Conveniently</title><categories>cs.AI cs.LO</categories><comments>ii + 21 pages</comments><report-no>SEKI Working-Paper SWP-94-04</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a convenient notation for positive/negative-conditional equations.
The idea is to merge rules specifying the same function by using case-, if-,
match-, and let-expressions. Based on the presented macro-rule-construct,
positive/negative-conditional equational specifications can be written on a
higher level. A rewrite system translates the macro-rule-constructs into
positive/negative-conditional equations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2995</identifier>
 <datestamp>2009-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2995</id><created>2009-02-17</created><authors><author><keyname>Lunde</keyname><forenames>Ruediger</forenames></author><author><keyname>Wirth</keyname><forenames>Claus-Peter</forenames></author></authors><title>ASF+ --- eine ASF-aehnliche Spezifikationssprache</title><categories>cs.AI cs.SC</categories><comments>iv + 58 pages</comments><report-no>SEKI Working-Paper SWP-94-05</report-no><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Maintaining the main aspects of the algebraic specification language ASF as
presented in [Bergstra&amp;al.89] we have extend ASF with the following concepts:
While once exported names in ASF must stay visible up to the top the module
hierarchy, ASF+ permits a more sophisticated hiding of signature names. The
erroneous merging of distinct structures that occurs when importing different
actualizations of the same parameterized module in ASF is avoided in ASF+ by a
more adequate form of parameter binding. The new ``Namensraum''-concept of ASF+
permits the specifier on the one hand directly to identify the origin of hidden
names and on the other to decide whether an imported module is only to be
accessed or whether an important property of it is to be modified. In the first
case he can access one single globally provided version; in the second he has
to import a copy of the module. Finally ASF+ permits semantic conditions on
parameters and the specification of tasks for a theorem prover.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3026</identifier>
 <datestamp>2009-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3026</id><created>2009-02-17</created><authors><author><keyname>Chebotko</keyname><forenames>Artem</forenames></author><author><keyname>Deng</keyname><forenames>Yu</forenames></author><author><keyname>Lu</keyname><forenames>Shiyong</forenames></author><author><keyname>Fotouhi</keyname><forenames>Farshad</forenames></author><author><keyname>Aristar</keyname><forenames>Anthony</forenames></author><author><keyname>Brugman</keyname><forenames>Hennie</forenames></author><author><keyname>Klassmann</keyname><forenames>Alexander</forenames></author><author><keyname>Sloetjes</keyname><forenames>Han</forenames></author><author><keyname>Russel</keyname><forenames>Albert</forenames></author><author><keyname>Wittenburg</keyname><forenames>Peter</forenames></author></authors><title>OntoELAN: An Ontology-based Linguistic Multimedia Annotator</title><categories>cs.DL cs.DB cs.MM cs.SE</categories><comments>Appeared in the Proceedings of the IEEE Sixth International Symposium
  on Multimedia Software Engineering (IEEE-MSE'04), pp. 329-336, Miami, FL,
  USA, December, 2004</comments><journal-ref>Proceedings of the IEEE Sixth International Symposium on
  Multimedia Software Engineering (IEEE-MSE'04), pp. 329-336, Miami, FL, USA,
  December, 2004</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite its scientific, political, and practical value, comprehensive
information about human languages, in all their variety and complexity, is not
readily obtainable and searchable. One reason is that many language data are
collected as audio and video recordings which imposes a challenge to document
indexing and retrieval. Annotation of multimedia data provides an opportunity
for making the semantics explicit and facilitates the searching of multimedia
documents. We have developed OntoELAN, an ontology-based linguistic multimedia
annotator that features: (1) support for loading and displaying ontologies
specified in OWL; (2) creation of a language profile, which allows a user to
choose a subset of terms from an ontology and conveniently rename them if
needed; (3) creation of ontological tiers, which can be annotated with profile
terms and, therefore, corresponding ontological terms; and (4) saving
annotations in the XML format as Multimedia Ontology class instances and,
linked to them, class instances of other ontologies used in ontological tiers.
To our best knowledge, OntoELAN is the first audio/video annotation tool in
linguistic domain that provides support for ontology-based annotation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3027</identifier>
 <datestamp>2009-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3027</id><created>2009-02-17</created><authors><author><keyname>Chebotko</keyname><forenames>Artem</forenames></author><author><keyname>Lu</keyname><forenames>Shiyong</forenames></author><author><keyname>Fotouhi</keyname><forenames>Farshad</forenames></author><author><keyname>Aristar</keyname><forenames>Anthony</forenames></author></authors><title>Ontology-Based Annotation of Multimedia Language Data for the Semantic
  Web</title><categories>cs.DL cs.DB cs.MM</categories><comments>The book chapter appeared in Semantic Web-Based Information Systems:
  State-of-the-Art Applications, Amit Sheth and Miltiadis D. Lytras (Eds.),
  Idea Group Publishers, ISBN 1599044269, 2006</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There is an increasing interest and effort in preserving and documenting
endangered languages. Language data are valuable only when they are
well-cataloged, indexed and searchable. Many language data, particularly those
of lesser-spoken languages, are collected as audio and video recordings. While
multimedia data provide more channels and dimensions to describe a language's
function, and gives a better presentation of the cultural system associated
with the language of that community, they are not text-based or structured (in
binary format), and their semantics is implicit in their content. The content
is thus easy for a human being to understand, but difficult for computers to
interpret. Hence, there is a great need for a powerful and user-friendly system
to annotate multimedia data with text-based, well-structured and searchable
metadata. This chapter describes an ontology-based multimedia annotation tool,
OntoELAN, that enables annotation of language multimedia data with a linguistic
ontology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3056</identifier>
 <datestamp>2009-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3056</id><created>2009-02-18</created><authors><author><keyname>Jain</keyname><forenames>Rahul</forenames></author><author><keyname>Klauck</keyname><forenames>Hartmut</forenames></author></authors><title>New Results in the Simultaneous Message Passing Model</title><categories>cs.DC cs.CC cs.IT math.IT quant-ph</categories><comments>16 pages, version 1</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider the following Simultaneous Message Passing (SMP) model for computing
a relation f subset of X x Y x Z. In this model Alice, on input x in X and Bob,
on input y in Y, send one message each to a third party Referee who then
outputs a z in Z such that (x,y,z) in f. We first show optimal 'Direct sum'
results for all relations f in this model, both in the quantum and classical
settings, in the situation where we allow shared resources (shared entanglement
in quantum protocols and public coins in classical protocols) between Alice and
Referee and Bob and Referee and no shared resource between Alice and Bob. This
implies that, in this model, the communication required to compute k
simultaneous instances of f, with constant success overall, is at least k-times
the communication required to compute one instance with constant success.
  This in particular implies an earlier Direct sum result, shown by
Chakrabarti, Shi, Wirth and Yao, 2001, for the Equality function (and a class
of other so-called robust functions), in the classical smp model with no shared
resources between any parties.
  Furthermore we investigate the gap between the smp model and the one-way
model in communication complexity and exhibit a partial function that is
exponentially more expensive in the former if quantum communication with
entanglement is allowed, compared to the latter even in the deterministic case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3065</identifier>
 <datestamp>2009-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3065</id><created>2009-02-18</created><authors><author><keyname>Casale</keyname><forenames>Giuliano</forenames></author></authors><title>The Multi-Branched Method of Moments for Queueing Networks</title><categories>cs.PF</categories><acm-class>C.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new exact solution algorithm for closed multiclass product-form
queueing networks that is several orders of magnitude faster and less memory
consuming than established methods for multiclass models, such as the Mean
Value Analysis (MVA) algorithm. The technique is an important generalization of
the recently proposed Method of Moments (MoM) which, differently from MVA,
recursively computes higher-order moments of queue-lengths instead of mean
values.
  The main contribution of this paper is to prove that the information used in
the MoM recursion can be increased by considering multiple recursive branches
that evaluate models with different number of queues. This reformulation allows
to formulate a simpler matrix difference equation which leads to large
computational savings with respect to the original MoM recursion. Computational
analysis shows several cases where the proposed algorithm is between 1,000 and
10,000 times faster and less memory consuming than the original MoM, thus
extending the range of multiclass models where exact solutions are feasible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3072</identifier>
 <datestamp>2009-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3072</id><created>2009-02-18</created><authors><author><keyname>Laporte</keyname><forenames>Eric</forenames><affiliation>IGM-LabInfo</affiliation></author><author><keyname>Ranchhod</keyname><forenames>Elisabete</forenames><affiliation>ONSET-CEL</affiliation></author><author><keyname>Yannacopoulou</keyname><forenames>Anastasia</forenames><affiliation>IGM-LabInfo</affiliation></author></authors><title>Syntactic variation of support verb constructions</title><categories>cs.CL</categories><proxy>ccsd hal-00362241</proxy><journal-ref>Lingvisticae Investigationes 31, 2 (2008) 173-185</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We report experiments about the syntactic variations of support verb
constructions, a special type of multiword expressions (MWEs) containing
predicative nouns. In these expressions, the noun can occur with or without the
verb, with no clear-cut semantic difference. We extracted from a large French
corpus a set of examples of the two situations and derived statistical results
from these data. The extraction involved large-coverage language resources and
finite-state techniques. The results show that, most frequently, predicative
nouns occur without a support verb. This fact has consequences on methods of
extracting or recognising MWEs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3076</identifier>
 <datestamp>2009-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3076</id><created>2009-02-18</created><authors><author><keyname>Kraidy</keyname><forenames>Ghassan M.</forenames></author><author><keyname>Gresset</keyname><forenames>Nicolas</forenames></author><author><keyname>Boutros</keyname><forenames>Joseph J.</forenames></author></authors><title>Coding for the Non-Orthogonal Amplify-and-Forward Cooperative Channel</title><categories>cs.IT math.IT</categories><comments>25 pages, 10 figures, submitted to IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we consider the problem of coding for the half-duplex
non-orthogonal amplify-and-forward (NAF) cooperative channel where the
transmitter to relay and the inter-relay links are highly reliable. We derive
bounds on the diversity order of the NAF protocol that are achieved by a
distributed space-time bit-interleaved coded modulation (D-ST-BICM) scheme
under iterative APP detection and decoding. These bounds lead to the design of
space-time precoders that ensure maximum diversity order and high coding gains.
The word error rate performance of D-ST-BICM are also compared to outage
probability limits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3081</identifier>
 <datestamp>2009-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3081</id><created>2009-02-18</created><authors><author><keyname>Fraigniaud</keyname><forenames>Pierre</forenames></author><author><keyname>Korman</keyname><forenames>Amos</forenames></author></authors><title>Compact Ancestry Labeling Schemes for Trees of Small Depth</title><categories>cs.DS cs.DC cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An {\em ancestry labeling scheme} labels the nodes of any tree in such a way
that ancestry queries between any two nodes in a tree can be answered just by
looking at their corresponding labels. The common measure to evaluate the
quality of an ancestry labeling scheme is by its {\em label size}, that is the
maximal number of bits stored in a label, taken over all $n$-node trees. The
design of ancestry labeling schemes finds applications in XML search engines.
In the context of these applications, even small improvements in the label size
are important. In fact, the literature about this topic is interested in the
exact label size rather than just its order of magnitude. As a result,
following the proposal of an original scheme of size $2\log n$ bits, a
considerable amount of work was devoted to improve the bound on the label size.
The current state of the art upper bound is $\log n + O(\sqrt{\log n})$ bits
which is still far from the known $\log n + \Omega(\log\log n)$ lower bound.
Moreover, the hidden constant factor in the additive $O(\sqrt{\log n})$ term is
large, which makes this term dominate the label size for typical current XML
trees.
  In attempt to provide good performances for real XML data, we rely on the
observation that the depth of a typical XML tree is bounded from above by a
small constant. Having this in mind, we present an ancestry labeling scheme of
size $\log n+2\log d +O(1)$, for the family of trees with at most $n$ nodes and
depth at most $d$. In addition to our main result, we prove a result that may
be of independent interest concerning the existence of a linear {\em universal
graph} for the family of forests with trees of bounded depth.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3088</identifier>
 <datestamp>2009-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3088</id><created>2009-02-18</created><authors><author><keyname>Fulger</keyname><forenames>Daniel</forenames></author><author><keyname>Germano</keyname><forenames>Guido</forenames></author></authors><title>Automatic generation of non-uniform random variates for arbitrary
  pointwise computable probability densities by tiling</title><categories>cs.MS cs.NA</categories><comments>20 pages, 3 figures, submitted to a peer-reviewed journal</comments><acm-class>G.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a rejection method based on recursive covering of the probability
density function with equal tiles. The concept works for any probability
density function that is pointwise computable or representable by tabular data.
By the implicit construction of piecewise constant majorizing and minorizing
functions that are arbitrarily close to the density function the production of
random variates is arbitrarily independent of the computation of the density
function and extremely fast. The method works unattended for probability
densities with discontinuities (jumps and poles). The setup time is short,
marginally independent of the shape of the probability density and linear in
table size. Recently formulated requirements to a general and automatic
non-uniform random number generator are topped. We give benchmarks together
with a similar rejection method and with a transformation method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3104</identifier>
 <datestamp>2009-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3104</id><created>2009-02-18</created><authors><author><keyname>Dikshit</keyname><forenames>Devansh</forenames></author><author><keyname>Narahari</keyname><forenames>Y.</forenames></author></authors><title>On Framework and Hybrid Auction Approach to the Spectrum Licensing
  Procedure</title><categories>cs.GT cs.CY</categories><comments>working paper, please contact the authors if you see any mistakes 15
  pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inspired by the recent developments in the field of Spectrum Auctions, we
have tried to provide a comprehensive framework for the complete procedure of
Spectrum Licensing. We have identified the various issues the Governments need
to decide upon while designing the licensing procedure and what are the various
options available in each issue. We also provide an in depth study of how each
of this options impact the overall procedure along with theoretical and
practical results from the past. Lastly we argue as to how we can combine the
positives two most widely used Spectrum Auctions mechanisms into the Hybrid
Multiple Round Auction mechanism being proposed by us.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3114</identifier>
 <datestamp>2009-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3114</id><created>2009-02-18</created><authors><author><keyname>Maatouk</keyname><forenames>Ghid</forenames></author><author><keyname>Shokrollahi</keyname><forenames>Amin</forenames></author></authors><title>Analysis of the Second Moment of the LT Decoder</title><categories>cs.IT math.IT</categories><comments>5 pages, 1 figure; submitted to ISIT 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze the second moment of the ripple size during the LT decoding
process and prove that the standard deviation of the ripple size for an LT-code
with length $k$ is of the order of $\sqrt k.$ Together with a result by Karp
et. al stating that the expectation of the ripple size is of the order of $k$
[3], this gives bounds on the error probability of the LT decoder. We also give
an analytic expression for the variance of the ripple size up to terms of
constant order, and refine the expression in [3] for the expectation of the
ripple size up to terms of the order of $1/k$, thus providing a first step
towards an analytic finite-length analysis of LT decoding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3121</identifier>
 <datestamp>2009-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3121</id><created>2009-02-18</created><authors><author><keyname>Gacias</keyname><forenames>Bernat</forenames><affiliation>LAAS</affiliation></author><author><keyname>Artigues</keyname><forenames>Christian</forenames><affiliation>LAAS</affiliation></author><author><keyname>Lopez</keyname><forenames>Pierre</forenames><affiliation>LAAS</affiliation></author></authors><title>Parallel machine scheduling with precedence constraints and setup times</title><categories>cs.DS</categories><proxy>ccsd hal-00362159</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents different methods for solving parallel machine scheduling
problems with precedence constraints and setup times between the jobs. Limited
discrepancy search methods mixed with local search principles, dominance
conditions and specific lower bounds are proposed. The proposed methods are
evaluated on a set of randomly generated instances and compared with previous
results from the literature and those obtained with an efficient commercial
solver. We conclude that our propositions are quite competitive and our results
even outperform other approaches in most cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3136</identifier>
 <datestamp>2009-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3136</id><created>2009-02-18</created><authors><author><keyname>Pasquier</keyname><forenames>Claude</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Th&#xe9;ry</keyname><forenames>Laurent</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author></authors><title>A distributed editing environment for XML documents</title><categories>cs.SE</categories><proxy>ccsd hal-00362451</proxy><journal-ref>1st ECOOP Workshop on XML and Object Technology, Sophia Antipolis
  : France (2000)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  XML is based on two essential aspects: the modelization of data in a tree
like structure and the separation between the information itself and the way it
is displayed. XML structures are easily serializable. The separation between an
abstract representation and one or several views on it allows the elaboration
of specialized interfaces to visualize or modify data. A lot of developments
were made to interact with XML data but the use of these applications over the
Internet is just starting. This paper presents a prototype of a distributed
editing environment over the Internet. The key point of our system is the way
user interactions are handled. Selections and modifications made by a user are
not directly reflected on the concrete view, they are serialized in XML and
transmitted to a server which applies them to the document and broadcasts
updates to the views. This organization has several advantages. XML documents
coding selection and modification operations are usually smaller than the
edited document and can be directly processed with a transformation engine
which can adapt them to different representations. In addition, several
selections or modifications can be combined into an unique XML document. This
allows one to update multiple views with different frequencies and fits the
requirement of an asynchronous communication mode like HTTP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3175</identifier>
 <datestamp>2009-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3175</id><created>2009-02-18</created><updated>2009-02-21</updated><authors><author><keyname>Aaronson</keyname><forenames>Scott</forenames></author><author><keyname>Gall</keyname><forenames>Fran&#xe7;ois Le</forenames></author><author><keyname>Russell</keyname><forenames>Alexander</forenames></author><author><keyname>Tani</keyname><forenames>Seiichiro</forenames></author></authors><title>The One-Way Communication Complexity of Group Membership</title><categories>cs.CC quant-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the one-way communication complexity of the subgroup
membership problem, a classical problem closely related to basic questions in
quantum computing. Here Alice receives, as input, a subgroup $H$ of a finite
group $G$; Bob receives an element $x \in G$. Alice is permitted to send a
single message to Bob, after which he must decide if his input $x$ is an
element of $H$. We prove the following upper bounds on the classical
communication complexity of this problem in the bounded-error setting: (1) The
problem can be solved with $O(\log |G|)$ communication, provided the subgroup
$H$ is normal; (2) The problem can be solved with $O(d_{\max} \cdot \log |G|)$
communication, where $d_{\max}$ is the maximum of the dimensions of the
irreducible complex representations of $G$; (3) For any prime $p$ not dividing
$|G|$, the problem can be solved with $O(d_{\max} \cdot \log p)$ communication,
where $d_{\max}$ is the maximum of the dimensions of the irreducible
$\F_p$-representations of $G$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3176</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3176</id><created>2009-02-18</created><updated>2010-02-03</updated><authors><author><keyname>Beygelzimer</keyname><forenames>Alina</forenames></author><author><keyname>Langford</keyname><forenames>John</forenames></author><author><keyname>Ravikumar</keyname><forenames>Pradeep</forenames></author></authors><title>Error-Correcting Tournaments</title><categories>cs.AI cs.LG</categories><comments>Minor wording improvements</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a family of pairwise tournaments reducing $k$-class classification
to binary classification. These reductions are provably robust against a
constant fraction of binary errors. The results improve on the PECOC
construction \cite{SECOC} with an exponential improvement in computation, from
$O(k)$ to $O(\log_2 k)$, and the removal of a square root in the regret
dependence, matching the best possible computation and regret up to a constant.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3178</identifier>
 <datestamp>2009-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3178</id><created>2009-02-18</created><authors><author><keyname>Gunduz</keyname><forenames>Deniz</forenames><affiliation>Shitz</affiliation></author><author><keyname>Simeone</keyname><forenames>Osvaldo</forenames><affiliation>Shitz</affiliation></author><author><keyname>Goldsmith</keyname><forenames>Andrea J.</forenames><affiliation>Shitz</affiliation></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames><affiliation>Shitz</affiliation></author><author><keyname>Shamai</keyname><forenames>Shlomo</forenames><affiliation>Shitz</affiliation></author></authors><title>Multiple Multicasts with the Help of a Relay</title><categories>cs.IT math.IT</categories><comments>Submitted to Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of simultaneous multicasting of multiple messages with the help
of a relay terminal is considered. In particular, a model is studied in which a
relay station simultaneously assists two transmitters in multicasting their
independent messages to two receivers. The relay may also have an independent
message of its own to multicast. As a first step to address this general model,
referred to as the compound multiple access channel with a relay (cMACr), the
capacity region of the multiple access channel with a &quot;cognitive&quot; relay is
characterized, including the cases of partial and rate-limited cognition. Then,
achievable rate regions for the cMACr model are presented based on
decode-and-forward (DF) and compress-and-forward (CF) relaying strategies.
Moreover, an outer bound is derived for the special case, called the cMACr
without cross-reception, in which each transmitter has a direct link to one of
the receivers while the connection to the other receiver is enabled only
through the relay terminal. The capacity region is characterized for a binary
modulo additive cMACr without cross-reception, showing the optimality of binary
linear block codes, thus highlighting the benefits of physical layer network
coding and structured codes. Results are extended to the Gaussian channel model
as well, providing achievable rate regions for DF and CF, as well as for a
structured code design based on lattice codes. It is shown that the performance
with lattice codes approaches the upper bound for increasing power, surpassing
the rates achieved by the considered random coding-based techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3196</identifier>
 <datestamp>2009-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3196</id><created>2009-02-18</created><authors><author><keyname>Brucks</keyname><forenames>Claudine</forenames></author><author><keyname>Hilker</keyname><forenames>Michael</forenames></author><author><keyname>Schommer</keyname><forenames>Christoph</forenames></author><author><keyname>Wagner</keyname><forenames>Cynthia</forenames></author><author><keyname>Weires</keyname><forenames>Ralph</forenames></author></authors><title>Symbolic Computing with Incremental Mindmaps to Manage and Mine Data
  Streams - Some Applications</title><categories>cs.NE cs.AI</categories><comments>4 pages; 4 figures</comments><acm-class>I.2.6; H.2.8</acm-class><journal-ref>Proceedings of the 4th International Workshop on Neural-Symbolic
  Learning and Reasoning (NeSy '08); July 2008., Patras, Greece</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In our understanding, a mind-map is an adaptive engine that basically works
incrementally on the fundament of existing transactional streams. Generally,
mind-maps consist of symbolic cells that are connected with each other and that
become either stronger or weaker depending on the transactional stream. Based
on the underlying biologic principle, these symbolic cells and their
connections as well may adaptively survive or die, forming different cell
agglomerates of arbitrary size. In this work, we intend to prove mind-maps'
eligibility following diverse application scenarios, for example being an
underlying management system to represent normal and abnormal traffic behaviour
in computer networks, supporting the detection of the user behaviour within
search engines, or being a hidden communication layer for natural language
interaction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3207</identifier>
 <datestamp>2015-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3207</id><created>2009-02-18</created><authors><author><keyname>Fulger</keyname><forenames>Daniel</forenames></author><author><keyname>Scalas</keyname><forenames>Enrico</forenames></author><author><keyname>Germano</keyname><forenames>Guido</forenames></author></authors><title>Random numbers from the tails of probability distributions using the
  transformation method</title><categories>cs.MS cs.NA</categories><comments>17 pages, 7 figures, submitted to a peer-reviewed journal</comments><acm-class>G.3</acm-class><journal-ref>Fractional Calculus and Applied Analysis 16 (2), 332-353, 2013</journal-ref><doi>10.2478/s13540-013-0021-z</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The speed of many one-line transformation methods for the production of, for
example, Levy alpha-stable random numbers, which generalize Gaussian ones, and
Mittag-Leffler random numbers, which generalize exponential ones, is very high
and satisfactory for most purposes. However, for the class of decreasing
probability densities fast rejection implementations like the Ziggurat by
Marsaglia and Tsang promise a significant speed-up if it is possible to
complement them with a method that samples the tails of the infinite support.
This requires the fast generation of random numbers greater or smaller than a
certain value. We present a method to achieve this, and also to generate random
numbers within any arbitrary interval. We demonstrate the method showing the
properties of the transform maps of the above mentioned distributions as
examples of stable and geometric stable random numbers used for the stochastic
solution of the space-time fractional diffusion equation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3208</identifier>
 <datestamp>2009-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3208</id><created>2009-02-18</created><authors><author><keyname>Ron</keyname><forenames>Dorit</forenames></author><author><keyname>Safro</keyname><forenames>Ilya</forenames></author><author><keyname>Brandt</keyname><forenames>Achi</forenames></author></authors><title>A Fast Multigrid Algorithm for Energy Minimization Under Planar Density
  Constraints</title><categories>cs.DS cs.MS cs.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The two-dimensional layout optimization problem reinforced by the efficient
space utilization demand has a wide spectrum of practical applications.
Formulating the problem as a nonlinear minimization problem under planar
equality and/or inequality density constraints, we present a linear time
multigrid algorithm for solving correction to this problem. The method is
demonstrated on various graph drawing (visualization) instances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3210</identifier>
 <datestamp>2009-05-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3210</id><created>2009-02-18</created><updated>2009-05-04</updated><authors><author><keyname>Chandrasekhar</keyname><forenames>Vikram</forenames></author><author><keyname>Kountouris</keyname><forenames>Marios</forenames></author><author><keyname>Andrews</keyname><forenames>Jeffrey G.</forenames></author></authors><title>Coverage in Multi-Antenna Two-Tier Networks</title><categories>cs.NI cs.IT math.IT</categories><comments>30 Pages, 11 figures, Revised and Resubmitted to IEEE Transactions on
  Wireless Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In two-tier networks -- comprising a conventional cellular network overlaid
with shorter range hotspots (e.g. femtocells, distributed antennas, or wired
relays) -- with universal frequency reuse, the near-far effect from cross-tier
interference creates dead spots where reliable coverage cannot be guaranteed to
users in either tier. Equipping the macrocell and femtocells with multiple
antennas enhances robustness against the near-far problem. This work derives
the maximum number of simultaneously transmitting multiple antenna femtocells
meeting a per-tier outage probability constraint. Coverage dead zones are
presented wherein cross-tier interference bottlenecks cellular and hotspot
coverage. Two operating regimes are shown namely 1) a cellular-limited regime
in which femtocell users experience unacceptable cross-tier interference and 2)
a hotspot-limited regime wherein both femtocell users and cellular users are
limited by hotspot interference. Our analysis accounts for the per-tier
transmit powers, the number of transmit antennas (single antenna transmission
being a special case) and terrestrial propagation such as the Rayleigh fading
and the path loss exponents. Single-user (SU) multiple antenna transmission at
each tier is shown to provide significantly superior coverage and spatial reuse
relative to multiuser (MU) transmission. We propose a decentralized
carrier-sensing approach to regulate femtocell transmission powers based on
their location. Considering a worst-case cell-edge location, simulations using
typical path loss scenarios show that our interference management strategy
provides reliable cellular coverage with about 60 femtocells per cellsite.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3223</identifier>
 <datestamp>2009-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3223</id><created>2009-02-18</created><authors><author><keyname>Brito</keyname><forenames>Jose</forenames></author><author><keyname>Lila</keyname><forenames>Mauricio</forenames></author><author><keyname>Montenegro</keyname><forenames>Flavio</forenames></author><author><keyname>Maculan</keyname><forenames>Nelson</forenames></author></authors><title>An Exact Algorithm for the Stratification Problem with Proportional
  Allocation</title><categories>cs.LG cs.DM cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We report a new optimal resolution for the statistical stratification problem
under proportional sampling allocation among strata. Consider a finite
population of N units, a random sample of n units selected from this population
and a number L of strata. Thus, we have to define which units belong to each
stratum so as to minimize the variance of a total estimator for one desired
variable of interest in each stratum,and consequently reduce the overall
variance for such quantity. In order to solve this problem, an exact algorithm
based on the concept of minimal path in a graph is proposed and assessed.
Computational results using real data from IBGE (Brazilian Central Statistical
Office) are provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3282</identifier>
 <datestamp>2009-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3282</id><created>2009-02-18</created><authors><author><keyname>Brass</keyname><forenames>Peter</forenames></author><author><keyname>Knauer</keyname><forenames>Christian</forenames></author><author><keyname>Na</keyname><forenames>Hyeon-Suk</forenames></author><author><keyname>Shin</keyname><forenames>Chan-Su</forenames></author><author><keyname>Vigneron</keyname><forenames>Antoine</forenames></author></authors><title>Computing k-Centers On a Line</title><categories>cs.CG</categories><comments>14 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider several instances of the k-center on a line problem
where the goal is, given a set of points S in the plane and a parameter k &gt;= 1,
to find k disks with centers on a line l such that their union covers S and the
maximum radius of the disks is minimized. This problem is a constraint version
of the well-known k-center problem in which the centers are constrained to lie
in a particular region such as a segment, a line, and a polygon. We first
consider the simplest version of the problem where the line l is given in
advance; we can solve this problem in O(n log^2 n) time. We then investigate
the cases where only the orientation of the line l is fixed and where the line
l can be arbitrary. We can solve these problems in O(n^2 log^2 n) time and in
O(n^4 log^2 n) expected time, respectively. For the last two problems, we
present (1 + e)-approximation algorithms, which run in O((1/e) n log^2 n) time
and O((1/e^2) n log^2 n) time, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3286</identifier>
 <datestamp>2009-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3286</id><created>2009-02-18</created><authors><author><keyname>Subramanian</keyname><forenames>Arunkumar</forenames></author><author><keyname>McLaughlin</keyname><forenames>Steven W.</forenames></author></authors><title>MDS codes on the erasure-erasure wiretap channel</title><categories>cs.IT math.IT</categories><comments>Submitted to the 2009 IEEE International Symposium on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the problem of perfectly secure communication on a
modified version of Wyner's wiretap channel II where both the main and
wiretapper's channels have some erasures. A secret message is to be encoded
into $n$ channel symbols and transmitted. The main channel is such that the
legitimate receiver receives the transmitted codeword with exactly $n - \nu$
erasures, where the positions of the erasures are random. Additionally, an
eavesdropper (wire-tapper) is able to observe the transmitted codeword with $n
- \mu$ erasures in a similar fashion. This paper studies the maximum achievable
information rate with perfect secrecy on this channel and gives a coding scheme
using nested codes that achieves the secrecy capacity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3287</identifier>
 <datestamp>2009-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3287</id><created>2009-02-18</created><updated>2009-04-23</updated><authors><author><keyname>Land</keyname><forenames>Ingmar</forenames></author><author><keyname>Lechner</keyname><forenames>Gottfried</forenames></author><author><keyname>Rasmussen</keyname><forenames>Lars K.</forenames></author></authors><title>Adaptive Decoding of LDPC Codes with Binary Messages</title><categories>cs.IT math.IT</categories><comments>5 pages, 4 figures, to be published at ISIT 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A novel adaptive binary decoding algorithm for LDPC codes is proposed, which
reduces the decoding complexity while having a comparable or even better
performance than corresponding non-adaptive alternatives. In each iteration the
variable node decoders use the binary check node decoders multiple times; each
single use is referred to as a sub-iteration. To process the sequences of
binary messages in each iteration, the variable node decoders employ
pre-computed look-up tables. These look-up tables as well as the number of
sub-iterations per iteration are dynamically adapted during the decoding
process based on the decoder state, represented by the mutual information
between the current messages and the syndrome bits. The look-up tables and the
number of sub-iterations per iteration are determined and optimized using
density evolution. The performance and the complexity of the proposed adaptive
decoding algorithm is exemplified by simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3294</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3294</id><created>2009-02-17</created><updated>2010-09-01</updated><authors><author><keyname>Wirth</keyname><forenames>Claus-Peter</forenames></author></authors><title>Progress in Computer-Assisted Inductive Theorem Proving by
  Human-Orientedness and Descente Infinie?</title><categories>cs.AI cs.LO</categories><comments>ii + 35 pages</comments><report-no>SEKI Working-Paper SR-2006-01</report-no><journal-ref>Logic Journal of the IGPL, 2012, Volume 20, Pp. 1046-1063</journal-ref><doi>10.1093/jigpal/jzr048</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this short position paper we briefly review the development history of
automated inductive theorem proving and computer-assisted mathematical
induction. We think that the current low expectations on progress in this field
result from a faulty narrow-scope historical projection. Our main motivation is
to explain--on an abstract but hopefully sufficiently descriptive level--why we
believe that future progress in the field is to result from human-orientedness
and descente infinie.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3304</identifier>
 <datestamp>2009-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3304</id><created>2009-02-19</created><authors><author><keyname>Basu</keyname><forenames>Saugata</forenames></author><author><keyname>Leroy</keyname><forenames>Richard</forenames></author><author><keyname>Roy</keyname><forenames>Marie-Francoise</forenames></author></authors><title>A bound on the minimum of a real positive polynomial over the standard
  simplex</title><categories>cs.SC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of bounding away from 0 the minimum value m taken by
a polynomial P of Z[X_1,...,X_k] over the standard simplex, assuming that m&gt;0.
Recent algorithmic developments in real algebraic geometry enable us to obtain
a positive lower bound on m in terms of the dimension k, the degree d and the
bitsize of the coefficients of P. The bound is explicit, and obtained without
any extra assumption on P, in contrast with previous results reported in the
literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3372</identifier>
 <datestamp>2009-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3372</id><created>2009-02-19</created><authors><author><keyname>Koch</keyname><forenames>Tobias</forenames></author><author><keyname>Lapidoth</keyname><forenames>Amos</forenames></author></authors><title>Gaussian Fading Is the Worst Fading</title><categories>cs.IT math.IT</categories><comments>12 pages, submitted to the IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The capacity of peak-power limited, single-antenna, noncoherent, flat-fading
channels with memory is considered. The emphasis is on the capacity pre-log,
i.e., on the limiting ratio of channel capacity to the logarithm of the
signal-to-noise ratio (SNR), as the SNR tends to infinity. It is shown that,
among all stationary &amp; ergodic fading processes of a given spectral
distribution function and whose law has no mass point at zero, the Gaussian
process gives rise to the smallest pre-log. The assumption that the law of the
fading process has no mass point at zero is essential in the sense that there
exist stationary &amp; ergodic fading processes whose law has a mass point at zero
and that give rise to a smaller pre-log than the Gaussian process of equal
spectral distribution function. An extension of our results to multiple-input
single-output fading channels with memory is also presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3373</identifier>
 <datestamp>2009-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3373</id><created>2009-02-19</created><authors><author><keyname>Cordier</keyname><forenames>Marie-Odile</forenames><affiliation>INRIA - Irisa</affiliation></author><author><keyname>Fromont</keyname><forenames>Elisa</forenames><affiliation>LAHC</affiliation></author><author><keyname>Quiniou</keyname><forenames>Ren&#xe9;</forenames><affiliation>INRIA - Irisa</affiliation></author></authors><title>Learning rules from multisource data for cardiac monitoring</title><categories>cs.LG</categories><proxy>ccsd hal-00362831</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper formalises the concept of learning symbolic rules from multisource
data in a cardiac monitoring context. Our sources, electrocardiograms and
arterial blood pressure measures, describe cardiac behaviours from different
viewpoints. To learn interpretable rules, we use an Inductive Logic Programming
(ILP) method. We develop an original strategy to cope with the dimensionality
issues caused by using this ILP technique on a rich multisource language. The
results show that our method greatly improves the feasibility and the
efficiency of the process while staying accurate. They also confirm the
benefits of using multiple sources to improve the diagnosis of cardiac
arrhythmias.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3430</identifier>
 <datestamp>2009-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3430</id><created>2009-02-19</created><updated>2009-02-23</updated><authors><author><keyname>Mansour</keyname><forenames>Yishay</forenames></author><author><keyname>Mohri</keyname><forenames>Mehryar</forenames></author><author><keyname>Rostamizadeh</keyname><forenames>Afshin</forenames></author></authors><title>Domain Adaptation: Learning Bounds and Algorithms</title><categories>cs.LG cs.AI</categories><comments>12 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the general problem of domain adaptation which arises in
a variety of applications where the distribution of the labeled sample
available somewhat differs from that of the test data. Building on previous
work by Ben-David et al. (2007), we introduce a novel distance between
distributions, discrepancy distance, that is tailored to adaptation problems
with arbitrary loss functions. We give Rademacher complexity bounds for
estimating the discrepancy distance from finite samples for different loss
functions. Using this distance, we derive novel generalization bounds for
domain adaptation for a wide family of loss functions. We also present a series
of novel adaptation bounds for large classes of regularization-based
algorithms, including support vector machines and kernel ridge regression based
on the empirical discrepancy. This motivates our analysis of the problem of
minimizing the empirical discrepancy for various loss functions for which we
also give novel algorithms. We report the results of preliminary experiments
that demonstrate the benefits of our discrepancy minimization algorithms for
domain adaptation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3485</identifier>
 <datestamp>2009-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3485</id><created>2009-02-19</created><authors><author><keyname>Arthur</keyname><forenames>David</forenames></author><author><keyname>Motwani</keyname><forenames>Rajeev</forenames></author><author><keyname>Sharma</keyname><forenames>Aneesh</forenames></author><author><keyname>Xu</keyname><forenames>Ying</forenames></author></authors><title>Pricing strategies for viral marketing on Social Networks</title><categories>cs.DS cs.CY</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We study the use of viral marketing strategies on social networks to maximize
revenue from the sale of a single product. We propose a model in which the
decision of a buyer to buy the product is influenced by friends that own the
product and the price at which the product is offered. The influence model we
analyze is quite general, naturally extending both the Linear Threshold model
and the Independent Cascade model, while also incorporating price information.
We consider sales proceeding in a cascading manner through the network, i.e. a
buyer is offered the product via recommendations from its neighbors who own the
product. In this setting, the seller influences events by offering a cashback
to recommenders and by setting prices (via coupons or discounts) for each buyer
in the social network.
  Finding a seller strategy which maximizes the expected revenue in this
setting turns out to be NP-hard. However, we propose a seller strategy that
generates revenue guaranteed to be within a constant factor of the optimal
strategy in a wide variety of models. The strategy is based on an
influence-and-exploit idea, and it consists of finding the right trade-off at
each time step between: generating revenue from the current user versus
offering the product for free and using the influence generated from this sale
later in the process. We also show how local search can be used to improve the
performance of this technique in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3503</identifier>
 <datestamp>2009-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3503</id><created>2009-02-19</created><authors><author><keyname>Jeganathan</keyname><forenames>L</forenames></author><author><keyname>Rama</keyname><forenames>R</forenames></author><author><keyname>Sengupta</keyname><forenames>Ritabrata</forenames></author></authors><title>Generalised sequential crossover of words and languages</title><categories>cs.DM</categories><comments>23 pages, 3 figures</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this paper, we propose a new operation, Generalised Sequential Crossover
(GSCO) of words, which in some sense an abstract model of crossing over of the
chromosomes in the living organisms. We extend GSCO over language $L$
iteratively ($GSCO^*(L)$ as well as iterated GSCO over two languages
$GSCO^*(L_1,L_2)$). Our study reveals that $GSCO^*(L)$ is subclass of regular
languages for any $L$. We compare the different classes of GSCO languages with
the prominent sub-regular classes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3513</identifier>
 <datestamp>2009-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3513</id><created>2009-02-19</created><authors><author><keyname>Burgin</keyname><forenames>Mark</forenames></author><author><keyname>Dodig-Crnkovic</keyname><forenames>Gordana</forenames></author></authors><title>A Systematic Approach to Artificial Agents</title><categories>cs.AI cs.MA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Agents and agent systems are becoming more and more important in the
development of a variety of fields such as ubiquitous computing, ambient
intelligence, autonomous computing, intelligent systems and intelligent
robotics. The need for improvement of our basic knowledge on agents is very
essential. We take a systematic approach and present extended classification of
artificial agents which can be useful for understanding of what artificial
agents are and what they can be in the future. The aim of this classification
is to give us insights in what kind of agents can be created and what type of
problems demand a specific kind of agents for their solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3517</identifier>
 <datestamp>2009-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3517</id><created>2009-02-20</created><authors><author><keyname>Augustine</keyname><forenames>John</forenames></author><author><keyname>Han</keyname><forenames>Qi</forenames></author><author><keyname>Loden</keyname><forenames>Philip</forenames></author><author><keyname>Lodha</keyname><forenames>Sachin</forenames></author><author><keyname>Roy</keyname><forenames>Sasanka</forenames></author></authors><title>Energy-Efficient Shortest Path Algorithms for Convergecast in Sensor
  Networks</title><categories>cs.DS cs.DC cs.DM</categories><comments>15 pages, 7 figures</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a variant of the capacitated vehicle routing problem that is
encountered in sensor networks for scientific data collection. Consider an
undirected graph $G=(V \cup \{\mathbf{sink}\},E)$. Each vertex $v \in V$ holds
a constant-sized reading normalized to 1 byte that needs to be communicated to
the $\mathbf{sink}$. The communication protocol is defined such that readings
travel in packets. The packets have a capacity of $k$ bytes. We define a {\em
packet hop} to be the communication of a packet from a vertex to its neighbor.
Each packet hop drains one unit of energy and therefore, we need to communicate
the readings to the $\mathbf{sink}$ with the fewest number of hops.
  We show this problem to be NP-hard and counter it with a simple distributed
$(2-\frac{3}{2k})$-approximation algorithm called {\tt SPT} that uses the
shortest path tree rooted at the $\mathbf{sink}$. We also show that {\tt SPT}
is absolutely optimal when $G$ is a tree and asymptotically optimal when $G$ is
a grid. Furthermore, {\tt SPT} has two nice properties. Firstly, the readings
always travel along a shortest path toward the $\mathbf{sink}$, which makes it
an appealing solution to the convergecast problem as it fits the natural
intuition. Secondly, each node employs a very elementary packing strategy.
Given all the readings that enter into the node, it sends out as many fully
packed packets as possible followed by at most 1 partial packet. We show that
any solution that has either one of the two properties cannot be a
$(2-\epsilon)$-approximation, for any fixed $\epsilon &gt; 0$. This makes \spt
optimal for the class of algorithms that obey either one of those properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3526</identifier>
 <datestamp>2009-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3526</id><created>2009-02-20</created><updated>2009-03-27</updated><authors><author><keyname>Lugosi</keyname><forenames>Gabor</forenames><affiliation>DMA, GREGH</affiliation></author><author><keyname>Papaspiliopoulos</keyname><forenames>Omiros</forenames><affiliation>DMA, GREGH</affiliation></author><author><keyname>Stoltz</keyname><forenames>Gilles</forenames><affiliation>DMA, GREGH</affiliation></author></authors><title>Online Multi-task Learning with Hard Constraints</title><categories>stat.ML cs.LG math.ST stat.TH</categories><proxy>ccsd hal-00362643</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss multi-task online learning when a decision maker has to deal
simultaneously with M tasks. The tasks are related, which is modeled by
imposing that the M-tuple of actions taken by the decision maker needs to
satisfy certain constraints. We give natural examples of such restrictions and
then discuss a general class of tractable constraints, for which we introduce
computationally efficient ways of selecting actions, essentially by reducing to
an on-line shortest path problem. We briefly discuss &quot;tracking&quot; and &quot;bandit&quot;
versions of the problem and extend the model in various ways, including
non-additive global losses and uncountably infinite sets of tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3528</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3528</id><created>2009-02-20</created><authors><author><keyname>Blin</keyname><forenames>L&#xe9;lia</forenames><affiliation>IBISC</affiliation></author><author><keyname>Potop-Butucaru</keyname><forenames>Maria Gradinariu</forenames><affiliation>LIP6</affiliation></author><author><keyname>Rovedakis</keyname><forenames>Stephane</forenames><affiliation>IBISC</affiliation></author></authors><title>A Superstabilizing $\log(n)$-Approximation Algorithm for Dynamic Steiner
  Trees</title><categories>cs.DC cs.DS cs.NI</categories><proxy>ccsd hal-00363003</proxy><doi>10.1007/978-3-642-05118-0_10</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we design and prove correct a fully dynamic distributed
algorithm for maintaining an approximate Steiner tree that connects via a
minimum-weight spanning tree a subset of nodes of a network (referred as
Steiner members or Steiner group) . Steiner trees are good candidates to
efficiently implement communication primitives such as publish/subscribe or
multicast, essential building blocks for the new emergent networks (e.g. P2P,
sensor or adhoc networks). The cost of the solution returned by our algorithm
is at most $\log |S|$ times the cost of an optimal solution, where $S$ is the
group of members. Our algorithm improves over existing solutions in several
ways. First, it tolerates the dynamism of both the group members and the
network. Next, our algorithm is self-stabilizing, that is, it copes with nodes
memory corruption. Last but not least, our algorithm is
\emph{superstabilizing}. That is, while converging to a correct configuration
(i.e., a Steiner tree) after a modification of the network, it keeps offering
the Steiner tree service during the stabilization time to all members that have
not been affected by this modification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3532</identifier>
 <datestamp>2009-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3532</id><created>2009-02-20</created><updated>2009-03-23</updated><authors><author><keyname>Tropashko</keyname><forenames>Vadim</forenames></author></authors><title>Relational Lattice Foundation for Algebraic Logic</title><categories>cs.DB cs.LO</categories><comments>15 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Relational Lattice is a succinct mathematical model for Relational Algebra.
It reduces the set of six classic relational algebra operators to two: natural
join and inner union. In this paper we push relational lattice theory in two
directions. First, we uncover a pair of complementary lattice operators, and
organize the model into a bilattice of four operations and four distinguished
constants. We take a notice a peculiar way bilattice symmetry is broken. Then,
we give axiomatic introduction of unary negation operation and prove several
laws, including double negation and De Morgan. Next we reduce the model back to
two basic binary operations and twelve axioms, and exhibit a convincing
argument that the resulting system is complete in model-theoretic sense. The
final parts of the paper casts relational lattice perspective onto database
dependency theory and into cylindric algebras.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3541</identifier>
 <datestamp>2009-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3541</id><created>2009-02-20</created><authors><author><keyname>Bagdasaryan</keyname><forenames>Armen</forenames></author></authors><title>System approach to synthesis, modeling and control of complex dynamical
  systems</title><categories>cs.CE</categories><comments>11 pages, 2 fig.; submitted for journal publication</comments><journal-ref>WSEAS Trans. Systems and Control, vol. 4, no. 2, 2009, pp. 77-87</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the basic features of complex dynamical and control systems.
Special attention is paid to the problems of synthesis of dynamical models of
complex systems, construction of efficient control models, and to the
development of simulation techniques. We propose an approach to the synthesis
of dynamic models of complex systems that integrates expert knowledge with the
process of modeling. A set-theoretic model of complex system is defined and
briefly analyzed. A mathematical model of complex dynamical system with
control, based on aggregate description, is also proposed. The structure of the
model is described, and architecture of computer simulation system is
presented, requirements to and components of computer simulation systems are
analyzed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3548</identifier>
 <datestamp>2011-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3548</id><created>2009-02-20</created><authors><author><keyname>Zlati&#x107;</keyname><forenames>Vinko</forenames></author><author><keyname>&#x160;tefan&#x10d;i&#x107;</keyname><forenames>Hrvoje</forenames></author></authors><title>Model of Wikipedia growth based on information exchange via reciprocal
  arcs</title><categories>physics.soc-ph cond-mat.stat-mech cs.CY</categories><comments>4 pages, 4 figures, companion paper of our paper &quot;Influence of
  reciprocal arcs on the degree distribution and degree correlations&quot;</comments><journal-ref>EPL 93 (2011) 58005</journal-ref><doi>10.1209/0295-5075/93/58005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show how reciprocal arcs significantly influence the structural
organization of Wikipedias, online encyclopedias. It is shown that random
addition of reciprocal arcs in the static network cannot explain the observed
reciprocity of Wikipedias. A model of Wikipedia growth based on preferential
attachment and on information exchange via reciprocal arcs is presented. An
excellent agreement between in-degree distributions of our model and real
Wikipedia networks is achieved without fitting the distributions, but by merely
extracting a small number of model parameters from the measurement of real
networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3549</identifier>
 <datestamp>2009-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3549</id><created>2009-02-20</created><authors><author><keyname>Dieudonn&#xe9;</keyname><forenames>Yoann</forenames><affiliation>LaRIA, MIS</affiliation></author><author><keyname>Dolev</keyname><forenames>Shlomi</forenames><affiliation>LaRIA, LIP, INRIA Rh&#xf4;ne-Alpes / LIP Laboratoire de l'Informatique du Parall&#xe9;lisme</affiliation></author><author><keyname>Petit</keyname><forenames>Franck</forenames><affiliation>LaRIA, LIP, INRIA Rh&#xf4;ne-Alpes / LIP Laboratoire de l'Informatique du Parall&#xe9;lisme</affiliation></author><author><keyname>Segal</keyname><forenames>Michael</forenames></author></authors><title>Deaf, Dumb, and Chatting Robots, Enabling Distributed Computation and
  Fault-Tolerance Among Stigmergic Robot</title><categories>cs.MA nlin.AO</categories><proxy>ccsd inria-00363081</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate ways for the exchange of information (explicit communication)
among deaf and dumb mobile robots scattered in the plane. We introduce the use
of movement-signals (analogously to flight signals and bees waggle) as a mean
to transfer messages, enabling the use of distributed algorithms among the
robots. We propose one-to-one deterministic movement protocols that implement
explicit communication. We first present protocols for synchronous robots. We
begin with a very simple coding protocol for two robots. Based on on this
protocol, we provide one-to-one communication for any system of n \geq 2 robots
equipped with observable IDs that agree on a common direction (sense of
direction). We then propose two solutions enabling one-to-one communication
among anonymous robots. Since the robots are devoid of observable IDs, both
protocols build recognition mechanisms using the (weak) capabilities offered to
the robots. The first protocol assumes that the robots agree on a common
direction and a common handedness (chirality), while the second protocol
assumes chirality only. Next, we show how the movements of robots can provide
implicit acknowledgments in asynchronous systems. We use this result to design
asynchronous one-to-one communication with two robots only. Finally, we combine
this solution with the schemes developed in synchronous settings to fit the
general case of asynchronous one-to-one communication among any number of
robots. Our protocols enable the use of distributing algorithms based on
message exchanges among swarms of Stigmergic robots. Furthermore, they provides
robots equipped with means of communication to overcome faults of their
communication device.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3593</identifier>
 <datestamp>2009-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3593</id><created>2009-02-20</created><authors><author><keyname>Moustakas</keyname><forenames>Aris L.</forenames></author><author><keyname>Kumar</keyname><forenames>K Raj</forenames></author><author><keyname>Caire</keyname><forenames>Giuseppe</forenames></author></authors><title>Performance of MMSE MIMO Receivers: A Large N Analysis for Correlated
  Channels</title><categories>cs.IT math.IT</categories><comments>Invited article at the IEEE Vehicular Technology Conference,
  Barcelona 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Linear receivers are considered as an attractive low-complexity alternative
to optimal processing for multi-antenna MIMO communications. In this paper we
characterize the performance of MMSE MIMO receivers in the limit of large
antenna numbers in the presence of channel correlations. Using the replica
method, we generalize our results obtained in arXiv:0810.0883 to
Kronecker-product correlated channels and calculate the asymptotic mean and
variance of the mutual information of a MIMO system of parallel MMSE
subchannels. The replica method allows us to use the ties between the optimal
receiver mutual information and the MMSE SIR of Gaussian inputs to calculate
the joint moments of the SIRs of the MMSE subchannels. Using the methodology
discussed in arXiv:0810.0883 it can be shown that the mutual information
converges in distribution to a Gaussian random variable. Our results agree very
well with simulations even with a moderate number of antennas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3595</identifier>
 <datestamp>2010-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3595</id><created>2009-02-20</created><updated>2010-01-14</updated><authors><author><keyname>Chen</keyname><forenames>Jinhui</forenames></author><author><keyname>Slock</keyname><forenames>Dirk T. M.</forenames></author></authors><title>On Optimum End-to-End Distortion in MIMO Systems</title><categories>cs.IT math.IT</categories><comments>35 pages, 10 figures, submitted to EURASIP Journal on Wireless
  Communications and Networking</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents the joint impact of the numbers of antennas,
source-to-channel bandwidth ratio and spatial correlation on the optimum
expected end-to-end distortion in an outage-free MIMO system. In particular,
based on an analytical expression valid for any SNR, a closed-form expression
of the optimum asymptotic expected end-to-end distortion valid for high SNR is
derived. It is comprised of the optimum distortion exponent and the
multiplicative optimum distortion factor. Demonstrated by the simulation
results, the analysis on the joint impact of the optimum distortion exponent
and the optimum distortion factor explains the behavior of the optimum expected
end-to-end distortion varying with the numbers of antennas, source-to-channel
bandwidth ratio and spatial correlation. It is also proved that as the
correlation tends to zero, the optimum asymptotic expected end-to-end
distortion in the setting of correlated channel approaches that in the setting
of uncorrelated channel. The results in this paper could be performance
objectives for analog-source transmission systems. To some extend, they are
instructive for system design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3614</identifier>
 <datestamp>2009-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3614</id><created>2009-02-20</created><authors><author><keyname>Wirth</keyname><forenames>Claus-Peter</forenames></author></authors><title>Syntactic Confluence Criteria for Positive/Negative-Conditional Term
  Rewriting Systems</title><categories>cs.AI cs.LO</categories><comments>ii + 187 pages</comments><report-no>SEKI Report SR-95-09</report-no><journal-ref>J. Symbolic Computation, 2009, 44:60--98</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We study the combination of the following already known ideas for showing
confluence of unconditional or conditional term rewriting systems into
practically more useful confluence criteria for conditional systems: Our
syntactical separation into constructor and non-constructor symbols, Huet's
introduction and Toyama's generalization of parallel closedness for
non-noetherian unconditional systems, the use of shallow confluence for proving
confluence of noetherian and non-noetherian conditional systems, the idea that
certain kinds of limited confluence can be assumed for checking the
fulfilledness or infeasibility of the conditions of conditional critical pairs,
and the idea that (when termination is given) only prime superpositions have to
be considered and certain normalization restrictions can be applied for the
substitutions fulfilling the conditions of conditional critical pairs. Besides
combining and improving already known methods, we present the following new
ideas and results: We strengthen the criterion for overlay joinable noetherian
systems, and, by using the expressiveness of our syntactical separation into
constructor and non-constructor symbols, we are able to present criteria for
level confluence that are not criteria for shallow confluence actually and also
able to weaken the severe requirement of normality (stiffened with
left-linearity) in the criteria for shallow confluence of noetherian and
non-noetherian conditional systems to the easily satisfied requirement of
quasi-normality. Finally, the whole paper may also give a practically useful
overview of the syntactical means for showing confluence of conditional term
rewriting systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3616</identifier>
 <datestamp>2009-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3616</id><created>2009-02-20</created><authors><author><keyname>Kreutzer</keyname><forenames>Stephan</forenames></author></authors><title>Algorithmic Meta-Theorems</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Algorithmic meta-theorems are general algorithmic results applying to a whole
range of problems, rather than just to a single problem alone. They often have
a &quot;logical&quot; and a &quot;structural&quot; component, that is they are results of the form:
every computational problem that can be formalised in a given logic L can be
solved efficiently on every class C of structures satisfying certain
conditions. This paper gives a survey of algorithmic meta-theorems obtained in
recent years and the methods used to prove them. As many meta-theorems use
results from graph minor theory, we give a brief introduction to the theory
developed by Robertson and Seymour for their proof of the graph minor theorem
and state the main algorithmic consequences of this theory as far as they are
needed in the theory of algorithmic meta-theorems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3623</identifier>
 <datestamp>2010-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3623</id><created>2009-02-20</created><updated>2010-12-14</updated><authors><author><keyname>Wirth</keyname><forenames>Claus-Peter</forenames></author></authors><title>A Self-Contained and Easily Accessible Discussion of the Method of
  Descente Infinie and Fermat's Only Explicitly Known Proof by Descente Infinie</title><categories>cs.AI cs.LO</categories><comments>ii + 36 pages, French abstract (R\'esum\'e) included in paper</comments><report-no>SEKI Working-Paper SWP-2006-02, Second edition</report-no><msc-class>03-03, 01A45</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the only proof of Pierre Fermat by descente infinie that is known
to exist today. As the text of its Latin original requires active mathematical
interpretation, it is more a proof sketch than a proper mathematical proof. We
discuss descente infinie from the mathematical, logical, historical,
linguistic, and refined logic-historical points of view. We provide the
required preliminaries from number theory and develop a self-contained proof in
a modern form, which nevertheless is intended to follow Fermat's ideas closely.
We then annotate an English translation of Fermat's original proof with terms
from the modern proof. Including all important facts, we present a concise and
self-contained discussion of Fermat's proof sketch, which is easily accessible
to laymen in number theory as well as to laymen in the history of mathematics,
and which provides new clarification of the Method of Descente Infinie to the
experts in these fields. Last but not least, this paper fills a gap regarding
the easy accessibility of the subject.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3631</identifier>
 <datestamp>2010-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3631</id><created>2009-02-20</created><updated>2010-07-16</updated><authors><author><keyname>Sterling</keyname><forenames>Aaron</forenames></author></authors><title>Distributed Agreement in Tile Self-Assembly</title><categories>cs.DC cs.NE</categories><comments>The extended abstract of this paper won the Best Student Paper Award
  at DNA 15. The current version has been accepted for publication in Natural
  Computing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Laboratory investigations have shown that a formal theory of fault-tolerance
will be essential to harness nanoscale self-assembly as a medium of
computation. Several researchers have voiced an intuition that self-assembly
phenomena are related to the field of distributed computing. This paper
formalizes some of that intuition. We construct tile assembly systems that are
able to simulate the solution of the wait-free consensus problem in some
distributed systems. (For potential future work, this may allow binding errors
in tile assembly to be analyzed, and managed, with positive results in
distributed computing, as a &quot;blockage&quot; in our tile assembly model is analogous
to a crash failure in a distributed computing model.) We also define a
strengthening of the &quot;traditional&quot; consensus problem, to make explicit an
expectation about consensus algorithms that is often implicit in distributed
computing literature. We show that solution of this strengthened consensus
problem can be simulated by a two-dimensional tile assembly model only for two
processes, whereas a three-dimensional tile assembly model can simulate its
solution in a distributed system with any number of processes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3635</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3635</id><created>2009-02-20</created><authors><author><keyname>Wirth</keyname><forenames>Claus-Peter</forenames></author></authors><title>lim+, delta+, and Non-Permutability of beta-Steps</title><categories>cs.AI cs.LO</categories><comments>ii + 36 pages</comments><report-no>SEKI Report SR-2005-01</report-no><journal-ref>Journal of Symbolic Computation, 2012, Volume 47, Pp. 1109-1135</journal-ref><doi>10.1016/j.jsc.2011.12.035</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using a human-oriented formal example proof of the (lim+) theorem, i.e. that
the sum of limits is the limit of the sum, which is of value for reference on
its own, we exhibit a non-permutability of beta-steps and delta+-steps
(according to Smullyan's classification), which is not visible with
non-liberalized delta-rules and not serious with further liberalized
delta-rules, such as the delta++-rule. Besides a careful presentation of the
search for a proof of (lim+) with several pedagogical intentions, the main
subject is to explain why the order of beta-steps plays such a practically
important role in some calculi.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3648</identifier>
 <datestamp>2009-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3648</id><created>2009-02-20</created><authors><author><keyname>Mattick</keyname><forenames>Volker</forenames></author><author><keyname>Wirth</keyname><forenames>Claus-Peter</forenames></author></authors><title>An Algebraic Dexter-Based Hypertext Reference Model</title><categories>cs.AI cs.LO</categories><comments>ii + 48 pages</comments><report-no>Research Report 719/1999 (green/grey series), Fachbereich
  Informatik, University of Dortmund</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the first formal algebraic specification of a hypertext reference
model. It is based on the well-known Dexter Hypertext Reference Model and
includes modifications with respect to the development of hypertext since the
WWW came up. Our hypertext model was developed as a product model with the aim
to automatically support the design process and is extended to a model of
hypertext-systems in order to be able to describe the state transitions in this
process. While the specification should be easy to read for non-experts in
algebraic specification, it guarantees a unique understanding and enables a
close connection to logic-based development and verification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3722</identifier>
 <datestamp>2009-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3722</id><created>2009-02-21</created><updated>2009-11-23</updated><authors><author><keyname>Monniaux</keyname><forenames>David</forenames><affiliation>VERIMAG - Imag</affiliation></author></authors><title>A minimalistic look at widening operators</title><categories>cs.LO cs.PL</categories><proxy>ccsd hal-00363204</proxy><acm-class>F.3.2; F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of formalizing the familiar notion of widening in
abstract interpretation in higher-order logic. It turns out that many axioms of
widening (e.g. widening sequences are ascending) are not useful for proving
correctness. After keeping only useful axioms, we give an equivalent
characterization of widening as a lazily constructed well-founded tree. In type
systems supporting dependent products and sums, this tree can be made to
reflect the condition of correct termination of the widening sequence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3725</identifier>
 <datestamp>2009-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3725</id><created>2009-02-21</created><authors><author><keyname>Diekman</keyname><forenames>Casey</forenames></author><author><keyname>Dasgupta</keyname><forenames>Kohinoor</forenames></author><author><keyname>Nair</keyname><forenames>Vijay</forenames></author><author><keyname>Sastry</keyname><forenames>P. S.</forenames></author><author><keyname>Unnikrishnan</keyname><forenames>K. P.</forenames></author></authors><title>Statistical Inference of Functional Connectivity in Neuronal Networks
  using Frequent Episodes</title><categories>q-bio.NC cond-mat.dis-nn cs.DB q-bio.QM stat.ME</categories><comments>15 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Identifying the spatio-temporal network structure of brain activity from
multi-neuronal data streams is one of the biggest challenges in neuroscience.
Repeating patterns of precisely timed activity across a group of neurons is
potentially indicative of a microcircuit in the underlying neural tissue.
Frequent episode discovery, a temporal data mining framework, has recently been
shown to be a computationally efficient method of counting the occurrences of
such patterns. In this paper, we propose a framework to determine when the
counts are statistically significant by modeling the counting process. Our
model allows direct estimation of the strengths of functional connections
between neurons with improved resolution over previously published methods. It
can also be used to rank the patterns discovered in a network of neurons
according to their strengths and begin to reconstruct the graph structure of
the network that produced the spike data. We validate our methods on simulated
data and present analysis of patterns discovered in data from cultures of
cortical neurons.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3730</identifier>
 <datestamp>2009-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3730</id><created>2009-02-21</created><authors><author><keyname>Wirth</keyname><forenames>Claus-Peter</forenames></author></authors><title>Full First-Order Sequent and Tableau Calculi With Preservation of
  Solutions and the Liberalized delta-Rule but Without Skolemization</title><categories>cs.AI cs.LO</categories><comments>ii + 40 pages</comments><report-no>Research Report 698/1998 (green/grey series), Fachbereich
  Informatik, University of Dortmund</report-no><journal-ref>Caferra, R. and Salzer, G., eds., Automated Deduction in Classical
  and Non-Classical Logics (FTP'98), LNAI 1761, pp. 283-298, Springer, 2000</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a combination of raising, explicit variable dependency
representation, the liberalized delta-rule, and preservation of solutions for
first-order deductive theorem proving. Our main motivation is to provide the
foundation for our work on inductive theorem proving, where the preservation of
solutions is indispensable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3749</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3749</id><created>2009-02-21</created><updated>2012-01-16</updated><authors><author><keyname>Wirth</keyname><forenames>Claus-Peter</forenames></author></authors><title>Hilbert's epsilon as an Operator of Indefinite Committed Choice</title><categories>cs.AI cs.LO</categories><comments>ii + 73 pages. arXiv admin note: substantial text overlap with
  arXiv:1104.2444</comments><report-no>SEKI Report SR-2006-02</report-no><journal-ref>Journal of Applied Logic 6 (2008), pp. 287-317</journal-ref><doi>10.1016/j.jal.2007.07.009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Paul Bernays and David Hilbert carefully avoided overspecification of
Hilbert's epsilon-operator and axiomatized only what was relevant for their
proof-theoretic investigations. Semantically, this left the epsilon-operator
underspecified. In the meanwhile, there have been several suggestions for
semantics of the epsilon as a choice operator. After reviewing the literature
on semantics of Hilbert's epsilon operator, we propose a new semantics with the
following features: We avoid overspecification (such as right-uniqueness), but
admit indefinite choice, committed choice, and classical logics. Moreover, our
semantics for the epsilon supports proof search optimally and is natural in the
sense that it does not only mirror some cases of referential interpretation of
indefinite articles in natural language, but may also contribute to philosophy
of language. Finally, we ask the question whether our epsilon within our
free-variable framework can serve as a paradigm useful in the specification and
computation of semantics of discourses in natural language.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3757</identifier>
 <datestamp>2009-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3757</id><created>2009-02-21</created><authors><author><keyname>Diakonikolas</keyname><forenames>Ilias</forenames></author><author><keyname>Gopalan</keyname><forenames>Parikshit</forenames></author><author><keyname>Jaiswal</keyname><forenames>Ragesh</forenames></author><author><keyname>Servedio</keyname><forenames>Rocco</forenames></author><author><keyname>Viola</keyname><forenames>Emanuele</forenames></author></authors><title>Bounded Independence Fools Halfspaces</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that any distribution on {-1,1}^n that is k-wise independent fools
any halfspace h with error \eps for k = O(\log^2(1/\eps) /\eps^2). Up to
logarithmic factors, our result matches a lower bound by Benjamini,
Gurel-Gurevich, and Peled (2007) showing that k = \Omega(1/(\eps^2 \cdot
\log(1/\eps))). Using standard constructions of k-wise independent
distributions, we obtain the first explicit pseudorandom generators G: {-1,1}^s
--&gt; {-1,1}^n that fool halfspaces. Specifically, we fool halfspaces with error
eps and seed length s = k \log n = O(\log n \cdot \log^2(1/\eps) /\eps^2).
  Our approach combines classical tools from real approximation theory with
structural results on halfspaces by Servedio (Computational Complexity 2007).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3780</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3780</id><created>2009-02-22</created><updated>2010-02-03</updated><authors><author><keyname>Marx</keyname><forenames>D&#xe1;niel</forenames><affiliation>Budapest University of Technology and Economics</affiliation></author><author><keyname>O'Sullivan</keyname><forenames>Barry</forenames><affiliation>Cork Constraint Computation Centre, University College Cork</affiliation></author><author><keyname>Razgon</keyname><forenames>Igor</forenames><affiliation>Cork Constraint Computation Centre, University College Cork</affiliation></author></authors><title>Treewidth reduction for constrained separation and bipartization
  problems</title><categories>cs.DS cs.DM</categories><comments>STACS final version of our result. For the complete description of
  the result please see version 1</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We present a method for reducing the treewidth of a graph while preserving
all the minimal $s-t$ separators. This technique turns out to be very useful
for establishing the fixed-parameter tractability of constrained separation and
bipartization problems. To demonstrate the power of this technique, we prove
the fixed-parameter tractability of a number of well-known separation and
bipartization problems with various additional restrictions (e.g., the vertices
being removed from the graph form an independent set). These results answer a
number of open questions in the area of parameterized complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3788</identifier>
 <datestamp>2009-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3788</id><created>2009-02-22</created><updated>2009-09-09</updated><authors><author><keyname>Porter</keyname><forenames>Mason A.</forenames></author><author><keyname>Onnela</keyname><forenames>Jukka-Pekka</forenames></author><author><keyname>Mucha</keyname><forenames>Peter J.</forenames></author></authors><title>Communities in Networks</title><categories>physics.soc-ph cond-mat.stat-mech cs.CY cs.DM math.ST nlin.AO physics.comp-ph stat.TH</categories><comments>survey/review article on community structure in networks; published
  version is available at
  http://people.maths.ox.ac.uk/~porterm/papers/comnotices.pdf</comments><journal-ref>Notices of the American Mathematical Society, Vol. 56, No. 9:
  1082-1097, 1164-1166, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We survey some of the concepts, methods, and applications of community
detection, which has become an increasingly important area of network science.
To help ease newcomers into the field, we provide a guide to available
methodology and open problems, and discuss why scientists from diverse
backgrounds are interested in these problems. As a running theme, we emphasize
the connections of community detection to problems in statistical physics and
computational optimization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3818</identifier>
 <datestamp>2009-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3818</id><created>2009-02-22</created><authors><author><keyname>Jeganathan</keyname><forenames>L.</forenames></author><author><keyname>Rama</keyname><forenames>R.</forenames></author><author><keyname>Sengupta</keyname><forenames>Ritabrata</forenames></author></authors><title>Application of Generalised sequential crossover of languages to
  generalised splicing</title><categories>cs.DM</categories><comments>8 pages, 3 figures</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper outlines an application of iterated version of generalised
sequential crossover of two languages (which in some sense, an abstraction of
the crossover of chromosomes in living organisms) in studying some classes of
the newly proposed generalised splicing ($GS$) over two languages. It is proved
that, for $X,Y \in \{FIN, REG, LIN, CF, CS, RE \}, \sg \in FIN$, the subclass
of generalized splicing languages namely $GS(X,Y,\sg)$, (which is a subclass of
the class $GS(X,Y,FIN)$) is always regular.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3846</identifier>
 <datestamp>2009-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3846</id><created>2009-02-22</created><authors><author><keyname>Singer</keyname><forenames>Amit</forenames></author><author><keyname>Cucuringu</keyname><forenames>Mihai</forenames></author></authors><title>Uniqueness of Low-Rank Matrix Completion by Rigidity Theory</title><categories>cs.LG</categories><comments>19 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of completing a low-rank matrix from a subset of its entries is
often encountered in the analysis of incomplete data sets exhibiting an
underlying factor model with applications in collaborative filtering, computer
vision and control. Most recent work had been focused on constructing efficient
algorithms for exact or approximate recovery of the missing matrix entries and
proving lower bounds for the number of known entries that guarantee a
successful recovery with high probability. A related problem from both the
mathematical and algorithmic point of view is the distance geometry problem of
realizing points in a Euclidean space from a given subset of their pairwise
distances. Rigidity theory answers basic questions regarding the uniqueness of
the realization satisfying a given partial set of distances. We observe that
basic ideas and tools of rigidity theory can be adapted to determine uniqueness
of low-rank matrix completion, where inner products play the role that
distances play in rigidity theory. This observation leads to an efficient
randomized algorithm for testing both local and global unique completion.
Crucial to our analysis is a new matrix, which we call the completion matrix,
that serves as the analogue of the rigidity matrix.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3858</identifier>
 <datestamp>2009-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3858</id><created>2009-02-23</created><authors><author><keyname>Jaeger</keyname><forenames>Eric</forenames><affiliation>DCSSI/SDS/Lti, Lip6</affiliation></author><author><keyname>Dubois</keyname><forenames>Catherine</forenames><affiliation>CEDRIC</affiliation></author></authors><title>Why Would You Trust B?</title><categories>cs.LO</categories><comments>15 pages</comments><proxy>ccsd hal-00363345</proxy><journal-ref>Logic for Programming, Artificial Intelligence, and Reasoning,
  Yerevan : Arm\'enie (2007)</journal-ref><doi>10.1007/978-3-540-75560-9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The use of formal methods provides confidence in the correctness of
developments. Yet one may argue about the actual level of confidence obtained
when the method itself -- or its implementation -- is not formally checked. We
address this question for the B, a widely used formal method that allows for
the derivation of correct programs from specifications. Through a deep
embedding of the B logic in Coq, we check the B theory but also implement B
tools. Both aspects are illustrated by the description of a proved prover for
the B logic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3861</identifier>
 <datestamp>2009-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3861</id><created>2009-02-23</created><authors><author><keyname>Jaeger</keyname><forenames>Eric</forenames><affiliation>LIP6, Dcssi/SDS/Lti</affiliation></author><author><keyname>Hardin</keyname><forenames>Th&#xe9;r&#xe8;se</forenames><affiliation>LIP6</affiliation></author></authors><title>A Few Remarks About Formal Development of Secure Systems</title><categories>cs.LO</categories><comments>10 pages</comments><proxy>ccsd hal-00363346</proxy><journal-ref>High Assurance Systems Engineering Symposium, Nanjing : Chine
  (2008)</journal-ref><doi>10.1109/HASE.2008.49</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Formal methods provide remarkable tools allowing for high levels of
confidence in the correctness of developments. Their use is therefore
encouraged, when not required, for the development of systems in which safety
or security is mandatory. But effectively specifying a secure system or
deriving a secure implementation can be tricky. We propose a review of some
classical `gotchas' and other possible sources of concerns with the objective
to improve the confidence in formal developments, or at least to better assess
the actual confidence level.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3865</identifier>
 <datestamp>2009-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3865</id><created>2009-02-23</created><authors><author><keyname>Jaeger</keyname><forenames>Eric</forenames><affiliation>LIP6, Dcssi/SDS/Lti</affiliation></author><author><keyname>Hardin</keyname><forenames>Th&#xe9;r&#xe8;se</forenames><affiliation>LIP6</affiliation></author></authors><title>Yet Another Deep Embedding of B:Extending de Bruijn Notations</title><categories>cs.LO</categories><comments>16 pages</comments><proxy>ccsd hal-00363348</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present Bicoq3, a deep embedding of the B system in Coq, focusing on the
technical aspects of the development. The main subjects discussed are related
to the representation of sets and maps, the use of induction principles, and
the introduction of a new de Bruijn notation providing solutions to various
problems related to the mechanisation of languages and logics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3883</identifier>
 <datestamp>2011-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3883</id><created>2009-02-23</created><updated>2009-12-15</updated><authors><author><keyname>Danielsen</keyname><forenames>Lars Eirik</forenames></author><author><keyname>Parker</keyname><forenames>Matthew G.</forenames></author></authors><title>Directed Graph Representation of Half-Rate Additive Codes over GF(4)</title><categories>math.CO cs.IT math.IT</categories><comments>Presented at International Workshop on Coding and Cryptography (WCC
  2009), 10-15 May 2009, Ullensvang, Norway. (14 pages, 2 figures)</comments><msc-class>94B60, 05C90</msc-class><journal-ref>Des. Codes Cryptogr. 59, pp. 119-130, 2011</journal-ref><doi>10.1007/s10623-010-9469-6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that (n,2^n) additive codes over GF(4) can be represented as directed
graphs. This generalizes earlier results on self-dual additive codes over
GF(4), which correspond to undirected graphs. Graph representation reduces the
complexity of code classification, and enables us to classify additive (n,2^n)
codes over GF(4) of length up to 7. From this we also derive classifications of
isodual and formally self-dual codes. We introduce new constructions of
circulant and bordered circulant directed graph codes, and show that these
codes will always be isodual. A computer search of all such codes of length up
to 26 reveals that these constructions produce many codes of high minimum
distance. In particular, we find new near-extremal formally self-dual codes of
length 11 and 13, and isodual codes of length 24, 25, and 26 with better
minimum distance than the best known self-dual codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3958</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3958</id><created>2009-02-23</created><updated>2009-03-02</updated><authors><author><keyname>Doyen</keyname><forenames>Laurent</forenames></author><author><keyname>Raskin</keyname><forenames>Jean-Francois</forenames></author></authors><title>Antichains for the Automata-Based Approach to Model-Checking</title><categories>cs.LO</categories><acm-class>F.4.1; I.1.2</acm-class><journal-ref>Logical Methods in Computer Science, Volume 5, Issue 1 (March 2,
  2009) lmcs:1027</journal-ref><doi>10.2168/LMCS-5(1:5)2009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose and evaluate antichain algorithms to solve the universality and
language inclusion problems for nondeterministic Buechi automata, and the
emptiness problem for alternating Buechi automata. To obtain those algorithms,
we establish the existence of simulation pre-orders that can be exploited to
efficiently evaluate fixed points on the automata defined during the
complementation step (that we keep implicit in our approach). We evaluate the
performance of the algorithm to check the universality of Buechi automata using
the random automaton model recently proposed by Tabakov and Vardi. We show that
on the difficult instances of this probabilistic model, our algorithm
outperforms the standard ones by several orders of magnitude.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3979</identifier>
 <datestamp>2013-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3979</id><created>2009-02-23</created><authors><author><keyname>Giovanidis</keyname><forenames>Anastasios</forenames></author><author><keyname>Wunder</keyname><forenames>Gerhard</forenames></author><author><keyname>Buehler</keyname><forenames>Joerg</forenames></author></authors><title>Optimal Control of a Single Queue with Retransmissions: Delay-Dropping
  Tradeoffs</title><categories>cs.MM</categories><comments>29 pages, 8 figures, submitted to IEEE Transactions on Wireless
  Communications</comments><journal-ref>IEEE Transactions on Wireless Communications (Volume:8 , Issue: 7
  ), pp. 3736 - 3746,. July 2009</journal-ref><doi>10.1109/TWC.2009.080959</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A single queue incorporating a retransmission protocol is investigated,
assuming that the sequence of per effort success probabilities in the Automatic
Retransmission reQuest (ARQ) chain is a priori defined and no channel state
information at the transmitter is available. A Markov Decision Problem with an
average cost criterion is formulated where the possible actions are to either
continue the retransmission process of an erroneous packet at the next time
slot or to drop the packet and move on to the next packet awaiting for
transmission. The cost per slot is a linear combination of the current queue
length and a penalty term in case dropping is chosen as action. The
investigation seeks policies that provide the best possible average packet
delay-dropping trade-off for Quality of Service guarantees. An optimal
deterministic stationary policy is shown to exist, several structural
properties of which are obtained. Based on that, a class of suboptimal
&lt;L,K&gt;-policies is introduced. These suggest that it is almost optimal to use a
K-truncated ARQ protocol as long as the queue length is lower than L, else send
all packets in one shot. The work concludes with an evaluation of the optimal
delay-dropping tradeoff using dynamic programming and a comparison between the
optimal and suboptimal policies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.4042</identifier>
 <datestamp>2009-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.4042</id><created>2009-02-23</created><authors><author><keyname>Missaoui</keyname><forenames>Rokia</forenames></author><author><keyname>Kwuida</keyname><forenames>Leonard</forenames></author><author><keyname>Quafafou</keyname><forenames>Mohamed</forenames></author><author><keyname>Vaillancourt</keyname><forenames>Jean</forenames></author></authors><title>Algebraic operators for querying pattern bases</title><categories>cs.DB cs.IR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The objectives of this research work which is intimately related to pattern
discovery and management are threefold: (i) handle the problem of pattern
manipulation by defining operations on patterns, (ii) study the problem of
enriching and updating a pattern set (e.g., concepts, rules) when changes occur
in the user's needs and the input data (e.g., object/attribute insertion or
elimination, taxonomy utilization), and (iii) approximate a &quot;presumed&quot; concept
using a related pattern space so that patterns can augment data with knowledge.
To conduct our work, we use formal concept analysis (FCA) as a framework for
pattern discovery and management and we take a joint database-FCA perspective
by defining operators similar in spirit to relational algebra operators,
investigating approximation in concept lattices and exploiting existing work
related to operations on contexts and lattices to formalize such operators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.4045</identifier>
 <datestamp>2009-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.4045</id><created>2009-02-23</created><authors><author><keyname>Khajehnejad</keyname><forenames>M. Amin</forenames></author><author><keyname>Dimakis</keyname><forenames>Alexandros G.</forenames></author><author><keyname>Xu</keyname><forenames>Weiyu</forenames></author><author><keyname>Hassibi</keyname><forenames>Babak</forenames></author></authors><title>Sparse Recovery of Positive Signals with Minimal Expansion</title><categories>cs.IT math.IT</categories><comments>25 pages, submitted for publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the sparse recovery problem of reconstructing a
high-dimensional non-negative sparse vector from lower dimensional linear
measurements. While much work has focused on dense measurement matrices, sparse
measurement schemes are crucial in applications, such as DNA microarrays and
sensor networks, where dense measurements are not practically feasible. One
possible construction uses the adjacency matrices of expander graphs, which
often leads to recovery algorithms much more efficient than $\ell_1$
minimization. However, to date, constructions based on expanders have required
very high expansion coefficients which can potentially make the construction of
such graphs difficult and the size of the recoverable sets small.
  In this paper, we construct sparse measurement matrices for the recovery of
non-negative vectors, using perturbations of the adjacency matrix of an
expander graph with much smaller expansion coefficient. We present a necessary
and sufficient condition for $\ell_1$ optimization to successfully recover the
unknown vector and obtain expressions for the recovery threshold. For certain
classes of measurement matrices, this necessary and sufficient condition is
further equivalent to the existence of a &quot;unique&quot; vector in the constraint set,
which opens the door to alternative algorithms to $\ell_1$ minimization. We
further show that the minimal expansion we use is necessary for any graph for
which sparse recovery is possible and that therefore our construction is tight.
We finally present a novel recovery algorithm that exploits expansion and is
much faster than $\ell_1$ optimization. Finally, we demonstrate through
theoretical bounds, as well as simulation, that our method is robust to noise
and approximate sparsity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.4060</identifier>
 <datestamp>2012-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.4060</id><created>2009-02-23</created><authors><author><keyname>Yamamoto</keyname><forenames>Ken</forenames></author><author><keyname>Yamazaki</keyname><forenames>Yoshihiro</forenames></author></authors><title>Network of two-Chinese-character compound words in Japanese language</title><categories>cs.CL physics.soc-ph</categories><journal-ref>Physica A 388, 2555-2560 (2009)</journal-ref><doi>10.1016/j.physa.2009.02.032</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Some statistical properties of a network of two-Chinese-character compound
words in Japanese language are reported. In this network, a node represents a
Chinese character and an edge represents a two-Chinese-character compound word.
It is found that this network has properties of &quot;small-world&quot; and &quot;scale-free.&quot;
A network formed by only Chinese characters for common use ({\it joyo-kanji} in
Japanese), which is regarded as a subclass of the original network, also has
small-world property. However, a degree distribution of the network exhibits no
clear power law. In order to reproduce disappearance of the power-law property,
a model for a selecting process of the Chinese characters for common use is
proposed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.4073</identifier>
 <datestamp>2009-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.4073</id><created>2009-02-24</created><authors><author><keyname>Sparavigna</keyname><forenames>Amelia</forenames></author></authors><title>Dipole and Quadrupole Moments in Image Processing</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes an algorithm for image processing, obtained by adapting
to image maps the definitions of two well-known physical quantities. These
quantities are the dipole and quadrupole moments of a charge distribution. We
will see how it is possible to define dipole and quadrupole moments for the
gray-tone maps and apply them in the development of algorithms for edge
detection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.4091</identifier>
 <datestamp>2009-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.4091</id><created>2009-02-24</created><authors><author><keyname>Bl&#xfc;mlein</keyname><forenames>J.</forenames></author><author><keyname>Kauers</keyname><forenames>M.</forenames></author><author><keyname>Klein</keyname><forenames>S.</forenames></author><author><keyname>Schneider</keyname><forenames>C.</forenames></author></authors><title>Determining the closed forms of the $O(a_s^3)$ anomalous dimensions and
  Wilson coefficients from Mellin moments by means of computer algebra</title><categories>hep-ph cs.SC math-ph math.AG math.CO math.MP</categories><comments>38 pages, 1 style file, 2 FORM files, 2 Mathematica files</comments><report-no>DESY 09-002, SFB/CPP-09-22</report-no><journal-ref>Comput.Phys.Commun.180:2143-2165,2009</journal-ref><doi>10.1016/j.cpc.2009.06.020</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Single scale quantities, as anomalous dimensions and hard scattering cross
sections, in renormalizable Quantum Field Theories are found to obey difference
equations of finite order in Mellin space. It is often easier to calculate
fixed moments for these quantities compared to a direct attempt to derive them
in terms of harmonic sums and their generalizations involving the Mellin
parameter $N$. Starting from a sufficiently large number of given moments, we
establish linear recurrence relations of lowest possible order with polynomial
coefficients of usually high degree. Then these recurrence equations are solved
in terms of d'Alembertian solutions where the involved nested sums are
represented in optimal nested depth. Given this representation, it is then an
easy task to express the result in terms of harmonic sums. In this process we
compactify the result such that no algebraic relations occur among the sums
involved. We demonstrate the method for the QCD unpolarized anomalous
dimensions and massless Wilson coefficients to 3--loop order treating the
contributions for individual color coefficients. For the most complicated
subproblem 5114 moments were needed in order to produce a recurrence of order
35 whose coefficients have degrees up to 938. About four months of CPU time
were needed to establish and solve the recurrences for the anomalous dimensions
and Wilson coefficients on a 2 GHz machine requiring less than 10 GB of memory.
No algorithm is known yet to provide such a high number of moments for 3--loop
quantities. Yet the method presented shows that it is possible to establish and
solve recurrences of rather large order and and degree, occurring in physics
problems, uniquely, fast and reliably with computer algebra.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.4095</identifier>
 <datestamp>2014-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.4095</id><created>2009-02-24</created><authors><author><keyname>Bl&#xfc;mlein</keyname><forenames>J.</forenames></author><author><keyname>Kauers</keyname><forenames>M.</forenames></author><author><keyname>Klein</keyname><forenames>S.</forenames></author><author><keyname>Schneider</keyname><forenames>C.</forenames></author></authors><title>From Moments to Functions in Quantum Chromodynamics</title><categories>hep-ph cs.SC math-ph math.AG math.CO math.MP</categories><comments>7 pages, 2 subsidiary files</comments><report-no>DESY 09-011, SFB-CPP-09/17</report-no><journal-ref>PoS ACAT08:106,2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Single-scale quantities, like the QCD anomalous dimensions and Wilson
coefficients, obey difference equations. Therefore their analytic form can be
determined from a finite number of moments. We demonstrate this in an explicit
calculation by establishing and solving large scale recursions by means of
computer algebra for the anomalous dimensions and Wilson coefficients in
unpolarized deeply inelastic scattering from their Mellin moments to 3-loop
order.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.4098</identifier>
 <datestamp>2009-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.4098</id><created>2009-02-24</created><authors><author><keyname>Chebotarev</keyname><forenames>Pavel</forenames></author><author><keyname>Agaev</keyname><forenames>Rafig</forenames></author></authors><title>Coordination in multiagent systems and Laplacian spectra of digraphs</title><categories>cs.MA cs.DM math.CO math.OC</categories><comments>15 pages, 2 figures, 40 references. To appear in Automation and
  Remote Control, Vol.70, No.3, 2009</comments><journal-ref>Automation and Remote Control, Vol.70 (2009), No.3, P. 469-483</journal-ref><doi>10.1134/S0005117909030126</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Constructing and studying distributed control systems requires the analysis
of the Laplacian spectra and the forest structure of directed graphs. In this
paper, we present some basic results of this analysis partially obtained by the
present authors. We also discuss the application of these results to
decentralized control and touch upon some problems of spectral graph theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.4106</identifier>
 <datestamp>2011-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.4106</id><created>2009-02-24</created><authors><author><keyname>Lin</keyname><forenames>Shih-Chun</forenames></author><author><keyname>Lin</keyname><forenames>Pin-Hsun</forenames></author><author><keyname>Lee</keyname><forenames>Chung-Pi</forenames></author><author><keyname>Su</keyname><forenames>Hsuan-Jung</forenames></author></authors><title>Filter and nested-lattice code design for fading MIMO channels with
  side-information</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Transactions on Communications, Feb, 2009</comments><journal-ref>IEEE Transactions on Communications, vol. 59. No. 6, pp. 1489 -
  1494, June 2011</journal-ref><doi>10.1109/TCOMM.2011.050211.090113A</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Linear-assignment Gel'fand-Pinsker coding (LA-GPC) is a coding technique for
channels with interference known only at the transmitter, where the known
interference is treated as side-information (SI). As a special case of LA-GPC,
dirty paper coding has been shown to be able to achieve the optimal
interference-free rate for interference channels with perfect channel state
information at the transmitter (CSIT). In the cases where only the channel
distribution information at the transmitter (CDIT) is available, LA-GPC also
has good (sometimes optimal) performance in a variety of fast and slow fading
SI channels. In this paper, we design the filters in nested-lattice based
coding to make it achieve the same rate performance as LA-GPC in multiple-input
multiple-output (MIMO) channels. Compared with the random Gaussian codebooks
used in previous works, our resultant coding schemes have an algebraic
structure and can be implemented in practical systems. A simulation in a
slow-fading channel is also provided, and near interference-free error
performance is obtained. The proposed coding schemes can serve as the
fundamental building blocks to achieve the promised rate performance of MIMO
Gaussian broadcast channels with CDIT or perfect CSIT
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.4127</identifier>
 <datestamp>2009-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.4127</id><created>2009-02-24</created><updated>2009-03-23</updated><authors><author><keyname>Chernov</keyname><forenames>Alexey</forenames></author><author><keyname>Vovk</keyname><forenames>Vladimir</forenames></author></authors><title>Prediction with expert evaluators' advice</title><categories>cs.LG</categories><comments>18 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new protocol for prediction with expert advice in which each
expert evaluates the learner's and his own performance using a loss function
that may change over time and may be different from the loss functions used by
the other experts. The learner's goal is to perform better or not much worse
than each expert, as evaluated by that expert, for all experts simultaneously.
If the loss functions used by the experts are all proper scoring rules and all
mixable, we show that the defensive forecasting algorithm enjoys the same
performance guarantee as that attainable by the Aggregating Algorithm in the
standard setting and known to be optimal. This result is also applied to the
case of &quot;specialist&quot; (or &quot;sleeping&quot;) experts. In this case, the defensive
forecasting algorithm reduces to a simple modification of the Aggregating
Algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.4157</identifier>
 <datestamp>2009-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.4157</id><created>2009-02-24</created><authors><author><keyname>Theoleyre</keyname><forenames>Fabrice</forenames><affiliation>LIG</affiliation></author><author><keyname>Schiller</keyname><forenames>Eryk</forenames><affiliation>LIG</affiliation></author><author><keyname>Duda</keyname><forenames>Andrzej</forenames><affiliation>LIG</affiliation></author></authors><title>Efficient Greedy Geographical Non-Planar Routing with Reactive
  Deflection</title><categories>cs.NI</categories><proxy>ccsd hal-00363811</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel geographical routing scheme for spontaneous wireless mesh
networks. Greedy geographical routing has many advantages, but suffers from
packet losses occurring at the border of voids. In this paper, we propose a
flexible greedy routing scheme that can be adapted to any variant of
geographical routing and works for any connectivity graph, not necessarily Unit
Disk Graphs. The idea is to reactively detect voids, backtrack packets, and
propagate information on blocked sectors to reduce packet loss. We also propose
an extrapolating algorithm to reduce the latency of void discovery and to limit
route stretch. Performance evaluation via simulation shows that our modified
greedy routing avoids most of packet losses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.4177</identifier>
 <datestamp>2009-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.4177</id><created>2009-02-24</created><updated>2009-08-06</updated><authors><author><keyname>Prasad</keyname><forenames>K.</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>Convolutional Codes for Network-Error Correction</title><categories>cs.IT math.IT</categories><comments>10 pages, 5 figures; Revised version; A shortened version of this
  paper is to appear in the proceedings of GlobeComm 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we introduce convolutional codes for network-error correction
in the context of coherent network coding. We give a construction of
convolutional codes that correct a given set of error patterns, as long as
consecutive errors are separated by a certain interval. We also give some
bounds on the field size and the number of errors that can get corrected in a
certain interval. Compared to previous network error correction schemes, using
convolutional codes is seen to have advantages in field size and decoding
technique. Some examples are discussed which illustrate the several possible
situations that arise in this context.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.4185</identifier>
 <datestamp>2011-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.4185</id><created>2009-02-24</created><updated>2010-07-28</updated><authors><author><keyname>Zdeborov&#xe1;</keyname><forenames>Lenka</forenames></author><author><keyname>Krzakala</keyname><forenames>Florent</forenames></author></authors><title>Quiet Planting in the Locked Constraint Satisfaction Problems</title><categories>cond-mat.stat-mech cond-mat.dis-nn cs.CC</categories><comments>21 pages, revised version</comments><journal-ref>SIAM J. Discrete Math. 25, 750-770 (2011)</journal-ref><doi>10.1137/090750755</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the planted ensemble of locked constraint satisfaction problems. We
describe the connection between the random and planted ensembles. The use of
the cavity method is combined with arguments from reconstruction on trees and
first and second moment considerations; in particular the connection with the
reconstruction on trees appears to be crucial. Our main result is the location
of the hard region in the planted ensemble. In a part of that hard region
instances have with high probability a single satisfying assignment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.4218</identifier>
 <datestamp>2010-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.4218</id><created>2009-02-24</created><authors><author><keyname>Chebotarev</keyname><forenames>Pavel</forenames></author></authors><title>On graph theoretic results underlying the analysis of consensus in
  multi-agent systems</title><categories>cs.MA cs.DM math.CO math.OC</categories><comments>3 pages, 13 references. Submitted</comments><journal-ref>Proceedings of the IEEE, Vol. 98, No. 7, July 2010</journal-ref><doi>10.1109/JPROC.2010.2049911</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This note corrects a pretty serious mistake and some inaccuracies in
&quot;Consensus and cooperation in networked multi-agent systems&quot; by R.
Olfati-Saber, J.A. Fax, and R.M. Murray, published in Vol. 95 of the
Proceedings of the IEEE (2007, No. 1, P. 215-233). It also mentions several
stronger results applicable to the class of problems under consideration and
addresses the issue of priority whose interpretation in the above-mentioned
paper is not exact.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.4221</identifier>
 <datestamp>2009-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.4221</id><created>2009-02-24</created><authors><author><keyname>Neufeld</keyname><forenames>Michael</forenames></author><author><keyname>Partridge</keyname><forenames>Craig</forenames></author></authors><title>Semantic Network Layering</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The stack in various forms has been widely used as an architectural template
for networking systems. Recently the stack has been subject to criticism for a
lack of flexibility. However, when it comes right down to it nobody has offered
a truly compelling alternative. Various cross-layer optimizations have been
proposed, but these optimizations are frequently hacks to achieve a particular
goal and offer no direct insight into why the existing network stack is
inadequate. We propose that a fundamental problem with the existing network
stack is that it attempts to layer functionality that is not well-suited to
layering. In this work we use a &quot;bottom up&quot; model of information computation,
storage, and transfer and the &quot;top down&quot; goals of networking systems to
formulate a modular decomposition of networking systems. Based on this modular
decomposition we propose a semantic layered structure for networking systems
that eliminates many awkward cross-layer interactions that arise in the
canonical layered stack.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.4228</identifier>
 <datestamp>2009-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.4228</id><created>2009-02-24</created><authors><author><keyname>Potluru</keyname><forenames>Vamsi K.</forenames></author><author><keyname>Plis</keyname><forenames>Sergey M.</forenames></author><author><keyname>Morup</keyname><forenames>Morten</forenames></author><author><keyname>Calhoun</keyname><forenames>Vince D.</forenames></author><author><keyname>Lane</keyname><forenames>Terran</forenames></author></authors><title>Multiplicative updates For Non-Negative Kernel SVM</title><categories>cs.LG</categories><comments>4 pages, 1 figure, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present multiplicative updates for solving hard and soft margin support
vector machines (SVM) with non-negative kernels. They follow as a natural
extension of the updates for non-negative matrix factorization. No additional
param- eter setting, such as choosing learning, rate is required. Ex- periments
demonstrate rapid convergence to good classifiers. We analyze the rates of
asymptotic convergence of the up- dates and establish tight bounds. We test the
performance on several datasets using various non-negative kernels and report
equivalent generalization errors to that of a standard SVM.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.4246</identifier>
 <datestamp>2012-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.4246</id><created>2009-02-24</created><updated>2009-06-24</updated><authors><author><keyname>Kurmaev</keyname><forenames>Oleg</forenames></author></authors><title>Constant-Weight and Constant-Charge Binary Run-Length Limited Codes</title><categories>cs.IT math.IT</categories><comments>29 pages, submitted to IEEE Transactions on Information Theory. This
  paper is a corrected version of a paper with the same title that appeared on
  the arXiv in Feb. 2009. The major change is in Section VI, in which
  Subsection D is now well defined</comments><doi>10.1109/TIT.2011.2145490</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Constant-weight and constant-charge binary sequences with constrained run
length of zeros are introduced. For these sequences, the weight and the charge
distribution are found. Then, recurrent and direct formulas for calculating the
number of these sequences are obtained. With considering these numbers of
constant-weight and constant-charge RLL sequences as coefficients of convergent
power series, generating functions are derived. The fact, that generating
function for enumerating constant-charge RLL sequences does not have a closed
form, is proved. Implementation of encoding and decoding procedures using
Cover's enumerative scheme is shown. On the base of obtained results, some
examples, such as enumeration of running-digital-sum (RDS) constrained RLL
sequences or peak-shifts control capability are also provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.4250</identifier>
 <datestamp>2009-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.4250</id><created>2009-02-25</created><authors><author><keyname>Rao</keyname><forenames>N. Raj</forenames></author><author><keyname>Silverstein</keyname><forenames>Jack W.</forenames></author></authors><title>Fundamental limit of sample generalized eigenvalue based detection of
  signals in noise using relatively few signal-bearing and noise-only samples</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE Journal of Selected Topics in Signal
  Processing, Special Issue on Model Order Selection in Signal Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The detection problem in statistical signal processing can be succinctly
formulated: Given m (possibly) signal bearing, n-dimensional signal-plus-noise
snapshot vectors (samples) and N statistically independent n-dimensional
noise-only snapshot vectors, can one reliably infer the presence of a signal?
This problem arises in the context of applications as diverse as radar, sonar,
wireless communications, bioinformatics, and machine learning and is the
critical first step in the subsequent signal parameter estimation phase.
  The signal detection problem can be naturally posed in terms of the sample
generalized eigenvalues. The sample generalized eigenvalues correspond to the
eigenvalues of the matrix formed by &quot;whitening&quot; the signal-plus-noise sample
covariance matrix with the noise-only sample covariance matrix. In this article
we prove a fundamental asymptotic limit of sample generalized eigenvalue based
detection of signals in arbitrarily colored noise when there are relatively few
signal bearing and noise-only samples.
  Numerical simulations highlight the accuracy of our analytical prediction and
permit us to extend our heuristic definition of the effective number of
identifiable signals in colored noise. We discuss implications of our result
for the detection of weak and/or closely spaced signals in sensor array
processing, abrupt change detection in sensor networks, and clustering
methodologies in machine learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.4291</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.4291</id><created>2009-02-25</created><updated>2009-11-10</updated><authors><author><keyname>Mishali</keyname><forenames>Moshe</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author></authors><title>From Theory to Practice: Sub-Nyquist Sampling of Sparse Wideband Analog
  Signals</title><categories>cs.IT math.IT</categories><comments>17 pages, 12 figures, to appear in IEEE Journal of Selected Topics in
  Signal Processing, the special issue on Compressed Sensing</comments><doi>10.1109/JSTSP.2010.2042414</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Conventional sub-Nyquist sampling methods for analog signals exploit prior
information about the spectral support. In this paper, we consider the
challenging problem of blind sub-Nyquist sampling of multiband signals, whose
unknown frequency support occupies only a small portion of a wide spectrum. Our
primary design goals are efficient hardware implementation and low
computational load on the supporting digital processing. We propose a system,
named the modulated wideband converter, which first multiplies the analog
signal by a bank of periodic waveforms. The product is then lowpass filtered
and sampled uniformly at a low rate, which is orders of magnitude smaller than
Nyquist. Perfect recovery from the proposed samples is achieved under certain
necessary and sufficient conditions. We also develop a digital architecture,
which allows either reconstruction of the analog input, or processing of any
band of interest at a low rate, that is, without interpolating to the high
Nyquist rate. Numerical simulations demonstrate many engineering aspects:
robustness to noise and mismodeling, potential hardware simplifications,
realtime performance for signals with time-varying support and stability to
quantization effects. We compare our system with two previous approaches:
periodic nonuniform sampling, which is bandwidth limited by existing hardware
devices, and the random demodulator, which is restricted to discrete multitone
signals and has a high computational load. In the broader context of Nyquist
sampling, our scheme has the potential to break through the bandwidth barrier
of state-of-the-art analog conversion technologies such as interleaved
converters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.4337</identifier>
 <datestamp>2009-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.4337</id><created>2009-02-25</created><authors><author><keyname>Alt</keyname><forenames>Helmut</forenames></author><author><keyname>Scharf</keyname><forenames>Ludmila</forenames></author><author><keyname>Schymura</keyname><forenames>Daria</forenames></author></authors><title>Probabilistic Matching of Planar Regions</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze a probabilistic algorithm for matching shapes modeled by planar
regions under translations and rigid motions (rotation and translation). Given
shapes $A$ and $B$, the algorithm computes a transformation $t$ such that with
high probability the area of overlap of $t(A)$ and $B$ is close to maximal. In
the case of polygons, we give a time bound that does not depend significantly
on the number of vertices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.4348</identifier>
 <datestamp>2012-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.4348</id><created>2009-02-25</created><updated>2012-09-07</updated><authors><author><keyname>Vagvolgyi</keyname><forenames>Sandor</forenames></author></authors><title>On ground word problem of term equation systems</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give semi-decision procedures for the ground word problem of variable
preserving term equation systems and term equation systems. They are natural
improvements of two well known trivial semi-decision procedures. We show the
correctness of our procedures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.4394</identifier>
 <datestamp>2009-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.4394</id><created>2009-02-25</created><authors><author><keyname>Rauhut</keyname><forenames>Holger</forenames></author></authors><title>Circulant and Toeplitz matrices in compressed sensing</title><categories>cs.IT math.IT</categories><comments>6 pages, submitted to Proc. SPARS'09 (Saint-Malo)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compressed sensing seeks to recover a sparse vector from a small number of
linear and non-adaptive measurements. While most work so far focuses on
Gaussian or Bernoulli random measurements we investigate the use of partial
random circulant and Toeplitz matrices in connection with recovery by
$\ell_1$-minization. In contrast to recent work in this direction we allow the
use of an arbitrary subset of rows of a circulant and Toeplitz matrix. Our
recovery result predicts that the necessary number of measurements to ensure
sparse reconstruction by $\ell_1$-minimization with random partial circulant or
Toeplitz matrices scales linearly in the sparsity up to a $\log$-factor in the
ambient dimension. This represents a significant improvement over previous
recovery results for such matrices. As a main tool for the proofs we use a new
version of the non-commutative Khintchine inequality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.4447</identifier>
 <datestamp>2009-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.4447</id><created>2009-02-25</created><updated>2009-08-28</updated><authors><author><keyname>Kong</keyname><forenames>Zhenning</forenames></author><author><keyname>Yeh</keyname><forenames>Edmund M.</forenames></author></authors><title>Percolation Processes and Wireless Network Resilience to
  Degree-Dependent and Cascading Node Failures</title><categories>cs.NI cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of wireless network resilience to node failures from a
percolation-based perspective. In practical wireless networks, it is often the
case that the failure probability of a node depends on its degree (number of
neighbors). We model this phenomenon as a degree-dependent site percolation
process on random geometric graphs. In particular, we obtain analytical
conditions for the existence of phase transitions within this model.
Furthermore, in networks carrying traffic load, the failure of one node can
result in redistribution of the load onto other nearby nodes. If these nodes
fail due to excessive load, then this process can result in a cascading
failure. Using a simple but descriptive model, we show that the cascading
failure problem for large-scale wireless networks is equivalent to a
degree-dependent site percolation on random geometric graphs. We obtain
analytical conditions for cascades in this model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.4449</identifier>
 <datestamp>2009-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.4449</id><created>2009-02-25</created><authors><author><keyname>Kong</keyname><forenames>Zhenning</forenames></author><author><keyname>Yeh</keyname><forenames>Edmund M.</forenames></author></authors><title>Connectivity, Percolation, and Information Dissemination in Large-Scale
  Wireless Networks with Dynamic Links</title><categories>cs.IT cs.NI math.IT math.PR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the problem of disseminating broadcast messages in wireless
networks with time-varying links from a percolation-based perspective. Using a
model of wireless networks based on random geometric graphs with dynamic on-off
links, we show that the delay for disseminating broadcast information exhibits
two behavioral regimes, corresponding to the phase transition of the underlying
network connectivity. When the dynamic network is in the subcritical phase,
ignoring propagation delays, the delay scales linearly with the Euclidean
distance between the sender and the receiver. When the dynamic network is in
the supercritical phase, the delay scales sub-linearly with the distance.
Finally, we show that in the presence of a non-negligible propagation delay,
the delay for information dissemination scales linearly with the Euclidean
distance in both the subcritical and supercritical regimes, with the rates for
the linear scaling being different in the two regimes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.4460</identifier>
 <datestamp>2009-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.4460</id><created>2009-02-25</created><authors><author><keyname>Borzenko</keyname><forenames>V. I.</forenames></author><author><keyname>Lezina</keyname><forenames>Z. M.</forenames></author><author><keyname>Loginov</keyname><forenames>A. K.</forenames></author><author><keyname>Tsodikova</keyname><forenames>Ya. Yu.</forenames></author><author><keyname>Chebotarev</keyname><forenames>P. Yu.</forenames></author></authors><title>Strategies of Voting in Stochastic Environment: Egoism and Collectivism</title><categories>math.OC cs.MA math.PR</categories><comments>18 pages, 7 figures, translated from Russian by M.A. Kasner</comments><msc-class>91B12; 91B70</msc-class><journal-ref>Automation and Remote Control, 2006, Vol. 67, No. 2, pp. 311-328.
  Original Russian text published in Avtomatika i Telemekhanika, 2006, No. 2,
  pp. 154-173</journal-ref><doi>10.1134/S0005117906020093</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consideration was given to a model of social dynamics controlled by
successive collective decisions based on the threshold majority procedures. The
current system state is characterized by the vector of participants' capitals
(utilities). At each step, the voters can either retain their status quo or
accept the proposal which is a vector of the algebraic increments in the
capitals of the participants. In this version of the model, the vector is
generated stochastically. Comparative utility of two social attitudes--egoism
and collectivism--was analyzed. It was established that, except for some
special cases, the collectivists have advantages, which makes realizable the
following scenario: on the conditions of protecting the corporate interests, a
group is created which is joined then by the egoists attracted by its
achievements. At that, group egoism approaches altruism. Additionally, one of
the considered variants of collectivism handicaps manipulation of voting by the
organizers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.4463</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.4463</id><created>2009-02-25</created><updated>2009-03-05</updated><authors><author><keyname>Gaburov</keyname><forenames>Evghenii</forenames></author><author><keyname>Harfst</keyname><forenames>Stefan</forenames></author><author><keyname>Zwart</keyname><forenames>Simon Portegies</forenames></author></authors><title>SAPPORO: A way to turn your graphics cards into a GRAPE-6</title><categories>astro-ph.IM cs.DC</categories><comments>13 pages, 9 figures, accepted to New Astronomy</comments><doi>10.1016/j.newast.2009.03.002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present Sapporo, a library for performing high-precision gravitational
N-body simulations on NVIDIA Graphical Processing Units (GPUs). Our library
mimics the GRAPE-6 library, and N-body codes currently running on GRAPE-6 can
switch to Sapporo by a simple relinking of the library. The precision of our
library is comparable to that of GRAPE-6, even though internally the GPU
hardware is limited to single precision arithmetics. This limitation is
effectively overcome by emulating double precision for calculating the distance
between particles. The performance loss of this operation is small (&lt; 20%)
compared to the advantage of being able to run at high precision. We tested the
library using several GRAPE-6-enabled N-body codes, in particular with Starlab
and phiGRAPE. We measured peak performance of 800 Gflop/s for running with 10^6
particles on a PC with four commercial G92 architecture GPUs (two GeForce
9800GX2). As a production test, we simulated a 32k Plummer model with equal
mass stars well beyond core collapse. The simulation took 41 days, during which
the mean performance was 113 Gflop/s. The GPU did not show any problems from
running in a production environment for such an extended period of time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.4481</identifier>
 <datestamp>2009-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.4481</id><created>2009-02-25</created><updated>2009-02-26</updated><authors><author><keyname>Jelenkovic</keyname><forenames>Predrag R.</forenames></author><author><keyname>Tan</keyname><forenames>Jian</forenames></author></authors><title>Stability of Finite Population ALOHA with Variable Packets</title><categories>cs.PF cs.IT math.IT</categories><comments>14 pages, 5 figures</comments><report-no>EE2009-02-20</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  ALOHA is one of the most basic Medium Access Control (MAC) protocols and
represents a foundation for other more sophisticated distributed and
asynchronous MAC protocols, e.g., CSMA. In this paper, unlike in the
traditional work that focused on mean value analysis, we study the
distributional properties of packet transmission delays over an ALOHA channel.
We discover a new phenomenon showing that a basic finite population ALOHA model
with variable size (exponential) packets is characterized by power law
transmission delays, possibly even resulting in zero throughput. These results
are in contrast to the classical work that shows exponential delays and
positive throughput for finite population ALOHA with fixed packets.
Furthermore, we characterize a new stability condition that is entirely derived
from the tail behavior of the packet and backoff distributions that may not be
determined by mean values. The power law effects and the possible instability
might be diminished, or perhaps eliminated, by reducing the variability of
packets. However, we show that even a slotted (synchronized) ALOHA with packets
of constant size can exhibit power law delays when the number of active users
is random. From an engineering perspective, our results imply that the
variability of packet sizes and number of active users need to be taken into
consideration when designing robust MAC protocols, especially for ad-hoc/sensor
networks where other factors, such as link failures and mobility, might further
compound the problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.4508</identifier>
 <datestamp>2009-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.4508</id><created>2009-02-26</created><authors><author><keyname>Luo</keyname><forenames>Jinquan</forenames></author><author><keyname>Tang</keyname><forenames>Yuansheng</forenames></author><author><keyname>Wang</keyname><forenames>Hongyu</forenames></author></authors><title>Exponential Sums, Cyclic Codes and Sequences: the Odd Characteristic
  Kasami Case</title><categories>cs.IT cs.DM math.CO math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $q=p^n$ with $n=2m$ and $p$ be an odd prime. Let $0\leq k\leq n-1$ and
$k\neq m$. In this paper we determine the value distribution of following
exponential(character) sums \[\sum\limits_{x\in \bF_q}\zeta_p^{\Tra_1^m (\alpha
x^{p^{m}+1})+\Tra_1^n(\beta x^{p^k+1})}\quad(\alpha\in \bF_{p^m},\beta\in
\bF_{q})\] and \[\sum\limits_{x\in \bF_q}\zeta_p^{\Tra_1^m (\alpha
x^{p^{m}+1})+\Tra_1^n(\beta x^{p^k+1}+\ga x)}\quad(\alpha\in
\bF_{p^m},\beta,\ga\in \bF_{q})\] where $\Tra_1^n: \bF_q\ra \bF_p$ and
$\Tra_1^m: \bF_{p^m}\ra\bF_p$ are the canonical trace mappings and
$\zeta_p=e^{\frac{2\pi i}{p}}$ is a primitive $p$-th root of unity. As
applications: (1). We determine the weight distribution of the cyclic codes
$\cC_1$ and $\cC_2$ over $\bF_{p^t}$ with parity-check polynomials
$h_2(x)h_3(x)$ and $h_1(x)h_2(x)h_3(x)$ respectively where $t$ is a divisor of
$d=\gcd(m,k)$, and $h_1(x)$, $h_2(x)$ and $h_3(x)$ are the minimal polynomials
of $\pi^{-1}$, $\pi^{-(p^k+1)}$ and $\pi^{-(p^m+1)}$ over $\bF_{p^t}$
respectively for a primitive element $\pi$ of $\bF_q$. (2). We determine the
correlation distribution among a family of m-sequences. This paper extends the
results in \cite{Zen Li}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.4509</identifier>
 <datestamp>2009-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.4509</id><created>2009-02-26</created><authors><author><keyname>Luo</keyname><forenames>Jinquan</forenames></author><author><keyname>Ling</keyname><forenames>San</forenames></author><author><keyname>Xing</keyname><forenames>Chaoping</forenames></author></authors><title>Cyclic Codes and Sequences from a Class of Dembowski-Ostrom Functions</title><categories>cs.IT cs.DM math.CO math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $q=p^n$ with $p$ be an odd prime. Let $0\leq k\leq n-1$ and $k\neq n/2$.
In this paper we determine the value distribution of following
exponential(character) sums \[\sum\limits_{x\in \bF_q}\zeta_p^{\Tra_1^n(\alpha
x^{p^{3k}+1}+\beta x^{p^k+1})}\quad(\alpha\in \bF_{p^m},\beta\in \bF_{q})\] and
\[\sum\limits_{x\in \bF_q}\zeta_p^{\Tra_1^n(\alpha x^{p^{3k}+1}+\beta
x^{p^k+1}+\ga x)}\quad(\alpha\in \bF_{p^m},\beta,\ga\in \bF_{q})\] where
$\Tra_1^n: \bF_q\ra \bF_p$ and $\Tra_1^m: \bF_{p^m}\ra\bF_p$ are the canonical
trace mappings and $\zeta_p=e^{\frac{2\pi i}{p}}$ is a primitive $p$-th root of
unity. As applications: (1). We determine the weight distribution of the cyclic
codes $\cC_1$ and $\cC_2$ over $\bF_{p^t}$ with parity-check polynomials
$h_2(x)h_3(x)$ and $h_1(x)h_2(x)h_3(x)$ respectively where $t$ is a divisor of
$d=\gcd(n,k)$, and $h_1(x)$, $h_2(x)$ and $h_3(x)$ are the minimal polynomials
of $\pi^{-1}$, $\pi^{-(p^k+1)}$ and $\pi^{-(p^{3k}+1)}$ over $\bF_{p^t}$
respectively for a primitive element $\pi$ of $\bF_q$. (2). We determine the
correlation distribution among a family of m-sequences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.4510</identifier>
 <datestamp>2009-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.4510</id><created>2009-02-26</created><authors><author><keyname>Luo</keyname><forenames>Jinquan</forenames></author><author><keyname>Wang</keyname><forenames>Hongyu</forenames></author><author><keyname>Tang</keyname><forenames>Yuansheng</forenames></author></authors><title>Cyclic Codes and Sequences: the Generalized Kasami Case</title><categories>cs.IT cs.DM math.CO math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $q=2^n$ with $n=2m$ . Let $1\leq k\leq n-1$ and $k\neq m$. In this paper
we determine the value distribution of following exponential sums
\[\sum\limits_{x\in \bF_q}(-1)^{\Tra_1^m (\alpha x^{2^{m}+1})+\Tra_1^n(\beta
x^{2^k+1})}\quad(\alpha\in \bF_{2^m},\beta\in \bF_{q})\] and
\[\sum\limits_{x\in \bF_q}(-1)^{\Tra_1^m (\alpha x^{2^{m}+1})+\Tra_1^n(\beta
x^{2^k+1}+\ga x)}\quad(\alpha\in \bF_{2^m},\beta,\ga\in \bF_{q})\] where
$\Tra_1^n: \bF_q\ra \bF_2$ and $\Tra_1^m: \bF_{p^m}\ra\bF_2$ are the canonical
trace mappings. As applications: (1). We determine the weight distribution of
the binary cyclic codes $\cC_1$ and $\cC_2$ with parity-check polynomials
$h_2(x)h_3(x)$ and $h_1(x)h_2(x)h_3(x)$ respectively where $h_1(x)$, $h_2(x)$
and $h_3(x)$ are the minimal polynomials of $\pi^{-1}$, $\pi^{-(2^k+1)}$ and
$\pi^{-(2^m+1)}$ over $\bF_{2}$ respectively for a primitive element $\pi$ of
$\bF_q$. (2). We determine the correlation distribution among a family of
m-sequences. This paper is the binary version of Luo, Tang and Wang\cite{Luo
Tan} and extends the results in Kasami\cite{Kasa1}, Van der Vlugt\cite{Vand2}
and Zeng, Liu and Hu\cite{Zen Liu}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.4511</identifier>
 <datestamp>2009-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.4511</id><created>2009-02-26</created><authors><author><keyname>Luo</keyname><forenames>Jinquan</forenames></author><author><keyname>Ling</keyname><forenames>San</forenames></author><author><keyname>Xing</keyname><forenames>Chaoping</forenames></author></authors><title>Cyclic Codes and Sequences from Kasami-Welch Functions</title><categories>cs.IT cs.DM math.CO math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $q=2^n$, $0\leq k\leq n-1$ and $k\neq n/2$. In this paper we determine
the value distribution of following exponential sums \[\sum\limits_{x\in
\bF_q}(-1)^{\Tra_1^n(\alpha x^{2^{3k}+1}+\beta x^{2^k+1})}\quad(\alpha,\beta\in
\bF_{q})\] and \[\sum\limits_{x\in \bF_q}(-1)^{\Tra_1^n(\alpha
x^{2^{3k}+1}+\beta x^{2^k+1}+\ga x)}\quad(\alpha,\beta,\ga\in \bF_{q})\] where
$\Tra_1^n: \bF_{2^n}\ra \bF_2$ is the canonical trace mapping. As applications:
(1). We determine the weight distribution of the binary cyclic codes $\cC_1$
and $\cC_2$ with parity-check polynomials $h_2(x)h_3(x)$ and
$h_1(x)h_2(x)h_3(x)$ respectively where $h_1(x)$, $h_2(x)$ and $h_3(x)$ are the
minimal polynomials of $\pi^{-1}$, $\pi^{-(2^k+1)}$ and $\pi^{-(2^{3k}+1)}$
respectively for a primitive element $\pi$ of $\bF_q$. (2). We determine the
correlation distribution among a family of binary m-sequences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.4514</identifier>
 <datestamp>2011-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.4514</id><created>2009-02-26</created><updated>2009-02-26</updated><authors><author><keyname>Chebotarev</keyname><forenames>Pavel</forenames></author></authors><title>Analytical Expression of the Expected Values of Capital at Voting in the
  Stochastic Environment</title><categories>math.OC cs.MA cs.SI cs.SY math.PR</categories><comments>13 pages, 5 figures, translated from Russian by M.A. Kasner</comments><msc-class>91B12; 91B70</msc-class><journal-ref>Automation and Remote Control, 2006, Vol. 67, No. 2, pp. 480-492.
  Original Russian text published in Avtomatika i Telemekhanika, 2006, No. 3,
  pp. 152-165</journal-ref><doi>10.1134/S000511790603012X</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the simplest version of the model of group decision making in the
stochastic environment, the participants are segregated into egoists and a
group of collectivists. A &quot;proposal of the environment&quot; is a stochastically
generated vector of algebraic increments of participants' capitals. The social
dynamics is determined by the sequence of proposals accepted by a majority
voting (with a threshold) of the participants. In this paper, we obtain
analytical expressions for the expected values of capitals for all the
participants, including collectivists and egoists. In addition, distinctions
between some principles of group voting are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.4521</identifier>
 <datestamp>2009-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.4521</id><created>2009-02-26</created><authors><author><keyname>Luo</keyname><forenames>Dijun</forenames></author><author><keyname>Huang</keyname><forenames>Heng</forenames></author><author><keyname>Ding</keyname><forenames>Chris</forenames></author></authors><title>Are Tensor Decomposition Solutions Unique? On the global convergence of
  HOSVD and ParaFac algorithms</title><categories>cs.CV cs.AI</categories><comments>Submitted to CVPR2009 in Nov. 20, 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For tensor decompositions such as HOSVD and ParaFac, the objective functions
are nonconvex. This implies, theoretically, there exists a large number of
local optimas: starting from different starting point, the iteratively improved
solution will converge to different local solutions. This non-uniqueness
present a stability and reliability problem for image compression and
retrieval. In this paper, we present the results of a comprehensive
investigation of this problem. We found that although all tensor decomposition
algorithms fail to reach a unique global solution on random data and severely
scrambled data; surprisingly however, on all real life several data sets (even
with substantial scramble and occlusions), HOSVD always produce the unique
global solution in the parameter region suitable to practical applications,
while ParaFac produce non-unique solutions. We provide an eigenvalue based rule
for the assessing the solution uniqueness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.4527</identifier>
 <datestamp>2009-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.4527</id><created>2009-02-26</created><authors><author><keyname>Livathinos</keyname><forenames>Nikolaos S.</forenames></author></authors><title>EXtensible Animator for Mobile Simulations: EXAMS</title><categories>cs.NI cs.PF</categories><comments>9 pages with 7 figures</comments><acm-class>I.6.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the most widely used simulation environments for mobile wireless
networks is the Network Simulator 2 (NS-2). However NS-2 stores its outcome in
a text file, so there is a need for a visualization tool to animate the
simulation of the wireless network. The purpose of this tool is to help the
researcher examine in detail how the wireless protocol works both on a network
and a node basis. It is clear that much of this information is protocol
dependent and cannot be depicted properly by a general purpose animation
process. Existing animation tools do not provide this level of information
neither permit the specific protocol to control the animation at all. EXAMS is
an NS-2 visualization tool for mobile simulations which makes possible the
portrayal of NS-2 internal information like transmission properties and node
data structures. This is mainly possible due to EXAMS extensible architecture
which separates the animation process into a general and a protocol specific
part. The latter can be developed independently by the protocol designer and
loaded on demand. These and other useful characteristics of the EXAMS tool can
be an invaluable help for a researcher in order to investigate and debug a
mobile networking protocol.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.4535</identifier>
 <datestamp>2009-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.4535</id><created>2009-02-26</created><authors><author><keyname>Apostol</keyname><forenames>Simona Angela</forenames></author><author><keyname>Catu</keyname><forenames>Cosmin</forenames></author><author><keyname>Vernic</keyname><forenames>Corina</forenames></author></authors><title>Electronical Health Record's Systems. Interoperability</title><categories>cs.DB</categories><comments>14 pages</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series 6 (2008), 7-20</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Understanding the importance that the electronic medical health records
system has, with its various structural types and grades, has led to the
elaboration of a series of standards and quality control methods, meant to
control its functioning. In time, the electronic health records system has
evolved along with the medical data change of structure. Romania has not yet
managed to fully clarify this concept, various definitions still being
encountered, such as &quot;Patient's electronic chart&quot;, &quot;Electronic health file&quot;. A
slow change from functional interoperability (OSI level 6) to semantic
interoperability (level 7) is being aimed at the moment. This current article
will try to present the main electronic files models, from a functional
interoperability system's possibility to be created perspective.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.4572</identifier>
 <datestamp>2009-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.4572</id><created>2009-02-26</created><authors><author><keyname>Chettibi</keyname><forenames>Saloua</forenames></author><author><keyname>Benmohamed</keyname><forenames>M.</forenames></author></authors><title>A Multipath Energy-Aware On demand Source Routing Protocol for Mobile
  Ad-Hoc Networks</title><categories>cs.NI</categories><proxy>ccsd hal-00364466</proxy><journal-ref>1st Workshop on Next Generation Networks: Mobility, WNGN,, Maroc
  (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Energy consumption is the most challenging issue in routing protocol design
for mobile ad-hoc networks (MANETs), since mobile nodes are battery powered.
Furthermore, replacing or recharging batteries is often impossible in critical
environments such as in military or rescue missions. In a MANET, the energy
depletion of a node does not affect the node itself only, but the overall
network lifetime. In this paper, we present multipath and energy-aware on
demand source routing (MEA-DSR) protocol, which exploits route diversity and
information about batteries-energy levels for balancing energy consumption
between mobile nodes. Simulation results, have shown that MEA-DSR protocol is
more energy efficient than DSR in almost mobility scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.4577</identifier>
 <datestamp>2010-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.4577</id><created>2009-02-26</created><updated>2010-03-22</updated><authors><author><keyname>Jing</keyname><forenames>Zhenhai</forenames></author><author><keyname>Bai</keyname><forenames>Baoming</forenames></author><author><keyname>Ma</keyname><forenames>Xiao</forenames></author></authors><title>Using Distributed Rate-Splitting Game to Approach Rate Region Boundary
  of the Gaussian Interference Channel</title><categories>cs.IT math.IT</categories><comments>29 pages, 10 figures, submitted to IEEE Trans on Information
  Theory,Feb.,2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Determining how to approach the rate boundary of the Gaussian interference
channel in practical system is a big concern. In this paper, a distributed
rate-splitting (DRS) scheme is proposed to approach the rate region boundary of
the Gaussian interference channel. It is shown that the DRS scheme can be
formulated as a non-cooperative game. We introduce the Stackelberg equilibrium
(SE) with multiple leaders as the equilibrium point of the non-cooperative
game. Therefore, an iterative multiple waterlevels water-filling algorithm
(IML-WFA) is developed to efficiently reach the SE of the non-cooperative game.
The existence of SE is established for the game. Numerical examples show that
the rate-tuples achieved by the DRS are very close to the boundary of the
well-known HK region.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.4640</identifier>
 <datestamp>2009-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.4640</id><created>2009-02-26</created><authors><author><keyname>Cardona</keyname><forenames>Gabriel</forenames></author><author><keyname>Llabres</keyname><forenames>Merce</forenames></author><author><keyname>Rossello</keyname><forenames>Francesc</forenames></author><author><keyname>Valiente</keyname><forenames>Gabriel</forenames></author></authors><title>The comparison of tree-sibling time consistent phylogenetic networks is
  graph isomorphism-complete</title><categories>q-bio.PE cs.DM</categories><comments>10 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a previous work, we gave a metric on the class of semibinary tree-sibling
time consistent phylogenetic networks that is computable in polynomial time; in
particular, the problem of deciding if two networks of this kind are isomorphic
is in P. In this paper, we show that if we remove the semibinarity condition
above, then the problem becomes much harder. More precisely, we proof that the
isomorphism problem for generic tree-sibling time consistent phylogenetic
networks is polynomially equivalent to the graph isomorphism problem. Since the
latter is believed to be neither in P nor NP-complete, the chances are that it
is impossible to define a metric on the class of all tree-sibling time
consistent phylogenetic networks that can be computed in polynomial time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.4647</identifier>
 <datestamp>2009-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.4647</id><created>2009-02-26</created><authors><author><keyname>Liang</keyname><forenames>Yifan</forenames></author><author><keyname>Goldsmith</keyname><forenames>Andrea</forenames></author><author><keyname>Effros</keyname><forenames>Michelle</forenames></author></authors><title>Source-Channel Coding and Separation for Generalized Communication
  Systems</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider transmission of stationary and ergodic sources over non-ergodic
composite channels with channel state information at the receiver (CSIR).
Previously we introduced alternate capacity definitions to Shannon capacity,
including the capacity versus outage and the expected capacity. These
generalized definitions relax the constraint of Shannon capacity that all
transmitted information must be decoded at the receiver. In this work alternate
end-to-end distortion metrics such as the distortion versus outage and the
expected distortion are introduced to relax the constraint that a single
distortion level has to be maintained for all channel states. For transmission
of stationary and ergodic sources over stationary and ergodic channels, the
classical Shannon separation theorem enables separate design of source and
channel codes and guarantees optimal performance. For generalized communication
systems, we show that different end-to-end distortion metrics lead to different
conclusions about separation optimality even for the same source and channel
models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.4658</identifier>
 <datestamp>2009-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.4658</id><created>2009-02-26</created><authors><author><keyname>Zinoviev</keyname><forenames>Dmitry</forenames></author><author><keyname>Duong</keyname><forenames>Vy</forenames></author></authors><title>Toward Understanding Friendship in Online Social Networks</title><categories>cs.CY</categories><comments>4 pages, 4 figures. Presented virtually at ICTKS'2008 (Huntsville,
  AL). Accepted to the International Journal of Technology, Knowledge, and
  Society</comments><acm-class>J.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  All major on-line social networks, such as MySpace, Facebook, LiveJournal,
and Orkut, are built around the concept of friendship. It is not uncommon for a
social network participant to have over 100 friends. A natural question arises:
are they all real friends of hers, or does she mean something different when
she calls them &quot;friends?&quot; Speaking in other words, what is the relationship
between off-line (real, traditional) friendship and its on-line (virtual)
namesake? In this paper, we use sociological data to suggest that there is a
significant difference between the concepts of virtual and real friendships. We
further investigate the structure of on-line friendship and observe that it
follows the Pareto (or double Pareto) distribution and is subject to age
stratification but not to gender segregation. We introduce the concept of
digital personality that quantifies the willingness of a social network
participant to engage in virtual friendships.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.4663</identifier>
 <datestamp>2009-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.4663</id><created>2009-02-26</created><authors><author><keyname>Sparavigna</keyname><forenames>Amelia</forenames></author></authors><title>Dipole Vectors in Images Processing</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Instead of evaluating the gradient field of the brightness map of an image,
we propose the use of dipole vectors. This approach is obtained by adapting to
the image gray-tone distribution the definition of the dipole moment of charge
distributions. We will show how to evaluate the dipoles and obtain a vector
field, which can be a good alternative to the gradient field in pattern
recognition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.4682</identifier>
 <datestamp>2014-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.4682</id><created>2009-02-26</created><updated>2014-05-27</updated><authors><author><keyname>Wirth</keyname><forenames>Claus-Peter</forenames></author><author><keyname>Siekmann</keyname><forenames>Joerg</forenames></author><author><keyname>Benzmueller</keyname><forenames>Christoph</forenames></author><author><keyname>Autexier</keyname><forenames>Serge</forenames></author></authors><title>Lectures on Jacques Herbrand as a Logician</title><categories>cs.LO cs.AI</categories><comments>ii + 82 pages</comments><report-no>SEKI Report SR-2009-01</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give some lectures on the work on formal logic of Jacques Herbrand, and
sketch his life and his influence on automated theorem proving. The intended
audience ranges from students interested in logic over historians to logicians.
Besides the well-known correction of Herbrand's False Lemma by Goedel and
Dreben, we also present the hardly known unpublished correction of Heijenoort
and its consequences on Herbrand's Modus Ponens Elimination. Besides Herbrand's
Fundamental Theorem and its relation to the Loewenheim-Skolem-Theorem, we
carefully investigate Herbrand's notion of intuitionism in connection with his
notion of falsehood in an infinite domain. We sketch Herbrand's two proofs of
the consistency of arithmetic and his notion of a recursive function, and last
but not least, present the correct original text of his unification algorithm
with a new translation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.4723</identifier>
 <datestamp>2009-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.4723</id><created>2009-02-26</created><authors><author><keyname>Endrullis</keyname><forenames>Joerg</forenames></author><author><keyname>Geuvers</keyname><forenames>Herman</forenames></author><author><keyname>Zantema</keyname><forenames>Hans</forenames></author></authors><title>Degrees of Undecidability in Rewriting</title><categories>cs.LO cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Undecidability of various properties of first order term rewriting systems is
well-known. An undecidable property can be classified by the complexity of the
formula defining it. This gives rise to a hierarchy of distinct levels of
undecidability, starting from the arithmetical hierarchy classifying properties
using first order arithmetical formulas and continuing into the analytic
hierarchy, where also quantification over function variables is allowed.
  In this paper we consider properties of first order term rewriting systems
and classify them in this hierarchy. Weak and strong normalization for single
terms turn out to be Sigma-0-1-complete, while their uniform versions as well
as dependency pair problems with minimality flag are Pi-0-2-complete. We find
that confluence is Pi-0-2-complete both for single terms and uniform.
Unexpectedly weak confluence for ground terms turns out to be harder than weak
confluence for open terms. The former property is Pi-0-2-complete while the
latter is Sigma-0-1-complete (and thereby recursively enumerable).
  The most surprising result is on dependency pair problems without minimality
flag: we prove this to be Pi-1-1-complete, which means that this property
exceeds the arithmetical hierarchy and is essentially analytic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.4730</identifier>
 <datestamp>2009-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.4730</id><created>2009-02-26</created><authors><author><keyname>Youssef</keyname><forenames>Saul</forenames></author><author><keyname>Brunelle</keyname><forenames>John</forenames></author><author><keyname>Huth</keyname><forenames>John</forenames></author><author><keyname>Parkes</keyname><forenames>David C.</forenames></author><author><keyname>Seltzer</keyname><forenames>Margo</forenames></author><author><keyname>Shank</keyname><forenames>Jim</forenames></author></authors><title>Minimal Economic Distributed Computing</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In an ideal distributed computing infrastructure, users would be able to use
diverse distributed computing resources in a simple coherent way, with
guaranteed security and efficient use of shared resources in accordance with
the wishes of the owners of the resources. Our strategy for approaching this
ideal is to first find the simplest structure within which these goals can
plausibly be achieved. This structure, we find, is given by a particular
recursive distributive lattice freely constructed from a presumed partially
ordered set of all data in the infrastructure. Minor syntactic adjustments to
the resulting algebra yields a simple language resembling a UNIX shell, a
concept of execution and an interprocess protocol. Persons, organizations and
servers within the system express their interests explicitly via a hierarchical
currency. The currency provides a common framework for treating authentication,
access control and resource sharing as economic problems while also introducing
a new dimension for improving the infrastructure over time by designing system
components which compete with each other to earn the currency. We explain these
results, discuss experience with an implementation called egg and point out
areas where more research is needed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.4779</identifier>
 <datestamp>2009-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.4779</id><created>2009-02-27</created><authors><author><keyname>Yi</keyname><forenames>Jiazi</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Cizeron</keyname><forenames>Eddy</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Hamma</keyname><forenames>Salima</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Parrein</keyname><forenames>Beno&#xee;t</forenames><affiliation>IRCCyN</affiliation></author></authors><title>Simulation and Performance Analysis of MP-OLSR for Mobile Ad hoc
  Networks</title><categories>cs.NI</categories><proxy>ccsd hal-00364744</proxy><journal-ref>IEEE WCNC 2008, Las Vegas : \'Etats-Unis d'Am\'erique (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mobile ad hoc networks (MANETs) consist of a collection of wireless mobile
nodes which dynamically exchange data without reliance on a fixed base station
or a wired backbone network, which makes routing a crucial issue for the design
of a ad hoc networks. In this paper we discussed a hybrid multipath routing
protocol named MP-OLSR. It is based on the link state algorithm and employs
periodic exchange of messages to maintain topology information of the networks.
In the mean time, it updates the routing table in an on-demand scheme and
forwards the packets in multiple paths which have been determined at the
source. If a link failure is detected, the algorithm recovers the route
automatically. Concerning the instability of the wireless networks, the
redundancy coding is used to improve the delivery ratio. The simulation in NS2
shows that the new protocol can effectively improve the performance of the
networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.4781</identifier>
 <datestamp>2009-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.4781</id><created>2009-02-27</created><authors><author><keyname>Yi</keyname><forenames>Jiazi</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Cizeron</keyname><forenames>Eddy</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Hamma</keyname><forenames>Salima</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Parrein</keyname><forenames>Beno&#xee;t</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Lesage</keyname><forenames>Pascal</forenames><affiliation>IRCCyN</affiliation></author></authors><title>Implementation of Multipath and Multiple Description Coding in OLSR</title><categories>cs.NI</categories><proxy>ccsd hal-00364751</proxy><journal-ref>4th OLSR Interop/Work Shop, Ottawa : Canada (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we discussed the application and the implementation of
multipath routing and multiple description coding (MDC) extension of OLSR,
called MP-OLSR. It is based on the link state algorithm and employs periodic
exchange of messages to maintain topology information of the networks. In the
mean time, it updates the routing table in an on-demand scheme and forwards the
packets in multiple paths which have been determined at the source. If a link
failure is detected, the algorithm recovers the route automatically. Concerning
the instability of the wireless networks, the multiple description coding is
used to improve reliability of the network transmission, and several methods
are proposed to allocate the redundancy in different paths. The simulation in
NS2 shows that the new protocol can effectively improve the performance of the
networks. The implementation of MP-OLSR is also proposed in the end.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.4822</identifier>
 <datestamp>2009-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.4822</id><created>2009-02-27</created><authors><author><keyname>Grehant</keyname><forenames>Xavier</forenames></author><author><keyname>Jarp</keyname><forenames>Sverre</forenames></author></authors><title>Lightweight Task Analysis for Cache-Aware Scheduling on Heterogeneous
  Clusters</title><categories>cs.DC cs.PF</categories><comments>The paper was originally published in: ISBN #: 1-60132-084-1 (a
  two-volume set) Proceedings of the 2008 International Conference on Parallel
  and Distributed Processing Techniques and Applications (PDPTA'08) Editors:
  Hamid R. Arabnia and Youngsong Mun</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel characterization of how a program stresses cache. This
characterization permits fast performance prediction in order to simulate and
assist task scheduling on heterogeneous clusters. It is based on the estimation
of stack distance probability distributions. The analysis requires the
observation of a very small subset of memory accesses, and yields a reasonable
to very accurate prediction in constant time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.4881</identifier>
 <datestamp>2012-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.4881</id><created>2009-02-27</created><updated>2012-03-03</updated><authors><author><keyname>Cornilleau</keyname><forenames>Pierre</forenames></author><author><keyname>Guerrero</keyname><forenames>Sergio</forenames></author></authors><title>Controllability and observabiliy of an artificial advection-diffusion
  problem</title><categories>math.OC cs.SY math.AP</categories><comments>20 pages, accepted for publication in MCSS. DOI:
  10.1007/s00498-012-0076-0</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study the controllability of an artificial
advection-diffusion system through the boundary. Suitable Carleman estimates
give us the observability on the adjoint system in the one dimensional case. We
also study some basic properties of our problem such as backward uniqueness and
we get an intuitive result on the control cost for vanishing viscosity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0034</identifier>
 <datestamp>2009-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0034</id><created>2009-02-28</created><authors><author><keyname>Braverman</keyname><forenames>Vladimir</forenames></author><author><keyname>Ostrovsky</keyname><forenames>Rafail</forenames></author></authors><title>Measuring Independence of Datasets</title><categories>cs.DS cs.DB cs.IR cs.PF</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A data stream model represents setting where approximating pairwise, or
$k$-wise, independence with sublinear memory is of considerable importance. In
the streaming model the joint distribution is given by a stream of $k$-tuples,
with the goal of testing correlations among the components measured over the
entire stream. In the streaming model, Indyk and McGregor (SODA 08) recently
gave exciting new results for measuring pairwise independence. The Indyk and
McGregor methods provide $\log{n}$-approximation under statistical distance
between the joint and product distributions in the streaming model. Indyk and
McGregor leave, as their main open question, the problem of improving their
$\log n$-approximation for the statistical distance metric.
  In this paper we solve the main open problem posed by of Indyk and McGregor
for the statistical distance for pairwise independence and extend this result
to any constant $k$. In particular, we present an algorithm that computes an
$(\epsilon, \delta)$-approximation of the statistical distance between the
joint and product distributions defined by a stream of $k$-tuples. Our
algorithm requires $O(({1\over \epsilon}\log({nm\over \delta}))^{(30+k)^k})$
memory and a single pass over the data stream.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0035</identifier>
 <datestamp>2009-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0035</id><created>2009-02-27</created><authors><author><keyname>Pyla</keyname><forenames>Hari K.</forenames></author><author><keyname>Ramesh</keyname><forenames>Bharath</forenames></author><author><keyname>Ribbens</keyname><forenames>Calvin J.</forenames></author><author><keyname>Varadarajan</keyname><forenames>Srinidhi</forenames></author></authors><title>ScALPEL: A Scalable Adaptive Lightweight Performance Evaluation Library
  for application performance monitoring</title><categories>cs.DC cs.PF</categories><comments>10 pages, 4 figures, 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As supercomputers continue to grow in scale and capabilities, it is becoming
increasingly difficult to isolate processor and system level causes of
performance degradation. Over the last several years, a significant number of
performance analysis and monitoring tools have been built/proposed. However,
these tools suffer from several important shortcomings, particularly in
distributed environments. In this paper we present ScALPEL, a Scalable Adaptive
Lightweight Performance Evaluation Library for application performance
monitoring at the functional level. Our approach provides several distinct
advantages. First, ScALPEL is portable across a wide variety of architectures,
and its ability to selectively monitor functions presents low run-time
overhead, enabling its use for large-scale production applications. Second, it
is run-time configurable, enabling both dynamic selection of functions to
profile as well as events of interest on a per function basis. Third, our
approach is transparent in that it requires no source code modifications.
Finally, ScALPEL is implemented as a pluggable unit by reusing existing
performance monitoring frameworks such as Perfmon and PAPI and extending them
to support both sequential and MPI applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0041</identifier>
 <datestamp>2009-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0041</id><created>2009-02-28</created><authors><author><keyname>Niennattrakul</keyname><forenames>Vit</forenames></author><author><keyname>Ratanamahatana</keyname><forenames>Chotirat Ann</forenames></author></authors><title>Learning DTW Global Constraint for Time Series Classification</title><categories>cs.AI</categories><comments>The first runner up of Workshop and Challenge on Time Series
  Classification held in conjunction with SIGKDD 2007. 8 pages, 5 figures</comments><acm-class>H.2.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  1-Nearest Neighbor with the Dynamic Time Warping (DTW) distance is one of the
most effective classifiers on time series domain. Since the global constraint
has been introduced in speech community, many global constraint models have
been proposed including Sakoe-Chiba (S-C) band, Itakura Parallelogram, and
Ratanamahatana-Keogh (R-K) band. The R-K band is a general global constraint
model that can represent any global constraints with arbitrary shape and size
effectively. However, we need a good learning algorithm to discover the most
suitable set of R-K bands, and the current R-K band learning algorithm still
suffers from an 'overfitting' phenomenon. In this paper, we propose two new
learning algorithms, i.e., band boundary extraction algorithm and iterative
learning algorithm. The band boundary extraction is calculated from the bound
of all possible warping paths in each class, and the iterative learning is
adjusted from the original R-K band learning. We also use a Silhouette index, a
well-known clustering validation technique, as a heuristic function, and the
lower bound function, LB_Keogh, to enhance the prediction speed. Twenty
datasets, from the Workshop and Challenge on Time Series Classification, held
in conjunction of the SIGKDD 2007, are used to evaluate our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0050</identifier>
 <datestamp>2014-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0050</id><created>2009-02-28</created><updated>2009-12-22</updated><authors><author><keyname>Yakaryilmaz</keyname><forenames>Abuzer</forenames></author><author><keyname>Say</keyname><forenames>A. C. Cem</forenames></author></authors><title>Succinctness of two-way probabilistic and quantum finite automata</title><categories>cs.CC</categories><comments>A new version, 21 pages, latex</comments><journal-ref>Discrete Mathematics &amp; Theoretical Computer Science, Vol 12, No 4
  (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that two-way probabilistic and quantum finite automata (2PFA's and
2QFA's) can be considerably more concise than both their one-way versions
(1PFA's and 1QFA's), and two-way nondeterministic finite automata (2NFA's). For
this purpose, we demonstrate several infinite families of regular languages
which can be recognized with some fixed probability greater than $ {1/2} $ by
just tuning the transition amplitudes of a 2QFA (and, in one case, a 2PFA) with
a constant number of states, whereas the sizes of the corresponding 1PFA's,
1QFA's and 2NFA's grow without bound. We also show that 2QFA's with mixed
states can support highly efficient probability amplification. The weakest
known model of computation where quantum computers recognize more languages
with bounded error than their classical counterparts is introduced.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0051</identifier>
 <datestamp>2009-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0051</id><created>2009-02-28</created><authors><author><keyname>Bucur</keyname><forenames>Petre</forenames></author><author><keyname>Luca</keyname><forenames>Lucian</forenames></author></authors><title>Non Linear System for a Veritable PID Substitute</title><categories>cs.DM</categories><comments>4 pages, exposed on 2nd &quot;European Conference on Computer Sience and
  Applications&quot; - XA2008, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series 6 (2008), 21-24</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper deals with a non-linear system largely used in biology, which, in
certain conditions and for particular coefficient values, becomes linear, with
a linear diagram over a large range of time. It can be used as a veritable
regulator in systems' control
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0053</identifier>
 <datestamp>2009-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0053</id><created>2009-02-28</created><authors><author><keyname>Fortis</keyname><forenames>Alexandra</forenames></author><author><keyname>Fortis</keyname><forenames>Florin</forenames></author></authors><title>Workflow Patterns in Process Modeling</title><categories>cs.SE</categories><comments>14 pages, exposed on 2nd &quot;European Conference on Computer Science &amp;
  Applications&quot; - XA2008, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series 6 (2008), 81-94</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes an introduction to one of the newest modelling methods,
an executable model based on workflows. We present the terminology for some
basic workflow patterns, as described in the Workflow Management Coalition
Terminology and Glossary.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0054</identifier>
 <datestamp>2009-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0054</id><created>2009-02-28</created><authors><author><keyname>Fortis</keyname><forenames>Alexandra</forenames></author><author><keyname>Cicortas</keyname><forenames>Alexandru</forenames></author><author><keyname>Iordan</keyname><forenames>Victoria</forenames></author></authors><title>Considerations on Resource Usage in Exceptions and Failures in Workflows</title><categories>cs.SE</categories><comments>12 pages, exposed on 2nd &quot;European Conference on Computer science and
  Applications&quot; - XA2008, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus, Comp. Sci. Series 6 (2008), 69-80</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper presents a description of some point of view of different authors
related to the failures and exceptions that appear in workflows, as a direct
consequence of unavailability of resources involved in the workflow. Each of
these interpretations is typical for a certain situation, depending on the
authors' interpretation of failures and exceptions in workflows modeling real
dynamical systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0061</identifier>
 <datestamp>2009-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0061</id><created>2009-02-28</created><authors><author><keyname>Hesse</keyname><forenames>Matthias</forenames><affiliation>UBC</affiliation></author><author><keyname>Lebrun</keyname><forenames>Jerome</forenames><affiliation>UBC</affiliation></author><author><keyname>Lampe</keyname><forenames>Lutz</forenames><affiliation>UBC</affiliation></author><author><keyname>Deneire</keyname><forenames>Luc</forenames></author></authors><title>Separable Implementation of L2-Orthogonal STC CPM with Fast Decoding</title><categories>cs.IT math.IT</categories><proxy>ccsd inria-00364952</proxy><journal-ref>IEEE International Conference on Communications (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present an alternative separable implementation of
L2-orthogonal space-time codes (STC) for continuous phase modulation (CPM). In
this approach, we split the STC CPM transmitter into a single conventional CPM
modulator and a correction filter bank. While the CPM modulator is common to
all transmit antennas, the correction filter bank applies different correction
units to each antenna. Thereby desirable code properties as orthogonality and
full diversity are achievable with just a slightly larger bandwidth demand.
This new representation has three main advantages. First, it allows to easily
generalize the orthogonality condition to any arbitrary number of transmit
antennas. Second, for a quite general set of correction functions that we
detail, it can be proved that full diversity is achieved. Third, by separating
the modulation and correction steps inside the receiver, a simpler receiver can
be designed as a bank of data independent inverse correction filters followed
by a single CPM demodulator. Therefore, in this implementation, only one
correlation filter bank for the detection of all transmitted signals is
necessary. The decoding effort grows only linearly with the number of transmit
antennas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0064</identifier>
 <datestamp>2009-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0064</id><created>2009-02-28</created><updated>2009-04-19</updated><authors><author><keyname>Yan</keyname><forenames>Xiang</forenames></author><author><keyname>Van Roy</keyname><forenames>Benjamin</forenames></author></authors><title>Manipulation Robustness of Collaborative Filtering Systems</title><categories>cs.LG cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A collaborative filtering system recommends to users products that similar
users like. Collaborative filtering systems influence purchase decisions, and
hence have become targets of manipulation by unscrupulous vendors. We provide
theoretical and empirical results demonstrating that while common nearest
neighbor algorithms, which are widely used in commercial systems, can be highly
susceptible to manipulation, two classes of collaborative filtering algorithms
which we refer to as linear and asymptotically linear are relatively robust.
These results provide guidance for the design of future collaborative filtering
systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0069</identifier>
 <datestamp>2009-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0069</id><created>2009-02-28</created><authors><author><keyname>Cayrel</keyname><forenames>Pierre-Louis</forenames></author><author><keyname>Gaborit</keyname><forenames>Philippe</forenames></author><author><keyname>Galindo</keyname><forenames>David</forenames></author><author><keyname>Girault</keyname><forenames>Marc</forenames></author></authors><title>Improved identity-based identification using correcting codes</title><categories>cs.CR</categories><comments>9 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a new identity-based identification scheme based on
error-correcting codes is proposed. Two well known code-based schemes are
combined : the signature scheme by Courtois, Finiasz and Sendrier and an
identification scheme by Stern. A proof of security for the scheme in the
Random Oracle Model is given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0094</identifier>
 <datestamp>2009-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0094</id><created>2009-03-01</created><updated>2009-12-08</updated><authors><author><keyname>Su</keyname><forenames>Yi</forenames></author><author><keyname>van der Schaar</keyname><forenames>Mihaela</forenames></author></authors><title>Dynamic Conjectures in Random Access Networks Using Bio-inspired
  Learning</title><categories>cs.GT</categories><comments>41 pages, 15 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers a conjecture-based distributed learning approach that
enables autonomous nodes to independently optimize their transmission
probabilities in random access networks. We model the interaction among
multiple self-interested nodes as a game. It is well-known that the Nash
equilibria in this game result in zero throughput for all the nodes if they
take myopic best-response, thereby leading to a network collapse. This paper
enables nodes to behave as intelligent entities which can proactively gather
information, form internal conjectures on how their competitors would react to
their actions, and update their beliefs according to their local observations.
In this way, nodes are capable to autonomously &quot;learn&quot; the behavior of their
competitors, optimize their own actions, and eventually cultivate reciprocity
in the random access network. To characterize the steady-state outcome, the
conjectural equilibrium is introduced. Inspired by the biological phenomena of
&quot;derivative action&quot; and &quot;gradient dynamics&quot;, two distributed conjecture-based
action update mechanisms are proposed to stabilize the random access network.
The sufficient conditions that guarantee the proposed conjecture-based learning
algorithms to converge are derived. Moreover, it is shown that all the
achievable operating points in the throughput region are essentially stable
conjectural equilibria corresponding to different conjectures. We investigate
how the conjectural equilibrium can be selected in heterogeneous networks and
how the proposed methods can be extended to ad-hoc networks. Simulations verify
that the system performance significantly outperforms existing protocols, such
as IEEE 802.11 DCF protocol and the PMAC protocol, in terms of throughput,
fairness, convergence, and stability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0096</identifier>
 <datestamp>2009-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0096</id><created>2009-02-28</created><updated>2009-03-14</updated><authors><author><keyname>Panda</keyname><forenames>Manoj K.</forenames></author><author><keyname>Kumar</keyname><forenames>Anurag</forenames></author></authors><title>Modeling Multi-Cell IEEE 802.11 WLANs with Application to Channel
  Assignment</title><categories>cs.NI cs.PF</categories><comments>Technical Report, Indian Institute of Science, Bangalore, 17 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide a simple and accurate analytical model for multi-cell
infrastructure IEEE 802.11 WLANs. Our model applies if the cell radius, $R$, is
much smaller than the carrier sensing range, $R_{cs}$. We argue that, the
condition $R_{cs} &gt;&gt; R$ is likely to hold in a dense deployment of Access
Points (APs) where, for every client or station (STA), there is an AP very
close to the STA such that the STA can associate with the AP at a high physical
rate. We develop a scalable cell level model for such WLANs with saturated AP
and STA queues as well as for TCP-controlled long file downloads. The accuracy
of our model is demonstrated by comparison with ns-2 simulations. We also
demonstrate how our analytical model could be applied in conjunction with a
Learning Automata (LA) algorithm for optimal channel assignment. Based on the
insights provided by our analytical model, we propose a simple decentralized
algorithm which provides static channel assignments that are Nash equilibria in
pure strategies for the objective of maximizing normalized network throughput.
Our channel assignment algorithm requires neither any explicit knowledge of the
topology nor any message passing, and provides assignments in only as many
steps as there are channels. In contrast to prior work, our approach to channel
assignment is based on the throughput metric.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0099</identifier>
 <datestamp>2009-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0099</id><created>2009-02-28</created><authors><author><keyname>Taki</keyname><forenames>Mehrdad</forenames></author><author><keyname>Lahouti</keyname><forenames>Farshad</forenames></author></authors><title>Spectral Efficiency Optimized Adaptive Transmission for Cognitive Radios
  in an Interference Channel</title><categories>cs.IT math.IT</categories><comments>accepted in ICC 2009</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this paper, we consider a primary and a cognitive user transmitting over a
wireless fading interference channel. The primary user transmits with a
constant power and utilizes an adaptive modulation and coding (AMC) scheme
satisfying a bit error rate requirement. We propose a link adaptation scheme to
maximize the average spectral efficiency of the cognitive radio, while a
minimum required spectral efficiency for the primary user is provisioned. The
resulting problem is constrained to also satisfy a bit error rate requirement
and a power constraint for the cognitive link. The AMC mode selection and power
control at the cognitive transmitter is optimized based on the scaled signal to
noise plus interference ratio feedback of both links. The problem is then cast
as a nonlinear discrete optimization problem for which a fast and efficient
suboptimum solution is presented. We also present a scheme with rate adaption
and a constant power. An important characteristic of the proposed schemes is
that no negotiation between the users is required. Comparisons with underlay
and interweave approaches to cognitive radio with adaptive transmission
demonstrate the efficiency of the proposed solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0116</identifier>
 <datestamp>2009-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0116</id><created>2009-02-28</created><authors><author><keyname>Haeupler</keyname><forenames>Bernhard</forenames></author><author><keyname>Sen</keyname><forenames>Siddhartha</forenames></author><author><keyname>Tarjan</keyname><forenames>Robert E.</forenames></author></authors><title>Heaps Simplified</title><categories>cs.DS</categories><acm-class>E.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The heap is a basic data structure used in a wide variety of applications,
including shortest path and minimum spanning tree algorithms. In this paper we
explore the design space of comparison-based, amortized-efficient heap
implementations. From a consideration of dynamic single-elimination
tournaments, we obtain the binomial queue, a classical heap implementation, in
a simple and natural way. We give four equivalent ways of representing heaps
arising from tournaments, and we obtain two new variants of binomial queues, a
one-tree version and a one-pass version. We extend the one-pass version to
support key decrease operations, obtaining the {\em rank-pairing heap}, or {\em
rp-heap}. Rank-pairing heaps combine the performance guarantees of Fibonacci
heaps with simplicity approaching that of pairing heaps. Like pairing heaps,
rank-pairing heaps consist of trees of arbitrary structure, but these trees are
combined by rank, not by list position, and rank changes, but not structural
changes, cascade during key decrease operations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0126</identifier>
 <datestamp>2009-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0126</id><created>2009-03-01</created><authors><author><keyname>He</keyname><forenames>Beihang</forenames></author></authors><title>Villager's dilemma</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With deeper study of the Game Theory, some conditions of Prisoner's Dilemma
is no longer suitable of games in real life. So we try to develop a new
model-Villager's Dilemma which has more realistic conditions to stimulate the
process of game. It is emphasize that Prisoner's Dilemma is an exception which
is lack of universality and the importance of rules in the game. And it puts
forward that to let the rule maker take part in the game and specifies game
players can stop the game as they like. This essay describes the basic model,
the villager's dilemma (VD) and put some extended use of it, and points out the
importance of rules and the effect it has on the result of the game. It briefly
describes the disadvantage of Prisoner's Dilemma and advantage Villager's
Dilemma has. It summarizes the premise and scope of application of Villager's
Dilemma, and provides theory foundation for making rules for game and forecast
of the future of the game.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0134</identifier>
 <datestamp>2010-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0134</id><created>2009-03-01</created><updated>2010-01-08</updated><authors><author><keyname>Eskandari</keyname><forenames>Ahmad Reza</forenames></author><author><keyname>Pourmohammad</keyname><forenames>Ali</forenames></author></authors><title>Recognition of Regular Shapes in Satelite Images</title><categories>cs.CV</categories><comments>This paper has been withdrawn</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn by the author ali pourmohammad.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0136</identifier>
 <datestamp>2009-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0136</id><created>2009-03-01</created><updated>2009-03-03</updated><authors><author><keyname>Porumbel</keyname><forenames>Daniel Cosmin</forenames></author></authors><title>A polynomial graph extension procedure for improving graph isomorphism
  algorithms</title><categories>cs.DS</categories><comments>A typo mistake!</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present in this short note a polynomial graph extension procedure that can
be used to improve any graph isomorphism algorithm. This construction
propagates new constraints from the isomorphism constraints of the input graphs
(denoted by $G(V,E)$ and $G'(V',E')$). Thus, information from the edge
structures of $G$ and $G'$ is &quot;hashed&quot; into the weighted edges of the extended
graphs. A bijective mapping is an isomorphism of the initial graphs if and only
if it is an isomorphism of the extended graphs. As such, the construction
enables the identification of pair of vertices $i\in V$ and $i'\in V'$ that can
not be mapped by any isomorphism $h^*:V \to V'$ (e.g. if the extended edges of
$i$ and $i'$ are different). A forbidding matrix $F$, that encodes all pairs of
incompatible mappings $(i,i')$, is constructed in order to be used by a
different algorithm. Moreover, tests on numerous graph classes show that the
matrix $F$ might leave only one compatible element for each $i \in V$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0153</identifier>
 <datestamp>2009-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0153</id><created>2009-03-01</created><authors><author><keyname>Galeas</keyname><forenames>Patricio</forenames><affiliation>University of Marburg, Germany</affiliation></author><author><keyname>Kretschmer</keyname><forenames>Ralph</forenames><affiliation>Kretschmer Software, Siegen, Germany</affiliation></author><author><keyname>Freisleben</keyname><forenames>Bernd</forenames><affiliation>University of Marburg, Germany</affiliation></author></authors><title>Document Relevance Evaluation via Term Distribution Analysis Using
  Fourier Series Expansion</title><categories>cs.IR</categories><comments>9 pages, submitted to proceedings of JCDL-2009</comments><acm-class>H.3.3</acm-class><journal-ref>Proceedings of the 2009 Joint international Conference on Digital
  Libraries (Austin, TX, USA, June 15 - 19, 2009). JCDL '09. ACM, New York, NY,
  277-284</journal-ref><doi>10.1145/1555400.1555446</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In addition to the frequency of terms in a document collection, the
distribution of terms plays an important role in determining the relevance of
documents for a given search query. In this paper, term distribution analysis
using Fourier series expansion as a novel approach for calculating an abstract
representation of term positions in a document corpus is introduced. Based on
this approach, two methods for improving the evaluation of document relevance
are proposed: (a) a function-based ranking optimization representing a user
defined document region, and (b) a query expansion technique based on
overlapping the term distributions in the top-ranked documents. Experimental
results demonstrate the effectiveness of the proposed approach in providing new
possibilities for optimizing the retrieval process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0173</identifier>
 <datestamp>2009-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0173</id><created>2009-03-01</created><authors><author><keyname>Gutfraind</keyname><forenames>Alexander</forenames></author><author><keyname>Hagberg</keyname><forenames>Aric</forenames></author><author><keyname>Pan</keyname><forenames>Feng</forenames></author></authors><title>Optimal Interdiction of Unreactive Markovian Evaders</title><categories>cs.DM cs.CC cs.DS</categories><comments>Accepted at the Sixth International Conference on integration of AI
  and OR Techniques in Constraint Programming for Combinatorial Optimization
  Problems (CPAIOR 2009)</comments><report-no>LA-UR-09-00560</report-no><acm-class>E.1; F.2; G.1.2</acm-class><journal-ref>CPAIOR 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The interdiction problem arises in a variety of areas including military
logistics, infectious disease control, and counter-terrorism. In the typical
formulation of network interdiction, the task of the interdictor is to find a
set of edges in a weighted network such that the removal of those edges would
maximally increase the cost to an evader of traveling on a path through the
network.
  Our work is motivated by cases in which the evader has incomplete information
about the network or lacks planning time or computational power, e.g. when
authorities set up roadblocks to catch bank robbers, the criminals do not know
all the roadblock locations or the best path to use for their escape.
  We introduce a model of network interdiction in which the motion of one or
more evaders is described by Markov processes and the evaders are assumed not
to react to interdiction decisions. The interdiction objective is to find an
edge set of size B, that maximizes the probability of capturing the evaders.
  We prove that similar to the standard least-cost formulation for
deterministic motion this interdiction problem is also NP-hard. But unlike that
problem our interdiction problem is submodular and the optimal solution can be
approximated within 1-1/e using a greedy algorithm. Additionally, we exploit
submodularity through a priority evaluation strategy that eliminates the linear
complexity scaling in the number of network edges and speeds up the solution by
orders of magnitude. Taken together the results bring closer the goal of
finding realistic solutions to the interdiction problem on global-scale
networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0174</identifier>
 <datestamp>2009-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0174</id><created>2009-03-01</created><updated>2009-03-10</updated><authors><author><keyname>Chen</keyname><forenames>Zhe</forenames></author><author><keyname>Wen</keyname><forenames>Dunwei</forenames></author></authors><title>Accelerating and Evaluation of Syntactic Parsing in Natural Language
  Question Answering Systems</title><categories>cs.AI cs.HC</categories><comments>7 pages, International Conference on Artificial Intelligence
  (ICAI'07)</comments><acm-class>I.2.7</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the development of Natural Language Processing (NLP), more and more
systems want to adopt NLP in User Interface Module to process user input, in
order to communicate with user in a natural way. However, this raises a speed
problem. That is, if NLP module can not process sentences in durable time
delay, users will never use the system. As a result, systems which are strict
with processing time, such as dialogue systems, web search systems, automatic
customer service systems, especially real-time systems, have to abandon NLP
module in order to get a faster system response. This paper aims to solve the
speed problem. In this paper, at first, the construction of a syntactic parser
which is based on corpus machine learning and statistics model is introduced,
and then a speed problem analysis is performed on the parser and its
algorithms. Based on the analysis, two accelerating methods, Compressed POS Set
and Syntactic Patterns Pruning, are proposed, which can effectively improve the
time efficiency of parsing in NLP module. To evaluate different parameters in
the accelerating algorithms, two new factors, PT and RT, are introduced and
explained in detail. Experiments are also completed to prove and test these
methods, which will surely contribute to the application of NLP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0194</identifier>
 <datestamp>2009-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0194</id><created>2009-03-01</created><authors><author><keyname>Rodriguez</keyname><forenames>Marko A.</forenames></author></authors><title>A Graph Analysis of the Linked Data Cloud</title><categories>cs.CY cs.AI cs.SC</categories><report-no>KRS-2009-01</report-no><acm-class>I.2.4; H.2.8</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The Linked Data community is focused on integrating Resource Description
Framework (RDF) data sets into a single unified representation known as the Web
of Data. The Web of Data can be traversed by both man and machine and shows
promise as the \textit{de facto} standard for integrating data world wide much
like the World Wide Web is the \textit{de facto} standard for integrating
documents. On February 27$^\text{th}$ of 2009, an updated Linked Data cloud
visualization was made publicly available. This visualization represents the
various RDF data sets currently in the Linked Data cloud and their interlinking
relationships. For the purposes of this article, this visual representation was
manually transformed into a directed graph and analyzed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0197</identifier>
 <datestamp>2009-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0197</id><created>2009-03-01</created><authors><author><keyname>Cleary</keyname><forenames>Sean</forenames></author><author><keyname>John</keyname><forenames>Katherine St.</forenames></author></authors><title>Rotation Distance is Fixed-Parameter Tractable</title><categories>cs.DS</categories><comments>9 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rotation distance between trees measures the number of simple operations it
takes to transform one tree into another. There are no known polynomial-time
algorithms for computing rotation distance. In the case of ordered rooted
trees, we show that the rotation distance between two ordered trees is
fixed-parameter tractable, in the parameter, k, the rotation distance. The
proof relies on the kernalization of the initial trees to trees with size
bounded by 7k.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0199</identifier>
 <datestamp>2009-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0199</id><created>2009-03-01</created><updated>2009-07-07</updated><authors><author><keyname>Cleary</keyname><forenames>Sean</forenames></author><author><keyname>John</keyname><forenames>Katherine St.</forenames></author></authors><title>A Linear-Time Approximation Algorithm for Rotation Distance</title><categories>cs.DS</categories><comments>5 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rotation distance between rooted binary trees measures the number of simple
operations it takes to transform one tree into another. There are no known
polynomial-time algorithms for computing rotation distance. We give an
efficient, linear-time approximation algorithm, which estimates the rotation
distance, within a provable factor of 2, between ordered rooted binary trees. .
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0200</identifier>
 <datestamp>2010-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0200</id><created>2009-03-01</created><authors><author><keyname>Rodriguez</keyname><forenames>Marko A.</forenames></author><author><keyname>Pepe</keyname><forenames>Alberto</forenames></author></authors><title>Faith in the Algorithm, Part 1: Beyond the Turing Test</title><categories>cs.CY cs.AI</categories><report-no>LA-UR-09-00052</report-no><journal-ref>Proceedings of the AISB Symposium on Computing and Philosophy, The
  Society for the Study of Artificial Intelligence and Simulation of Behaviour,
  Edinburgh, Scotland, April 2009.</journal-ref><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Since the Turing test was first proposed by Alan Turing in 1950, the primary
goal of artificial intelligence has been predicated on the ability for
computers to imitate human behavior. However, the majority of uses for the
computer can be said to fall outside the domain of human abilities and it is
exactly outside of this domain where computers have demonstrated their greatest
contribution to intelligence. Another goal for artificial intelligence is one
that is not predicated on human mimicry, but instead, on human amplification.
This article surveys various systems that contribute to the advancement of
human and social intelligence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0207</identifier>
 <datestamp>2009-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0207</id><created>2009-03-01</created><authors><author><keyname>Fu</keyname><forenames>Fangwen</forenames></author><author><keyname>van der Schaar</keyname><forenames>Mihaela</forenames></author></authors><title>A Systematic Framework for Dynamically Optimizing Multi-User Wireless
  Video Transmission</title><categories>cs.MM</categories><comments>36 pages, 13 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we formulate the collaborative multi-user wireless video
transmission problem as a multi-user Markov decision process (MUMDP) by
explicitly considering the users' heterogeneous video traffic characteristics,
time-varying network conditions and the resulting dynamic coupling between the
wireless users. These environment dynamics are often ignored in existing
multi-user video transmission solutions. To comply with the decentralized
nature of wireless networks, we propose to decompose the MUMDP into local MDPs
using Lagrangian relaxation. Unlike in conventional multi-user video
transmission solutions stemming from the network utility maximization
framework, the proposed decomposition enables each wireless user to
individually solve its own dynamic cross-layer optimization (i.e. the local
MDP) and the network coordinator to update the Lagrangian multipliers (i.e.
resource prices) based on not only current, but also future resource needs of
all users, such that the long-term video quality of all users is maximized.
However, solving the MUMDP requires statistical knowledge of the experienced
environment dynamics, which is often unavailable before transmission time. To
overcome this obstacle, we then propose a novel online learning algorithm,
which allows the wireless users to update their policies in multiple states
during one time slot. This is different from conventional learning solutions,
which often update one state per time slot. The proposed learning algorithm can
significantly improve the learning performance, thereby dramatically improving
the video quality experienced by the wireless users over time. Our simulation
results demonstrate the efficiency of the proposed MUMDP framework as compared
to conventional multi-user video transmission solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0211</identifier>
 <datestamp>2009-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0211</id><created>2009-03-02</created><authors><author><keyname>Bessiere</keyname><forenames>Christian</forenames></author><author><keyname>Hebrard</keyname><forenames>Emmanuel</forenames></author><author><keyname>Hnich</keyname><forenames>Brahim</forenames></author><author><keyname>Kiziltan</keyname><forenames>Zeynep</forenames></author><author><keyname>Walsh</keyname><forenames>Toby</forenames></author></authors><title>Range and Roots: Two Common Patterns for Specifying and Propagating
  Counting and Occurrence Constraints</title><categories>cs.AI</categories><comments>41 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose Range and Roots which are two common patterns useful for
specifying a wide range of counting and occurrence constraints. We design
specialised propagation algorithms for these two patterns. Counting and
occurrence constraints specified using these patterns thus directly inherit a
propagation algorithm. To illustrate the capabilities of the Range and Roots
constraints, we specify a number of global constraints taken from the
literature. Preliminary experiments demonstrate that propagating counting and
occurrence constraints using these two patterns leads to a small loss in
performance when compared to specialised global constraints and is competitive
with alternative decompositions using elementary constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0276</identifier>
 <datestamp>2009-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0276</id><created>2009-03-02</created><authors><author><keyname>Nekovee</keyname><forenames>Maziar</forenames></author></authors><title>Impact of Cognitive Radio on Future Management of Spectrum</title><categories>cs.AI cs.GT</categories><comments>Invited Paper, presented at the International Conference on Cognitive
  Radio Oriented Wireless Communications and Networks (CrownCom), May 2008,
  Singapore</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cognitive radio is a breakthrough technology which is expected to have a
profound impact on the way radio spectrum will be accessed, managed and shared
in the future. In this paper I examine some of the implications of cognitive
radio for future management of spectrum. Both a near-term view involving the
opportunistic spectrum access model and a longer-term view involving a
self-regulating dynamic spectrum access model within a society of cognitive
radios are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0279</identifier>
 <datestamp>2009-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0279</id><created>2009-03-02</created><authors><author><keyname>Dezert</keyname><forenames>Jean</forenames><affiliation>ONERA</affiliation></author><author><keyname>Smarandache</keyname><forenames>Florentin</forenames></author></authors><title>An introduction to DSmT</title><categories>cs.AI</categories><proxy>ccsd hal-00365080</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The management and combination of uncertain, imprecise, fuzzy and even
paradoxical or high conflicting sources of information has always been, and
still remains today, of primal importance for the development of reliable
modern information systems involving artificial reasoning. In this
introduction, we present a survey of our recent theory of plausible and
paradoxical reasoning, known as Dezert-Smarandache Theory (DSmT), developed for
dealing with imprecise, uncertain and conflicting sources of information. We
focus our presentation on the foundations of DSmT and on its most important
rules of combination, rather than on browsing specific applications of DSmT
available in literature. Several simple examples are given throughout this
presentation to show the efficiency and the generality of this new approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0302</identifier>
 <datestamp>2009-03-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0302</id><created>2009-03-02</created><updated>2009-03-11</updated><authors><author><keyname>Spasov</keyname><forenames>Dejan</forenames></author><author><keyname>Gusev</keyname><forenames>Marjan</forenames></author></authors><title>Asymptotic Improvement of the Binary Gilbert-Varshamov Bound on the Code
  Rate</title><categories>cs.IT math.IT</categories><comments>This submission has been withdrawn by author [arXiv admin]</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We compute the code parameters for binary linear codes obtained by greedy
constructing the parity check matrix. Then we show that these codes improve the
Gilbert-Varshamov (GV) bound on the code size and rate. This result counter
proves the conjecture on the asymptotical exactness of the binary GV bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0307</identifier>
 <datestamp>2009-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0307</id><created>2009-03-02</created><authors><author><keyname>Korada</keyname><forenames>Satish Babu</forenames></author><author><keyname>Urbanke</keyname><forenames>Rudiger</forenames></author></authors><title>Polar Codes are Optimal for Lossy Source Coding</title><categories>cs.IT math.IT</categories><comments>15 pages, submitted to Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider lossy source compression of a binary symmetric source using polar
codes and the low-complexity successive encoding algorithm. It was recently
shown by Arikan that polar codes achieve the capacity of arbitrary symmetric
binary-input discrete memoryless channels under a successive decoding strategy.
We show the equivalent result for lossy source compression, i.e., we show that
this combination achieves the rate-distortion bound for a binary symmetric
source. We further show the optimality of polar codes for various problems
including the binary Wyner-Ziv and the binary Gelfand-Pinsker problem
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0308</identifier>
 <datestamp>2009-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0308</id><created>2009-03-02</created><authors><author><keyname>Gudmundsson</keyname><forenames>Joachim</forenames></author><author><keyname>Morin</keyname><forenames>Pat</forenames></author><author><keyname>Smid</keyname><forenames>Michiel</forenames></author></authors><title>Algorithms for Marketing-Mix Optimization</title><categories>cs.CG</categories><comments>12 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Algorithms for determining quality/cost/price tradeoffs in saturated markets
are considered. A product is modeled by $d$ real-valued qualities whose sum
determines the unit cost of producing the product. This leads to the following
optimization problem: given a set of $n$ customers, each of whom has certain
minimum quality requirements and a maximum price they are willing to pay,
design a new product and select a price for that product in order to maximize
the resulting profit. An $O(n\log n)$ time algorithm is given for the case,
$d=1$, of linear products, and $O(n(\log n)^{d+1})$ time approximation
algorithms are given for products with any constant number, $d$, of qualities.
To achieve the latter result, an $O(nk^{d-1})$ bound on the complexity of an
arrangement of homothetic simplices in $\R^d$ is given, where $k$ is the
maximum number of simplices that all contain a single points.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0314</identifier>
 <datestamp>2009-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0314</id><created>2009-03-02</created><updated>2009-05-25</updated><authors><author><keyname>Schiller</keyname><forenames>Marvin</forenames></author><author><keyname>Benzmueller</keyname><forenames>Christoph</forenames></author></authors><title>Granularity-Adaptive Proof Presentation</title><categories>cs.AI</categories><comments>Extended Version. This SEKI Working-Paper refines and extends the
  following publication: Granularity-Adaptive Proof Presentation. Proceedings
  of the 14th International Conference on Artificial Intelligence in Education;
  Brighton, UK, 2009. Submitted</comments><report-no>SEKI Working-Paper SWP-2009-01</report-no><acm-class>K.3.1; I.2.3; I.2.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When mathematicians present proofs they usually adapt their explanations to
their didactic goals and to the (assumed) knowledge of their addressees. Modern
automated theorem provers, in contrast, present proofs usually at a fixed level
of detail (also called granularity). Often these presentations are neither
intended nor suitable for human use. A challenge therefore is to develop user-
and goal-adaptive proof presentation techniques that obey common mathematical
practice. We present a flexible and adaptive approach to proof presentation
that exploits machine learning techniques to extract a model of the specific
granularity of proof examples and employs this model for the automated
generation of further proofs at an adapted level of granularity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0353</identifier>
 <datestamp>2009-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0353</id><created>2009-03-02</created><authors><author><keyname>Tagiew</keyname><forenames>Rustam</forenames></author></authors><title>General Game Management Agent</title><categories>cs.GT cs.MA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The task of managing general game playing in a multi-agent system is the
problem addressed in this paper. It is considered to be done by an agent. There
are many reasons for constructing such an agent, called general game management
agent. This agent manages strategic interactions between other agents -
players, natural or also artificial. The agent records the interaction for
further benchmarking and analysis. He can also be used for a kind of restricted
communications. His behavior is defined by a game description written in a
logic-based language. The language, we present for this application, is more
expressive than the language GDL, which is already used for such purposes. Our
language can represent imperfect information and time dependent elements of a
game. Time dependent elements like delays and timeouts are of crucial
importance for interactions between players with bounded processing power like
humans. We provide examples to show the feasibility of our approach. A way for
game theoretical solving of an interaction description in our language is
considered as future work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0367</identifier>
 <datestamp>2009-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0367</id><created>2009-03-02</created><authors><author><keyname>Makarychev</keyname><forenames>Konstantin</forenames></author><author><keyname>Makarychev</keyname><forenames>Yury</forenames></author></authors><title>How to Play Unique Games on Expanders</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this note we improve a recent result by Arora, Khot, Kolla, Steurer,
Tulsiani, and Vishnoi on solving the Unique Games problem on expanders.
  Given a $(1-\varepsilon)$-satisfiable instance of Unique Games with the
constraint graph $G$, our algorithm finds an assignment satisfying at least a
$1- C \varepsilon/h_G$ fraction of all constraints if $\varepsilon &lt; c
\lambda_G$ where $h_G$ is the edge expansion of $G$, $\lambda_G$ is the second
smallest eigenvalue of the Laplacian of $G$, and $C$ and $c$ are some absolute
constants.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0391</identifier>
 <datestamp>2009-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0391</id><created>2009-03-02</created><authors><author><keyname>Arbitman</keyname><forenames>Yuriy</forenames></author><author><keyname>Naor</keyname><forenames>Moni</forenames></author><author><keyname>Segev</keyname><forenames>Gil</forenames></author></authors><title>De-amortized Cuckoo Hashing: Provable Worst-Case Performance and
  Experimental Results</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cuckoo hashing is a highly practical dynamic dictionary: it provides
amortized constant insertion time, worst case constant deletion time and lookup
time, and good memory utilization. However, with a noticeable probability
during the insertion of n elements some insertion requires \Omega(log n) time.
Whereas such an amortized guarantee may be suitable for some applications, in
other applications (such as high-performance routing) this is highly
undesirable.
  Recently, Kirsch and Mitzenmacher (Allerton '07) proposed a de-amortization
of cuckoo hashing using various queueing techniques that preserve its
attractive properties. Kirsch and Mitzenmacher demonstrated a significant
improvement to the worst case performance of cuckoo hashing via experimental
results, but they left open the problem of constructing a scheme with provable
properties.
  In this work we follow Kirsch and Mitzenmacher and present a de-amortization
of cuckoo hashing that provably guarantees constant worst case operations.
Specifically, for any sequence of polynomially many operations, with
overwhelming probability over the randomness of the initialization phase, each
operation is performed in constant time. Our theoretical analysis and
experimental results indicate that the scheme is highly efficient, and provides
a practical alternative to the only other known dynamic dictionary with such
worst case guarantees, due to Dietzfelbinger and Meyer auf der Heide (ICALP
'90).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0419</identifier>
 <datestamp>2009-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0419</id><created>2009-03-02</created><authors><author><keyname>Ghoshal</keyname><forenames>Gourab</forenames></author><author><keyname>Zlatic</keyname><forenames>Vinko</forenames></author><author><keyname>Caldarelli</keyname><forenames>Guido</forenames></author><author><keyname>Newman</keyname><forenames>M. E. J.</forenames></author></authors><title>Random hypergraphs and their applications</title><categories>physics.soc-ph cs.DL</categories><comments>11 pages, 7 figures</comments><journal-ref>Phys. Rev. E 79, 066118 (2009)</journal-ref><doi>10.1103/PhysRevE.79.066118</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the last few years we have witnessed the emergence, primarily in on-line
communities, of new types of social networks that require for their
representation more complex graph structures than have been employed in the
past. One example is the folksonomy, a tripartite structure of users,
resources, and tags -- labels collaboratively applied by the users to the
resources in order to impart meaningful structure on an otherwise
undifferentiated database. Here we propose a mathematical model of such
tripartite structures which represents them as random hypergraphs. We show that
it is possible to calculate many properties of this model exactly in the limit
of large network size and we compare the results against observations of a real
folksonomy, that of the on-line photography web site Flickr. We show that in
some cases the model matches the properties of the observed network well, while
in others there are significant differences, which we find to be attributable
to the practice of multiple tagging, i.e., the application by a single user of
many tags to one resource, or one tag to many resources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0422</identifier>
 <datestamp>2009-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0422</id><created>2009-03-02</created><authors><author><keyname>Makino</keyname><forenames>Kazuhisa</forenames></author><author><keyname>Ono</keyname><forenames>Hirotaka</forenames></author></authors><title>Deductive Inference for the Interiors and Exteriors of Horn Theories</title><categories>cs.AI cs.CC cs.DS cs.LO</categories><comments>20 pages, 1 figure, An extended abstract of this article was
  presented in Proceedings of Algorithms and Computation, 19th International
  Symposium (ISAAC 2008), Lecture Notes in Computer Science, Vol. 5369, pp.
  390-401, Springer-Verlag Berlin Heidelberg, 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate the deductive inference for the interiors and
exteriors of Horn knowledge bases, where the interiors and exteriors were
introduced by Makino and Ibaraki to study stability properties of knowledge
bases. We present a linear time algorithm for the deduction for the interiors
and show that it is co-NP-complete for the deduction for the exteriors. Under
model-based representation, we show that the deduction problem for interiors is
NP-complete while the one for exteriors is co-NP-complete. As for Horn
envelopes of the exteriors, we show that it is linearly solvable under
model-based representation, while it is co-NP-complete under formula-based
representation. We also discuss the polynomially solvable cases for all the
intractable problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0443</identifier>
 <datestamp>2013-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0443</id><created>2009-03-02</created><authors><author><keyname>Zhou</keyname><forenames>Xiangyun</forenames></author><author><keyname>Sadeghi</keyname><forenames>Parastoo</forenames></author><author><keyname>Lamahewa</keyname><forenames>Tharaka A.</forenames></author><author><keyname>Durrani</keyname><forenames>Salman</forenames></author></authors><title>Design Guidelines for Training-based MIMO Systems with Feedback</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Trans. Signal Processing</comments><journal-ref>IEEE Transactions on Signal Processing, vol. 57, no. 10, pp.
  4014-4026, Oct. 2009</journal-ref><doi>10.1109/TSP.2009.2023930</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the optimal training and data transmission strategies
for block fading multiple-input multiple-output (MIMO) systems with feedback.
We consider both the channel gain feedback (CGF) system and the channel
covariance feedback (CCF) system. Using an accurate capacity lower bound as a
figure of merit, we investigate the optimization problems on the temporal power
allocation to training and data transmission as well as the training length.
For CGF systems without feedback delay, we prove that the optimal solutions
coincide with those for non-feedback systems. Moreover, we show that these
solutions stay nearly optimal even in the presence of feedback delay. This
finding is important for practical MIMO training design. For CCF systems, the
optimal training length can be less than the number of transmit antennas, which
is verified through numerical analysis. Taking this fact into account, we
propose a simple yet near optimal transmission strategy for CCF systems, and
derive the optimal temporal power allocation over pilot and data transmission.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0445</identifier>
 <datestamp>2009-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0445</id><created>2009-03-03</created><authors><author><keyname>Aly</keyname><forenames>Salah A.</forenames></author><author><keyname>Kong</keyname><forenames>Zhenning</forenames></author><author><keyname>Soljanin</keyname><forenames>Emina</forenames></author></authors><title>Raptor Codes Based Distributed Storage Algorithms for Wireless Sensor
  Networks</title><categories>cs.IT cs.DS cs.NI math.IT</categories><comments>published in IEEE ISIT 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a distributed storage problem in a large-scale wireless sensor
network with $n$ nodes among which $k$ acquire (sense) independent data. The
goal is to disseminate the acquired information throughout the network so that
each of the $n$ sensors stores one possibly coded packet and the original $k$
data packets can be recovered later in a computationally simple way from any
$(1+\epsilon)k$ of nodes for some small $\epsilon&gt;0$. We propose two Raptor
codes based distributed storage algorithms for solving this problem. In the
first algorithm, all the sensors have the knowledge of $n$ and $k$. In the
second one, we assume that no sensor has such global information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0460</identifier>
 <datestamp>2009-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0460</id><created>2009-03-03</created><authors><author><keyname>Frisch</keyname><forenames>Alan</forenames></author><author><keyname>Hnich</keyname><forenames>Brahim</forenames></author><author><keyname>Kiziltan</keyname><forenames>Zeynep</forenames></author><author><keyname>Miguel</keyname><forenames>Ian</forenames></author><author><keyname>Walsh</keyname><forenames>Toby</forenames></author></authors><title>Filtering Algorithms for the Multiset Ordering Constraint</title><categories>cs.AI cs.DS</categories><journal-ref>Artificial Intelligence, 173 (2), 299-328, 2009</journal-ref><doi>10.1016/j.artint.2008.11.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Constraint programming (CP) has been used with great success to tackle a wide
variety of constraint satisfaction problems which are computationally
intractable in general. Global constraints are one of the important factors
behind the success of CP. In this paper, we study a new global constraint, the
multiset ordering constraint, which is shown to be useful in symmetry breaking
and searching for leximin optimal solutions in CP. We propose efficient and
effective filtering algorithms for propagating this global constraint. We show
that the algorithms are sound and complete and we discuss possible extensions.
We also consider alternative propagation methods based on existing constraints
in CP toolkits. Our experimental results on a number of benchmark problems
demonstrate that propagating the multiset ordering constraint via a dedicated
algorithm can be very beneficial.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0465</identifier>
 <datestamp>2009-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0465</id><created>2009-03-03</created><authors><author><keyname>Walsh</keyname><forenames>Toby</forenames></author></authors><title>Breaking Value Symmetry</title><categories>cs.AI</categories><comments>Proceedings of the Twenty-Third AAAI Conference on Artificial
  Intelligence</comments><acm-class>I.2.4</acm-class><journal-ref>AAAI 2008: 1585-1588</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Symmetry is an important factor in solving many constraint satisfaction
problems. One common type of symmetry is when we have symmetric values. In a
recent series of papers, we have studied methods to break value symmetries. Our
results identify computational limits on eliminating value symmetry. For
instance, we prove that pruning all symmetric values is NP-hard in general.
Nevertheless, experiments show that much value symmetry can be broken in
practice. These results may be useful to researchers in planning, scheduling
and other areas as value symmetry occurs in many different domains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0467</identifier>
 <datestamp>2009-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0467</id><created>2009-03-03</created><authors><author><keyname>Bessiere</keyname><forenames>Christian</forenames></author><author><keyname>Hebrard</keyname><forenames>Emmanuel</forenames></author><author><keyname>Hnich</keyname><forenames>Brahim</forenames></author><author><keyname>Kiziltan</keyname><forenames>Zeynep</forenames></author><author><keyname>Walsh</keyname><forenames>Toby</forenames></author></authors><title>The Parameterized Complexity of Global Constraints</title><categories>cs.AI cs.CC</categories><comments>Proceedings of the Twenty-Third AAAI Conference on Artificial
  Intelligence</comments><acm-class>I.2.4</acm-class><journal-ref>AAAI-2008, 235-240, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We argue that parameterized complexity is a useful tool with which to study
global constraints. In particular, we show that many global constraints which
are intractable to propagate completely have natural parameters which make them
fixed-parameter tractable and which are easy to compute. This tractability
tends either to be the result of a simple dynamic program or of a decomposition
which has a strong backdoor of bounded size. This strong backdoor is often a
cycle cutset. We also show that parameterized complexity can be used to study
other aspects of constraint programming like symmetry breaking. For instance,
we prove that value symmetry is fixed-parameter tractable to break in the
number of symmetries. Finally, we argue that parameterized complexity can be
used to derive results about the approximability of constraint propagation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0470</identifier>
 <datestamp>2009-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0470</id><created>2009-03-03</created><authors><author><keyname>Quimper</keyname><forenames>Claude-Guy</forenames></author><author><keyname>Walsh</keyname><forenames>Toby</forenames></author></authors><title>Decompositions of Grammar Constraints</title><categories>cs.AI cs.FL</categories><comments>Proceedings of the Twenty-Third AAAI Conference on Artificial
  Intelligence</comments><acm-class>I.2.4</acm-class><journal-ref>AAAI 2008: 1567-1570</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A wide range of constraints can be compactly specified using automata or
formal languages. In a sequence of recent papers, we have shown that an
effective means to reason with such specifications is to decompose them into
primitive constraints. We can then, for instance, use state of the art SAT
solvers and profit from their advanced features like fast unit propagation,
clause learning, and conflict-based search heuristics. This approach holds
promise for solving combinatorial problems in scheduling, rostering, and
configuration, as well as problems in more diverse areas like bioinformatics,
software testing and natural language processing. In addition, decomposition
may be an effective method to propagate other global constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0471</identifier>
 <datestamp>2009-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0471</id><created>2009-03-03</created><authors><author><keyname>Bessiere</keyname><forenames>Christian</forenames></author><author><keyname>Hebrard</keyname><forenames>Emmanuel</forenames></author><author><keyname>Hnich</keyname><forenames>Brahim</forenames></author><author><keyname>Kiziltan</keyname><forenames>Zeynep</forenames></author><author><keyname>Walsh</keyname><forenames>Toby</forenames></author></authors><title>SLIDE: A Useful Special Case of the CARDPATH Constraint</title><categories>cs.AI cs.CC</categories><comments>18th European Conference on Artificial Intelligence</comments><acm-class>I.2.4</acm-class><journal-ref>ECAI 2008: 475-479</journal-ref><doi>10.3233/978-1-58603-891-5-475</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the CardPath constraint. This ensures a given constraint holds a
number of times down a sequence of variables. We show that SLIDE, a special
case of CardPath where the slid constraint must hold always, can be used to
encode a wide range of sliding sequence constraints including CardPath itself.
We consider how to propagate SLIDE and provide a complete propagator for
CardPath. Since propagation is NP-hard in general, we identify special cases
where propagation takes polynomial time. Our experiments demonstrate that using
SLIDE to encode global constraints can be as efficient and effective as
specialised propagators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0475</identifier>
 <datestamp>2009-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0475</id><created>2009-03-03</created><authors><author><keyname>Katsirelos</keyname><forenames>George</forenames></author><author><keyname>Narodytska</keyname><forenames>Nina</forenames></author><author><keyname>Walsh</keyname><forenames>Toby</forenames></author></authors><title>Reformulating Global Grammar Constraints</title><categories>cs.AI</categories><comments>15 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An attractive mechanism to specify global constraints in rostering and other
domains is via formal languages. For instance, the Regular and Grammar
constraints specify constraints in terms of the languages accepted by an
automaton and a context-free grammar respectively. Taking advantage of the
fixed length of the constraint, we give an algorithm to transform a
context-free grammar into an automaton. We then study the use of minimization
techniques to reduce the size of such automata and speed up propagation. We
show that minimizing such automata after they have been unfolded and domains
initially reduced can give automata that are more compact than minimizing
before unfolding and reducing. Experimental results show that such
transformations can improve the size of rostering problems that we can 'model
and run'.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0479</identifier>
 <datestamp>2009-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0479</id><created>2009-03-03</created><authors><author><keyname>Katsirelos</keyname><forenames>George</forenames></author><author><keyname>Narodytska</keyname><forenames>Nina</forenames></author><author><keyname>Walsh</keyname><forenames>Toby</forenames></author></authors><title>Combining Symmetry Breaking and Global Constraints</title><categories>cs.AI</categories><comments>15 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new family of constraints which combine together lexicographical
ordering constraints for symmetry breaking with other common global
constraints. We give a general purpose propagator for this family of
constraints, and show how to improve its complexity by exploiting properties of
the included global constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0519</identifier>
 <datestamp>2009-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0519</id><created>2009-03-03</created><authors><author><keyname>Karnyanszky</keyname><forenames>Tiberiu Marius</forenames></author><author><keyname>Lacrama</keyname><forenames>Laurentiu Dan</forenames></author><author><keyname>Luca</keyname><forenames>Lucian</forenames></author><author><keyname>Iacob</keyname><forenames>Ioana</forenames></author></authors><title>Teacher's Evaluation - a Component of Quality Assessment System</title><categories>cs.CY</categories><comments>6 pages, exposed on 2nd &quot;European Conference on Computer Science &amp;
  Applications&quot; - XA2008, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series 6 (2008), 107 - 112</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the most important activities to increase the importance and the
responsibility of the higher education is the quality management, assessment
and evaluation. Starting from 2006, a national mechanism was created in Romania
and all the educational institutions have to apply a concrete algorithm to
ensure the internal evaluation, the external evaluation and, the most
important, to increase the quality of the educational process. This paper
presents the implementation of the quality assessment in &quot;Tibiscus&quot; University
of Timisoara, particularly at the Faculty of Computers and Applied Computer
Science.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0520</identifier>
 <datestamp>2009-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0520</id><created>2009-03-03</created><authors><author><keyname>Clementi</keyname><forenames>Andrea E. F.</forenames></author><author><keyname>Pasquale</keyname><forenames>Francesco</forenames></author><author><keyname>Silvestri</keyname><forenames>Riccardo</forenames></author></authors><title>MANETS: High mobility can make up for low transmission power</title><categories>cs.DM cs.PF</categories><comments>18 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a Mobile Ad-hoc NETworks (MANET) formed by &quot;n&quot; nodes that move
independently at random over a finite square region of the plane. Nodes
exchange data if they are at distance at most &quot;r&quot; within each other, where r&gt;0
is the node transmission radius. The &quot;flooding time&quot; is the number of time
steps required to broadcast a message from a source node to every node of the
network. Flooding time is an important measure of the speed of information
spreading in dynamic networks.
  We derive a nearly-tight upper bound on the flooding time which is a
decreasing function of the maximal &quot;velocity&quot; of the nodes. It turns out that,
when the node velocity is sufficiently high, even if the node transmission
radius &quot;r&quot; is far below the &quot;connectivity threshold&quot;, the flooding time does
not asymptotically depend on &quot;r&quot;. This implies that flooding can be very fast
even though every &quot;snapshot&quot; (i.e. the static random geometric graph at any
fixed time) of the MANET is fully disconnected. Data reach all nodes quickly
despite these ones use very low transmission power.
  Our result is the first analytical evidence of the fact that high, random
node mobility strongly speed-up information spreading and, at the same time,
let nodes save energy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0538</identifier>
 <datestamp>2009-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0538</id><created>2009-03-03</created><authors><author><keyname>Lacrama</keyname><forenames>Dan Laurentiu</forenames></author><author><keyname>Alexa</keyname><forenames>Florin</forenames></author><author><keyname>Balta</keyname><forenames>Adriana</forenames></author></authors><title>Real-time Texture Error Detection</title><categories>cs.CV</categories><comments>8 pages, exposed on 2nd &quot;European conference on Computer Science &amp;
  Applications&quot; - XA2008, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus, Comp. Sci. Series 6 (2008), 127-134</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper advocates an improved solution for real-time error detection of
texture errors that occurs in the production process in textile industry. The
research is focused on the mono-color products with 3D texture model (Jaquard
fabrics). This is a more difficult task than, for example, 2D multicolor
textures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0544</identifier>
 <datestamp>2009-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0544</id><created>2009-03-03</created><updated>2009-05-20</updated><authors><author><keyname>Moser</keyname><forenames>Robin A.</forenames></author><author><keyname>Tardos</keyname><forenames>G&#xe1;bor</forenames></author></authors><title>A constructive proof of the general Lovasz Local Lemma</title><categories>cs.DS cs.CC cs.DM</categories><comments>8 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Lovasz Local Lemma [EL75] is a powerful tool to non-constructively prove
the existence of combinatorial objects meeting a prescribed collection of
criteria. In his breakthrough paper [Bec91], Beck demonstrated that a
constructive variant can be given under certain more restrictive conditions.
Simplifications of his procedure and relaxations of its restrictions were
subsequently exhibited in several publications [Alo91, MR98, CS00, Mos06,
Sri08, Mos08]. In [Mos09], a constructive proof was presented that works under
negligible restrictions, formulated in terms of the Bounded Occurrence
Satisfiability problem. In the present paper, we reformulate and improve upon
these findings so as to directly apply to almost all known applications of the
general Local Lemma.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0548</identifier>
 <datestamp>2009-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0548</id><created>2009-03-03</created><updated>2009-10-27</updated><authors><author><keyname>Choo</keyname><forenames>Li-Chia</forenames></author><author><keyname>Wong</keyname><forenames>Kai-Kit</forenames></author></authors><title>On the 3-Receiver Broadcast Channel with Degraded Message Sets and
  Confidential Messages</title><categories>cs.IT math.IT</categories><comments>Revised version submiitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, bounds to the rate-equivocation region for the general
3-receiver broadcast channel (BC) with degraded message sets, are presented for
confidential messages to be kept secret from one of the receivers. This model
is more general than the 2-receiver BCs with confidential messages with an
external wiretapper, and the recently studied 3-receiver degraded BCs with
confidential messages, since in the model studied in this paper, the conditions
on the receivers are general and the wiretapper receives the common message.
Wyner's code partitioning combined with double-binning is used to show the
achievable rate tuples. Error probability analysis and equivocation calculation
are also provided. The secure coding scheme is sufficient to provide security
for the 3-receiver BC with 2 or 3 degraded message sets, for the scenarios: (i)
3 degraded message sets, where the first confidential message is sent to
receivers 1 and 2 and the second confidential message is sent to receiver 1,
(ii) 2 degraded message sets, where one confidential message is sent to
receiver 1, and (iii) 2 degraded message sets, where one confidential message
is sent to receivers 1 and 2. The proof for the outer bound is shown for the
cases where receiver 1 is more capable than the wiretap receiver 3, for the
first two scenarios. Under the condition that both receivers 1 and 2 are less
noisy than the wiretap receiver 3, the inner and outer bounds coincide, giving
the rate-equivocation region for (iii). In addition, a new outer bound for the
general 3-receiver BC with 3 degraded messages is obtained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0566</identifier>
 <datestamp>2015-03-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0566</id><created>2009-03-03</created><updated>2013-01-11</updated><authors><author><keyname>Tillich</keyname><forenames>Jean-Pierre</forenames></author><author><keyname>Zemor</keyname><forenames>Gilles</forenames></author></authors><title>Quantum LDPC codes with positive rate and minimum distance proportional
  to n^{1/2}</title><categories>cs.IT math.IT quant-ph</categories><comments>21 pages</comments><msc-class>68P30, 81P68</msc-class><journal-ref>IEEE Trans. Inform. Theory. Vol. 60, No 2, pp. 1193--1202. 2014</journal-ref><doi>10.1109/TIT.2013.2292061</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The current best asymptotic lower bound on the minimum distance of quantum
LDPC codes with fixed non-zero rate is logarithmic in the blocklength. We
propose a construction of quantum LDPC codes with fixed non-zero rate and prove
that the minimum distance grows proportionally to the square root of the
blocklength.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0571</identifier>
 <datestamp>2009-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0571</id><created>2009-03-03</created><authors><author><keyname>Rasenack</keyname><forenames>Rolf Andreas</forenames></author></authors><title>Adaptation of Black-Box Software Components</title><categories>cs.SE</categories><comments>16 pages, exposed on 2nd &quot;European Conference on Computer Science &amp;
  Applications&quot; - XA2008, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus, Comp. Sci. Series 6 (2008),153-168</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The globalization of the software market leads to crucial problems for
software companies. More competition between software companies arises and
leads to the force on companies to develop ever newer software products in ever
shortened time interval. Therefor the time to market for software systems is
shortened and obviously the product life cycle is shortened too[...]The
approach introduced here presents the novel technique together with a
supportive environment that enables developers to cope with the adaptability of
black-box software components. A supported environment will be designed that
checks the compatibility of black-box software components with the assistance
of their specifications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0572</identifier>
 <datestamp>2009-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0572</id><created>2009-03-03</created><authors><author><keyname>Karnyanszky</keyname><forenames>Tiberiu Marius</forenames></author><author><keyname>Musuroi</keyname><forenames>Corina</forenames></author><author><keyname>Karnyanszky</keyname><forenames>Carla Amira</forenames></author></authors><title>Expert Software for the Determination of Juvenile People's Obesity</title><categories>cs.CY</categories><comments>8 pages, exposed on 2nd &quot;European Conference on Computer Science and
  Applications&quot; - XA2008, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus, Comp. Sci. Series 6 (2008), 113-120</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Keeping the health condition at the juvenile population is the concern of
both the medical staff and the physical education teachers. Considering the
steady tendency of the growth of the number of the youth with excessive weight
(overweighted or obese) the intervention to combat this phenomenon must be
initiated in the early stage when this condition occurs. The screening method
for evaluating the body weight presented in this study uses a calculus program
through which, based on the input data (age, sex, weight the width of the skin
fold) an evaluation regarding each juvenile's weight and the body structure can
be done. This program can be used in schools, high schools, universities, to
signal the weight excess and to appreciate the intervention results for getting
a normal weight.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0578</identifier>
 <datestamp>2009-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0578</id><created>2009-03-03</created><authors><author><keyname>Karnyanszky</keyname><forenames>Tiberiu Marius</forenames></author><author><keyname>Selariu</keyname><forenames>Bogdan Ion</forenames></author></authors><title>About Testing the Speed of Calculating the Shortest Route</title><categories>cs.DM</categories><comments>6 pages, exposed on the 2nd &quot;European Conference on Computer Science
  &amp; Applications&quot; - XA2008, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus, Comp. Sci. Series 6 (2008), 121-126</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Applied into a various area of domains, the graph theory and its applications
allow the determination of the shortest route. The common algorithm to solve
this problem is Bellman-Kalaba, based on the matrix multiplying operation. If
the graph is very large (e.g., the dimension of the associated incidence matrix
is big) one of the main problems is to reduce the calculus time. This paper
presents a testing method able to analyze if an acceleration of the
Bellman-Kalaba is possible and able to determine the time efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0588</identifier>
 <datestamp>2009-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0588</id><created>2009-03-03</created><authors><author><keyname>Tuican</keyname><forenames>Catalin</forenames></author><author><keyname>Karnyanszky</keyname><forenames>Tiberiu Marius</forenames></author><author><keyname>Selariu</keyname><forenames>Bogdan Ioan</forenames></author></authors><title>Expert System for Quality Assessment in &quot;Tibiscus&quot; University</title><categories>cs.CY</categories><comments>10 pages, exposed on 2nd &quot;European Conference on Computer Science &amp;
  Applications&quot; - XA2008, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus, Comp. Sci. Series 6 (2008), 239-248</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The periodical evaluation of the teaching staff in &quot;Tibiscus&quot; University is
based on the specification of the Romanian Agency for Quality Assurance in
Higher Education (ARACIS), namely &quot;The quality of teaching and researching
staff: The universities must dispose of teaching staff which, as number and
functional base must be correctly allocated to the total number of students,
depending on the study domain and regarding the qualifications it must depend
on the specific of the study program and the proposed quality objectives.&quot; This
paper presents the implementation of an expert system, offering to the students
the possibility to perform the evaluation in a modern way and to the evaluation
committee a quick access to all necessary data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0595</identifier>
 <datestamp>2009-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0595</id><created>2009-03-03</created><authors><author><keyname>Shang</keyname><forenames>Xiaohu</forenames></author><author><keyname>Chen</keyname><forenames>Biao</forenames></author><author><keyname>Kramer</keyname><forenames>Gerhard</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Noisy-interference Sum-rate Capacity of Parallel Gaussian Interference
  Channels</title><categories>cs.IT math.IT</categories><comments>32 pages, 8 figures, submitted to IEEE trans. on Information Theory
  in Feb</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The sum-rate capacity of the parallel Gaussian interference channel is shown
to be achieved by independent transmission across sub-channels and treating
interference as noise in each sub-channel if the channel coefficients and power
constraints satisfy a certain condition. The condition requires the
interference to be weak, a situation commonly encountered in, e.g., digital
subscriber line transmission. The optimal power allocation is characterized by
using the concavity of sum-rate capacity as a function of the power
constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0604</identifier>
 <datestamp>2009-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0604</id><created>2009-03-03</created><authors><author><keyname>Lotfinezhad</keyname><forenames>Mahdi</forenames></author><author><keyname>Liang</keyname><forenames>Ben</forenames></author><author><keyname>Sousa</keyname><forenames>Elvino S.</forenames></author></authors><title>On Stability Region and Delay Performance of Linear-Memory Randomized
  Scheduling for Time-Varying Networks</title><categories>cs.NI cs.IT math.IT</categories><comments>Long version of preprint to appear in the IEEE Transactions on
  Networking</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Throughput optimal scheduling policies in general require the solution of a
complex and often NP-hard optimization problem. Related literature has shown
that in the context of time-varying channels, randomized scheduling policies
can be employed to reduce the complexity of the optimization problem but at the
expense of a memory requirement that is exponential in the number of data
flows. In this paper, we consider a Linear-Memory Randomized Scheduling Policy
(LM-RSP) that is based on a pick-and-compare principle in a time-varying
network with $N$ one-hop data flows. For general ergodic channel processes, we
study the performance of LM-RSP in terms of its stability region and average
delay. Specifically, we show that LM-RSP can stabilize a fraction of the
capacity region. Our analysis characterizes this fraction as well as the
average delay as a function of channel variations and the efficiency of LM-RSP
in choosing an appropriate schedule vector. Applying these results to a class
of Markovian channels, we provide explicit results on the stability region and
delay performance of LM-RSP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0625</identifier>
 <datestamp>2009-03-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0625</id><created>2009-03-03</created><authors><author><keyname>Cohen</keyname><forenames>Edith</forenames></author><author><keyname>Kaplan</keyname><forenames>Haim</forenames></author></authors><title>Leveraging Discarded Samples for Tighter Estimation of Multiple-Set
  Aggregates</title><categories>cs.DB cs.IR</categories><comments>16 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many datasets such as market basket data, text or hypertext documents, and
sensor observations recorded in different locations or time periods, are
modeled as a collection of sets over a ground set of keys. We are interested in
basic aggregates such as the weight or selectivity of keys that satisfy some
selection predicate defined over keys' attributes and membership in particular
sets. This general formulation includes basic aggregates such as the Jaccard
coefficient, Hamming distance, and association rules.
  On massive data sets, exact computation can be inefficient or infeasible.
Sketches based on coordinated random samples are classic summaries that support
approximate query processing.
  Queries are resolved by generating a sketch (sample) of the union of sets
used in the predicate from the sketches these sets and then applying an
estimator to this union-sketch.
  We derive novel tighter (unbiased) estimators that leverage sampled keys that
are present in the union of applicable sketches but excluded from the union
sketch. We establish analytically that our estimators dominate estimators
applied to the union-sketch for {\em all queries and data sets}. Empirical
evaluation on synthetic and real data reveals that on typical applications we
can expect a 25%-4 fold reduction in estimation error.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0650</identifier>
 <datestamp>2009-03-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0650</id><created>2009-03-03</created><authors><author><keyname>Ak&#xe7;akaya</keyname><forenames>Mehmet</forenames></author><author><keyname>Park</keyname><forenames>Jinsoo</forenames></author><author><keyname>Tarokh</keyname><forenames>Vahid</forenames></author></authors><title>Compressive Sensing Using Low Density Frames</title><categories>cs.IT math.IT stat.CO</categories><comments>11 pages, 6 figures, Submitted to IEEE Transactions on Signal
  Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the compressive sensing of a sparse or compressible signal ${\bf
x} \in {\mathbb R}^M$. We explicitly construct a class of measurement matrices,
referred to as the low density frames, and develop decoding algorithms that
produce an accurate estimate $\hat{\bf x}$ even in the presence of additive
noise. Low density frames are sparse matrices and have small storage
requirements. Our decoding algorithms for these frames have $O(M)$ complexity.
Simulation results are provided, demonstrating that our approach significantly
outperforms state-of-the-art recovery algorithms for numerous cases of
interest. In particular, for Gaussian sparse signals and Gaussian noise, we are
within 2 dB range of the theoretical lower bound in most cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0666</identifier>
 <datestamp>2009-03-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0666</id><created>2009-03-03</created><authors><author><keyname>McKay</keyname><forenames>Matthew R.</forenames></author><author><keyname>Collings</keyname><forenames>Iain B.</forenames></author><author><keyname>Tulino</keyname><forenames>Antonia M.</forenames></author></authors><title>Achievable Sum Rate of MIMO MMSE Recievers: A General Analytic Framework</title><categories>cs.IT math.IT</categories><comments>to appear in IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the achievable sum rate of multiple-input
multiple-output (MIMO) wireless systems employing linear minimum mean-squared
error (MMSE) receivers. We present a new analytic framework which unveils an
interesting connection between the achievable sum rate with MMSE receivers and
the ergodic mutual information achieved with optimal receivers. This simple but
powerful result enables the vast prior literature on ergodic MIMO mutual
information to be directly applied to the analysis of MMSE receivers. The
framework is particularized to various Rayleigh and Rician channel scenarios to
yield new exact closed-form expressions for the achievable sum rate, as well as
simplified expressions in the asymptotic regimes of high and low signal to
noise ratios. These expressions lead to the discovery of key insights into the
performance of MIMO MMSE receivers under practical channel conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0673</identifier>
 <datestamp>2009-03-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0673</id><created>2009-03-03</created><authors><author><keyname>McKilliam</keyname><forenames>Robby G.</forenames></author><author><keyname>Smith</keyname><forenames>Warren D.</forenames></author><author><keyname>Clarkson</keyname><forenames>I. Vaughan L.</forenames></author></authors><title>Linear-time nearest point algorithms for Coxeter lattices</title><categories>cs.IT math.IT math.NT</categories><comments>submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Coxeter lattices, which we denote $A_{n/m}$, are a family of lattices
containing many of the important lattices in low dimensions. This includes
$A_n$, $E_7$, $E_8$ and their duals $A_n^*$, $E_7^*$ and $E_8^*$. We consider
the problem of finding a nearest point in a Coxeter lattice. We describe two
new algorithms, one with worst case arithmetic complexity $O(n\log{n})$ and the
other with worst case complexity O(n) where $n$ is the dimension of the
lattice. We show that for the particular lattices $A_n$ and $A_n^*$ the
algorithms reduce to simple nearest point algorithms that already exist in the
literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0682</identifier>
 <datestamp>2009-03-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0682</id><created>2009-03-04</created><authors><author><keyname>Wong</keyname><forenames>Raymond Chi-Wing</forenames></author><author><keyname>Fu</keyname><forenames>Ada Wai-Chee</forenames></author><author><keyname>Liu</keyname><forenames>Jia</forenames></author><author><keyname>Wang</keyname><forenames>Ke</forenames></author><author><keyname>Xu</keyname><forenames>Yabo</forenames></author></authors><title>Preserving Individual Privacy in Serial Data Publishing</title><categories>cs.DB cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While previous works on privacy-preserving serial data publishing consider
the scenario where sensitive values may persist over multiple data releases, we
find that no previous work has sufficient protection provided for sensitive
values that can change over time, which should be the more common case. In this
work we propose to study the privacy guarantee for such transient sensitive
values, which we call the global guarantee. We formally define the problem for
achieving this guarantee and derive some theoretical properties for this
problem. We show that the anonymized group sizes used in the data anonymization
is a key factor in protecting individual privacy in serial publication. We
propose two strategies for anonymization targeting at minimizing the average
group size and the maximum group size. Finally, we conduct experiments on a
medical dataset to show that our method is highly efficient and also produces
published data of very high utility.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0694</identifier>
 <datestamp>2009-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0694</id><created>2009-03-04</created><updated>2009-10-04</updated><authors><author><keyname>Briscoe</keyname><forenames>Gerard</forenames></author><author><keyname>Marinos</keyname><forenames>Alexandros</forenames></author></authors><title>Digital Ecosystems in the Clouds: Towards Community Cloud Computing</title><categories>cs.NI cs.DC cs.SE</categories><comments>7 pages, 3 figures, IEEE Digital EcosystemS and Technologies DEST
  (2009)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cloud Computing is rising fast, with its data centres growing at an
unprecedented rate. However, this has come with concerns of privacy, efficiency
at the expense of resilience, and environmental sustainability, because of the
dependence on Cloud vendors such as Google, Amazon, and Microsoft. Community
Cloud Computing makes use of the principles of Digital Ecosystems to provide a
paradigm for Clouds in the community, offering an alternative architecture for
the use cases of Cloud Computing. It is more technically challenging to deal
with issues of distributed computing, such as latency, differential resource
management, and additional security requirements. However, these are not
insurmountable challenges, and with the need to retain control over our digital
lives and the potential environmental consequences, it is a challenge we must
pursue.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0695</identifier>
 <datestamp>2009-03-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0695</id><created>2009-03-03</created><authors><author><keyname>Haim</keyname><forenames>Shai</forenames></author><author><keyname>Walsh</keyname><forenames>Toby</forenames></author></authors><title>Online Estimation of SAT Solving Runtime</title><categories>cs.AI</categories><comments>6 pages, 3 figures. Proc. of the 11th International Conf. on Theory
  and Applications of Satisfiability Testing, Guangzhou, China, May 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an online method for estimating the cost of solving SAT problems.
Modern SAT solvers present several challenges to estimate search cost including
non-chronological backtracking, learning and restarts. Our method uses a linear
model trained on data gathered at the start of search. We show the
effectiveness of this method using random and structured problems. We
demonstrate that predictions made in early restarts can be used to improve
later predictions. We also show that we can use such cost estimations to select
a solver from a portfolio.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0696</identifier>
 <datestamp>2011-06-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0696</id><created>2009-03-03</created><updated>2011-06-06</updated><authors><author><keyname>Owen</keyname><forenames>Megan</forenames></author></authors><title>Computing Geodesic Distances in Tree Space</title><categories>math.CO cs.CG cs.DM math.MG q-bio.PE</categories><comments>24 pages, 7 figures; v2: substantially revised for clarity</comments><msc-class>68R05 (primary), 92D15 (secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present two algorithms for computing the geodesic distance between
phylogenetic trees in tree space, as introduced by Billera, Holmes, and
Vogtmann (2001). We show that the possible combinatorial types of shortest
paths between two trees can be compactly represented by a partially ordered
set. We calculate the shortest distance along each candidate path by converting
the problem into one of finding the shortest path through a certain region of
Euclidean space. In particular, we show there is a linear time algorithm for
finding the shortest path between a point in the all positive orthant and a
point in the all negative orthant of R^k contained in the subspace of R^k
consisting of all orthants with the first i coordinates non-positive and the
remaining coordinates non-negative for 0 &lt;= i &lt;= k.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0710</identifier>
 <datestamp>2009-03-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0710</id><created>2009-03-04</created><authors><author><keyname>Benoit</keyname><forenames>Anne</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes / LIP Laboratoire de l'Informatique du Parall&#xe9;lisme</affiliation></author><author><keyname>Casanova</keyname><forenames>Henri</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes / LIP Laboratoire de l'Informatique du Parall&#xe9;lisme</affiliation></author><author><keyname>Rehn-Sonigo</keyname><forenames>Veronika</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes / LIP Laboratoire de l'Informatique du Parall&#xe9;lisme</affiliation></author><author><keyname>Robert</keyname><forenames>Yves</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes / LIP Laboratoire de l'Informatique du Parall&#xe9;lisme</affiliation></author></authors><title>Resource Allocation for Multiple Concurrent In-Network Stream-Processing
  Applications</title><categories>cs.DC</categories><proxy>ccsd inria-00365514</proxy><report-no>RR-6864</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the operator mapping problem for in-network
stream-processing applications. In-network stream-processing amounts to
applying one or more trees of operators in steady-state, to multiple data
objects that are continuously updated at different locations in the network.
The goal is to compute some final data at some desired rate. Different operator
trees may share common subtrees. Therefore, it may be possible to reuse some
intermediate results in different application trees. The first contribution of
this work is to provide complexity results for different instances of the basic
problem, as well as integer linear program formulations of various problem
instances. The second second contribution is the design of several
polynomial-time heuristics. One of the primary objectives of these heuristics
is to reuse intermediate results shared by multiple applications. Our
quantitative comparisons of these heuristics in simulation demonstrates the
importance of choosing appropriate processors for operator mapping. It also
allow us to identify a heuristic that achieves good results in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0730</identifier>
 <datestamp>2009-03-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0730</id><created>2009-03-04</created><authors><author><keyname>Stinga</keyname><forenames>Delia Sabina</forenames></author></authors><title>Grid Technologies</title><categories>cs.DC</categories><comments>6 pages, exposed on 2nd &quot;European Conference on Computer Science &amp;
  Applications&quot; - XA2008, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus, Comp. Sci. Series 6 (2008), 181-186</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper contains the most important aspects of computing grids. Grid
computing allows high performance distributed systems to act as a single
computer. An overview of grids structure and techniques is given in order to
understand the way grids work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0735</identifier>
 <datestamp>2009-03-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0735</id><created>2009-03-04</created><authors><author><keyname>Broekens</keyname><forenames>Joost</forenames></author></authors><title>Modeling the Experience of Emotion</title><categories>cs.AI cs.HC cs.RO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Affective computing has proven to be a viable field of research comprised of
a large number of multidisciplinary researchers resulting in work that is
widely published. The majority of this work consists of computational models of
emotion recognition, computational modeling of causal factors of emotion and
emotion expression through rendered and robotic faces. A smaller part is
concerned with modeling the effects of emotion, formal modeling of cognitive
appraisal theory and models of emergent emotions. Part of the motivation for
affective computing as a field is to better understand emotional processes
through computational modeling. One of the four major topics in affective
computing is computers that have emotions (the others are recognizing,
expressing and understanding emotions). A critical and neglected aspect of
having emotions is the experience of emotion (Barrett, Mesquita, Ochsner, and
Gross, 2007): what does the content of an emotional episode look like, how does
this content change over time and when do we call the episode emotional. Few
modeling efforts have these topics as primary focus. The launch of a journal on
synthetic emotions should motivate research initiatives in this direction, and
this research should have a measurable impact on emotion research in
psychology. I show that a good way to do so is to investigate the psychological
core of what an emotion is: an experience. I present ideas on how the
experience of emotion could be modeled and provide evidence that several
computational models of emotion are already addressing the issue.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0737</identifier>
 <datestamp>2009-03-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0737</id><created>2009-03-04</created><authors><author><keyname>Ilea</keyname><forenames>Daniela</forenames></author></authors><title>C# - Connecting a Mobile Application to Oracle Server via Web Services</title><categories>cs.NI</categories><comments>6 pages, exposed on 2nd &quot;European Comference on Computer Science and
  Applications&quot; - XA2008, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus, Comp. Sci. Series 6 (2008), 101-106</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article is focused on mobile development using Visual Studio 2005, web
services and their connection to Oracle server, willing to help programmers to
realize simple and useful mobile applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0742</identifier>
 <datestamp>2015-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0742</id><created>2009-03-04</created><updated>2009-08-01</updated><authors><author><keyname>Bagchi</keyname><forenames>Amitabha</forenames></author><author><keyname>Madan</keyname><forenames>Adit</forenames></author><author><keyname>Premi</keyname><forenames>Achal</forenames></author></authors><title>Hierarchical neighbor graphs: A low stretch connected structure for
  points in Euclidean space</title><categories>cs.NI</categories><acm-class>C.2.1; G.3</acm-class><journal-ref>Ad Hoc Sens. Wirel. Ne 26(1-4):171-191, 2015</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce hierarchical neighbor graphs, a new architecture for connecting
ad hoc wireless nodes distributed in a plane. The structure has the flavor of
hierarchical clustering and requires only local knowledge and minimal
computation at each node to be formed and repaired. Hence, it is a suitable
interconnection model for an ad hoc wireless sensor network. The structure is
able to use energy efficiently by reorganizing dynamically when the battery
power of heavily utilized nodes degrades and is able to achieve throughput,
energy efficiency and network lifetimes that compare favorably with the leading
proposals for data collation in sensor networks such as LEACH (Heinzelman et.
al., 2002). Additionally, hierarchical neighbor graphs have low power stretch
i.e. the power required to connect nodes through the network is a small factor
higher than the power required to connect them directly. Our structure also
compares favorably to mathematical structures proposed for connecting points in
a plane e.g. nearest-neighbor graphs (Ballister et. al., 2005), $\theta$-graphs
(Ruppert and Seidel, 1991), in that it has expected constant degree and does
not require any significant computation or global information to be formed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0748</identifier>
 <datestamp>2010-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0748</id><created>2009-03-04</created><updated>2009-10-14</updated><authors><author><keyname>Trisetyarso</keyname><forenames>Agung</forenames></author><author><keyname>Van Meter</keyname><forenames>Rodney</forenames></author></authors><title>Circuit Design for A Measurement-Based Quantum Carry-Lookahead Adder</title><categories>quant-ph cs.AR</categories><comments>28 pages and 14 figures</comments><journal-ref>Int. J. Quantum Inf. 8, 843 (2010)</journal-ref><doi>10.1142/S0219749910006496</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the design and evaluation of a quantum carry-lookahead adder
(QCLA) using measurement-based quantum computation (MBQC), called MBQCLA. QCLA
was originally designed for an abstract, concurrent architecture supporting
long-distance communication, but most realistic architectures heavily constrain
communication distances. The quantum carry-lookahead adder is faster than a
quantum ripple-carry adder; QCLA has logarithmic depth while ripple adders have
linear depth. MBQCLA utilizes MBQC's ability to transfer quantum states in unit
time to accelerate addition. MBQCLA breaks the latency limit of addition
circuits in nearest neighbor-only architectures : compared to the $\Theta(n)$
limit on circuit depth for linear nearest-neighbor architectures, it can reach
$\Theta(log n)$ depth. MBQCLA is an order of magnitude faster than a
ripple-carry adder when adding registers longer than 100 qubits, but requires a
cluster state that is an order of magnitude larger. The cluster state resources
can be classified as computation and communication; for the unoptimized form,
$\approx$ 88 % of the resources are used for communication. Hand optimization
of horizontal communication costs results in a $\approx$ 12% reduction in
spatial resources for the in-place MBQCLA circuit. For comparison, a graph
state quantum carry-lookahead adder (GSQCLA) uses only $\approx$ 9 % of the
spatial resources of the MBQCLA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0786</identifier>
 <datestamp>2009-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0786</id><created>2009-03-04</created><updated>2009-03-13</updated><authors><author><keyname>Loria-Saenz</keyname><forenames>Carlos</forenames></author></authors><title>On Requirements for Programming Exercises from an E-learning Perspective</title><categories>cs.AI</categories><comments>ii + 31 pages</comments><report-no>SEKI Working-Paper SWP-2008-01</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we deal with the question of modeling programming exercises for
novices pointing to an e-learning scenario. Our purpose is to identify basic
requirements, raise some key questions and propose potential answers from a
conceptual perspective. Presented as a general picture, we hypothetically
situate our work in a general context where e-learning instructional material
needs to be adapted to form part of an introductory Computer Science (CS)
e-learning course at the CS1-level. Meant is a potential course which aims at
improving novices skills and knowledge on the essentials of programming by
using e-learning based approaches in connection (at least conceptually) with a
general host framework like Activemath (www.activemath.org). Our elaboration
covers contextual and, particularly, cognitive elements preparing the terrain
for eventual research stages in a derived project, as indicated. We concentrate
our main efforts on reasoning mechanisms about exercise complexity that can
eventually offer tool support for the task of exercise authoring. We base our
requirements analysis on our own perception of the exercise subsystem provided
by Activemath especially within the domain reasoner area. We enrich the
analysis by bringing to the discussion several relevant contextual elements
from the CS1 courses, its definition and implementation. Concerning cognitive
models and exercises, we build upon the principles of Bloom's Taxonomy as a
relatively standardized basis and use them as a framework for study and
analysis of complexity in basic programming exercises. Our analysis includes
requirements for the domain reasoner which are necessary for the exercise
analysis. We propose for such a purpose a three-layered conceptual model
considering exercise evaluation, programming and metaprogramming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0802</identifier>
 <datestamp>2009-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0802</id><created>2009-03-04</created><updated>2009-05-29</updated><authors><author><keyname>Kuesters</keyname><forenames>Ralf</forenames></author><author><keyname>Truderung</keyname><forenames>Tomasz</forenames></author></authors><title>An Epistemic Approach to Coercion-Resistance for Electronic Voting
  Protocols</title><categories>cs.CR</categories><comments>An extended version of a paper from IEEE Symposium on Security and
  Privacy (S&amp;P) 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Coercion resistance is an important and one of the most intricate security
requirements of electronic voting protocols. Several definitions of coercion
resistance have been proposed in the literature, including definitions based on
symbolic models. However, existing definitions in such models are rather
restricted in their scope and quite complex.
  In this paper, we therefore propose a new definition of coercion resistance
in a symbolic setting, based on an epistemic approach. Our definition is
relatively simple and intuitive. It allows for a fine-grained formulation of
coercion resistance and can be stated independently of a specific, symbolic
protocol and adversary model. As a proof of concept, we apply our definition to
three voting protocols. In particular, we carry out the first rigorous analysis
of the recently proposed Civitas system. We precisely identify those conditions
under which this system guarantees coercion resistance or fails to be coercion
resistant. We also analyze protocols proposed by Lee et al. and Okamoto.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0829</identifier>
 <datestamp>2009-03-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0829</id><created>2009-03-04</created><authors><author><keyname>Horvat</keyname><forenames>Marko</forenames></author><author><keyname>Popovic</keyname><forenames>Sinisa</forenames></author><author><keyname>Bogunovic</keyname><forenames>Nikola</forenames></author><author><keyname>Cosic</keyname><forenames>Kresimir</forenames></author></authors><title>Tagging multimedia stimuli with ontologies</title><categories>cs.AI</categories><comments>7 pages, 7 figures, 1 table, submitted for publication (MIPRO 2009)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Successful management of emotional stimuli is a pivotal issue concerning
Affective Computing (AC) and the related research. As a subfield of Artificial
Intelligence, AC is concerned not only with the design of computer systems and
the accompanying hardware that can recognize, interpret, and process human
emotions, but also with the development of systems that can trigger human
emotional response in an ordered and controlled manner. This requires the
maximum attainable precision and efficiency in the extraction of data from
emotionally annotated databases While these databases do use keywords or tags
for description of the semantic content, they do not provide either the
necessary flexibility or leverage needed to efficiently extract the pertinent
emotional content. Therefore, to this extent we propose an introduction of
ontologies as a new paradigm for description of emotionally annotated data. The
ability to select and sequence data based on their semantic attributes is vital
for any study involving metadata, semantics and ontological sorting like the
Semantic Web or the Social Semantic Desktop, and the approach described in the
paper facilitates reuse in these areas as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0843</identifier>
 <datestamp>2009-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0843</id><created>2009-03-04</created><updated>2009-03-06</updated><authors><author><keyname>Manquinho</keyname><forenames>Vasco</forenames></author><author><keyname>Marques-Silva</keyname><forenames>Joao</forenames></author><author><keyname>Planes</keyname><forenames>Jordi</forenames></author></authors><title>Algorithms for Weighted Boolean Optimization</title><categories>cs.AI cs.LO</categories><comments>14 pages, 2 algorithms, 3 tables, 1 figure</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The Pseudo-Boolean Optimization (PBO) and Maximum Satisfiability (MaxSAT)
problems are natural optimization extensions of Boolean Satisfiability (SAT).
  In the recent past, different algorithms have been proposed for PBO and for
MaxSAT, despite the existence of straightforward mappings from PBO to MaxSAT
and vice-versa. This papers proposes Weighted Boolean Optimization (WBO), a new
unified framework that aggregates and extends PBO and MaxSAT. In addition, the
paper proposes a new unsatisfiability-based algorithm for WBO, based on recent
unsatisfiability-based algorithms for MaxSAT. Besides standard MaxSAT, the new
algorithm can also be used to solve weighted MaxSAT and PBO, handling
pseudo-Boolean constraints either natively or by translation to clausal form.
Experimental results illustrate that unsatisfiability-based algorithms for
MaxSAT can be orders of magnitude more efficient than existing dedicated
algorithms. Finally, the paper illustrates how other algorithms for either PBO
or MaxSAT can be extended to WBO.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0889</identifier>
 <datestamp>2009-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0889</id><created>2009-03-04</created><authors><author><keyname>Doty</keyname><forenames>David</forenames></author><author><keyname>Patitz</keyname><forenames>Matthew J.</forenames></author></authors><title>A Domain-Specific Language for Programming in the Tile Assembly Model</title><categories>cs.SE cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a domain-specific language (DSL) for creating sets of tile types
for simulations of the abstract Tile Assembly Model. The language defines
objects known as tile templates, which represent related groups of tiles, and a
small number of basic operations on tile templates that help to eliminate the
error-prone drudgery of enumerating such tile types manually or with low-level
constructs of general-purpose programming languages. The language is
implemented as a class library in Python (a so-called internal DSL), but is
presented independently of Python or object-oriented programming, with emphasis
on supporting the creation of visual editing tools for programmatically
creating large sets of complex tile types without needing to write a program.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0914</identifier>
 <datestamp>2009-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0914</id><created>2009-03-05</created><authors><author><keyname>Munoz</keyname><forenames>Freddy</forenames><affiliation>INRIA - Irisa</affiliation></author><author><keyname>Baudry</keyname><forenames>Benoit</forenames><affiliation>INRIA - Irisa</affiliation></author></authors><title>Artificial table testing dynamically adaptive systems</title><categories>cs.SE</categories><proxy>ccsd inria-00365874</proxy><report-no>RR-6866</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dynamically Adaptive Systems (DAS) are systems that modify their behavior and
structure in response to changes in their surrounding environment. Critical
mission systems increasingly incorporate adaptation and response to the
environment; examples include disaster relief and space exploration systems.
These systems can be decomposed in two parts: the adaptation policy that
specifies how the system must react according to the environmental changes and
the set of possible variants to reconfigure the system. A major challenge for
testing these systems is the combinatorial explosions of variants and
envi-ronment conditions to which the system must react. In this paper we focus
on testing the adaption policy and propose a strategy for the selection of
envi-ronmental variations that can reveal faults in the policy. Artificial
Shaking Table Testing (ASTT) is a strategy inspired by shaking table testing
(STT), a technique widely used in civil engineering to evaluate building's
structural re-sistance to seismic events. ASTT makes use of artificial
earthquakes that simu-late violent changes in the environmental conditions and
stresses the system adaptation capability. We model the generation of
artificial earthquakes as a search problem in which the goal is to optimize
different types of envi-ronmental variations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0938</identifier>
 <datestamp>2009-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0938</id><created>2009-03-05</created><authors><author><keyname>Cohen</keyname><forenames>Nathann</forenames></author><author><keyname>Fomin</keyname><forenames>Fedor V.</forenames></author><author><keyname>Gutin</keyname><forenames>Gregory</forenames></author><author><keyname>Kim</keyname><forenames>Eun Jung</forenames></author><author><keyname>Saurabh</keyname><forenames>Saket</forenames></author><author><keyname>Yeo</keyname><forenames>Anders</forenames></author></authors><title>Algorithm for Finding $k$-Vertex Out-trees and its Application to
  $k$-Internal Out-branching Problem</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An out-tree $T$ is an oriented tree with only one vertex of in-degree zero. A
vertex $x$ of $T$ is internal if its out-degree is positive. We design
randomized and deterministic algorithms for deciding whether an input digraph
contains a given out-tree with $k$ vertices. The algorithms are of runtime
$O^*(5.704^k)$ and $O^*(5.704^{k(1+o(1))})$, respectively. We apply the
deterministic algorithm to obtain a deterministic algorithm of runtime
$O^*(c^k)$, where $c$ is a constant, for deciding whether an input digraph
contains a spanning out-tree with at least $k$ internal vertices. This answers
in affirmative a question of Gutin, Razgon and Kim (Proc. AAIM'08).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0952</identifier>
 <datestamp>2009-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0952</id><created>2009-03-05</created><authors><author><keyname>Gotsulenko</keyname><forenames>V. V.</forenames></author><author><keyname>Gaponova</keyname><forenames>L. A.</forenames></author><author><keyname>Kogut</keyname><forenames>P. I.</forenames></author></authors><title>Definition of Strange Attractor in Benard problem for Generalized
  Couette Cell</title><categories>nlin.CD cs.CE</categories><comments>6 pages, exposed on 2nd &quot;European Conference on Computer Science and
  Applications&quot; - XA2008, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus, Comp. Sci. Series 6 (2008), 95-100</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For movements of the viscous continuous flow in generalized Couette cell the
dynamic system describing the central limiting variety is received.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0960</identifier>
 <datestamp>2009-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0960</id><created>2009-03-05</created><authors><author><keyname>Fintineanu</keyname><forenames>Georgiana Petruta</forenames></author></authors><title>Directing RF Terminals Using TELNET Applications</title><categories>cs.OH</categories><comments>8 pages, exposed on 2nd &quot;European Conference on Computer Sicence &amp;
  Applications&quot; - XA2008, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus, Comp. Sci. Series 6 (2008), 61-68</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The present study aims to emphasize the way in which the TELNET protocol for
directing the mobile terminals is used and works. The paper is structured in
three parts: the first two parts are a theoretic presentation of the TELNET
protocol, respectively of the mobile terminals. The third part contains an
application of the way in which a mobile terminal can be programmed using the
TELNET protocol.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0962</identifier>
 <datestamp>2009-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0962</id><created>2009-03-05</created><authors><author><keyname>Mada</keyname><forenames>Leonard</forenames></author></authors><title>Hospital Acquired Infections: Advantages of a Computerized Surveillance</title><categories>cs.DM</categories><comments>10 pages, exposed on 2nd &quot;European Conference on Computer Science &amp;
  Applications&quot; - XA2008, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus, Comp. Sci. Series 6 (2008), 135-144</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To asses the advantages of a computerized surveillance system to detect
Healthcare-Associated Infections (HAI). All HAI reported to the Timis County
branch of the Romanian National Health Insurance and the Public Health
Authority during the year 2007 were collected and assessed for validity
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0992</identifier>
 <datestamp>2009-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0992</id><created>2009-03-05</created><updated>2009-06-23</updated><authors><author><keyname>Codat</keyname><forenames>Diana Sophia</forenames></author></authors><title>L'entreprise franco-roumaine face au Internet</title><categories>cs.CY</categories><comments>6 pages, exposed on 2nd &quot;European conference on Computer Science &amp;
  Applications&quot; - XA2008, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series 6 (2008), 25-30</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The main goal of the present work is to analyze the activity of the French
companies from Romania related to the increasing use of the information and
communication technology in the productive field. The convergent assembly of
information and communication technologies and the process of economic
globalization have led to a profound transformation of the economic activity.
The present paper is part of a series of studies made on the French firms from
Romania between 2007 and 2008.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1002</identifier>
 <datestamp>2009-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1002</id><created>2009-03-05</created><authors><author><keyname>Razak</keyname><forenames>Saquib</forenames></author><author><keyname>Kolar</keyname><forenames>Vinay</forenames></author><author><keyname>Abu-Ghazaleh</keyname><forenames>Nael B.</forenames></author><author><keyname>Harras</keyname><forenames>Khaled A.</forenames></author></authors><title>How do Wireless Chains Behave? The Impact of MAC Interactions</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a Multi-hop Wireless Networks (MHWN), packets are routed between source
and destination using a chain of intermediate nodes; chains are a fundamental
communication structure in MHWNs whose behavior must be understood to enable
building effective protocols. The behavior of chains is determined by a number
of complex and interdependent processes that arise as the sources of different
chain hops compete to transmit their packets on the shared medium. In this
paper, we show that MAC level interactions play the primary role in determining
the behavior of chains. We evaluate the types of chains that occur based on the
MAC interactions between different links using realistic propagation and packet
forwarding models. We discover that the presence of destructive interactions,
due to different forms of hidden terminals, does not impact the throughput of
an isolated chain significantly. However, due to the increased number of
retransmissions required, the amount of bandwidth consumed is significantly
higher in chains exhibiting destructive interactions, substantially influencing
the overall network performance. These results are validated by testbed
experiments. We finally study how different types of chains interfere with each
other and discover that well behaved chains in terms of self-interference are
more resilient to interference from other chains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1017</identifier>
 <datestamp>2009-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1017</id><created>2009-03-05</created><authors><author><keyname>Schwab</keyname><forenames>Emil</forenames></author></authors><title>On the Category of Partial Bijections</title><categories>cs.DM</categories><comments>8 pages, exposed on 2nd &quot;European Conference on Computer Science &amp;
  Applications&quot; - XA2008, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series 6 (2008), 173-180</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Categories of partial functions have become increasingly important
principally because of their applications in theoretical computer science. In
this note we prove that the category of partial bijections between sets as an
inverse-Baer*-category with closed projections and in which the idempotent
split is an exact category. Finally the Noether isomorphism theorems are given
for this exact category.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1022</identifier>
 <datestamp>2009-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1022</id><created>2009-03-05</created><updated>2009-03-09</updated><authors><author><keyname>Fletcher</keyname><forenames>Alyson K.</forenames></author><author><keyname>Rangan</keyname><forenames>Sundeep</forenames></author><author><keyname>Goyal</keyname><forenames>Vivek K</forenames></author></authors><title>On-Off Random Access Channels: A Compressed Sensing Framework</title><categories>cs.IT math.IT</categories><comments>18 pages, 5 figures; addition of inadvertently omitted support
  information and acknowledgments</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers a simple on-off random multiple access channel, where n
users communicate simultaneously to a single receiver over m degrees of
freedom. Each user transmits with probability lambda, where typically lambda n
&lt; m &lt;&lt; n, and the receiver must detect which users transmitted. We show that
when the codebook has i.i.d. Gaussian entries, detecting which users
transmitted is mathematically equivalent to a certain sparsity detection
problem considered in compressed sensing. Using recent sparsity results, we
derive upper and lower bounds on the capacities of these channels. We show that
common sparsity detection algorithms, such as lasso and orthogonal matching
pursuit (OMP), can be used as tractable multiuser detection schemes and have
significantly better performance than single-user detection. These methods do
achieve some near-far resistance but--at high signal-to-noise ratios
(SNRs)--may achieve capacities far below optimal maximum likelihood detection.
We then present a new algorithm, called sequential OMP, that illustrates that
iterative detection combined with power ordering or power shaping can
significantly improve the high SNR performance. Sequential OMP is analogous to
successive interference cancellation in the classic multiple access channel.
Our results thereby provide insight into the roles of power control and
multiuser detection on random-access signalling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1032</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1032</id><created>2009-03-05</created><updated>2009-04-24</updated><authors><author><keyname>Raza</keyname><forenames>Mohammad</forenames></author><author><keyname>Gardner</keyname><forenames>Philippa</forenames></author></authors><title>Footprints in Local Reasoning</title><categories>cs.SE cs.LO</categories><comments>LMCS 2009 (FOSSACS 2008 special issue)</comments><acm-class>D.2.4; F.3.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 5, Issue 2 (April 24,
  2009) lmcs:1118</journal-ref><doi>10.2168/LMCS-5(2:4)2009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Local reasoning about programs exploits the natural local behaviour common in
programs by focussing on the footprint - that part of the resource accessed by
the program. We address the problem of formally characterising and analysing
the footprint notion for abstract local functions introduced by Calcagno, O
Hearn and Yang. With our definition, we prove that the footprints are the only
essential elements required for a complete specification of a local function.
We formalise the notion of small specifications in local reasoning and show
that for well-founded resource models, a smallest specification always exists
that only includes the footprints, and also present results for the
non-well-founded case. Finally, we use this theory of footprints to investigate
the conditions under which the footprints correspond to the smallest safe
states. We present a new model of RAM in which, unlike the standard model, the
footprints of every program correspond to the smallest safe states, and we also
identify a general condition on the primitive commands of a programming
language which guarantees this property for arbitrary models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1033</identifier>
 <datestamp>2009-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1033</id><created>2009-03-05</created><authors><author><keyname>Bernal</keyname><forenames>Jose Joaquin</forenames></author><author><keyname>del Rio</keyname><forenames>Angel</forenames></author><author><keyname>Simon</keyname><forenames>Juan Jacobo</forenames></author></authors><title>Group code structures on affine-invariant codes</title><categories>cs.IT math.GR math.IT</categories><comments>7 pages</comments><msc-class>94B05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A group code structure of a linear code is a description of the code as
one-sided or two-sided ideal of a group algebra of a finite group. In these
realizations, the group algebra is identified with the ambient space, and the
group elements with the coordinates of the ambient space. It is well known that
every affine-invariant code of length $p^m$, with $p$ prime, can be realized as
an ideal of the group algebra $\F\I$, where $\I$ is the underlying additive
group of the field with $p^m$ elements. In this paper we describe all the group
code structures of an affine-invariant code of length $p^m$ in terms of a
family of maps from $\I$ to the group of automorphisms of $\I$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1059</identifier>
 <datestamp>2009-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1059</id><created>2009-03-05</created><authors><author><keyname>Karnyanszky</keyname><forenames>Tiberiu Marius</forenames></author></authors><title>Home Heating Systems Design using PHP and MySQL Databases</title><categories>cs.DB</categories><comments>8 pages (121-128), 5th &quot;Actualities and Perspectives in Hard and
  Soft&quot;, 2007</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series 5 (2007), 121-128</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents the use of a computer application based on a MySQL
database, managed by PHP programs, allowing the selection of a heating device
using coefficient-based calculus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1061</identifier>
 <datestamp>2009-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1061</id><created>2009-03-05</created><authors><author><keyname>Crista</keyname><forenames>Ovidiu</forenames></author><author><keyname>Karnyanszky</keyname><forenames>Tiberiu Marius</forenames></author></authors><title>Application for Evaluation of the Professional Competencies of the
  Teaching Staff</title><categories>cs.CY</categories><comments>6 pages (71-76), 5th &quot;Actualities and Perspectives in Hard and Soft&quot;,
  2007</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series 5 (2007), 71-76</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The goal of the presented application is to offer a full support for
universities in retrieving the feedback from their students with regard to
their teachers. This is the main reason we described it in this paper. To build
this application the following tools have been used: Microsoft Notepad 5.1 (to
make the source files), Adobe Photoshop CS3 (to make the background image) and
Adobe Flash Media Encoder 8 (to render the video clips).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1095</identifier>
 <datestamp>2014-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1095</id><created>2009-03-05</created><updated>2009-03-20</updated><authors><author><keyname>Burke</keyname><forenames>Edmund K.</forenames></author><author><keyname>Marecek</keyname><forenames>Jakub</forenames></author><author><keyname>Parkes</keyname><forenames>Andrew J.</forenames></author><author><keyname>Rudova</keyname><forenames>Hana</forenames></author></authors><title>Decomposition, Reformulation, and Diving in University Course
  Timetabling</title><categories>cs.DS cs.AI</categories><comments>45 pages, 7 figures. Improved typesetting of figures and tables</comments><report-no>NOTTCS-TR-2008-02</report-no><acm-class>G.2.3; I.2.8; F.2.2</acm-class><journal-ref>Computers and Operations Research (2010) 37(3), 582-597</journal-ref><doi>10.1016/j.cor.2009.02.023</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many real-life optimisation problems, there are multiple interacting
components in a solution. For example, different components might specify
assignments to different kinds of resource. Often, each component is associated
with different sets of soft constraints, and so with different measures of soft
constraint violation. The goal is then to minimise a linear combination of such
measures. This paper studies an approach to such problems, which can be thought
of as multiphase exploitation of multiple objective-/value-restricted
submodels. In this approach, only one computationally difficult component of a
problem and the associated subset of objectives is considered at first. This
produces partial solutions, which define interesting neighbourhoods in the
search space of the complete problem. Often, it is possible to pick the initial
component so that variable aggregation can be performed at the first stage, and
the neighbourhoods to be explored next are guaranteed to contain feasible
solutions. Using integer programming, it is then easy to implement heuristics
producing solutions with bounds on their quality.
  Our study is performed on a university course timetabling problem used in the
2007 International Timetabling Competition, also known as the Udine Course
Timetabling Problem. In the proposed heuristic, an objective-restricted
neighbourhood generator produces assignments of periods to events, with
decreasing numbers of violations of two period-related soft constraints. Those
are relaxed into assignments of events to days, which define neighbourhoods
that are easier to search with respect to all four soft constraints. Integer
programming formulations for all subproblems are given and evaluated using ILOG
CPLEX 11. The wider applicability of this approach is analysed and discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1125</identifier>
 <datestamp>2009-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1125</id><created>2009-03-05</created><authors><author><keyname>Gilad-Bachrach</keyname><forenames>Ran</forenames></author><author><keyname>Bar-Hillel</keyname><forenames>Aharon</forenames></author><author><keyname>Ein-Dor</keyname><forenames>Liat</forenames></author></authors><title>Efficient Human Computation</title><categories>cs.LG</categories><comments>8 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Collecting large labeled data sets is a laborious and expensive task, whose
scaling up requires division of the labeling workload between many teachers.
When the number of classes is large, miscorrespondences between the labels
given by the different teachers are likely to occur, which, in the extreme
case, may reach total inconsistency. In this paper we describe how globally
consistent labels can be obtained, despite the absence of teacher coordination,
and discuss the possible efficiency of this process in terms of human labor. We
define a notion of label efficiency, measuring the ratio between the number of
globally consistent labels obtained and the number of labels provided by
distributed teachers. We show that the efficiency depends critically on the
ratio alpha between the number of data instances seen by a single teacher, and
the number of classes. We suggest several algorithms for the distributed
labeling problem, and analyze their efficiency as a function of alpha. In
addition, we provide an upper bound on label efficiency for the case of
completely uncoordinated teachers, and show that efficiency approaches 0 as the
ratio between the number of labels each teacher provides and the number of
classes drops (i.e. alpha goes to 0).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1136</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1136</id><created>2009-03-05</created><authors><author><keyname>Walsh</keyname><forenames>Toby</forenames></author></authors><title>Symmetry Breaking Using Value Precedence</title><categories>cs.AI cs.CC</categories><comments>17th European Conference on Artificial Intelligence</comments><acm-class>I.2.4</acm-class><journal-ref>ECAI 2006, 168-172</journal-ref><doi>10.1088/1126-6708/2009/06/075</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a comprehensive study of the use of value precedence constraints
to break value symmetry. We first give a simple encoding of value precedence
into ternary constraints that is both efficient and effective at breaking
symmetry. We then extend value precedence to deal with a number of
generalizations like wreath value and partial interchangeability. We also show
that value precedence is closely related to lexicographical ordering. Finally,
we consider the interaction between value precedence and symmetry breaking
constraints for variable symmetries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1137</identifier>
 <datestamp>2012-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1137</id><created>2009-03-05</created><authors><author><keyname>Walsh</keyname><forenames>Toby</forenames></author></authors><title>Complexity of Terminating Preference Elicitation</title><categories>cs.AI cs.CC cs.MA</categories><comments>7th International Joint Conference on Autonomous Agents and
  Multiagent Systems (AAMAS 2008)</comments><acm-class>I.2.4</acm-class><journal-ref>AAMAS 2008: 967-974</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Complexity theory is a useful tool to study computational issues surrounding
the elicitation of preferences, as well as the strategic manipulation of
elections aggregating together preferences of multiple agents. We study here
the complexity of determining when we can terminate eliciting preferences, and
prove that the complexity depends on the elicitation strategy. We show, for
instance, that it may be better from a computational perspective to elicit all
preferences from one agent at a time than to elicit individual preferences from
multiple agents. We also study the connection between the strategic
manipulation of an election and preference elicitation. We show that what we
can manipulate affects the computational complexity of manipulation. In
particular, we prove that there are voting rules which are easy to manipulate
if we can change all of an agent's vote, but computationally intractable if we
can change only some of their preferences. This suggests that, as with
preference elicitation, a fine-grained view of manipulation may be informative.
Finally, we study the connection between predicting the winner of an election
and preference elicitation. Based on this connection, we identify a voting rule
where it is computationally difficult to decide the probability of a candidate
winning given a probability distribution over the votes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1139</identifier>
 <datestamp>2009-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1139</id><created>2009-03-05</created><authors><author><keyname>Bessiere</keyname><forenames>Christian</forenames></author><author><keyname>Hebrard</keyname><forenames>Emmanuel</forenames></author><author><keyname>Hnich</keyname><forenames>Brahim</forenames></author><author><keyname>Walsh</keyname><forenames>Toby</forenames></author></authors><title>The Complexity of Reasoning with Global Constraints</title><categories>cs.AI cs.CC</categories><acm-class>I.2.4</acm-class><journal-ref>Constraints 12(2): 239-259 (2007)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Constraint propagation is one of the techniques central to the success of
constraint programming. To reduce search, fast algorithms associated with each
constraint prune the domains of variables. With global (or non-binary)
constraints, the cost of such propagation may be much greater than the
quadratic cost for binary constraints. We therefore study the computational
complexity of reasoning with global constraints. We first characterise a number
of important questions related to constraint propagation. We show that such
questions are intractable in general, and identify dependencies between the
tractability and intractability of the different questions. We then demonstrate
how the tools of computational complexity can be used in the design and
analysis of specific global constraints. In particular, we illustrate how
computational complexity can be used to determine when a lesser level of local
consistency should be enforced, when constraints can be safely generalized,
when decomposing constraints will reduce the amount of pruning, and when
combining constraints is tractable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1146</identifier>
 <datestamp>2009-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1146</id><created>2009-03-05</created><authors><author><keyname>Walsh</keyname><forenames>Toby</forenames></author></authors><title>Breaking Value Symmetry</title><categories>cs.AI cs.CC</categories><comments>Principles and Practice of Constraint Programming - CP 2007, 13th
  International Conference, CP 2007, Providence, RI, USA, September 23-27,
  2007, Proceedings. Lecture Notes in Computer Science 4741 Springer 2007, ISBN
  978-3-540-74969-</comments><report-no>COMIC-2007-008</report-no><acm-class>I.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One common type of symmetry is when values are symmetric. For example, if we
are assigning colours (values) to nodes (variables) in a graph colouring
problem then we can uniformly interchange the colours throughout a colouring.
For a problem with value symmetries, all symmetric solutions can be eliminated
in polynomial time. However, as we show here, both static and dynamic methods
to deal with symmetry have computational limitations. With static methods,
pruning all symmetric values is NP-hard in general. With dynamic methods, we
can take exponential time on problems which static methods solve without
search.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1147</identifier>
 <datestamp>2012-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1147</id><created>2009-03-05</created><authors><author><keyname>Takenaga</keyname><forenames>Yasuhiko</forenames></author><author><keyname>Walsh</keyname><forenames>Toby</forenames></author></authors><title>Tetravex is NP-complete</title><categories>cs.CC cs.AI</categories><acm-class>F.1.3</acm-class><journal-ref>Inf. Process. Lett. 99(5): 171-174 (2006)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tetravex is a widely played one person computer game in which you are given
$n^2$ unit tiles, each edge of which is labelled with a number. The objective
is to place each tile within a $n$ by $n$ square such that all neighbouring
edges are labelled with an identical number. Unfortunately, playing Tetravex is
computationally hard. More precisely, we prove that deciding if there is a
tiling of the Tetravex board is NP-complete. Deciding where to place the tiles
is therefore NP-hard. This may help to explain why Tetravex is a good puzzle.
This result compliments a number of similar results for one person games
involving tiling. For example, NP-completeness results have been shown for: the
offline version of Tetris, KPlumber (which involves rotating tiles containing
drawings of pipes to make a connected network), and shortest sliding puzzle
problems. It raises a number of open questions. For example, is the infinite
version Turing-complete? How do we generate Tetravex problems which are truly
puzzling as random NP-complete problems are often surprising easy to solve? Can
we observe phase transition behaviour? What about the complexity of the problem
when it is guaranteed to have an unique solution? How do we generate puzzles
with unique solutions?
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1150</identifier>
 <datestamp>2009-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1150</id><created>2009-03-05</created><authors><author><keyname>Tarim</keyname><forenames>S. Armagan</forenames></author><author><keyname>Manandhar</keyname><forenames>Suresh</forenames></author><author><keyname>Walsh</keyname><forenames>Toby</forenames></author></authors><title>Stochastic Constraint Programming: A Scenario-Based Approach</title><categories>cs.AI</categories><acm-class>I.2.4</acm-class><journal-ref>Constraints 11(1): 53-80 (2006)</journal-ref><doi>10.1007/s10601-006-6849-7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To model combinatorial decision problems involving uncertainty and
probability, we introduce scenario based stochastic constraint programming.
Stochastic constraint programs contain both decision variables, which we can
set, and stochastic variables, which follow a discrete probability
distribution. We provide a semantics for stochastic constraint programs based
on scenario trees. Using this semantics, we can compile stochastic constraint
programs down into conventional (non-stochastic) constraint programs. This
allows us to exploit the full power of existing constraint solvers. We have
implemented this framework for decision making under uncertainty in stochastic
OPL, a language which is based on the OPL constraint modelling language
[Hentenryck et al., 1999]. To illustrate the potential of this framework, we
model a wide range of problems in areas as diverse as portfolio
diversification, agricultural planning and production/inventory management.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1152</identifier>
 <datestamp>2009-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1152</id><created>2009-03-05</created><authors><author><keyname>Walsh</keyname><forenames>Toby</forenames></author></authors><title>Stochastic Constraint Programming</title><categories>cs.AI</categories><comments>Proceedings of the 15th Eureopean Conference on Artificial
  Intelligence</comments><acm-class>I.2.4</acm-class><journal-ref>ECAI 2002: 111-115</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To model combinatorial decision problems involving uncertainty and
probability, we introduce stochastic constraint programming. Stochastic
constraint programs contain both decision variables (which we can set) and
stochastic variables (which follow a probability distribution). They combine
together the best features of traditional constraint satisfaction, stochastic
integer programming, and stochastic satisfiability. We give a semantics for
stochastic constraint programs, and propose a number of complete algorithms and
approximation procedures. Finally, we discuss a number of extensions of
stochastic constraint programming to relax various assumptions like the
independence between stochastic variables, and compare with other approaches
for decision making under uncertainty.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1157</identifier>
 <datestamp>2009-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1157</id><created>2009-03-06</created><authors><author><keyname>Jacquet</keyname><forenames>Philippe</forenames></author><author><keyname>Mans</keyname><forenames>Bernard</forenames></author><author><keyname>Rodolakis</keyname><forenames>Georgios</forenames></author></authors><title>Information Propagation Speed in Mobile and Delay Tolerant Networks</title><categories>cs.IT cs.NI math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The goal of this paper is to increase our understanding of the fundamental
performance limits of mobile and Delay Tolerant Networks (DTNs), where
end-to-end multi-hop paths may not exist and communication routes may only be
available through time and mobility. We use analytical tools to derive generic
theoretical upper bounds for the information propagation speed in large scale
mobile and intermittently connected networks. In other words, we upper-bound
the optimal performance, in terms of delay, that can be achieved using any
routing algorithm. We then show how our analysis can be applied to specific
mobility and graph models to obtain specific analytical estimates. In
particular, in two-dimensional networks, when nodes move at a maximum speed $v$
and their density $\nu$ is small (the network is sparse and surely
disconnected), we prove that the information propagation speed is upper bounded
by ($1+O(\nu^2))v$ in the random way-point model, while it is upper bounded by
$O(\sqrt{\nu v} v)$ for other mobility models (random walk, Brownian motion).
We also present simulations that confirm the validity of the bounds in these
scenarios. Finally, we generalize our results to one-dimensional and
three-dimensional networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1183</identifier>
 <datestamp>2009-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1183</id><created>2009-03-06</created><authors><author><keyname>Da</keyname><forenames>Shan</forenames><affiliation>Shanghai Jiao Tong University</affiliation></author><author><keyname>Xiaoying</keyname><forenames>Gan</forenames><affiliation>Shanghai Jiao Tong University</affiliation></author><author><keyname>Hsiao-Hwa</keyname><forenames>Chen</forenames><affiliation>National Cheng Kung University</affiliation></author><author><keyname>Liang</keyname><forenames>Qian</forenames><affiliation>Shanghai Jiao Tong University</affiliation></author></authors><title>Fast Cycle Frequency Domain Feature Detection for Cognitive Radio
  Systems</title><categories>cs.IT math.IT</categories><comments>4 pages, 3 figures, submitted to Crowncom 2009</comments><msc-class>94A05, 94A13</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In cognitive radio systems, one of the main requirements is to detect the
presence of the primary users' transmission, especially in weak signal cases.
Cyclostationary detection is always used to solve weak signal detection,
however, the computational complexity prevents it from wide usage. In this
paper, a fast cycle frequency domain feature detection algorithm has been
proposed, in which only feature frequency with significant cyclic signature is
considered for a certain modulation mode. Simulation results show that the
proposed algorithm has remarkable performance gain than energy detection when
supporting real-time detection with low computational complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1196</identifier>
 <datestamp>2009-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1196</id><created>2009-03-06</created><authors><author><keyname>Bethke</keyname><forenames>Inge</forenames></author><author><keyname>Rodenburg</keyname><forenames>Piet</forenames></author><author><keyname>Sevenster</keyname><forenames>Arjen</forenames></author></authors><title>The structure of finite meadows</title><categories>cs.LO</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A meadow is a commutative ring with a total inverse operator satisfying
0^{-1}=0. We show that the class of finite meadows is the closure of the class
of Galois fields under finite products. As a corollary, we obtain a unique
representation of minimal finite meadows in terms of finite prime fields.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1204</identifier>
 <datestamp>2010-05-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1204</id><created>2009-03-06</created><authors><author><keyname>Vlasov</keyname><forenames>Alexander Yu.</forenames></author></authors><title>Quantum Information Science and Nanotechnology</title><categories>quant-ph cs.OH</categories><comments>LaTeX, 12pt, 6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this note is touched upon an application of quantum information science
(QIS) in nanotechnology area. The laws of quantum mechanics may be very
important for nano-scale objects. A problem with simulating of quantum systems
is well known and quantum computer was initially suggested by R. Feynman just
as the way to overcome such difficulties. Mathematical methods developed in QIS
also may be applied for description of nano-devices. Few illustrative examples
are mentioned and they may be related with so-called fourth generation of
nanotechnology products.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1291</identifier>
 <datestamp>2014-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1291</id><created>2009-03-06</created><updated>2014-10-06</updated><authors><author><keyname>Ambainis</keyname><forenames>Andris</forenames></author><author><keyname>Childs</keyname><forenames>Andrew M.</forenames></author><author><keyname>Gall</keyname><forenames>Fran&#xe7;ois Le</forenames></author><author><keyname>Tani</keyname><forenames>Seiichiro</forenames></author></authors><title>The quantum query complexity of certification</title><categories>quant-ph cs.CC</categories><comments>8 pages; Updated to reflect changes in final journal version and to
  point out that the main result only applies for k&gt;1</comments><journal-ref>Quantum Information and Computation 10, 181-188 (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the quantum query complexity of finding a certificate for a
d-regular, k-level balanced NAND formula. Up to logarithmic factors, we show
that the query complexity is Theta(d^{(k+1)/2}) for 0-certificates, and
Theta(d^{k/2}) for 1-certificates. In particular, this shows that the
zero-error quantum query complexity of evaluating such formulas is
O(d^{(k+1)/2}) (again neglecting a logarithmic factor). Our lower bound relies
on the fact that the quantum adversary method obeys a direct sum theorem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1337</identifier>
 <datestamp>2011-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1337</id><created>2009-03-07</created><authors><author><keyname>Carli</keyname><forenames>Ruggero</forenames></author><author><keyname>Fagnani</keyname><forenames>Fabio</forenames></author><author><keyname>Frasca</keyname><forenames>Paolo</forenames></author><author><keyname>Zampieri</keyname><forenames>Sandro</forenames></author></authors><title>Efficient quantization for average consensus</title><categories>math.OC cs.SY</categories><comments>Based on material from the third author's PhD thesis, and on a 2007
  conference paper</comments><msc-class>93A14, 93D21</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an algorithm which solves exponentially fast the average
consensus problem on strongly connected network of digital links. The algorithm
is based on an efficient zooming-in/zooming-out quantization scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1352</identifier>
 <datestamp>2009-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1352</id><created>2009-03-07</created><updated>2009-11-07</updated><authors><author><keyname>Bergstra</keyname><forenames>Jan A.</forenames></author><author><keyname>Ponse</keyname><forenames>Alban</forenames></author></authors><title>An Instruction Sequence Semigroup with Involutive Anti-Automorphisms</title><categories>cs.PL math.RA</categories><comments>36 pages, 1 table</comments><acm-class>D.3.1; F.3.2; I.1.1</acm-class><journal-ref>Scientific Annals of Computer Science, 19:57-92, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce an algebra of instruction sequences by presenting a semigroup C
in which programs can be represented without directional bias: in terms of the
next instruction to be executed, C has both forward and backward instructions
and a C-expression can be interpreted starting from any instruction. We provide
equations for thread extraction, i.e., C's program semantics. Then we consider
thread extraction compatible (anti-)homomorphisms and (anti-)automorphisms.
Finally we discuss some expressiveness results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1374</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1374</id><created>2009-03-07</created><updated>2009-04-27</updated><authors><author><keyname>Intrigila</keyname><forenames>Benedetto</forenames></author><author><keyname>Statman</keyname><forenames>Richard</forenames></author></authors><title>The Omega Rule is $\mathbf{\Pi_{1}^{1}}$-Complete in the
  $\lambda\beta$-Calculus</title><categories>cs.LO</categories><acm-class>F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 5, Issue 2 (April 27,
  2009) lmcs:1147</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a functional calculus, the so called \Omega-rule states that if two terms
P and Q applied to any closed term &lt;i&gt;N&lt;/i&gt; return the same value (i.e. PN =
QN), then they are equal (i.e. P = Q holds). As it is well known, in the
\lambda\beta-calculus the \Omega-rule does not hold, even when the \eta-rule
(weak extensionality) is added to the calculus. A long-standing problem of H.
Barendregt (1975) concerns the determination of the logical power of the
\Omega-rule when added to the \lambda\beta-calculus. In this paper we solve the
problem, by showing that the resulting theory is \Pi\_{1}^{1}-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1379</identifier>
 <datestamp>2009-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1379</id><created>2009-03-07</created><authors><author><keyname>Jindal</keyname><forenames>Nihar</forenames></author><author><keyname>Lozano</keyname><forenames>Angel</forenames></author></authors><title>Optimum Pilot Overhead in Wireless Communication: A Unified Treatment of
  Continuous and Block-Fading Channels</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Trans. Wireless Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The optimization of the pilot overhead in single-user wireless fading
channels is investigated, and the dependence of this overhead on various system
parameters of interest (e.g., fading rate, signal-to-noise ratio) is
quantified. The achievable pilot-based spectral efficiency is expanded with
respect to the fading rate about the no-fading point, which leads to an
accurate order expansion for the pilot overhead. This expansion identifies that
the pilot overhead, as well as the spectral efficiency penalty with respect to
a reference system with genie-aided CSI (channel state information) at the
receiver, depend on the square root of the normalized Doppler frequency.
Furthermore, it is shown that the widely-used block fading model is only a
special case of more accurate continuous fading models in terms of the
achievable pilot-based spectral efficiency, and that the overhead optimization
for multiantenna systems is effectively the same as for single-antenna systems
with the normalized Doppler frequency multiplied by the number of transmit
antennas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1386</identifier>
 <datestamp>2009-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1386</id><created>2009-03-07</created><authors><author><keyname>Vecchiola</keyname><forenames>Christian</forenames></author><author><keyname>Kirley</keyname><forenames>Michael</forenames></author><author><keyname>Buyya</keyname><forenames>Rajkumar</forenames></author></authors><title>Multi-Objective Problem Solving With Offspring on Enterprise Clouds</title><categories>cs.DC</categories><comments>8 pages</comments><acm-class>C.2.4</acm-class><journal-ref>Proceedings of the 10th International Conference on
  High-Performance Computing in Asia-Pacific Region (HPC Asia 2009), March 2~5,
  2009, Kaohsiung, Taiwan</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a distributed implementation of a network based
multi-objective evolutionary algorithm, called EMO, by using Offspring. Network
based evolutionary algorithms have proven to be effective for multi-objective
problem solving. They feature a network of connections between individuals that
drives the evolution of the algorithm. Unfortunately, they require large
populations to be effective and a distributed implementation can leverage the
computation time. Most of the existing frameworks are limited to providing
solutions that are basic or specific to a given algorithm. Our Offspring
framework is a plug-in based software environment that allows rapid deployment
and execution of evolutionary algorithms on distributed computing environments
such as Enterprise Clouds. Its features and benefits are presented by
describing the distributed implementation of EMO.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1388</identifier>
 <datestamp>2009-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1388</id><created>2009-03-07</created><authors><author><keyname>Jin</keyname><forenames>Chao</forenames></author><author><keyname>Gubbi</keyname><forenames>Jayavardhana</forenames></author><author><keyname>Buyya</keyname><forenames>Rajkumar</forenames></author><author><keyname>Palaniswami</keyname><forenames>Marimuthu</forenames></author></authors><title>Jeeva: Enterprise Grid-enabled Web Portal for Protein Secondary
  Structure Prediction</title><categories>cs.DC</categories><comments>7 pages</comments><acm-class>C.2.4</acm-class><journal-ref>Proceedings of the 16th International Conference on Advanced
  Computing and Communication (ADCOM 2008, IEEE Press, New York, USA), Dec.
  14-17, 2008, Chennai, India</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a Grid portal for protein secondary structure prediction
developed by using services of Aneka, a .NET-based enterprise Grid technology.
The portal is used by research scientists to discover new prediction structures
in a parallel manner. An SVM (Support Vector Machine)-based prediction
algorithm is used with 64 sample protein sequences as a case study to
demonstrate the potential of enterprise Grids.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1389</identifier>
 <datestamp>2009-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1389</id><created>2009-03-07</created><authors><author><keyname>Garg</keyname><forenames>Saurabh</forenames></author><author><keyname>Konugurthi</keyname><forenames>Pramod</forenames></author><author><keyname>Buyya</keyname><forenames>Rajkumar</forenames></author></authors><title>A Linear Programming Driven Genetic Algorithm for Meta-Scheduling on
  Utility Grids</title><categories>cs.DC cs.NE</categories><comments>9 pages</comments><acm-class>C.2.4</acm-class><journal-ref>Proceedings of the 16th International Conference on Advanced
  Computing and Communication (ADCOM 2008, IEEE Press, New York, USA), Dec.
  14-17, 2008, Chennai, India</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The user-level brokers in grids consider individual application QoS
requirements and minimize their cost without considering demands from other
users. This results in contention for resources and sub-optimal schedules.
Meta-scheduling in grids aims to address this scheduling problem, which is NP
hard due to its combinatorial nature. Thus, many heuristic-based solutions
using Genetic Algorithm (GA) have been proposed, apart from traditional
algorithms such as Greedy and FCFS.
  We propose a Linear Programming/Integer Programming model (LP/IP) for
scheduling these applications to multiple resources. We also propose a novel
algorithm LPGA (Linear programming driven Genetic Algorithm) which combines the
capabilities of LP and GA. The aim of this algorithm is to obtain the best
metaschedule for utility grids which minimize combined cost of all users in a
coordinated manner. Simulation results show that our proposed integrated
algorithm offers the best schedule having the minimum processing cost with
negligible time overhead.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1407</identifier>
 <datestamp>2009-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1407</id><created>2009-03-08</created><authors><author><keyname>Campelo</keyname><forenames>Manoel</forenames></author><author><keyname>Correa</keyname><forenames>Ricardo C.</forenames></author></authors><title>A Lagrangian Relaxation for the Maximum Stable Set Problem</title><categories>cs.DM cs.DS</categories><comments>Submitted to International Transactions on Operations Research</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new integer programming formulation for the problem of finding a
maximum stable set of a graph based on representatives of stable sets. In
addition, we investigate exact solutions provided by a Lagrangian decomposition
of this formulation in which only one constraint is relaxed. Some computational
experiments were carried out with an effective multi-threaded implementation of
our algorithm in a multi-core system, and their results are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1443</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1443</id><created>2009-03-09</created><updated>2009-06-28</updated><authors><author><keyname>Asif</keyname><forenames>Muhammad Salman</forenames></author><author><keyname>Romberg</keyname><forenames>Justin</forenames></author></authors><title>Dynamic Updating for L1 Minimization</title><categories>cs.IT math.IT</categories><comments>Some sections are re-organized</comments><doi>10.1109/JSTSP.2009.2039174</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The theory of compressive sensing (CS) suggests that under certain
conditions, a sparse signal can be recovered from a small number of linear
incoherent measurements. An effective class of reconstruction algorithms
involve solving a convex optimization program that balances the L1 norm of the
solution against a data fidelity term. Tremendous progress has been made in
recent years on algorithms for solving these L1 minimization programs. These
algorithms, however, are for the most part static: they focus on finding the
solution for a fixed set of measurements.
  In this paper, we will discuss &quot;dynamic algorithms&quot; for solving L1
minimization programs for streaming sets of measurements. We consider cases
where the underlying signal changes slightly between measurements, and where
new measurements of a fixed signal are sequentially added to the system. We
develop algorithms to quickly update the solution of several different types of
L1 optimization problems whenever these changes occur, thus avoiding having to
solve a new optimization problem from scratch. Our proposed schemes are based
on homotopy continuation, which breaks down the solution update in a systematic
and efficient way into a small number of linear steps. Each step consists of a
low-rank update and a small number of matrix-vector multiplications -- very
much like recursive least squares. Our investigation also includes dynamic
updating schemes for L1 decoding problems, where an arbitrary signal is to be
recovered from redundant coded measurements which have been corrupted by sparse
errors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1448</identifier>
 <datestamp>2009-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1448</id><created>2009-03-09</created><authors><author><keyname>Sparavigna</keyname><forenames>Amelia</forenames></author></authors><title>The Digital Restoration of Da Vinci's Sketches</title><categories>cs.CV cs.GR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A sketch, found in one of Leonardo da Vinci's notebooks and covered by the
written notes of this genius, has been recently restored. The restoration
reveals a possible self-portrait of the artist, drawn when he was young. Here,
we discuss the discovery of this self-portrait and the procedure used for
restoration. Actually, this is a restoration performed on the digital image of
the sketch, a procedure that can easily extended and applied to ancient
documents for studies of art and palaeography.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1450</identifier>
 <datestamp>2011-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1450</id><created>2009-03-08</created><updated>2011-03-02</updated><authors><author><keyname>Hafalir</keyname><forenames>I.</forenames></author><author><keyname>Ravi</keyname><forenames>R.</forenames></author><author><keyname>Sayedi</keyname><forenames>A.</forenames></author></authors><title>Multi-unit Auctions with Budget Constraints</title><categories>cs.GT</categories><acm-class>F.2.2</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Motivated by sponsored search auctions, we study multi-unit auctions with
budget constraints. In the mechanism we propose, Sort-Cut, understating budgets
or values is weakly dominated. Since Sort-Cut's revenue is increasing in
budgets and values, all kinds of equilibrium deviations from true valuations
turn out to be beneficial to the auctioneer. We show that the revenue of
Sort-Cut can be an order of magnitude greater than that of the natural Market
Clearing Price mechanism, and we discuss the efficiency properties of its
ex-post Nash equilibrium.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1451</identifier>
 <datestamp>2009-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1451</id><created>2009-03-08</created><updated>2009-03-30</updated><authors><author><keyname>Dambreville</keyname><forenames>Frederic</forenames><affiliation>DGA/Cta/DT/Gip</affiliation></author></authors><title>Definition of evidence fusion rules on the basis of Referee Functions</title><categories>cs.AI math.PR stat.AP</categories><proxy>ccsd hal-00366494</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This chapter defines a new concept and framework for constructing fusion
rules for evidences. This framework is based on a referee function, which does
a decisional arbitrament conditionally to basic decisions provided by the
several sources of information. A simple sampling method is derived from this
framework. The purpose of this sampling approach is to avoid the combinatorics
which are inherent to the definition of fusion rules of evidences. This
definition of the fusion rule by the means of a sampling process makes possible
the construction of several rules on the basis of an algorithmic implementation
of the referee function, instead of a mathematical formulation. Incidentally,
it is a versatile and intuitive way for defining rules. The framework is
implemented for various well known evidence rules. On the basis of this
framework, new rules for combining evidences are proposed, which takes into
account a consensual evaluation of the sources of information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1476</identifier>
 <datestamp>2009-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1476</id><created>2009-03-08</created><authors><author><keyname>Candes</keyname><forenames>Emmanuel J.</forenames></author><author><keyname>Tao</keyname><forenames>Terence</forenames></author></authors><title>The Power of Convex Relaxation: Near-Optimal Matrix Completion</title><categories>cs.IT math.IT</categories><comments>51 pages, 12 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is concerned with the problem of recovering an unknown matrix from
a small fraction of its entries. This is known as the matrix completion
problem, and comes up in a great number of applications, including the famous
Netflix Prize and other similar questions in collaborative filtering. In
general, accurate recovery of a matrix from a small number of entries is
impossible; but the knowledge that the unknown matrix has low rank radically
changes this premise, making the search for solutions meaningful.
  This paper presents optimality results quantifying the minimum number of
entries needed to recover a matrix of rank r exactly by any method whatsoever
(the information theoretic limit). More importantly, the paper shows that,
under certain incoherence assumptions on the singular vectors of the matrix,
recovery is possible by solving a convenient convex program as soon as the
number of entries is on the order of the information theoretic limit (up to
logarithmic factors). This convex program simply finds, among all matrices
consistent with the observed entries, that with minimum nuclear norm. As an
example, we show that on the order of nr log(n) samples are needed to recover a
random n x n matrix of rank r by any method, and to be sure, nuclear norm
minimization succeeds as soon as the number of entries is of the form nr
polylog(n).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1484</identifier>
 <datestamp>2009-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1484</id><created>2009-03-09</created><updated>2009-03-29</updated><authors><author><keyname>Merhav</keyname><forenames>Neri</forenames></author></authors><title>Physics of the Shannon Limits</title><categories>cs.IT math.IT</categories><comments>9 pages; submitted to IEEE Trans. on Inform. Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide a simple physical interpretation, in the context of the second law
of thermodynamics, to the information inequality (a.k.a. the Gibbs' inequality,
which is also equivalent to the log-sum inequality), asserting that the
relative entropy between two probability distributions cannot be negative.
Since this inequality stands at the basis of the data processing theorem (DPT),
and the DPT in turn is at the heart of most, if not all, proofs of converse
theorems in Shannon theory, it is observed that conceptually, the roots of
fundamental limits of Information Theory can actually be attributed to the laws
of physics, in particular, to the second law of thermodynamics, and at least
indirectly, also to the law of energy conservation. By the same token, in the
other direction: one can view the second law as stemming from
information-theoretic principles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1496</identifier>
 <datestamp>2009-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1496</id><created>2009-03-09</created><authors><author><keyname>Sung</keyname><forenames>Youngchul</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author><author><keyname>Yu</keyname><forenames>Heejung</forenames></author></authors><title>How Much Information can One Get from a Wireless Ad Hoc Sensor Network
  over a Correlated Random Field?</title><categories>cs.IT math.IT</categories><comments>46 pages and 9 figures. To appear in IEEE Transactions on Information
  Theory, June 2009</comments><acm-class>E.4; H.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  New large deviations results that characterize the asymptotic information
rates for general $d$-dimensional ($d$-D) stationary Gaussian fields are
obtained. By applying the general results to sensor nodes on a two-dimensional
(2-D) lattice, the asymptotic behavior of ad hoc sensor networks deployed over
correlated random fields for statistical inference is investigated. Under a 2-D
hidden Gauss-Markov random field model with symmetric first order conditional
autoregression and the assumption of no in-network data fusion, the behavior of
the total obtainable information [nats] and energy efficiency [nats/J] defined
as the ratio of total gathered information to the required energy is obtained
as the coverage area, node density and energy vary. When the sensor node
density is fixed, the energy efficiency decreases to zero with rate
$\Theta({area}^{-1/2})$ and the per-node information under fixed per-node
energy also diminishes to zero with rate $O(N_t^{-1/3})$ as the number $N_t$ of
network nodes increases by increasing the coverage area. As the sensor spacing
$d_n$ increases, the per-node information converges to its limit $D$ with rate
$D-\sqrt{d_n}e^{-\alpha d_n}$ for a given diffusion rate $\alpha$. When the
coverage area is fixed and the node density increases, the per-node information
is inversely proportional to the node density. As the total energy $E_t$
consumed in the network increases, the total information obtainable from the
network is given by $O(\log E_t)$ for the fixed node density and fixed coverage
case and by $\Theta (E_t^{2/3})$ for the fixed per-node sensing energy and
fixed density and increasing coverage case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1502</identifier>
 <datestamp>2012-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1502</id><created>2009-03-09</created><updated>2011-03-28</updated><authors><author><keyname>Duyck</keyname><forenames>Dieter</forenames></author><author><keyname>Boutros</keyname><forenames>Joseph J.</forenames></author><author><keyname>Moeneclaey</keyname><forenames>Marc</forenames></author></authors><title>Low-Density Graph Codes for slow fading Relay Channels</title><categories>cs.IT math.IT</categories><comments>Accepted for publication in IEEE Transactions on Information Theory</comments><msc-class>68Pxx</msc-class><journal-ref>IEEE Transactions on Information theory, vol 57, no 7, pp. 4202 -
  4218, 2011</journal-ref><doi>10.1109/TIT.2011.2145470</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study Low-Density Parity-Check (LDPC) codes with iterative decoding on
block-fading (BF) Relay Channels. We consider two users that employ coded
cooperation, a variant of decode-and-forward with a smaller outage probability
than the latter. An outage probability analysis for discrete constellations
shows that full diversity can be achieved only when the coding rate does not
exceed a maximum value that depends on the level of cooperation. We derive a
new code structure by extending the previously published full-diversity
root-LDPC code, designed for the BF point-to-point channel, to exhibit a
rate-compatibility property which is necessary for coded cooperation. We
estimate the asymptotic performance through a new density evolution analysis
and the word error rate performance is determined for finite length codes. We
show that our code construction exhibits near-outage limit performance for all
block lengths and for a range of coding rates up to 0.5, which is the highest
possible coding rate for two cooperating users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1506</identifier>
 <datestamp>2009-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1506</id><created>2009-03-09</created><authors><author><keyname>Bera</keyname><forenames>Rabindranath</forenames></author><author><keyname>Sil</keyname><forenames>Sanjib</forenames></author><author><keyname>Dhar</keyname><forenames>Sourav</forenames></author><author><keyname>Sarkar</keyname><forenames>Subir K.</forenames></author></authors><title>Wi-Fi, WiMax and WCDMA A comparative study based on Channel Impairments
  and Equalization method used</title><categories>cs.NI</categories><comments>5 pages, 15 fig.,published in ISM-08, Bangalore, India</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we describe the channel impairments and equalization methods
currently used in WiFi, WiMax and WCDMA. After a review of channel model for
Intelligent Transportation System (ITS), we proposed an equalization method
which will be useful for the estimation of strong multipath channel at a high
velocity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1509</identifier>
 <datestamp>2009-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1509</id><created>2009-03-09</created><authors><author><keyname>Bera</keyname><forenames>Rabindranath</forenames></author><author><keyname>Dhar</keyname><forenames>Sourav</forenames></author><author><keyname>Kandar</keyname><forenames>Debdatta</forenames></author></authors><title>Digital Radar for Collision Avoidance and Automatic Cruise Control in
  Transportation</title><categories>cs.NI</categories><comments>5 pages, 12 figs.,published in ISM-08, Bangalore, India, 3-6 December
  2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A proper remote sensing device is required for automatic cruise control (ACC)
to avoid collision in transportation system. In this paper we proposed a direct
sequence spread spectrum (DSSS) radar for remote sensing in intelligent
transporation system(ITS). We have successfully detected single target and
through 1D radar imaging we are capable to separate multiple targets. We have
also implemented DSSS radar using software defined radio (SDR) and successfully
detected a single target.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1511</identifier>
 <datestamp>2009-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1511</id><created>2009-03-09</created><authors><author><keyname>Kandar</keyname><forenames>D.</forenames></author><author><keyname>Dhar</keyname><forenames>Sourav</forenames></author><author><keyname>Bera</keyname><forenames>Rabindranath</forenames></author><author><keyname>Sarkar</keyname><forenames>C. K.</forenames></author></authors><title>MIMO Based Multimedia Communication System</title><categories>cs.NI</categories><comments>3 pages, 5 figs., published in ISM-08, Bangalore, India, 3-6 December
  2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  High data rate is required for multimedia communication. But the
communication at high data rate is always challenging. In this work we have
successfully performed data chatting, Voice chatting and high quality video
transmission between two distant units using MIMO adapter, Direct sequence
spread spectrum system and MATLAB/SIMULINK platform.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1556</identifier>
 <datestamp>2009-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1556</id><created>2009-03-09</created><authors><author><keyname>Silberstein</keyname><forenames>Natalia</forenames></author><author><keyname>Etzion</keyname><forenames>Tuvi</forenames></author></authors><title>Enumerative Encoding in the Grassmannian Space</title><categories>cs.IT math.IT</categories><comments>2009 Informaton Theory Workshop, Taormina</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Codes in the Grassmannian space have found recently application in network
coding. Representation of $k$-dimensional subspaces of $\F_q^n$ has generally
an essential role in solving coding problems in the Grassmannian, and in
particular in encoding subspaces of the Grassmannian. Different representations
of subspaces in the Grassmannian are presented. We use two of these
representations for enumerative encoding of the Grassmannian. One enumerative
encoding is based on Ferrers diagrams representation of subspaces; and another
is based on identifying vector and reduced row echelon form representation of
subspaces. A third method which combine the previous two is more efficient than
the other two enumerative encodings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1588</identifier>
 <datestamp>2010-05-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1588</id><created>2009-03-09</created><updated>2010-05-04</updated><authors><author><keyname>Flanagan</keyname><forenames>Mark F.</forenames></author><author><keyname>Paolini</keyname><forenames>Enrico</forenames></author><author><keyname>Chiani</keyname><forenames>Marco</forenames></author><author><keyname>Fossorier</keyname><forenames>Marc</forenames></author></authors><title>On the Growth Rate of the Weight Distribution of Irregular
  Doubly-Generalized LDPC Codes</title><categories>cs.IT math.IT</categories><comments>Revision of the journal paper. 37 pages, 2 figures. Submitted</comments><report-no>UCD-01-01</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, an expression for the asymptotic growth rate of the number of
small linear-weight codewords of irregular doubly-generalized LDPC (D-GLDPC)
codes is derived. The expression is compact and generalizes existing results
for LDPC and generalized LDPC (GLDPC) codes. Ensembles with check or variable
node minimum distance greater than 2 are shown to be have good growth rate
behavior, while for other ensembles a fundamental parameter is identified which
discriminates between an asymptotically small and an asymptotically large
expected number of small linear-weight codewords. Also, in the latter case it
is shown that the growth rate depends only on the check and variable nodes with
minimum distance 2. An important connection between this new result and the
stability condition of D-GLDPC codes over the BEC is highlighted. Such a
connection, previously observed for LDPC and GLDPC codes, is now extended to
the case of D-GLDPC codes. Finally, it is shown that the analysis may be
extended to include the growth rate of the stopping set size distribution of
irregular D-GLDPC codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1598</identifier>
 <datestamp>2009-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1598</id><created>2009-03-09</created><updated>2009-03-26</updated><authors><author><keyname>Arenas</keyname><forenames>Puri</forenames></author><author><keyname>Zanardini</keyname><forenames>Damiano</forenames></author></authors><title>18th Workshop on Logic-based methods in Programming Environments (WLPE
  2008)</title><categories>cs.PL</categories><report-no>WLPE/2008</report-no><acm-class>D.2.6; D.1.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This volume contains the papers presented at WLPE 2008: the 18th Workshop on
Logic-based Methods in Programming Environments held on 12th December, 2008 in
Udine, Italy. It was held as a satellite workshop of ICLP 2008, the 24th
International Conference on Logic Programming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1621</identifier>
 <datestamp>2010-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1621</id><created>2009-03-09</created><authors><author><keyname>Higuchi</keyname><forenames>Saburo</forenames></author><author><keyname>M&#xe9;zard</keyname><forenames>Marc</forenames></author></authors><title>Susceptibility Propagation for Constraint Satisfaction Problems</title><categories>cond-mat.dis-nn cond-mat.stat-mech cs.IT math.IT</categories><comments>17 pages, 5 figures</comments><journal-ref>J. Phys.: Conf. Ser. 233(2010)012003</journal-ref><doi>10.1088/1742-6596/233/1/012003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the susceptibility propagation, a message-passing algorithm to
compute correlation functions. It is applied to constraint satisfaction
problems and its accuracy is examined. As a heuristic method to find a
satisfying assignment, we propose susceptibility-guided decimation where
correlations among the variables play an important role. We apply this novel
decimation to locked occupation problems, a class of hard constraint
satisfaction problems exhibited recently. It is shown that the present method
performs better than the standard belief-guided decimation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1624</identifier>
 <datestamp>2009-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1624</id><created>2009-03-09</created><authors><author><keyname>Chilappagari</keyname><forenames>Shashi Kiran</forenames></author><author><keyname>Chertkov</keyname><forenames>Michael</forenames></author><author><keyname>Stepanov</keyname><forenames>Mikhail G.</forenames></author><author><keyname>Vasic</keyname><forenames>Bane</forenames></author></authors><title>Instanton-based Techniques for Analysis and Reduction of Error Floors of
  LDPC Codes</title><categories>cs.IT math.IT</categories><comments>To appear in IEEE JSAC On Capacity Approaching Codes. 11 Pages and 6
  Figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a family of instanton-based optimization methods developed
recently for the analysis of the error floors of low-density parity-check
(LDPC) codes. Instantons are the most probable configurations of the channel
noise which result in decoding failures. We show that the general idea and the
respective optimization technique are applicable broadly to a variety of
channels, discrete or continuous, and variety of sub-optimal decoders.
Specifically, we consider: iterative belief propagation (BP) decoders, Gallager
type decoders, and linear programming (LP) decoders performing over the
additive white Gaussian noise channel (AWGNC) and the binary symmetric channel
(BSC).
  The instanton analysis suggests that the underlying topological structures of
the most probable instanton of the same code but different channels and
decoders are related to each other. Armed with this understanding of the
graphical structure of the instanton and its relation to the decoding failures,
we suggest a method to construct codes whose Tanner graphs are free of these
structures, and thus have less significant error floors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1627</identifier>
 <datestamp>2012-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1627</id><created>2009-03-09</created><updated>2012-02-01</updated><authors><author><keyname>Cassaigne</keyname><forenames>Julien</forenames></author><author><keyname>Nicolas</keyname><forenames>Francois</forenames></author></authors><title>On the Morse-Hedlund complexity gap</title><categories>cs.FL cs.DM</categories><comments>7 pages. Not intended to be submitted. New proof of an old result</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In 1938, Morse and Hedlund proved that the subword complexity function of an
infinite word is either bounded or at least linearly growing. In 1982,
Ehrenfeucht and Rozenberg proved that this gap property holds for the subword
complexity function of any language. The aim of the present paper is to present
a self-contained, compact proof of Ehrenfeucht and Rozenberg's result.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1659</identifier>
 <datestamp>2009-03-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1659</id><created>2009-03-09</created><authors><author><keyname>Chen</keyname><forenames>Zhe</forenames></author></authors><title>Heuristic Reasoning on Graph and Game Complexity of Sudoku</title><categories>cs.AI cs.GT cs.SC</categories><comments>6 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Sudoku puzzle has achieved worldwide popularity recently, and attracted
great attention of the computational intelligence community. Sudoku is always
considered as Satisfiability Problem or Constraint Satisfaction Problem. In
this paper, we propose to focus on the essential graph structure underlying the
Sudoku puzzle. First, we formalize Sudoku as a graph. Then a solving algorithm
based on heuristic reasoning on the graph is proposed. The related r-Reduction
theorem, inference theorem and their properties are proved, providing the
formal basis for developments of Sudoku solving systems. In order to evaluate
the difficulty levels of puzzles, a quantitative measurement of the complexity
level of Sudoku puzzles based on the graph structure and information theory is
proposed. Experimental results show that all the puzzles can be solved fast
using the proposed heuristic reasoning, and that the proposed game complexity
metrics can discriminate difficulty levels of puzzles perfectly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1675</identifier>
 <datestamp>2009-03-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1675</id><created>2009-03-09</created><authors><author><keyname>Kailas</keyname><forenames>Aravind</forenames></author><author><keyname>Thanayankizil</keyname><forenames>Lakshmi</forenames></author><author><keyname>Ingram</keyname><forenames>Mary Ann</forenames></author></authors><title>A Simple Cooperative Transmission Protocol for Energy-Efficient
  Broadcasting Over Multi-Hop Wireless Networks</title><categories>cs.NI cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper analyzes a broadcasting technique for wireless multi-hop sensor
networks that uses a form of cooperative diversity called opportunistic large
arrays (OLAs). We propose a method for autonomous scheduling of the nodes,
which limits the nodes that relay and saves as much as 32% of the transmit
energy compared to other broadcast approaches, without requiring Global
Positioning System (GPS), individual node addressing, or inter-node
interaction. This energy-saving is a result of cross-layer interaction, in the
sense that the Medium Access Control (MAC) and routing functions are partially
executed in the Physical (PHY) layer. Our proposed method is called OLA with a
transmission threshold (OLA-T), where a node compares its received power to a
threshold to decide if it should forward. We also investigate OLA with variable
threshold (OLA-VT), which optimizes the thresholds as a function of level.
OLA-T and OLA-VT are compared with OLA broadcasting without a transmission
threshold, each in their minimum energy configuration, using an analytical
method under the orthogonal and continuum assumptions. The trade-off between
the number of OLA levels (or hops) required to achieve successful network
broadcast and transmission energy saved is investigated. The results based on
the analytical assumptions are confirmed with Monte Carlo simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1680</identifier>
 <datestamp>2010-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1680</id><created>2009-03-10</created><updated>2010-10-05</updated><authors><author><keyname>Zhuge</keyname><forenames>H.</forenames></author><author><keyname>He</keyname><forenames>C.</forenames></author></authors><title>Faceted Exploration of Emerging Resource Spaces</title><categories>cs.DB cs.DL cs.HC</categories><comments>20 pages, 18 figures</comments><acm-class>H.2.1; H.2.8; H.3.1; H.3.7; H.1.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Humans have the ability to regcognize the real world from different facets.
Faceted exploration is a mechanism for browsing and understanding large-scale
resources in information network by multiple facets. This paper proposes an
Emerging Resource Space Model, whose schema is a partially ordered set of
concepts with subclassOf relation and each resource is categorized by multiple
concepts. Emering Resource Space (ERS) is a class of resources characterized by
a concept set. ERSes compose a lattice (ERSL) via concept association. A series
of exploration operations is proposed to guide users to explore through ERSL
with more demanding and richer semantics than current faceted navigation. To
fulfill instant response during faceted exploration, we devise an efficient
algorithm for mining and indexing ERSL. The proposed model can effectively
support faceted exploration in various applications from personal information
management to large-scale information sharing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1684</identifier>
 <datestamp>2009-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1684</id><created>2009-03-10</created><updated>2009-08-09</updated><authors><author><keyname>Ren</keyname><forenames>Wei</forenames></author><author><keyname>Zhao</keyname><forenames>Qing</forenames></author><author><keyname>Swami</keyname><forenames>Ananthram</forenames></author></authors><title>Connectivity of Heterogeneous Wireless Networks</title><categories>cs.NI</categories><comments>46 pages, 19 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the connectivity of large-scale ad hoc heterogeneous wireless
networks, where secondary users exploit channels temporarily unused by primary
users and the existence of a communication link between two secondary users
depends on not only the distance between them but also the transmitting and
receiving activities of nearby primary users. We introduce the concept of
connectivity region defined as the set of density pairs -- the density of
secondary users and the density of primary transmitters -- under which the
secondary network is connected. Using theories and techniques from continuum
percolation, we analytically characterize the connectivity region of the
secondary network and reveal the tradeoff between proximity (the number of
neighbors) and the occurrence of spectrum opportunities. Specifically, we
establish three basic properties of the connectivity region -- contiguity,
monotonicity of the boundary, and uniqueness of the infinite connected
component, where the uniqueness implies the occurrence of a phase transition
phenomenon in terms of the almost sure existence of either zero or one infinite
connected component; we identify and analyze two critical densities which
jointly specify the profile as well as an outer bound on the connectivity
region; we study the impacts of secondary users' transmission power on the
connectivity region and the conditional average degree of a secondary user, and
demonstrate that matching the interference ranges of the primary and the
secondary networks maximizes the tolerance of the secondary network to the
primary traffic load. Furthermore, we establish a necessary condition and a
sufficient condition for connectivity, which lead to an outer bound and an
inner bound on the connectivity region.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1716</identifier>
 <datestamp>2009-03-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1716</id><created>2009-03-10</created><authors><author><keyname>Louidor</keyname><forenames>Erez</forenames></author><author><keyname>Marcus</keyname><forenames>Brian</forenames></author></authors><title>Improved Lower Bounds on Capacities of Symmetric 2-Dimensional
  Constraints using Rayleigh Quotients</title><categories>cs.IT cs.DM math.CO math.IT</categories><comments>Submitted to IEEE Trans. Inform. Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A method for computing lower bounds on capacities of 2-dimensional
constraints having a symmetric presentation in either the horizontal or the
vertical direction is presented. The method is a generalization of the method
of Calkin and Wilf (SIAM J. Discrete Math., 1998). Previous best lower bounds
on capacities of certain constraints are improved using the method. It is also
shown how this method, as well as their method for computing upper bounds on
the capacity, can be applied to constraints which are not of finite-type.
Additionally, capacities of 2 families of multi-dimensional constraints are
given exactly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1724</identifier>
 <datestamp>2009-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1724</id><created>2009-03-10</created><updated>2009-07-29</updated><authors><author><keyname>Etzion</keyname><forenames>Tuvi</forenames></author></authors><title>Folding, Tiling, and Multidimensional Coding</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Folding a sequence $S$ into a multidimensional box is a method that is used
to construct multidimensional codes. The well known operation of folding is
generalized in a way that the sequence $S$ can be folded into various shapes.
The new definition of folding is based on lattice tiling and a direction in the
$D$-dimensional grid. There are potentially $\frac{3^D-1}{2}$ different folding
operations. Necessary and sufficient conditions that a lattice combined with a
direction define a folding are given. The immediate and most impressive
application is some new lower bounds on the number of dots in two-dimensional
synchronization patterns. This can be also generalized for multidimensional
synchronization patterns. We show how folding can be used to construct
multidimensional error-correcting codes and to generate multidimensional
pseudo-random arrays.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1734</identifier>
 <datestamp>2009-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1734</id><created>2009-03-10</created><updated>2009-12-29</updated><authors><author><keyname>Thampi</keyname><forenames>Sabu M.</forenames></author><author><keyname>Sekaran</keyname><forenames>K. Chandra</forenames></author></authors><title>Review of Replication Schemes for Unstructured P2P Networks</title><categories>cs.DC cs.NI</categories><comments>7 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To improve unstructured P2P system performance, one wants to minimize the
number of peers that have to be probed for the shortening of the search time. A
solution to the problem is to employ a replication scheme, which provides high
hit rate for target files. Replication can also provide load balancing and
reduce access latency if the file is accessed by a large population of users.
This paper briefly describes various replication schemes that have appeared in
the literature and also focuses on a novel replication technique called
Q-replication to increase availability of objects in unstructured P2P networks.
The Q-replication technique replicates objects autonomously to suitable sites
based on object popularity and site selection logic by extensively employing
Q-learning concept.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1765</identifier>
 <datestamp>2009-03-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1765</id><created>2009-03-10</created><authors><author><keyname>Br&#xf6;cker</keyname><forenames>Jochen</forenames></author></authors><title>A Lower Bound on Arbitrary $f$--Divergences in Terms of the Total
  Variation</title><categories>math.PR cs.IT math.IT math.ST stat.TH</categories><comments>4 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An important tool to quantify the likeness of two probability measures are
f-divergences, which have seen widespread application in statistics and
information theory. An example is the total variation, which plays an
exceptional role among the f-divergences. It is shown that every f-divergence
is bounded from below by a monotonous function of the total variation. Under
appropriate regularity conditions, this function is shown to be monotonous.
  Remark: The proof of the main proposition is relatively easy, whence it is
highly likely that the result is known. The author would be very grateful for
any information regarding references or related work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1788</identifier>
 <datestamp>2009-03-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1788</id><created>2009-03-10</created><authors><author><keyname>Bollen</keyname><forenames>Dirk</forenames></author><author><keyname>Halpin</keyname><forenames>Harry</forenames></author></authors><title>The Role of Tag Suggestions in Folksonomies</title><categories>cs.HC cs.IR</categories><acm-class>H.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most tagging systems support the user in the tag selection process by
providing tag suggestions, or recommendations, based on a popularity
measurement of tags other users provided when tagging the same resource. In
this paper we investigate the influence of tag suggestions on the emergence of
power law distributions as a result of collaborative tag behavior. Although
previous research has already shown that power laws emerge in tagging systems,
the cause of why power law distributions emerge is not understood empirically.
The majority of theories and mathematical models of tagging found in the
literature assume that the emergence of power laws in tagging systems is mainly
driven by the imitation behavior of users when observing tag suggestions
provided by the user interface of the tagging system. This imitation behavior
leads to a feedback loop in which some tags are reinforced and get more popular
which is also known as the `rich get richer' or a preferential attachment
model. We present experimental results that show that the power law
distribution forms regardless of whether or not tag suggestions are presented
to the users. Furthermore, we show that the real effect of tag suggestions is
rather subtle; the resulting power law distribution is `compressed' if tag
suggestions are given to the user, resulting in a shorter long tail and a
`compressed' top of the power law distribution. The consequences of this
experiment show that tag suggestions by themselves do not account for the
formation of power law distributions in tagging systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1817</identifier>
 <datestamp>2009-03-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1817</id><created>2009-03-10</created><authors><author><keyname>Greengard</keyname><forenames>Leslie</forenames></author><author><keyname>Stucchio</keyname><forenames>Chris</forenames></author></authors><title>Reconstructing Curves from Points and Tangents</title><categories>cs.CG</categories><comments>22 pages, 11 figures</comments><acm-class>I.3.5; F.2.2</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Reconstructing a finite set of curves from an unordered set of sample points
is a well studied topic. There has been less effort that considers how much
better the reconstruction can be if tangential information is given as well. We
show that if curves are separated from each other by a distance D, then the
sampling rate need only be O(sqrt(D)) for error-free reconstruction. For the
case of point data alone, O(D) sampling is required.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1818</identifier>
 <datestamp>2009-03-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1818</id><created>2009-03-10</created><authors><author><keyname>Lathrop</keyname><forenames>James I.</forenames></author><author><keyname>Lutz</keyname><forenames>Jack H.</forenames></author><author><keyname>Summers</keyname><forenames>Scott M.</forenames></author></authors><title>Strict Self-Assembly of Discrete Sierpinski Triangles</title><categories>cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Winfree (1998) showed that discrete Sierpinski triangles can self-assemble in
the Tile Assembly Model. A striking molecular realization of this
self-assembly, using DNA tiles a few nanometers long and verifying the results
by atomic-force microscopy, was achieved by Rothemund, Papadakis, and Winfree
(2004). Precisely speaking, the above self-assemblies tile completely
filled-in, two-dimensional regions of the plane, with labeled subsets of these
tiles representing discrete Sierpinski triangles. This paper addresses the more
challenging problem of the strict self-assembly of discrete Sierpinski
triangles, i.e., the task of tiling a discrete Sierpinski triangle and nothing
else. We first prove that the standard discrete Sierpinski triangle cannot
strictly self-assemble in the Tile Assembly Model. We then define the fibered
Sierpinski triangle, a discrete Sierpinski triangle with the same fractal
dimension as the standard one but with thin fibers that can carry data, and
show that the fibered Sierpinski triangle strictly self-assembles in the Tile
Assembly Model. In contrast with the simple XOR algorithm of the earlier,
non-strict self-assemblies, our strict self-assembly algorithm makes extensive,
recursive use of optimal counters, coupled with measured delay and
corner-turning operations. We verify our strict self-assembly using the local
determinism method of Soloveichik and Winfree (2007).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1820</identifier>
 <datestamp>2009-03-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1820</id><created>2009-03-10</created><authors><author><keyname>Lapidoth</keyname><forenames>Amos</forenames></author><author><keyname>Moser</keyname><forenames>Stefan M.</forenames></author><author><keyname>Wigger</keyname><forenames>Michele A.</forenames></author></authors><title>On the Capacity of Free-Space Optical Intensity Channels</title><categories>cs.IT math.IT</categories><comments>Transmitted to IEEE Transactions on Information Theory. Presented at
  ISIT 2008 in Toronto</comments><report-no>13454533334</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  New upper and lower bounds are presented on the capacity of the free-space
optical intensity channel. This channel is characterized by inputs that are
nonnegative (representing the transmitted optical intensity) and by outputs
that are corrupted by additive white Gaussian noise (because in free space the
disturbances arise from many independent sources). Due to battery and safety
reasons the inputs are simultaneously constrained in both their average and
peak power. For a fixed ratio of the average power to the peak power the
difference between the upper and the lower bounds tends to zero as the average
power tends to infinity, and the ratio of the upper and lower bounds tends to
one as the average power tends to zero. The case where only an average-power
constraint is imposed on the input is treated separately. In this case, the
difference of the upper and lower bound tends to 0 as the average power tends
to infinity, and their ratio tends to a constant as the power tends to zero.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1822</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1822</id><created>2009-03-10</created><updated>2009-05-25</updated><authors><author><keyname>Santo</keyname><forenames>Jose Espirito</forenames></author><author><keyname>Matthes</keyname><forenames>Ralph</forenames></author><author><keyname>Pinto</keyname><forenames>Luis</forenames></author></authors><title>Continuation-Passing Style and Strong Normalisation for Intuitionistic
  Sequent Calculi</title><categories>cs.LO</categories><acm-class>F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 5, Issue 2 (May 25,
  2009) lmcs:1149</journal-ref><doi>10.2168/LMCS-5(2:11)2009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The intuitionistic fragment of the call-by-name version of Curien and
Herbelin's \lambda\_mu\_{\~mu}-calculus is isolated and proved strongly
normalising by means of an embedding into the simply-typed lambda-calculus. Our
embedding is a continuation-and-garbage-passing style translation, the
inspiring idea coming from Ikeda and Nakazawa's translation of Parigot's
\lambda\_mu-calculus. The embedding strictly simulates reductions while usual
continuation-passing-style transformations erase permutative reduction steps.
For our intuitionistic sequent calculus, we even only need &quot;units of garbage&quot;
to be passed. We apply the same method to other calculi, namely successive
extensions of the simply-typed &amp;lambda;-calculus leading to our intuitionistic
system, and already for the simplest extension we consider (&amp;lambda;-calculus
with generalised application), this yields the first proof of strong
normalisation through a reduction-preserving embedding. The results obtained
extend to second and higher-order calculi.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1842</identifier>
 <datestamp>2009-03-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1842</id><created>2009-03-10</created><authors><author><keyname>Kudekar</keyname><forenames>Shrinivas</forenames></author><author><keyname>Macris</keyname><forenames>Nicolas</forenames></author></authors><title>Decay of Correlations for Sparse Graph Error Correcting Codes</title><categories>cs.IT math.IT</categories><comments>40 pages, Submitted to SIAM Journal of Discrete Mathematics</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The subject of this paper is transmission over a general class of
binary-input memoryless symmetric channels using error correcting codes based
on sparse graphs, namely low-density generator-matrix and low-density
parity-check codes. The optimal (or ideal) decoder based on the posterior
measure over the code bits, and its relationship to the sub-optimal belief
propagation decoder, are investigated. We consider the correlation (or
covariance) between two codebits, averaged over the noise realizations, as a
function of the graph distance, for the optimal decoder. Our main result is
that this correlation decays exponentially fast for fixed general low-density
generator-matrix codes and high enough noise parameter, and also for fixed
general low-density parity-check codes and low enough noise parameter. This has
many consequences. Appropriate performance curves - called GEXIT functions - of
the belief propagation and optimal decoders match in high/low noise regimes.
This means that in high/low noise regimes the performance curves of the optimal
decoder can be computed by density evolution. Another interpretation is that
the replica predictions of spin-glass theory are exact. Our methods are rather
general and use cluster expansions first developed in the context of
mathematical statistical mechanics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1850</identifier>
 <datestamp>2009-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1850</id><created>2009-03-11</created><authors><author><keyname>Bhavnagri</keyname><forenames>Burzin</forenames></author></authors><title>Free actions and Grassmanian variety</title><categories>math.AG cs.CV q-bio.NC</categories><comments>fixed matrices lost in latex and numbered equations</comments><msc-class>14Q15 (Primary) 53C27, 53C80 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An algebraic notion of representational consistency is defined. A theorem
relating it to free actions is proved. A metrizability problem of the quotient
(a shape space) is discussed. This leads to a new algebraic variety with a
metrizability result. A concrete example is given from stereo vision.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1857</identifier>
 <datestamp>2009-03-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1857</id><created>2009-03-10</created><authors><author><keyname>Doty</keyname><forenames>David</forenames></author><author><keyname>Patitz</keyname><forenames>Matthew J</forenames></author><author><keyname>Summers</keyname><forenames>Scott M</forenames></author></authors><title>Limitations of Self-Assembly at Temperature 1</title><categories>cs.DM</categories><comments>10 page conference submission with additional technical appendix
  containing proofs</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that if a set $X \subseteq \Z^2$ weakly self-assembles at
temperature 1 in a deterministic tile assembly system satisfying a natural
condition known as \emph{pumpability}, then $X$ is a finite union of
semi-doubly periodic sets. This shows that only the most simple of infinite
shapes and patterns can be constructed using pumpable temperature 1 tile
assembly systems, and gives evidence for the thesis that temperature 2 or
higher is required to carry out general-purpose computation in a tile assembly
system. Finally, we show that general-purpose computation \emph{is} possible at
temperature 1 if negative glue strengths are allowed in the tile assembly
model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1878</identifier>
 <datestamp>2009-03-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1878</id><created>2009-03-10</created><authors><author><keyname>Mindolin</keyname><forenames>Denis</forenames></author><author><keyname>Chomicki</keyname><forenames>Jan</forenames></author></authors><title>Contracting preference relations for database applications</title><categories>cs.AI cs.DB</categories><comments>44 pages, 15 figures, submitted to the Special Issue of AIJ on
  Preferences</comments><acm-class>I.2.4; H.2.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The binary relation framework has been shown to be applicable to many
real-life preference handling scenarios. Here we study preference contraction:
the problem of discarding selected preferences. We argue that the property of
minimality and the preservation of strict partial orders are crucial for
contractions. Contractions can be further constrained by specifying which
preferences should be protected. We consider two classes of preference
relations: finite and finitely representable. We present algorithms for
computing minimal and preference-protecting minimal contractions for finite as
well as finitely representable preference relations. We study relationships
between preference change in the binary relation framework and belief change in
the belief revision theory. We also introduce some preference query
optimization techniques which can be used in the presence of contraction. We
evaluate the proposed algorithms experimentally and present the results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1904</identifier>
 <datestamp>2010-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1904</id><created>2009-03-11</created><authors><author><keyname>Laumann</keyname><forenames>C. R.</forenames></author><author><keyname>Moessner</keyname><forenames>R.</forenames></author><author><keyname>Scardicchio</keyname><forenames>A.</forenames></author><author><keyname>Sondhi</keyname><forenames>S. L.</forenames></author></authors><title>Phase transitions and random quantum satisfiability</title><categories>quant-ph cond-mat.dis-nn cond-mat.stat-mech cs.CC</categories><comments>9 pages, 3 figures</comments><journal-ref>Quant. Inf. and Comp. (2010) vol. 10 (1) 1 pp. 0001-0015</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Alongside the effort underway to build quantum computers, it is important to
better understand which classes of problems they will find easy and which
others even they will find intractable. We study random ensembles of the
QMA$_1$-complete quantum satisfiability (QSAT) problem introduced by Bravyi.
QSAT appropriately generalizes the NP-complete classical satisfiability (SAT)
problem. We show that, as the density of clauses/projectors is varied, the
ensembles exhibit quantum phase transitions between phases that are satisfiable
and unsatisfiable. Remarkably, almost all instances of QSAT for any hypergraph
exhibit the same dimension of the satisfying manifold. This establishes the
QSAT decision problem as equivalent to a, potentially new, graph theoretic
problem and that the hardest typical instances are likely to be localized in a
bounded range of clause density.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1945</identifier>
 <datestamp>2009-03-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1945</id><created>2009-03-11</created><authors><author><keyname>Payar&#xf3;</keyname><forenames>M.</forenames></author><author><keyname>Palomar</keyname><forenames>D. P.</forenames></author></authors><title>Hessian and concavity of mutual information, differential entropy, and
  entropy power in linear vector Gaussian channels</title><categories>cs.IT math.IT</categories><comments>33 pages, 2 figures. A shorter version of this paper is to appear in
  IEEE Transactions on Information Theory</comments><msc-class>94A15; 94A05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Within the framework of linear vector Gaussian channels with arbitrary
signaling, closed-form expressions for the Jacobian of the minimum mean square
error and Fisher information matrices with respect to arbitrary parameters of
the system are calculated in this paper. Capitalizing on prior research where
the minimum mean square error and Fisher information matrices were linked to
information-theoretic quantities through differentiation, closed-form
expressions for the Hessian of the mutual information and the differential
entropy are derived. These expressions are then used to assess the concavity
properties of mutual information and differential entropy under different
channel conditions and also to derive a multivariate version of the entropy
power inequality due to Costa.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1952</identifier>
 <datestamp>2009-03-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1952</id><created>2009-03-11</created><authors><author><keyname>Gao</keyname><forenames>Xiqi</forenames></author><author><keyname>Jiang</keyname><forenames>Bin</forenames></author><author><keyname>Li</keyname><forenames>Xiao</forenames></author><author><keyname>Gershman</keyname><forenames>Alex B.</forenames></author><author><keyname>McKay</keyname><forenames>Matthew R.</forenames></author></authors><title>Statistical Eigenmode Transmission over Jointly-Correlated MIMO Channels</title><categories>cs.IT math.IT</categories><comments>32 pages, 6 figures, to appear in IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate MIMO eigenmode transmission using statistical channel state
information at the transmitter. We consider a general jointly-correlated MIMO
channel model, which does not require separable spatial correlations at the
transmitter and receiver. For this model, we first derive a closed-form tight
upper bound for the ergodic capacity, which reveals a simple and interesting
relationship in terms of the matrix permanent of the eigenmode channel coupling
matrix and embraces many existing results in the literature as special cases.
Based on this closed-form and tractable upper bound expression, we then employ
convex optimization techniques to develop low-complexity power allocation
solutions involving only the channel statistics. Necessary and sufficient
optimality conditions are derived, from which we develop an iterative
water-filling algorithm with guaranteed convergence. Simulations demonstrate
the tightness of the capacity upper bound and the near-optimal performance of
the proposed low-complexity transmitter optimization approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1953</identifier>
 <datestamp>2009-03-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1953</id><created>2009-03-11</created><authors><author><keyname>Cate</keyname><forenames>Balder ten</forenames></author><author><keyname>Chiticariu</keyname><forenames>Laura</forenames></author><author><keyname>Kolaitis</keyname><forenames>Phokion</forenames></author><author><keyname>Tan</keyname><forenames>Wang-Chiew</forenames></author></authors><title>Laconic schema mappings: computing core universal solutions by means of
  SQL queries</title><categories>cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new method for computing core universal solutions in data
exchange settings specified by source-to-target dependencies, by means of SQL
queries. Unlike previously known algorithms, which are recursive in nature, our
method can be implemented directly on top of any DBMS. Our method is based on
the new notion of a laconic schema mapping. A laconic schema mapping is a
schema mapping for which the canonical universal solution is the core universal
solution. We give a procedure by which every schema mapping specified by FO s-t
tgds can be turned into a laconic schema mapping specified by FO s-t tgds that
may refer to a linear order on the domain of the source instance. We show that
our results are optimal, in the sense that the linear order is necessary and
the method cannot be extended to schema mapping involving target constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1967</identifier>
 <datestamp>2009-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1967</id><created>2009-03-11</created><updated>2009-09-09</updated><authors><author><keyname>Prasad</keyname><forenames>K.</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>Network error correction for unit-delay, memory-free networks using
  convolutional codes</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A single source network is said to be memory-free if all of the internal
nodes (those except the source and the sinks) do not employ memory but merely
send linear combinations of the symbols received at their incoming edges on
their outgoing edges. In this work, we introduce network-error correction for
single source, acyclic, unit-delay, memory-free networks with coherent network
coding for multicast. A convolutional code is designed at the source based on
the network code in order to correct network-errors that correspond to any of a
given set of error patterns, as long as consecutive errors are separated by a
certain interval which depends on the convolutional code selected. Bounds on
this interval and the field size required for constructing the convolutional
code with the required free distance are also obtained. We illustrate the
performance of convolutional network error correcting codes (CNECCs) designed
for the unit-delay networks using simulations of CNECCs on an example network
under a probabilistic error model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1972</identifier>
 <datestamp>2009-03-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1972</id><created>2009-03-11</created><authors><author><keyname>Gajic</keyname><forenames>Vojislav</forenames><affiliation>EPFL</affiliation></author><author><keyname>Huang</keyname><forenames>Jianwei</forenames><affiliation>CUHK</affiliation></author><author><keyname>Rimoldi</keyname><forenames>Bixio</forenames><affiliation>EPFL</affiliation></author></authors><title>On Competing Wireless Service Providers</title><categories>cs.IT cs.GT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a situation where wireless service providers compete for
heterogenous wireless users. The users differ in their willingness to pay as
well as in their individual channel gains. We prove existence and uniqueness of
the Nash equilibrium for the competition of two service providers, for a
generic channel model. Interestingly, the competition of two providers leads to
a globally optimal outcome. We extend some of the results to the case where
more than two providers are competing. Finally, we provide numerical examples
that illustrate the effects of various parameters on the Nash equilibrium.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2015</identifier>
 <datestamp>2009-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2015</id><created>2009-03-11</created><updated>2009-06-29</updated><authors><author><keyname>Ning</keyname><forenames>Kang</forenames></author></authors><title>Deposition and Extension Approach to Find Longest Common Subsequence for
  Multiple Sequences</title><categories>cs.DS cs.DM math.CO</categories><comments>25 pages, 6 figures. Ready to be submitted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of finding the longest common subsequence (LCS) for a set of
sequences is a very interesting and challenging problem in computer science.
This problem is NP-complete, but because of its importance, many heuristic
algorithms have been proposed, such as Long Run algorithm and Expansion
algorithm.
  However, the performance of many current heuristic algorithms deteriorates
fast when the number of sequences and sequence length increase. In this paper,
we have proposed a post process heuristic algorithm for the LCS problem, the
Deposition and Extension algorithm (DEA). This algorithm first generates common
subsequence by the process of sequences deposition, and then extends this
common subsequence. The algorithm is proven to generate Common Subsequences
(CSs) with guaranteed lengths. The experiments show that the results of DEA
algorithm are better than those of Long Run and Expansion algorithm, especially
on many long sequences. The algorithm also has superior efficiency both in time
and space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2016</identifier>
 <datestamp>2009-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2016</id><created>2009-03-11</created><updated>2009-09-18</updated><authors><author><keyname>Hernando</keyname><forenames>Fernando</forenames></author><author><keyname>McGuire</keyname><forenames>Gary</forenames></author></authors><title>Proof of a Conjecture on the Sequence of Exceptional Numbers,
  Classifying Cyclic Codes and APN Functions</title><categories>cs.IT math.AG math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove a conjecture that classifies exceptional numbers. This conjecture
arises in two different ways, from cryptography and from coding theory. An odd
integer $t\geq 3$ is said to be exceptional if $f(x)=x^t$ is APN (Almost
Perfect Nonlinear) over $\mathbb{F}_{2^n}$ for infinitely many values of $n$.
Equivalently, $t$ is exceptional if the binary cyclic code of length $2^n-1$
with two zeros $\omega, \omega^t$ has minimum distance 5 for infinitely many
values of $n$. The conjecture we prove states that every exceptional number has
the form $2^i+1$ or $4^i-2^i+1$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2071</identifier>
 <datestamp>2014-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2071</id><created>2009-03-12</created><updated>2009-06-29</updated><authors><author><keyname>Kish</keyname><forenames>Laszlo B.</forenames></author><author><keyname>Horvath</keyname><forenames>Tamas</forenames></author></authors><title>Notes on Recent Approaches Concerning the
  Kirchhoff-Law-Johnson-Noise-based Secure Key Exchange</title><categories>physics.gen-ph cs.CR physics.class-ph</categories><comments>Accepted for publication in Physics Letters A on May 29, 2009. In the
  present version, DOI and acceptance info is added in the pdf file, too</comments><journal-ref>Physics Letters A 373 (2009) 2858-2868</journal-ref><doi>10.1016/j.physleta.2009.05.077</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We critically analyze the results and claims in [Physics Letters A 373 (2009)
901-904].
  We show that the strong security leak appeared in the simulations is only an
artifact and not caused by &quot;multiple reflections&quot;. Since no wave modes exist at
cable length of 5% of the shortest wavelength of the signal, no wave is present
to reflect it.
  In the high wave impedance limit, the conditions used in the simulations are
heavily unphysical (requiring cable diameters up to 28000 times greater than
the measured size of the known universe) and the results are modeling artifacts
due to the unphysical values.
  At the low cable impedance limit, the observed artifacts are due to violating
the recommended (and tested) conditions by neglecting the cable capacitance
restrictions and using about 100 times longer cable than recommended without
cable capacitance compensation arrangement.
  We implement and analyze the general circuitry of Liu's circulator and
confirm that they are conceptually secure against passive attacks. We introduce
an asymmetric, more robust version without feedback loop. Then we crack all
these systems by an active attack: a circulator-based man-in-the middle attack.
  Finally, we analyze the proposed method to increase security by dropping only
high-risk bits. We point out the differences between different types of
high-risk bits and show the shortage of this strategy for some simple key
exchange protocols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2100</identifier>
 <datestamp>2009-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2100</id><created>2009-03-12</created><updated>2009-10-20</updated><authors><author><keyname>Lyaudet</keyname><forenames>Laurent</forenames><affiliation>LIP</affiliation></author><author><keyname>Mazoit</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>LaBRI</affiliation></author><author><keyname>Thomasse</keyname><forenames>Stephan</forenames><affiliation>LIRMM</affiliation></author></authors><title>Partitions versus sets : a case of duality</title><categories>cs.DM</categories><proxy>ccsd hal-00345894</proxy><journal-ref>European Journal of Combinatorics (2009) 1-7</journal-ref><doi>10.1016/j.ejc.2009.09.004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a recent paper, Amini et al. introduce a general framework to prove
duality theorems between special decompositions and their dual combinatorial
object. They thus unify all known ad-hoc proofs in one single theorem. While
this unification process is definitely good, their main theorem remains quite
technical and does not give a real insight of why some decompositions admit
dual objects and why others do not. The goal of this paper is both to
generalise a little this framework and to give an enlightening simple proof of
its central theorem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2101</identifier>
 <datestamp>2010-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2101</id><created>2009-03-12</created><updated>2010-08-27</updated><authors><author><keyname>Duchamp</keyname><forenames>G&#xe9;rard Henry Edmond</forenames><affiliation>LIPN</affiliation></author><author><keyname>Tollu</keyname><forenames>Christophe</forenames><affiliation>LIPN</affiliation></author><author><keyname>Penson</keyname><forenames>K. A.</forenames><affiliation>LPTMC</affiliation></author><author><keyname>Koshevoy</keyname><forenames>Gleb</forenames><affiliation>CEMI</affiliation></author></authors><title>Combinatorial Deformations of Algebras: Twisting and Perturbations</title><categories>cs.SC math-ph math.CO math.MP</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The framework used to prove the multiplicative law deformation of the algebra
of Feynman-Bender diagrams is a \textit{twisted shifted dual law} (in fact,
twice). We give here a clear interpretation of its two parameters. The crossing
parameter is a deformation of the tensor structure whereas the superposition
parameters is a perturbation of the shuffle coproduct of Hoffman type which, in
turn, can be interpreted as the diagonal restriction of a superproduct. Here,
we systematically detail these constructions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2108</identifier>
 <datestamp>2009-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2108</id><created>2009-03-12</created><authors><author><keyname>Margenstern</keyname><forenames>Maurice</forenames></author></authors><title>A new universal cellular automaton on the ternary heptagrid</title><categories>cs.FL cs.CG</categories><comments>35 pages, 33 figures</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we construct a new weakly universal cellular automaton on the
ternary heptagrid. The previous result, obtained by the same author and Y. Song
required six states only. This time, the number of states is four. This is the
best result up to date for cellular automata in the hyperbolic plane.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2119</identifier>
 <datestamp>2009-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2119</id><created>2009-03-12</created><authors><author><keyname>Fischer</keyname><forenames>Matthias</forenames></author><author><keyname>J&#xe4;hn</keyname><forenames>Claudius</forenames></author><author><keyname>Ziegler</keyname><forenames>Martin</forenames></author></authors><title>Adaptive Mesh Approach for Predicting Algorithm Behavior with
  Application to Visibility Culling in Computer Graphics</title><categories>cs.PF cs.GR</categories><acm-class>C.4; I.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a concise approximate description, and a method for efficiently
obtaining this description, via adaptive random sampling of the performance
(running time, memory consumption, or any other profileable numerical quantity)
of a given algorithm on some low-dimensional rectangular grid of inputs. The
formal correctness is proven under reasonable assumptions on the algorithm
under consideration; and the approach's practical benefit is demonstrated by
predicting for which observer positions and viewing directions an occlusion
culling algorithm yields a net performance benefit or loss compared to a simple
brute force renderer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2134</identifier>
 <datestamp>2009-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2134</id><created>2009-03-12</created><authors><author><keyname>Chabchoub</keyname><forenames>Yousra</forenames></author><author><keyname>Fricker</keyname><forenames>Christine</forenames></author><author><keyname>Mohamed</keyname><forenames>Hanene</forenames></author></authors><title>Analysis of a Bloom Filter Algorithm via the Supermarket Model</title><categories>cs.DM cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with the problem of identifying elephants in the Internet
Traffic. The aim is to analyze a new adaptive algorithm based on a Bloom
Filter. This algorithm uses a so-called min-rule which can be described as in
the supermarket model. This model consists of joining the shortest queue among
d queues selected at random in a large number of m queues. In case of equality,
one of the shortest queues is chosen at random. An analysis of a simplified
model gives an insight of the error generated by the algorithm on the
estimation of the number of the elephants. The main conclusion is that, as m
gets large, there is a deterministic limit for the empirical distribution of
the filter counters. Limit theorems are proved and the limit is identified. It
depends on key parameters. The condition for the algorithm to perform well is
discussed. Theoretical results are validated by experiments on a traffic trace
from France Telecom and by simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2158</identifier>
 <datestamp>2009-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2158</id><created>2009-03-12</created><authors><author><keyname>Gerbracht</keyname><forenames>Eberhard H. -A.</forenames></author></authors><title>Supernodal Analysis Revisited</title><categories>cs.SC cs.CE cs.DM</categories><comments>V1: documentclass IEEEtran, 5 pages, 6 figures. Re-release of the
  printed version, with some minor typographical errors corrected, abstract
  rewritten, and short CV according to IEEE standards added</comments><acm-class>I.1; J.2</acm-class><journal-ref>SMACD'04 Proceedings of the International Workshop on Symbolic
  Methods and Applications in Circuit Design, Wroclaw, Poland, 23-24 September
  2004; pp. 113-116</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we show how to extend the known algorithm of nodal analysis in
such a way that, in the case of circuits without nullors and controlled sources
(but allowing for both, independent current and voltage sources), the system of
nodal equations describing the circuit is partitioned into one part, where the
nodal variables are explicitly given as linear combinations of the voltage
sources and the voltages of certain reference nodes, and another, which
contains the node variables of these reference nodes only and which moreover
can be read off directly from the given circuit. Neither do we need
preparational graph transformations, nor do we need to introduce additional
current variables (as in MNA). Thus this algorithm is more accessible to
students, and consequently more suitable for classroom presentations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2168</identifier>
 <datestamp>2009-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2168</id><created>2009-03-12</created><authors><author><keyname>Triska</keyname><forenames>Markus</forenames></author><author><keyname>Neumerkel</keyname><forenames>Ulrich</forenames></author><author><keyname>Wielemaker</keyname><forenames>Jan</forenames></author></authors><title>Better Termination for Prolog with Constraints</title><categories>cs.PL cs.SE</categories><comments>Paper presented at the 18th Workshop on Logic-based Methods in
  Programming Environments (WLPE2008) (Report-No: WLPE/2008). Paper submitted
  by a co-editor of the Workshop proceedings</comments><report-no>WLPE/2008/02</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Termination properties of actual Prolog systems with constraints are fragile
and difficult to analyse. The lack of the occurs-check, moded and overloaded
arithmetical evaluation via is/2 and the occasional nontermination of finite
domain constraints are all sources for invalidating termination results
obtained by current termination analysers that rely on idealized assumptions.
In this paper, we present solutions to address these problems on the level of
the underlying Prolog system. Improved unification modes meet the requirements
of norm based analysers by offering dynamic occurs-check detection. A
generalized finite domain solver overcomes the shortcomings of conventional
arithmetic without significant runtime overhead. The solver offers unbounded
domains, yet propagation always terminates. Our work improves Prolog's
termination and makes Prolog a more reliable target for termination and type
analysis. It is part of SWI-Prolog since version 5.6.50.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2171</identifier>
 <datestamp>2009-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2171</id><created>2009-03-12</created><updated>2009-06-03</updated><authors><author><keyname>Ferraiolo</keyname><forenames>David F.</forenames></author><author><keyname>Kuhn</keyname><forenames>D. Richard</forenames></author></authors><title>Role-Based Access Controls</title><categories>cs.CR</categories><comments>pp. 554 - 563</comments><acm-class>D.4.6</acm-class><journal-ref>15th National Computer Security Conference, Baltimore, MD. October
  13-16, 1992</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While Mandatory Access Controls (MAC) are appropriate for multilevel secure
military applications, Discretionary Access Controls (DAC) are often perceived
as meeting the security processing needs of industry and civilian government.
This paper argues that reliance on DAC as the principal method of access
control is unfounded and inappropriate for many commercial and civilian
government organizations. The paper describes a type of non-discretionary
access control - role-based access control (RBAC) - that is more central to the
secure processing needs of non-military systems than DAC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2174</identifier>
 <datestamp>2010-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2174</id><created>2009-03-12</created><authors><author><keyname>Leshem</keyname><forenames>Amir</forenames></author><author><keyname>Zehavi</keyname><forenames>Ephi</forenames></author></authors><title>Game theory and the frequency selective interference channel - A
  tutorial</title><categories>cs.IT cs.GT math.IT</categories><journal-ref>IEEE Signal Processing Magazine. Special issue on applications of
  game theory in signal processing and communications. Volume 26, Issue 4,
  pages 28-40. Sep. 2009</journal-ref><doi>10.1109/MSP.2009.933372</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper provides a tutorial overview of game theoretic techniques used for
communication over frequency selective interference channels. We discuss both
competitive and cooperative techniques.
  Keywords: Game theory, competitive games, cooperative games, Nash
Equilibrium, Nash bargaining solution, Generalized Nash games, Spectrum
optimization, distributed coordination, interference channel, multiple access
channel, iterative water-filling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2177</identifier>
 <datestamp>2010-10-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2177</id><created>2009-03-12</created><updated>2010-10-21</updated><authors><author><keyname>Pauly</keyname><forenames>Arno</forenames></author></authors><title>On the (semi)lattices induced by continuous reducibilities</title><categories>cs.LO</categories><comments>this version of the paper is outdated, please consult the journal
  version</comments><acm-class>F.4.1</acm-class><journal-ref>Mathematical Logic Quarterly, 56(5): 488--502, 2010</journal-ref><doi>10.1002/malq.200910104</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Continuous reducibilities are a proven tool in computable analysis, and have
applications in other fields such as constructive mathematics or reverse
mathematics. We study the order-theoretic properties of several variants of the
two most important definitions, and especially introduce suprema for them. The
suprema are shown to commutate with several characteristic numbers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2188</identifier>
 <datestamp>2009-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2188</id><created>2009-03-12</created><authors><author><keyname>Ceruelo</keyname><forenames>Victor Pablos</forenames></author><author><keyname>Munoz-Hernandez</keyname><forenames>Susana</forenames></author><author><keyname>Strass</keyname><forenames>Hannes</forenames></author></authors><title>Rfuzzy framework</title><categories>cs.PL cs.LO</categories><comments>Paper presented at the 18th Workshop on Logic-based Methods in
  Programming Environments (WLPE2008) (Report-No: WLPE/2008). Paper submitted
  by a co-editor of the Workshop proceedings</comments><report-no>WLPE/2008/01</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fuzzy reasoning is a very productive research field that during the last
years has provided a number of theoretical approaches and practical
implementation prototypes. Nevertheless, the classical implementations, like
Fril, are not adapted to the latest formal approaches, like multi-adjoint logic
semantics. Some promising implementations, like Fuzzy Prolog, are so general
that the regular user/programmer does not feel comfortable because either
representation of fuzzy concepts is complex or the results difficult to
interpret. In this paper we present a modern framework, Rfuzzy, that is
modelling multi-adjoint logic. It provides some extensions as default values
(to represent missing information, even partial default values) and typed
variables. Rfuzzy represents the truth value of predicates through facts, rules
and functions. Rfuzzy answers queries with direct results (instead of
constraints) and it is easy to use for any person that wants to represent a
problem using fuzzy reasoning in a simple way (by using the classical
representation with real numbers).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2199</identifier>
 <datestamp>2009-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2199</id><created>2009-03-12</created><authors><author><keyname>Gomez-Zamalloa</keyname><forenames>Miguel</forenames></author><author><keyname>Albert</keyname><forenames>Elvira</forenames></author><author><keyname>Puebla</keyname><forenames>German</forenames></author></authors><title>On the Generation of Test Data for Prolog by Partial Evaluation</title><categories>cs.PL cs.SE</categories><comments>Paper presented at the 18th Workshop on Logic-based Methods in
  Programming Environments (WLPE2008) (Report-No: WLPE/2008). Paper submitted
  by a co-editor of the Workshop proceedings</comments><report-no>WLPE/2008/06</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent work, we have proposed an approach to Test Data Generation (TDG) of
imperative bytecode by partial evaluation (PE) of CLP which consists in two
phases: (1) the bytecode program is first transformed into an equivalent CLP
program by means of interpretive compilation by PE, (2) a second PE is
performed in order to supervise the generation of test-cases by execution of
the CLP decompiled program. The main advantages of TDG by PE include
flexibility to handle new coverage criteria, the possibility to obtain
test-case generators and its simplicity to be implemented. The approach in
principle can be directly applied for TDG of any imperative language. However,
when one tries to apply it to a declarative language like Prolog, we have found
as a main difficulty the generation of test-cases which cover the more complex
control flow of Prolog. Essentially, the problem is that an intrinsic feature
of PE is that it only computes non-failing derivations while in TDG for Prolog
it is essential to generate test-cases associated to failing computations.
Basically, we propose to transform the original Prolog program into an
equivalent Prolog program with explicit failure by partially evaluating a
Prolog interpreter which captures failing derivations w.r.t. the input program.
Another issue that we discuss in the paper is that, while in the case of
bytecode the underlying constraint domain only manipulates integers, in Prolog
it should properly handle the symbolic data manipulated by the program. The
resulting scheme is of interest for bringing the advantages which are inherent
in TDG by PE to the field of logic programming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2202</identifier>
 <datestamp>2009-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2202</id><created>2009-03-12</created><authors><author><keyname>Leuschel</keyname><forenames>Michael</forenames></author><author><keyname>Tamarit</keyname><forenames>Salvador</forenames></author><author><keyname>Vidal</keyname><forenames>German</forenames></author></authors><title>Improving Size-Change Analysis in Offline Partial Evaluation</title><categories>cs.PL</categories><comments>Paper presented at the 18th Workshop on Logic-based Methods in
  Programming Environments (WLPE2008) (Report-No: WLPE/2008). Paper submitted
  by a co-editor of the Workshop proceedings</comments><report-no>WLPE/2008/07</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Some recent approaches for scalable offline partial evaluation of logic
programs include a size-change analysis for ensuring both so called local and
global termination. In this work|inspired by experimental evaluation|we
introduce several improvements that may increase the accuracy of the analysis
and, thus, the quality of the associated specialized programs. We aim to
achieve this while maintaining the same complexity and scalability of the
recent works.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2203</identifier>
 <datestamp>2009-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2203</id><created>2009-03-12</created><authors><author><keyname>Sabbag</keyname><forenames>Erez</forenames></author><author><keyname>Merhav</keyname><forenames>Neri</forenames></author></authors><title>Achievable Error Exponents for Channel with Side Information - Erasure
  and List Decoding</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Trans. Inform. Theory, March 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a decoder with an erasure option and a variable size list decoder
for channels with non-casual side information at the transmitter. First,
universally achievable error exponents are offered for decoding with an erasure
option using a parameterized decoder in the spirit of Csisz\'{a}r and
K\&quot;{o}rner's decoder. Then, the proposed decoding rule is generalized by
extending the range of its parameters to allow variable size list decoding.
This extension gives a unified treatment for erasure/list decoding. Exponential
bounds on the probability of list error and the average number of incorrect
messages on the list are given. Relations to Forney's and Csisz\'{a}r and
K\&quot;{o}rner's decoders for discrete memoryless channel are discussed. These
results are obtained by exploring a random binning code with conditionally
constant composition codewords proposed by Moulin and Wang, but with a
different decoding rule.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2205</identifier>
 <datestamp>2009-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2205</id><created>2009-03-12</created><authors><author><keyname>Lopez-Fraguas</keyname><forenames>Francisco Javier</forenames></author><author><keyname>Rodriguez-Hortala</keyname><forenames>Juan</forenames></author><author><keyname>Sanchez-Hernandez</keyname><forenames>Jaime</forenames></author></authors><title>A Lightweight Combination of Semantics for Non-deterministic Functions</title><categories>cs.PL</categories><comments>Paper presented at the 18th Workshop on Logic-based Methods in
  Programming Environments (WLPE2008) (Report-No: WLPE/2008). Paper submitted
  by a co-editor of the Workshop proceedings</comments><report-no>WLPE/2008/08</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The use of non-deterministic functions is a distinctive feature of modern
functional logic languages. The semantics commonly adopted is call-time choice,
a notion that at the operational level is related to the sharing mechanism of
lazy evaluation in functional languages. However, there are situations where
run-time choice, closer to ordinary rewriting, is more appropriate. In this
paper we propose an extension of existing call-time choice based languages, to
provide support for run-time choice in localized parts of a program. The
extension is remarkably simple at three relevant levels: syntax, formal
operational calculi and implementation, which is based on the system Toy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2207</identifier>
 <datestamp>2009-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2207</id><created>2009-03-12</created><authors><author><keyname>Adachi</keyname><forenames>Yoshihiro</forenames></author></authors><title>Prolog Visualization System Using Logichart Diagrams</title><categories>cs.PL cs.HC cs.SE</categories><comments>Paper presented at the 18th Workshop on Logic-based Methods in
  Programming Environments (WLPE2008, arXiv:0903.1598). Paper submitted by a
  co-editor of the Workshop proceedings</comments><report-no>WLPE/2008/03</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We have developed a Prolog visualization system that is intended to support
Prolog programming education. The system uses Logichart diagrams to visualize
Prolog programs. The Logichart diagram is designed to visualize the Prolog
execution flow intelligibly and to enable users to easily correlate the Prolog
clauses with its parts. The system has the following functions. (1) It visually
traces Prolog execution (goal calling, success, and failure) on the Logichart
diagram. (2) Dynamic change in a Prolog program by calling extra-logical
predicates, such as `assertz' and `retract', is visualized in real time. (3)
Variable substitution processes are displayed in a text widget in real time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2226</identifier>
 <datestamp>2009-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2226</id><created>2009-03-12</created><updated>2009-05-01</updated><authors><author><keyname>Ak&#xe7;aba</keyname><forenames>Cemal</forenames></author><author><keyname>B&#xf6;lcskei</keyname><forenames>Helmut</forenames></author></authors><title>On the achievable diversity-multiplexing tradeoff in interference
  channels</title><categories>cs.IT math.IT</categories><comments>5 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze two-user single-antenna fading interference channels with perfect
receive channel state information (CSI) and no transmit CSI. For the case of
very strong interference, we prove that decoding interference while treating
the intended signal as noise, subtracting the result out, and then decoding the
desired signal, a process known as &quot;stripping&quot;, achieves the
diversity-multiplexing tradeoff (DMT) outer bound derived in Akuiyibo and
Leveque, Int. Zurich Seminar on Commun., 2008. The proof is constructive in the
sense that it provides corresponding code design criteria for DMT optimality.
For general interference levels, we compute the DMT of a fixed-power-split Han
and Kobayashi type superposition coding scheme, provide design criteria for the
corresponding superposition codes, and find that this scheme is DMT-optimal for
certain multiplexing rates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2232</identifier>
 <datestamp>2012-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2232</id><created>2009-03-12</created><updated>2012-01-30</updated><authors><author><keyname>Zhang</keyname><forenames>Fan</forenames></author><author><keyname>Pfister</keyname><forenames>Henry D.</forenames></author></authors><title>On the Iterative Decoding of High-Rate LDPC Codes With Applications in
  Compressed Sensing</title><categories>cs.IT math.IT</categories><comments>accepted by IEEE Trans. on IT</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the performance of $(j,k)$-regular low-density
parity-check (LDPC) codes with message-passing (MP) decoding algorithms in the
high-rate regime. In particular, we derive the high-rate scaling law for MP
decoding of LDPC codes on the binary erasure channel (BEC) and the $q$-ary
symmetric channel ($q$-SC). For the BEC, the density evolution (DE) threshold
of iterative decoding scales like $\Theta(k^{-1})$ and the critical stopping
ratio scales like $\Theta(k^{-j/(j-2)})$. For the $q$-SC, the DE threshold of
verification decoding depends on the details of the decoder and scales like
$\Theta(k^{-1})$ for one decoder.
  Using the fact that coding over large finite alphabets is very similar to
coding over the real numbers, the analysis of verification decoding is also
extended to the the compressed sensing (CS) of strictly-sparse signals. A DE
based approach is used to analyze the CS systems with randomized-reconstruction
guarantees. This leads to the result that strictly-sparse signals can be
reconstructed efficiently with high-probability using a constant oversampling
ratio (i.e., when the number of measurements scales linearly with the sparsity
of the signal). A stopping-set based approach is also used to get stronger
(e.g., uniform-in-probability) reconstruction guarantees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2243</identifier>
 <datestamp>2014-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2243</id><created>2009-03-12</created><updated>2014-09-22</updated><authors><author><keyname>Weinberger</keyname><forenames>Edward D.</forenames></author></authors><title>Pragmatic Information Rates, Generalizations of the Kelly Criterion, and
  Financial Market Efficiency</title><categories>cs.IT math.IT q-fin.PM q-fin.TR</categories><comments>Revised to clarify the text</comments><msc-class>94A17, 91G80</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is part of an ongoing investigation of &quot;pragmatic information&quot;,
defined in Weinberger (2002) as &quot;the amount of information actually used in
making a decision&quot;. Because a study of information rates led to the Noiseless
and Noisy Coding Theorems, two of the most important results of Shannon's
theory, we begin the paper by defining a pragmatic information rate, showing
that all of the relevant limits make sense, and interpreting them as the
improvement in compression obtained from using the correct distribution of
transmitted symbols.
  The first of two applications of the theory extends the information theoretic
analysis of the Kelly Criterion, and its generalization, the horse race, to a
series of races where the stochastic process of winning horses, payoffs, and
strategies depend on some stationary process, including, but not limited to the
history of previous races. If the bettor is receiving messages (side
information) about the probability distribution of winners, the doubling rate
of the bettor's winnings is bounded by the pragmatic information of the
messages.
  A second application is to the question of market efficiency. An efficient
market is, by definition, a market in which the pragmatic information of the
&quot;tradable past&quot; with respect to current prices is zero. Under this definition,
markets whose returns are characterized by a GARCH(1,1) process cannot be
efficient.
  Finally, a pragmatic informational analogue to Shannon's Noisy Coding Theorem
suggests that a cause of market inefficiency is that the underlying
fundamentals are changing so fast that the price discovery mechanism simply
cannot keep up. This may happen most readily in the run-up to a financial
bubble, where investors' willful ignorance degrade the information processing
capabilities of the market.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2251</identifier>
 <datestamp>2009-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2251</id><created>2009-03-12</created><authors><author><keyname>Prantl</keyname><forenames>Adrian</forenames></author><author><keyname>Knoop</keyname><forenames>Jens</forenames></author><author><keyname>Schordan</keyname><forenames>Markus</forenames></author><author><keyname>Triska</keyname><forenames>Markus</forenames></author></authors><title>Constraint solving for high-level WCET analysis</title><categories>cs.PL cs.LO</categories><comments>Paper presented at the 18th Workshop on Logic-based Methods in
  Programming Environments (WLPE2008) (Report-No: WLPE/2008). Paper submitted
  by a co-editor of the Workshop proceedings</comments><report-no>WLPE/2008/05</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The safety of our day-to-day life depends crucially on the correct
functioning of embedded software systems which control the functioning of more
and more technical devices. Many of these software systems are time-critical.
Hence, computations performed need not only to be correct, but must also be
issued in a timely fashion. Worst case execution time (WCET) analysis is
concerned with computing tight upper bounds for the execution time of a system
in order to provide formal guarantees for the proper timing behaviour of a
system. Central for this is to compute safe and tight bounds for loops and
recursion depths. In this paper, we highlight the TuBound approach to this
challenge at whose heart is a constraint logic based approach for loop
analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2252</identifier>
 <datestamp>2009-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2252</id><created>2009-03-12</created><authors><author><keyname>Bendisposto</keyname><forenames>Jens</forenames></author><author><keyname>Endrijautzki</keyname><forenames>Ian</forenames></author><author><keyname>Leuschel</keyname><forenames>Michael</forenames></author><author><keyname>Schneider</keyname><forenames>David</forenames></author></authors><title>A Semantics-Aware Editing Environment for Prolog in Eclipse</title><categories>cs.PL cs.HC cs.SE</categories><comments>Paper presented at the 18th Workshop on Logic-based Methods in
  Programming Environments (WLPE2008) (Report-No: WLPE/2008). Paper submitted
  by a co-editor of the Workshop proceedings</comments><report-no>WLPE/2008/04</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a Prolog plugin for Eclipse based upon BE4, and
providing many features such as semantic-aware syntax highlighting, outline
view, error marking, content assist, hover information, documentation
generation, and quick fixes. The plugin makes use of a Java parser for full
Prolog with an integrated Prolog engine, and can be extended with further
semantic analyses, e.g., based on abstract interpretation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2265</identifier>
 <datestamp>2009-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2265</id><created>2009-03-13</created><authors><author><keyname>Harren</keyname><forenames>Rolf</forenames></author><author><keyname>van Stee</keyname><forenames>Rob</forenames></author></authors><title>An Absolute 2-Approximation Algorithm for Two-Dimensional Bin Packing</title><categories>cs.DS cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of packing rectangles into bins that are unit
squares, where the goal is to minimize the number of bins used. All rectangles
have to be packed non-overlapping and orthogonal, i.e., axis-parallel. We
present an algorithm for this problem with an absolute worst-case ratio of 2,
which is optimal provided P != NP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2272</identifier>
 <datestamp>2009-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2272</id><created>2009-03-13</created><authors><author><keyname>Lee</keyname><forenames>Sang-Yong</forenames></author><author><keyname>Ortega</keyname><forenames>Antonio</forenames></author></authors><title>A Novel Approach for Compression of Images Captured using Bayer Color
  Filter Arrays</title><categories>cs.MM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new approach for image compression in digital cameras, where the
goal is to achieve better quality at a given rate by using the characteristics
of a Bayer color filter array. Most digital cameras produce color images by
using a single CCD plate, so that each pixel in an image has only one color
component and therefore an interpolation method is needed to produce a full
color image. After the image processing stage, in order to reduce the memory
requirements of the camera, a lossless or lossy compression stage often
follows. But in this scheme, before decreasing redundancy through compression,
redundancy is increased in an interpolation stage. In order to avoid increasing
the redundancy before compression, we propose algorithms for image compression
in which the order of the compression and interpolation stages is reversed. We
introduce image transform algorithms, since non interpolated images cannot be
directly compressed with general image coders. The simulation results show that
our algorithm outperforms conventional methods with various color interpolation
methods in a wide range of compression ratios. Our proposed algorithm provides
not only better quality but also lower encoding complexity because the amount
of luminance data used is only half of that in conventional methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2278</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2278</id><created>2009-03-12</created><authors><author><keyname>Kash</keyname><forenames>Ian A.</forenames></author><author><keyname>Friedman</keyname><forenames>Eric J.</forenames></author><author><keyname>Halpern</keyname><forenames>Joseph Y.</forenames></author></authors><title>Manipulating Scrip Systems: Sybils and Collusion</title><categories>cs.GT</categories><comments>20 pages, 5 figures. To appear in the Proceedings of The First
  Conference on Auctions, Market Mechanisms and Their Applications (AMMA '09)</comments><doi>10.1007/978-3-642-03821-1_4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Game-theoretic analyses of distributed and peer-to-peer systems typically use
the Nash equilibrium solution concept, but this explicitly excludes the
possibility of strategic behavior involving more than one agent. We examine the
effects of two types of strategic behavior involving more than one agent,
sybils and collusion, in the context of scrip systems where agents provide each
other with service in exchange for scrip. Sybils make an agent more likely to
be chosen to provide service, which generally makes it harder for agents
without sybils to earn money and decreases social welfare. Surprisingly, in
certain circumstances it is possible for sybils to make all agents better off.
While collusion is generally bad, in the context of scrip systems it actually
tends to make all agents better off, not merely those who collude. These
results also provide insight into the effects of allowing agents to advertise
and loan money. While many extensions of Nash equilibrium have been proposed
that address collusion and other issues relevant to distributed and
peer-to-peer systems, our results show that none of them adequately address the
issues raised by sybils and collusion in scrip systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2282</identifier>
 <datestamp>2009-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2282</id><created>2009-03-12</created><authors><author><keyname>Kash</keyname><forenames>Ian A.</forenames></author><author><keyname>Friedman</keyname><forenames>Eric J.</forenames></author><author><keyname>Halpern</keyname><forenames>Joseph Y.</forenames></author></authors><title>Multiagent Learning in Large Anonymous Games</title><categories>cs.MA cs.GT cs.LG</categories><comments>8 pages, 2 figures. To Appear in Proceedings of the Eighth
  International Conference on Autonomous Agents and Multiagent Systems</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In large systems, it is important for agents to learn to act effectively, but
sophisticated multi-agent learning algorithms generally do not scale. An
alternative approach is to find restricted classes of games where simple,
efficient algorithms converge. It is shown that stage learning efficiently
converges to Nash equilibria in large anonymous games if best-reply dynamics
converge. Two features are identified that improve convergence. First, rather
than making learning more difficult, more agents are actually beneficial in
many settings. Second, providing agents with statistical information about the
behavior of others can significantly reduce the number of observations needed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2299</identifier>
 <datestamp>2013-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2299</id><created>2009-03-13</created><updated>2013-07-08</updated><authors><author><keyname>McAllester</keyname><forenames>David</forenames></author></authors><title>Differential Contrastive Divergence</title><categories>cs.LG</categories><comments>This paper was a rediscovery of known material</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been retracted.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2310</identifier>
 <datestamp>2010-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2310</id><created>2009-03-13</created><authors><author><keyname>Ning</keyname><forenames>Kang</forenames></author><author><keyname>Ng</keyname><forenames>Hoong Kee</forenames></author><author><keyname>Leong</keyname><forenames>Hon Wai</forenames></author></authors><title>Analysis of the Relationships among Longest Common Subsequences,
  Shortest Common Supersequences and Patterns and its application on Pattern
  Discovery in Biological Sequences</title><categories>cs.DS cs.DM cs.IR cs.OH q-bio.QM</categories><comments>Extended version of paper presented in IEEE BIBE 2006 submitted to
  journal for review</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For a set of mulitple sequences, their patterns,Longest Common Subsequences
(LCS) and Shortest Common Supersequences (SCS) represent different aspects of
these sequences profile, and they can all be used for biological sequence
comparisons and analysis. Revealing the relationship between the patterns and
LCS,SCS might provide us with a deeper view of the patterns of biological
sequences, in turn leading to better understanding of them. However, There is
no careful examinaton about the relationship between patterns, LCS and SCS. In
this paper, we have analyzed their relation, and given some lemmas. Based on
their relations, a set of algorithms called the PALS (PAtterns by Lcs and Scs)
algorithms are propsoed to discover patterns in a set of biological sequences.
These algorithms first generate the results for LCS and SCS of sequences by
heuristic, and consequently derive patterns from these results. Experiments
show that the PALS algorithms perform well (both in efficiency and in accuracy)
on a variety of sequences. The PALS approach also provides us with a solution
for transforming between the heuristic results of SCS and LCS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2315</identifier>
 <datestamp>2009-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2315</id><created>2009-03-13</created><updated>2009-04-29</updated><authors><author><keyname>Shi</keyname><forenames>Cuizhu</forenames></author><author><keyname>Ramamoorthy</keyname><forenames>Aditya</forenames></author></authors><title>Design and Analysis of E2RC Codes</title><categories>cs.IT cs.DM math.IT</categories><comments>To appear in IEEE Journal on Selected Areas in Communications,
  special issue on Capacity Approaching Codes, 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the design and analysis of the efficiently-encodable
rate-compatible ($E^2RC$) irregular LDPC codes proposed in previous work. In
this work we introduce semi-structured $E^2RC$-like codes and protograph
$E^2RC$ codes. EXIT chart based methods are developed for the design of
semi-structured $E^2RC$-like codes that allow us to determine near-optimal
degree distributions for the systematic part of the code while taking into
account the structure of the deterministic parity part, thus resolving one of
the open issues in the original construction. We develop a fast EXIT function
computation method that does not rely on Monte-Carlo simulations and can be
used in other scenarios as well. Our approach allows us to jointly optimize
code performance across the range of rates under puncturing. We then consider
protograph $E^2RC$ codes (that have a protograph representation) and propose
rules for designing a family of rate-compatible punctured protographs with low
thresholds. For both the semi-structured and protograph $E^2RC$ families we
obtain codes whose gap to capacity is at most 0.3 dB across the range of rates
when the maximum variable node degree is twenty.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2352</identifier>
 <datestamp>2009-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2352</id><created>2009-03-13</created><updated>2009-06-10</updated><authors><author><keyname>Gast</keyname><forenames>Nicolas</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes / LIG laboratoire d'Informatique de Grenoble</affiliation></author><author><keyname>Gaujal</keyname><forenames>Bruno</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes / LIG laboratoire d'Informatique de Grenoble</affiliation></author></authors><title>A Mean Field Approach for Optimization in Particles Systems and
  Applications</title><categories>math.PR cs.NI cs.PF</categories><proxy>ccsd inria-00368011</proxy><report-no>RR-6877</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the limit behavior of Markov Decision Processes
(MDPs) made of independent particles evolving in a common environment, when the
number of particles goes to infinity. In the finite horizon case or with a
discounted cost and an infinite horizon, we show that when the number of
particles becomes large, the optimal cost of the system converges almost surely
to the optimal cost of a discrete deterministic system (the ``optimal mean
field''). Convergence also holds for optimal policies. We further provide
insights on the speed of convergence by proving several central limits theorems
for the cost and the state of the Markov decision process with explicit
formulas for the variance of the limit Gaussian laws. Then, our framework is
applied to a brokering problem in grid computing. The optimal policy for the
limit deterministic system is computed explicitly. Several simulations with
growing numbers of processors are reported. They compare the performance of the
optimal policy of the limit system used in the finite case with classical
policies (such as Join the Shortest Queue) by measuring its asymptotic gain as
well as the threshold above which it starts outperforming classical policies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2353</identifier>
 <datestamp>2009-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2353</id><created>2009-03-13</created><authors><author><keyname>King</keyname><forenames>Andy</forenames></author></authors><title>Relations, Constraints and Abstractions: Using the Tools of Logic
  Programming in the Security Industry</title><categories>cs.PL</categories><comments>Paper presented as an invited talk at the 18th Workshop on
  Logic-based Methods in Programming Environments (WLPE2008) (Report-No:
  WLPE/2008). Paper submitted by a co-editor of the Workshop proceedings</comments><report-no>WLPE/2008/00</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Logic programming is sometimes described as relational programming: a
paradigm in which the programmer specifies and composes n-ary relations using
systems of constraints. An advanced logic programming environment will provide
tools that abstract these relations to transform, optimise, or even verify the
correctness of a logic program. This talk will show that these concepts, namely
relations, constraints and abstractions, turn out to also be important in the
reverse engineer process that underpins the discovery of bugs within the
security industry.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2361</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2361</id><created>2009-03-13</created><updated>2013-06-21</updated><authors><author><keyname>Tyukin</keyname><forenames>Ivan Y.</forenames></author><author><keyname>Steur</keyname><forenames>Erik</forenames></author><author><keyname>Nijmeijer</keyname><forenames>Henk</forenames></author><author><keyname>van Leeuwen</keyname><forenames>Cees</forenames></author></authors><title>Adaptive Observers and Parameter Estimation for a Class of Systems
  Nonlinear in the Parameters</title><categories>math.OC cs.SY math.DS q-bio.QM</categories><comments>Preliminary version is presented at the 17-th IFAC World Congress,
  6-11 Seoul, 2008</comments><msc-class>93B30, 93B07, 34D05, 34D45</msc-class><doi>10.1016/j.automatica.2013.05.008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of asymptotic reconstruction of the state and
parameter values in systems of ordinary differential equations. A solution to
this problem is proposed for a class of systems of which the unknowns are
allowed to be nonlinearly parameterized functions of state and time.
Reconstruction of state and parameter values is based on the concepts of weakly
attracting sets and non-uniform convergence and is subjected to persistency of
excitation conditions. In absence of nonlinear parametrization the resulting
observers reduce to standard estimation schemes. In this respect, the proposed
method constitutes a generalization of the conventional canonical adaptive
observer design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2382</identifier>
 <datestamp>2009-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2382</id><created>2009-03-13</created><authors><author><keyname>Berstel</keyname><forenames>Jean</forenames></author><author><keyname>Boasson</keyname><forenames>Luc</forenames></author><author><keyname>Carton</keyname><forenames>Olivier</forenames></author><author><keyname>Fagnot</keyname><forenames>Isabelle</forenames></author></authors><title>Infinite words without palindrome</title><categories>cs.DM</categories><comments>3 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that there exists an uniformly recurrent infinite word whose set of
factors is closed under reversal and which has only finitely many palindromic
factors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2410</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2410</id><created>2009-03-13</created><updated>2009-03-30</updated><authors><author><keyname>Marion</keyname><forenames>Jean-Yves</forenames></author></authors><title>On tiered small jump operators</title><categories>cs.CC cs.LO</categories><acm-class>F.2.0</acm-class><journal-ref>Logical Methods in Computer Science, Volume 5, Issue 1 (March 31,
  2009) lmcs:1146</journal-ref><doi>10.2168/LMCS-5(1:7)2009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Predicative analysis of recursion schema is a method to characterize
complexity classes like the class FPTIME of polynomial time computable
functions. This analysis comes from the works of Bellantoni and Cook, and
Leivant by data tiering. Here, we refine predicative analysis by using a
ramified Ackermann's construction of a non-primitive recursive function. We
obtain a hierarchy of functions which characterizes exactly functions, which
are computed in O(n^k) time over register machine model of computation. For
this, we introduce a strict ramification principle. Then, we show how to
diagonalize in order to obtain an exponential function and to jump outside
deterministic polynomial time. Lastly, we suggest a dependent typed
lambda-calculus to represent this construction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2426</identifier>
 <datestamp>2009-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2426</id><created>2009-03-13</created><authors><author><keyname>Kadloor</keyname><forenames>Sachin</forenames></author><author><keyname>Adve</keyname><forenames>Raviraj</forenames></author></authors><title>Relay Selection and Power Allocation in Cooperative Cellular Networks</title><categories>cs.IT math.IT</categories><comments>20 Pages, 5 Figures, Submitted to IEEE Transactions on Wireless
  Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a system with a single base station communicating with multiple
users over orthogonal channels while being assisted by multiple relays. Several
recent works have suggested that, in such a scenario, selection, i.e., a single
relay helping the source, is the best relaying option in terms of the resulting
complexity and overhead. However, in a multiuser setting, optimal relay
assignment is a combinatorial problem. In this paper, we formulate a related
convex optimization problem that provides an extremely tight upper bound on
performance and show that selection is, almost always, inherent in the
solution. We also provide a heuristic to find a close-to-optimal relay
assignment and power allocation across users supported by a single relay.
Simulation results using realistic channel models demonstrate the efficacy of
the proposed schemes, but also raise the question as to whether the gains from
relaying are worth the additional costs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2429</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2429</id><created>2009-03-13</created><updated>2009-04-27</updated><authors><author><keyname>Altarelli</keyname><forenames>F.</forenames></author><author><keyname>Braunstein</keyname><forenames>A.</forenames></author><author><keyname>Realpe-Gomez</keyname><forenames>J.</forenames></author><author><keyname>Zecchina</keyname><forenames>R.</forenames></author></authors><title>Statistical mechanics of budget-constrained auctions</title><categories>cs.GT cond-mat.stat-mech physics.soc-ph</categories><comments>Minor revision</comments><journal-ref>JSTAT 2009;2009:P07002 (27pp)</journal-ref><doi>10.1088/1742-5468/2009/07/P07002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Finding the optimal assignment in budget-constrained auctions is a
combinatorial optimization problem with many important applications, a notable
example being the sale of advertisement space by search engines (in this
context the problem is often referred to as the off-line AdWords problem).
Based on the cavity method of statistical mechanics, we introduce a message
passing algorithm that is capable of solving efficiently random instances of
the problem extracted from a natural distribution, and we derive from its
properties the phase diagram of the problem. As the control parameter (average
value of the budgets) is varied, we find two phase transitions delimiting a
region in which long-range correlations arise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2445</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2445</id><created>2009-03-13</created><updated>2009-05-04</updated><authors><author><keyname>Chatterjee</keyname><forenames>Krishnendu</forenames></author><author><keyname>de Alfaro</keyname><forenames>Luca</forenames></author><author><keyname>Faella</keyname><forenames>Marco</forenames></author><author><keyname>Legay</keyname><forenames>Axel</forenames></author></authors><title>Qualitative Logics and Equivalences for Probabilistic Systems</title><categories>cs.LO</categories><comments>The paper is accepted for LMCS</comments><acm-class>F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 5, Issue 2 (May 4,
  2009) lmcs:1082</journal-ref><doi>10.2168/LMCS-5(2:7)2009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate logics and equivalence relations that capture the qualitative
behavior of Markov Decision Processes (MDPs). We present Qualitative Randomized
CTL (QRCTL): formulas of this logic can express the fact that certain temporal
properties hold over all paths, or with probability 0 or 1, but they do not
distinguish among intermediate probability values. We present a symbolic,
polynomial time model-checking algorithm for QRCTL on MDPs.
  The logic QRCTL induces an equivalence relation over states of an MDP that we
call qualitative equivalence: informally, two states are qualitatively
equivalent if the sets of formulas that hold with probability 0 or 1 at the two
states are the same. We show that for finite alternating MDPs, where
nondeterministic and probabilistic choices occur in different states,
qualitative equivalence coincides with alternating bisimulation, and can thus
be computed via efficient partition-refinement algorithms. On the other hand,
in non-alternating MDPs the equivalence relations cannot be computed via
partition-refinement algorithms, but rather, they require non-local
computation. Finally, we consider QRCTL*, that extends QRCTL with nested
temporal operators in the same manner in which CTL* extends CTL. We show that
QRCTL and QRCTL* induce the same qualitative equivalence on alternating MDPs,
while on non-alternating MDPs, the equivalence arising from QRCTL* can be
strictly finer. We also provide a full characterization of the relation between
qualitative equivalence, bisimulation, and alternating bisimulation, according
to whether the MDPs are finite, and to whether their transition relations are
finitely-branching.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2448</identifier>
 <datestamp>2009-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2448</id><created>2009-03-13</created><updated>2009-03-23</updated><authors><author><keyname>Sadrzadeh</keyname><forenames>Mehrnoosh</forenames></author><author><keyname>Dyckhoff</keyname><forenames>Roy</forenames></author></authors><title>Positive Logic with Adjoint Modalities: Proof Theory, Semantics and
  Reasoning about Information</title><categories>cs.LO cs.MA</categories><comments>This paper is the full version of the article that is to appear in
  the ENTCS proceedings of the 25th conference on the Mathematical Foundations
  of Programming Semantics (MFPS), April 2009, University of Oxford</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a simple modal logic whose non-modal part has conjunction and
disjunction as connectives and whose modalities come in adjoint pairs, but are
not in general closure operators. Despite absence of negation and implication,
and of axioms corresponding to the characteristic axioms of (e.g.) T, S4 and
S5, such logics are useful, as shown in previous work by Baltag, Coecke and the
first author, for encoding and reasoning about information and misinformation
in multi-agent systems. For such a logic we present an algebraic semantics,
using lattices with agent-indexed families of adjoint pairs of operators, and a
cut-free sequent calculus. The calculus exploits operators on sequents, in the
style of &quot;nested&quot; or &quot;tree-sequent&quot; calculi; cut-admissibility is shown by
constructive syntactic methods. The applicability of the logic is illustrated
by reasoning about the muddy children puzzle, for which the calculus is
augmented with extra rules to express the facts of the muddy children scenario.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2471</identifier>
 <datestamp>2009-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2471</id><created>2009-03-13</created><authors><author><keyname>Yijia</keyname><affiliation>Richard</affiliation></author><author><keyname>Fan</keyname></author><author><keyname>Wang</keyname><forenames>Chao</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author><author><keyname>Thompson</keyname><forenames>John S.</forenames></author></authors><title>Cooperative Multiplexing: Toward Higher Spectral Efficiency in
  Multi-antenna Relay Networks</title><categories>cs.IT math.IT</categories><comments>To appear in IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Previous work on cooperative communications has concentrated primarily on the
diversity benefits of such techniques. This paper, instead, considers the
multiplexing benefits of cooperative communications. First, a new
interpretation on the fundamental tradeoff between the transmission rate and
outage probability in multi-antenna relay networks is given. It follows that
multiplexing gains can be obtained at any finite SNR, in full-duplex
multi-antenna relay networks. Thus relaying can offer not only stronger link
reliability, but also higher spectral efficiency.
  Specifically, the decode-and-forward protocol is applied and networks that
have one source, one destination, and multiple relays are considered. A receive
power gain at the relays, which captures the network large scale fading
characteristics, is also considered. It is shown that this power gain can
significantly affect the system diversity-multiplexing tradeoff for any finite
SNR value. Several relaying protocols are proposed and are shown to offer
nearly the same outage probability as if the transmit antennas at the source
and the relay(s) were co-located, given certain SNR and receive power gains at
the relays. Thus a higher multiplexing gain than that of the direct link can be
obtained if the destination has more antennas than the source.
  Much of the analysis in the paper is valid for arbitrary channel fading
statistics. These results point to a view of relay networks as a means for
providing higher spectral efficiency, rather than only link reliability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2499</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2499</id><created>2009-03-13</created><authors><author><keyname>Ouangraoua</keyname><forenames>Aida</forenames></author><author><keyname>Bergeron</keyname><forenames>Anne</forenames></author></authors><title>Parking functions, labeled trees and DCJ sorting scenarios</title><categories>cs.DM</categories><comments>12 pages, 3 figures</comments><acm-class>J.3</acm-class><doi>10.1007/978-3-642-04744-2_3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In genome rearrangement theory, one of the elusive questions raised in recent
years is the enumeration of rearrangement scenarios between two genomes. This
problem is related to the uniform generation of rearrangement scenarios, and
the derivation of tests of statistical significance of the properties of these
scenarios. Here we give an exact formula for the number of double-cut-and-join
(DCJ) rearrangement scenarios of co-tailed genomes. We also construct effective
bijections between the set of scenarios that sort a cycle and well studied
combinatorial objects such as parking functions and labeled trees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2507</identifier>
 <datestamp>2009-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2507</id><created>2009-03-13</created><authors><author><keyname>Cabello</keyname><forenames>Sergio</forenames></author><author><keyname>Eppstein</keyname><forenames>David</forenames></author><author><keyname>Klavzar</keyname><forenames>Sandi</forenames></author></authors><title>The Fibonacci dimension of a graph</title><categories>math.CO cs.DS</categories><comments>20 pages, 6 figures</comments><report-no>IMFM Preprint 1084</report-no><msc-class>05C78 (Primary) 05C85 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Fibonacci dimension fdim(G) of a graph G is introduced as the smallest
integer f such that G admits an isometric embedding into Gamma_f, the
f-dimensional Fibonacci cube. We give bounds on the Fibonacci dimension of a
graph in terms of the isometric and lattice dimension, provide a combinatorial
characterization of the Fibonacci dimension using properties of an associated
graph, and establish the Fibonacci dimension for certain families of graphs.
  From the algorithmic point of view we prove that it is NP-complete to decide
if fdim(G) equals to the isometric dimension of G, and that it is also NP-hard
to approximate fdim(G) within (741/740)-epsilon. We also give a
(3/2)-approximation algorithm for fdim(G) in the general case and a
(1+epsilon)-approximation algorithm for simplex graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2516</identifier>
 <datestamp>2009-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2516</id><created>2009-03-13</created><authors><author><keyname>Khor</keyname><forenames>Susan</forenames></author></authors><title>Effect of Degree Distribution on Evolutionary Search</title><categories>cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a method to generate hierarchically modular networks
with prescribed node degree list and proposes a metric to measure network
modularity based on the notion of edge distance. The generated networks are
used as test problems to explore the effect of modularity and degree
distribution on evolutionary algorithm performance. Results from the
experiments (i) confirm a previous finding that modularity increases the
performance advantage of genetic algorithms over hill climbers, and (ii)
support a new conjecture that test problems with modularized constraint
networks having heavy-tailed right-skewed degree distributions are more easily
solved than test problems with modularized constraint networks having
bell-shaped normal degree distributions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2525</identifier>
 <datestamp>2009-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2525</id><created>2009-03-14</created><authors><author><keyname>Calheiros</keyname><forenames>Rodrigo N.</forenames></author><author><keyname>Ranjan</keyname><forenames>Rajiv</forenames></author><author><keyname>De Rose</keyname><forenames>Cesar A. F.</forenames></author><author><keyname>Buyya</keyname><forenames>Rajkumar</forenames></author></authors><title>CloudSim: A Novel Framework for Modeling and Simulation of Cloud
  Computing Infrastructures and Services</title><categories>cs.DC cs.OS cs.SE</categories><comments>9 pages, 9 figures</comments><report-no>echnical Report, GRIDS-TR-2009-1, Grid Computing and Distributed
  Systems Laboratory, The University of Melbourne, Australia, March 13, 2009</report-no><acm-class>C.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cloud computing focuses on delivery of reliable, secure, fault-tolerant,
sustainable, and scalable infrastructures for hosting Internet-based
application services. These applications have different composition,
configuration, and deployment requirements. Quantifying the performance of
scheduling and allocation policy on a Cloud infrastructure (hardware, software,
services) for different application and service models under varying load,
energy performance (power consumption, heat dissipation), and system size is an
extremely challenging problem to tackle. To simplify this process, in this
paper we propose CloudSim: a new generalized and extensible simulation
framework that enables seamless modelling, simulation, and experimentation of
emerging Cloud computing infrastructures and management services. The
simulation framework has the following novel features: (i) support for
modelling and instantiation of large scale Cloud computing infrastructure,
including data centers on a single physical computing node and java virtual
machine; (ii) a self-contained platform for modelling data centers, service
brokers, scheduling, and allocations policies; (iii) availability of
virtualization engine, which aids in creation and management of multiple,
independent, and co-hosted virtualized services on a data center node; and (iv)
flexibility to switch between space-shared and time-shared allocation of
processing cores to virtualized services.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2528</identifier>
 <datestamp>2009-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2528</id><created>2009-03-14</created><authors><author><keyname>Li</keyname><forenames>Chendong</forenames></author></authors><title>Airport Gate Assignment A Hybrid Model and Implementation</title><categories>cs.AI cs.OH</categories><comments>5 pages, 2 figures, submitted to IC-AI 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the rapid development of airlines, airports today become much busier and
more complicated than previous days. During airlines daily operations,
assigning the available gates to the arriving aircrafts based on the fixed
schedule is a very important issue, which motivates researchers to study and
solve Airport Gate Assignment Problems (AGAP) with all kinds of
state-of-the-art combinatorial optimization techniques. In this paper, we study
the AGAP and propose a novel hybrid mathematical model based on the method of
constraint programming and 0 - 1 mixed-integer programming. With the objective
to minimize the number of gate conflicts of any two adjacent aircrafts assigned
to the same gate, we build a mathematical model with logical constraints and
the binary constraints. For practical considerations, the potential objective
of the model is also to minimize the number of gates that airlines must lease
or purchase in order to run their business smoothly. We implement the model in
the Optimization Programming Language (OPL) and carry out empirical studies
with the data obtained from online timetable of Continental Airlines, Houston
Gorge Bush Intercontinental Airport IAH, which demonstrate that our model can
provide an efficient evaluation criteria for the airline companies to estimate
the efficiency of their current gate assignments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2543</identifier>
 <datestamp>2009-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2543</id><created>2009-03-14</created><authors><author><keyname>Khalil</keyname><forenames>Khaled M.</forenames></author><author><keyname>Abdel-Aziz</keyname><forenames>M.</forenames></author><author><keyname>Nazmy</keyname><forenames>Taymour T.</forenames></author><author><keyname>Salem</keyname><forenames>Abdel-Badeeh M.</forenames></author></authors><title>Multi-Agent Crisis Response systems - Design Requirements and Analysis
  of Current Systems</title><categories>cs.MA</categories><comments>6 pages, 1 figure, accepted at Fourth International Conference on
  Intelligent Computing and Information Systems 2009</comments><acm-class>I.6; I.2; J.7</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Crisis response is a critical area of research, with encouraging progress in
the past view yeas. The aim of the research is to contribute to building future
crisis environment where software agents, robots, responders, crisis managers,
and crisis organizations interact to provide advice, protection and aid. This
paper discusses the crisis response domain requirements, and provides analysis
of five crisis response systems namely: DrillSim [2], DEFACTO [15], ALADDIN
[1], RoboCup Rescue [18], and FireGrid [3]. Analysis of systems includes
systems architecture and methodology. In addition, we identified features and
limitations of systems based on crisis response domain requirements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2544</identifier>
 <datestamp>2009-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2544</id><created>2009-03-14</created><authors><author><keyname>Zotos</keyname><forenames>N.</forenames></author><author><keyname>Tzekou</keyname><forenames>P.</forenames></author><author><keyname>Tsatsaronis</keyname><forenames>G.</forenames></author><author><keyname>Kozanidis</keyname><forenames>L.</forenames></author><author><keyname>Stamou</keyname><forenames>S.</forenames></author><author><keyname>Varlamis</keyname><forenames>I.</forenames></author></authors><title>To Click or not to Click? The Role of Contextualized and User-Centric
  Web Snippets</title><categories>cs.IR</categories><comments>In proceedings of SIGIR 2007 Workshop on Focused Retrieval. 8 pages</comments><acm-class>H.3.3</acm-class><journal-ref>SIGIR 2007 Workshop on Focused Retrieval</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When searching the web, it is often possible that there are too many results
available for ambiguous queries. Text snippets, extracted from the retrieved
pages, are an indicator of the pages' usefulness to the query intention and can
be used to focus the scope of search results. In this paper, we propose a novel
method for automatically extracting web page snippets that are highly relevant
to the query intention and expressive of the pages' entire content. We show
that the usage of semantics, as a basis for focused retrieval, produces high
quality text snippet suggestions. The snippets delivered by our method are
significantly better in terms of retrieval performance compared to those
derived using the pages' statistical content. Furthermore, our study suggests
that semantically-driven snippet generation can also be used to augment
traditional passage retrieval algorithms based on word overlap or statistical
weights, since they typically differ in coverage and produce different results.
User clicks on the query relevant snippets can be used to refine the query
results and promote the most comprehensive among the relevant documents.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2554</identifier>
 <datestamp>2013-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2554</id><created>2009-03-14</created><updated>2013-07-31</updated><authors><author><keyname>Durand</keyname><forenames>Irene</forenames></author><author><keyname>Senizergues</keyname><forenames>Geraud</forenames></author></authors><title>Bottom-up rewriting for words and terms</title><categories>cs.FL</categories><comments>86 pages; long version to be cut into pieces for publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For the whole class of linear term rewriting systems, we define
\emph{bottom-up rewriting} which is a restriction of the usual notion of
rewriting. We show that bottom-up rewriting effectively inverse-preserves
recognizability and analyze the complexity of the underlying construction. The
Bottom-Up class (BU) is, by definition, the set of linear systems for which
every derivation can be replaced by a bottom-up derivation. Membership to BU
turns out to be undecidable, we are thus lead to define more restricted
classes: the classes SBU(k), k in N of Strongly Bottom-Up(k) systems for which
we show that membership is decidable. We define the class of Strongly Bottom-Up
systems by SBU = U_{k in \} SBU(k). We give a polynomial sufficient condition
for a system to be in $\SBU$. The class SBU contains (strictly) several classes
of systems which were already known to inverse preserve recognizability: the
inverse left-basic semi-Thue systems (viewed as unary term rewriting systems),
the linear growing term rewriting systems, the inverse
Linear-Finite-Path-Ordering systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2584</identifier>
 <datestamp>2009-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2584</id><created>2009-03-14</created><updated>2009-09-25</updated><authors><author><keyname>Krioukov</keyname><forenames>Dmitri</forenames></author><author><keyname>Papadopoulos</keyname><forenames>Fragkiskos</forenames></author><author><keyname>Vahdat</keyname><forenames>Amin</forenames></author><author><keyname>Boguna</keyname><forenames>Marian</forenames></author></authors><title>Curvature and temperature of complex networks</title><categories>cond-mat.stat-mech cond-mat.dis-nn cs.NI physics.soc-ph</categories><journal-ref>Phys. Rev. E 80, 035101(R) (2009)</journal-ref><doi>10.1103/PhysRevE.80.035101</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that heterogeneous degree distributions in observed scale-free
topologies of complex networks can emerge as a consequence of the exponential
expansion of hidden hyperbolic space. Fermi-Dirac statistics provides a
physical interpretation of hyperbolic distances as energies of links. The
hidden space curvature affects the heterogeneity of the degree distribution,
while clustering is a function of temperature. We embed the Internet into the
hyperbolic plane, and find a remarkable congruency between the embedding and
our hyperbolic model. Besides proving our model realistic, this embedding may
be used for routing with only local information, which holds significant
promise for improving the performance of Internet routing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2598</identifier>
 <datestamp>2009-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2598</id><created>2009-03-14</created><updated>2009-07-05</updated><authors><author><keyname>Khor</keyname><forenames>Susan</forenames></author></authors><title>Generating Hierarchically Modular Networks via Link Switching</title><categories>cs.OH</categories><comments>Appendix B</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a method to generate hierarchically modular networks
with prescribed node degree list by link switching. Unlike many existing
network generating models, our method does not use link probabilities to
achieve modularity. Instead, it utilizes a user-specified topology to determine
relatedness between pairs of nodes in terms of edge distances and links are
switched to increase edge distances. To measure the modular-ness of a network
as a whole, a new metric called Q2 is proposed. Comparisons are made between
the Q [15] and Q2 measures. We also comment on the effect of our modularization
method on other network characteristics such as clustering, hierarchy, average
path length, small-worldness, degree correlation and centrality. An application
of this method is reported elsewhere [12]. Briefly, the generated networks are
used as test problems to explore the effect of modularity and degree
distribution on evolutionary search algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2641</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2641</id><created>2009-03-15</created><authors><author><keyname>Spiliotis</keyname><forenames>Konstantinos G.</forenames></author><author><keyname>Siettos</keyname><forenames>Constantinos I.</forenames></author></authors><title>Multiscale Computations on Neural Networks: From the Individual Neuron
  Interactions to the Macroscopic-Level Analysis</title><categories>cs.CE cs.NA q-bio.NC</categories><journal-ref>Int. J. Bifurcation and Chaos 20 (1) 121-134 (2010)</journal-ref><doi>10.1142/S0218127410025442</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show how the Equation-Free approach for multi-scale computations can be
exploited to systematically study the dynamics of neural interactions on a
random regular connected graph under a pairwise representation perspective.
Using an individual-based microscopic simulator as a black box coarse-grained
timestepper and with the aid of simulated annealing we compute the
coarse-grained equilibrium bifurcation diagram and analyze the stability of the
stationary states sidestepping the necessity of obtaining explicit closures at
the macroscopic level. We also exploit the scheme to perform a rare-events
analysis by estimating an effective Fokker-Planck describing the evolving
probability density function of the corresponding coarse-grained observables.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2653</identifier>
 <datestamp>2009-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2653</id><created>2009-03-15</created><authors><author><keyname>Avestimehr</keyname><forenames>Salman</forenames></author><author><keyname>Khajehnejad</keyname><forenames>Amin</forenames></author><author><keyname>Sezgin</keyname><forenames>Aydin</forenames></author><author><keyname>Hassibi</keyname><forenames>Babak</forenames></author></authors><title>Capacity region of the deterministic multi-pair bi-directional relay
  network</title><categories>cs.IT math.IT</categories><comments>Will be presented in the 2009 IEEE Information Theory Workshop on
  Networking and Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study the capacity region of the multi-pair bidirectional
(or two-way) wireless relay network, in which a relay node facilitates the
communication between multiple pairs of users. This network is a generalization
of the well known bidirectional relay channel, where we have only one pair of
users. We examine this problem in the context of the deterministic channel
interaction model, which eliminates the channel noise and allows us to focus on
the interaction between signals. We characterize the capacity region of this
network when the relay is operating at either full-duplex mode or half-duplex
mode (with non adaptive listen-transmit scheduling). In both cases we show that
the cut-set upper bound is tight and, quite interestingly, the capacity region
is achieved by a simple equation-forwarding strategy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2675</identifier>
 <datestamp>2009-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2675</id><created>2009-03-15</created><authors><author><keyname>Gadouleau</keyname><forenames>Maximilien</forenames></author><author><keyname>Yan</keyname><forenames>Zhiyuan</forenames></author></authors><title>Construction and Covering Properties of Constant-Dimension Codes</title><categories>cs.IT math.IT</categories><comments>20 pages, submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Constant-dimension codes (CDCs) have been investigated for noncoherent error
correction in random network coding. The maximum cardinality of CDCs with given
minimum distance and how to construct optimal CDCs are both open problems,
although CDCs obtained by lifting Gabidulin codes, referred to as KK codes, are
nearly optimal. In this paper, we first construct a new class of CDCs based on
KK codes, referred to as augmented KK codes, whose cardinalities are greater
than previously proposed CDCs. We then propose a low-complexity decoding
algorithm for our augmented KK codes using that for KK codes. Our decoding
algorithm corrects more errors than a bounded subspace distance decoder by
taking advantage of the structure of our augmented KK codes. In the rest of the
paper we investigate the covering properties of CDCs. We first derive bounds on
the minimum cardinality of a CDC with a given covering radius and then
determine the asymptotic behavior of this quantity. Moreover, we show that
liftings of rank metric codes have the highest possible covering radius, and
hence liftings of rank metric codes are not optimal packing CDCs. Finally, we
construct good covering CDCs by permuting liftings of rank metric codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2679</identifier>
 <datestamp>2009-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2679</id><created>2009-03-15</created><authors><author><keyname>Orum</keyname><forenames>Chris</forenames></author><author><keyname>Joslyn</keyname><forenames>Cliff A</forenames></author></authors><title>Valuations and Metrics on Partially Ordered Sets</title><categories>math.CO cs.IT math.IT</categories><comments>Submitted</comments><report-no>PNWD-SA-8513</report-no><msc-class>06A06</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We extend the definitions of upper and lower valuations on partially ordered
sets, and consider the metrics they induce, in particular the metrics available
(or not) based on the logarithms of such valuations. Motivating applications in
computational linguistics and computational biology are indicated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2682</identifier>
 <datestamp>2009-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2682</id><created>2009-03-15</created><authors><author><keyname>Mohaisen</keyname><forenames>Abedelaziz</forenames></author><author><keyname>Hong</keyname><forenames>Dowon</forenames></author><author><keyname>Nyang</keyname><forenames>DaeHun</forenames></author></authors><title>Privacy in Location Based Services: Primitives Toward the Solution</title><categories>cs.CR</categories><comments>Appeared in proceeding of NCM 2008</comments><doi>10.1109/NCM.2008.137</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Location based services (LBS) are one of the most promising and innovative
directions of convergence technologies resulting of emergence of several fields
including database systems, mobile communication, Internet technology, and
positioning systems. Although being initiated as early as middle of 1990's, it
is only recently that the LBS received a systematic profound research interest
due to its commercial and technological impact. As the LBS is related to the
user's location which can be used to trace the user's activities, a strong
privacy concern has been raised. To preserve the user's location, several
intelligent works have been introduced though many challenges are still
awaiting solutions. This paper introduces a survey on LBS systems considering
both localization technologies, model and architectures guaranteeing privacy.
We also overview cryptographic primitive to possibly use in preserving LBS's
privacy followed by fruitful research directions basically concerned with the
privacy issue.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2693</identifier>
 <datestamp>2012-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2693</id><created>2009-03-16</created><authors><author><keyname>Ning</keyname><forenames>Kang</forenames></author></authors><title>A Pseudo DNA Cryptography Method</title><categories>cs.CR cs.DM</categories><comments>A small work that quite some people asked about</comments><doi>10.1016/j.compeleceng.2012.02.007</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The DNA cryptography is a new and very promising direction in cryptography
research. DNA can be used in cryptography for storing and transmitting the
information, as well as for computation. Although in its primitive stage, DNA
cryptography is shown to be very effective. Currently, several DNA computing
algorithms are proposed for quite some cryptography, cryptanalysis and
steganography problems, and they are very powerful in these areas. However, the
use of the DNA as a means of cryptography has high tech lab requirements and
computational limitations, as well as the labor intensive extrapolation means
so far. These make the efficient use of DNA cryptography difficult in the
security world now. Therefore, more theoretical analysis should be performed
before its real applications.
  In this project, We do not intended to utilize real DNA to perform the
cryptography process; rather, We will introduce a new cryptography method based
on central dogma of molecular biology. Since this method simulates some
critical processes in central dogma, it is a pseudo DNA cryptography method.
The theoretical analysis and experiments show this method to be efficient in
computation, storage and transmission; and it is very powerful against certain
attacks. Thus, this method can be of many uses in cryptography, such as an
enhancement insecurity and speed to the other cryptography methods. There are
also extensions and variations to this method, which have enhanced security,
effectiveness and applicability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2695</identifier>
 <datestamp>2009-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2695</id><created>2009-03-16</created><authors><author><keyname>Pavone</keyname><forenames>Marco</forenames></author><author><keyname>Smith</keyname><forenames>Stephen L.</forenames></author><author><keyname>Bullo</keyname><forenames>Francesco</forenames></author><author><keyname>Frazzoli</keyname><forenames>Emilio</forenames></author></authors><title>Dynamic Multi-Vehicle Routing with Multiple Classes of Demands</title><categories>cs.RO</categories><comments>Extended version of paper presented in American Control Conference
  2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study a dynamic vehicle routing problem in which there are
multiple vehicles and multiple classes of demands. Demands of each class arrive
in the environment randomly over time and require a random amount of on-site
service that is characteristic of the class. To service a demand, one of the
vehicles must travel to the demand location and remain there for the required
on-site service time. The quality of service provided to each class is given by
the expected delay between the arrival of a demand in the class, and that
demand's service completion. The goal is to design a routing policy for the
service vehicles which minimizes a convex combination of the delays for each
class. First, we provide a lower bound on the achievable values of the convex
combination of delays. Then, we propose a novel routing policy and analyze its
performance under heavy load conditions (i.e., when the fraction of time the
service vehicles spend performing on-site service approaches one). The policy
performs within a constant factor of the lower bound (and thus the optimal),
where the constant depends only on the number of classes, and is independent of
the number of vehicles, the arrival rates of demands, the on-site service
times, and the convex combination coefficients.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2711</identifier>
 <datestamp>2010-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2711</id><created>2009-03-16</created><updated>2010-12-04</updated><authors><author><keyname>Fertl</keyname><forenames>Peter</forenames></author><author><keyname>Jalden</keyname><forenames>Joakim</forenames></author><author><keyname>Matz</keyname><forenames>Gerald</forenames></author></authors><title>Performance Assessment of MIMO-BICM Demodulators based on System
  Capacity</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Signal Processing, Oct. 20010
  (paper was presented in part at IEEE SPAWC 2008, Recife, Brazil, July 2008)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide a comprehensive performance comparison of soft-output and
hard-output demodulators in the context of non-iterative multiple-input
multiple-output bit-interleaved coded modulation (MIMO-BICM). Coded bit error
rate (BER), widely used in literature for demodulator comparison, has the
drawback of depending strongly on the error correcting code being used. This
motivates us to propose a code-independent performance measure in terms of
system capacity, i.e., mutual information of the equivalent modulation channel
that comprises modulator, wireless channel, and demodulator. We present
extensive numerical results for ergodic and quasi-static fading channels under
perfect and imperfect channel state information. These results reveal that the
performance ranking of MIMO demodulators is rate-dependent. Furthermore, they
provide new insights regarding MIMO-BICM system design, i.e., the choice of
antenna configuration, symbol constellation, and demodulator for a given target
rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2742</identifier>
 <datestamp>2009-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2742</id><created>2009-03-16</created><authors><author><keyname>Istrate</keyname><forenames>Gabriel</forenames></author></authors><title>On Hadwiger's Number of a graph with partial information</title><categories>cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the possibility of proving upper bounds on Hadwiger's number
of a graph with partial information, mirroring several known upper bounds for
the chromatic number. For each such bound we determine whether the
corresponding bound for Hadwiger's number holds. Our results suggest that the
``locality'' of an inequality accounts for the existence of such an extension.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2749</identifier>
 <datestamp>2010-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2749</id><created>2009-03-16</created><updated>2010-01-10</updated><authors><author><keyname>&#xd6;sterg&#xe5;rd</keyname><forenames>Patric R. J.</forenames></author><author><keyname>Pottonen</keyname><forenames>Olli</forenames></author><author><keyname>Phelps</keyname><forenames>Kevin T.</forenames></author></authors><title>The Perfect Binary One-Error-Correcting Codes of Length 15: Part
  II--Properties</title><categories>cs.IT math.IT</categories><comments>v2: fixed two errors (extension of nonsystematic codes, table of
  coordinates fixed by symmetries of codes), added and extended many other
  results</comments><journal-ref>IEEE Trans. Inform. Theory vol. 56, pp. 2571-2582, 2010</journal-ref><doi>10.1109/TIT.2010.2046197</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A complete classification of the perfect binary one-error-correcting codes of
length 15 as well as their extensions of length 16 was recently carried out in
[P. R. J. \&quot;Osterg{\aa}rd and O. Pottonen, &quot;The perfect binary
one-error-correcting codes of length 15: Part I--Classification,&quot; IEEE Trans.
Inform. Theory vol. 55, pp. 4657--4660, 2009]. In the current accompanying
work, the classified codes are studied in great detail, and their main
properties are tabulated. The results include the fact that 33 of the 80
Steiner triple systems of order 15 occur in such codes. Further understanding
is gained on full-rank codes via switching, as it turns out that all but two
full-rank codes can be obtained through a series of such transformations from
the Hamming code. Other topics studied include (non)systematic codes, embedded
one-error-correcting codes, and defining sets of codes. A classification of
certain mixed perfect codes is also obtained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2774</identifier>
 <datestamp>2010-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2774</id><created>2009-03-16</created><updated>2010-05-07</updated><authors><author><keyname>Tauboeck</keyname><forenames>Georg</forenames></author><author><keyname>Hlawatsch</keyname><forenames>Franz</forenames></author><author><keyname>Eiwen</keyname><forenames>Daniel</forenames></author><author><keyname>Rauhut</keyname><forenames>Holger</forenames></author></authors><title>Compressive estimation of doubly selective channels in multicarrier
  systems: Leakage effects and sparsity-enhancing processing</title><categories>cs.IT math.IT</categories><comments>18 pages, 6 figures; content is identical to published paper version
  (in IEEE Journal of Selected Topics in Signal Processing - Special Issue on
  Compressed Sensing), only format is different; this revision contains
  substantially new material compared with previous (arXiv) revision, also
  title and author list have changed</comments><journal-ref>IEEE J. Sel. Top. Sig. Process., vol. 4, no. 2, pp. 255-271, April
  2010</journal-ref><doi>10.1109/JSTSP.2010.2042410</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the application of compressed sensing (CS) to the estimation of
doubly selective channels within pulse-shaping multicarrier systems (which
include OFDM systems as a special case). By exploiting sparsity in the
delay-Doppler domain, CS-based channel estimation allows for an increase in
spectral efficiency through a reduction of the number of pilot symbols. For
combating leakage effects that limit the delay-Doppler sparsity, we propose a
sparsity-enhancing basis expansion and a method for optimizing the basis with
or without prior statistical information about the channel. We also present an
alternative CS-based channel estimator for (potentially) strongly
time-frequency dispersive channels, which is capable of estimating the
&quot;off-diagonal&quot; channel coefficients characterizing intersymbol and intercarrier
interference (ISI/ICI). For this estimator, we propose a basis construction
combining Fourier (exponential) and prolate spheroidal sequences. Simulation
results assess the performance gains achieved by the proposed
sparsity-enhancing processing techniques and by explicit estimation of ISI/ICI
channel coefficients.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2791</identifier>
 <datestamp>2009-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2791</id><created>2009-03-16</created><authors><author><keyname>Lopez-Permouth</keyname><forenames>Sergio</forenames></author><author><keyname>Szabo</keyname><forenames>Steve</forenames></author></authors><title>On the Hamming weight of Repeated Root Cyclic and Negacyclic Codes over
  Galois Rings</title><categories>cs.IT math.IT</categories><comments>Submitted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Repeated root Cyclic and Negacyclic codes over Galois rings have been studied
much less than their simple root counterparts. This situation is beginning to
change. For example, repeated root codes of length $p^s$, where $p$ is the
characteristic of the alphabet ring, have been studied under some additional
hypotheses. In each one of those cases, the ambient space for the codes has
turned out to be a chain ring. In this paper, all remaining cases of cyclic and
negacyclic codes of length $p^s$ over a Galois ring alphabet are considered. In
these cases the ambient space is a local ring with simple socle but not a chain
ring. Nonetheless, by reducing the problem to one dealing with uniserial
subambients, a method for computing the Hamming distance of these codes is
provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2792</identifier>
 <datestamp>2011-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2792</id><created>2009-03-16</created><updated>2011-02-27</updated><authors><author><keyname>Koroutchev</keyname><forenames>Kostadin</forenames></author><author><keyname>Shen</keyname><forenames>Jian</forenames></author><author><keyname>Koroutcheva</keyname><forenames>Elka</forenames></author><author><keyname>Cebrian</keyname><forenames>Manuel</forenames></author></authors><title>Thermodynamics of Information Retrieval</title><categories>cs.IT cs.CL cs.SI math.IT</categories><comments>12 pages, 7 figures</comments><acm-class>E.4; G.3; H.3.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we suggest a parameterized statistical model (the gamma
distribution) for the frequency of word occurrences in long strings of English
text and use this model to build a corresponding thermodynamic picture by
constructing the partition function. We then use our partition function to
compute thermodynamic quantities such as the free energy and the specific heat.
In this approach, the parameters of the word frequency model vary from word to
word so that each word has a different corresponding thermodynamics and we
suggest that differences in the specific heat reflect differences in how the
words are used in language, differentiating keywords from common and function
words. Finally, we apply our thermodynamic picture to the problem of retrieval
of texts based on keywords and suggest some advantages over traditional
information retrieval methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2816</identifier>
 <datestamp>2009-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2816</id><created>2009-03-16</created><authors><author><keyname>Spielman</keyname><forenames>Daniel A</forenames></author><author><keyname>Woo</keyname><forenames>Jaeoh</forenames></author></authors><title>A Note on Preconditioning by Low-Stretch Spanning Trees</title><categories>cs.NA cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Boman and Hendrickson observed that one can solve linear systems in Laplacian
matrices in time $\bigO{m^{3/2 + o (1)} \ln (1/\epsilon)}$ by preconditioning
with the Laplacian of a low-stretch spanning tree. By examining the
distribution of eigenvalues of the preconditioned linear system, we prove that
the preconditioned conjugate gradient will actually solve the linear system in
time $\softO{m^{4/3} \ln (1/\epsilon)}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2820</identifier>
 <datestamp>2009-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2820</id><created>2009-03-16</created><updated>2009-11-16</updated><authors><author><keyname>Chatterjee</keyname><forenames>Debdeep</forenames></author><author><keyname>Wong</keyname><forenames>Tan F.</forenames></author><author><keyname>Lok</keyname><forenames>Tat M.</forenames></author></authors><title>Cooperative Transmission in a Wireless Relay Network based on Flow
  Management</title><categories>cs.IT math.IT</categories><comments>31 pages, 10 figures. First version submitted to Transactions on
  Communications, Nov. 2007. This is the revised detailed version. Further
  updated on Nov. 16, 2009 with minor modifications. To appear</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a cooperative transmission design for a general multi-node
half-duplex wireless relay network is presented. It is assumed that the nodes
operate in half-duplex mode and that channel information is available at the
nodes. The proposed design involves solving a convex flow optimization problem
on a graph that models the relay network. A much simpler generalized-link
selection protocol based on the above design is also presented. Both the
proposed flow-optimized protocol and the generalized-link selection protocol
are shown to achieve the optimal diversity-multiplexing tradeoff (DMT) for the
relay network. Moreover, simulation results are presented to quantify the gap
between the performances of the proposed protocols and that of a
max-flow-min-cut type bound, in terms of outage probability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2825</identifier>
 <datestamp>2009-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2825</id><created>2009-03-16</created><authors><author><keyname>Jha</keyname><forenames>Susmit</forenames></author><author><keyname>Seshia</keyname><forenames>Sanjit A.</forenames></author><author><keyname>Limaye</keyname><forenames>Rhishikesh</forenames></author></authors><title>On the Computational Complexity of Satisfiability Solving for String
  Theories</title><categories>cs.CC cs.LO cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Satisfiability solvers are increasingly playing a key role in software
verification, with particularly effective use in the analysis of security
vulnerabilities. String processing is a key part of many software applications,
such as browsers and web servers. These applications are susceptible to attacks
through malicious data received over network. Automated tools for analyzing the
security of such applications, thus need to reason about strings. For
efficiency reasons, it is desirable to have a solver that treats strings as
first-class types. In this paper, we present some theories of strings that are
useful in a software security context and analyze the computational complexity
of the presented theories. We use this complexity analysis to motivate a
byte-blast approach which employs a Boolean encoding of the string constraints
to a corresponding Boolean satisfiability problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2851</identifier>
 <datestamp>2010-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2851</id><created>2009-03-16</created><updated>2010-01-18</updated><authors><author><keyname>Chaudhuri</keyname><forenames>Kamalika</forenames></author><author><keyname>Freund</keyname><forenames>Yoav</forenames></author><author><keyname>Hsu</keyname><forenames>Daniel</forenames></author></authors><title>A parameter-free hedging algorithm</title><categories>cs.LG cs.AI</categories><comments>Updated Version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of decision-theoretic online learning (DTOL). Motivated
by practical applications, we focus on DTOL when the number of actions is very
large. Previous algorithms for learning in this framework have a tunable
learning rate parameter, and a barrier to using online-learning in practical
applications is that it is not understood how to set this parameter optimally,
particularly when the number of actions is large.
  In this paper, we offer a clean solution by proposing a novel and completely
parameter-free algorithm for DTOL. We introduce a new notion of regret, which
is more natural for applications with a large number of actions. We show that
our algorithm achieves good performance with respect to this new notion of
regret; in addition, it also achieves performance close to that of the best
bounds achieved by previous algorithms with optimally-tuned parameters,
according to previous notions of regret.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2862</identifier>
 <datestamp>2010-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2862</id><created>2009-03-16</created><updated>2010-01-18</updated><authors><author><keyname>Chaudhuri</keyname><forenames>Kamalika</forenames></author><author><keyname>Freund</keyname><forenames>Yoav</forenames></author><author><keyname>Hsu</keyname><forenames>Daniel</forenames></author></authors><title>Tracking using explanation-based modeling</title><categories>cs.LG cs.AI cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the tracking problem, namely, estimating the hidden state of an
object over time, from unreliable and noisy measurements. The standard
framework for the tracking problem is the generative framework, which is the
basis of solutions such as the Bayesian algorithm and its approximation, the
particle filters. However, the problem with these solutions is that they are
very sensitive to model mismatches. In this paper, motivated by online
learning, we introduce a new framework -- an {\em explanatory} framework -- for
tracking. We provide an efficient tracking algorithm for this framework. We
provide experimental results comparing our algorithm to the Bayesian algorithm
on simulated data. Our experiments show that when there are slight model
mismatches, our algorithm vastly outperforms the Bayesian algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2870</identifier>
 <datestamp>2009-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2870</id><created>2009-03-16</created><updated>2009-06-24</updated><authors><author><keyname>Bradley</keyname><forenames>Patrick Erik</forenames></author></authors><title>On $p$-adic Classification</title><categories>cs.LG</categories><comments>16 pages, 7 figures, 1 table; added reference, corrected typos, minor
  content changes</comments><journal-ref>p-Adic Numbers, Ultrametric Analysis, and Applications, Vol. 1,
  No. 4 (2009), 271-285</journal-ref><doi>10.1134/S2070046609040013</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A $p$-adic modification of the split-LBG classification method is presented
in which first clusterings and then cluster centers are computed which locally
minimise an energy function. The outcome for a fixed dataset is independent of
the prime number $p$ with finitely many exceptions. The methods are applied to
the construction of $p$-adic classifiers in the context of learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2890</identifier>
 <datestamp>2010-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2890</id><created>2009-03-16</created><updated>2010-05-28</updated><authors><author><keyname>Kar</keyname><forenames>Soummya</forenames></author><author><keyname>Sinopoli</keyname><forenames>Bruno</forenames></author><author><keyname>Moura</keyname><forenames>Jose M. F.</forenames></author></authors><title>Kalman Filtering with Intermittent Observations: Weak Convergence to a
  Stationary Distribution</title><categories>cs.IT cs.LG math.IT math.ST stat.TH</categories><comments>Submitted for publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper studies the asymptotic behavior of Random Algebraic Riccati
Equations (RARE) arising in Kalman filtering when the arrival of the
observations is described by a Bernoulli i.i.d. process. We model the RARE as
an order-preserving, strongly sublinear random dynamical system (RDS). Under a
sufficient condition, stochastic boundedness, and using a limit-set dichotomy
result for order-preserving, strongly sublinear RDS, we establish the
asymptotic properties of the RARE: the sequence of random prediction error
covariance matrices converges weakly to a unique invariant distribution, whose
support exhibits fractal behavior. In particular, this weak convergence holds
under broad conditions and even when the observations arrival rate is below the
critical probability for mean stability. We apply the weak-Feller property of
the Markov process governing the RARE to characterize the support of the
limiting invariant distribution as the topological closure of a countable set
of points, which, in general, is not dense in the set of positive semi-definite
matrices. We use the explicit characterization of the support of the invariant
distribution and the almost sure ergodicity of the sample paths to easily
compute the moments of the invariant distribution. A one dimensional example
illustrates that the support is a fractured subset of the non-negative reals
with self-similarity properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2904</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2904</id><created>2009-03-17</created><authors><author><keyname>Bauer</keyname><forenames>Andreas</forenames></author><author><keyname>Gore</keyname><forenames>Rajeev</forenames></author><author><keyname>Tiu</keyname><forenames>Alwen</forenames></author></authors><title>A decidable policy language for history-based transaction monitoring</title><categories>cs.LO cs.CR</categories><doi>10.1007/978-3-642-03466-4_6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Online trading invariably involves dealings between strangers, so it is
important for one party to be able to judge objectively the trustworthiness of
the other. In such a setting, the decision to trust a user may sensibly be
based on that user's past behaviour. We introduce a specification language
based on linear temporal logic for expressing a policy for categorising the
behaviour patterns of a user depending on its transaction history. We also
present an algorithm for checking whether the transaction history obeys the
stated policy. To be useful in a real setting, such a language should allow one
to express realistic policies which may involve parameter quantification and
quantitative or statistical patterns. We introduce several extensions of linear
temporal logic to cater for such needs: a restricted form of universal and
existential quantification; arbitrary computable functions and relations in the
term language; and a &quot;counting&quot; quantifier for counting how many times a
formula holds in the past. We then show that model checking a transaction
history against a policy, which we call the history-based transaction
monitoring problem, is PSPACE-complete in the size of the policy formula and
the length of the history. The problem becomes decidable in polynomial time
when the policies are fixed. We also consider the problem of transaction
monitoring in the case where not all the parameters of actions are observable.
We formulate two such &quot;partial observability&quot; monitoring problems, and show
their decidability under certain restrictions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2908</identifier>
 <datestamp>2009-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2908</id><created>2009-03-17</created><updated>2009-09-23</updated><authors><author><keyname>Zhou</keyname><forenames>Haijun</forenames></author><author><keyname>Ma</keyname><forenames>Hui</forenames></author></authors><title>Communities of solutions in single solution clusters of a random
  K-Satisfiability formula</title><categories>cond-mat.dis-nn cond-mat.stat-mech cs.CC</categories><comments>Extensively revised and expanded into 15 pages with 10 figures. New
  mean-field calculations and simulation results added</comments><journal-ref>Phys. Rev. E 80, 066108 (2009)</journal-ref><doi>10.1103/PhysRevE.80.066108</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The solution space of a K-satisfiability (K-SAT) formula is a collection of
solution clusters, each of which contains all the solutions that are mutually
reachable through a sequence of single-spin flips. Knowledge of the statistical
property of solution clusters is valuable for a complete understanding of the
solution space structure and the computational complexity of the random K-SAT
problem. This paper explores single solution clusters of random 3- and 4-SAT
formulas through unbiased and biased random walk processes and the
replica-symmetric cavity method of statistical physics. We find that the giant
connected component of the solution space has already formed many different
communities when the constraint density of the formula is still lower than the
solution space clustering transition point. Solutions of the same community are
more similar with each other and more densely connected with each other than
with the other solutions. The entropy density of a solution community is
calculated using belief propagation and is found to be different for different
communities of the same cluster. When the constraint density is beyond the
clustering transition point, the same behavior is observed for the solution
clusters reached by several stochastic search algorithms. Taking together, the
results of this work suggests a refined picture on the evolution of the
solution space structure of the random K-SAT problem; they may also be helpful
for designing new heuristic algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2914</identifier>
 <datestamp>2013-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2914</id><created>2009-03-17</created><updated>2013-03-28</updated><authors><author><keyname>Bergstra</keyname><forenames>J. A.</forenames></author><author><keyname>Middelburg</keyname><forenames>C. A.</forenames></author></authors><title>A process calculus with finitary comprehended terms</title><categories>cs.LO math.RA</categories><comments>25 pages, combined with arXiv:0901.3012 [math.RA]; presentation
  improved, mistakes in Table 5 corrected</comments><acm-class>D.1.3; F.1.2; F.4.1</acm-class><journal-ref>Theory of Computing Systems, 53(4):645--668, 2013</journal-ref><doi>10.1007/s00224-013-9468-x</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce the notion of an ACP process algebra and the notion of a meadow
enriched ACP process algebra. The former notion originates from the models of
the axiom system ACP. The latter notion is a simple generalization of the
former notion to processes in which data are involved, the mathematical
structure of data being a meadow. Moreover, for all associative operators from
the signature of meadow enriched ACP process algebras that are not of an
auxiliary nature, we introduce variable-binding operators as generalizations.
These variable-binding operators, which give rise to comprehended terms, have
the property that they can always be eliminated. Thus, we obtain a process
calculus whose terms can be interpreted in all meadow enriched ACP process
algebras. Use of the variable-binding operators can have a major impact on the
size of terms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2923</identifier>
 <datestamp>2010-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2923</id><created>2009-03-17</created><updated>2010-09-09</updated><authors><author><keyname>Ghobber</keyname><forenames>Saifallah</forenames><affiliation>MAPMO</affiliation></author><author><keyname>Jaming</keyname><forenames>Philippe</forenames><affiliation>MAPMO, IMB</affiliation></author></authors><title>On uncertainty principles in the finite dimensional setting</title><categories>math.CA cs.IT math.IT</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of this paper is to prove an uncertainty principle for the
representation of a vector in two bases. Our result extends previously known
qualitative uncertainty principles into quantitative estimates. We then show
how to transfer this result to the discrete version of the Short Time Fourier
Transform. An application to trigonometric polynomials is also given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2966</identifier>
 <datestamp>2009-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2966</id><created>2009-03-17</created><authors><author><keyname>Lasaulce</keyname><forenames>S.</forenames></author><author><keyname>Hayel</keyname><forenames>Y.</forenames></author><author><keyname>Azouzi</keyname><forenames>R. El</forenames></author><author><keyname>Debbah</keyname><forenames>M.</forenames></author></authors><title>Introducing Hierarchy in Energy Games</title><categories>cs.GT</categories><comments>Accepted for publication in IEEE Trans. on Wireless Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we introduce hierarchy in wireless networks that can be modeled
by a decentralized multiple access channel and for which energy-efficiency is
the main performance index. In these networks users are free to choose their
power control strategy to selfishly maximize their energy-efficiency.
Specifically, we introduce hierarchy in two different ways: 1. Assuming
single-user decoding at the receiver, we investigate a Stackelberg formulation
of the game where one user is the leader whereas the other users are assumed to
be able to react to the leader's decisions; 2. Assuming neither leader nor
followers among the users, we introduce hierarchy by assuming successive
interference cancellation at the receiver. It is shown that introducing a
certain degree of hierarchy in non-cooperative power control games not only
improves the individual energy efficiency of all the users but can also be a
way of insuring the existence of a non-saturated equilibrium and reaching a
desired trade-off between the global network performance at the equilibrium and
the requested amount of signaling. In this respect, the way of measuring the
global performance of an energy-efficient network is shown to be a critical
issue.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2972</identifier>
 <datestamp>2009-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2972</id><created>2009-03-17</created><updated>2009-05-20</updated><authors><author><keyname>Danihelka</keyname><forenames>Ivo</forenames></author></authors><title>Optimistic Simulated Exploration as an Incentive for Real Exploration</title><categories>cs.LG cs.AI</categories><comments>accepted, noted that the initial path was 217 steps long</comments><journal-ref>POSTER 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many reinforcement learning exploration techniques are overly optimistic and
try to explore every state. Such exploration is impossible in environments with
the unlimited number of states. I propose to use simulated exploration with an
optimistic model to discover promising paths for real exploration. This reduces
the needs for the real exploration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2999</identifier>
 <datestamp>2009-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2999</id><created>2009-03-17</created><updated>2009-07-27</updated><authors><author><keyname>Radicchi</keyname><forenames>Filippo</forenames></author></authors><title>Human Activity in the Web</title><categories>physics.soc-ph cond-mat.stat-mech cs.HC</categories><comments>10 pages, 9 figures. Final version accepted for publication in
  Physical Review E</comments><journal-ref>Phys. Rev. E 80, 026118 (2009)</journal-ref><doi>10.1103/PhysRevE.80.026118</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The recent information technology revolution has enabled the analysis and
processing of large-scale datasets describing human activities. The main source
of data is represented by the Web, where humans generally use to spend a
relevant part of their day. Here we study three large datasets containing the
information about Web human activities in different contexts. We study in
details inter-event and waiting time statistics. In both cases, the number of
subsequent operations which differ by tau units of time decays power-like as
tau increases. We use non-parametric statistical tests in order to estimate the
significance level of reliability of global distributions to describe activity
patterns of single users. Global inter-event time probability distributions are
not representative for the behavior of single users: the shape of single
users'inter-event distributions is strongly influenced by the total number of
operations performed by the users and distributions of the total number of
operations performed by users are heterogeneous. A universal behavior can be
anyway found by suppressing the intrinsic dependence of the global probability
distribution on the activity of the users. This suppression can be performed by
simply dividing the inter-event times with their average values. Differently,
waiting time probability distributions seem to be independent of the activity
of users and global probability distributions are able to significantly
represent the replying activity patterns of single users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3000</identifier>
 <datestamp>2009-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3000</id><created>2009-03-17</created><authors><author><keyname>Morelli</keyname><forenames>Michele</forenames></author><author><keyname>Sanguinetti</keyname><forenames>Luca</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>A Robust Ranging Scheme for OFDMA-Based Networks</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Uplink synchronization in orthogonal frequency-division multiple-access
(OFDMA) systems is a challenging task. In IEEE 802.16-based networks, users
that intend to establish a communication link with the base station must go
through a synchronization procedure called Initial Ranging (IR). Existing IR
schemes aim at estimating the timing offsets and power levels of ranging
subscriber stations (RSSs) without considering possible frequency misalignments
between the received uplink signals and the base station local reference. In
this work, we present a novel IR scheme for OFDMA systems where carrier
frequency offsets, timing errors and power levels are estimated for all RSSs in
a decoupled fashion. The proposed frequency estimator is based on a subspace
decomposition approach, while timing recovery is accomplished by measuring the
phase shift between the users'channel responses over adjacent subcarriers.
Computer simulations are employed to assess the effectiveness of the proposed
solution and to make comparisons with existing alternatives.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3004</identifier>
 <datestamp>2009-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3004</id><created>2009-03-17</created><authors><author><keyname>Tom&#xe1;s</keyname><forenames>Virtudes</forenames></author><author><keyname>Rosenthal</keyname><forenames>Joachim</forenames></author><author><keyname>Smarandache</keyname><forenames>Roxana</forenames></author></authors><title>Decoding of MDP Convolutional Codes over the Erasure Channel</title><categories>cs.IT math.IT</categories><msc-class>94B10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the decoding capabilities of maximum distance profile
(MDP) convolutional codes over the erasure channel and compares them with the
decoding capabilities of MDS block codes over the same channel. The erasure
channel involving large alphabets is an important practical channel model when
studying packet transmissions over a network, e.g, the Internet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3024</identifier>
 <datestamp>2009-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3024</id><created>2009-03-17</created><authors><author><keyname>Liu</keyname><forenames>Ruoheng</forenames><affiliation>Shitz</affiliation></author><author><keyname>Liu</keyname><forenames>Tie</forenames><affiliation>Shitz</affiliation></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames><affiliation>Shitz</affiliation></author><author><keyname>Shamai</keyname><forenames>Shlomo</forenames><affiliation>Shitz</affiliation></author></authors><title>A Vector Generalization of Costa's Entropy-Power Inequality with
  Applications</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE Transactions on Information Theory</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This paper considers an entropy-power inequality (EPI) of Costa and presents
a natural vector generalization with a real positive semidefinite matrix
parameter. This new inequality is proved using a perturbation approach via a
fundamental relationship between the derivative of mutual information and the
minimum mean-square error (MMSE) estimate in linear vector Gaussian channels.
As an application, a new extremal entropy inequality is derived from the
generalized Costa EPI and then used to establish the secrecy capacity regions
of the degraded vector Gaussian broadcast channel with layered confidential
messages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3072</identifier>
 <datestamp>2009-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3072</id><created>2009-03-18</created><authors><author><keyname>Son</keyname><forenames>Wanbin</forenames></author><author><keyname>Lee</keyname><forenames>Mu-Woong</forenames></author><author><keyname>Ahn</keyname><forenames>Hee-Kap</forenames></author><author><keyname>Hwang</keyname><forenames>Seung-won</forenames></author></authors><title>Spatial Skyline Queries: An Efficient Geometric Algorithm</title><categories>cs.DB cs.CG</categories><comments>18 pages, uses LNCS format</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As more data-intensive applications emerge, advanced retrieval semantics,
such as ranking or skylines, have attracted attention. Geographic information
systems are such an application with massive spatial data. Our goal is to
efficiently support skyline queries over massive spatial data. To achieve this
goal, we first observe that the best known algorithm VS2, despite its claim,
may fail to deliver correct results. In contrast, we present a simple and
efficient algorithm that computes the correct results. To validate the
effectiveness and efficiency of our algorithm, we provide an extensive
empirical comparison of our algorithm and VS2 in several aspects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3080</identifier>
 <datestamp>2009-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3080</id><created>2009-03-17</created><authors><author><keyname>Fitz</keyname><forenames>Kelly R.</forenames></author><author><keyname>Fulop</keyname><forenames>Sean A.</forenames></author></authors><title>A Unified Theory of Time-Frequency Reassignment</title><categories>cs.SD</categories><comments>38 pages, 13 figures, draft of paper submitted to Digital Signal
  Processing (Elsevier) in 2005, still in review</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Time-frequency representations such as the spectrogram are commonly used to
analyze signals having a time-varying distribution of spectral energy, but the
spectrogram is constrained by an unfortunate tradeoff between resolution in
time and frequency. A method of achieving high-resolution spectral
representations has been independently introduced by several parties. The
technique has been variously named reassignment and remapping, but while the
implementations have differed in details, they are all based on the same
theoretical and mathematical foundation. In this work, we present a brief
history of work on the method we will call the method of time-frequency
reassignment, and present a unified mathematical description of the technique
and its derivation. We will focus on the development of time-frequency
reassignment in the context of the spectrogram, and conclude with a discussion
of some current applications of the reassigned spectrogram.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3096</identifier>
 <datestamp>2009-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3096</id><created>2009-03-18</created><authors><author><keyname>Ekrem</keyname><forenames>Ersen</forenames></author><author><keyname>Ulukus</keyname><forenames>Sennur</forenames></author></authors><title>The Secrecy Capacity Region of the Gaussian MIMO Multi-receiver Wiretap
  Channel</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory, March 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the Gaussian multiple-input multiple-output (MIMO)
multi-receiver wiretap channel in which a transmitter wants to have
confidential communication with an arbitrary number of users in the presence of
an external eavesdropper. We derive the secrecy capacity region of this channel
for the most general case. We first show that even for the single-input
single-output (SISO) case, existing converse techniques for the Gaussian scalar
broadcast channel cannot be extended to this secrecy context, to emphasize the
need for a new proof technique. Our new proof technique makes use of the
relationships between the minimum-mean-square-error and the mutual information,
and equivalently, the relationships between the Fisher information and the
differential entropy. Using the intuition gained from the converse proof of the
SISO channel, we first prove the secrecy capacity region of the degraded MIMO
channel, in which all receivers have the same number of antennas, and the noise
covariance matrices can be arranged according to a positive semi-definite
order. We then generalize this result to the aligned case, in which all
receivers have the same number of antennas, however there is no order among the
noise covariance matrices. We accomplish this task by using the channel
enhancement technique. Finally, we find the secrecy capacity region of the
general MIMO channel by using some limiting arguments on the secrecy capacity
region of the aligned MIMO channel. We show that the capacity achieving coding
scheme is a variant of dirty-paper coding with Gaussian signals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3100</identifier>
 <datestamp>2009-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3100</id><created>2009-03-18</created><authors><author><keyname>Duflos</keyname><forenames>Emmanuel</forenames><affiliation>INRIA Futurs</affiliation></author><author><keyname>De Vilmorin</keyname><forenames>Marie</forenames><affiliation>LGI2A</affiliation></author><author><keyname>Vanheeghe</keyname><forenames>Philippe</forenames><affiliation>INRIA Futurs</affiliation></author></authors><title>Time Allocation of a Set of Radars in a Multitarget Environment</title><categories>math.OC cs.NI math.PR</categories><proxy>ccsd inria-00368905</proxy><journal-ref>FUSION 2007 (2007)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The question tackled here is the time allocation of radars in a multitarget
environment. At a given time radars can only observe a limited part of the
space; it is therefore necessary to move their axis with respect to time, in
order to be able to explore the overall space facing them. Such sensors are
used to detect, to locate and to identify targets which are in their
surrounding aerial space. In this paper we focus on the detection schema when
several targets need to be detected by a set of delocalized radars. This work
is based on the modelling of the radar detection performances in terms of
probability of detection and on the optimization of a criterion based on
detection probabilities. This optimization leads to the derivation of
allocation strategies and is made for several contexts and several hypotheses
about the targets locations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3103</identifier>
 <datestamp>2009-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3103</id><created>2009-03-18</created><authors><author><keyname>Shen</keyname><forenames>Chunhua</forenames></author><author><keyname>Paisitkriangkrai</keyname><forenames>Sakrapee</forenames></author><author><keyname>Zhang</keyname><forenames>Jian</forenames></author></authors><title>Efficiently Learning a Detection Cascade with Sparse Eigenvectors</title><categories>cs.MM cs.AI cs.LG</categories><comments>12 pages, conference version published in CVPR2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we first show that feature selection methods other than
boosting can also be used for training an efficient object detector. In
particular, we introduce Greedy Sparse Linear Discriminant Analysis (GSLDA)
\cite{Moghaddam2007Fast} for its conceptual simplicity and computational
efficiency; and slightly better detection performance is achieved compared with
\cite{Viola2004Robust}. Moreover, we propose a new technique, termed Boosted
Greedy Sparse Linear Discriminant Analysis (BGSLDA), to efficiently train a
detection cascade. BGSLDA exploits the sample re-weighting property of boosting
and the class-separability criterion of GSLDA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3106</identifier>
 <datestamp>2009-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3106</id><created>2009-03-18</created><authors><author><keyname>Masuzawa</keyname><forenames>Toshimitsu</forenames><affiliation>LIP6</affiliation></author><author><keyname>Tixeuil</keyname><forenames>S&#xe9;bastien</forenames><affiliation>LIP6</affiliation></author></authors><title>Stabilizing Maximal Independent Set in Unidirectional Networks is Hard</title><categories>cs.DS cs.CC cs.DC cs.NI cs.PF</categories><proxy>ccsd inria-00368950</proxy><report-no>RR-6880</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A distributed algorithm is self-stabilizing if after faults and attacks hit
the system and place it in some arbitrary global state, the system recovers
from this catastrophic situation without external intervention in finite time.
In this paper, we consider the problem of constructing self-stabilizingly a
\emph{maximal independent set} in uniform unidirectional networks of arbitrary
shape. On the negative side, we present evidence that in uniform networks,
\emph{deterministic} self-stabilization of this problem is \emph{impossible}.
Also, the \emph{silence} property (\emph{i.e.} having communication fixed from
some point in every execution) is impossible to guarantee, either for
deterministic or for probabilistic variants of protocols. On the positive side,
we present a deterministic protocol for networks with arbitrary unidirectional
networks with unique identifiers that exhibits polynomial space and time
complexity in asynchronous scheduling. We complement the study with
probabilistic protocols for the uniform case: the first probabilistic protocol
requires infinite memory but copes with asynchronous scheduling, while the
second probabilistic protocol has polynomial space complexity but can only
handle synchronous scheduling. Both probabilistic solutions have expected
polynomial time complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3114</identifier>
 <datestamp>2009-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3114</id><created>2009-03-18</created><authors><author><keyname>Held</keyname><forenames>Karsten</forenames></author><author><keyname>Kops</keyname><forenames>Elena Rota</forenames></author><author><keyname>Krause</keyname><forenames>Bernd J.</forenames></author><author><keyname>Wells</keyname><forenames>William M.</forenames><suffix>III</suffix></author><author><keyname>Kikinis</keyname><forenames>Ron</forenames></author><author><keyname>Mueller-Gaertner</keyname><forenames>Hans-Wilhelm</forenames></author></authors><title>Markov Random Field Segmentation of Brain MR Images</title><categories>cs.CV cond-mat.stat-mech physics.data-an physics.med-ph</categories><comments>34 pages, 10 figures; the paper (published in 1997) has introduced
  the concept of Markov random field to the segmentation of medical MR images.
  For the published version see http://dx.doi.org/10.1109/42.650883</comments><journal-ref>IEEE Trans. Med. Imag. vol. 16, p. 878 (1997)</journal-ref><doi>10.1109/42.650883</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a fully-automatic 3D-segmentation technique for brain MR images.
Using Markov random fields the segmentation algorithm captures three important
MR features, i.e. non-parametric distributions of tissue intensities,
neighborhood correlations and signal inhomogeneities. Detailed simulations and
real MR images demonstrate the performance of the segmentation algorithm. The
impact of noise, inhomogeneity, smoothing and structure thickness is analyzed
quantitatively. Even single echo MR images are well classified into gray
matter, white matter, cerebrospinal fluid, scalp-bone and background. A
simulated annealing and an iterated conditional modes implementation are
presented.
  Keywords: Magnetic Resonance Imaging, Segmentation, Markov Random Fields
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3126</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3126</id><created>2009-03-18</created><updated>2009-04-22</updated><authors><author><keyname>Bouajjani</keyname><forenames>Ahmed</forenames></author><author><keyname>Dragoi</keyname><forenames>Cezara</forenames></author><author><keyname>Enea</keyname><forenames>Constantin</forenames></author><author><keyname>Jurski</keyname><forenames>Yan</forenames></author><author><keyname>Sighireanu</keyname><forenames>Mihaela</forenames></author></authors><title>A Generic Framework for Reasoning about Dynamic Networks of
  Infinite-State Processes</title><categories>cs.LO</categories><comments>29 pages, 5 tables, 1 figure, extended version of the paper published
  in the the Proceedings of TACAS 2007, LNCS 4424</comments><acm-class>E.1; F.3.1; F.4.1; F.4.3; I.2.2</acm-class><journal-ref>Logical Methods in Computer Science, Volume 5, Issue 2 (April 22,
  2009) lmcs:991</journal-ref><doi>10.2168/LMCS-5(2:3)2009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a framework for reasoning about unbounded dynamic networks of
infinite-state processes. We propose Constrained Petri Nets (CPN) as generic
models for these networks. They can be seen as Petri nets where tokens
(representing occurrences of processes) are colored by values over some
potentially infinite data domain such as integers, reals, etc. Furthermore, we
define a logic, called CML (colored markings logic), for the description of CPN
configurations. CML is a first-order logic over tokens allowing to reason about
their locations and their colors. Both CPNs and CML are parametrized by a color
logic allowing to express constraints on the colors (data) associated with
tokens. We investigate the decidability of the satisfiability problem of CML
and its applications in the verification of CPNs. We identify a fragment of CML
for which the satisfiability problem is decidable (whenever it is the case for
the underlying color logic), and which is closed under the computations of post
and pre images for CPNs. These results can be used for several kinds of
analysis such as invariance checking, pre-post condition reasoning, and bounded
reachability analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3127</identifier>
 <datestamp>2010-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3127</id><created>2009-03-18</created><updated>2010-06-28</updated><authors><author><keyname>Hazan</keyname><forenames>Tamir</forenames></author><author><keyname>Shashua</keyname><forenames>Amnon</forenames></author></authors><title>Norm-Product Belief Propagation: Primal-Dual Message-Passing for
  Approximate Inference</title><categories>cs.AI cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we treat both forms of probabilistic inference, estimating
marginal probabilities of the joint distribution and finding the most probable
assignment, through a unified message-passing algorithm architecture. We
generalize the Belief Propagation (BP) algorithms of sum-product and
max-product and tree-rewaighted (TRW) sum and max product algorithms (TRBP) and
introduce a new set of convergent algorithms based on &quot;convex-free-energy&quot; and
Linear-Programming (LP) relaxation as a zero-temprature of a
convex-free-energy. The main idea of this work arises from taking a general
perspective on the existing BP and TRBP algorithms while observing that they
all are reductions from the basic optimization formula of $f + \sum_i h_i$
where the function $f$ is an extended-valued, strictly convex but non-smooth
and the functions $h_i$ are extended-valued functions (not necessarily convex).
We use tools from convex duality to present the &quot;primal-dual ascent&quot; algorithm
which is an extension of the Bregman successive projection scheme and is
designed to handle optimization of the general type $f + \sum_i h_i$. Mapping
the fractional-free-energy variational principle to this framework introduces
the &quot;norm-product&quot; message-passing. Special cases include sum-product and
max-product (BP algorithms) and the TRBP algorithms. When the
fractional-free-energy is set to be convex (convex-free-energy) the
norm-product is globally convergent for estimating of marginal probabilities
and for approximating the LP-relaxation. We also introduce another branch of
the norm-product, the &quot;convex-max-product&quot;. The convex-max-product is
convergent (unlike max-product) and aims at solving the LP-relaxation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3131</identifier>
 <datestamp>2009-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3131</id><created>2009-03-18</created><authors><author><keyname>Candes</keyname><forenames>Emmanuel J.</forenames></author><author><keyname>Plan</keyname><forenames>Yaniv</forenames></author></authors><title>Matrix Completion With Noise</title><categories>cs.IT math.IT</categories><comments>11 pages, 4 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  On the heels of compressed sensing, a remarkable new field has very recently
emerged. This field addresses a broad range of problems of significant
practical interest, namely, the recovery of a data matrix from what appears to
be incomplete, and perhaps even corrupted, information. In its simplest form,
the problem is to recover a matrix from a small sample of its entries, and
comes up in many areas of science and engineering including collaborative
filtering, machine learning, control, remote sensing, and computer vision to
name a few.
  This paper surveys the novel literature on matrix completion, which shows
that under some suitable conditions, one can recover an unknown low-rank matrix
from a nearly minimal set of entries by solving a simple convex optimization
problem, namely, nuclear-norm minimization subject to data constraints.
Further, this paper introduces novel results showing that matrix completion is
provably accurate even when the few observed entries are corrupted with a small
amount of noise. A typical result is that one can recover an unknown n x n
matrix of low rank r from just about nr log^2 n noisy samples with an error
which is proportional to the noise level. We present numerical results which
complement our quantitative analysis and show that, in practice, nuclear norm
minimization accurately fills in the many missing entries of large low-rank
matrices from just a few noisy samples. Some analogies between matrix
completion and compressed sensing are discussed throughout.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3163</identifier>
 <datestamp>2009-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3163</id><created>2009-03-18</created><authors><author><keyname>Dhar</keyname><forenames>Sourav</forenames></author><author><keyname>Kandar</keyname><forenames>Debdattta</forenames></author><author><keyname>Bose</keyname><forenames>Tanushree</forenames></author><author><keyname>Bera</keyname><forenames>Rabindranath</forenames></author></authors><title>Smart Antenna Based Broadband communication in Intelligent
  Transportation system</title><categories>cs.NI</categories><comments>4 pages, 2 figs., published in NCEEERE 2008, 23-24 December 2008,
  sikkim, INDIA</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a review for the development of Intelligent
Transportation System (ITS) world wide and the use of Smart Antennas in ITS.
This review work also discusses the usual problems in ITS and proposes the
solution of such problems using smart antennas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3165</identifier>
 <datestamp>2009-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3165</id><created>2009-03-18</created><authors><author><keyname>Dutta</keyname><forenames>Victor</forenames></author><author><keyname>Bera</keyname><forenames>R.</forenames></author><author><keyname>Dhar</keyname><forenames>Sourav</forenames></author><author><keyname>Chakravorty</keyname><forenames>Jaydeep</forenames></author><author><keyname>Bagehel</keyname><forenames>Nishant</forenames></author></authors><title>Automated Vehicle Location (AVL) Using Global Positioning System (GPS)</title><categories>cs.NI</categories><comments>6 pages,10figs.,published in NCEEERE 2008,23-24 December 2008,
  sikkim, INDIA</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  this is a review paper. this describes how DGPS is helpful for lane detection
and to avoid collission.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3182</identifier>
 <datestamp>2009-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3182</id><created>2009-03-18</created><authors><author><keyname>Dubrova</keyname><forenames>Elena</forenames></author></authors><title>Finding matching initial states for equivalent NLFSRs in the fibonacci
  and the galois configurations</title><categories>cs.CR</categories><comments>4 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a mapping between initial states of the Fibonacci and the
Galois configurations of NLFSRs is established. We show how to choose initial
states for two configurations so that the resulting output sequences are
equivalent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3198</identifier>
 <datestamp>2009-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3198</id><created>2009-03-18</created><authors><author><keyname>Gemmeke</keyname><forenames>J. F.</forenames></author><author><keyname>Cranen</keyname><forenames>B.</forenames></author></authors><title>TR02: State dependent oracle masks for improved dynamical features</title><categories>cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using the AURORA-2 digit recognition task, we show that recognition
accuracies obtained with classical, SNR based oracle masks can be substantially
improved by using a state-dependent mask estimation technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3204</identifier>
 <datestamp>2009-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3204</id><created>2009-03-18</created><updated>2009-05-18</updated><authors><author><keyname>Senger</keyname><forenames>Christian</forenames></author><author><keyname>Sidorenko</keyname><forenames>Vladimir</forenames></author><author><keyname>Zyablov</keyname><forenames>Victor</forenames></author></authors><title>On Generalized Minimum Distance Decoding Thresholds for the AWGN Channel</title><categories>cs.IT math.IT</categories><comments>Accepted for the XII International Symposium on Problems of
  Redundancy in Information and Control Systems, St. Petersburg, Russia, May 26
  - 30, 2009. 5 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the Additive White Gaussian Noise channel with Binary Phase Shift
Keying modulation. Our aim is to enable an algebraic hard decision Bounded
Minimum Distance decoder for a binary block code to exploit soft information
obtained from the demodulator. This idea goes back to Forney and is based on
treating received symbols with low reliability as erasures. This erasing at the
decoder is done using a threshold, each received symbol with reliability
falling below the threshold is erased. Depending on the target overall
complexity of the decoder this pseudo-soft decision decoding can be extended
from one threshold T to z&gt;1 thresholds T_1&lt;...&lt;T_z for erasing received symbols
with lowest reliability. The resulting technique is widely known as Generalized
Minimum Distance decoding. In this paper we provide a means for explicit
determination of the optimal threshold locations in terms of minimal decoding
error probability. We do this for the one and the general z&gt;1 thresholds case,
starting with a geometric interpretation of the optimal threshold location
problem and using an approach from Zyablov.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3218</identifier>
 <datestamp>2009-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3218</id><created>2009-03-18</created><authors><author><keyname>Karlin</keyname><forenames>Josh</forenames><affiliation>University of New Mexico</affiliation></author><author><keyname>Forrest</keyname><forenames>Stephanie</forenames><affiliation>University of New Mexico and the Santa Fe Institute</affiliation></author><author><keyname>Rexford</keyname><forenames>Jennifer</forenames><affiliation>Princeton University</affiliation></author></authors><title>Nation-State Routing: Censorship, Wiretapping, and BGP</title><categories>cs.NI cs.CR cs.CY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The treatment of Internet traffic is increasingly affected by national
policies that require the ISPs in a country to adopt common protocols or
practices. Examples include government enforced censorship, wiretapping, and
protocol deployment mandates for IPv6 and DNSSEC. If an entire nation's worth
of ISPs apply common policies to Internet traffic, the global implications
could be significant. For instance, how many countries rely on China or Great
Britain (known traffic censors) to transit their traffic? These kinds of
questions are surprisingly difficult to answer, as they require combining
information collected at the prefix, Autonomous System, and country level, and
grappling with incomplete knowledge about the AS-level topology and routing
policies. In this paper we develop the first framework for country-level
routing analysis, which allows us to answer questions about the influence of
each country on the flow of international traffic. Our results show that some
countries known for their national policies, such as Iran and China, have
relatively little effect on interdomain routing, while three countries (the
United States, Great Britain, and Germany) are central to international
reachability, and their policies thus have huge potential impact.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3228</identifier>
 <datestamp>2009-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3228</id><created>2009-03-18</created><authors><author><keyname>Kurtz</keyname><forenames>Michael J.</forenames></author><author><keyname>Accomazzi</keyname><forenames>Alberto</forenames></author><author><keyname>Murray</keyname><forenames>Stephen S.</forenames></author></authors><title>The Smithsonian/NASA Astrophysics Data System (ADS) Decennial Report</title><categories>astro-ph.IM cs.DL</categories><comments>6 pages, whitepaper submitted to the National Research Council
  Astronomy and Astrophysics Decadal Survey</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Eight years after the ADS first appeared the last decadal survey wrote:
&quot;NASA's initiative for the Astrophysics Data System has vastly increased the
accessibility of the scientific literature for astronomers. NASA deserves
credit for this valuable initiative and is urged to continue it.&quot; Here we
summarize some of the changes concerning the ADS which have occurred in the
past ten years, and we describe the current status of the ADS. We then point
out two areas where the ADS is building an improved capability which could
benefit from a policy statement of support in the ASTRO2010 report. These are:
The Semantic Interlinking of Astronomy Observations and Datasets and The
Indexing of the Full Text of Astronomy Research Publications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3257</identifier>
 <datestamp>2009-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3257</id><created>2009-03-18</created><authors><author><keyname>Zhang</keyname><forenames>Ke</forenames></author><author><keyname>Hutter</keyname><forenames>Marcus</forenames></author><author><keyname>Jin</keyname><forenames>Huidong</forenames></author></authors><title>A New Local Distance-Based Outlier Detection Approach for Scattered
  Real-World Data</title><categories>cs.LG cs.IR</categories><comments>15 LaTeX pages, 7 figures, 2 tables, 1 algorithm, 2 theorems</comments><journal-ref>Proc. 13th Pacific-Asia Conf. on Knowledge Discovery and Data
  Mining (PAKDD 2009) pages 813-822</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Detecting outliers which are grossly different from or inconsistent with the
remaining dataset is a major challenge in real-world KDD applications. Existing
outlier detection methods are ineffective on scattered real-world datasets due
to implicit data patterns and parameter setting issues. We define a novel
&quot;Local Distance-based Outlier Factor&quot; (LDOF) to measure the {outlier-ness} of
objects in scattered datasets which addresses these issues. LDOF uses the
relative location of an object to its neighbours to determine the degree to
which the object deviates from its neighbourhood. Properties of LDOF are
theoretically analysed including LDOF's lower bound and its false-detection
probability, as well as parameter settings. In order to facilitate parameter
settings in real-world applications, we employ a top-n technique in our outlier
detection approach, where only the objects with the highest LDOF values are
regarded as outliers. Compared to conventional approaches (such as top-n KNN
and top-n LOF), our method top-n LDOF is more effective at detecting outliers
in scattered data. It is also easier to set parameters, since its performance
is relatively stable over a large range of parameter values, as illustrated by
experimental results on both real-world and synthetic datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3261</identifier>
 <datestamp>2009-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3261</id><created>2009-03-18</created><updated>2009-10-19</updated><authors><author><keyname>Bagherikaram</keyname><forenames>Ghadamali</forenames></author><author><keyname>Motahari</keyname><forenames>Abolfazl S.</forenames></author><author><keyname>Khandani</keyname><forenames>Amir K.</forenames></author></authors><title>The Secrecy Capacity Region of the Gaussian MIMO Broadcast Channel</title><categories>cs.IT math.IT</categories><comments>23 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider a scenario where a source node wishes to broadcast
two confidential messages for two respective receivers via a Gaussian MIMO
broadcast channel. A wire-tapper also receives the transmitted signal via
another MIMO channel. First we assumed that the channels are degraded and the
wire-tapper has the worst channel. We establish the capacity region of this
scenario. Our achievability scheme is a combination of the superposition of
Gaussian codes and randomization within the layers which we will refer to as
Secret Superposition Coding. For the outerbound, we use the notion of enhanced
channel to show that the secret superposition of Gaussian codes is optimal. We
show that we only need to enhance the channels of the legitimate receivers, and
the channel of the eavesdropper remains unchanged. Then we extend the result of
the degraded case to non-degraded case. We show that the secret superposition
of Gaussian codes along with successive decoding cannot work when the channels
are not degraded. we develop a Secret Dirty Paper Coding (SDPC) scheme and show
that SDPC is optimal for this channel. Finally, we investigate practical
characterizations for the specific scenario in which the transmitter and the
eavesdropper have multiple antennas, while both intended receivers have a
single antenna. We characterize the secrecy capacity region in terms of
generalized eigenvalues of the receivers channel and the eavesdropper channel.
We refer to this configuration as the MISOME case. In high SNR we show that the
capacity region is a convex closure of two rectangular regions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3276</identifier>
 <datestamp>2009-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3276</id><created>2009-03-19</created><authors><author><keyname>Narayanan</keyname><forenames>Arvind</forenames></author><author><keyname>Shmatikov</keyname><forenames>Vitaly</forenames></author></authors><title>De-anonymizing Social Networks</title><categories>cs.CR cs.DS</categories><comments>Published in the 30th IEEE Symposium on Security and Privacy, 2009.
  The definitive version is available at:
  http://www.cs.utexas.edu/~shmat/shmat_oak09.pdf Frequently Asked Questions
  are answered at: http://www.cs.utexas.edu/~shmat/socialnetworks-faq.html</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Operators of online social networks are increasingly sharing potentially
sensitive information about users and their relationships with advertisers,
application developers, and data-mining researchers. Privacy is typically
protected by anonymization, i.e., removing names, addresses, etc.
  We present a framework for analyzing privacy and anonymity in social networks
and develop a new re-identification algorithm targeting anonymized
social-network graphs. To demonstrate its effectiveness on real-world networks,
we show that a third of the users who can be verified to have accounts on both
Twitter, a popular microblogging service, and Flickr, an online photo-sharing
site, can be re-identified in the anonymous Twitter graph with only a 12% error
rate.
  Our de-anonymization algorithm is based purely on the network topology, does
not require creation of a large number of dummy &quot;sybil&quot; nodes, is robust to
noise and all existing defenses, and works even when the overlap between the
target network and the adversary's auxiliary information is small.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3278</identifier>
 <datestamp>2010-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3278</id><created>2009-03-19</created><updated>2009-06-15</updated><authors><author><keyname>Xu</keyname><forenames>Yuedong</forenames></author><author><keyname>Lui</keyname><forenames>John C. S.</forenames></author><author><keyname>Chiu</keyname><forenames>Dah-Ming</forenames></author></authors><title>On Oligopoly Spectrum Allocation Game in Cognitive Radio Networks with
  Capacity Constraints</title><categories>cs.NI cs.GT</categories><comments>40 pages, 22 figures</comments><journal-ref>Elsevier, Computer Networks, 2010</journal-ref><doi>10.1016/j.comnet.2009.11.018</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dynamic spectrum sharing is a promising technology to improve spectrum
utilization in the future wireless networks. The flexible spectrum management
provides new opportunities for licensed primary user and unlicensed secondary
users to reallocate the spectrum resource efficiently. In this paper, we
present an oligopoly pricing framework for dynamic spectrum allocation in which
the primary users sell excessive spectrum to the secondary users for monetary
return. We present two approaches, the strict constraints (type-I) and the QoS
penalty (type-II), to model the realistic situation that the primary users have
limited capacities. In the oligopoly model with strict constraints, we propose
a low-complexity searching method to obtain the Nash Equilibrium and prove its
uniqueness. When reduced to a duopoly game, we analytically show the
interesting gaps in the leader-follower pricing strategy. In the QoS penalty
based oligopoly model, a novel variable transformation method is developed to
derive the unique Nash Equilibrium. When the market information is limited, we
provide three myopically optimal algorithms &quot;StrictBEST&quot;, &quot;StrictBR&quot; and
&quot;QoSBEST&quot; that enable price adjustment for duopoly primary users based on the
Best Response Function (BRF) and the bounded rationality (BR) principles.
Numerical results validate the effectiveness of our analysis and demonstrate
the fast convergence of &quot;StrictBEST&quot; as well as &quot;QoSBEST&quot; to the Nash
Equilibrium. For the &quot;StrictBR&quot; algorithm, we reveal the chaotic behaviors of
dynamic price adaptation in response to the learning rates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3287</identifier>
 <datestamp>2009-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3287</id><created>2009-03-19</created><authors><author><keyname>Nielsen</keyname><forenames>Frank</forenames></author><author><keyname>Nock</keyname><forenames>Richard</forenames></author></authors><title>Hyperbolic Voronoi diagrams made easy</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a simple framework to compute hyperbolic Voronoi diagrams of
finite point sets as affine diagrams. We prove that bisectors in Klein's
non-conformal disk model are hyperplanes that can be interpreted as power
bisectors of Euclidean balls. Therefore our method simply consists in computing
an equivalent clipped power diagram followed by a mapping transformation
depending on the selected representation of the hyperbolic space (e.g.,
Poincar\'e conformal disk or upper-plane representations). We discuss on
extensions of this approach to weighted and $k$-order diagrams, and describe
their dual triangulations. Finally, we consider two useful primitives on the
hyperbolic Voronoi diagrams for designing tailored user interfaces of an image
catalog browsing application in the hyperbolic disk: (1) finding nearest
neighbors, and (2) computing smallest enclosing balls.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3311</identifier>
 <datestamp>2009-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3311</id><created>2009-03-19</created><updated>2009-06-12</updated><authors><author><keyname>Dumas</keyname><forenames>Jean-Guillaume</forenames><affiliation>LJK</affiliation></author><author><keyname>Duval</keyname><forenames>Dominique</forenames><affiliation>LJK</affiliation></author><author><keyname>Reynaud</keyname><forenames>Jean-Claude</forenames><affiliation>RC</affiliation></author></authors><title>Cartesian effect categories are Freyd-categories</title><categories>cs.LO math.CT</categories><comments>23 pages</comments><proxy>ccsd hal-00369328</proxy><acm-class>F.3.2; D.3.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most often, in a categorical semantics for a programming language, the
substitution of terms is expressed by composition and finite products. However
this does not deal with the order of evaluation of arguments, which may have
major consequences when there are side-effects. In this paper Cartesian effect
categories are introduced for solving this issue, and they are compared with
strong monads, Freyd-categories and Haskell's Arrows. It is proved that a
Cartesian effect category is a Freyd-category where the premonoidal structure
is provided by a kind of binary product, called the sequential product. The
universal property of the sequential product provides Cartesian effect
categories with a powerful tool for constructions and proofs. To our knowledge,
both effect categories and sequential products are new notions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3317</identifier>
 <datestamp>2009-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3317</id><created>2009-03-19</created><updated>2009-06-12</updated><authors><author><keyname>Song</keyname><forenames>Shaoxu</forenames></author><author><keyname>Chen</keyname><forenames>Lei</forenames></author></authors><title>Discovering Matching Dependencies</title><categories>cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The concept of matching dependencies (mds) is recently pro- posed for
specifying matching rules for object identification. Similar to the functional
dependencies (with conditions), mds can also be applied to various data quality
applications such as violation detection. In this paper, we study the problem
of discovering matching dependencies from a given database instance. First, we
formally define the measures, support and confidence, for evaluating utility of
mds in the given database instance. Then, we study the discovery of mds with
certain utility requirements of support and confidence. Exact algorithms are
developed, together with pruning strategies to improve the time performance.
Since the exact algorithm has to traverse all the data during the computation,
we propose an approximate solution which only use some of the data. A bound of
relative errors introduced by the approximation is also developed. Finally, our
experimental evaluation demonstrates the efficiency of the proposed methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3329</identifier>
 <datestamp>2009-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3329</id><created>2009-03-19</created><authors><author><keyname>Br&#xe9;hard</keyname><forenames>Thomas</forenames><affiliation>INRIA Futurs</affiliation></author><author><keyname>Duflos</keyname><forenames>Emmanuel</forenames><affiliation>INRIA Futurs, LAGIS</affiliation></author><author><keyname>Vanheeghe</keyname><forenames>Philippe</forenames><affiliation>LAGIS</affiliation></author><author><keyname>Coquelin</keyname><forenames>Pierre-Arnaud</forenames><affiliation>INRIA Futurs</affiliation></author></authors><title>Optimal Policies Search for Sensor Management</title><categories>cs.LG stat.AP</categories><proxy>ccsd inria-00368875</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a new approach to solve sensor management problems.
Classically sensor management problems can be well formalized as
Partially-Observed Markov Decision Processes (POMPD). The original approach
developped here consists in deriving the optimal parameterized policy based on
a stochastic gradient estimation. We assume in this work that it is possible to
learn the optimal policy off-line (in simulation) using models of the
environement and of the sensor(s). The learned policy can then be used to
manage the sensor(s). In order to approximate the gradient in a stochastic
context, we introduce a new method to approximate the gradient, based on
Infinitesimal Perturbation Approximation (IPA). The effectiveness of this
general framework is illustrated by the managing of an Electronically Scanned
Array Radar. First simulations results are finally proposed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3433</identifier>
 <datestamp>2009-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3433</id><created>2009-03-19</created><authors><author><keyname>Tadaki</keyname><forenames>Kohtaro</forenames></author></authors><title>Fixed point theorems on partial randomness</title><categories>cs.IT cs.CC math.IT math.LO math.PR</categories><comments>19 pages, LaTeX2e, no figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In our former work [K. Tadaki, Local Proceedings of CiE 2008, pp.425-434,
2008], we developed a statistical mechanical interpretation of algorithmic
information theory by introducing the notion of thermodynamic quantities at
temperature T, such as free energy F(T), energy E(T), and statistical
mechanical entropy S(T), into the theory. These quantities are real functions
of real argument T&gt;0. We then discovered that, in the interpretation, the
temperature T equals to the partial randomness of the values of all these
thermodynamic quantities, where the notion of partial randomness is a stronger
representation of the compression rate by program-size complexity. Furthermore,
we showed that this situation holds for the temperature itself as a
thermodynamic quantity. Namely, the computability of the value of partition
function Z(T) gives a sufficient condition for T in (0,1) to be a fixed point
on partial randomness. In this paper, we show that the computability of each of
all the thermodynamic quantities above gives the sufficient condition also.
Moreover, we show that the computability of F(T) gives completely different
fixed points from the computability of Z(T).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3461</identifier>
 <datestamp>2009-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3461</id><created>2009-03-20</created><authors><author><keyname>Delporte-Gallet</keyname><forenames>Carole</forenames><affiliation>LIAFA</affiliation></author><author><keyname>Fauconnier</keyname><forenames>Hugues</forenames><affiliation>LIAFA</affiliation></author><author><keyname>Tielmann</keyname><forenames>Andreas</forenames><affiliation>LIAFA</affiliation></author></authors><title>Fault-Tolerant Consensus in Unknown and Anonymous Networks</title><categories>cs.DS cs.DC</categories><proxy>ccsd hal-00369280</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates under which conditions information can be reliably
shared and consensus can be solved in unknown and anonymous message-passing
networks that suffer from crash-failures. We provide algorithms to emulate
registers and solve consensus under different synchrony assumptions. For this,
we introduce a novel pseudo leader-election approach which allows a
leader-based consensus implementation without breaking symmetry.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3462</identifier>
 <datestamp>2009-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3462</id><created>2009-03-20</created><authors><author><keyname>Santocanale</keyname><forenames>Luigi</forenames><affiliation>LIF</affiliation></author></authors><title>A Nice Labelling for Tree-Like Event Structures of Degree 3 (Extended
  Version)</title><categories>cs.DC</categories><proxy>ccsd hal-00369451</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the problem of finding nice labellings for event structures of
degree 3. We develop a minimum theory by which we prove that the labelling
number of an event structure of degree 3 is bounded by a linear function of the
height. The main theorem we present in this paper states that event structures
of degree 3 whose causality order is a tree have a nice labelling with 3
colors. Finally, we exemplify how to use this theorem to construct upper bounds
for the labelling number of other event structures of degree 3.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3480</identifier>
 <datestamp>2009-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3480</id><created>2009-03-20</created><updated>2009-08-18</updated><authors><author><keyname>Furon</keyname><forenames>Teddy</forenames></author><author><keyname>Perez-Freire</keyname><forenames>Luis</forenames></author></authors><title>Worst case attacks against binary probabilistic traitor tracing codes</title><categories>cs.IT cs.CR math.IT</categories><comments>submitted to IEEE Trans. on Information Forensics and Security</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An insightful view into the design of traitor tracing codes should
necessarily consider the worst case attacks that the colluders can lead. This
paper takes an information-theoretic point of view where the worst case attack
is defined as the collusion strategy minimizing the achievable rate of the
traitor tracing code. Two different decoders are envisaged, the joint decoder
and the simple decoder, as recently defined by P. Moulin
\cite{Moulin08universal}. Several classes of colluders are defined with
increasing power. The worst case attack is derived for each class and each
decoder when applied to Tardos' codes and a probabilistic version of the
Boneh-Shaw construction. This contextual study gives the real rates achievable
by the binary probabilistic traitor tracing codes. Attacks usually considered
in literature, such as majority or minority votes, are indeed largely
suboptimal. This article also shows the utmost importance of the time-sharing
concept in a probabilistic codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3487</identifier>
 <datestamp>2009-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3487</id><created>2009-03-20</created><authors><author><keyname>Lapidoth</keyname><forenames>Amos</forenames></author><author><keyname>Tinguely</keyname><forenames>Stephan</forenames></author></authors><title>Sending a Bivariate Gaussian Source over a Gaussian MAC with Feedback</title><categories>cs.IT math.IT</categories><comments>submitted to the IEEE Transactions on Information Theory</comments><acm-class>E.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the power-versus-distortion trade-off for the transmission of a
memoryless bivariate Gaussian source over a two-to-one Gaussian multiple-access
channel with perfect causal feedback. In this problem, each of two separate
transmitters observes a different component of a memoryless bivariate Gaussian
source as well as the feedback from the channel output of the previous
time-instants. Based on the observed source sequence and the feedback, each
transmitter then describes its source component to the common receiver via an
average-power constrained Gaussian multiple-access channel. From the resulting
channel output, the receiver wishes to reconstruct both source components with
the least possible expected squared-error distortion. We study the set of
distortion pairs that can be achieved by the receiver on the two source
components.
  We present sufficient conditions and necessary conditions for the
achievability of a distortion pair. These conditions are expressed in terms of
the source correlation and of the signal-to-noise ratio (SNR) of the channel.
In several cases the necessary conditions and sufficient conditions coincide.
This allows us to show that if the channel SNR is below a certain threshold,
then an uncoded transmission scheme that ignores the feedback is optimal. Thus,
below this SNR-threshold feedback is useless. We also derive the precise
high-SNR asymptotics of optimal schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3513</identifier>
 <datestamp>2009-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3513</id><created>2009-03-20</created><authors><author><keyname>Syropoulos</keyname><forenames>Apostolos</forenames></author></authors><title>Fuzzy Chemical Abstract Machines</title><categories>cs.FL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fuzzy set theory opens new vistas in computability theory and here I show
this by defining a new computational metaphor--the fuzzy chemical metaphor.
This metaphor is an extension of the chemical metaphor. In particular, I
introduce the idea of a state of a system as a solution of fuzzy molecules,
that is molecules that are not just different but rather similar, that react
according to a set of fuzzy reaction rules. These notions become precise by
introducing fuzzy labeled transition systems. Solutions of fuzzy molecules and
fuzzy reaction rules are used to define the general notion of a fuzzy chemical
abstract machine, which is a {\em realization} of the fuzzy chemical metaphor.
Based on the idea that these machines can be used to describe the operational
semantics of process calculi and algebras that include fuzziness as a
fundamental property, I present a toy calculus that is a fuzzy equivalent of
the $\pi$-calculus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3524</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3524</id><created>2009-03-20</created><authors><author><keyname>Cheng</keyname><forenames>Jin-San</forenames></author><author><keyname>Gao</keyname><forenames>Xiao-Shan</forenames></author><author><keyname>Li</keyname><forenames>Jia</forenames></author></authors><title>Ambient Isotopic Meshing of Implicit Algebraic Surface with
  Singularities</title><categories>cs.CG cs.GR</categories><comments>34 pages, 17 Postscript figures</comments><report-no>MM-preprints, vol. 27, 2008</report-no><acm-class>G.1.2</acm-class><doi>10.1007/978-3-642-04103-7_9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A complete method is proposed to compute a certified, or ambient isotopic,
meshing for an implicit algebraic surface with singularities. By certified, we
mean a meshing with correct topology and any given geometric precision. We
propose a symbolic-numeric method to compute a certified meshing for the
surface inside a box containing singularities and use a modified
Plantinga-Vegter marching cube method to compute a certified meshing for the
surface inside a box without singularities. Nontrivial examples are given to
show the effectiveness of the algorithm. To our knowledge, this is the first
method to compute a certified meshing for surfaces with singularities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3537</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3537</id><created>2009-03-20</created><updated>2010-02-05</updated><authors><author><keyname>Oreshkin</keyname><forenames>Boris N.</forenames></author><author><keyname>Coates</keyname><forenames>Mark J.</forenames></author><author><keyname>Rabbat</keyname><forenames>Michael G.</forenames></author></authors><title>Optimization and Analysis of Distributed Averaging with Short Node
  Memory</title><categories>cs.DC cs.IT cs.MA math.IT</categories><doi>10.1109/TSP.2010.2043127</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we demonstrate, both theoretically and by numerical examples,
that adding a local prediction component to the update rule can significantly
improve the convergence rate of distributed averaging algorithms. We focus on
the case where the local predictor is a linear combination of the node's two
previous values (i.e., two memory taps), and our update rule computes a
combination of the predictor and the usual weighted linear combination of
values received from neighbouring nodes. We derive the optimal mixing parameter
for combining the predictor with the neighbors' values, and carry out a
theoretical analysis of the improvement in convergence rate that can be
obtained using this acceleration methodology. For a chain topology on n nodes,
this leads to a factor of n improvement over the one-step algorithm, and for a
two-dimensional grid, our approach achieves a factor of n^1/2 improvement, in
terms of the number of iterations required to reach a prescribed level of
accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3545</identifier>
 <datestamp>2009-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3545</id><created>2009-03-20</created><authors><author><keyname>Boon</keyname><forenames>Jean Pierre</forenames></author></authors><title>Complexity, time and music</title><categories>physics.soc-ph cs.SD physics.data-an</categories><comments>4 pages with 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The concept of complexity as considered in terms of its algorithmic
definition proposed by G.J. Chaitin and A.N. Kolmogorov is revisited for the
dynamical complexity of music. When music pieces are cast in the form of time
series of pitch variations, concepts of dynamical systems theory can be used to
define new quantities such as the {\em dimensionality} as a measure of the {\em
global temporal dynamics} of a music piece, and the Shanon {\em entropy} as an
evaluation of its {\em local dynamics}. When these quantities are computed
explicitly for sequences sampled in the music literature from the 18th to the
20th century, no indication is found of a systematic increase in complexity
paralleling historically the evolution of classical western music, but the
analysis suggests that the fractional nature of art might have an intrinsic
value of more general significance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3562</identifier>
 <datestamp>2009-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3562</id><created>2009-03-20</created><authors><author><keyname>Boerner</keyname><forenames>Katy</forenames></author><author><keyname>Scharnhorst</keyname><forenames>Andrea</forenames></author></authors><title>Visual Conceptualizations and Models of Science</title><categories>cs.DL physics.soc-ph</categories><comments>Guest Editor's Introduction to the 2009 Journal of Informetrics
  Special Issue on the Science of Science</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This Journal of Informetrics special issue aims to improve our understanding
of the structure and dynamics of science by reviewing and advancing existing
conceptualizations and models of scholarly activity. Several of these
conceptualizations and models have visual manifestations supporting the
combination and comparison of theories and approaches developed in different
disciplines of science. Subsequently, we discuss challenges towards a
theoretically grounded and practically useful science of science and provide a
brief chronological review of relevant work. Then, we exemplarily present three
conceptualizations of science that attempt to provide frameworks for the
comparison and combination of existing approaches, theories, laws, and
measurements. Finally, we discuss the contributions of and interlinkages among
the eight papers included in this issue. Each paper makes a unique contribution
towards conceptualizations and models of science and roots this contribution in
a review and comparison with existing work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3579</identifier>
 <datestamp>2009-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3579</id><created>2009-03-20</created><authors><author><keyname>Krusche</keyname><forenames>Peter</forenames></author><author><keyname>Tiskin</keyname><forenames>Alexander</forenames></author></authors><title>String comparison by transposition networks</title><categories>cs.DS cs.DM</categories><comments>Published in London Algorithmics 2008: Theory And Practice, to appear</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computing string or sequence alignments is a classical method of comparing
strings and has applications in many areas of computing, such as signal
processing and bioinformatics. Semi-local string alignment is a recent
generalisation of this method, in which the alignment of a given string and all
substrings of another string are computed simultaneously at no additional
asymptotic cost. In this paper, we show that there is a close connection
between semi-local string alignment and a certain class of traditional
comparison networks known as transposition networks. The transposition network
approach can be used to represent different string comparison algorithms in a
unified form, and in some cases provides generalisations or improvements on
existing algorithms. This approach allows us to obtain new algorithms for
sparse semi-local string comparison and for comparison of highly similar and
highly dissimilar strings, as well as of run-length compressed strings. We
conclude that the transposition network method is a very general and flexible
way of understanding and improving different string comparison algorithms, as
well as their efficient implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3622</identifier>
 <datestamp>2009-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3622</id><created>2009-03-20</created><authors><author><keyname>Andreica</keyname><forenames>Mugurel Ionut</forenames></author><author><keyname>Briciu</keyname><forenames>Sorin</forenames></author><author><keyname>Andreica</keyname><forenames>Madalina Ecaterina</forenames></author></authors><title>Algorithmic Solutions to Some Transportation Optimization Problems with
  Applications in the Metallurgical Industry</title><categories>cs.DS cs.CG cs.DM</categories><acm-class>G.2.2; G.2.1</acm-class><journal-ref>Metalurgia International, vol. 14, special issue no. 5, pp. 46-53,
  2009. (ISSN: 1582-2214) ; http://www.metalurgia.ro/metalurgia_int.html</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we address several constrained transportation optimization
problems (e.g. vehicle routing, shortest Hamiltonian path), for which we
present novel algorithmic solutions and extensions, considering several
optimization objectives, like minimizing costs and resource usage. All the
considered problems are motivated by practical situations arising, for
instance, in the mining and metallurgical industry or in data communication. We
restrict our attention to transportation networks with path, tree or geometric
structures, for which the developed polynomial-time algorithms are optimal or
nearly optimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3623</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3623</id><created>2009-03-20</created><authors><author><keyname>Slater</keyname><forenames>Paul B.</forenames></author></authors><title>Matrix plots of reordered bistochastized transaction flow tables: A
  United States intercounty migration example</title><categories>physics.soc-ph cs.SI physics.data-an stat.AP</categories><comments>12 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a number of variously rearranged matrix plots of the $3, 107
\times 3, 107$ 1995-2000 (asymmetric) intercounty migration table for the
United States, principally in its bistochasticized form (all 3,107 row and
column sums iteratively proportionally fitted to equal 1). In one set of plots,
the counties are seriated on the bases of the subdominant (left and right)
eigenvectors of the bistochastic matrix. In another set, we use the ordering of
counties in the dendrogram generated by the associated strong component
hierarchical clustering. Interesting, diverse features of U. S. intercounty
migration emerge--such as a contrast in centralized, hub-like
(cosmopolitan/provincial) properties between cosmopolitan &quot;Sunbelt&quot; and
provincial &quot;Black Belt&quot; counties. The methodologies employed should also be
insightful for the many other diverse forms of interesting transaction
flow-type data--interjournal citations being an obvious, much-studied example,
where one might expect that the journals Science, Nature and PNAS would display
&quot;cosmopolitan&quot; characteristics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3624</identifier>
 <datestamp>2009-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3624</id><created>2009-03-20</created><authors><author><keyname>Pavone</keyname><forenames>Marco</forenames></author><author><keyname>Frazzoli</keyname><forenames>Emilio</forenames></author><author><keyname>Bullo</keyname><forenames>Francesco</forenames></author></authors><title>Distributed and Adaptive Algorithms for Vehicle Routing in a Stochastic
  and Dynamic Environment</title><categories>cs.RO</categories><comments>Paper to be submitted to IEEE Transactions on Automatic Control</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present distributed and adaptive algorithms for motion
coordination of a group of m autonomous vehicles. The vehicles operate in a
convex environment with bounded velocity and must service demands whose time of
arrival, location and on-site service are stochastic; the objective is to
minimize the expected system time (wait plus service) of the demands. The
general problem is known as the m-vehicle Dynamic Traveling Repairman Problem
(m-DTRP). The best previously known control algorithms rely on centralized
a-priori task assignment and are not robust against changes in the environment,
e.g. changes in load conditions; therefore, they are of limited applicability
in scenarios involving ad-hoc networks of autonomous vehicles operating in a
time-varying environment. First, we present a new class of policies for the
1-DTRP problem that: (i) are provably optimal both in light- and heavy-load
condition, and (ii) are adaptive, in particular, they are robust against
changes in load conditions. Second, we show that partitioning policies, whereby
the environment is partitioned among the vehicles and each vehicle follows a
certain set of rules in its own region, are optimal in heavy-load conditions.
Finally, by combining the new class of algorithms for the 1-DTRP with suitable
partitioning policies, we design distributed algorithms for the m-DTRP problem
that (i) are spatially distributed, scalable to large networks, and adaptive to
network changes, (ii) are within a constant-factor of optimal in heavy-load
conditions and stabilize the system in any load condition. Simulation results
are presented and discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3627</identifier>
 <datestamp>2009-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3627</id><created>2009-03-20</created><authors><author><keyname>Gurevich</keyname><forenames>Shamgar</forenames><affiliation>Berkeley</affiliation></author><author><keyname>Hadani</keyname><forenames>Ronny</forenames><affiliation>Chicago</affiliation></author></authors><title>Statistical RIP and Semi-Circle Distribution of Incoherent Dictionaries</title><categories>cs.IT cs.DM math.IT math.PR</categories><comments>This version Includes all the proofs. Submitted for publication
  (2009)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we formulate and prove a statistical version of the Candes-Tao
restricted isometry property (SRIP for short) which holds in general for any
incoherent dictionary which is a disjoint union of orthonormal bases. In
addition, we prove that, under appropriate normalization, the eigenvalues of
the associated Gram matrix fluctuate around 1 according to the Wigner
semicircle distribution. The result is then applied to various dictionaries
that arise naturally in the setting of finite harmonic analysis, giving, in
particular, a better understanding on a remark of
Applebaum-Howard-Searle-Calderbank concerning RIP for the Heisenberg dictionary
of chirp like functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3667</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3667</id><created>2009-03-21</created><updated>2011-01-02</updated><authors><author><keyname>Ratsaby</keyname><forenames>Joel</forenames></author></authors><title>How random are a learner's mistakes?</title><categories>cs.LG cs.IT math.IT math.PR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a random binary sequence $X^{(n)}$ of random variables, $X_{t},$
$t=1,2,...,n$, for instance, one that is generated by a Markov source (teacher)
of order $k^{*}$ (each state represented by $k^{*}$ bits). Assume that the
probability of the event $X_{t}=1$ is constant and denote it by $\beta$.
Consider a learner which is based on a parametric model, for instance a Markov
model of order $k$, who trains on a sequence $x^{(m)}$ which is randomly drawn
by the teacher. Test the learner's performance by giving it a sequence
$x^{(n)}$ (generated by the teacher) and check its predictions on every bit of
$x^{(n)}.$ An error occurs at time $t$ if the learner's prediction $Y_{t}$
differs from the true bit value $X_{t}$. Denote by $\xi^{(n)}$ the sequence of
errors where the error bit $\xi_{t}$ at time $t$ equals 1 or 0 according to
whether the event of an error occurs or not, respectively. Consider the
subsequence $\xi^{(\nu)}$ of $\xi^{(n)}$ which corresponds to the errors of
predicting a 0, i.e., $\xi^{(\nu)}$ consists of the bits of $\xi^{(n)}$ only at
times $t$ such that $Y_{t}=0.$ In this paper we compute an estimate on the
deviation of the frequency of 1s of $\xi^{(\nu)}$ from $\beta$. The result
shows that the level of randomness of $\xi^{(\nu)}$ decreases relative to an
increase in the complexity of the learner.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3669</identifier>
 <datestamp>2009-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3669</id><created>2009-03-21</created><authors><author><keyname>Wang</keyname><forenames>Xiuli</forenames></author></authors><title>Comment on &quot;Language Trees and Zipping&quot; arXiv:cond-mat/0108530</title><categories>cs.AI cs.IT math.IT</categories><comments>2 pages comment on arXiv:cond-mat/0108530, arXiv:cond-mat/0203275</comments><acm-class>H.5.3</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Every encoding has priori information if the encoding represents any semantic
information of the unverse or object. Encoding means mapping from the unverse
to the string or strings of digits. The semantic here is used in the
model-theoretic sense or denotation of the object. If encoding or strings of
symbols is the adequate and true mapping of model or object, and the mapping is
recursive or computable, the distance between two strings (text) is mapping the
distance between models. We then are able to measure the distance by computing
the distance between the two strings. Otherwise, we may take a misleading
course. &quot;Language tree&quot; may not be a family tree in the sense of historical
linguistics. Rather it just means the similarity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3676</identifier>
 <datestamp>2010-05-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3676</id><created>2009-03-23</created><authors><author><keyname>Saucan</keyname><forenames>Emil</forenames></author><author><keyname>Appleboilm</keyname><forenames>Eli</forenames></author><author><keyname>Wolansky</keyname><forenames>Gershon</forenames></author><author><keyname>Zeevi</keyname><forenames>Yehoshua Y.</forenames></author></authors><title>Combinatorial Ricci Curvature and Laplacians for Image Processing</title><categories>cs.CV cs.CG</categories><comments>12 pages, 8 figures (some of the these may be of lesser quality than
  those in the Technical report version)</comments><report-no>CCIT Report # 722 March 2009 (EE Pub. No. 1679)</report-no><journal-ref>Proceedings of CISP'09, Vol. 2, 992-997, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new Combinatorial Ricci curvature and Laplacian operators for grayscale
images are introduced and tested on 2D synthetic, natural and medical images.
Analogue formulae for voxels are also obtained. These notions are based upon
more general concepts developed by R. Forman. Further applications, in
particular a fitting Ricci flow, are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3685</identifier>
 <datestamp>2009-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3685</id><created>2009-03-21</created><authors><author><keyname>Dejter</keyname><forenames>Italo J.</forenames></author></authors><title>Quasiperfect domination in triangular lattices</title><categories>math.CO cs.IT math.IT</categories><comments>20 pages, 9 figures, 5 arrays</comments><msc-class>05C69, 68R10</msc-class><journal-ref>Discussiones Mathematicae Graph Theory 29(2009) 179-198</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A vertex subset $S$ of a graph $G$ is a perfect (resp. quasiperfect)
dominating set in $G$ if each vertex $v$ of $G\setminus S$ is adjacent to only
one vertex ($d_v\in\{1,2\}$ vertices) of $S$. Perfect and quasiperfect
dominating sets in the regular tessellation graph of Schl\&quot;afli symbol
$\{3,6\}$ and in its toroidal quotients are investigated, yielding the
classification of their perfect dominating sets and most of their quasiperfect
dominating sets $S$ with induced components of the form $K_{\nu}$, where
$\nu\in\{1,2,3\}$ depends only on $S$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3690</identifier>
 <datestamp>2009-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3690</id><created>2009-03-21</created><updated>2009-07-24</updated><authors><author><keyname>Li</keyname><forenames>Xin</forenames></author><author><keyname>Maza</keyname><forenames>Marc Moreno</forenames></author><author><keyname>Pan</keyname><forenames>Wei</forenames></author></authors><title>Computations modulo regular chains</title><categories>cs.SC</categories><comments>27 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The computation of triangular decompositions are based on two fundamental
operations: polynomial GCDs modulo regular chains and regularity test modulo
saturated ideals. We propose new algorithms for these core operations relying
on modular methods and fast polynomial arithmetic. Our strategies take also
advantage of the context in which these operations are performed. We report on
extensive experimentation, comparing our code to pre-existing Maple
implementations, as well as more optimized Magma functions. In most cases, our
new code outperforms the other packages by several orders of magnitude.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3696</identifier>
 <datestamp>2014-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3696</id><created>2009-03-23</created><updated>2014-11-06</updated><authors><author><keyname>Bell</keyname><forenames>George I.</forenames></author></authors><title>Notes on solving and playing peg solitaire on a computer</title><categories>math.CO cs.DM math.HO</categories><comments>25 pages, 11 figures, 8 tables. Some text rewritten, more ancillary
  material added</comments><msc-class>00A08, 97A20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the one-person game of peg solitaire played on a computer. Two
popular board shapes are the 33-hole cross-shaped board, and the 15-hole
triangle board---we use them as examples throughout. The basic game begins from
a full board with one peg missing and the goal is to finish at a board position
with one peg. First, we discuss ways to solve the basic game on a computer.
Then we consider the problem of quickly distinguishing board positions where
the goal can still be reached (&quot;winning&quot; board positions) from those where it
cannot. This enables a computer to alert the player if a jump under
consideration leads to a dead end. On the 15-hole triangle board, it is
possible to identify all winning board positions (from any single vacancy
start) by storing a key set of 437 board positions. For the &quot;central game&quot; on
the 33-hole cross-shaped board, we can identify all winning board positions by
storing 839,536 board positions. By viewing a successful game as a traversal of
a directed graph of winning board positions, we apply a simple algorithm to
count the number of ways to traverse this graph, and calculate that the total
number of solutions to the central game is 40,861,647,040,079,968. Our analysis
can also determine how quickly we can reach a &quot;dead board position&quot;, where a
one peg finish is no longer possible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3715</identifier>
 <datestamp>2009-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3715</id><created>2009-03-22</created><updated>2009-05-22</updated><authors><author><keyname>Raymond</keyname><forenames>Jack</forenames></author></authors><title>Optimal sparse CDMA detection at high load</title><categories>cs.IT math.IT</categories><comments>Submitted to physcomnet09, 6 pages 6 figures, pdflatex</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Balancing efficiency of bandwidth use and complexity of detection involves
choosing a suitable load for a multi-access channel. In the case of synchronous
CDMA, with random codes, it is possible to demonstrate the existence of a
threshold in the load beyond which there is an apparent jump in computational
complexity. At small load unit clause propagation can determine a jointly
optimal detection of sources on a noiseless channel, but fails at high load.
Analysis provides insight into the difference between the standard dense random
codes and sparse codes, and the limitations of optimal detection in the sparse
case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3741</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3741</id><created>2009-03-22</created><updated>2012-02-28</updated><authors><author><keyname>Arrighi</keyname><forenames>Pablo</forenames><affiliation>ENS-Lyon, LIP and Universite de Grenoble, LIG</affiliation></author><author><keyname>Diaz-Caro</keyname><forenames>Alejandro</forenames><affiliation>Universite de Grenoble, LIG, and Universite Paris-Nord, Laboratoire LIPN</affiliation></author></authors><title>A System F accounting for scalars</title><categories>cs.LO cs.PL quant-ph</categories><proxy>Logical Methods In Computer Science</proxy><acm-class>F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 8, Issue 1 (February
  27, 2012) lmcs:846</journal-ref><doi>10.2168/LMCS-8(1:11)2012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Algebraic lambda-calculus and the Linear-Algebraic lambda-calculus extend
the lambda-calculus with the possibility of making arbitrary linear
combinations of terms. In this paper we provide a fine-grained, System F-like
type system for the linear-algebraic lambda-calculus. We show that this
&quot;scalar&quot; type system enjoys both the subject-reduction property and the
strong-normalisation property, our main technical results. The latter yields a
significant simplification of the linear-algebraic lambda-calculus itself, by
removing the need for some restrictions in its reduction rules. But the more
important, original feature of this scalar type system is that it keeps track
of 'the amount of a type' that is present in each term. As an example of its
use, we shown that it can serve as a guarantee that the normal form of a term
is barycentric, i.e that its scalars are summing to one.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3759</identifier>
 <datestamp>2009-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3759</id><created>2009-03-22</created><authors><author><keyname>Asaduzzaman</keyname><forenames>Shah</forenames></author><author><keyname>Bochmann</keyname><forenames>Gregor v.</forenames></author></authors><title>GeoP2P: An adaptive peer-to-peer overlay for efficient search and update
  of spatial information</title><categories>cs.NI cs.DB cs.DC</categories><comments>13 pages, Submitted to VLDB-2009 conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a fully decentralized peer-to-peer overlay structure
GeoP2P, to facilitate geographic location based search and retrieval of
information. Certain limitations of centralized geographic indexes favor
peer-to-peer organization of the information, which, in addition to avoiding
performance bottleneck, allows autonomy over local information. Peer-to-peer
systems for geographic or multidimensional range queries built on existing DHTs
suffer from the inaccuracy in linearization of the multidimensional space.
Other overlay structures that are based on hierarchical partitioning of the
search space are not scalable because they use special super-peers to represent
the nodes in the hierarchy. GeoP2P partitions the search space hierarchically,
maintains the overlay structure and performs the routing without the need of
any super-peers. Although similar fully-decentralized overlays have been
previously proposed, they lack the ability to dynamically grow and retract the
partition hierarchy when the number of peers change. GeoP2P provides such
adaptive features with minimum perturbation of the system state. Such
adaptation makes both the routing delay and the state size of each peer
logarithmic to the total number of peers, irrespective of the size of the
multidimensional space. Our analysis also reveals that the overlay structure
and the routing algorithm are generic and independent of several aspects of the
partitioning hierarchy, such as the geometric shape of the zones or the
dimensionality of the search space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3786</identifier>
 <datestamp>2009-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3786</id><created>2009-03-23</created><authors><author><keyname>Liu</keyname><forenames>Ruoheng</forenames><affiliation>Shitz</affiliation></author><author><keyname>Liu</keyname><forenames>Tie</forenames><affiliation>Shitz</affiliation></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames><affiliation>Shitz</affiliation></author><author><keyname>Shamai</keyname><forenames>Shlomo</forenames><affiliation>Shitz</affiliation></author></authors><title>Multiple-Input Multiple-Output Gaussian Broadcast Channels with
  Confidential Messages</title><categories>cs.IT cs.CR math.IT</categories><comments>Submitted to the IEEE Transactions on Information Theory, March 2009</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This paper considers the problem of secret communication over a two-receiver
multiple-input multiple-output (MIMO) Gaussian broadcast channel. The
transmitter has two independent messages, each of which is intended for one of
the receivers but needs to be kept asymptotically perfectly secret from the
other. It is shown that, surprisingly, under a matrix power constraint both
messages can be simultaneously transmitted at their respective maximal secrecy
rates. To prove this result, the MIMO Gaussian wiretap channel is revisited and
a new characterization of its secrecy capacity is provided via a new coding
scheme that uses artificial noise and random binning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3797</identifier>
 <datestamp>2009-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3797</id><created>2009-03-23</created><authors><author><keyname>Combemale</keyname><forenames>Beno&#xee;t</forenames><affiliation>IRIT</affiliation></author></authors><title>Personal report of the 3rd ECMDA-FA'07 conference</title><categories>cs.SE</categories><proxy>ccsd hal-00369872</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Manuscripts notes taken during the conference ECMDA 2008. I give the full
conference program (title of the article and name of the person who introduced)
detailing some of the presentations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3850</identifier>
 <datestamp>2009-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3850</id><created>2009-03-23</created><authors><author><keyname>Bertot</keyname><forenames>Yves</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Komendantskaya</keyname><forenames>Ekaterina</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author></authors><title>Using Structural Recursion for Corecursion</title><categories>cs.LO</categories><proxy>ccsd inria-00322331</proxy><journal-ref>Types 2008 5497 (2008) 220-236</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a (limited) solution to the problem of constructing stream values
defined by recursive equations that do not respect the guardedness condition.
The guardedness condition is imposed on definitions of corecursive functions in
Coq, AGDA, and other higher-order proof assistants. In this paper, we
concentrate in particular on those non-guarded equations where recursive calls
appear under functions. We use a correspondence between streams and functions
over natural numbers to show that some classes of non-guarded definitions can
be modelled through the encoding as structural recursive functions. In
practice, this work extends the class of stream values that can be defined in a
constructive type theory-based theorem prover with inductive and coinductive
types, structural recursion and guarded corecursion
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3889</identifier>
 <datestamp>2009-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3889</id><created>2009-03-23</created><authors><author><keyname>Zimand</keyname><forenames>Marius</forenames></author></authors><title>On generating independent random strings</title><categories>cs.IT cs.CC math.IT</categories><comments>CiE 2009, Heidelberg</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is shown that from two strings that are partially random and independent
(in the sense of Kolmogorov complexity) it is possible to effectively construct
polynomially many strings that are random and pairwise independent. If the two
initial strings are random, then the above task can be performed in polynomial
time. It is also possible to construct in polynomial time a random string, from
two strings that have constant randomness rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3900</identifier>
 <datestamp>2009-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3900</id><created>2009-03-23</created><authors><author><keyname>Ugus</keyname><forenames>Osman</forenames></author><author><keyname>Westhoff</keyname><forenames>Dirk</forenames></author><author><keyname>Laue</keyname><forenames>Ralf</forenames></author><author><keyname>Shoufan</keyname><forenames>Abdulhadi</forenames></author><author><keyname>Huss</keyname><forenames>Sorin A.</forenames></author></authors><title>Optimized Implementation of Elliptic Curve Based Additive Homomorphic
  Encryption for Wireless Sensor Networks</title><categories>cs.CR cs.PF</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When deploying wireless sensor networks (WSNs) in public environments it may
become necessary to secure their data storage and transmission against possible
attacks such as node-compromise and eavesdropping. The nodes feature only small
computational and energy resources, thus requiring efficient algorithms. As a
solution for this problem the TinyPEDS approach was proposed in [7], which
utilizes the Elliptic Curve ElGamal (EC-ElGamal) cryptosystem for additive
homomorphic encryption allowing concealed data aggregation. This work presents
an optimized implementation of EC-ElGamal on a MicaZ mote, which is a typical
sensor node platform with 8-bit processor for WSNs. Compared to the best
previous result, our implementation is at least 44% faster for fixed-point
multiplication. Because most parts of the algorithm are similar to standard
Elliptic Curve algorithms, the results may be reused in other realizations on
constrained devices as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3926</identifier>
 <datestamp>2009-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3926</id><created>2009-03-23</created><authors><author><keyname>Homik</keyname><forenames>Martin</forenames></author><author><keyname>Meier</keyname><forenames>Andreas</forenames></author></authors><title>Designing a GUI for Proofs - Evaluation of an HCI Experiment</title><categories>cs.AI</categories><report-no>SEKI Working-Paper SWP-2005-01</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Often user interfaces of theorem proving systems focus on assisting
particularly trained and skilled users, i.e., proof experts. As a result, the
systems are difficult to use for non-expert users. This paper describes a paper
and pencil HCI experiment, in which (non-expert) students were asked to make
suggestions for a GUI for an interactive system for mathematical proofs. They
had to explain the usage of the GUI by applying it to construct a proof sketch
for a given theorem. The evaluation of the experiment provides insights for the
interaction design for non-expert users and the needs and wants of this user
group.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3995</identifier>
 <datestamp>2009-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3995</id><created>2009-03-23</created><authors><author><keyname>Chu</keyname><forenames>Jinyu</forenames></author><author><keyname>Liu</keyname><forenames>Ju</forenames></author><author><keyname>Qiao</keyname><forenames>Jianping</forenames></author><author><keyname>Wang</keyname><forenames>Xiaoling</forenames></author><author><keyname>Li</keyname><forenames>Yujun</forenames></author></authors><title>Gradient-based adaptive interpolation in super-resolution image
  restoration</title><categories>cs.MM cs.CV</categories><comments>4pages, 7figures, This paper presents a super-resolution method based
  on gradient-based adaptive interpolation</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper presents a super-resolution method based on gradient-based
adaptive interpolation. In this method, in addition to considering the distance
between the interpolated pixel and the neighboring valid pixel, the
interpolation coefficients take the local gradient of the original image into
account. The smaller the local gradient of a pixel is, the more influence it
should have on the interpolated pixel. And the interpolated high resolution
image is finally deblurred by the application of wiener filter. Experimental
results show that our proposed method not only substantially improves the
subjective and objective quality of restored images, especially enhances edges,
but also is robust to the registration error and has low computational
complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4014</identifier>
 <datestamp>2012-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4014</id><created>2009-03-24</created><updated>2010-04-09</updated><authors><author><keyname>Muramatsu</keyname><forenames>Jun</forenames></author><author><keyname>Miyake</keyname><forenames>Shigeki</forenames></author></authors><title>Construction of Codes for Wiretap Channel and Secret Key Agreement from
  Correlated Source Outputs by Using Sparse Matrices</title><categories>cs.IT cs.CR math.IT</categories><comments>A part of this paper is presented in part at 2009 IEEE Information
  Theory Workshop (ITW2009), Taormina, Italy, pp.105-109, 2009. This paper is
  submitted to IEEE Transactions on Information Theory. 34 pages</comments><journal-ref>IEEE Transactions on Information Theory, vol. 58, no. 2, pp.
  671-692, Feb. 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of this paper is to prove coding theorems for the wiretap channel
coding problem and secret key agreement problem based on the the notion of a
hash property for an ensemble of functions. These theorems imply that codes
using sparse matrices can achieve the optimal rate. Furthermore, fixed-rate
universal coding theorems for a wiretap channel and a secret key agreement are
also proved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4035</identifier>
 <datestamp>2009-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4035</id><created>2009-03-24</created><authors><author><keyname>Kritikopoulos</keyname><forenames>A.</forenames></author><author><keyname>Sideri</keyname><forenames>M.</forenames></author><author><keyname>Varlamis</keyname><forenames>I.</forenames></author></authors><title>BLOGRANK: Ranking Weblogs Based On Connectivity And Similarity Features</title><categories>cs.IR</categories><comments>9 pages, in 2nd international workshop on Advanced architectures and
  algorithms for internet delivery and applications</comments><acm-class>H.3.3</acm-class><journal-ref>Proceedings of the 2nd international Workshop on Advanced
  Architectures and Algorithms For internet Delivery and Applications (Pisa,
  Italy, October 10 - 10, 2006). AAA-IDEA '06</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A large part of the hidden web resides in weblog servers. New content is
produced in a daily basis and the work of traditional search engines turns to
be insufficient due to the nature of weblogs. This work summarizes the
structure of the blogosphere and highlights the special features of weblogs. In
this paper we present a method for ranking weblogs based on the link graph and
on several similarity characteristics between weblogs. First we create an
enhanced graph of connected weblogs and add new types of edges and weights
utilising many weblog features. Then, we assign a ranking to each weblog using
our algorithm, BlogRank, which is a modified version of PageRank. For the
validation of our method we run experiments on a weblog dataset, which we
process and adapt to our search engine. (http://spiderwave.aueb.gr/Blogwave).
The results suggest that the use of the enhanced graph and the BlogRank
algorithm is preferred by the users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4036</identifier>
 <datestamp>2009-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4036</id><created>2009-03-24</created><authors><author><keyname>Dideban</keyname><forenames>Abbas</forenames><affiliation>GIPSA-lab</affiliation></author><author><keyname>Alla</keyname><forenames>Hassane</forenames><affiliation>GIPSA-lab</affiliation></author></authors><title>Feedback control logic synthesis for non safe Petri nets</title><categories>cs.IT math.IT</categories><proxy>ccsd hal-00370275</proxy><journal-ref>13th IFAC Symposium on INFORMATION CONTROL PROBLEMS IN
  MANUFACTURING, Moscou : Russie (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the problem of forbidden states of non safe Petri Net
(PN) modelling discrete events systems. To prevent the forbidden states, it is
possible to use conditions or predicates associated with transitions.
Generally, there are many forbidden states, thus many complex conditions are
associated with the transitions. A new idea for computing predicates in non
safe Petri nets will be presented. Using this method, we can construct a
maximally permissive controller if it exists.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4046</identifier>
 <datestamp>2009-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4046</id><created>2009-03-24</created><updated>2009-04-07</updated><authors><author><keyname>Alagoz</keyname><forenames>B. Baykant</forenames></author></authors><title>Boolean Logic with Fault Tolerant Coding</title><categories>cs.OH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Error detectable and error correctable coding in Hamming space was researched
to discover possible fault tolerant coding constellations, which can implement
Boolean logic with fault tolerant property. Basic logic operators of the
Boolean algebra were developed to apply fault tolerant coding in the logic
circuits. It was shown that application of three-bit fault tolerant codes have
provided the digital system skill of auto-recovery without need for designing
additional-fault tolerance mechanisms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4053</identifier>
 <datestamp>2009-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4053</id><created>2009-03-24</created><authors><author><keyname>Stefan</keyname><forenames>Laura</forenames></author></authors><title>The generating of Fractal Images Using MathCAD Program</title><categories>cs.MS</categories><comments>10 pages, exposed on 2nd &quot;European Conference on Computer Science and
  Applications&quot; - XA2008, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series 6 (2008), 211 - 220</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents the graphic representation in the z-plane of the first
three iterations of the algorithm that generates the Sierpinski Gasket. It
analyzes the influence of the f(z) map when we represent fractal images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4100</identifier>
 <datestamp>2009-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4100</id><created>2009-03-24</created><authors><author><keyname>Asaduzzaman</keyname><forenames>Shah</forenames></author><author><keyname>Maheswaran</keyname><forenames>Muthucumaru</forenames></author></authors><title>Decentralized Management of Bi-modal Network Resources in a Distributed
  Stream Processing Platform</title><categories>cs.DC cs.NI</categories><comments>17 pages, submitted to Journal of Parallel and Distributed Computing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents resource management techniques for allocating
communication and computational resources in a distributed stream processing
platform. The platform is designed to exploit the synergy of two classes of
network connections -- dedicated and opportunistic. Previous studies we
conducted have demonstrated the benefits of such bi-modal resource organization
that combines small pools of dedicated computers with a very large pool of
opportunistic computing capacities of idle computers to serve high throughput
computing applications. This paper extends the idea of bi-modal resource
organization into the management of communication resources. Since distributed
stream processing applications demand large volume of data transmission between
processing sites at a consistent rate, adequate control over the network
resources is important to assure a steady flow of processing. The system model
used in this paper is a platform where stream processing servers at distributed
sites are interconnected with a combination of dedicated and opportunistic
communication links. Two pertinent resource allocation problems are analyzed in
details and solved using decentralized algorithms. One is the mapping of the
stream processing tasks on the processing and the communication resources. The
other is the adaptive re-allocation of the opportunistic communication links
due to the variations in their capacities. Overall optimization goal is higher
task throughput and better utilization of the expensive dedicated links. The
evaluation demonstrates that the algorithms are able to exploit the synergy of
bi-modal communication links towards achieving the optimization goals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4101</identifier>
 <datestamp>2009-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4101</id><created>2009-03-24</created><authors><author><keyname>Mayordomo</keyname><forenames>Elvira</forenames></author><author><keyname>Moser</keyname><forenames>Philippe</forenames></author><author><keyname>Perifel</keyname><forenames>Sylvain</forenames></author></authors><title>Polylog space compression, pushdown compression, and Lempel-Ziv are
  incomparable</title><categories>cs.CC cs.IR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The pressing need for efficient compression schemes for XML documents has
recently been focused on stack computation, and in particular calls for a
formulation of information-lossless stack or pushdown compressors that allows a
formal analysis of their performance and a more ambitious use of the stack in
XML compression, where so far it is mainly connected to parsing mechanisms. In
this paper we introduce the model of pushdown compressor, based on pushdown
transducers that compute a single injective function while keeping the widest
generality regarding stack computation.
  We also consider online compression algorithms that use at most
polylogarithmic space (plogon). These algorithms correspond to compressors in
the data stream model.
  We compare the performance of these two families of compressors with each
other and with the general purpose Lempel-Ziv algorithm. This comparison is
made without any a priori assumption on the data's source and considering the
asymptotic compression ratio for infinite sequences. We prove that in all cases
they are incomparable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4113</identifier>
 <datestamp>2009-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4113</id><created>2009-03-24</created><authors><author><keyname>Asaduzzaman</keyname><forenames>Shah</forenames></author><author><keyname>Bochmann</keyname><forenames>Gregor v.</forenames></author></authors><title>Overlay Structure for Large Scale Content Sharing: Leveraging Geography
  as the Basis for Routing Locality</title><categories>cs.NI cs.DC cs.MM</categories><comments>5 pages, position paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we place our arguments on two related issues in the design of
generalized structured peer-to-peer overlays. First, we argue that for the
large-scale content-sharing applications, lookup and content transport
functions need to be treated separately. Second, to create a location-based
routing overlay suitable for content sharing and other applications, we argue
that off-the-shelf geographic coordinates of Internet-connected hosts can be
used as a basis. We then outline the design principles and present a design for
the generalized routing overlay based on adaptive hierarchical partitioning of
the geographical space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4128</identifier>
 <datestamp>2009-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4128</id><created>2009-03-24</created><authors><author><keyname>Aggarwal</keyname><forenames>Rohit</forenames></author><author><keyname>Schniter</keyname><forenames>Philip</forenames></author><author><keyname>Koksal</keyname><forenames>C. Emre</forenames></author></authors><title>Rate Adaptation via Link-Layer Feedback for Goodput Maximization over a
  Time-Varying Channel</title><categories>cs.IT cs.NI math.IT math.OC</categories><comments>25 pages, 9 figures, submitted to IEEE Transactions on Wireless
  Communications in August 2008 and revised in March 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider adapting the transmission rate to maximize the goodput, i.e., the
amount of data transmitted without error, over a continuous Markov flat-fading
wireless channel. In particular, we consider schemes in which transmitter
channel state is inferred from degraded causal error-rate feedback, such as
packet-level ACK/NAKs in an automatic repeat request (ARQ) system. In such
schemes, the choice of transmission rate affects not only the subsequent
goodput but also the subsequent feedback, implying that the optimal rate
schedule is given by a partially observable Markov decision process (POMDP).
Because solution of the POMDP is computationally impractical, we consider
simple suboptimal greedy rate assignment and show that the optimal scheme would
itself be greedy if the error-rate feedback was non-degraded. Furthermore, we
show that greedy rate assignment using non-degraded feedback yields a total
goodput that upper bounds that of optimal rate assignment using degraded
feedback. We then detail the implementation of the greedy scheme and propose a
reduced-complexity greedy scheme that adapts the transmission rate only once
per block of packets. We also investigate the performance of the schemes
numerically, and show that the proposed greedy scheme achieves steady-state
goodputs that are reasonably close to the upper bound on goodput calculated
using non-degraded feedback. A similar improvement is obtained in steady-state
goodput, drop rate, and average buffer occupancy in the presence of data
buffers. We also investigate an upper bound on the performance of optimal rate
assignment for a discrete approximation of the channel and show that such
quantization leads to a significant loss in achievable goodput.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4130</identifier>
 <datestamp>2009-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4130</id><created>2009-03-24</created><updated>2009-04-09</updated><authors><author><keyname>Elmasry</keyname><forenames>Amr</forenames></author></authors><title>Pairing Heaps with Costless Meld</title><categories>cs.DS</categories><comments>10 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Improving the structure and analysis in \cite{elm0}, we give a variation of
the pairing heaps that has amortized zero cost per meld (compared to an $O(\log
\log{n})$ in \cite{elm0}) and the same amortized bounds for all other
operations. More precisely, the new pairing heap requires: no cost per meld,
O(1) per find-min and insert, $O(\log{n})$ per delete-min, and $O(\log\log{n})$
per decrease-key. These bounds are the best known for any self-adjusting heap,
and match the lower bound proved by Fredman for a family of such heaps.
Moreover, the changes we have done make our structure even simpler than that in
\cite{elm0}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4132</identifier>
 <datestamp>2010-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4132</id><created>2009-03-24</created><authors><author><keyname>Go&#xf1;i</keyname><forenames>Joaqu&#xed;n</forenames></author><author><keyname>Martincorena</keyname><forenames>I&#xf1;igo</forenames></author><author><keyname>Corominas-Murtra</keyname><forenames>Bernat</forenames></author><author><keyname>Arrondo</keyname><forenames>Gonzalo</forenames></author><author><keyname>Ardanza-Trevijano</keyname><forenames>Sergio</forenames></author><author><keyname>Villoslada</keyname><forenames>Pablo</forenames></author></authors><title>Switcher-random-walks: a cognitive-inspired mechanism for network
  exploration</title><categories>cs.AI cond-mat.dis-nn physics.soc-ph</categories><comments>9 pages, 3 figures. Accepted in &quot;International Journal of
  Bifurcations and Chaos&quot;: Special issue on &quot;Modelling and Computation on
  Complex Networks&quot;</comments><journal-ref>International Journal of Bifurcation and Chaos 20, 913-922 (2010)</journal-ref><doi>10.1142/S0218127410026204</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Semantic memory is the subsystem of human memory that stores knowledge of
concepts or meanings, as opposed to life specific experiences. The organization
of concepts within semantic memory can be understood as a semantic network,
where the concepts (nodes) are associated (linked) to others depending on
perceptions, similarities, etc. Lexical access is the complementary part of
this system and allows the retrieval of such organized knowledge. While
conceptual information is stored under certain underlying organization (and
thus gives rise to a specific topology), it is crucial to have an accurate
access to any of the information units, e.g. the concepts, for efficiently
retrieving semantic information for real-time needings. An example of an
information retrieval process occurs in verbal fluency tasks, and it is known
to involve two different mechanisms: -clustering-, or generating words within a
subcategory, and, when a subcategory is exhausted, -switching- to a new
subcategory. We extended this approach to random-walking on a network
(clustering) in combination to jumping (switching) to any node with certain
probability and derived its analytical expression based on Markov chains.
Results show that this dual mechanism contributes to optimize the exploration
of different network models in terms of the mean first passage time.
Additionally, this cognitive inspired dual mechanism opens a new framework to
better understand and evaluate exploration, propagation and transport phenomena
in other complex systems where switching-like phenomena are feasible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4207</identifier>
 <datestamp>2009-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4207</id><created>2009-03-24</created><updated>2009-08-04</updated><authors><author><keyname>Forney</keyname><forenames>G. David</forenames><suffix>Jr</suffix></author></authors><title>MacWilliams Identities for Codes on Graphs</title><categories>cs.IT math.IT</categories><comments>5 pages, 2 figures; final version to be presented at IEEE Information
  Theory Workshop, Taormina, Sicily, Oct. 11-16, 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The MacWilliams identity for linear time-invariant convolutional codes that
has recently been found by Gluesing-Luerssen and Schneider is proved concisely,
and generalized to arbitrary group codes on graphs. A similar development
yields a short, transparent proof of the dual sum-product update rule.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4217</identifier>
 <datestamp>2009-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4217</id><created>2009-03-24</created><updated>2009-06-03</updated><authors><author><keyname>Beygelzimer</keyname><forenames>Alina</forenames></author><author><keyname>Langford</keyname><forenames>John</forenames></author><author><keyname>Lifshits</keyname><forenames>Yuri</forenames></author><author><keyname>Sorkin</keyname><forenames>Gregory</forenames></author><author><keyname>Strehl</keyname><forenames>Alex</forenames></author></authors><title>Conditional Probability Tree Estimation Analysis and Algorithms</title><categories>cs.LG cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of estimating the conditional probability of a label
in time $O(\log n)$, where $n$ is the number of possible labels. We analyze a
natural reduction of this problem to a set of binary regression problems
organized in a tree structure, proving a regret bound that scales with the
depth of the tree. Motivated by this analysis, we propose the first online
algorithm which provably constructs a logarithmic depth tree on the set of
labels to solve this problem. We test the algorithm empirically, showing that
it works succesfully on a dataset with roughly $10^6$ labels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4237</identifier>
 <datestamp>2011-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4237</id><created>2009-03-25</created><updated>2010-02-17</updated><authors><author><keyname>Kramer</keyname><forenames>Josh Brown</forenames></author><author><keyname>Sabalka</keyname><forenames>Lucas</forenames></author></authors><title>Projection-Forcing Multisets of Weight Changes</title><categories>math.CO cs.IT math.IT</categories><comments>11 Pages</comments><msc-class>05E99, 94B05</msc-class><journal-ref>Journal of Combinatorial Theory, Series A, 117(8): 1136-1142, 2010</journal-ref><doi>10.1016/j.jcta.2010.01.005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $F$ be a finite field. A multiset $S$ of integers is projection-forcing
if for every linear function $\phi : F^n \to F^m$ whose multiset of weight
changes is $S$, $\phi$ is a coordinate projection up to permutation and scaling
of entries. The MacWilliams Extension Theorem from coding theory says that $S =
\{0, 0, ..., 0\}$ is projection-forcing. We give a (super-polynomial) algorithm
to determine whether or not a given $S$ is projection-forcing. We also give a
condition that can be checked in polynomial time that implies that $S$ is
projection-forcing. This result is a generalization of the MacWilliams
Extension Theorem and work by the first author.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4251</identifier>
 <datestamp>2009-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4251</id><created>2009-03-25</created><authors><author><keyname>Ferreira</keyname><forenames>Artur</forenames></author><author><keyname>Oliveira</keyname><forenames>Arlindo</forenames></author><author><keyname>Figueiredo</keyname><forenames>Mario</forenames></author></authors><title>On the Use of Suffix Arrays for Memory-Efficient Lempel-Ziv Data
  Compression</title><categories>cs.DS</categories><comments>10 pages, submited to IEEE - Data Compression Conference 2009</comments><acm-class>E.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Much research has been devoted to optimizing algorithms of the Lempel-Ziv
(LZ) 77 family, both in terms of speed and memory requirements. Binary search
trees and suffix trees (ST) are data structures that have been often used for
this purpose, as they allow fast searches at the expense of memory usage.
  In recent years, there has been interest on suffix arrays (SA), due to their
simplicity and low memory requirements. One key issue is that an SA can solve
the sub-string problem almost as efficiently as an ST, using less memory. This
paper proposes two new SA-based algorithms for LZ encoding, which require no
modifications on the decoder side. Experimental results on standard benchmarks
show that our algorithms, though not faster, use 3 to 5 times less memory than
the ST counterparts. Another important feature of our SA-based algorithms is
that the amount of memory is independent of the text to search, thus the memory
that has to be allocated can be defined a priori. These features of low and
predictable memory requirements are of the utmost importance in several
scenarios, such as embedded systems, where memory is at a premium and speed is
not critical. Finally, we point out that the new algorithms are general, in the
sense that they are adequate for applications other than LZ compression, such
as text retrieval and forward/backward sub-string search.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4258</identifier>
 <datestamp>2010-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4258</id><created>2009-03-25</created><updated>2010-02-16</updated><authors><author><keyname>Burkhart</keyname><forenames>Martin</forenames></author><author><keyname>Strasser</keyname><forenames>Mario</forenames></author><author><keyname>Many</keyname><forenames>Dilip</forenames></author><author><keyname>Dimitropoulos</keyname><forenames>Xenofontas</forenames></author></authors><title>SEPIA: Security through Private Information Aggregation</title><categories>cs.NI cs.CR</categories><report-no>TIK-Report No. 298</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Secure multiparty computation (MPC) allows joint privacy-preserving
computations on data of multiple parties. Although MPC has been studied
substantially, building solutions that are practical in terms of computation
and communication cost is still a major challenge. In this paper, we
investigate the practical usefulness of MPC for multi-domain network security
and monitoring. We first optimize MPC comparison operations for processing high
volume data in near real-time. We then design privacy-preserving protocols for
event correlation and aggregation of network traffic statistics, such as
addition of volume metrics, computation of feature entropy, and distinct item
count. Optimizing performance of parallel invocations, we implement our
protocols along with a complete set of basic operations in a library called
SEPIA. We evaluate the running time and bandwidth requirements of our protocols
in realistic settings on a local cluster as well as on PlanetLab and show that
they work in near real-time for up to 140 input providers and 9 computation
nodes. Compared to implementations using existing general-purpose MPC
frameworks, our protocols are significantly faster, requiring, for example, 3
minutes for a task that takes 2 days with general-purpose frameworks. This
improvement paves the way for new applications of MPC in the area of
networking. Finally, we run SEPIA's protocols on real traffic traces of 17
networks and show how they provide new possibilities for distributed
troubleshooting and early anomaly detection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4261</identifier>
 <datestamp>2009-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4261</id><created>2009-03-25</created><authors><author><keyname>Pintea</keyname><forenames>Florentina Anica</forenames></author></authors><title>On-Line Tests</title><categories>cs.HC</categories><comments>8 pages, exposed on 4th International Conference &quot;Actualities and
  Perspectives on Hardware and Software&quot; - APHS2007, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series V (2007), 77-84</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an interactive implementation which makes the link
between a human operator and a system of a administration of a relational
databases MySQL. This application conceived as a multimedia presentations is
illustrative for the way in which the transfer and the remaking of the
information between the human operator, the module of data processing and the
database which stores the informations can be solved (with help of the PHP
language and the web use).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4266</identifier>
 <datestamp>2009-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4266</id><created>2009-03-25</created><authors><author><keyname>Burkhart</keyname><forenames>Martin</forenames></author><author><keyname>Brauckhoff</keyname><forenames>Daniela</forenames></author><author><keyname>May</keyname><forenames>Martin</forenames></author><author><keyname>Boschi</keyname><forenames>Elisa</forenames></author></authors><title>The Risk-Utility Tradeoff for IP Address Truncation</title><categories>cs.NI</categories><acm-class>C.2.3</acm-class><journal-ref>1st ACM Workshop on Network Data Anonymization (NDA), Fairfax,
  Virginia, USA, October, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Network operators are reluctant to share traffic data due to security and
privacy concerns. Consequently, there is a lack of publicly available traces
for validating and generalizing the latest results in network and security
research. Anonymization is a possible solution in this context; however, it is
unclear how the sanitization of data preserves characteristics important for
traffic analysis. In addition, the privacy-preserving property of
state-of-the-art IP address anonymization techniques has come into question by
recent attacks that successfully identified a large number of hosts in
anonymized traces.
  In this paper, we examine the tradeoff between data utility for anomaly
detection and the risk of host identification for IP address truncation.
Specifically, we analyze three weeks of unsampled and non-anonymized network
traces from a medium-sized backbone network to assess data utility. The risk of
de-anonymizing individual IP addresses is formally evaluated, using a metric
based on conditional entropy.
  Our results indicate that truncation effectively prevents host identification
but degrades the utility of data for anomaly detection. However, the degree of
degradation depends on the metric used and whether network-internal or external
addresses are considered. Entropy metrics are more resistant to truncation than
unique counts and the detection quality of anomalies degrades much faster in
internal addresses than in external addresses. In particular, the usefulness of
internal address counts is lost even for truncation of only 4 bits whereas
utility of external address entropy is virtually unchanged even for truncation
of 20 bits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4267</identifier>
 <datestamp>2009-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4267</id><created>2009-03-25</created><authors><author><keyname>Despi</keyname><forenames>Ioan</forenames></author><author><keyname>Luca</keyname><forenames>Lucian</forenames></author></authors><title>Delving into Transition to the Semantic Web</title><categories>cs.SE</categories><comments>10 pages, exposed on 4th International Conference &quot;Actualities and
  Perspectives on Hardware and Software&quot; - APHS2007, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series V (2007), 7-16</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The semantic technologies pose new challenge for the way in which we built
and operate systems. They are tools used to represent significances,
associations, theories, separated from data and code. Their goal is to create,
to discover, to represent, to organize, to process, to manage, to ratiocinate,
to represent, to share and use the significances and knowledge to fulfill the
business, personal or social goals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4270</identifier>
 <datestamp>2009-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4270</id><created>2009-03-25</created><authors><author><keyname>Fortis</keyname><forenames>Alexandra Emilia</forenames></author></authors><title>Analysis of some properties for a basic Petri net model</title><categories>cs.OH</categories><comments>8 pages, exposed on 4th International Conference &quot;Actualities and
  Perspectives on Hardware and Software&quot; - APHS2007, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series V (2007), 17-24</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The formalism of the models with Petri networks provides a sound theoretical
base, supported by powerful mathematical methods able to extract information
necessary for the formalism and simulation of the real system that provides
features of competition and synchronization. The paper presents a model based
on a Petri net, in order to extract information relative to the technological
producing process of a food additive.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4283</identifier>
 <datestamp>2009-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4283</id><created>2009-03-25</created><authors><author><keyname>Chis</keyname><forenames>Timur</forenames></author></authors><title>Pipeline Leak Detection Techniques</title><categories>cs.OH</categories><comments>10 pages, exposed on 4th International Conferences &quot;Actualities and
  Perspectives on Hardware and Software&quot; - APHS2007, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series V (2007), 25-34</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Leak detection systems range from simple, visual line walking and checking
ones to complex arrangements of hard-ware and software. No one method is
universally applicable and operating requirements dictate which method is the
most cost effective. The aim of the paper is to review the basic techniques of
leak detection that are currently in use. The advantages and disadvantages of
each method are discussed and some indications of applicability are outlined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4286</identifier>
 <datestamp>2009-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4286</id><created>2009-03-25</created><authors><author><keyname>Chis</keyname><forenames>Timur</forenames></author></authors><title>Computer Systems to Oil Pipeline Transporting</title><categories>cs.OH</categories><comments>10 pages, exposed on 4th International Conferences &quot;Actualities and
  Perspectives on Hardware and Software&quot; - APHS2007, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series V (2007), 35-44</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computer systems in the pipeline oil transporting that the greatest amount of
data can be gathered, analyzed and acted upon in the shortest amount of time.
Most operators now have some form of computer based monitoring system employing
either commercially available or custom developed software to run the system.
This paper presented the SCADA systems to oil pipeline in concordance to the
Romanian environmental reglementations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4293</identifier>
 <datestamp>2009-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4293</id><created>2009-03-25</created><authors><author><keyname>Bucur</keyname><forenames>Petre</forenames></author><author><keyname>Luca</keyname><forenames>Lucian</forenames></author></authors><title>Non linear system become linear system</title><categories>cs.DM</categories><comments>8 pages, exposed on 4th International Conferences &quot;Actualities and
  Perspectives on Hardware and Software&quot; - APHS2007, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series V (2007), 55-62</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The present paper refers to the theory and the practice of the systems
regarding non-linear systems and their applications. We aimed the integration
of these systems to elaborate their response as well as to highlight some
outstanding features.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4298</identifier>
 <datestamp>2009-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4298</id><created>2009-03-25</created><authors><author><keyname>Timis</keyname><forenames>Mihai</forenames></author></authors><title>Design of Log-Map / Max-Log-Map Decoder</title><categories>cs.IT math.IT</categories><comments>8 pages, exposed on 4th International Conferences &quot;Actualities and
  Perspectives on Hardware and Software&quot; - APHS2007, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series V (2007), 63-70</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The process of turbo-code decoding starts with the formation of a posteriori
probabilities (APPs) for each data bit, which is followed by choosing the
data-bit value that corresponds to the maximum a posteriori (MAP) probability
for that data bit. Upon reception of a corrupted code-bit sequence, the process
of decision making with APPs allows the MAP algorithm to determine the most
likely information bit to have been transmitted at each bit time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4299</identifier>
 <datestamp>2009-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4299</id><created>2009-03-25</created><authors><author><keyname>Streian</keyname><forenames>Virgiliu</forenames></author><author><keyname>Ionescu</keyname><forenames>Adela</forenames></author></authors><title>Token Ring Project</title><categories>cs.NI</categories><comments>6 pages, exposed on 4th International Conferences &quot;Actualities and
  Perspectives on Hardware and Software&quot; - APHS2007, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series V (2007), 85-90</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ring topology is a simple configuration used to connect processes that
communicate among themselves. A number of network standards such as token ring,
token bus, and FDDI are based on the ring connectivity. This article will
develop an implementation of a ring of processes that communicate among
themselves via pipe links. The processes are nodes in the ring. Each process
reads from its standard input and writes in its standard output. N-1 process
redirects the its standard output to a standard input of the process through a
pipe. When the ring-structure is designed, the project can be extended to
simulate networks or to implement algorithms for mutual exclusion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4302</identifier>
 <datestamp>2009-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4302</id><created>2009-03-25</created><authors><author><keyname>Ilea</keyname><forenames>Daniela</forenames></author><author><keyname>Lacrama</keyname><forenames>Dan L.</forenames></author></authors><title>ShopList: Programming PDA applications for Windows Mobile using C#</title><categories>cs.OH</categories><comments>8 pages, exposed on 4th International Conferences &quot;Actualities and
  Perspectives on Hardware and Software&quot; - APHS2007, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series V (2007), 91-98</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is focused on a C# and Sql Server Mobile 2005 application to keep
evidence of a shop list. The purpose of the application is to offer to the user
an easier way to manage his shopping options.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4305</identifier>
 <datestamp>2009-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4305</id><created>2009-03-25</created><updated>2009-06-22</updated><authors><author><keyname>Codat</keyname><forenames>Diana Sophia</forenames></author></authors><title>Evaluation d'une requete en SQL</title><categories>cs.DB</categories><comments>6 pages, exposed on 4th International Conferences &quot;Actualities and
  Perspectives on Hardware and Software&quot; - APHS2007, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series V (2007), 99-104</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The objective of this paper is to show how the interrogation processor
responds to SQL interrogation. The interrogation processor is split into two
parts. The first, called the interrogation compiler translates an SQL query
into a plan of physical execution. The second, called evaluation query runs the
execution plan.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4307</identifier>
 <datestamp>2009-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4307</id><created>2009-03-25</created><authors><author><keyname>Apostol</keyname><forenames>Simona</forenames></author></authors><title>FISLAB - the Fuzzy Inference Tool-box for SCILAB</title><categories>cs.MS</categories><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series V (2007), 105-114</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The present study represents &quot;The Fislab package of programs meant to develop
the fuzzy regulators in the Scilab environment&quot; in which we present some
general issues, usage requirements and the working mode of the Fislab
environment. In the second part of the article some features of the Scilab
functions from the Fislab package are described.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4313</identifier>
 <datestamp>2009-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4313</id><created>2009-03-25</created><authors><author><keyname>Apostol</keyname><forenames>Simona</forenames></author></authors><title>The development of a fuzzy regulator with an entry and an output in
  Fislab</title><categories>cs.MS</categories><comments>6 pages, exposed on 4th International Conferences &quot;Actualities and
  Perspectives on Hardware and Software&quot; - APHS2007, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series V (2007), 115-120</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The present article is a sequel of the article &quot;Fislab the Fuzzy Inference
Tool-Box for Scilab&quot; and it represents the practical application of:&quot;The
development of the Fuzzy regulator with an input and an output in Fislab&quot;. The
article contains, besides this application, some functions to be used in the
program, namely Scilab functions for the fuzzification of the firm information,
functions for the operation of de-fuzzification and functions for the
implementation of.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4314</identifier>
 <datestamp>2009-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4314</id><created>2009-03-25</created><authors><author><keyname>Lacrama</keyname><forenames>Dan L.</forenames></author><author><keyname>Fera</keyname><forenames>Dorina</forenames></author></authors><title>Virtual Reality</title><categories>cs.MM</categories><comments>8 pages, exposed on 4th International Conferences &quot;Actualities and
  Perspectives on Hardware and Software&quot; - APHS2007, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series V (2007), 137-144</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is focused on the presentation of Virtual Reality principles
together with the main implementation methods and techniques. An overview of
the main development directions is included.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4358</identifier>
 <datestamp>2009-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4358</id><created>2009-03-25</created><authors><author><keyname>Dashti</keyname><forenames>M. Torabi</forenames></author></authors><title>Sums of powers via integration</title><categories>cs.DM</categories><comments>4 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sum of powers 1^p+...+n^p, with n and p being natural numbers and n&gt;=1, can
be expressed as a polynomial function of n of degree p+1. Such representations
are often called Faulhaber formulae. A simple recursive algorithm for computing
coefficients of Faulhaber formulae is presented. The correctness of the
algorithm is proved by giving a recurrence relation on Faulhaber formulae.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4365</identifier>
 <datestamp>2009-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4365</id><created>2009-03-25</created><updated>2009-03-26</updated><authors><author><keyname>Asaduzzaman</keyname><forenames>Shah</forenames></author><author><keyname>Qiao</keyname><forenames>Ying</forenames></author><author><keyname>Bochmann</keyname><forenames>Gregor v.</forenames></author></authors><title>CliqueStream: an efficient and fault-resilient live streaming network on
  a clustered peer-to-peer overlay</title><categories>cs.NI cs.DC cs.MM</categories><comments>10 pages</comments><journal-ref>Proc. 8th IEEE Intl. Conf. on Peer-to-Peer Computing (P2P'08),
  Sep. 2008, Aachen, Germany</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Several overlay-based live multimedia streaming platforms have been proposed
in the recent peer-to-peer streaming literature. In most of the cases, the
overlay neighbors are chosen randomly for robustness of the overlay. However,
this causes nodes that are distant in terms of proximity in the underlying
physical network to become neighbors, and thus data travels unnecessary
distances before reaching the destination. For efficiency of bulk data
transmission like multimedia streaming, the overlay neighborhood should
resemble the proximity in the underlying network. In this paper, we exploit the
proximity and redundancy properties of a recently proposed clique-based
clustered overlay network, named eQuus, to build efficient as well as robust
overlays for multimedia stream dissemination. To combine the efficiency of
content pushing over tree structured overlays and the robustness of data-driven
mesh overlays, higher capacity stable nodes are organized in tree structure to
carry the long haul traffic and less stable nodes with intermittent presence
are organized in localized meshes. The overlay construction and fault-recovery
procedures are explained in details. Simulation study demonstrates the good
locality properties of the platform. The outage time and control overhead
induced by the failure recovery mechanism are minimal as demonstrated by the
analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4366</identifier>
 <datestamp>2009-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4366</id><created>2009-03-25</created><updated>2009-07-31</updated><authors><author><keyname>Endrullis</keyname><forenames>Joerg</forenames></author><author><keyname>Grabmayer</keyname><forenames>Clemens</forenames></author><author><keyname>Hendriks</keyname><forenames>Dimitri</forenames></author></authors><title>Complexity of Fractran and Productivity</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In functional programming languages the use of infinite structures is common
practice. For total correctness of programs dealing with infinite structures
one must guarantee that every finite part of the result can be evaluated in
finitely many steps. This is known as productivity. For programming with
infinite structures, productivity is what termination in well-defined results
is for programming with finite structures.
  Fractran is a simple Turing-complete programming language invented by Conway.
We prove that the question whether a Fractran program halts on all positive
integers is Pi^0_2-complete. In functional programming, productivity typically
is a property of individual terms with respect to the inbuilt evaluation
strategy. By encoding Fractran programs as specifications of infinite lists, we
establish that this notion of productivity is Pi^0_2-complete even for the most
simple specifications. Therefore it is harder than termination of individual
terms. In addition, we explore possible generalisations of the notion of
productivity in the framework of term rewriting, and prove that their
computational complexity is Pi^1_1-complete, thus exceeding the expressive
power of first-order logic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4378</identifier>
 <datestamp>2009-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4378</id><created>2009-03-25</created><authors><author><keyname>Asaduzzaman</keyname><forenames>Shah</forenames></author><author><keyname>Maheswaran</keyname><forenames>Muthucumaru</forenames></author></authors><title>Using Dedicated and Opportunistic Networks in Synergy for a
  Cost-effective Distributed Stream Processing Platform</title><categories>cs.DC cs.NI</categories><comments>9 pages</comments><journal-ref>Proc. 14th IEEE Intl. Conf. on Parallel and Distributed Systems
  (ICPADS), Dec. 2008, Melbourne, Australia</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a case for exploiting the synergy of dedicated and
opportunistic network resources in a distributed hosting platform for data
stream processing applications. Our previous studies have demonstrated the
benefits of combining dedicated reliable resources with opportunistic resources
in case of high-throughput computing applications, where timely allocation of
the processing units is the primary concern. Since distributed stream
processing applications demand large volume of data transmission between the
processing sites at a consistent rate, adequate control over the network
resources is important here to assure a steady flow of processing. In this
paper, we propose a system model for the hybrid hosting platform where stream
processing servers installed at distributed sites are interconnected with a
combination of dedicated links and public Internet. Decentralized algorithms
have been developed for allocation of the two classes of network resources
among the competing tasks with an objective towards higher task throughput and
better utilization of expensive dedicated resources. Results from extensive
simulation study show that with proper management, systems exploiting the
synergy of dedicated and opportunistic resources yield considerably higher task
throughput and thus, higher return on investment over the systems solely using
expensive dedicated resources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4382</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4382</id><created>2009-03-25</created><updated>2009-05-25</updated><authors><author><keyname>Ben-Amram</keyname><forenames>Amir M.</forenames></author><author><keyname>Lee</keyname><forenames>Chin Soon</forenames></author></authors><title>Ranking Functions for Size-Change Termination II</title><categories>cs.LO</categories><comments>29 pages;</comments><acm-class>D.2.4; F.3.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 5, Issue 2 (May 25,
  2009) lmcs:1000</journal-ref><doi>10.2168/LMCS-5(2:8)2009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Size-Change Termination is an increasingly-popular technique for verifying
program termination. These termination proofs are deduced from an abstract
representation of the program in the form of &quot;size-change graphs&quot;.
  We present algorithms that, for certain classes of size-change graphs, deduce
a global ranking function: an expression that ranks program states, and
decreases on every transition. A ranking function serves as a witness for a
termination proof, and is therefore interesting for program certification. The
particular form of the ranking expressions that represent SCT termination
proofs sheds light on the scope of the proof method. The complexity of the
expressions is also interesting, both practicaly and theoretically.
  While deducing ranking functions from size-change graphs has already been
shown possible, the constructions in this paper are simpler and more
transparent than previously known. They improve the upper bound on the size of
the ranking expression from triply exponential down to singly exponential (for
certain classes of instances). We claim that this result is, in some sense,
optimal. To this end, we introduce a framework for lower bounds on the
complexity of ranking expressions and prove exponential lower bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4386</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4386</id><created>2009-03-25</created><updated>2011-09-01</updated><authors><author><keyname>Nakiboglu</keyname><forenames>Baris</forenames></author><author><keyname>Zheng</keyname><forenames>Lizhong</forenames></author></authors><title>Error-and-Erasure Decoding for Block Codes with Feedback</title><categories>cs.IT math.IT</categories><comments>33 pages, 1 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inner and outer bounds are derived on the optimal performance of fixed length
block codes on discrete memoryless channels with feedback and
errors-and-erasures decoding. First an inner bound is derived using a two phase
encoding scheme with communication and control phases together with the optimal
decoding rule for the given encoding scheme, among decoding rules that can be
represented in terms of pairwise comparisons between the messages. Then an
outer bound is derived using a generalization of the straight-line bound to
errors-and-erasures decoders and the optimal error exponent trade off of a
feedback encoder with two messages. In addition upper and lower bounds are
derived, for the optimal erasure exponent of error free block codes in terms of
the rate. Finally we present a proof of the fact that the optimal trade off
between error exponents of a two message code does not increase with feedback
on DMCs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4392</identifier>
 <datestamp>2009-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4392</id><created>2009-03-25</created><authors><author><keyname>Asaduzzaman</keyname><forenames>Shah</forenames></author><author><keyname>Maheswaran</keyname><forenames>Muthucumaru</forenames></author></authors><title>Towards a decentralized algorithm for mapping network and computational
  resources for distributed data-flow computations</title><categories>cs.DC cs.NI</categories><comments>7 pages</comments><journal-ref>Proc. 21st IEEE Intl. Symp. on High Performance Computing Systems
  and Applications (HPCS), May 2007, Saskatoon, SK, Canada</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Several high-throughput distributed data-processing applications require
multi-hop processing of streams of data. These applications include continual
processing on data streams originating from a network of sensors, composing a
multimedia stream through embedding several component streams originating from
different locations, etc. These data-flow computing applications require
multiple processing nodes interconnected according to the data-flow topology of
the application, for on-stream processing of the data. Since the applications
usually sustain for a long period, it is important to optimally map the
component computations and communications on the nodes and links in the
network, fulfilling the capacity constraints and optimizing some quality metric
such as end-to-end latency. The mapping problem is unfortunately NP-complete
and heuristics have been previously proposed to compute the approximate
solution in a centralized way. However, because of the dynamicity of the
network, it is practically impossible to aggregate the correct state of the
whole network in a single node. In this paper, we present a distributed
algorithm for optimal mapping of the components of the data flow applications.
We propose several heuristics to minimize the message complexity of the
algorithm while maintaining the quality of the solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4426</identifier>
 <datestamp>2009-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4426</id><created>2009-03-25</created><authors><author><keyname>Lucani</keyname><forenames>Daniel E.</forenames></author><author><keyname>M&#xe9;dard</keyname><forenames>Muriel</forenames></author><author><keyname>Stojanovic</keyname><forenames>Milica</forenames></author></authors><title>Capacity Scaling Laws for Underwater Networks</title><categories>cs.IT math.IT</categories><comments>5 pages, 2 figures, to Appear in Proceedings of Asilomar Conference
  on Signals, Systems, and Computers, 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The underwater acoustic channel is characterized by a path loss that depends
not only on the transmission distance, but also on the signal frequency.
Signals transmitted from one user to another over a distance $l$ are subject to
a power loss of $l^{-\alpha}{a(f)}^{-l}$. Although a terrestrial radio channel
can be modeled similarly, the underwater acoustic channel has different
characteristics. The spreading factor $\alpha$, related to the geometry of
propagation, has values in the range $1 \leq \alpha \leq 2$. The absorption
coefficient $a(f)$ is a rapidly increasing function of frequency: it is three
orders of magnitude greater at 100 kHz than at a few Hz. Existing results for
capacity of wireless networks correspond to scenarios for which $a(f) = 1$, or
a constant greater than one, and $\alpha \geq 2$. These results cannot be
applied to underwater acoustic networks in which the attenuation varies over
the system bandwidth. We use a water-filling argument to assess the minimum
transmission power and optimum transmission band as functions of the link
distance and desired data rate, and study the capacity scaling laws under this
model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4434</identifier>
 <datestamp>2009-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4434</id><created>2009-03-25</created><authors><author><keyname>Lucani</keyname><forenames>Daniel E.</forenames></author><author><keyname>M&#xe9;dard</keyname><forenames>Muriel</forenames></author><author><keyname>Stojanovic</keyname><forenames>Milica</forenames></author></authors><title>Random Linear Network Coding for Time-Division Duplexing: Queueing
  Analysis</title><categories>cs.IT math.IT</categories><comments>5 pages, 5 figures, 2 tables, Submitted to ISIT 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the performance of random linear network coding for time division
duplexing channels with Poisson arrivals. We model the system as a bulk-service
queue with variable bulk size. A full characterization for random linear
network coding is provided for time division duplexing channels [1] by means of
the moment generating function. We present numerical results for the mean
number of packets in the queue and consider the effect of the range of
allowable bulk sizes. We show that there exists an optimal choice of this range
that minimizes the mean number of data packets in the queue.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4435</identifier>
 <datestamp>2009-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4435</id><created>2009-03-25</created><authors><author><keyname>Shcherbina</keyname><forenames>O.</forenames></author></authors><title>Tree decomposition and postoptimality analysis in discrete optimization</title><categories>cs.DM</categories><comments>19 pages, 5 fugures</comments><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many real discrete optimization problems (DOPs) are $NP$-hard and contain a
huge number of variables and/or constraints that make the models intractable
for currently available solvers. Large DOPs can be solved due to their special
tructure using decomposition approaches. An important example of decomposition
approaches is tree decomposition with local decomposition algorithms using the
special block matrix structure of constraints which can exploit sparsity in the
interaction graph of a discrete optimization problem. In this paper, discrete
optimization problems with a tree structural graph are solved by local
decomposition algorithms. Local decomposition algorithms generate a family of
related DO problems which have the same structure but differ in the right-hand
sides. Due to this fact, postoptimality techniques in DO are applied.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4443</identifier>
 <datestamp>2009-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4443</id><created>2009-03-25</created><authors><author><keyname>Lucani</keyname><forenames>Daniel E.</forenames></author><author><keyname>M&#xe9;dard</keyname><forenames>Muriel</forenames></author><author><keyname>Stojanovic</keyname><forenames>Milica</forenames></author></authors><title>Broadcasting in Time-Division Duplexing: A Random Linear Network Coding
  Approach</title><categories>cs.IT math.IT</categories><comments>6 pages, 5 figures, Submitted to Workshop on Network Coding, Theory,
  and Applications (NetCod 2009)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study random linear network coding for broadcasting in time division
duplexing channels. We assume a packet erasure channel with nodes that cannot
transmit and receive information simultaneously. The sender transmits coded
data packets back-to-back before stopping to wait for the receivers to
acknowledge the number of degrees of freedom, if any, that are required to
decode correctly the information. We study the mean time to complete the
transmission of a block of packets to all receivers. We also present a bound on
the number of stops to wait for acknowledgement in order to complete
transmission with probability at least $1-\epsilon$, for any $\epsilon&gt;0$. We
present analysis and numerical results showing that our scheme outperforms
optimal scheduling policies for broadcast, in terms of the mean completion
time. We provide a simple heuristic to compute the number of coded packets to
be sent before stopping that achieves close to optimal performance with the
advantage of a considerable reduction in the search time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4510</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4510</id><created>2009-03-26</created><updated>2009-11-10</updated><authors><author><keyname>Gupta</keyname><forenames>Anupam</forenames></author><author><keyname>Ligett</keyname><forenames>Katrina</forenames></author><author><keyname>McSherry</keyname><forenames>Frank</forenames></author><author><keyname>Roth</keyname><forenames>Aaron</forenames></author><author><keyname>Talwar</keyname><forenames>Kunal</forenames></author></authors><title>Differentially Private Combinatorial Optimization</title><categories>cs.DS cs.CR cs.GT</categories><comments>28 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider the following problem: given a metric space, some of whose points
are &quot;clients&quot;, open a set of at most $k$ facilities to minimize the average
distance from the clients to these facilities. This is just the well-studied
$k$-median problem, for which many approximation algorithms and hardness
results are known. Note that the objective function encourages opening
facilities in areas where there are many clients, and given a solution, it is
often possible to get a good idea of where the clients are located. However,
this poses the following quandary: what if the identity of the clients is
sensitive information that we would like to keep private? Is it even possible
to design good algorithms for this problem that preserve the privacy of the
clients?
  In this paper, we initiate a systematic study of algorithms for discrete
optimization problems in the framework of differential privacy (which
formalizes the idea of protecting the privacy of individual input elements). We
show that many such problems indeed have good approximation algorithms that
preserve differential privacy; this is even in cases where it is impossible to
preserve cryptographic definitions of privacy while computing any non-trivial
approximation to even the_value_ of an optimal solution, let alone the entire
solution.
  Apart from the $k$-median problem, we study the problems of vertex and set
cover, min-cut, facility location, Steiner tree, and the recently introduced
submodular maximization problem, &quot;Combinatorial Public Projects&quot; (CPP).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4513</identifier>
 <datestamp>2011-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4513</id><created>2009-03-26</created><updated>2011-10-13</updated><authors><author><keyname>Vishnevskaya</keyname><forenames>Elena S.</forenames></author></authors><title>Building the information kernel and the problem of recognition</title><categories>cs.CV cs.AI</categories><comments>This paper has been withdrawn by the author</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  At this point in time there is a need for a new representation of different
information, to identify and organize descending its characteristics. Today,
science is a powerful tool for the description of reality - the numbers. Why
the most important property of numbers. Suppose we have a number 0.2351734, it
is clear that the figures are there in order of importance. If necessary, we
can round the number up to some value, eg 0.235. Arguably, the 0,235 - the most
important information of 0.2351734. Thus, we can reduce the size of numbers is
not losing much with the accuracy. Clearly, if learning to provide a graphical
or audio information kernel, we can provide the most relevant information,
discarding the rest. Introduction of various kinds of information in an
information kernel, is an important task, to solve many problems in artificial
intelligence and information theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4521</identifier>
 <datestamp>2009-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4521</id><created>2009-03-26</created><updated>2009-05-15</updated><authors><author><keyname>Philip</keyname><forenames>Geevarghese</forenames></author><author><keyname>Raman</keyname><forenames>Venkatesh</forenames></author><author><keyname>Sikdar</keyname><forenames>Somnath</forenames></author></authors><title>Solving Dominating Set in Larger Classes of Graphs: FPT Algorithms and
  Polynomial Kernels</title><categories>cs.DS</categories><comments>12 pages, 1 figure, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the k-Dominating Set problem is fixed parameter tractable (FPT)
and has a polynomial kernel for any class of graphs that exclude K_{i,j} as a
subgraph, for any fixed i, j &gt;= 1. This strictly includes every class of graphs
for which this problem has been previously shown to have FPT algorithms and/or
polynomial kernels. In particular, our result implies that the problem
restricted to bounded- degenerate graphs has a polynomial kernel, solving an
open problem posed by Alon and Gutner.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4526</identifier>
 <datestamp>2009-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4526</id><created>2009-03-26</created><authors><author><keyname>Vaze</keyname><forenames>Chinmay S.</forenames></author><author><keyname>Varanasi</keyname><forenames>Mahesh K.</forenames></author></authors><title>On the Achievable Rate of the Fading Dirty Paper Channel with Imperfect
  CSIT</title><categories>cs.IT math.IT</categories><comments>Presented at the 43rd Annual Conference on Information Sciences and
  Systems, John Hopkins University, March 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of dirty paper coding (DPC) over the (multi-antenna) fading dirty
paper channel (FDPC) Y = H(X + S) + Z is considered when there is imperfect
knowledge of the channel state information H at the transmitter (CSIT). The
case of FDPC with positive definite (p.d.) input covariance matrix was studied
by the authors in a recent paper, and here the more general case of positive
semi-definite (p.s.d.) input covariance is dealt with. Towards this end, the
choice of auxiliary random variable is modified. The algorithms for
determination of inflation factor proposed in the p.d. case are then
generalized to the case of p.s.d. input covariance. Subsequently, the largest
DPC-achievable high-SNR (signal-to-noise ratio) scaling factor over the no-CSIT
FDPC with p.s.d. input covariance matrix is derived. This scaling factor is
seen to be a non-trivial generalization of the one achieved for the p.d. case.
Next, in the limit of low SNR, it is proved that the choice of all-zero
inflation factor (thus treating interference as noise) is optimal in the
'ratio' sense, regardless of the covariance matrix used. Further, in the p.d.
covariance case, the inflation factor optimal at high SNR is obtained when the
number of transmit antennas is greater than the number of receive antennas,
with the other case having been already considered in the earlier paper.
Finally, the problem of joint optimization of the input covariance matrix and
the inflation factor is dealt with, and an iterative numerical algorithm is
developed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4527</identifier>
 <datestamp>2009-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4527</id><created>2009-03-26</created><updated>2009-11-14</updated><authors><author><keyname>Watanabe</keyname><forenames>Yusuke</forenames></author><author><keyname>Fukumizu</keyname><forenames>Kenji</forenames></author></authors><title>Graph polynomials and approximation of partition functions with Loopy
  Belief Propagation</title><categories>cs.DM cs.LG</categories><comments>7 pages. The 9th conference of Japanese Society for Artificial
  Intelligence, Special Interest Group on Data Mining and Statistical
  Mathematics (JSAI SIG-DMSM) in Kyoto 2009, March 3,4 Minor typos corrected</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Bethe approximation, or loopy belief propagation algorithm is a
successful method for approximating partition functions of probabilistic models
associated with a graph. Chertkov and Chernyak derived an interesting formula
called Loop Series Expansion, which is an expansion of the partition function.
The main term of the series is the Bethe approximation while other terms are
labeled by subgraphs called generalized loops. In our recent paper, we derive
the loop series expansion in form of a polynomial with coefficients positive
integers, and extend the result to the expansion of marginals. In this paper,
we give more clear derivation for the results and discuss the properties of the
polynomial which is introduced in the paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4530</identifier>
 <datestamp>2009-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4530</id><created>2009-03-26</created><updated>2009-04-12</updated><authors><author><keyname>Lim</keyname><forenames>Lek-Heng</forenames></author><author><keyname>Comon</keyname><forenames>Pierre</forenames></author></authors><title>Nonnegative approximations of nonnegative tensors</title><categories>cs.NA cs.IR</categories><comments>14 pages</comments><acm-class>G.1.2; G.1.6; G.3; I.2.6; I.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the decomposition of a nonnegative tensor into a minimal sum of
outer product of nonnegative vectors and the associated parsimonious naive
Bayes probabilistic model. We show that the corresponding approximation
problem, which is central to nonnegative PARAFAC, will always have optimal
solutions. The result holds for any choice of norms and, under a mild
assumption, even Bregman divergences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4545</identifier>
 <datestamp>2009-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4545</id><created>2009-03-26</created><authors><author><keyname>Troccaz</keyname><forenames>Jocelyne</forenames><affiliation>TIMC</affiliation></author></authors><title>Computer- and robot-assisted Medical Intervention</title><categories>cs.RO</categories><comments>Handbook of Automation, Shimon Nof (Ed.) (2009) 000-000</comments><proxy>ccsd hal-00371025</proxy><journal-ref>Handbook of Automation, Shimon Nof (Ed.) (2009) 1451-1466</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Medical robotics includes assistive devices used by the physician in order to
make his/her diagnostic or therapeutic practices easier and more efficient.
This chapter focuses on such systems. It introduces the general field of
Computer-Assisted Medical Interventions, its aims, its different components and
describes the place of robots in that context. The evolutions in terms of
general design and control paradigms in the development of medical robots are
presented and issues specific to that application domain are discussed. A view
of existing systems, on-going developments and future trends is given. A
case-study is detailed. Other types of robotic help in the medical environment
(such as for assisting a handicapped person, for rehabilitation of a patient or
for replacement of some damaged/suppressed limbs or organs) are out of the
scope of this chapter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4554</identifier>
 <datestamp>2009-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4554</id><created>2009-03-26</created><authors><author><keyname>Malinen</keyname><forenames>Mikko</forenames></author></authors><title>Fountain Codes and Invertible Matrices</title><categories>cs.IT math.IT</categories><comments>3 pages, 2 figures, submitted to the IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with Fountain codes, and especially with their encoding
matrices, which are required here to be invertible. A result is stated that an
encoding matrix induces a permutation. Also, a result is that encoding matrices
form a group with multiplication operation. An encoding is a transformation,
which reduces the entropy of an initially high-entropy input vector. A special
encoding matrix, with which the entropy reduction is more effective than with
matrices created by the Ideal Soliton distribution is formed. Experimental
results with entropy reduction are shown.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4582</identifier>
 <datestamp>2009-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4582</id><created>2009-03-26</created><updated>2009-08-16</updated><authors><author><keyname>Zhang</keyname><forenames>Xiao Juan</forenames></author><author><keyname>Gong</keyname><forenames>Yi</forenames></author></authors><title>On the Achievable Diversity-Multiplexing Tradeoff in MIMO Fading
  Channels with Imperfect CSIT</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we analyze the fundamental tradeoff of diversity and
multiplexing in multi-input multi-output (MIMO) channels with imperfect channel
state information at the transmitter (CSIT). We show that with imperfect CSIT,
a higher diversity gain as well as a more efficient diversity-multiplexing
tradeoff (DMT) can be achieved. In the case of multi-input single-output
(MISO)/single-input multi-output (SIMO) channels with K transmit/receive
antennas, one can achieve a diversity gain of d(r)=K(1-r+K\alpha) at spatial
multiplexing gain r, where \alpha is the CSIT quality defined in this paper.
For general MIMO channels with M (M&gt;1) transmit and N (N&gt;1) receive antennas,
we show that depending on the value of \alpha, different DMT can be derived and
the value of \alpha has a great impact on the achievable diversity, especially
at high multiplexing gains. Specifically, when \alpha is above a certain
threshold, one can achieve a diversity gain of d(r)=MN(1+MN\alpha)-(M+N-1)r;
otherwise, the achievable DMT is much lower and can be described as a
collection of discontinuous line segments depending on M, N, r and \alpha. Our
analysis reveals that imperfect CSIT significantly improves the achievable
diversity gain while enjoying high spatial multiplexing gains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4594</identifier>
 <datestamp>2009-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4594</id><created>2009-03-26</created><authors><author><keyname>Lotfinezhad</keyname><forenames>Mahdi</forenames></author><author><keyname>Liang</keyname><forenames>Ben</forenames></author><author><keyname>Sousa</keyname><forenames>Elvino S.</forenames></author></authors><title>Dynamic Control of Tunable Sub-optimal Algorithms for Scheduling of
  Time-varying Wireless Networks</title><categories>cs.IT math.IT</categories><comments>Submitted for journal consideration. A shorter version was presented
  in IEEE IWQoS 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is well known that for ergodic channel processes the Generalized
Max-Weight Matching (GMWM) scheduling policy stabilizes the network for any
supportable arrival rate vector within the network capacity region. This
policy, however, often requires the solution of an NP-hard optimization
problem. This has motivated many researchers to develop sub-optimal algorithms
that approximate the GMWM policy in selecting schedule vectors. One implicit
assumption commonly shared in this context is that during the algorithm
runtime, the channel states remain effectively unchanged. This assumption may
not hold as the time needed to select near-optimal schedule vectors usually
increases quickly with the network size. In this paper, we incorporate channel
variations and the time-efficiency of sub-optimal algorithms into the scheduler
design, to dynamically tune the algorithm runtime considering the tradeoff
between algorithm efficiency and its robustness to changing channel states.
Specifically, we propose a Dynamic Control Policy (DCP) that operates on top of
a given sub-optimal algorithm, and dynamically but in a large time-scale
adjusts the time given to the algorithm according to queue backlog and channel
correlations. This policy does not require knowledge of the structure of the
given sub-optimal algorithm, and with low overhead can be implemented in a
distributed manner. Using a novel Lyapunov analysis, we characterize the
throughput stability region induced by DCP and show that our characterization
can be tight. We also show that the throughput stability region of DCP is at
least as large as that of any other static policy. Finally, we provide two case
studies to gain further intuition into the performance of DCP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4615</identifier>
 <datestamp>2010-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4615</id><created>2009-03-26</created><updated>2009-06-01</updated><authors><author><keyname>Finkel</keyname><forenames>Olivier</forenames><affiliation>ELM, Lip</affiliation></author></authors><title>On Decidability Properties of One-Dimensional Cellular Automata</title><categories>cs.LO cs.CC math.LO</categories><comments>Final version; to appear in the Journal of Cellular Automata</comments><proxy>ccsd hal-00371169</proxy><journal-ref>Journal of Cellular Automata 6, 2-3 (2011) 181-193</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a recent paper Sutner proved that the first-order theory of the
phase-space $\mathcal{S}_\mathcal{A}=(Q^\mathbb{Z}, \longrightarrow)$ of a
one-dimensional cellular automaton $\mathcal{A}$ whose configurations are
elements of $Q^\mathbb{Z}$, for a finite set of states $Q$, and where
$\longrightarrow$ is the &quot;next configuration relation&quot;, is decidable. He asked
whether this result could be extended to a more expressive logic. We prove in
this paper that this is actuallly the case. We first show that, for each
one-dimensional cellular automaton $\mathcal{A}$, the phase-space
$\mathcal{S}_\mathcal{A}$ is an omega-automatic structure. Then, applying
recent results of Kuske and Lohrey on omega-automatic structures, it follows
that the first-order theory, extended with some counting and cardinality
quantifiers, of the structure $\mathcal{S}_\mathcal{A}$, is decidable. We give
some examples of new decidable properties for one-dimensional cellular
automata. In the case of surjective cellular automata, some more efficient
algorithms can be deduced from results of Kuske and Lohrey on structures of
bounded degree. On the other hand we show that the case of cellular automata
give new results on automatic graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4616</identifier>
 <datestamp>2010-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4616</id><created>2009-03-26</created><authors><author><keyname>Stroeer</keyname><forenames>Alexander</forenames></author><author><keyname>Cannizzo</keyname><forenames>John K.</forenames></author><author><keyname>Camp</keyname><forenames>Jordan B.</forenames></author><author><keyname>Gagarin</keyname><forenames>Nicolas</forenames></author></authors><title>Methods for detection and characterization of signals in noisy data with
  the Hilbert-Huang Transform</title><categories>physics.data-an cs.NA gr-qc</categories><comments>submitted to PRD, 10 pages, 9 figures in color</comments><journal-ref>Phys.Rev.D79:124022,2009</journal-ref><doi>10.1103/PhysRevD.79.124022</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Hilbert-Huang Transform is a novel, adaptive approach to time series
analysis that does not make assumptions about the data form. Its adaptive,
local character allows the decomposition of non-stationary signals with
hightime-frequency resolution but also renders it susceptible to degradation
from noise. We show that complementing the HHT with techniques such as
zero-phase filtering, kernel density estimation and Fourier analysis allows it
to be used effectively to detect and characterize signals with low signal to
noise ratio.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4696</identifier>
 <datestamp>2011-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4696</id><created>2009-03-26</created><authors><author><keyname>Kramer</keyname><forenames>Joshua Brown</forenames></author><author><keyname>Sabalka</keyname><forenames>Lucas</forenames></author></authors><title>Multidimensional Online Robot Motion</title><categories>cs.CG cs.RO</categories><comments>26 pages, 5 figures</comments><acm-class>F.2.2; I.2.9</acm-class><journal-ref>International Journal of Computational Geometry and Applications,
  20(6):653-684, 2010</journal-ref><doi>10.1142/S0218195910003475</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider three related problems of robot movement in arbitrary dimensions:
coverage, search, and navigation. For each problem, a spherical robot is asked
to accomplish a motion-related task in an unknown environment whose geometry is
learned by the robot during navigation. The robot is assumed to have tactile
and global positioning sensors. We view these problems from the perspective of
(non-linear) competitiveness as defined by Gabriely and Rimon. We first show
that in 3 dimensions and higher, there is no upper bound on competitiveness:
every online algorithm can do arbitrarily badly compared to the optimal. We
then modify the problems by assuming a fixed clearance parameter. We are able
to give optimally competitive algorithms under this assumption.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4726</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4726</id><created>2009-03-26</created><updated>2010-04-07</updated><authors><author><keyname>Gagie</keyname><forenames>Travis</forenames></author><author><keyname>Puglisi</keyname><forenames>Simon J.</forenames></author><author><keyname>Turpin</keyname><forenames>Andrew</forenames></author></authors><title>Range Quantile Queries: Another Virtue of Wavelet Trees</title><categories>cs.DS</categories><comments>Added note about generalization to any constant number of dimensions.</comments><doi>10.1007/978-3-642-03784-9_1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show how to use a balanced wavelet tree as a data structure that stores a
list of numbers and supports efficient {\em range quantile queries}. A range
quantile query takes a rank and the endpoints of a sublist and returns the
number with that rank in that sublist. For example, if the rank is half the
sublist's length, then the query returns the sublist's median. We also show how
these queries can be used to support space-efficient {\em coloured range
reporting} and {\em document listing}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4728</identifier>
 <datestamp>2011-10-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4728</id><created>2009-03-26</created><updated>2011-10-06</updated><authors><author><keyname>Cai</keyname><forenames>Jin-Yi</forenames></author><author><keyname>Chen</keyname><forenames>Xi</forenames></author><author><keyname>Lu</keyname><forenames>Pinyan</forenames></author></authors><title>Graph Homomorphisms with Complex Values: A Dichotomy Theorem</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graph homomorphism has been studied intensively. Given an m x m symmetric
matrix A, the graph homomorphism function is defined as \[Z_A (G) =
\sum_{f:V-&gt;[m]} \prod_{(u,v)\in E} A_{f(u),f(v)}, \] where G = (V,E) is any
undirected graph. The function Z_A can encode many interesting graph
properties, including counting vertex covers and k-colorings. We study the
computational complexity of Z_A for arbitrary symmetric matrices A with
algebraic complex values. Building on work by Dyer and Greenhill, Bulatov and
Grohe, and especially the recent beautiful work by Goldberg, Grohe, Jerrum and
Thurley, we prove a complete dichotomy theorem for this problem. We show that
Z_A is either computable in polynomial-time or #P-hard, depending explicitly on
the matrix A. We further prove that the tractability criterion on A is
polynomial-time decidable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4738</identifier>
 <datestamp>2009-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4738</id><created>2009-03-27</created><authors><author><keyname>Park</keyname><forenames>Hong Ju</forenames></author><author><keyname>Ayanoglu</keyname><forenames>Ender</forenames></author></authors><title>Constellation Precoded Beamforming</title><categories>cs.IT math.IT</categories><comments>submitted to conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present and analyze the performance of constellation precoded beamforming.
This multi-input multi-output transmission technique is based on the singular
value decomposition of a channel matrix. In this work, the beamformer is
precoded to improve its diversity performance. It was shown previously that
while single beamforming achieves full diversity without channel coding,
multiple beamforming results in diversity loss. In this paper, we show that a
properly designed constellation precoder makes uncoded multiple beamforming
achieve full diversity order. We also show that partially precoded multiple
beamforming gets better diversity order than multiple beamforming without
constellation precoder if the subchannels to be precoded are properly chosen.
We propose several criteria to design the constellation precoder. Simulation
results match the analysis, and show that precoded multiple beamforming
actually outperforms single beamforming without precoding at the same system
data rate while achieving full diversity order.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4742</identifier>
 <datestamp>2009-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4742</id><created>2009-03-27</created><authors><author><keyname>Lee</keyname><forenames>Kiryung</forenames></author><author><keyname>Bresler</keyname><forenames>Yoram</forenames></author></authors><title>Guaranteed Minimum Rank Approximation from Linear Observations by
  Nuclear Norm Minimization with an Ellipsoidal Constraint</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The rank minimization problem is to find the lowest-rank matrix in a given
set. Nuclear norm minimization has been proposed as an convex relaxation of
rank minimization. Recht, Fazel, and Parrilo have shown that nuclear norm
minimization subject to an affine constraint is equivalent to rank minimization
under a certain condition given in terms of the rank-restricted isometry
property. However, in the presence of measurement noise, or with only
approximately low rank generative model, the appropriate constraint set is an
ellipsoid rather than an affine space. There exist polynomial-time algorithms
to solve the nuclear norm minimization with an ellipsoidal constraint, but no
performance guarantee has been shown for these algorithms. In this paper, we
derive such an explicit performance guarantee, bounding the error in the
approximate solution provided by nuclear norm minimization with an ellipsoidal
constraint.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4770</identifier>
 <datestamp>2009-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4770</id><created>2009-03-27</created><authors><author><keyname>Pabitra</keyname><forenames>Pal Choudhury</forenames></author><author><keyname>Sudhakar</keyname><forenames>Sahoo</forenames></author><author><keyname>Kumar</keyname><forenames>Nayak Birendra</forenames></author><author><keyname>Sarif</keyname><forenames>Hassan Sk.</forenames></author></authors><title>Act of CVT and EVT In The Formation of Number-Theoretic Fractals</title><categories>cs.DM</categories><comments>15 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we have defined two functions that have been used to construct
different fractals having fractal dimensions between 1 and 2. More precisely,
we can say that one of our defined functions produce the fractals whose fractal
dimension lies in [1.58, 2) and rest function produce the fractals whose
fractal dimension lies in (1, 1.58]. Also we tried to calculate the amount of
increment of fractal dimension in accordance with base of the number systems.
And in switching of fractals from one base to another, the increment of fractal
dimension is constant, which is 1.58, its quite surprising!
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4796</identifier>
 <datestamp>2011-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4796</id><created>2009-03-27</created><updated>2011-03-09</updated><authors><author><keyname>Bui-Xuan</keyname><forenames>B. -M.</forenames><affiliation>Department of Informatics, University of Bergen, Norway</affiliation></author><author><keyname>Telle</keyname><forenames>J. A.</forenames><affiliation>Department of Informatics, University of Bergen, Norway</affiliation></author><author><keyname>Vatshelle</keyname><forenames>M.</forenames><affiliation>Department of Informatics, University of Bergen, Norway</affiliation></author></authors><title>Fast FPT algorithms for vertex subset and vertex partitioning problems
  using neighborhood unions</title><categories>cs.DS cs.DM</categories><comments>The new version has runtimes expressed by number of equivalence
  classes, but no other changes</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce the graph parameter boolean-width, related to the number of
different unions of neighborhoods across a cut of a graph. Boolean-width is
similar to rank-width, which is related to the number of $GF[2]$-sums (1+1=0)
of neighborhoods instead of the boolean-sums (1+1=1) used for boolean-width. We
give algorithms for a large class of NP-hard vertex subset and vertex
partitioning problems that are FPT when parameterized by either boolean-width,
rank-width or clique-width, with runtime single exponential in either parameter
if given the pertinent optimal decomposition. To compare boolean-width versus
rank-width or clique-width, we first show that for any graph, the square root
of its boolean-width is never more than its rank-width. Next, we exhibit a
class of graphs, the Hsu-grids, for which we can solve NP-hard problems in
polynomial time, if we use the right parameter. An $n \times \frac{n}{10}$
Hsu-grid on ${1/10}n^2$ vertices has boolean-width $\Theta(\log n)$ and
rank-width $\Theta(n)$. Moreover, any optimal rank-decomposition of such a
graph will have boolean-width $\Theta(n)$, i.e. exponential in the optimal
boolean-width. A main open problem is to approximate the boolean-width better
than what is given by the algorithm for rank-width [Hlin\v{e}n\'y and Oum,
2008]
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4812</identifier>
 <datestamp>2011-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4812</id><created>2009-03-27</created><authors><author><keyname>Bhatnagar</keyname><forenames>Nayantara</forenames></author><author><keyname>Maneva</keyname><forenames>Elitza</forenames></author></authors><title>A computational method for bounding the probability of reconstruction on
  trees</title><categories>cs.DM</categories><comments>19 pages</comments><journal-ref>SIAM J. on Discrete Math, 25(2):854-871, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For a tree Markov random field non-reconstruction is said to hold if as the
depth of the tree goes to infinity the information that a typical configuration
at the leaves gives about the value at the root goes to zero. The distribution
of the measure at the root conditioned on a typical boundary can be computed
using a distributional recurrence. However the exact computation is not
feasible because the support of the distribution grows exponentially with the
depth.
  In this work, we introduce a notion of a survey of a distribution over
probability vectors which is a succinct representation of the true
distribution. We show that a survey of the distribution of the measure at the
root can be constructed by an efficient recursive algorithm. The key properties
of surveys are that the size does not grow with the depth, they can be
constructed recursively, and they still provide a good bound for the distance
between the true conditional distribution and the unconditional distribution at
the root. This approach applies to a large class of Markov random field models
including randomly generated ones. As an application we show bounds on the
reconstruction threshold for the Potts model on small-degree trees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4817</identifier>
 <datestamp>2012-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4817</id><created>2009-03-27</created><updated>2012-10-25</updated><authors><author><keyname>G&#xe4;rtner</keyname><forenames>Bernd</forenames></author><author><keyname>Jaggi</keyname><forenames>Martin</forenames></author><author><keyname>Maria</keyname><forenames>Cl&#xe9;ment</forenames></author></authors><title>An Exponential Lower Bound on the Complexity of Regularization Paths</title><categories>cs.LG cs.CG cs.CV math.OC stat.ML</categories><comments>Journal version, 28 Pages, 5 Figures</comments><msc-class>90C20</msc-class><acm-class>F.2.2; I.5.1</acm-class><journal-ref>Journal of Computational Geometry (JoCG) 3(1), 168-195, 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For a variety of regularized optimization problems in machine learning,
algorithms computing the entire solution path have been developed recently.
Most of these methods are quadratic programs that are parameterized by a single
parameter, as for example the Support Vector Machine (SVM). Solution path
algorithms do not only compute the solution for one particular value of the
regularization parameter but the entire path of solutions, making the selection
of an optimal parameter much easier.
  It has been assumed that these piecewise linear solution paths have only
linear complexity, i.e. linearly many bends. We prove that for the support
vector machine this complexity can be exponential in the number of training
points in the worst case. More strongly, we construct a single instance of n
input points in d dimensions for an SVM such that at least \Theta(2^{n/2}) =
\Theta(2^d) many distinct subsets of support vectors occur as the
regularization parameter changes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4826</identifier>
 <datestamp>2010-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4826</id><created>2009-03-27</created><updated>2010-05-12</updated><authors><author><keyname>Hernando</keyname><forenames>Fernando</forenames></author><author><keyname>Ruano</keyname><forenames>Diego</forenames></author></authors><title>New Linear Codes from Matrix-Product Codes with Polynomial Units</title><categories>cs.IT math.IT</categories><msc-class>68P30</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new construction of codes from old ones is considered, it is an extension
of the matrix-product construction. Several linear codes that improve the
parameters of the known ones are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4856</identifier>
 <datestamp>2009-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4856</id><created>2009-03-27</created><authors><author><keyname>G&#xe4;rtner</keyname><forenames>Bernd</forenames></author><author><keyname>Giesen</keyname><forenames>Joachim</forenames></author><author><keyname>Jaggi</keyname><forenames>Martin</forenames></author><author><keyname>Welsch</keyname><forenames>Torsten</forenames></author></authors><title>A Combinatorial Algorithm to Compute Regularization Paths</title><categories>cs.LG cs.AI cs.CV</categories><comments>7 Pages, 1 Figure</comments><acm-class>F.2.2; I.5.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For a wide variety of regularization methods, algorithms computing the entire
solution path have been developed recently. Solution path algorithms do not
only compute the solution for one particular value of the regularization
parameter but the entire path of solutions, making the selection of an optimal
parameter much easier. Most of the currently used algorithms are not robust in
the sense that they cannot deal with general or degenerate input. Here we
present a new robust, generic method for parametric quadratic programming. Our
algorithm directly applies to nearly all machine learning applications, where
so far every application required its own different algorithm.
  We illustrate the usefulness of our method by applying it to a very low rank
problem which could not be solved by existing path tracking methods, namely to
compute part-worth values in choice based conjoint analysis, a popular
technique from market research to estimate consumers preferences on a class of
parameterized options.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4860</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4860</id><created>2009-03-27</created><authors><author><keyname>Furtlehner</keyname><forenames>Cyril</forenames></author><author><keyname>Lasgouttes</keyname><forenames>Jean-Marc</forenames></author><author><keyname>Auger</keyname><forenames>Anne</forenames></author></authors><title>Learning Multiple Belief Propagation Fixed Points for Real Time
  Inference</title><categories>cs.LG cond-mat.dis-nn physics.data-an</categories><comments>RR Inria 6887, 26 pages, 7 figures</comments><journal-ref>Physica A. Vol. 389(1), pp. 149-163 (2010)</journal-ref><doi>10.1016/j.physa.2009.08.030</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the context of inference with expectation constraints, we propose an
approach based on the &quot;loopy belief propagation&quot; algorithm LBP, as a surrogate
to an exact Markov Random Field MRF modelling. A prior information composed of
correlations among a large set of N variables, is encoded into a graphical
model; this encoding is optimized with respect to an approximate decoding
procedure LBP, which is used to infer hidden variables from an observed subset.
We focus on the situation where the underlying data have many different
statistical components, representing a variety of independent patterns.
Considering a single parameter family of models we show how LBP may be used to
encode and decode efficiently such information, without solving the NP hard
inverse problem yielding the optimal MRF. Contrary to usual practice, we work
in the non-convex Bethe free energy minimization framework, and manage to
associate a belief propagation fixed point to each component of the underlying
probabilistic mixture. The mean field limit is considered and yields an exact
connection with the Hopfield model at finite temperature and steady state, when
the number of mixture components is proportional to the number of variables. In
addition, we provide an enhanced learning procedure, based on a straightforward
multi-parameter extension of the model in conjunction with an effective
continuous optimization procedure. This is performed using the stochastic
search heuristic CMAES and yields a significant improvement with respect to the
single parameter basic model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4875</identifier>
 <datestamp>2014-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4875</id><created>2009-03-27</created><updated>2009-07-24</updated><authors><author><keyname>Dubey</keyname><forenames>A.</forenames></author><author><keyname>Reid</keyname><forenames>L. B.</forenames></author><author><keyname>Weide</keyname><forenames>K.</forenames></author><author><keyname>Antypas</keyname><forenames>K.</forenames></author><author><keyname>Ganapathy</keyname><forenames>M. K.</forenames></author><author><keyname>Riley</keyname><forenames>K.</forenames></author><author><keyname>Sheeler</keyname><forenames>D.</forenames></author><author><keyname>Siegal</keyname><forenames>A.</forenames></author></authors><title>Extensible Component Based Architecture for FLASH, A Massively Parallel,
  Multiphysics Simulation Code</title><categories>cs.SE</categories><comments>33 pages, 7 figures; revised paper submitted to Parallel Computing</comments><doi>10.1016/j.parco.2009.08.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  FLASH is a publicly available high performance application code which has
evolved into a modular, extensible software system from a collection of
unconnected legacy codes. FLASH has been successful because its capabilities
have been driven by the needs of scientific applications, without compromising
maintainability, performance, and usability. In its newest incarnation, FLASH3
consists of inter-operable modules that can be combined to generate different
applications. The FLASH architecture allows arbitrarily many alternative
implementations of its components to co-exist and interchange with each other,
resulting in greater flexibility. Further, a simple and elegant mechanism
exists for customization of code functionality without the need to modify the
core implementation of the source. A built-in unit test framework providing
verifiability, combined with a rigorous software maintenance process, allow the
code to operate simultaneously in the dual mode of production and development.
In this paper we describe the FLASH3 architecture, with emphasis on solutions
to the more challenging conflicts arising from solver complexity, portable
performance requirements, and legacy codes. We also include results from user
surveys conducted in 2005 and 2007, which highlight the success of the code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4898</identifier>
 <datestamp>2009-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4898</id><created>2009-03-27</created><authors><author><keyname>Jelenkovic</keyname><forenames>Predrag R.</forenames></author><author><keyname>Radovanovic</keyname><forenames>Ana</forenames></author></authors><title>Asymptotic Optimality of the Static Frequency Caching in the Presence of
  Correlated Requests</title><categories>cs.PF cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is well known that the static caching algorithm that keeps the most
frequently requested documents in the cache is optimal in case when documents
are of the same size and requests are independent and equally distributed.
However, it is hard to develop explicit and provably optimal caching algorithms
when requests are statistically correlated. In this paper, we show that keeping
the most frequently requested documents in the cache is still optimal for large
cache sizes even if the requests are strongly correlated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4907</identifier>
 <datestamp>2015-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4907</id><created>2009-03-27</created><updated>2015-12-09</updated><authors><author><keyname>Hambardzumyan</keyname><forenames>Sasun</forenames></author><author><keyname>Mkrtchyan</keyname><forenames>Vahan V.</forenames></author><author><keyname>Musoyan</keyname><forenames>Vahe L.</forenames></author><author><keyname>Sargsyan</keyname><forenames>Hovhannes</forenames></author></authors><title>The hardness of the independence and matching clutter of a graph</title><categories>cs.DM math.CO</categories><comments>23 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A {\it clutter} (or {\it antichain} or {\it Sperner family}) $L$ is a pair
$(V,E)$, where $V$ is a finite set and $E$ is a family of subsets of $V$ none
of which is a subset of another. Usually, the elements of $V$ are called {\it
vertices} of $L$, and the elements of $E$ are called {\it edges} of $L$. A
subset $s_e$ of an edge $e$ of a clutter is called {\it recognizing} for $e$,
if $s_e$ is not a subset of another edge. The {\it hardness} of an edge $e$ of
a clutter is the ratio of the size of $e\textrm{'s}$ smallest recognizing
subset to the size of $e$. The hardness of a clutter is the maximum hardness of
its edges. We study the hardness of clutters arising from independent sets and
matchings of graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4930</identifier>
 <datestamp>2009-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4930</id><created>2009-03-27</created><authors><author><keyname>Kormushev</keyname><forenames>Petar</forenames></author><author><keyname>Nomoto</keyname><forenames>Kohei</forenames></author><author><keyname>Dong</keyname><forenames>Fangyan</forenames></author><author><keyname>Hirota</keyname><forenames>Kaoru</forenames></author></authors><title>Time manipulation technique for speeding up reinforcement learning in
  simulations</title><categories>cs.AI cs.LG cs.RO</categories><comments>12 pages</comments><journal-ref>International Journal of Cybernetics and Information Technologies,
  vol. 8, no. 1, pp. 12-24, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A technique for speeding up reinforcement learning algorithms by using time
manipulation is proposed. It is applicable to failure-avoidance control
problems running in a computer simulation. Turning the time of the simulation
backwards on failure events is shown to speed up the learning by 260% and
improve the state space exploration by 12% on the cart-pole balancing task,
compared to the conventional Q-learning and Actor-Critic algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4939</identifier>
 <datestamp>2009-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4939</id><created>2009-03-28</created><authors><author><keyname>Li</keyname><forenames>Lianlin</forenames></author><author><keyname>Li</keyname><forenames>Fang</forenames></author></authors><title>A Novel Algorithm for Compressive Sensing: Iteratively Reweighed
  Operator Algorithm (IROA)</title><categories>cs.IT math.IT</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Compressive sensing claims that the sparse signals can be reconstructed
exactly from many fewer measurements than traditionally believed necessary. One
of issues ensuring the successful compressive sensing is to deal with the
sparsity-constraint optimization. Up to now, many excellent theories,
algorithms and software have been developed, for example, the so-called greedy
algorithm ant its variants, the sparse Bayesian algorithm, the convex
optimization methods, and so on. The formulations for them consist of two
terms, in which one is and the other is (, mostly, p=1 is adopted due to good
characteristic of the convex function) (NOTE: without the loss of generality,
itself is assumed to be sparse). It is noted that all of them specify the
sparsity constraint by the second term. Different from them, the developed
formulation in this paper consists of two terms where one is with () and the
other is . For each iteration the measurement matrix (linear operator) is
reweighed by determined by which is obtained in the previous iteration, so the
proposed method is called the iteratively reweighed operator algorithm (IROA).
Moreover, in order to save the computation time, another reweighed operation
has been carried out; in particular, the columns of corresponding to small have
been excluded out. Theoretical analysis and numerical simulations have shown
that the proposed method overcomes the published algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4959</identifier>
 <datestamp>2009-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4959</id><created>2009-03-28</created><updated>2009-04-05</updated><authors><author><keyname>Koukoutsidis</keyname><forenames>Ioannis</forenames></author></authors><title>TCP over 3G links: Problems and Solutions</title><categories>cs.NI</categories><comments>A review paper prepared unofficially for the Institute of Informatics
  and Telecommunications of NCSR Demokritos, in November 2005 (13 pages, 3
  figures)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This review paper presents analytical information regarding the transfer of
TCP data flows on paths towards interconnected wireless systems, with emphasis
on 3G cellular networks. The focus is on protocol modifications in face of
problems arising from terminal mobility and wireless transmission. The
objective of this paper is not to present an exhaustive review of the
literature, but to filter out the causes of poor TCP performance in such
systems and give a rationalized view of measures that can be taken against
them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4961</identifier>
 <datestamp>2009-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4961</id><created>2009-03-29</created><updated>2009-07-12</updated><authors><author><keyname>Chen</keyname><forenames>Yunji</forenames></author><author><keyname>Chen</keyname><forenames>Tianshi</forenames></author><author><keyname>Hu</keyname><forenames>Weiwu</forenames></author></authors><title>Global Clock, Physical Time Order and Pending Period Analysis in
  Multiprocessor Systems</title><categories>cs.DC</categories><comments>22 pages, 4 figures</comments><acm-class>F.1.2; C.1.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In multiprocessor systems, various problems are treated with Lamport's
logical clock and the resultant logical time orders between operations.
However, one often needs to face the high complexities caused by the lack of
logical time order information in practice. In this paper, we utilize the
\emph{global clock} to infuse the so-called \emph{pending period} to each
operation in a multiprocessor system, where the pending period is a time
interval that contains the performed time of the operation. Further, we define
the \emph{physical time order} for any two operations with disjoint pending
periods. The physical time order is obeyed by any real execution in
multiprocessor systems due to that it is part of the truly happened operation
orders restricted by global clock, and it is then proven to be independent and
consistent with traditional logical time orders. The above novel yet
fundamental concepts enables new effective approaches for analyzing
multiprocessor systems, which are named \emph{pending period analysis} as a
whole. As a consequence of pending period analysis, many important problems of
multiprocessor systems can be tackled effectively. As a significant application
example, complete memory consistency verification, which was known as an
NP-hard problem, can be solved with the complexity of $O(n^2)$ (where $n$ is
the number of operations). Moreover, the two event ordering problems, which
were proven to be Co-NP-Hard and NP-hard respectively, can both be solved with
the time complexity of O(n) if restricted by pending period information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.5024</identifier>
 <datestamp>2009-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.5024</id><created>2009-03-29</created><authors><author><keyname>Bhardwaj</keyname><forenames>Er. Akshay</forenames></author></authors><title>Analysis Paralysis: when to stop?</title><categories>cs.SE</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Analysis of a system constitutes the most important aspect of the systems
development life cycle.But it is also the most confusing and time consuming of
all the stages.The critical question always remains: How much and till when to
analyse? Ed Yourdon has called this phenomenon as Analysis Paralysis. In this
paper, I suggest a model which can actually help in arriving at a satisfactory
answer to this problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.5045</identifier>
 <datestamp>2009-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.5045</id><created>2009-03-30</created><authors><author><keyname>Sparavigna</keyname><forenames>Amelia</forenames></author></authors><title>Digital Restoration of Ancient Papyri</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Image processing can be used for digital restoration of ancient papyri, that
is, for a restoration performed on their digital images. The digital
manipulation allows reducing the background signals and enhancing the
readability of texts. In the case of very old and damaged documents, this is
fundamental for identification of the patterns of letters. Some examples of
restoration, obtained with an image processing which uses edges detection and
Fourier filtering, are shown. One of them concerns 7Q5 fragment of the Dead Sea
Scrolls.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.5049</identifier>
 <datestamp>2010-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.5049</id><created>2009-03-29</created><updated>2010-02-16</updated><authors><author><keyname>Dejter</keyname><forenames>Italo J.</forenames></author></authors><title>SQS-graphs of extended 1-perfect codes</title><categories>math.CO cs.IT math.IT</categories><comments>20 pages</comments><msc-class>05C90,94B25</msc-class><journal-ref>Congressus Numerantium, {\bf 193}(2008), 175--194, {\bf
  MR}2487725; 94B05, (05C90)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A binary extended 1-perfect code $\mathcal C$ folds over its kernel via the
Steiner quadruple systems associated with its codewords. The resulting folding,
proposed as a graph invariant for $\mathcal C$, distinguishes among the 361
nonlinear codes $\mathcal C$ of kernel dimension $\kappa$ with $9\geq\kappa\geq
5$ obtained via Solov'eva-Phelps doubling construction. Each of the 361
resulting graphs has most of its nonloop edges expressible in terms of the
lexicographically disjoint quarters of the products of the components of two of
the ten 1-perfect partitions of length 8 classified by Phelps, and loops mostly
expressible in terms of the lines of the Fano plane.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.5054</identifier>
 <datestamp>2009-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.5054</id><created>2009-03-29</created><authors><author><keyname>Thomsen</keyname><forenames>Knud</forenames></author></authors><title>Flow of Activity in the Ouroboros Model</title><categories>cs.AI</categories><comments>6 pages, 4 figures</comments><acm-class>B.2.0; C.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Ouroboros Model is a new conceptual proposal for an algorithmic structure
for efficient data processing in living beings as well as for artificial
agents. Its central feature is a general repetitive loop where one iteration
cycle sets the stage for the next. Sensory input activates data structures
(schemata) with similar constituents encountered before, thus expectations are
kindled. This corresponds to the highlighting of empty slots in the selected
schema, and these expectations are compared with the actually encountered
input. Depending on the outcome of this consumption analysis different next
steps like search for further data or a reset, i.e. a new attempt employing
another schema, are triggered. Monitoring of the whole process, and in
particular of the flow of activation directed by the consumption analysis,
yields valuable feedback for the optimum allocation of attention and resources
including the selective establishment of useful new memory entries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.5066</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.5066</id><created>2009-03-30</created><updated>2010-07-27</updated><authors><author><keyname>Vaswani</keyname><forenames>Namrata</forenames></author><author><keyname>Lu</keyname><forenames>Wei</forenames></author></authors><title>Modified-CS: Modifying Compressive Sensing for Problems with Partially
  Known Support</title><categories>cs.IT math.IT math.ST stat.ME stat.TH</categories><comments>To Appear in IEEE Trans. Signal Processing, September 2010, shorter
  version presented at ISIT 2009</comments><journal-ref>IEEE Trans. Signal Processing, pages 4595--4607, vol. 58 (9),
  September 2010</journal-ref><doi>10.1109/TSP.2010.2051150</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of reconstructing a sparse signal from a limited number
of its linear projections when a part of its support is known, although the
known part may contain some errors. The ``known&quot; part of the support, denoted
T, may be available from prior knowledge. Alternatively, in a problem of
recursively reconstructing time sequences of sparse spatial signals, one may
use the support estimate from the previous time instant as the ``known&quot; part.
The idea of our proposed solution (modified-CS) is to solve a convex relaxation
of the following problem: find the signal that satisfies the data constraint
and is sparsest outside of T. We obtain sufficient conditions for exact
reconstruction using modified-CS. These are much weaker than those needed for
compressive sensing (CS) when the sizes of the unknown part of the support and
of errors in the known part are small compared to the support size. An
important extension called Regularized Modified-CS (RegModCS) is developed
which also uses prior signal estimate knowledge. Simulation comparisons for
both sparse and compressible signals are shown.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.5074</identifier>
 <datestamp>2009-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.5074</id><created>2009-03-29</created><authors><author><keyname>Vaswani</keyname><forenames>Namrata</forenames></author></authors><title>Analyzing Least Squares and Kalman Filtered Compressed Sensing</title><categories>cs.IT math.IT</categories><comments>Proc. IEEE Intl. Conf. Acous. Speech Sig. Proc. (ICASSP), 2009</comments><journal-ref>Proc. IEEE Intl. Conf. Acous. Speech Sig. Proc. (ICASSP), 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent work, we studied the problem of causally reconstructing time
sequences of spatially sparse signals, with unknown and slow time-varying
sparsity patterns, from a limited number of linear &quot;incoherent&quot; measurements.
We proposed a solution called Kalman Filtered Compressed Sensing (KF-CS). The
key idea is to run a reduced order KF only for the current signal's estimated
nonzero coefficients' set, while performing CS on the Kalman filtering error to
estimate new additions, if any, to the set. KF may be replaced by Least Squares
(LS) estimation and we call the resulting algorithm LS-CS. In this work, (a) we
bound the error in performing CS on the LS error and (b) we obtain the
conditions under which the KF-CS (or LS-CS) estimate converges to that of a
genie-aided KF (or LS), i.e. the KF (or LS) which knows the true nonzero sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.5108</identifier>
 <datestamp>2010-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.5108</id><created>2009-03-29</created><updated>2010-03-13</updated><authors><author><keyname>Zhang</keyname><forenames>Jun</forenames></author><author><keyname>Kountouris</keyname><forenames>Marios</forenames></author><author><keyname>Andrews</keyname><forenames>Jeffrey G.</forenames></author><author><keyname>Heath</keyname><forenames>Robert W.</forenames><suffix>Jr</suffix></author></authors><title>Multi-mode Transmission for the MIMO Broadcast Channel with Imperfect
  Channel State Information</title><categories>cs.IT math.IT</categories><comments>25 pages, 10 figures, submitted to IEEE Trans. Commun., March 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes an adaptive multi-mode transmission strategy to improve
the spectral efficiency achieved in the multiple-input multiple-output (MIMO)
broadcast channel with delayed and quantized channel state information. The
adaptive strategy adjusts the number of active users, denoted as the
transmission mode, to balance transmit array gain, spatial division
multiplexing gain, and residual inter-user interference. Accurate closed-form
approximations are derived for the achievable rates for different modes, which
help identify the active mode that maximizes the average sum throughput for
given feedback delay and channel quantization error. The proposed transmission
strategy is combined with round-robin scheduling, and is shown to provide
throughput gain over single-user MIMO at moderate signal-to-noise ratio. It
only requires feedback of instantaneous channel state information from a small
number of users. With a feedback load constraint, the proposed algorithm
provides performance close to that achieved by opportunistic scheduling with
instantaneous feedback from a large number of users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.5122</identifier>
 <datestamp>2009-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.5122</id><created>2009-03-30</created><authors><author><keyname>Huang</keyname><forenames>Xiaofei</forenames></author></authors><title>A Constructive Generalization of Nash Equilibrium for Better Payoffs and
  Stability</title><categories>cs.GT cs.MA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a society of completely selfish individuals where everybody is only
interested in maximizing his own payoff, does any equilibrium exist for the
society? John Nash proved more than 50 years ago that an equilibrium always
exists such that nobody would benefit from unilaterally changing his strategy.
Nash Equilibrium is a central concept in game theory, which offers a
mathematical foundation for social science and economy. However, it is
important from both a theoretical and a practical point of view to understand
game playing where individuals are less selfish. This paper offers a
constructive generalization of Nash equilibrium to study n-person games where
the selfishness of individuals can be defined at any level, including the
extreme of complete selfishness. The generalization is constructive since it
offers a protocol for individuals in a society to reach an equilibrium. Most
importantly, this paper presents experimental results and theoretical
investigation to show that the individuals in a society can reduce their
selfishness level together to reach a new equilibrium where they can have
better payoffs and the society is more stable at the same time. This study
suggests that, for the benefit of everyone in a society (including the
financial market), the pursuit of maximal payoff by each individual should be
controlled at some level either by voluntary good citizenship or by imposed
regulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.5154</identifier>
 <datestamp>2009-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.5154</id><created>2009-03-30</created><authors><author><keyname>Duncan</keyname><forenames>Ross</forenames></author></authors><title>Generalised Proof-Nets for Compact Categories with Biproducts</title><categories>math.CT cs.LO</categories><comments>77 pages, many figures. To appear in CUP volume, &quot;Semantics of
  Quantum Computation&quot;</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Just as conventional functional programs may be understood as proofs in an
intuitionistic logic, so quantum processes can also be viewed as proofs in a
suitable logic. We describe such a logic, the logic of compact closed
categories and biproducts, presented both as a sequent calculus and as a system
of proof-nets. This logic captures much of the necessary structure needed to
represent quantum processes under classical control, while remaining agnostic
to the fine details. We demonstrate how to represent quantum processes as
proof-nets, and show that the dynamic behaviour of a quantum process is
captured by the cut-elimination procedure for the logic. We show that the cut
elimination procedure is strongly normalising: that is, that every legal way of
simplifying a proof-net leads to the same, unique, normal form. Finally, taking
some initial set of operations as non-logical axioms, we show that that the
resulting category of proof-nets is a representation of the free compact closed
category with biproducts generated by those operations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.5168</identifier>
 <datestamp>2009-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.5168</id><created>2009-03-30</created><authors><author><keyname>Pandey</keyname><forenames>Rakesh</forenames></author><author><keyname>Dhami</keyname><forenames>H. S.</forenames></author></authors><title>Mathematical Model for Transformation of Sentences from Active Voice to
  Passive Voice</title><categories>cs.CL</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Formal work in linguistics has both produced and used important mathematical
tools. Motivated by a survey of models for context and word meaning, syntactic
categories, phrase structure rules and trees, an attempt is being made in the
present paper to present a mathematical model for structuring of sentences from
active voice to passive voice, which is is the form of a transitive verb whose
grammatical subject serves as the patient, receiving the action of the verb.
  For this purpose we have parsed all sentences of a corpus and have generated
Boolean groups for each of them. It has been observed that when we take
constituents of the sentences as subgroups, the sequences of phrases form
permutation roups. Application of isomorphism property yields permutation
mapping between the important subgroups. It has resulted in a model for
transformation of sentences from active voice to passive voice. A computer
program has been written to enable the software developers to evolve grammar
software for sentence transformations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.5172</identifier>
 <datestamp>2009-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.5172</id><created>2009-03-30</created><authors><author><keyname>Giraud</keyname><forenames>Olivier</forenames></author><author><keyname>Georgeot</keyname><forenames>Bertrand</forenames></author><author><keyname>Shepelyansky</keyname><forenames>Dima L.</forenames></author></authors><title>Delocalization transition for the Google matrix</title><categories>cs.IR cond-mat.dis-nn nlin.AO</categories><comments>4 pages, 5 figures. Research done at
  http://www.quantware.ups-tlse.fr/</comments><journal-ref>Phys. Rev. E 80, 026107 (2009)</journal-ref><doi>10.1103/PhysRevE.80.026107</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the localization properties of eigenvectors of the Google matrix,
generated both from the World Wide Web and from the Albert-Barabasi model of
networks. We establish the emergence of a delocalization phase for the PageRank
vector when network parameters are changed. In the phase of localized PageRank,
a delocalization takes place in the complex plane of eigenvalues of the matrix,
leading to delocalized relaxation modes. We argue that the efficiency of
information retrieval by Google-type search is strongly affected in the phase
of delocalized PageRank.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.5177</identifier>
 <datestamp>2009-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.5177</id><created>2009-03-30</created><authors><author><keyname>Dolev</keyname><forenames>Shlomi</forenames></author><author><keyname>Kopeetsky</keyname><forenames>Marina</forenames></author><author><keyname>Shamir</keyname><forenames>Adi</forenames></author></authors><title>RFID Authentication, Efficient Proactive Information Security within
  Computational Security</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider repeated communication sessions between a RFID Tag (e.g., Radio
Frequency Identification, RFID Tag) and a RFID Verifier. A proactive
information theoretic security scheme is proposed. The scheme is based on the
assumption that the information exchanged during at least one of every n
successive communication sessions is not exposed to an adversary. The Tag and
the Verifier maintain a vector of n entries that is repeatedly refreshed by
pairwise xoring entries, with a new vector of n entries that is randomly chosen
by the Tag and sent to the Verifier as a part of each communication session.
The general case in which the adversary does not listen in k &gt; 0 sessions among
any n successive communication sessions is also considered. A lower bound of
n(k+1) for the number of random numbers used during any n successive
communication sessions is proven. In other words, we prove that an algorithm
must use at least n(k+1) new random numbers during any n successive
communication sessions. Then a randomized scheme that uses only O(n log n) new
random numbers is presented. A computational secure scheme which is based on
the information theoretic secure scheme is used to ensure that even in the case
that the adversary listens in all the information exchanges, the communication
between the Tag and the Verifier is secure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.5188</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.5188</id><created>2009-03-30</created><authors><author><keyname>Yukalov</keyname><forenames>V. I.</forenames></author><author><keyname>Sornette</keyname><forenames>D.</forenames></author></authors><title>Quantum decision theory as quantum theory of measurement</title><categories>quant-ph cs.AI</categories><comments>Latex file, 11 pages</comments><journal-ref>Phys. Lett. A 372 (2008) 6867-6871</journal-ref><doi>10.1016/j.physleta.2008.09.053</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a general theory of quantum information processing devices, that
can be applied to human decision makers, to atomic multimode registers, or to
molecular high-spin registers. Our quantum decision theory is a generalization
of the quantum theory of measurement, endowed with an action ring, a prospect
lattice and a probability operator measure. The algebra of probability
operators plays the role of the algebra of local observables. Because of the
composite nature of prospects and of the entangling properties of the
probability operators, quantum interference terms appear, which make actions
noncommutative and the prospect probabilities non-additive. The theory provides
the basis for explaining a variety of paradoxes typical of the application of
classical utility theory to real human decision making. The principal advantage
of our approach is that it is formulated as a self-consistent mathematical
theory, which allows us to explain not just one effect but actually all known
paradoxes in human decision making. Being general, the approach can serve as a
tool for characterizing quantum information processing by means of atomic,
molecular, and condensed-matter systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.5201</identifier>
 <datestamp>2009-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.5201</id><created>2009-03-30</created><authors><author><keyname>Mozer</keyname><forenames>Pierre</forenames><affiliation>TIMC</affiliation></author><author><keyname>Baumann</keyname><forenames>Michael</forenames><affiliation>TIMC</affiliation></author><author><keyname>Chevreau</keyname><forenames>Gregoire</forenames><affiliation>TIMC</affiliation></author><author><keyname>Moreau-Gaudry</keyname><forenames>Alexandre</forenames><affiliation>TIMC, CHU-Grenoble CIC</affiliation></author><author><keyname>Bart</keyname><forenames>Stephane</forenames><affiliation>TIMC</affiliation></author><author><keyname>Renard-Penna</keyname><forenames>Raphaele</forenames><affiliation>TIMC</affiliation></author><author><keyname>Comperat</keyname><forenames>Eva</forenames><affiliation>TIMC</affiliation></author><author><keyname>Conort</keyname><forenames>Pierre</forenames><affiliation>TIMC</affiliation></author><author><keyname>Bitker</keyname><forenames>Marc-Olivier</forenames><affiliation>TIMC</affiliation></author><author><keyname>Chartier-Kastler</keyname><forenames>Emmanuel</forenames><affiliation>TIMC</affiliation></author><author><keyname>Richard</keyname><forenames>Francois</forenames><affiliation>TIMC</affiliation></author><author><keyname>Troccaz</keyname><forenames>Jocelyne</forenames><affiliation>TIMC</affiliation></author></authors><title>Mapping of transrectal ultrasonographic prostate biopsies: quality
  control and learning curve assessment by image processing</title><categories>physics.med-ph cs.OH</categories><proxy>ccsd hal-00371744</proxy><journal-ref>Journal of ultrasound in medicine : official journal of the
  American Institute of Ultrasound in Medicine 28, 4 (2009) 455-60</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Objective: Mapping of transrectal ultrasonographic (TRUS) prostate biopsies
is of fundamental importance for either diagnostic purposes or the management
and treatment of prostate cancer, but the localization of the cores seems
inaccurate. Our objective was to evaluate the capacities of an operator to plan
transrectal prostate biopsies under 2-dimensional TRUS guidance using a
registration algorithm to represent the localization of biopsies in a reference
3-dimensional ultrasonographic volume.
  Methods: Thirty-two patients underwent a series of 12 prostate biopsies under
local anesthesia performed by 1 operator using a TRUS probe combined with
specific third-party software to verify that the biopsies were indeed conducted
within the planned targets. RESULTS: The operator reached 71% of the planned
targets with substantial variability that depended on their localization (100%
success rate for targets in the middle and right parasagittal parts versus 53%
for targets in the left lateral base). Feedback from this system after each
series of biopsies enabled the operator to significantly improve his dexterity
over the course of time (first 16 patients: median score, 7 of 10 and cumulated
median biopsy length in targets of 90 mm; last 16 patients, median score, 9 of
10 and a cumulated median length of 121 mm; P = .046).
  Conclusions: In addition to being a useful tool to improve the distribution
of prostate biopsies, the potential of this system is above all the preparation
of a detailed &quot;map&quot; of each patient showing biopsy zones without substantial
changes in routine clinical practices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.5208</identifier>
 <datestamp>2009-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.5208</id><created>2009-03-30</created><authors><author><keyname>Ghaffari</keyname><forenames>M.</forenames></author><author><keyname>Hariri</keyname><forenames>B.</forenames></author><author><keyname>Shirmohammadi</keyname><forenames>S.</forenames></author></authors><title>On the Necessary and Sufficient Condition of Greedy Routing Supporting
  Geographical Data Networks</title><categories>cs.CG cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Large scale decentralized communication systems have introduced the new trend
towards online routing where routing decisions are performed based on a limited
and localized knowledge of the network. Geometrical greedy routing has been
among the simplest and most common online routing schemes. A perfect
geometrical routing scheme is expected to deliver each packet to the point in
the network that is closest to the packet destination. However greedy routing
fails to guarantee such delivery as the greedy forwarding decision sometimes
leads the packets to localized minimums. This article investigates the
necessary and sufficient properties of the greedy supporting graphs that
provide the guaranteed delivery of packets when acting as a routing substrate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.5221</identifier>
 <datestamp>2009-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.5221</id><created>2009-03-30</created><authors><author><keyname>Chen</keyname><forenames>Changbo</forenames><affiliation>ORCCA, University of Western Ontario</affiliation></author><author><keyname>Maza</keyname><forenames>Marc Moreno</forenames><affiliation>ORCCA, University of Western Ontario</affiliation></author><author><keyname>Xia</keyname><forenames>Bican</forenames><affiliation>School of Mathematical Sciences, Peking University, Beijing, China</affiliation></author><author><keyname>Yang</keyname><forenames>Lu</forenames><affiliation>Shanghai Key Laboratory of Trustworthy Computing, East China Normal University, Shanghai, China</affiliation></author></authors><title>Computing Cylindrical Algebraic Decomposition via Triangular
  Decomposition</title><categories>cs.SC</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cylindrical algebraic decomposition is one of the most important tools for
computing with semi-algebraic sets, while triangular decomposition is among the
most important approaches for manipulating constructible sets. In this paper,
for an arbitrary finite set $F \subset {\R}[y_1, ..., y_n]$ we apply
comprehensive triangular decomposition in order to obtain an $F$-invariant
cylindrical decomposition of the $n$-dimensional complex space, from which we
extract an $F$-invariant cylindrical algebraic decomposition of the
$n$-dimensional real space. We report on an implementation of this new approach
for constructing cylindrical algebraic decompositions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.5254</identifier>
 <datestamp>2009-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.5254</id><created>2009-03-30</created><authors><author><keyname>Archambault</keyname><forenames>Eric</forenames></author><author><keyname>Campbell</keyname><forenames>David</forenames></author><author><keyname>Gingras</keyname><forenames>Yves</forenames></author><author><keyname>Lariviere</keyname><forenames>Vincent</forenames></author></authors><title>Comparing Bibliometric Statistics Obtained from the Web of Science and
  Scopus</title><categories>cs.IR cs.DL</categories><comments>9 pages, 6 figures</comments><doi>10.1002/asi.21062</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For more than 40 years, the Institute for Scientific Information (ISI, now
part of Thomson Reuters) produced the only available bibliographic databases
from which bibliometricians could compile large-scale bibliometric indicators.
ISI's citation indexes, now regrouped under the Web of Science (WoS), were the
major sources of bibliometric data until 2004, when Scopus was launched by the
publisher Reed Elsevier. For those who perform bibliometric analyses and
comparisons of countries or institutions, the existence of these two major
databases raises the important question of the comparability and stability of
statistics obtained from different data sources. This paper uses macro-level
bibliometric indicators to compare results obtained from the WoS and Scopus. It
shows that the correlations between the measures obtained with both databases
for the number of papers and the number of citations received by countries, as
well as for their ranks, are extremely high (R2 &gt; .99). There is also a very
high correlation when countries' papers are broken down by field. The paper
thus provides evidence that indicators of scientific production and citations
at the country level are stable and largely independent of the database.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.5259</identifier>
 <datestamp>2010-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.5259</id><created>2009-03-30</created><updated>2010-07-27</updated><authors><author><keyname>Strassburger</keyname><forenames>Lutz</forenames></author><author><keyname>Guglielmi</keyname><forenames>Alessio</forenames></author></authors><title>A System of Interaction and Structure IV: The Exponentials and
  Decomposition</title><categories>cs.LO</categories><acm-class>F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a system, called NEL, which is the mixed commutative/non-commutative
linear logic BV augmented with linear logic's exponentials. Equivalently, NEL
is MELL augmented with the non-commutative self-dual connective seq. In this
paper, we show a basic compositionality property of NEL, which we call
decomposition. This result leads to a cut-elimination theorem, which is proved
in the next paper of this series. To control the induction measure for the
theorem, we rely on a novel technique that extracts from NEL proofs the
structure of exponentials, into what we call !-?-Flow-Graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.5267</identifier>
 <datestamp>2009-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.5267</id><created>2009-03-30</created><authors><author><keyname>Pavone</keyname><forenames>Marco</forenames></author><author><keyname>Arsie</keyname><forenames>Alessandro</forenames></author><author><keyname>Frazzoli</keyname><forenames>Emilio</forenames></author><author><keyname>Bullo</keyname><forenames>Francesco</forenames></author></authors><title>Equitable Partitioning Policies for Mobile Robotic Networks</title><categories>cs.RO</categories><comments>Paper submitted to IEEE Transactions on Automatic Control in December
  2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The most widely applied strategy for workload sharing is to equalize the
workload assigned to each resource. In mobile multi-agent systems, this
principle directly leads to equitable partitioning policies in which (i) the
workspace is divided into subregions of equal measure, (ii) there is a
bijective correspondence between agents and subregions, and (iii) each agent is
responsible for service requests originating within its own subregion. In this
paper, we design provably correct, spatially-distributed and adaptive policies
that allow a team of agents to achieve a convex and equitable partition of a
convex workspace, where each subregion has the same measure. We also consider
the issue of achieving convex and equitable partitions where subregions have
shapes similar to those of regular polygons. Our approach is related to the
classic Lloyd algorithm, and exploits the unique features of power diagrams. We
discuss possible applications to routing of vehicles in stochastic and dynamic
environments. Simulation results are presented and discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.5282</identifier>
 <datestamp>2009-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.5282</id><created>2009-03-30</created><authors><author><keyname>Li</keyname><forenames>Husheng</forenames></author></authors><title>Multi-agent Q-Learning of Channel Selection in Multi-user Cognitive
  Radio Systems: A Two by Two Case</title><categories>cs.IT math.IT</categories><comments>submitted to 2009 IEEE International Conference on Systems, Man, and
  Cybernetics; the results of general n by m case will be published soon</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Resource allocation is an important issue in cognitive radio systems. It can
be done by carrying out negotiation among secondary users. However, significant
overhead may be incurred by the negotiation since the negotiation needs to be
done frequently due to the rapid change of primary users' activity. In this
paper, a channel selection scheme without negotiation is considered for
multi-user and multi-channel cognitive radio systems. To avoid collision
incurred by non-coordination, each user secondary learns how to select channels
according to its experience. Multi-agent reinforcement leaning (MARL) is
applied in the framework of Q-learning by considering the opponent secondary
users as a part of the environment. The dynamics of the Q-learning are
illustrated using Metrick-Polak plot. A rigorous proof of the convergence of
Q-learning is provided via the similarity between the Q-learning and
Robinson-Monro algorithm, as well as the analysis of convergence of the
corresponding ordinary differential equation (via Lyapunov function). Examples
are illustrated and the performance of learning is evaluated by numerical
simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.5289</identifier>
 <datestamp>2009-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.5289</id><created>2009-03-30</created><authors><author><keyname>Rialle</keyname><forenames>Vincent</forenames><affiliation>TIMC, DMIS</affiliation></author><author><keyname>Vila</keyname><forenames>Annick</forenames><affiliation>TIMC</affiliation></author><author><keyname>Besnard</keyname><forenames>Yves</forenames><affiliation>TIMC</affiliation></author></authors><title>Heterogeneous knowledge representation using a finite automaton and
  first order logic: a case study in electromyography</title><categories>cs.AI</categories><proxy>ccsd hal-00371948</proxy><journal-ref>Artificial Intelligence in Medicine 3, 2 (1991) 65-74</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a certain number of situations, human cognitive functioning is difficult
to represent with classical artificial intelligence structures. Such a
difficulty arises in the polyneuropathy diagnosis which is based on the spatial
distribution, along the nerve fibres, of lesions, together with the synthesis
of several partial diagnoses. Faced with this problem while building up an
expert system (NEUROP), we developed a heterogeneous knowledge representation
associating a finite automaton with first order logic. A number of knowledge
representation problems raised by the electromyography test features are
examined in this study and the expert system architecture allowing such a
knowledge modeling are laid out.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.5316</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.5316</id><created>2009-03-30</created><authors><author><keyname>Muchnik</keyname><forenames>An. A.</forenames></author><author><keyname>Pritykin</keyname><forenames>Yu. L.</forenames></author><author><keyname>Semenov</keyname><forenames>A. L.</forenames></author></authors><title>Sequences close to periodic</title><categories>cs.DM cs.FL</categories><comments>In Russian. 76 pages, 6 figures</comments><doi>10.1070/RM2009v064n05ABEH004641</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper is a survey of notions and results related to classical and new
generalizations of the notion of a periodic sequence. The topics related to
almost periodicity in combinatorics on words, symbolic dynamics, expressibility
in logical theories, algorithmic computability, Kolmogorov complexity, number
theory, are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.5328</identifier>
 <datestamp>2009-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.5328</id><created>2009-03-30</created><authors><author><keyname>Abernethy</keyname><forenames>Jacob</forenames></author><author><keyname>Agarwal</keyname><forenames>Alekh</forenames></author><author><keyname>Bartlett</keyname><forenames>Peter L.</forenames></author><author><keyname>Rakhlin</keyname><forenames>Alexander</forenames></author></authors><title>A Stochastic View of Optimal Regret through Minimax Duality</title><categories>cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the regret of optimal strategies for online convex optimization
games. Using von Neumann's minimax theorem, we show that the optimal regret in
this adversarial setting is closely related to the behavior of the empirical
minimization algorithm in a stochastic process setting: it is equal to the
maximum, over joint distributions of the adversary's action sequence, of the
difference between a sum of minimal expected losses and the minimal empirical
loss. We show that the optimal regret has a natural geometric interpretation,
since it can be viewed as the gap in Jensen's inequality for a concave
functional--the minimizer over the player's actions of expected loss--defined
on a set of probability distributions. We use this expression to obtain upper
and lower bounds on the regret of an optimal strategy for a variety of online
learning problems. Our method provides upper bounds without the need to
construct a learning algorithm; the lower bounds provide explicit optimal
strategies for the adversary.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.5341</identifier>
 <datestamp>2009-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.5341</id><created>2009-03-30</created><updated>2009-12-13</updated><authors><author><keyname>Sarnowski</keyname><forenames>Wojciech</forenames></author><author><keyname>Szajowski</keyname><forenames>Krzysztof</forenames></author></authors><title>Unspecified distribution in single disorder problem</title><categories>math.PR cs.IT math.IT math.ST stat.TH</categories><comments>23 pages</comments><report-no>Rap. Inst. Mat. Copm. Sci. PWr. 2009,, Ser. PRE ; no 8</report-no><msc-class>60G40; 60K99; 90D60</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We register a stochastic sequence affected by one disorder. Monitoring of the
sequence is made in the circumstances when not full information about
distributions before and after the change is available. The initial problem of
disorder detection is transformed to optimal stopping of observed sequence.
Formula for optimal decision functions is derived.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.5342</identifier>
 <datestamp>2009-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.5342</id><created>2009-03-30</created><authors><author><keyname>Hutter</keyname><forenames>Marcus</forenames></author></authors><title>Exact Non-Parametric Bayesian Inference on Infinite Trees</title><categories>math.PR cs.LG math.ST stat.TH</categories><comments>32 LaTeX pages, 9 figures, 5 theorems, 1 algorithm</comments><msc-class>62G07; 60B10; 68W99</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given i.i.d. data from an unknown distribution, we consider the problem of
predicting future items. An adaptive way to estimate the probability density is
to recursively subdivide the domain to an appropriate data-dependent
granularity. A Bayesian would assign a data-independent prior probability to
&quot;subdivide&quot;, which leads to a prior over infinite(ly many) trees. We derive an
exact, fast, and simple inference algorithm for such a prior, for the data
evidence, the predictive distribution, the effective model dimension, moments,
and other quantities. We prove asymptotic convergence and consistency results,
and illustrate the behavior of our model on some prototypical functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.5346</identifier>
 <datestamp>2009-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.5346</id><created>2009-03-30</created><authors><author><keyname>Kot</keyname><forenames>Lucja</forenames></author><author><keyname>Koch</keyname><forenames>Christoph</forenames></author></authors><title>Cooperative Update Exchange in the Youtopia System</title><categories>cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Youtopia is a platform for collaborative management and integration of
relational data. At the heart of Youtopia is an update exchange abstraction:
changes to the data propagate through the system to satisfy user-specified
mappings. We present a novel change propagation model that combines a
deterministic chase with human intervention. The process is fundamentally
cooperative and gives users significant control over how mappings are repaired.
An additional advantage of our model is that mapping cycles can be permitted
without compromising correctness.
  We investigate potential harmful interference between updates in our model;
we introduce two appropriate notions of serializability that avoid such
interference if enforced. The first is very general and related to classical
final-state serializability; the second is more restrictive but highly
practical and related to conflict-serializability. We present an algorithm to
enforce the latter notion. Our algorithm is an optimistic one, and as such may
sometimes require updates to be aborted. We develop techniques for reducing the
number of aborts and we test these experimentally.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.5372</identifier>
 <datestamp>2010-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.5372</id><created>2009-03-31</created><updated>2010-02-26</updated><authors><author><keyname>Huang</keyname><forenames>Dong</forenames></author><author><keyname>Shen</keyname><forenames>Zhiqi</forenames></author><author><keyname>Miao</keyname><forenames>Chunyan</forenames></author><author><keyname>Miao</keyname><forenames>Yuan</forenames></author><author><keyname>Leung</keyname><forenames>Cyril</forenames></author></authors><title>A game theory approach for self-coexistence analysis among IEEE 802.22
  networks</title><categories>cs.IT cs.GT math.IT</categories><comments>This paper has been withdrawn</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn by the author due to some errors
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.5392</identifier>
 <datestamp>2016-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.5392</id><created>2009-03-31</created><updated>2016-02-24</updated><authors><author><keyname>Bruscoli</keyname><forenames>Paola</forenames></author><author><keyname>Guglielmi</keyname><forenames>Alessio</forenames></author><author><keyname>Gundersen</keyname><forenames>Tom</forenames></author><author><keyname>Parigot</keyname><forenames>Michel</forenames></author></authors><title>Quasipolynomial Normalisation in Deep Inference via Atomic Flows and
  Threshold Formulae</title><categories>cs.CC cs.LO</categories><comments>Accepted by Logical Methods in Computer Science</comments><acm-class>F.4.1; F.2.2</acm-class><doi>10.1007/978-3-642-17511-4_9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Je\v{r}\'abek showed that cuts in classical propositional logic proofs in
deep inference can be eliminated in quasipolynomial time. The proof is indirect
and it relies on a result of Atserias, Galesi and Pudl\'ak about monotone
sequent calculus and a correspondence between that system and cut-free
deep-inference proofs. In this paper we give a direct proof of Je\v{r}\'abek's
result: we give a quasipolynomial-time cut-elimination procedure for classical
propositional logic in deep inference. The main new ingredient is the use of a
computational trace of deep-inference proofs called atomic flows, which are
both very simple (they only trace structural rules and forget logical rules)
and strong enough to faithfully represent the cut-elimination procedure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.5399</identifier>
 <datestamp>2009-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.5399</id><created>2009-03-31</created><authors><author><keyname>Grunwald</keyname><forenames>Peter</forenames></author><author><keyname>Harremoes</keyname><forenames>Peter</forenames></author></authors><title>Regret and Jeffreys Integrals in Exp. Families</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of whether minimax redundancy, minimax regret and Jeffreys
integrals are finite or infinite are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.5426</identifier>
 <datestamp>2009-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.5426</id><created>2009-03-31</created><authors><author><keyname>Harremoes</keyname><forenames>Peter</forenames></author></authors><title>Testing Goodness-of-Fit via Rate Distortion</title><categories>cs.IT math.IT math.ST stat.TH</categories><msc-class>94A34; 62G10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A framework is developed using techniques from rate distortion theory in
statistical testing. The idea is first to do optimal compression according to a
certain distortion function and then use information divergence from the
compressed empirical distribution to the compressed null hypothesis as
statistic. Only very special cases have been studied in more detail, but they
indicate that the approach can be used under very general conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.5505</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.5505</id><created>2009-03-31</created><updated>2013-02-13</updated><authors><author><keyname>David</keyname><forenames>Ren&#xe9;</forenames><affiliation>LAMA</affiliation></author><author><keyname>Grygiel</keyname><forenames>Katarzyna</forenames><affiliation>LAMA</affiliation></author><author><keyname>Kozic</keyname><forenames>Jakub</forenames><affiliation>LAMA</affiliation></author><author><keyname>Raffalli</keyname><forenames>Christophe</forenames><affiliation>LAMA</affiliation></author><author><keyname>Theyssier</keyname><forenames>Guillaume</forenames><affiliation>LAMA</affiliation></author><author><keyname>Zaionc</keyname><forenames>Marek</forenames></author></authors><title>Asymptotically almost all \lambda-terms are strongly normalizing</title><categories>math.LO cs.DM cs.LO math.CO</categories><proxy>Logical Methods In Computer Science</proxy><acm-class>G.2.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 9, Issue 1 (February
  15, 2013) lmcs:848</journal-ref><doi>10.2168/LMCS-9(1:02)2013</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present quantitative analysis of various (syntactic and behavioral)
properties of random \lambda-terms. Our main results are that asymptotically
all the terms are strongly normalizing and that any fixed closed term almost
never appears in a random term. Surprisingly, in combinatory logic (the
translation of the \lambda-calculus into combinators), the result is exactly
opposite. We show that almost all terms are not strongly normalizing. This is
due to the fact that any fixed combinator almost always appears in a random
combinator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0016</identifier>
 <datestamp>2009-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0016</id><created>2009-03-31</created><authors><author><keyname>Hogg</keyname><forenames>Tad</forenames></author><author><keyname>Lerman</keyname><forenames>Kristina</forenames></author></authors><title>Stochastic Models of User-Contributory Web Sites</title><categories>cs.CY cs.IR</categories><journal-ref>Proc. of the 3rd Intl Conf on Weblogs and Social Media
  (ICWSM2009), pp. 50-57 (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a general stochastic processes-based approach to modeling
user-contributory web sites, where users create, rate and share content. These
models describe aggregate measures of activity and how they arise from simple
models of individual users. This approach provides a tractable method to
understand user activity on the web site and how this activity depends on web
site design choices, especially the choice of what information about other
users' behaviors is shown to each user. We illustrate this modeling approach in
the context of user-created content on the news rating site Digg.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0019</identifier>
 <datestamp>2009-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0019</id><created>2009-03-31</created><authors><author><keyname>Argelich</keyname><forenames>Josep</forenames></author><author><keyname>Lynce</keyname><forenames>Ines</forenames></author><author><keyname>Marques-Silva</keyname><forenames>Joao</forenames></author></authors><title>On Solving Boolean Multilevel Optimization Problems</title><categories>cs.LO cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many combinatorial optimization problems entail a number of hierarchically
dependent optimization problems. An often used solution is to associate a
suitably large cost with each individual optimization problem, such that the
solution of the resulting aggregated optimization problem solves the original
set of hierarchically dependent optimization problems. This paper starts by
studying the package upgradeability problem in software distributions.
Straightforward solutions based on Maximum Satisfiability (MaxSAT) and
pseudo-Boolean (PB) optimization are shown to be ineffective, and unlikely to
scale for large problem instances. Afterwards, the package upgradeability
problem is related to multilevel optimization. The paper then develops new
algorithms for Boolean Multilevel Optimization (BMO) and highlights a large
number of potential applications. The experimental results indicate that the
proposed algorithms for BMO allow solving optimization problems that existing
MaxSAT and PB solvers would otherwise be unable to solve.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0027</identifier>
 <datestamp>2009-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0027</id><created>2009-04-01</created><authors><author><keyname>Rodriguez</keyname><forenames>Marko A.</forenames></author><author><keyname>Watkins</keyname><forenames>Jennifer H.</forenames></author></authors><title>Faith in the Algorithm, Part 2: Computational Eudaemonics</title><categories>cs.CY cs.AI</categories><report-no>LA-UR-09-02095</report-no><acm-class>K.4.1; H.1.2; H.3</acm-class><journal-ref>Proceedings of the International Conference on Knowledge-Based and
  Intelligent Information &amp; Engineering Systems, Invited Session: Innovations
  in Intelligent Systems, Lecture Notes in Artificial Intelligence,
  Springer-Verlag, October 2009.</journal-ref><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Eudaemonics is the study of the nature, causes, and conditions of human
well-being. According to the ethical theory of eudaemonia, reaping satisfaction
and fulfillment from life is not only a desirable end, but a moral
responsibility. However, in modern society, many individuals struggle to meet
this responsibility. Computational mechanisms could better enable individuals
to achieve eudaemonia by yielding practical real-world systems that embody
algorithms that promote human flourishing. This article presents eudaemonic
systems as the evolutionary goal of the present day recommender system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0029</identifier>
 <datestamp>2009-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0029</id><created>2009-03-31</created><authors><author><keyname>Hamadi</keyname><forenames>Youssef</forenames></author><author><keyname>Jabbour</keyname><forenames>Said</forenames></author><author><keyname>Sais</keyname><forenames>Lakhdar</forenames></author></authors><title>Learning for Dynamic subsumption</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper a new dynamic subsumption technique for Boolean CNF formulae is
proposed. It exploits simple and sufficient conditions to detect during
conflict analysis, clauses from the original formula that can be reduced by
subsumption. During the learnt clause derivation, and at each step of the
resolution process, we simply check for backward subsumption between the
current resolvent and clauses from the original formula and encoded in the
implication graph. Our approach give rise to a strong and dynamic
simplification technique that exploits learning to eliminate literals from the
original clauses. Experimental results show that the integration of our dynamic
subsumption approach within the state-of-the-art SAT solvers Minisat and Rsat
achieves interesting improvements particularly on crafted instances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0034</identifier>
 <datestamp>2009-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0034</id><created>2009-03-31</created><authors><author><keyname>Benevides</keyname><forenames>Mario R. F.</forenames></author><author><keyname>Schechter</keyname><forenames>L. Menasch&#xe9;</forenames></author></authors><title>CCS-Based Dynamic Logics for Communicating Concurrent Programs</title><categories>cs.LO</categories><comments>28 pages</comments><acm-class>F.4.1; F.3.1; F.1.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work presents three increasingly expressive Dynamic Logics in which the
programs are CCS processes (sCCS-PDL, CCS-PDL and XCCS-PDL). Their goal is to
reason about properties of concurrent programs and systems described using CCS.
In order to accomplish that, CCS's operators and constructions are added to a
basic modal logic in order to create dynamic logics that are suitable for the
description and verification of properties of communicating, concurrent and
non-deterministic programs and systems, in a similar way as PDL is used for the
sequential case. We provide complete axiomatizations for the three logics.
Unlike Peleg's Concurrent PDL with Channels, our logics have a simple Kripke
semantics, complete axiomatizations and the finite model property.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0037</identifier>
 <datestamp>2009-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0037</id><created>2009-03-31</created><authors><author><keyname>Host-Madsen</keyname><forenames>Anders</forenames></author></authors><title>Deterministic Capacity of MIMO Relay Networks</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The deterministic capacity of a relay network is the capacity of a network
when relays are restricted to transmitting \emph{reliable} information, that
is, (asymptotically) deterministic function of the source message. In this
paper it is shown that the deterministic capacity of a number of MIMO relay
networks can be found in the low power regime where $\SNR\to0$. This is
accomplished through deriving single letter upper bounds and finding the limit
of these as $\SNR\to0$. The advantage of this technique is that it overcomes
the difficulty of finding optimum distributions for mutual information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0052</identifier>
 <datestamp>2009-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0052</id><created>2009-04-01</created><authors><author><keyname>Pashkevich</keyname><forenames>Anatoly</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Chablat</keyname><forenames>Damien</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Wenger</keyname><forenames>Philippe</forenames><affiliation>IRCCyN</affiliation></author></authors><title>Stiffness Analysis of Overconstrained Parallel Manipulators</title><categories>cs.RO</categories><proxy>ccsd hal-00372638</proxy><journal-ref>Journal of Mechanism and Machine Theory 44, 5 (2009) 966-982</journal-ref><doi>10.1016/j.mechmachtheory.2008.05.017</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper presents a new stiffness modeling method for overconstrained
parallel manipulators with flexible links and compliant actuating joints. It is
based on a multidimensional lumped-parameter model that replaces the link
flexibility by localized 6-dof virtual springs that describe both
translational/rotational compliance and the coupling between them. In contrast
to other works, the method involves a FEA-based link stiffness evaluation and
employs a new solution strategy of the kinetostatic equations for the unloaded
manipulator configuration, which allows computing the stiffness matrix for the
overconstrained architectures, including singular manipulator postures. The
advantages of the developed technique are confirmed by application examples,
which deal with comparative stiffness analysis of two translational parallel
manipulators of 3-PUU and 3-PRPaR architectures. Accuracy of the proposed
approach was evaluated for a case study, which focuses on stiffness analysis of
Orthoglide parallel manipulator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0058</identifier>
 <datestamp>2009-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0058</id><created>2009-04-01</created><authors><author><keyname>Chablat</keyname><forenames>Damien</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Staicu</keyname><forenames>Stefan</forenames></author></authors><title>Kinematics of A 3-PRP planar parallel robot</title><categories>cs.RO</categories><proxy>ccsd hal-00372634</proxy><journal-ref>UPB Scientific Bulletin, Series D: Mechanical Engineering 71, 1
  (2009) 3-16</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recursive modelling for the kinematics of a 3-PRP planar parallel robot is
presented in this paper. Three planar chains connecting to the moving platform
of the manipulator are located in a vertical plane. Knowing the motion of the
platform, we develop the inverse kinematics and determine the positions,
velocities and accelerations of the robot. Several matrix equations offer
iterative expressions and graphs for the displacements, velocities and
accelerations of three prismatic actuators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0071</identifier>
 <datestamp>2014-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0071</id><created>2009-04-01</created><updated>2010-06-07</updated><authors><author><keyname>Ilik</keyname><forenames>Danko</forenames><affiliation>PPS, INRIA Paris - Rocquencourt, LIX</affiliation></author><author><keyname>Lee</keyname><forenames>Gyesik</forenames><affiliation>ROSAEC</affiliation></author><author><keyname>Herbelin</keyname><forenames>Hugo</forenames><affiliation>PPS, INRIA Paris - Rocquencourt</affiliation></author></authors><title>Kripke Models for Classical Logic</title><categories>math.LO cs.LO</categories><proxy>ccsd</proxy><journal-ref>Annals of Pure and Applied Logic 161(11), 2010</journal-ref><doi>10.1016/j.apal.2010.04.007</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a notion of Kripke model for classical logic for which we
constructively prove soundness and cut-free completeness. We discuss the
novelty of the notion and its potential applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0087</identifier>
 <datestamp>2010-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0087</id><created>2009-04-01</created><updated>2009-09-16</updated><authors><author><keyname>Kohring</keyname><forenames>G. A.</forenames></author></authors><title>Complex Dependencies in Large Software Systems</title><categories>nlin.AO cs.SE physics.soc-ph</categories><comments>24 pages, 5 figures. Revised paper in line with 2nd round of
  reviewer's comments</comments><report-no>LR-09- 357</report-no><journal-ref>Advances in Complex Systems, Vol. 12, No. 6, pp. 565-581, (2009).</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Two large, open source software systems are analyzed from the vantage point
of complex adaptive systems theory. For both systems, the full dependency
graphs are constructed and their properties are shown to be consistent with the
assumption of stochastic growth. In particular, the afferent links are
distributed according to Zipf's law for both systems. Using the Small-World
criterion for directed graphs, it is shown that contrary to claims in the
literature, these software systems do not possess Small-World properties.
Furthermore, it is argued that the Small-World property is not of any
particular advantage in a standard layered architecture. Finally, it is
suggested that the eigenvector centrality can play an important role in
deciding which open source software packages to use in mission critical
applications. This comes about because knowing the absolute number of afferent
links alone is insufficient to decide how important a package is to the system
as a whole, instead the importance of the linking package plays a major role as
well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0109</identifier>
 <datestamp>2009-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0109</id><created>2009-04-01</created><authors><author><keyname>Huber</keyname><forenames>Michael</forenames></author></authors><title>Authentication and Secrecy Codes for Equiprobable Source Probability
  Distributions</title><categories>cs.CR cs.DM</categories><comments>5 pages (double-column); to appear in Proc. IEEE International
  Symposium on Information Theory (ISIT 2009, Seoul, South Korea)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give new combinatorial constructions for codes providing authentication
and secrecy for equiprobable source probability distributions. In particular,
we construct an infinite class of optimal authentication codes which are
multiple-fold secure against spoofing and simultaneously achieve perfect
secrecy. Several further new optimal codes satisfying these properties will
also be constructed and presented in general tables. Almost all of these appear
to be the first authentication codes with these properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0125</identifier>
 <datestamp>2009-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0125</id><created>2009-04-01</created><authors><author><keyname>Cohen</keyname><forenames>Jonathan Asher</forenames></author></authors><title>Coherence for rewriting 2-theories</title><categories>math.CT cs.LO</categories><comments>PhD thesis, 88 pages</comments><msc-class>18D99; 18C10; 68Q42; 20F05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  General coherence theorems are constructed that yield explicit presentations
of categorical and algebraic objects. The categorical structures involved are
finitary discrete Lawvere 2-theories, though they are approached within the
language of term rewriting theory. Two general coherence theorems are obtained.
The first applies to terminating and confluent rewriting 2-theories. This
result is exploited to construct systematic presentations for the higher
Thompson groups and the Higman-Thompson groups. The presentations are
categorically interesting as they arise from higher-arity analogues of the
Stasheff/Mac Lane coherence axioms, which involve phenomena not present in the
classical binary axioms. The second general coherence theorem holds for
2-theories that are not necessarily confluent or terminating and is used to
construct a new proof of coherence for iterated monoidal categories, which
arise as categorical models of iterated loop spaces and fail to be confluent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0145</identifier>
 <datestamp>2009-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0145</id><created>2009-04-01</created><authors><author><keyname>Ur-Rehman</keyname><forenames>Raza</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Caro</keyname><forenames>St&#xe9;phane</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Chablat</keyname><forenames>Damien</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Wenger</keyname><forenames>Philippe</forenames><affiliation>IRCCyN</affiliation></author></authors><title>Kinematic and Dynamic Analysis of the 2-DOF Spherical Wrist of
  Orthoglide 5-axis</title><categories>cs.RO physics.class-ph</categories><proxy>ccsd hal-00372622</proxy><journal-ref>Troisi\`eme Congr\`es International. Conception et Mod\'elisation
  des Syst\`emes M\'ecaniques, Hammamet : Tunisie (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with the kinematics and dynamics of a two degree of freedom
spherical manipulator, the wrist of Orthoglide 5-axis. The latter is a parallel
kinematics machine composed of two manipulators: i) the Orthoglide 3-axis; a
three-dof translational parallel manipulator that belongs to the family of
Delta robots, and ii) the Agile eye; a two-dof parallel spherical wrist. The
geometric and inertial parameters used in the model are determined by means of
a CAD software. The performance of the spherical wrist is emphasized by means
of several test trajectories. The effects of machining and/or cutting forces
and the length of the cutting tool on the dynamic performance of the wrist are
also analyzed. Finally, a preliminary selection of the motors is proposed from
the velocities and torques required by the actuators to carry out the test
trajectories.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0166</identifier>
 <datestamp>2009-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0166</id><created>2009-04-01</created><authors><author><keyname>Lorca</keyname><forenames>Alejandro</forenames></author><author><keyname>Vazquez-Poletti</keyname><forenames>Jose Luis</forenames></author><author><keyname>Huedo</keyname><forenames>Eduardo</forenames></author><author><keyname>Llorente</keyname><forenames>Ignacio M.</forenames></author></authors><title>Grid porting of Bhabha scattering code through a master-worker scheme</title><categories>hep-ph cs.DC</categories><comments>12 pages, 9 figures (8 in color). To appear in proceedings of
  IBERGRID 2009 - 3rd Iberian Grid Infrastructure Conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A program calculating Bhabha scattering at high energy colliders is
considered for porting to the EGEE Grid infrastructure. The program code, which
is a result of the aITALC project, is ported by using a master-worker operating
scheme. The job submission, execution and monitoring are implemented using the
GridWay metascheduler. The unattended execution of jobs turned out to be
complete and rather efficient, even when pre-knowledge of the grid is absent.
While the batch of jobs remains organized at the user's side, the actual
computation was carried out within the phenogrid virtual organization. The
scientific results support the use of the small angle Bhabha scattering for the
luminosity measurements of the International Linear Collider project.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0214</identifier>
 <datestamp>2010-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0214</id><created>2009-04-01</created><updated>2010-03-31</updated><authors><author><keyname>Bytev</keyname><forenames>Vladimir V.</forenames><affiliation>Hamburg U., Inst. Theor. Phys. II &amp; Dubna, JINR</affiliation></author><author><keyname>Kalmykov</keyname><forenames>Mikhail Yu.</forenames><affiliation>Hamburg U., Inst. Theor. Phys. II &amp; Dubna, JINR</affiliation></author><author><keyname>Kniehl</keyname><forenames>Bernd A.</forenames><affiliation>Hamburg U., Inst. Theor. Phys. II</affiliation></author></authors><title>Differential reduction of generalized hypergeometric functions from
  Feynman diagrams: One-variable case</title><categories>hep-th cs.SC hep-ph math-ph math.CA math.MP</categories><comments>46 pages in LaTeX; 2 eps figures; v3. Section 3 improved; Section 4
  changed; new References added; version published in Nucl. Phys. B;</comments><report-no>DESY-10-027</report-no><journal-ref>Nucl.Phys.B836:129-170, 2010</journal-ref><doi>10.1016/j.nuclphysb.2010.03.025</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The differential-reduction algorithm, which allows one to express generalized
hypergeometric functions with parameters of arbitrary values in terms of such
functions with parameters whose values differ from the original ones by
integers, is discussed in the context of evaluating Feynman diagrams. Where
this is possible, we compare our results with those obtained using standard
techniques. It is shown that the criterion of reducibility of multiloop Feynman
integrals can be reformulated in terms of the criterion of reducibility of
hypergeometric functions. The relation between the numbers of master integrals
obtained by differential reduction and integration by parts is discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0217</identifier>
 <datestamp>2009-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0217</id><created>2009-04-01</created><authors><author><keyname>M&#xe9;rindol</keyname><forenames>Pascal</forenames></author><author><keyname>Pansiot</keyname><forenames>Jean-Jacques</forenames></author><author><keyname>Cateloin</keyname><forenames>St&#xe9;phane</forenames></author></authors><title>The mdt algorithm</title><categories>cs.NI</categories><comments>Long version from a talk at GIS 2009</comments><report-no>LSIIT Research Report RR-PM01-09</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Link state routing protocols such as OSPF or IS-IS currently use only best
paths to forward IP packets throughout a domain. The optimality of sub-paths
ensures consistency of hop by hop forwarding although paths, calculated using
Dijkstra algorithm, are recursively composed. According to the link metric, the
diversity of existing paths can be underestimated using only best paths. Hence,
it reduces potential benefits of multipath applications such as load balancing
and fast rerouting. In this paper, we propose a low time complexity multipath
computation algorithm able to calculate at least two paths with a different
first hop between all pairs of nodes in the network if such next hops exist.
Using real and generated topologies, we evaluate and compare the complexity of
our proposition with several techniques. Simulation results suggest that the
path diversity achieved with our proposition is approximatively the same that
the one obtained using consecutive Dijsktra computations, but with a lower time
complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0226</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0226</id><created>2009-04-01</created><updated>2010-03-30</updated><authors><author><keyname>Wu</keyname><forenames>Peng</forenames></author><author><keyname>Jindal</keyname><forenames>Nihar</forenames></author></authors><title>Coding Versus ARQ in Fading Channels: How reliable should the PHY be?</title><categories>cs.IT math.IT</categories><comments>27 pages, 10 figures. submitted to IEEE Trans. Commun., Mar. 2010</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This paper studies the tradeoff between channel coding and ARQ (automatic
repeat request) in Rayleigh block-fading channels. A heavily coded system
corresponds to a low transmission rate with few ARQ re-transmissions, whereas
lighter coding corresponds to a higher transmitted rate but more
re-transmissions. The optimum error probability, where optimum refers to the
maximization of the average successful throughput, is derived and is shown to
be a decreasing function of the average signal-to-noise ratio and of the
channel diversity order. A general conclusion of the work is that the optimum
error probability is quite large (e.g., 10% or larger) for reasonable channel
parameters, and that operating at a very small error probability can lead to a
significantly reduced throughput. This conclusion holds even when a number of
practical ARQ considerations, such as delay constraints and acknowledgement
feedback errors, are taken into account.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0228</identifier>
 <datestamp>2009-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0228</id><created>2009-04-01</created><authors><author><keyname>Grabarnik</keyname><forenames>Genady</forenames><affiliation>IBM TJ Watson Research</affiliation></author><author><keyname>Kershenbaum</keyname><forenames>Aaron</forenames><affiliation>IBM TJ Watson Research</affiliation></author></authors><title>Safe Reasoning Over Ontologies</title><categories>cs.AI cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As ontologies proliferate and automatic reasoners become more powerful, the
problem of protecting sensitive information becomes more serious. In
particular, as facts can be inferred from other facts, it becomes increasingly
likely that information included in an ontology, while not itself deemed
sensitive, may be able to be used to infer other sensitive information.
  We first consider the problem of testing an ontology for safeness defined as
its not being able to be used to derive any sensitive facts using a given
collection of inference rules. We then consider the problem of optimizing an
ontology based on the criterion of making as much useful information as
possible available without revealing any sensitive facts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0262</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0262</id><created>2009-04-01</created><updated>2009-04-24</updated><authors><author><keyname>Abel</keyname><forenames>Zachary</forenames></author><author><keyname>Ballinger</keyname><forenames>Brad</forenames></author><author><keyname>Bose</keyname><forenames>Prosenjit</forenames></author><author><keyname>Collette</keyname><forenames>S&#xe9;bastien</forenames></author><author><keyname>Dujmovi&#x107;</keyname><forenames>Vida</forenames></author><author><keyname>Hurtado</keyname><forenames>Ferran</forenames></author><author><keyname>Kominers</keyname><forenames>Scott D.</forenames></author><author><keyname>Langerman</keyname><forenames>Stefan</forenames></author><author><keyname>P&#xf3;r</keyname><forenames>Attila</forenames></author><author><keyname>Wood</keyname><forenames>David R.</forenames></author></authors><title>Every Large Point Set contains Many Collinear Points or an Empty
  Pentagon</title><categories>math.CO cs.CG</categories><msc-class>52C10, 05D10</msc-class><journal-ref>Graphs and Combinatorics 27(1), (2011), 47-60</journal-ref><doi>10.1007/s00373-010-0957-2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove the following generalised empty pentagon theorem: for every integer
$\ell \geq 2$, every sufficiently large set of points in the plane contains
$\ell$ collinear points or an empty pentagon. As an application, we settle the
next open case of the &quot;big line or big clique&quot; conjecture of K\'ara, P\'or, and
Wood [\emph{Discrete Comput. Geom.} 34(3):497--506, 2005].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0274</identifier>
 <datestamp>2012-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0274</id><created>2009-04-01</created><authors><author><keyname>Cadambe</keyname><forenames>Viveck R.</forenames></author><author><keyname>Jafar</keyname><forenames>Syed A.</forenames></author><author><keyname>Wang</keyname><forenames>Chenwei</forenames></author></authors><title>Interference Alignment with Asymmetric Complex Signaling - Settling the
  Host-Madsen-Nosratinia Conjecture</title><categories>cs.IT math.IT</categories><journal-ref>IEEE Transactions on Information Theory, Sep. 2010, Vol. 56,
  Issue: 9, Pages: 4552-4565</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It has been conjectured by Host-Madsen and Nosratinia that complex Gaussian
interference channels with constant channel coefficients have only one
degree-of-freedom regardless of the number of users. While several examples are
known of constant channels that achieve more than 1 degree of freedom, these
special cases only span a subset of measure zero. In other words, for almost
all channel coefficient values, it is not known if more than 1
degree-of-freedom is achievable. In this paper, we settle the
Host-Madsen-Nosratinia conjecture in the negative. We show that at least 1.2
degrees-of-freedom are achievable for all values of complex channel
coefficients except for a subset of measure zero. For the class of linear
beamforming and interference alignment schemes considered in this paper, it is
also shown that 1.2 is the maximum number of degrees of freedom achievable on
the complex Gaussian 3 user interference channel with constant channel
coefficients, for almost all values of channel coefficients. To establish the
achievability of 1.2 degrees of freedom we introduce the novel idea of
asymmetric complex signaling - i.e., the inputs are chosen to be complex but
not circularly symmetric. It is shown that unlike Gaussian point-to-point,
multiple-access and broadcast channels where circularly symmetric complex
Gaussian inputs are optimal, for interference channels optimal inputs are in
general asymmetric. With asymmetric complex signaling, we also show that the 2
user complex Gaussian X channel with constant channel coefficients achieves the
outer bound of 4/3 degrees-of-freedom, i.e., the assumption of
time-variations/frequency-selectivity used in prior work to establish the same
result, is not needed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0292</identifier>
 <datestamp>2009-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0292</id><created>2009-04-01</created><authors><author><keyname>Ba</keyname><forenames>Khanh Do</forenames></author><author><keyname>Nguyen</keyname><forenames>Huy L</forenames></author><author><keyname>Nguyen</keyname><forenames>Huy N</forenames></author><author><keyname>Rubinfeld</keyname><forenames>Ronitt</forenames></author></authors><title>Sublinear Time Algorithms for Earth Mover's Distance</title><categories>cs.DS</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of estimating the Earth Mover's Distance (EMD) between
probability distributions when given access only to samples. We give closeness
testers and additive-error estimators over domains in $[0, \Delta]^d$, with
sample complexities independent of domain size - permitting the testability
even of continuous distributions over infinite domains. Instead, our algorithms
depend on other parameters, such as the diameter of the domain space, which may
be significantly smaller. We also prove lower bounds showing the dependencies
on these parameters to be essentially optimal. Additionally, we consider
whether natural classes of distributions exist for which there are algorithms
with better dependence on the dimension, and show that for highly clusterable
data, this is indeed the case. Lastly, we consider a variant of the EMD,
defined over tree metrics instead of the usual L1 metric, and give optimal
algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0293</identifier>
 <datestamp>2012-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0293</id><created>2009-04-01</created><updated>2012-01-07</updated><authors><author><keyname>Agre</keyname><forenames>Gennady</forenames></author><author><keyname>Kormushev</keyname><forenames>Petar</forenames></author><author><keyname>Dilov</keyname><forenames>Ivan</forenames></author></authors><title>INFRAWEBS axiom editor - a graphical ontology-driven tool for creating
  complex logical expressions</title><categories>cs.SE</categories><comments>This preprint has been withdrawn by the author for revision</comments><acm-class>H.5.2</acm-class><journal-ref>International Journal of Information Theories and Applications,
  vol. 13, no. 2, ISSN 1310-0513, pp. 169-178, 2006</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The current INFRAWEBS European research project aims at developing ICT
framework enabling software and service providers to generate and establish
open and extensible development platforms for Web Service applications. One of
the concrete project objectives is developing a full-life-cycle software
toolset for creating and maintaining Semantic Web Services (SWSs) supporting
specific applications based on Web Service Modelling Ontology (WSMO) framework.
According to WSMO, functional and behavioural descriptions of a SWS may be
represented by means of complex logical expressions (axioms). The paper
describes a specialized user-friendly tool for constructing and editing such
axioms - INFRAWEBS Axiom Editor. After discussing the main design principles of
the Editor, its functional architecture is briefly presented. The tool is
implemented in Eclipse Graphical Environment Framework and Eclipse Rich Client
Platform.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0300</identifier>
 <datestamp>2009-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0300</id><created>2009-04-02</created><authors><author><keyname>Kormushev</keyname><forenames>Petar</forenames></author></authors><title>Design, development and implementation of a tool for construction of
  declarative functional descriptions of semantic web services based on WSMO
  methodology</title><categories>cs.AI cs.LO</categories><comments>Master's Thesis in Artificial Intelligence, 105 pages, in Bulgarian.
  Submitted to Faculty of Mathematics and Informatics, Sofia University, 2005</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Semantic web services (SWS) are self-contained, self-describing, semantically
marked-up software resources that can be published, discovered, composed and
executed across the Web in a semi-automatic way. They are a key component of
the future Semantic Web, in which networked computer programs become providers
and users of information at the same time. This work focuses on developing a
full-life-cycle software toolset for creating and maintaining Semantic Web
Services (SWSs) based on the Web Service Modelling Ontology (WSMO) framework. A
main part of WSMO-based SWS is service capability - a declarative description
of Web service functionality. A formal syntax and semantics for such a
description is provided by Web Service Modeling Language (WSML), which is based
on different logical formalisms, namely, Description Logics, First-Order Logic
and Logic Programming. A WSML description of a Web service capability is
represented as a set of complex logical expressions (axioms). We develop a
specialized user-friendly tool for constructing and editing WSMO-based SWS
capabilities. Since the users of this tool are not specialists in first-order
logic, a graphical way for constricting and editing axioms is proposed. The
designed process for constructing logical expressions is ontology-driven, which
abstracts away as much as possible from any concrete syntax of logical
language. We propose several mechanisms to guarantees the semantic consistency
of the produced logical expressions. The tool is implemented in Java using
Eclipse for IDE and GEF (Graphical Editing Framework) for visualization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0308</identifier>
 <datestamp>2011-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0308</id><created>2009-04-02</created><updated>2011-06-22</updated><authors><author><keyname>Hayashi</keyname><forenames>Masahito</forenames></author></authors><title>Exponential decreasing rate of leaked information in universal random
  privacy amplification</title><categories>cs.IT cs.CR math.AC math.IT</categories><comments>The organization is a little changed. This version is the same as the
  published version</comments><journal-ref>IEEE TRANSACTIONS ON INFORMATION THEORY, VOL. 57, NO. 6, JUNE
  2011, 3989-4001</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We derive a new upper bound for Eve's information in secret key generation
from a common random number without communication. This bound improves on
Bennett et al(1995)'s bound based on the R\'enyi entropy of order 2 because the
bound obtained here uses the R\'enyi entropy of order $1+s$ for $s \in [0,1]$.
This bound is applied to a wire-tap channel. Then, we derive an exponential
upper bound for Eve's information. Our exponent is compared with
Hayashi(2006)'s exponent. For the additive case, the bound obtained here is
better. The result is applied to secret key agreement by public discussion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0313</identifier>
 <datestamp>2009-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0313</id><created>2009-04-02</created><authors><author><keyname>Kormushev</keyname><forenames>Petar</forenames></author></authors><title>Visual approach for data mining on medical information databases using
  Fastmap algorithm</title><categories>cs.IR cs.DB</categories><comments>Master's Thesis in Bio- and Medical Informatics, 76 pages, in
  Bulgarian. Submitted to Faculty of Mathematics and Informatics, Sofia
  University, 2006</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The rapid development of tools for acquisition and storage of information has
lead to the formation of enormous medical databases. The large quantity of data
definitely surpasses the abilities of humans for efficient usage without
specialized tools for analysis. The situation is described as rich in data, but
poor in information. In order to fill this growing gap, different approaches
from the field of Data Mining are applied. These methods perform analysis of
large sets of observed data in order to find new dependencies or concise
representation of the data, which is more meaningful to humans. One of the
possible approaches for discovery of dependencies is the visual approach, in
which data is processed and visualized in a way suitable for analysis by a
domain expert. This work proposes a visual approach, in which data is processed
and visualized in a way suitable for analysis by a domain expert. We design and
implement a software solution for visualization of multi-dimensional,
classified medical data using the FastMap algorithm for graduate reduction of
dimensions. The implementation of the graphical user interface is described in
detail since it is the most important factor for the ease of use of these tools
by non-professionals in data mining.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0322</identifier>
 <datestamp>2009-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0322</id><created>2009-04-02</created><authors><author><keyname>Fliess</keyname><forenames>Michel</forenames><affiliation>LIX, INRIA Saclay - Ile de France</affiliation></author><author><keyname>Join</keyname><forenames>C&#xe9;dric</forenames><affiliation>INRIA Saclay - Ile de France, CRAN</affiliation></author></authors><title>Model-free control and intelligent PID controllers: towards a possible
  trivialization of nonlinear control?</title><categories>math.OC cs.NA math.CA</categories><comments>This communication is a slightly modified and updated version of a
  paper by the same authors (Commande sans mod\`ele et commande \`a mod\`ele
  restreint, e-STA, vol. 5 (\degree 4), pp. 1-23, 2008. Available at
  http://hal.inria.fr/inria-00288107/en/), which is written in French</comments><proxy>ccsd inria-00372325</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We are introducing a model-free control and a control with a restricted model
for finite-dimensional complex systems. This control design may be viewed as a
contribution to &quot;intelligent&quot; PID controllers, the tuning of which becomes
quite straightforward, even with highly nonlinear and/or time-varying systems.
Our main tool is a newly developed numerical differentiation. Differential
algebra provides the theoretical framework. Our approach is validated by
several numerical experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0352</identifier>
 <datestamp>2009-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0352</id><created>2009-04-02</created><updated>2009-07-12</updated><authors><author><keyname>Dolev</keyname><forenames>Shlomi</forenames></author><author><keyname>Elovici</keyname><forenames>Yuval</forenames></author><author><keyname>Puzis</keyname><forenames>Rami</forenames></author><author><keyname>Zilberman</keyname><forenames>Polina</forenames></author></authors><title>Incremental Deployment of Network Monitors Based on Group Betweenness
  Centrality</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many applications we are required to increase the deployment of a
distributed monitoring system on an evolving network. In this paper we present
a new method for finding candidate locations for additional deployment in the
network. This method is based on the Group Betweenness Centrality (GBC) measure
that is used to estimate the influence of a group of nodes over the information
flow in the network. The new method assists in finding the location of k
additional monitors in the evolving network, such that the portion of
additional traffic covered is at least (1-1/e) of the optimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0417</identifier>
 <datestamp>2009-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0417</id><created>2009-04-02</created><authors><author><keyname>Budinich</keyname><forenames>Marco</forenames></author></authors><title>On Computational Complexity of Clifford Algebra</title><categories>math-ph cs.DM math.MP</categories><comments>13 pages</comments><journal-ref>Journal of Mathematical Physics, 50 #5, 053514, 18 May 2009</journal-ref><doi>10.1063/1.3133042</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  After a brief discussion of the computational complexity of Clifford
algebras, we present a new basis for even Clifford algebra Cl(2m) that
simplifies greatly the actual calculations and, without resorting to the
conventional matrix isomorphism formulation, obtains the same complexity. In
the last part we apply these results to the Clifford algebra formulation of the
NP-complete problem of the maximum clique of a graph introduced in a previous
paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0437</identifier>
 <datestamp>2009-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0437</id><created>2009-04-02</created><authors><author><keyname>Rialle</keyname><forenames>Vincent</forenames><affiliation>TIMC, DMIS</affiliation></author><author><keyname>Ollivet</keyname><forenames>Catherine</forenames><affiliation>FA 93</affiliation></author><author><keyname>Guigui</keyname><forenames>Carole</forenames><affiliation>TIMC</affiliation></author><author><keyname>Herv&#xe9;</keyname><forenames>Christian</forenames><affiliation>LEM</affiliation></author></authors><title>What Do Family Caregivers of Alzheimer's Disease Patients Desire in
  Smart Home Technologies?</title><categories>cs.CY</categories><proxy>ccsd hal-00200917</proxy><journal-ref>Methods of information in medicine 47, 1 (2008) 63-69</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Objectives - The authors' aim was to investigate the representations, wishes,
and fears of family caregivers (FCs) regarding 14 innovative technologies (IT)
for care aiding and burden alleviation, given the severe physical and
psychological stress induced by dementia care, and the very slow uptake of
these technologies in our society. Methods - A cluster sample survey based on a
self-administered questionnaire was carried out on data collected from 270
families of patients with Alzheimer's disease or related disorders, located in
the greater Paris area. Multiple Correspondence Analysis was used in addition
to usual statistical tests to identify homogenous FCs clusters concerning the
appreciation or rejection of the considered technologies. Results - Two
opposite clusters were clearly defined: FCs in favor of a substantial use of
technology, and those rather or totally hostile. Furthermore the distributions
of almost all the answers of appreciations were U shaped. Significant relations
were demonstrated between IT appreciation and FC's family or gender statuses
(e.g., female FCs appreciated more than male FCs a tracking device for quick
recovering of wandering patients: p=0.0025, N=195). Conclusions - The study
provides further evidence of the contrasted perception of technology in
dementia care at home, and suggests the development of public debates based on
rigorous assessment of practices and a strict ethical aim to protect against
misuse.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0471</identifier>
 <datestamp>2009-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0471</id><created>2009-04-02</created><authors><author><keyname>Landsberg</keyname><forenames>J. M.</forenames></author><author><keyname>Morton</keyname><forenames>Jason</forenames></author><author><keyname>Norine</keyname><forenames>Serguei</forenames></author></authors><title>Holographic algorithms without matchgates</title><categories>cs.CC math.CO math.RT</categories><comments>13 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The theory of holographic algorithms, which are polynomial time algorithms
for certain combinatorial counting problems, yields insight into the hierarchy
of complexity classes. In particular, the theory produces algebraic tests for a
problem to be in the class P. In this article we streamline the implementation
of holographic algorithms by eliminating one of the steps in the construction
procedure, and generalize their applicability to new signatures. Instead of
matchgates, which are weighted graph fragments that replace vertices of a
natural bipartite graph G associated to a problem P, our approach uses only
only a natural number-of-edges by number-of-edges matrix associated to G. An
easy-to-compute multiple of its Pfaffian is the number of solutions to the
counting problem. This simplification improves our understanding of the
applicability of holographic algorithms, indicates a more geometric approach to
complexity classes, and facilitates practical implementations. The generalized
applicability arises because our approach allows for new algebraic tests that
are different from the &quot;Grassmann-Plucker identities&quot; used up until now.
Natural problems treatable by these new methods have been previously considered
in a different context, and we present one such example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0477</identifier>
 <datestamp>2009-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0477</id><created>2009-04-02</created><updated>2009-07-27</updated><authors><author><keyname>Zdeborov&#xe1;</keyname><forenames>Lenka</forenames></author><author><keyname>Decelle</keyname><forenames>Aur&#xe9;lien</forenames></author><author><keyname>Chertkov</keyname><forenames>Michael</forenames></author></authors><title>Message Passing for Optimization and Control of Power Grid: Model of
  Distribution System with Redundancy</title><categories>cond-mat.stat-mech cs.CE cs.NI</categories><comments>10 pages</comments><journal-ref>Phys. Rev. E 80, 046112 (2009)</journal-ref><doi>10.1103/PhysRevE.80.046112</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We use a power grid model with $M$ generators and $N$ consumption units to
optimize the grid and its control. Each consumer demand is drawn from a
predefined finite-size-support distribution, thus simulating the instantaneous
load fluctuations. Each generator has a maximum power capability. A generator
is not overloaded if the sum of the loads of consumers connected to a generator
does not exceed its maximum production. In the standard grid each consumer is
connected only to its designated generator, while we consider a more general
organization of the grid allowing each consumer to select one generator
depending on the load from a pre-defined consumer-dependent and sufficiently
small set of generators which can all serve the load. The model grid is
interconnected in a graph with loops, drawn from an ensemble of random
bipartite graphs, while each allowed configuration of loaded links represent a
set of graph covering trees. Losses, the reactive character of the grid and the
transmission-level connections between generators (and many other details
relevant to realistic power grid) are ignored in this proof-of-principles
study. We focus on the asymptotic limit and we show that the interconnects
allow significant expansion of the parameter domains for which the probability
of a generator overload is asymptotically zero. Our construction explores the
formal relation between the problem of grid optimization and the modern theory
of sparse graphical models. We also design heuristic algorithms that achieve
the asymptotically optimal selection of loaded links. We conclude discussing
the ability of this approach to include other effects, such as a more realistic
modeling of the power grid and related optimization and control algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0489</identifier>
 <datestamp>2009-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0489</id><created>2009-04-02</created><authors><author><keyname>Wu</keyname><forenames>Fang</forenames></author><author><keyname>Huberman</keyname><forenames>Bernardo A.</forenames></author></authors><title>Persistence and Success in the Attention Economy</title><categories>cs.CY physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A hallmark of the attention economy is the competition for the attention of
others. Thus people persistently upload content to social media sites, hoping
for the highly unlikely outcome of topping the charts and reaching a wide
audience. And yet, an analysis of the production histories and success dynamics
of 10 million videos from \texttt{YouTube} revealed that the more frequently an
individual uploads content the less likely it is that it will reach a success
threshold. This paradoxical result is further compounded by the fact that the
average quality of submissions does increase with the number of uploads, with
the likelihood of success less than that of playing a lottery.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0494</identifier>
 <datestamp>2009-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0494</id><created>2009-04-02</created><authors><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author><author><keyname>Rauhut</keyname><forenames>Holger</forenames></author></authors><title>Average Case Analysis of Multichannel Sparse Recovery Using Convex
  Relaxation</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Trans. on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider recovery of jointly sparse multichannel signals
from incomplete measurements. Several approaches have been developed to recover
the unknown sparse vectors from the given observations, including thresholding,
simultaneous orthogonal matching pursuit (SOMP), and convex relaxation based on
a mixed matrix norm. Typically, worst-case analysis is carried out in order to
analyze conditions under which the algorithms are able to recover any jointly
sparse set of vectors. However, such an approach is not able to provide
insights into why joint sparse recovery is superior to applying standard sparse
reconstruction methods to each channel individually. Previous work considered
an average case analysis of thresholding and SOMP by imposing a probability
model on the measured signals. In this paper, our main focus is on analysis of
convex relaxation techniques. In particular, we focus on the mixed l_2,1
approach to multichannel recovery. We show that under a very mild condition on
the sparsity and on the dictionary characteristics, measured for example by the
coherence, the probability of recovery failure decays exponentially in the
number of channels. This demonstrates that most of the time, multichannel
sparse recovery is indeed superior to single channel methods. Our probability
bounds are valid and meaningful even for a small number of signals. Using the
tools we develop to analyze the convex relaxation method, we also tighten the
previous bounds for thresholding and SOMP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0525</identifier>
 <datestamp>2009-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0525</id><created>2009-04-03</created><authors><author><keyname>Gao</keyname><forenames>Zhi-Han</forenames></author><author><keyname>Fu</keyname><forenames>Fang-Wei</forenames></author></authors><title>The Minimal Polynomial over F_q of Linear Recurring Sequence over
  F_{q^m}</title><categories>cs.IT cs.CR math.IT</categories><comments>Submitted to the journal Finite Fields and Their Applications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, motivated by the study of vectorized stream cipher systems, the
joint linear complexity and joint minimal polynomial of multisequences have
been investigated. Let S be a linear recurring sequence over finite field
F_{q^m} with minimal polynomial h(x) over F_{q^m}. Since F_{q^m} and F_{q}^m
are isomorphic vector spaces over the finite field F_q, S is identified with an
m-fold multisequence S^{(m)} over the finite field F_q. The joint minimal
polynomial and joint linear complexity of the m-fold multisequence S^{(m)} are
the minimal polynomial and linear complexity over F_q of S respectively. In
this paper, we study the minimal polynomial and linear complexity over F_q of a
linear recurring sequence S over F_{q^m} with minimal polynomial h(x) over
F_{q^m}. If the canonical factorization of h(x) in F_{q^m}[x] is known, we
determine the minimal polynomial and linear complexity over F_q of the linear
recurring sequence S over F_{q^m}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0534</identifier>
 <datestamp>2009-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0534</id><created>2009-04-03</created><authors><author><keyname>Choudhury</keyname><forenames>Pabitra Pal</forenames></author><author><keyname>Sahoo</keyname><forenames>Sudhakar</forenames></author><author><keyname>Nayak</keyname><forenames>Birendra Kumar</forenames></author><author><keyname>Hassan</keyname><forenames>Sk. Sarif</forenames></author></authors><title>Theory of Carry Value Transformation (CVT) and its Application in
  Fractal formation</title><categories>cs.DM</categories><comments>13 pages, 14 figures, it would be interesting those who are really
  interested in fractal experimentally</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper the theory of Carry Value Transformation (CVT) is designed and
developed on a pair of n-bit strings and is used to produce many interesting
patterns. One of them is found to be a self-similar fractal whose dimension is
same as the dimension of the Sierpinski triangle. Different construction
procedures like L-system, Cellular Automata rule, Tilling for this fractal are
obtained which signifies that like other tools CVT can also be used for the
formation of self-similar fractals. It is shown that CVT can be used for the
production of periodic as well as chaotic patterns. Also, the analytical and
algebraic properties of CVT are discussed. The definition of CVT in
two-dimension is slightly modified and its mathematical properties are
highlighted. Finally, the extension of CVT and modified CVT (MCVT) are done in
higher dimensions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0544</identifier>
 <datestamp>2009-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0544</id><created>2009-04-03</created><authors><author><keyname>Park</keyname><forenames>Jaeok</forenames></author><author><keyname>van der Schaar</keyname><forenames>Mihaela</forenames></author></authors><title>Mission-Aware Medium Access Control in Random Access Networks</title><categories>cs.NI cs.GT cs.IT math.IT</categories><comments>28 pages, 8 tables, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study mission-critical networking in wireless communication networks,
where network users are subject to critical events such as emergencies and
crises. If a critical event occurs to a user, the user needs to send necessary
information for help as early as possible. However, most existing medium access
control (MAC) protocols are not adequate to meet the urgent need for
information transmission by users in a critical situation. In this paer, we
propose a novel class of MAC protocols that utilize available past information
as well as current information. Our proposed protocols are mission-aware since
they prescribe different transmission decision rules to users in different
situations. We show that the proposed protocols perform well not only when the
system faces a critical situation but also when there is no critical situation.
By utilizing past information, the proposed protocols coordinate transmissions
by users to achieve high throughput in the normal phase of operation and to let
a user in a critical situation make successful transmissions while it is in the
critical situation. Moreover, the proposed protocols require short memory and
no message exchanges.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0545</identifier>
 <datestamp>2011-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0545</id><created>2009-04-03</created><updated>2011-09-06</updated><authors><author><keyname>Kormushev</keyname><forenames>Petar</forenames></author><author><keyname>Nomoto</keyname><forenames>Kohei</forenames></author><author><keyname>Dong</keyname><forenames>Fangyan</forenames></author><author><keyname>Hirota</keyname><forenames>Kaoru</forenames></author></authors><title>Time Hopping technique for faster reinforcement learning in simulations</title><categories>cs.AI cs.LG cs.RO</categories><comments>This preprint has been withdrawn by the author for revision</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This preprint has been withdrawn by the author for revision
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0546</identifier>
 <datestamp>2009-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0546</id><created>2009-04-03</created><authors><author><keyname>Kormushev</keyname><forenames>Petar</forenames></author><author><keyname>Nomoto</keyname><forenames>Kohei</forenames></author><author><keyname>Dong</keyname><forenames>Fangyan</forenames></author><author><keyname>Hirota</keyname><forenames>Kaoru</forenames></author></authors><title>Eligibility Propagation to Speed up Time Hopping for Reinforcement
  Learning</title><categories>cs.AI cs.LG cs.RO</categories><comments>7 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A mechanism called Eligibility Propagation is proposed to speed up the Time
Hopping technique used for faster Reinforcement Learning in simulations.
Eligibility Propagation provides for Time Hopping similar abilities to what
eligibility traces provide for conventional Reinforcement Learning. It
propagates values from one state to all of its temporal predecessors using a
state transitions graph. Experiments on a simulated biped crawling robot
confirm that Eligibility Propagation accelerates the learning process more than
3 times.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0570</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0570</id><created>2009-04-03</created><updated>2011-07-11</updated><authors><author><keyname>Moser</keyname><forenames>Georg</forenames><affiliation>University of Innsbruck</affiliation></author><author><keyname>Schnabl</keyname><forenames>Andreas</forenames><affiliation>University of Innsbruck</affiliation></author></authors><title>The Derivational Complexity Induced by the Dependency Pair Method</title><categories>cs.LO cs.AI cs.CC cs.PL</categories><proxy>LMCS</proxy><acm-class>F.4.1, F.2.2, D.2.4, D.2.8</acm-class><journal-ref>Logical Methods in Computer Science, Volume 7, Issue 3 (July 13,
  2011) lmcs:805</journal-ref><doi>10.2168/LMCS-7(3:1)2011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the derivational complexity induced by the dependency pair method,
enhanced with standard refinements. We obtain upper bounds on the derivational
complexity induced by the dependency pair method in terms of the derivational
complexity of the base techniques employed. In particular we show that the
derivational complexity induced by the dependency pair method based on some
direct technique, possibly refined by argument filtering, the usable rules
criterion, or dependency graphs, is primitive recursive in the derivational
complexity induced by the direct method. This implies that the derivational
complexity induced by a standard application of the dependency pair method
based on traditional termination orders like KBO, LPO, and MPO is exactly the
same as if those orders were applied as the only termination technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0578</identifier>
 <datestamp>2009-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0578</id><created>2009-04-03</created><updated>2009-04-09</updated><authors><author><keyname>Luk&#xe1;csy</keyname><forenames>Gergely</forenames></author><author><keyname>Szeredi</keyname><forenames>P&#xe9;ter</forenames></author></authors><title>Efficient Description Logic Reasoning in Prolog: The DLog system</title><categories>cs.LO</categories><comments>73 pages, 5 Postscript figures, uses
  {rotating,multirow,fancyvrb,psfrag}.sty To appear in Theory and Practice of
  Logic Programming (TPLP)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes a resolution based Description Logic reasoning system
called DLog. DLog transforms Description Logic axioms into a Prolog program and
uses the standard Prolog execution for efficiently answering instance retrieval
queries. From the Description Logic point of view, DLog is an ABox reasoning
engine for the full SHIQ language. The DLog approach makes it possible to store
the individuals in a database instead of memory, which results in better
scalability and helps using description logic ontologies directly on top of
existing information sources.
  To appear in Theory and Practice of Logic Programming (TPLP).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0583</identifier>
 <datestamp>2009-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0583</id><created>2009-04-03</created><authors><author><keyname>Chandrasekaran</keyname><forenames>Karthekeyan</forenames></author><author><keyname>Dadush</keyname><forenames>Daniel</forenames></author><author><keyname>Vempala</keyname><forenames>Santosh</forenames></author></authors><title>Thin Partitions: Isoperimetric Inequalities and Sampling Algorithms for
  some Nonconvex Families</title><categories>cs.DS math.FA math.PR</categories><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Star-shaped bodies are an important nonconvex generalization of convex bodies
(e.g., linear programming with violations). Here we present an efficient
algorithm for sampling a given star-shaped body. The complexity of the
algorithm grows polynomially in the dimension and inverse polynomially in the
fraction of the volume taken up by the kernel of the star-shaped body. The
analysis is based on a new isoperimetric inequality. Our main technical
contribution is a tool for proving such inequalities when the domain is not
convex. As a consequence, we obtain a polynomial algorithm for computing the
volume of such a set as well. In contrast, linear optimization over star-shaped
sets is NP-hard.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0585</identifier>
 <datestamp>2009-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0585</id><created>2009-04-03</created><authors><author><keyname>Dideban</keyname><forenames>Abbas</forenames><affiliation>GIPSA-lab</affiliation></author><author><keyname>Zareiee</keyname><forenames>M.</forenames><affiliation>GIPSA-lab</affiliation></author><author><keyname>Alla</keyname><forenames>Hassane</forenames><affiliation>GIPSA-lab</affiliation></author></authors><title>Controller synthesis with very simplified linear constraints in PN model</title><categories>cs.IT math.IT</categories><comments>Dependable Control of discrete Systems, Bari : Italie (2009)</comments><proxy>ccsd hal-00371113</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the problem of forbidden states for safe Petri net
modeling discrete event systems. We present an efficient method to construct a
controller. A set of linear constraints allow forbidding the reachability of
specific states. The number of these so-called forbidden states and
consequently the number of constraints are large and lead to a large number of
control places. A systematic method for constructing very simplified controller
is offered. By using a method based on Petri nets partial invariants, maximal
permissive controllers are determined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0586</identifier>
 <datestamp>2009-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0586</id><created>2009-04-03</created><authors><author><keyname>Alla</keyname><forenames>Hassane.</forenames><affiliation>GIPSA-lab</affiliation></author></authors><title>Optimal Supervisory Control Synthesis</title><categories>cs.IT math.IT</categories><comments>Journ\'ee sur l'Instrumentation Industrielle J2I, ORAN : Alg\'erie
  (2009)</comments><proxy>ccsd hal-00369211</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The place invariant method is well known as an elegant way to construct a
Petri net controller. It is possible to use the constraint for preventing
forbidden states. But in general case, the number forbidden states can be very
large giving a great number of control places. In this paper is presented a
systematic method to reduce the size and the number of constraints. This method
is applicable for safe and conservative Petri nets giving a maximally
permissive controller.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0589</identifier>
 <datestamp>2009-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0589</id><created>2009-04-03</created><authors><author><keyname>Le</keyname><forenames>Van Hung</forenames><affiliation>La Trobe University, Australia</affiliation></author><author><keyname>Liu</keyname><forenames>Fei</forenames><affiliation>La Trobe University, Australia</affiliation></author><author><keyname>Tran</keyname><forenames>Dinh Khang</forenames><affiliation>Hanoi University of Technology, Vietnam</affiliation></author></authors><title>Fuzzy Linguistic Logic Programming and its Applications</title><categories>cs.LO</categories><comments>33 pages, to appear in Theory and Practice of Logic Programming
  (TPLP)</comments><acm-class>I.2.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper introduces fuzzy linguistic logic programming, which is a
combination of fuzzy logic programming, introduced by P. Vojtas, and hedge
algebras in order to facilitate the representation and reasoning on human
knowledge expressed in natural languages. In fuzzy linguistic logic
programming, truth values are linguistic ones, e.g., VeryTrue,
VeryProbablyTrue, and LittleFalse, taken from a hedge algebra of a linguistic
truth variable, and linguistic hedges (modifiers) can be used as unary
connectives in formulae. This is motivated by the fact that humans reason
mostly in terms of linguistic terms rather than in terms of numbers, and
linguistic hedges are often used in natural languages to express different
levels of emphasis. The paper presents: (i) the language of fuzzy linguistic
logic programming; (ii) a declarative semantics in terms of Herbrand
interpretations and models; (iii) a procedural semantics which directly
manipulates linguistic terms to compute a lower bound to the truth value of a
query, and proves its soundness; (iv) a fixpoint semantics of logic programs,
and based on it, proves the completeness of the procedural semantics; (v)
several applications of fuzzy linguistic logic programming; and (vi) an idea of
implementing a system to execute fuzzy linguistic logic programs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0643</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0643</id><created>2009-04-03</created><authors><author><keyname>Levin</keyname><forenames>David N.</forenames><affiliation>University of Chicago</affiliation></author></authors><title>Performing Nonlinear Blind Source Separation with Signal Invariants</title><categories>cs.AI cs.LG</categories><comments>8 pages, 3 figures</comments><acm-class>C.3; H.5.5</acm-class><doi>10.1109/TSP.2009.2034916</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a time series of multicomponent measurements x(t), the usual objective
of nonlinear blind source separation (BSS) is to find a &quot;source&quot; time series
s(t), comprised of statistically independent combinations of the measured
components. In this paper, the source time series is required to have a density
function in (s,ds/dt)-space that is equal to the product of density functions
of individual components. This formulation of the BSS problem has a solution
that is unique, up to permutations and component-wise transformations.
Separability is shown to impose constraints on certain locally invariant
(scalar) functions of x, which are derived from local higher-order correlations
of the data's velocity dx/dt. The data are separable if and only if they
satisfy these constraints, and, if the constraints are satisfied, the sources
can be explicitly constructed from the data. The method is illustrated by using
it to separate two speech-like sounds recorded with a single microphone.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0644</identifier>
 <datestamp>2009-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0644</id><created>2009-04-03</created><authors><author><keyname>Chen</keyname><forenames>Xi</forenames></author><author><keyname>Dai</keyname><forenames>Decheng</forenames></author><author><keyname>Du</keyname><forenames>Ye</forenames></author><author><keyname>Teng</keyname><forenames>Shang-Hua</forenames></author></authors><title>Settling the Complexity of Arrow-Debreu Equilibria in Markets with
  Additively Separable Utilities</title><categories>cs.CC cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that the problem of computing an Arrow-Debreu market equilibrium is
PPAD-complete even when all traders use additively separable, piecewise-linear
and concave utility functions. In fact, our proof shows that this
market-equilibrium problem does not have a fully polynomial-time approximation
scheme unless every problem in PPAD is solvable in polynomial time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0648</identifier>
 <datestamp>2009-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0648</id><created>2009-04-03</created><authors><author><keyname>Srivastava</keyname><forenames>Nisheeth</forenames></author></authors><title>Evolvability need not imply learnability</title><categories>cs.LG cs.CC</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  We show that Boolean functions expressible as monotone disjunctive normal
forms are PAC-evolvable under a uniform distribution on the Boolean cube if the
hypothesis size is allowed to remain fixed. We further show that this result is
insufficient to prove the PAC-learnability of monotone Boolean functions,
thereby demonstrating a counter-example to a recent claim to the contrary. We
further discuss scenarios wherein evolvability and learnability will coincide
as well as scenarios under which they differ. The implications of the latter
case on the prospects of learning in complex hypothesis spaces is briefly
examined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0682</identifier>
 <datestamp>2011-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0682</id><created>2009-04-04</created><updated>2011-05-11</updated><authors><author><keyname>Goetz</keyname><forenames>Michaela</forenames></author><author><keyname>Machanavajjhala</keyname><forenames>Ashwin</forenames></author><author><keyname>Wang</keyname><forenames>Guozhang</forenames></author><author><keyname>Xiao</keyname><forenames>Xiaokui</forenames></author><author><keyname>Gehrke</keyname><forenames>Johannes</forenames></author></authors><title>Privacy in Search Logs</title><categories>cs.DB cs.IR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Search engine companies collect the &quot;database of intentions&quot;, the histories
of their users' search queries. These search logs are a gold mine for
researchers. Search engine companies, however, are wary of publishing search
logs in order not to disclose sensitive information. In this paper we analyze
algorithms for publishing frequent keywords, queries and clicks of a search
log. We first show how methods that achieve variants of $k$-anonymity are
vulnerable to active attacks. We then demonstrate that the stronger guarantee
ensured by $\epsilon$-differential privacy unfortunately does not provide any
utility for this problem. We then propose an algorithm ZEALOUS and show how to
set its parameters to achieve $(\epsilon,\delta)$-probabilistic privacy. We
also contrast our analysis of ZEALOUS with an analysis by Korolova et al. [17]
that achieves $(\epsilon',\delta')$-indistinguishability. Our paper concludes
with a large experimental study using real applications where we compare
ZEALOUS and previous work that achieves $k$-anonymity in search log publishing.
Our results show that ZEALOUS yields comparable utility to $k-$anonymity while
at the same time achieving much stronger privacy guarantees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0698</identifier>
 <datestamp>2010-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0698</id><created>2009-04-04</created><updated>2010-01-28</updated><authors><author><keyname>R&#xe9;mon</keyname><forenames>M.</forenames></author></authors><title>About the impossibility to prove P=NP or P!=NP and the pseudo-randomness
  in NP</title><categories>cs.CC</categories><comments>21 pages, 1 figure, 2 tables</comments><report-no>2008/18, Dept Math, Namur University</report-no><acm-class>F.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The relationship between the complexity classes P and NP is an unsolved
question in the field of theoretical computer science. In this paper, we look
at the link between the P - NP question and the &quot;Deterministic&quot; versus &quot;Non
Deterministic&quot; nature of a problem, and more specifically at the temporal
nature of the complexity within the NP class of problems. Let us remind that
the NP class is called the class of &quot;Non Deterministic Polynomial&quot; languages.
Using the meta argument that results in Mathematics should be &quot;time
independent&quot; as they are reproducible, the paper shows that the P!=NP assertion
is impossible to prove in the a-temporal framework of Mathematics. A similar
argument based on randomness shows that the P=NP assertion is also impossible
to prove, so that the P - NP problem turns out to be &quot;unprovable&quot; in
Mathematics. This is not an undecidability theorem, as undecidability points to
the paradoxical nature of a proposition. In fact, this paper highlights the
time dependence of the complexity for any NP problem, linked to some
pseudo-randomness in its heart.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0719</identifier>
 <datestamp>2009-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0719</id><created>2009-04-04</created><authors><author><keyname>Andreyev</keyname><forenames>Sergey</forenames></author></authors><title>Moveable objects and applications, based on them</title><categories>cs.HC</categories><comments>11 pages, 13 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The inner views of all our applications are predetermined by the designers;
only some non-significant variations are allowed with the help of adaptive
interface. In several programs you can find some moveable objects, but it is an
extremely rare thing. However, the design of applications on the basis of
moveable and resizable objects opens an absolutely new way of programming; such
applications are much more effective in users' work, because each user can
adjust an application to his purposes. Programs, using adaptive interface, only
implement the designer's ideas of what would be the best reaction to any of the
users' doings or commands. Applications on moveable elements do not have such
predetermined system of rules; they are fully controlled by the users. This
article describes and demonstrates the new way of applications' design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0721</identifier>
 <datestamp>2011-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0721</id><created>2009-04-04</created><updated>2009-06-01</updated><authors><author><keyname>Nguyen</keyname><forenames>Linh Anh</forenames></author><author><keyname>Sza&#x142;as</keyname><forenames>Andrzej</forenames></author></authors><title>Optimal Tableau Decision Procedures for PDL</title><categories>cs.LO cs.AI cs.CC</categories><journal-ref>Fund. Inform. 104(4), pp. 349-384, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We reformulate Pratt's tableau decision procedure of checking satisfiability
of a set of formulas in PDL. Our formulation is simpler and more direct for
implementation. Extending the method we give the first EXPTIME (optimal)
tableau decision procedure not based on transformation for checking consistency
of an ABox w.r.t. a TBox in PDL (here, PDL is treated as a description logic).
We also prove the new result that the data complexity of the instance checking
problem in PDL is coNP-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0727</identifier>
 <datestamp>2013-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0727</id><created>2009-04-04</created><updated>2013-09-25</updated><authors><author><keyname>Bodlaender</keyname><forenames>Hans L.</forenames></author><author><keyname>Fomin</keyname><forenames>Fedor V.</forenames></author><author><keyname>Lokshtanov</keyname><forenames>Daniel</forenames></author><author><keyname>Penninkx</keyname><forenames>Eelko</forenames></author><author><keyname>Saurabh</keyname><forenames>Saket</forenames></author><author><keyname>Thilikos</keyname><forenames>Dimitrios M.</forenames></author></authors><title>(Meta) Kernelization</title><categories>cs.DM cs.DS</categories><comments>Complete version of the paper of FOCS 2009</comments><msc-class>05C85, 68W05, 68R10,</msc-class><acm-class>F.2.2; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a parameterized problem, every instance I comes with a positive integer k.
The problem is said to admit a polynomial kernel if, in polynomial time, one
can reduce the size of the instance I to a polynomial in k, while preserving
the answer. In this work we give two meta-theorems on kernelzation. The first
theorem says that all problems expressible in Counting Monadic Second Order
Logic and satisfying a coverability property admit a polynomial kernel on
graphs of bounded genus. Our second result is that all problems that have
finite integer index and satisfy a weaker coverability property admit a linear
kernel on graphs of bounded genus. These theorems unify and extend all
previously known kernelization results for planar graph problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0747</identifier>
 <datestamp>2009-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0747</id><created>2009-04-04</created><authors><author><keyname>Anguita</keyname><forenames>Jaime A.</forenames></author><author><keyname>Chertkov</keyname><forenames>Michael</forenames></author><author><keyname>Neifeld</keyname><forenames>Mark A.</forenames></author><author><keyname>Vasic</keyname><forenames>Bane</forenames></author></authors><title>Bethe Free Energy Approach to LDPC Decoding on Memory Channels</title><categories>cs.IT math.IT</categories><comments>9 pages, 8 figures, submitted to Transactions on Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the problem of the joint sequence detection in partial-response
(PR) channels and decoding of low-density parity-check (LDPC) codes. We model
the PR channel and the LDPC code as a combined inference problem. We present
for the first time the derivation of the belief propagation (BP) equations that
allow the simultaneous detection and decoding of a LDPC codeword in a PR
channel. To accomplish this we follow an approach from statistical mechanics,
in which the Bethe free energy is minimized with respect to the beliefs on the
nodes of the PR-LDPC graph. The equations obtained are explicit and are optimal
for decoding LDPC codes on PR channels with polynomial $h(D) = 1 - a D^n$ (a
real, n positive integer) in the sense that they provide the exact inference of
the marginal probabilities on the nodes in a graph free of loops. A simple
algorithmic solution to the set of BP equations is proposed and evaluated using
numerical simulations, yielding bit-error rate performances that surpass those
of turbo equalization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0751</identifier>
 <datestamp>2009-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0751</id><created>2009-04-05</created><updated>2009-08-09</updated><authors><author><keyname>Oohama</keyname><forenames>Yasutada</forenames></author></authors><title>Distributed Source Coding of Correlated Gaussian Remote Sources</title><categories>cs.IT math.IT</categories><comments>20 pages,3 figres</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the distributed source coding system for $L$ correlated Gaussian
observations $Y_i, i=1,2, ..., L$. Let $X_i,i=1,2, ..., L$ be $L$ correlated
Gaussian random variables and $N_i,$ $i=1,2,... L$ be independent additive
Gaussian noises also independent of $X_i, i=1,2,..., L$. We consider the case
where for each $i=1,2,..., L$, $Y_i$ is a noisy observation of $X_i$, that is,
$Y_i=X_i+N_i$. On this coding system the determination problem of the rate
distortion region remains open. In this paper, we derive explicit outer and
inner bounds of the rate distortion region. We further find an explicit
sufficient condition for those two to match. We also study the sum rate part of
the rate distortion region when the correlation has some symmetrical property
and derive a new lower bound of the sum rate part. We derive a sufficient
condition for this lower bound to be tight. The derived sufficient condition
depends only on the correlation property of the sources and their observations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0768</identifier>
 <datestamp>2009-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0768</id><created>2009-04-05</created><updated>2009-05-15</updated><authors><author><keyname>Srinivasan</keyname><forenames>Srimathy</forenames></author><author><keyname>Thangaraj</keyname><forenames>Andrew</forenames></author></authors><title>Codes on Planar Graphs</title><categories>cs.IT math.IT</categories><comments>several improvements in presentation; more figures for illustration</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Codes defined on graphs and their properties have been subjects of intense
recent research. On the practical side, constructions for capacity-approaching
codes are graphical. On the theoretical side, codes on graphs provide several
intriguing problems in the intersection of coding theory and graph theory. In
this paper, we study codes defined by planar Tanner graphs. We derive an upper
bound on minimum distance $d$ of such codes as a function of the code rate $R$
for $R \ge 5/8$. The bound is given by $$d\le \lceil \frac{7-8R}{2(2R-1)}
\rceil + 3\le 7.$$ Among the interesting conclusions of this result are the
following: (1) planar graphs do not support asymptotically good codes, and (2)
finite-length, high-rate codes on graphs with high minimum distance will
necessarily be non-planar.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0771</identifier>
 <datestamp>2009-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0771</id><created>2009-04-05</created><authors><author><keyname>Koukoutsidis</keyname><forenames>Ioannis</forenames></author><author><keyname>Papaioannou</keyname><forenames>Petros</forenames></author><author><keyname>Theologou</keyname><forenames>Michael E.</forenames></author></authors><title>Effect of cell residence time variance on the performance of an advanced
  paging algorithm</title><categories>cs.PF cs.NI</categories><comments>8 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The use of advanced sequential paging algorithms has been suggested as a
means to reduce the signaling cost in future mobile cellular networks. In a
proposed algorithm (Koukoutsidis and Theologou, 2003), the system can use the
additional information of the last interaction cell combined with a mobility
model to predict the short-term location probabilities at the time of an
incoming call arrival. The short-term location probabilities reduce the
uncertainty in mobile user position and thus greatly improve the search. In
this paper, an analytical model is derived that allows for a general
distribution of cell residence times. By considering a Gamma distribution, we
study the effect of the variance of cell residence times and derive useful
results on the performance of the algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0776</identifier>
 <datestamp>2009-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0776</id><created>2009-04-05</created><authors><author><keyname>Robinet</keyname><forenames>Vivien</forenames><affiliation>Leibniz - IMAG, TIMC</affiliation></author><author><keyname>Bisson</keyname><forenames>Gilles</forenames><affiliation>Leibniz - IMAG, TIMC</affiliation></author><author><keyname>Gordon</keyname><forenames>Mirta B.</forenames><affiliation>Leibniz - IMAG, TIMC</affiliation></author><author><keyname>Lemaire</keyname><forenames>Beno&#xee;t</forenames><affiliation>Leibniz - IMAG, TIMC</affiliation></author></authors><title>Induction of High-level Behaviors from Problem-solving Traces using
  Machine Learning Tools</title><categories>stat.ML cs.LG</categories><proxy>ccsd hal-00370553</proxy><journal-ref>IEEE Intelligent Systems 22, 4 (2007) 22</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper applies machine learning techniques to student modeling. It
presents a method for discovering high-level student behaviors from a very
large set of low-level traces corresponding to problem-solving actions in a
learning environment. Basic actions are encoded into sets of domain-dependent
attribute-value patterns called cases. Then a domain-independent hierarchical
clustering identifies what we call general attitudes, yielding automatic
diagnosis expressed in natural language, addressed in principle to teachers.
The method can be applied to individual students or to entire groups, like a
class. We exhibit examples of this system applied to thousands of students'
actions in the domain of algebraic transformations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0785</identifier>
 <datestamp>2009-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0785</id><created>2009-04-05</created><authors><author><keyname>Clegg</keyname><forenames>Richard</forenames></author><author><keyname>Landa</keyname><forenames>Raul</forenames></author><author><keyname>Harder</keyname><forenames>Uli</forenames></author><author><keyname>Rio</keyname><forenames>Miguel</forenames></author></authors><title>Evaluating and Optimising Models of Network Growth</title><categories>cs.NI</categories><comments>Submitted conference paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a statistically sound method for measuring the accuracy
with which a probabilistic model reflects the growth of a network, and a method
for optimising parameters in such a model. The technique is data-driven, and
can be used for the modeling and simulation of any kind of evolving network.
  The overall framework, a Framework for Evolving Topology Analysis (FETA), is
tested on data sets collected from the Internet AS-level topology, social
networking websites and a co-authorship network. Statistical models of the
growth of these networks are produced and tested using a likelihood-based
method. The models are then used to generate artificial topologies with the
same statistical properties as the originals. This work can be used to predict
future growth patterns for a known network, or to generate artificial models of
graph topology evolution for simulation purposes. Particular application
examples include strategic network planning, user profiling in social networks
or infrastructure deployment in managed overlay-based services.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0811</identifier>
 <datestamp>2009-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0811</id><created>2009-04-05</created><authors><author><keyname>Lovett</keyname><forenames>Shachar</forenames></author></authors><title>The density of weights of Generalized Reed--Muller codes</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the density of the weights of Generalized Reed--Muller codes. Let
$RM_p(r,m)$ denote the code of multivariate polynomials over $\F_p$ in $m$
variables of total degree at most $r$. We consider the case of fixed degree
$r$, when we let the number of variables $m$ tend to infinity. We prove that
the set of relative weights of codewords is quite sparse: for every $\alpha \in
[0,1]$ which is not rational of the form $\frac{\ell}{p^k}$, there exists an
interval around $\alpha$ in which no relative weight exists, for any value of
$m$. This line of research is to the best of our knowledge new, and complements
the traditional lines of research, which focus on the weight distribution and
the divisibility properties of the weights.
  Equivalently, we study distributions taking values in a finite field, which
can be approximated by distributions coming from constant degree polynomials,
where we do not bound the number of variables. We give a complete
characterization of all such distributions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0813</identifier>
 <datestamp>2009-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0813</id><created>2009-04-05</created><updated>2009-04-08</updated><authors><author><keyname>Khaleghi</keyname><forenames>Azadeh</forenames></author><author><keyname>Kschischang</keyname><forenames>Frank R.</forenames></author></authors><title>Projective Space Codes for the Injection Metric</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the context of error control in random linear network coding, it is useful
to construct codes that comprise well-separated collections of subspaces of a
vector space over a finite field. In this paper, the metric used is the
so-called &quot;injection distance&quot;, introduced by Silva and Kschischang. A
Gilbert-Varshamov bound for such codes is derived. Using the code-construction
framework of Etzion and Silberstein, new non-constant-dimension codes are
constructed; these codes contain more codewords than comparable codes designed
for the subspace metric.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0814</identifier>
 <datestamp>2009-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0814</id><created>2009-04-05</created><authors><author><keyname>Cortes</keyname><forenames>Corinna</forenames></author><author><keyname>Mohri</keyname><forenames>Mehryar</forenames></author><author><keyname>Pechyony</keyname><forenames>Dmitry</forenames></author><author><keyname>Rastogi</keyname><forenames>Ashish</forenames></author></authors><title>Stability Analysis and Learning Bounds for Transductive Regression
  Algorithms</title><categories>cs.LG</categories><comments>26 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper uses the notion of algorithmic stability to derive novel
generalization bounds for several families of transductive regression
algorithms, both by using convexity and closed-form solutions. Our analysis
helps compare the stability of these algorithms. It also shows that a number of
widely used transductive regression algorithms are in fact unstable. Finally,
it reports the results of experiments with local transductive regression
demonstrating the benefit of our stability bounds for model selection, for one
of the algorithms, in particular for determining the radius of the local
neighborhood used by the algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0821</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0821</id><created>2009-04-05</created><authors><author><keyname>Stojanovic</keyname><forenames>Ivana</forenames></author><author><keyname>Karl</keyname><forenames>William C.</forenames></author></authors><title>Imaging of moving targets with multi-static SAR using an overcomplete
  dictionary</title><categories>cs.IT math.IT</categories><comments>This work has been submitted to IEEE Journal on Selected Topics in
  Signal Processing (Special Issue on MIMO Radar and Its Applications) for
  possible publication</comments><doi>10.1109/JSTSP.2009.2038982</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a method for imaging of moving targets using multi-static
SAR by treating the problem as one of spatial reflectivity signal inversion
over an overcomplete dictionary of target velocities. Since SAR sensor returns
can be related to the spatial frequency domain projections of the scattering
field, we exploit insights from compressed sensing theory to show that moving
targets can be effectively imaged with transmitters and receivers randomly
dispersed in a multi-static geometry within a narrow forward cone around the
scene of interest. Existing approaches to dealing with moving targets in SAR
solve a coupled non-linear problem of target scattering and motion estimation
typically through matched filtering. In contrast, by using an overcomplete
dictionary approach we effectively linearize the forward model and solve the
moving target problem as a larger, unified regularized inversion problem
subject to sparsity constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0828</identifier>
 <datestamp>2009-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0828</id><created>2009-04-05</created><updated>2009-08-09</updated><authors><author><keyname>Anand</keyname><forenames>M.</forenames></author><author><keyname>Kumar</keyname><forenames>P. R.</forenames></author></authors><title>On approximating Gaussian relay networks by deterministic networks</title><categories>cs.IT math.IT</categories><comments>Accepted for publication in proceedings of ITW 09, Taormina, Sicily.
  Corrected typos, added references, changed name of network model</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We examine the extent to which Gaussian relay networks can be approximated by
deterministic networks, and present two results, one negative and one positive.
  The gap between the capacities of a Gaussian relay network and a
corresponding linear deterministic network can be unbounded. The key reasons
are that the linear deterministic model fails to capture the phase of received
signals, and there is a loss in signal strength in the reduction to a linear
deterministic network.
  On the positive side, Gaussian relay networks are indeed well approximated by
certain discrete superposition networks, where the inputs and outputs to the
channels are discrete, and channel gains are signed integers.
  As a corollary, MIMO channels cannot be approximated by the linear
deterministic model but can be by the discrete superposition model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0859</identifier>
 <datestamp>2010-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0859</id><created>2009-04-06</created><updated>2010-02-09</updated><authors><author><keyname>Pritchard</keyname><forenames>David</forenames></author><author><keyname>Chakrabarty</keyname><forenames>Deeparnab</forenames></author></authors><title>Approximability of Sparse Integer Programs</title><categories>cs.DS cs.DM</categories><comments>Version submitted to Algorithmica special issue on ESA 2009. Previous
  conference version: http://dx.doi.org/10.1007/978-3-642-04128-0_8</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The main focus of this paper is a pair of new approximation algorithms for
certain integer programs. First, for covering integer programs {min cx: Ax &gt;=
b, 0 &lt;= x &lt;= d} where A has at most k nonzeroes per row, we give a
k-approximation algorithm. (We assume A, b, c, d are nonnegative.) For any k &gt;=
2 and eps&gt;0, if P != NP this ratio cannot be improved to k-1-eps, and under the
unique games conjecture this ratio cannot be improved to k-eps. One key idea is
to replace individual constraints by others that have better rounding
properties but the same nonnegative integral solutions; another critical
ingredient is knapsack-cover inequalities. Second, for packing integer programs
{max cx: Ax &lt;= b, 0 &lt;= x &lt;= d} where A has at most k nonzeroes per column, we
give a (2k^2+2)-approximation algorithm. Our approach builds on the iterated LP
relaxation framework. In addition, we obtain improved approximations for the
second problem when k=2, and for both problems when every A_{ij} is small
compared to b_i. Finally, we demonstrate a 17/16-inapproximability for covering
integer programs with at most two nonzeroes per column.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0879</identifier>
 <datestamp>2009-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0879</id><created>2009-04-06</created><authors><author><keyname>Cappellari</keyname><forenames>Lorenzo</forenames></author></authors><title>On Superposition Coding for the Wyner-Ziv Problem</title><categories>cs.IT math.IT</categories><comments>5 pages, 1 figure, submitted to IEEE ITW2009 Taormina, Italy</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In problems of lossy source/noisy channel coding with side information, the
theoretical bounds are achieved using &quot;good&quot; source/channel codes that can be
partitioned into &quot;good&quot; channel/source codes. A scheme that achieves optimality
in channel coding with side information at the encoder using independent
channel and source codes was outlined in previous works. In practice, the
original problem is transformed into a multiple-access problem in which the
superposition of the two independent codes can be decoded using successive
interference cancellation. Inspired by this work, we analyze the superposition
approach for source coding with side information at the decoder. We present a
random coding analysis that shows achievability of the Wyner-Ziv bound. Then,
we discuss some issues related to the practical implementation of this method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0942</identifier>
 <datestamp>2010-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0942</id><created>2009-04-06</created><updated>2010-07-08</updated><authors><author><keyname>Hay</keyname><forenames>Michael</forenames></author><author><keyname>Rastogi</keyname><forenames>Vibhor</forenames></author><author><keyname>Miklau</keyname><forenames>Gerome</forenames></author><author><keyname>Suciu</keyname><forenames>Dan</forenames></author></authors><title>Boosting the Accuracy of Differentially-Private Histograms Through
  Consistency</title><categories>cs.DB cs.CR</categories><comments>15 pages, 7 figures, minor revisions to previous version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that it is possible to significantly improve the accuracy of a
general class of histogram queries while satisfying differential privacy. Our
approach carefully chooses a set of queries to evaluate, and then exploits
consistency constraints that should hold over the noisy output. In a
post-processing phase, we compute the consistent input most likely to have
produced the noisy output. The final output is differentially-private and
consistent, but in addition, it is often much more accurate. We show, both
theoretically and experimentally, that these techniques can be used for
estimating the degree sequence of a graph very precisely, and for computing a
histogram that can support arbitrary range queries accurately.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0962</identifier>
 <datestamp>2009-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0962</id><created>2009-04-06</created><authors><author><keyname>Sparavigna</keyname><forenames>Amelia</forenames></author></authors><title>Color Dipole Moments for Edge Detection</title><categories>cs.CV</categories><comments>8 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dipole and higher moments are physical quantities used to describe a charge
distribution. In analogy with electromagnetism, it is possible to define the
dipole moments for a gray-scale image, according to the single aspect of a
gray-tone map. In this paper we define the color dipole moments for color
images. For color maps in fact, we have three aspects, the three primary
colors, to consider. Associating three color charges to each pixel, color
dipole moments can be easily defined and used for edge detection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0973</identifier>
 <datestamp>2009-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0973</id><created>2009-04-06</created><updated>2009-08-09</updated><authors><author><keyname>Tadaki</keyname><forenames>Kohtaro</forenames></author></authors><title>A statistical mechanical interpretation of algorithmic information
  theory III: Composite systems and fixed points</title><categories>cs.IT cs.CC math.IT math.PR</categories><comments>5 pages, no figures, final manuscript to appear in the Proceedings of
  the 2009 IEEE Information Theory Workshop, Taormina, Sicily, Italy, October
  11 - 16, 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The statistical mechanical interpretation of algorithmic information theory
(AIT, for short) was introduced and developed by our former works [K. Tadaki,
Local Proceedings of CiE 2008, pp.425-434, 2008] and [K. Tadaki, Proceedings of
LFCS'09, Springer's LNCS, vol.5407, pp.422-440, 2009], where we introduced the
notion of thermodynamic quantities, such as partition function Z(T), free
energy F(T), energy E(T), and statistical mechanical entropy S(T), into AIT. We
then discovered that, in the interpretation, the temperature T equals to the
partial randomness of the values of all these thermodynamic quantities, where
the notion of partial randomness is a stronger representation of the
compression rate by means of program-size complexity. Furthermore, we showed
that this situation holds for the temperature itself as a thermodynamic
quantity, namely, for each of all the thermodynamic quantities above, the
computability of its value at temperature T gives a sufficient condition for T
in (0,1) to be a fixed point on partial randomness. In this paper, we develop
the statistical mechanical interpretation of AIT further and pursue its formal
correspondence to normal statistical mechanics. The thermodynamic quantities in
AIT are defined based on the halting set of an optimal computer, which is a
universal decoding algorithm used to define the notion of program-size
complexity. We show that there are infinitely many optimal computers which give
completely different sufficient conditions in each of the thermodynamic
quantities in AIT. We do this by introducing the notion of composition of
computers into AIT, which corresponds to the notion of composition of systems
in normal statistical mechanics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0981</identifier>
 <datestamp>2011-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0981</id><created>2009-04-06</created><updated>2011-06-08</updated><authors><author><keyname>Avanzini</keyname><forenames>Martin</forenames></author><author><keyname>Moser</keyname><forenames>Georg</forenames></author></authors><title>Dependency Pairs and Polynomial Path Orders</title><categories>cs.LO cs.AI cs.CC cs.SC</categories><comments>23 pages, conference version accepted at RTA 2009</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We show how polynomial path orders can be employed efficiently in conjunction
with weak innermost dependency pairs to automatically certify polynomial
runtime complexity of term rewrite systems and the polytime computability of
the functions computed. The established techniques have been implemented and we
provide ample experimental data to assess the new method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0986</identifier>
 <datestamp>2009-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0986</id><created>2009-04-06</created><authors><author><keyname>Sidhom</keyname><forenames>Sahbi</forenames><affiliation>LORIA</affiliation></author></authors><title>Approche conceptuelle par un processus d'annotation pour la
  repr\'esentation et la valorisation de contenus informationnels en
  intelligence \'economique (IE)</title><categories>cs.IR</categories><proxy>ccsd inria-00344865</proxy><journal-ref>Syst\`emes d'Information et Intelligence Economique (SIIE) 1 (
  ISBN 9978-9973868-19-0) (2008) pp. 172-190</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the era of the information society, the impact of the information systems
on the economy of material and immaterial is certainly perceptible. With
regards to the information resources of an organization, the annotation
involved to enrich informational content, to track the intellectual activities
on a document and to set the added value on information for the benefit of
solving a decision-making problem in the context of economic intelligence. Our
contribution is distinguished by the representation of an annotation process
and its inherent concepts to lead the decisionmaker to an anticipated decision:
the provision of relevant and annotated information. Such information in the
system is made easy by taking into account the diversity of resources and those
that are well annotated so formally and informally by the EI actors. A capital
research framework consist of integrating in the decision-making process the
annotator activity, the software agent (or the reasoning mechanisms) and the
information resources enhancement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.0994</identifier>
 <datestamp>2009-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.0994</id><created>2009-04-06</created><authors><author><keyname>Xu</keyname><forenames>Weiyu</forenames></author><author><keyname>Khajehnejad</keyname><forenames>M. Amin</forenames></author><author><keyname>Avestimehr</keyname><forenames>Salman</forenames></author><author><keyname>Hassibi</keyname><forenames>Babak</forenames></author></authors><title>Breaking through the Thresholds: an Analysis for Iterative Reweighted
  $\ell_1$ Minimization via the Grassmann Angle Framework</title><categories>math.PR cs.IT math.IT</categories><comments>Submitted to ITW 2009 in Sicily</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is now well understood that $\ell_1$ minimization algorithm is able to
recover sparse signals from incomplete measurements [2], [1], [3] and sharp
recoverable sparsity thresholds have also been obtained for the $\ell_1$
minimization algorithm. However, even though iterative reweighted $\ell_1$
minimization algorithms or related algorithms have been empirically observed to
boost the recoverable sparsity thresholds for certain types of signals, no
rigorous theoretical results have been established to prove this fact. In this
paper, we try to provide a theoretical foundation for analyzing the iterative
reweighted $\ell_1$ algorithms. In particular, we show that for a nontrivial
class of signals, the iterative reweighted $\ell_1$ minimization can indeed
deliver recoverable sparsity thresholds larger than that given in [1], [3]. Our
results are based on a high-dimensional geometrical analysis (Grassmann angle
analysis) of the null-space characterization for $\ell_1$ minimization and
weighted $\ell_1$ minimization algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1002</identifier>
 <datestamp>2009-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1002</id><created>2009-04-06</created><authors><author><keyname>Bein</keyname><forenames>Wolfgang</forenames></author><author><keyname>Epstein</keyname><forenames>Leah</forenames></author><author><keyname>Larmore</keyname><forenames>Lawrence L.</forenames></author><author><keyname>Noga</keyname><forenames>John</forenames></author></authors><title>A Program to Determine the Exact Competitive Ratio of List s-Batching
  with Unit Jobs</title><categories>cs.DS</categories><acm-class>F.2; I.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the online list s-batch problem, where all the jobs have
processing time 1 and we seek to minimize the sum of the completion times of
the jobs. We give a Java program which is used to verify that the
competitiveness of this problem is 619/583.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1083</identifier>
 <datestamp>2009-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1083</id><created>2009-04-07</created><authors><author><keyname>Tournier</keyname><forenames>Christophe</forenames><affiliation>LURPA</affiliation></author><author><keyname>Lavernhe</keyname><forenames>Sylvain</forenames><affiliation>LURPA</affiliation></author><author><keyname>Lartigue</keyname><forenames>Claire</forenames><affiliation>LURPA</affiliation></author></authors><title>5-axis High Speed Milling Optimisation</title><categories>cs.OH</categories><proxy>ccsd hal-00373724</proxy><journal-ref>Revue Internationale d Ingenierie Numerique 2, 1-2 (2006) pages
  173-184</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Manufacturing of free form parts relies on the calculation of a tool path
based on a CAD model, on a machining strategy and on a given numerically
controlled machine tool. In order to reach the best possible performances, it
is necessary to take into account a maximum of constraints during tool path
calculation. For this purpose, we have developed a surface representation of
the tool paths to manage 5-axis High Speed Milling, which is the most
complicated case. This model allows integrating early in the step of tool path
computation the machine tool geometrical constraints (axis ranges, part holder
orientation), kinematical constraints (speed and acceleration on the axes,
singularities) as well as gouging issues between the tool and the part. The aim
of the paper is to optimize the step of 5-axis HSM tool path calculation with a
bi-parameter surface representation of the tool path. We propose an example of
integration of the digital process for tool path computation, ensuring the
required quality and maximum productivity
</abstract></arXiv>
</metadata>
</record>
<resumptionToken cursor="6000" completeListSize="102538">1122234|7001</resumptionToken>
</ListRecords>
</OAI-PMH>
