<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2016-03-09T00:55:56Z</responseDate>
<request verb="ListRecords" resumptionToken="1122234|27001">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:1112.2680</identifier>
 <datestamp>2011-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.2680</id><created>2011-12-12</created><authors><author><keyname>Hall</keyname><forenames>Rob</forenames></author><author><keyname>Rinaldo</keyname><forenames>Alessandro</forenames></author><author><keyname>Wasserman</keyname><forenames>Larry</forenames></author></authors><title>Random Differential Privacy</title><categories>stat.ME cs.CR cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a relaxed privacy definition called {\em random differential
privacy} (RDP). Differential privacy requires that adding any new observation
to a database will have small effect on the output of the data-release
procedure. Random differential privacy requires that adding a {\em randomly
drawn new observation} to a database will have small effect on the output. We
show an analog of the composition property of differentially private procedures
which applies to our new definition. We show how to release an RDP histogram
and we show that RDP histograms are much more accurate than histograms obtained
using ordinary differential privacy. We finally show an analog of the global
sensitivity framework for the release of functions under our privacy
definition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.2681</identifier>
 <datestamp>2012-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.2681</id><created>2011-12-12</created><updated>2012-10-07</updated><authors><author><keyname>Islam</keyname><forenames>Muhammad Asiful</forenames></author><author><keyname>Ramakrishnan</keyname><forenames>C. R.</forenames></author><author><keyname>Ramakrishnan</keyname><forenames>I. V.</forenames></author></authors><title>Inference in Probabilistic Logic Programs with Continuous Random
  Variables</title><categories>cs.AI</categories><comments>12 pages. arXiv admin note: substantial text overlap with
  arXiv:1203.4287</comments><journal-ref>Theory and Practice of Logic Programming / Volume12 / Special
  Issue4-5 / July 2012, pp 505-523</journal-ref><doi>10.1017/S1471068412000154</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Probabilistic Logic Programming (PLP), exemplified by Sato and Kameya's
PRISM, Poole's ICL, Raedt et al's ProbLog and Vennekens et al's LPAD, is aimed
at combining statistical and logical knowledge representation and inference. A
key characteristic of PLP frameworks is that they are conservative extensions
to non-probabilistic logic programs which have been widely used for knowledge
representation. PLP frameworks extend traditional logic programming semantics
to a distribution semantics, where the semantics of a probabilistic logic
program is given in terms of a distribution over possible models of the
program. However, the inference techniques used in these works rely on
enumerating sets of explanations for a query answer. Consequently, these
languages permit very limited use of random variables with continuous
distributions. In this paper, we present a symbolic inference procedure that
uses constraints and represents sets of explanations without enumeration. This
permits us to reason over PLPs with Gaussian or Gamma-distributed random
variables (in addition to discrete-valued random variables) and linear equality
constraints over reals. We develop the inference procedure in the context of
PRISM; however the procedure's core ideas can be easily applied to other PLP
languages as well. An interesting aspect of our inference procedure is that
PRISM's query evaluation process becomes a special case in the absence of any
continuous random variables in the program. The symbolic inference procedure
enables us to reason over complex probabilistic models such as Kalman filters
and a large subclass of Hybrid Bayesian networks that were hitherto not
possible in PLP frameworks. (To appear in Theory and Practice of Logic
Programming).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.2690</identifier>
 <datestamp>2011-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.2690</id><created>2011-12-12</created><updated>2011-12-14</updated><authors><author><keyname>Hern</keyname><forenames>Brett</forenames></author><author><keyname>Narayanan</keyname><forenames>Krishna</forenames></author></authors><title>Multilevel Coding Schemes for Compute-and-Forward with Flexible Decoding</title><categories>cs.IT math.IT</categories><comments>This paper was submitted to IEEE Transactions on Information Theory
  in July 2011. A shorter version also appeared in the proceedings of the
  International Symposium on Information Theory in August 2011 without the
  proof of the main theorem</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the design of coding schemes for the wireless two-way relaying
channel when there is no channel state information at the transmitter. In the
spirit of the compute and forward paradigm, we present a multilevel coding
scheme that permits computation (or, decoding) of a class of functions at the
relay. The function to be computed (or, decoded) is then chosen depending on
the channel realization. We define such a class of functions which can be
decoded at the relay using the proposed coding scheme and derive rates that are
universally achievable over a set of channel gains when this class of functions
is used at the relay. We develop our framework with general modulation formats
in mind, but numerical results are presented for the case where each node
transmits using the QPSK constellation. Numerical results with QPSK show that
the flexibility afforded by our proposed scheme results in substantially higher
rates than those achievable by always using a fixed function or by adapting the
function at the relay but coding over GF(4).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.2699</identifier>
 <datestamp>2011-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.2699</id><created>2011-12-12</created><authors><author><keyname>Singh</keyname><forenames>Inder</forenames></author><author><keyname>Punia</keyname><forenames>Devendra Kumar</forenames></author></authors><title>Employees Adoption of E-Procurement System: An Empirical Study</title><categories>cs.OH</categories><comments>11 Pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Today, organizations are investing a lot in their IT infrastructure and
reengineering their business processes by digitizing firms. If organizational
employees will not optimum utilize its IT infrastructure, the productivity gain
reduced enormously. In Uttarakhand e-procurement system implemented by public
sector under e-governance integrated mission mode projects. So, there is need
to find the determinants which influence employee's adoption and uses of
e-procurement systems. This research study assesses the organizational and
individual determinants that influence the use of e-procurement system in
Uttarakhand public sector. This study provides managers with the valuable
information to take intervention programs to achieve greater acceptance and
usage of e-procurement system. Data collected for this study by the means of a
survey conducted in Uttarakhand state in 2011. A total 1200 questionnaire forms
were distributed personally and online to employees using e-procurement system
in Uttarakhand.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.2723</identifier>
 <datestamp>2011-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.2723</id><created>2011-12-12</created><authors><author><keyname>Bandari</keyname><forenames>Dorna</forenames></author><author><keyname>Pottie</keyname><forenames>Gregory</forenames></author><author><keyname>Frossard</keyname><forenames>Pascal</forenames></author></authors><title>Correlation-aware Resource Allocation in Multi-Cell Networks</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a cross-layer strategy for resource allocation between spatially
correlated sources in the uplink of multi-cell FDMA networks. Our objective is
to find the optimum power and channel to sources, in order to minimize the
maximum distortion achieved by any source in the network. Given that the
network is multi-cell, the inter-cell interference must also be taken into
consideration. This resource allocation problem is NP-hard and the optimal
solution can only be found by exhaustive search over the entire solution space,
which is not computationally feasible. We propose a three step method to be
performed separately by the scheduler in each cell, which finds cross-layer
resource allocation in simple steps. The three- step algorithm separates the
problem into inter-cell resource management, grouping of sources for joint
decoding, and intra- cell channel assignment. For each of the steps we propose
allocation methods that satisfy different design constraints. In the
simulations we compare methods for each step of the algorithm. We also
demonstrate the overall gain of using correlation-aware resource allocation for
a typical multi-cell network of Gaussian sources. We show that, while using
correlation in compression and joint decoding can achieve 25% loss in
distortion over independent decoding, this loss can be increased to 37% when
correlation is also utilized in resource allocation method. This significant
distortion loss motivates further work in correlation-aware resource
allocation. Overall, we find that our method achieves a 60% decrease in 5
percentile distortion compared to independent methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.2738</identifier>
 <datestamp>2013-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.2738</id><created>2011-12-12</created><authors><author><keyname>Sch&#xf6;lkopf</keyname><forenames>Bernhard</forenames></author><author><keyname>Janzing</keyname><forenames>Dominik</forenames></author><author><keyname>Peters</keyname><forenames>Jonas</forenames></author><author><keyname>Zhang</keyname><forenames>Kun</forenames></author></authors><title>Robust Learning via Cause-Effect Models</title><categories>stat.ML cs.LG</categories><journal-ref>A version of this paper has been published as &quot;On Causal and
  Anticausal Learning&quot; in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of function estimation in the case where the data
distribution may shift between training and test time, and additional
information about it may be available at test time. This relates to popular
scenarios such as covariate shift, concept drift, transfer learning and
semi-supervised learning. This working paper discusses how these tasks could be
tackled depending on the kind of changes of the distributions. It argues that
knowledge of an underlying causal direction can facilitate several of these
tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.2746</identifier>
 <datestamp>2012-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.2746</id><created>2011-12-12</created><updated>2012-02-17</updated><authors><author><keyname>Manipatruni</keyname><forenames>Sasikanth</forenames></author><author><keyname>Nikonov</keyname><forenames>Dmitri E.</forenames></author><author><keyname>Young</keyname><forenames>Ian A.</forenames></author></authors><title>Circuit Theory for SPICE of Spintronic Integrated Circuits</title><categories>cond-mat.mes-hall cs.ET</categories><comments>14 pages, 11 figures; added fig. 2; added citations; modified title
  to emphasize SPICE; Results unchanged</comments><acm-class>B.3; B.6.1; B.7.0; B.7.1; B.7.2; J.2; G.4; I.6.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a theoretical and a numerical formalism for analysis and design of
spintronic integrated circuits (SPINICs). The formalism encompasses a
generalized circuit theory for spintronic integrated circuits based on
nanomagnetic dynamics and spin transport. We propose an extension to the
Modified Nodal Analysis technique for the analysis of spin circuits based on
the recently developed spin conduction matrices. We demonstrate the
applicability of the framework using an example spin logic circuit described
using spin Netlists.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.2755</identifier>
 <datestamp>2011-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.2755</id><created>2011-12-12</created><authors><author><keyname>Lerman</keyname><forenames>Kristina</forenames></author><author><keyname>Intagorn</keyname><forenames>Suradej</forenames></author><author><keyname>Kang</keyname><forenames>Jeon-Hyung</forenames></author><author><keyname>Ghosh</keyname><forenames>Rumi</forenames></author></authors><title>Using Proximity to Predict Activity in Social Networks</title><categories>cs.SI physics.soc-ph</categories><comments>submitted to WWW conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The structure of a social network contains information useful for predicting
its evolution. Nodes that are &quot;close&quot; in some sense are more likely to become
linked in the future than more distant nodes. We show that structural
information can also help predict node activity. We use proximity to capture
the degree to which two nodes are &quot;close&quot; to each other in the network. In
addition to standard proximity metrics used in the link prediction task, such
as neighborhood overlap, we introduce new metrics that model different types of
interactions that can occur between network nodes. We argue that the &quot;closer&quot;
nodes are in a social network, the more similar will be their activity. We
study this claim using data about URL recommendation on social media sites Digg
and Twitter. We show that structural proximity of two users in the follower
graph is related to similarity of their activity, i.e., how many URLs they both
recommend. We also show that given friends' activity, knowing their proximity
to the user can help better predict which URLs the user will recommend. We
compare the performance of different proximity metrics on the activity
prediction task and find that some metrics lead to substantial performance
improvements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.2762</identifier>
 <datestamp>2012-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.2762</id><created>2011-12-12</created><updated>2012-07-03</updated><authors><author><keyname>Swanson</keyname><forenames>Colleen M.</forenames></author><author><keyname>Stinson</keyname><forenames>Douglas R.</forenames></author></authors><title>Extended Combinatorial Constructions for Peer-to-peer User-Private
  Information Retrieval</title><categories>cs.CR</categories><comments>Updated version, which reflects reviewer comments and includes
  expanded explanations throughout. Paper is accepted for publication by
  Advances in Mathematics of Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider user-private information retrieval (UPIR), an interesting
alternative to private information retrieval (PIR) introduced by Domingo-Ferrer
et al. In UPIR, the database knows which records have been retrieved, but does
not know the identity of the query issuer. The goal of UPIR is to disguise user
profiles from the database. Domingo-Ferrer et al.\ focus on using a
peer-to-peer community to construct a UPIR scheme, which we term P2P UPIR. In
this paper, we establish a strengthened model for P2P UPIR and clarify the
privacy goals of such schemes using standard terminology from the field of
privacy research. In particular, we argue that any solution providing privacy
against the database should attempt to minimize any corresponding loss of
privacy against other users. We give an analysis of existing schemes, including
a new attack by the database. Finally, we introduce and analyze two new
protocols. Whereas previous work focuses on a special type of combinatorial
design known as a configuration, our protocols make use of more general
designs. This allows for flexibility in protocol set-up, allowing for a choice
between having a dynamic scheme (in which users are permitted to enter and
leave the system), or providing increased privacy against other users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.2774</identifier>
 <datestamp>2011-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.2774</id><created>2011-12-12</created><authors><author><keyname>Gupte</keyname><forenames>Mangesh</forenames></author><author><keyname>Eliassi-Rad</keyname><forenames>Tina</forenames></author></authors><title>Measuring Tie Strength in Implicit Social Networks</title><categories>cs.SI physics.soc-ph</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a set of people and a set of events they attend, we address the problem
of measuring connectedness or tie strength between each pair of persons given
that attendance at mutual events gives an implicit social network between
people. We take an axiomatic approach to this problem. Starting from a list of
axioms that a measure of tie strength must satisfy, we characterize functions
that satisfy all the axioms and show that there is a range of measures that
satisfy this characterization. A measure of tie strength induces a ranking on
the edges (and on the set of neighbors for every person). We show that for
applications where the ranking, and not the absolute value of the tie strength,
is the important thing about the measure, the axioms are equivalent to a
natural partial order. Also, to settle on a particular measure, we must make a
non-obvious decision about extending this partial order to a total order, and
that this decision is best left to particular applications. We classify
measures found in prior literature according to the axioms that they satisfy.
In our experiments, we measure tie strength and the coverage of our axioms in
several datasets. Also, for each dataset, we bound the maximum Kendall's Tau
divergence (which measures the number of pairwise disagreements between two
lists) between all measures that satisfy the axioms using the partial order.
This informs us if particular datasets are well behaved where we do not have to
worry about which measure to choose, or we have to be careful about the exact
choice of measure we make.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.2791</identifier>
 <datestamp>2011-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.2791</id><created>2011-12-12</created><authors><author><keyname>Gungor</keyname><forenames>Onur</forenames></author><author><keyname>Tan</keyname><forenames>Jian</forenames></author><author><keyname>Koksal</keyname><forenames>C. Emre</forenames></author><author><keyname>Gamal</keyname><forenames>Hesham El</forenames></author><author><keyname>Shroff</keyname><forenames>Ness B.</forenames></author></authors><title>Secrecy Outage Capacity of Fading Channels</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers point to point secure communication over flat fading
channels under an outage constraint. More specifically, we extend the
definition of outage capacity to account for the secrecy constraint and obtain
sharp characterizations of the corresponding fundamental limits under two
different assumptions on the transmitter CSI (Channel state information).
First, we find the outage secrecy capacity assuming that the transmitter has
perfect knowledge of the legitimate and eavesdropper channel gains. In this
scenario, the capacity achieving scheme relies on opportunistically exchanging
private keys between the legitimate nodes. These keys are stored in a key
buffer and later used to secure delay sensitive data using the Vernam's one
time pad technique. We then extend our results to the more practical scenario
where the transmitter is assumed to know only the legitimate channel gain.
Here, our achievability arguments rely on privacy amplification techniques to
generate secret key bits. In the two cases, we also characterize the optimal
power control policies which, interestingly, turn out to be a judicious
combination of channel inversion and the optimal ergodic strategy. Finally, we
analyze the effect of key buffer overflow on the overall outage probability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.2792</identifier>
 <datestamp>2011-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.2792</id><created>2011-12-12</created><authors><author><keyname>sanei</keyname><forenames>Masoomeh</forenames></author><author><keyname>Charkari</keyname><forenames>Nasrollah Moghaddam</forenames></author></authors><title>Hybrid Heuristic-Based Artificial Immune System for Task Scheduling</title><categories>cs.DC cs.NE</categories><comments>12 pages, 8 figures; International Journal of Distributed and
  Parallel Systems (IJDPS) Vol.2, No.6, November 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Task scheduling problem in heterogeneous systems is the process of allocating
tasks of an application to heterogeneous processors interconnected by
high-speed networks, so that minimizing the finishing time of application as
much as possible. Tasks are processing units of application and have
precedenceconstrained, communication and also, are presented by Directed
Acyclic Graphs (DAGs). Evolutionary algorithms are well suited for solving task
scheduling problem in heterogeneous environment. In this paper, we propose a
hybrid heuristic-based Artificial Immune System (AIS) algorithm for solving the
scheduling problem. In this regard, AIS with some heuristics and Single
Neighbourhood Search (SNS) technique are hybridized. Clonning and immune-remove
operators of AIS provide diversity, while heuristics and SNS provide
convergence of algorithm into good solutions, that is balancing between
exploration and exploitation. We have compared our method with some
state-of-the art algorithms. The results of the experiments show the validity
and efficiency of our method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.2793</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.2793</id><created>2011-12-12</created><updated>2014-05-20</updated><authors><author><keyname>Gungor</keyname><forenames>Onur</forenames></author><author><keyname>Chen</keyname><forenames>Fangzhou</forenames></author><author><keyname>Koksal</keyname><forenames>C. Emre</forenames></author></authors><title>Secret Key Generation Via Localization and Mobility</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider secret key generation from relative localization information of a
pair of nodes in a mobile wireless network in the presence of a mobile
eavesdropper. Our problem can be categorized under the source models of
information theoretic secrecy, where the distance between the legitimate nodes
acts as the observed common randomness. We characterize the theoretical limits
on the achievable secret key bit rate, in terms of the observation noise
variance at the legitimate nodes and the eavesdropper. This work provides a
framework that combines information theoretic secrecy and wireless
localization, and proves that the localization information provides a
significant additional resource for secret key generation in mobile wireless
networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.2795</identifier>
 <datestamp>2012-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.2795</id><created>2011-12-13</created><updated>2012-05-25</updated><authors><author><keyname>Mans</keyname><forenames>Bernard</forenames></author><author><keyname>Mathieson</keyname><forenames>Luke</forenames></author></authors><title>On the Treewidth of Dynamic Graphs</title><categories>cs.CC cs.DM cs.LO</categories><msc-class>68</msc-class><acm-class>F.2.2; F.4.1; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dynamic graph theory is a novel, growing area that deals with graphs that
change over time and is of great utility in modelling modern wireless, mobile
and dynamic environments. As a graph evolves, possibly arbitrarily, it is
challenging to identify the graph properties that can be preserved over time
and understand their respective computability.
  In this paper we are concerned with the treewidth of dynamic graphs. We focus
on metatheorems, which allow the generation of a series of results based on
general properties of classes of structures. In graph theory two major
metatheorems on treewidth provide complexity classifications by employing
structural graph measures and finite model theory. Courcelle's Theorem gives a
general tractability result for problems expressible in monadic second order
logic on graphs of bounded treewidth, and Frick &amp; Grohe demonstrate a similar
result for first order logic and graphs of bounded local treewidth.
  We extend these theorems by showing that dynamic graphs of bounded (local)
treewidth where the length of time over which the graph evolves and is observed
is finite and bounded can be modelled in such a way that the (local) treewidth
of the underlying graph is maintained. We show the application of these results
to problems in dynamic graph theory and dynamic extensions to static problems.
In addition we demonstrate that certain widely used dynamic graph classes
naturally have bounded local treewidth.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.2801</identifier>
 <datestamp>2012-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.2801</id><created>2011-12-13</created><updated>2012-02-29</updated><authors><author><keyname>Akama</keyname><forenames>Yohji</forenames></author></authors><title>A new order theory of set systems and better quasi-orderings</title><categories>math.CO cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  By reformulating a learning process of a set system L as a game between
Teacher (presenter of data) and Learner (updater of the abstract independent
set), we define the order type dim L of L to be the order type of the game
tree. The theory of this new order type and continuous, monotone function
between set systems corresponds to the theory of well quasi-orderings (WQOs).
As Nash-Williams developed the theory of WQOs to the theory of better
quasi-orderings (BQOs), we introduce a set system that has order type and
corresponds to a BQO. We prove that the class of set systems corresponding to
BQOs is closed by any monotone function. In (Shinohara and Arimura. &quot;Inductive
inference of unbounded unions of pattern languages from positive data.&quot;
Theoretical Computer Science, pp. 191-209, 2000), for any set system L, they
considered the class of arbitrary (finite) unions of members of L. From
viewpoint of WQOs and BQOs, we characterize the set systems L such that the
class of arbitrary (finite) unions of members of L has order type. The
characterization shows that the order structure of the set system L with
respect to the set-inclusion is not important for the resulting set system
having order type. We point out continuous, monotone function of set systems is
similar to positive reduction to Jockusch-Owings' weakly semirecursive sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.2807</identifier>
 <datestamp>2012-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.2807</id><created>2011-12-13</created><updated>2012-02-08</updated><authors><author><keyname>Mirzal</keyname><forenames>Andri</forenames></author></authors><title>Design and Implementation of a Simple Web Search Engine</title><categories>cs.IR</categories><comments>8 pages, 5 figures</comments><journal-ref>International Journal of Multimedia and Ubiquitous Engineering
  International Journal of Multimedia and Ubiquitous Engineering International
  Journal of Multimedia and Ubiquitous Engineering, Vol. 7, No. 1, January,
  2012</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  We present a simple web search engine for indexing and searching html
documents using python programming language. Because python is well known for
its simple syntax and strong support for main operating systems, we hope it
will be beneficial for learning information retrieval techniques, especially
web search engine technology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.2809</identifier>
 <datestamp>2011-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.2809</id><created>2011-12-13</created><authors><author><keyname>Ibrahim</keyname><forenames>Rosziati</forenames></author><author><keyname>Kuan</keyname><forenames>Teoh Suk</forenames></author></authors><title>Steganography Algorithm to Hide Secret Message inside an Image</title><categories>cs.MM cs.CR</categories><comments>7 pages, 7 figures</comments><journal-ref>Computer Technology and Application 2 (2011) 102-108</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the authors propose a new algorithm to hide data inside image
using steganography technique. The proposed algorithm uses binary codes and
pixels inside an image. The zipped file is used before it is converted to
binary codes to maximize the storage of data inside the image. By applying the
proposed algorithm, a system called Steganography Imaging System (SIS) is
developed. The system is then tested to see the viability of the proposed
algorithm. Various sizes of data are stored inside the images and the PSNR
(Peak signal-to-noise ratio) is also captured for each of the images tested.
Based on the PSNR value of each images, the stego image has a higher PSNR
value. Hence this new steganography algorithm is very efficient to hide the
data inside the image.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.2810</identifier>
 <datestamp>2011-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.2810</id><created>2011-12-13</created><authors><author><keyname>Torabkhani</keyname><forenames>Nima</forenames></author><author><keyname>Vellambi</keyname><forenames>Badri N.</forenames></author><author><keyname>Beirami</keyname><forenames>Ahmad</forenames></author><author><keyname>Fekri</keyname><forenames>Faramarz</forenames></author></authors><title>Exact Modeling of the Performance of Random Linear Network Coding in
  Finite-buffer Networks</title><categories>cs.IT math.IT</categories><comments>5 pages, 5 figures, ITW2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present an exact model for the analysis of the performance
of Random Linear Network Coding (RLNC) in wired erasure networks with finite
buffers. In such networks, packets are delayed due to either random link
erasures or blocking by full buffers. We assert that because of RLNC, the
content of buffers have dependencies which cannot be captured directly using
the classical queueing theoretical models. We model the performance of the
network using Markov chains by a careful derivation of the buffer occupancy
states and their transition rules. We verify by simulations that the proposed
framework results in an accurate measure of the network throughput offered by
RLNC. Further, we introduce a class of acyclic networks for which the number of
state variables is significantly reduced.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.2816</identifier>
 <datestamp>2012-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.2816</id><created>2011-12-13</created><updated>2012-11-11</updated><authors><author><keyname>Mori</keyname><forenames>Shintaro</forenames></author><author><keyname>Hisakado</keyname><forenames>Masato</forenames></author><author><keyname>Takahashi</keyname><forenames>Taiki</forenames></author></authors><title>Phase transition to two-peaks phase in an information cascade voting
  experiment</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><comments>11 pages, 9 figures, 3 tables</comments><journal-ref>Phys. Rev. E 86, 026109 (2012)</journal-ref><doi>10.1103/PhysRevE.86.026109</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Observational learning is an important information aggregation mechanism.
However, it occasionally leads to a state in which an entire population chooses
a sub-optimal option. When it occurs and whether it is a phase transition
remain unanswered. To address these questions, we performed a voting experiment
in which subjects answered a two-choice quiz sequentially with and without
information about the prior subjects' choices. The subjects who could copy
others are called herders. We obtained a microscopic rule regarding how herders
copy others. Varying the ratio of herders led to qualitative changes in the
macroscopic behavior in the experiment of about 50 subjects. If the ratio is
small, the sequence of choices rapidly converges to the true one. As the ratio
approaches 100%, convergence becomes extremely slow and information aggregation
almost terminates. A simulation study of a stochastic model for 10^{6} subjects
based on the herder's microscopic rule showed a phase transition to the
two-peaks phase, where the convergence completely terminates, as the ratio
exceeds some critical value.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.2822</identifier>
 <datestamp>2011-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.2822</id><created>2011-12-13</created><authors><author><keyname>Xie</keyname><forenames>Jing</forenames></author><author><keyname>Jiang</keyname><forenames>Yuming</forenames></author><author><keyname>Xie</keyname><forenames>Min</forenames></author></authors><title>A Temporal Approach to Stochastic Network Calculus</title><categories>cs.PF</categories><comments>45 pages. An early version of this paper has been presented at 17th
  Annual Meeting of the IEEE/ACM International Symposium on Modelling, Analysis
  and Simulation of Computer and Telecommunication Systems. This version has
  been submitted to a journal and is waiting for being reviewed</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Stochastic network calculus is a newly developed theory for stochastic
service guarantee analysis of computer networks. In the current stochastic
network calculus literature, its fundamental models are based on the cumulative
amount of traffic or cumulative amount of service. However, there are network
scenarios where direct application of such models is difficult. This paper
presents a temporal approach to stochastic network calculus. The key idea is to
develop models and derive results from the time perspective. Particularly, we
define traffic models and service models based on the cumulative packet
inter-arrival time and the cumulative packet service time, respectively.
Relations among these models as well as with the existing models in the
literature are established. In addition, we prove the basic properties of the
proposed models, such as delay bound and backlog bound, output
characterization, concatenation property and superposition property. These
results form a temporal stochastic network calculus and compliment the existing
results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.2842</identifier>
 <datestamp>2011-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.2842</id><created>2011-12-13</created><authors><author><keyname>Wang</keyname><forenames>Xiumin</forenames></author><author><keyname>Yuen</keyname><forenames>Chau</forenames></author><author><keyname>Xu</keyname><forenames>Yinlong</forenames></author></authors><title>Joint Rate Selection and Wireless Network Coding for Time Critical
  Applications</title><categories>cs.NI</categories><comments>Accepted by 2012 IEEE Wireless Communications and Networking
  Conference (WCNC)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we dynamically select the transmission rate and design
wireless network coding to improve the quality of services such as delay for
time critical applications. With low transmission rate, and hence longer
transmission range, more packets may be encoded together, which increases the
coding opportunity. However, low transmission rate may incur extra transmission
delay, which is intolerable for time critical applications. We design a novel
joint rate selection and wireless network coding (RSNC) scheme with delay
constraint, so as to minimize the total number of packets that miss their
deadlines at the destination nodes. We prove that the proposed problem is
NPhard, and propose a novel graph model and transmission metric which consider
both the heterogenous transmission rates and the packet deadline constraints
during the graph construction. Using the graph model, we mathematically
formulate the problem and design an efficient algorithm to determine the
transmission rate and coding strategy for each transmission. Finally,
simulation results demonstrate the superiority of the RSNC scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.2861</identifier>
 <datestamp>2012-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.2861</id><created>2011-12-13</created><updated>2012-11-19</updated><authors><author><keyname>Freixas</keyname><forenames>Josep</forenames></author><author><keyname>Kurz</keyname><forenames>Sascha</forenames></author></authors><title>On $\alpha$-roughly weighted games</title><categories>math.CO cs.GT</categories><comments>26 pages, 4 tables</comments><msc-class>91B12, 94C10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Gvozdeva, Hemaspaandra, and Slinko (2011) have introduced three hierarchies
for simple games in order to measure the distance of a given simple game to the
class of (roughly) weighted voting games. Their third class
$\mathcal{C}_\alpha$ consists of all simple games permitting a weighted
representation such that each winning coalition has a weight of at least 1 and
each losing coalition a weight of at most $\alpha$. For a given game the
minimal possible value of $\alpha$ is called its critical threshold value. We
continue the work on the critical threshold value, initiated by Gvozdeva et
al., and contribute some new results on the possible values for a given number
of voters as well as some general bounds for restricted subclasses of games. A
strong relation beween this concept and the cost of stability, i.e. the minimum
amount of external payment to ensure stability in a coalitional game, is
uncovered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.2864</identifier>
 <datestamp>2013-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.2864</id><created>2011-12-13</created><updated>2013-02-05</updated><authors><author><keyname>Luttenberger</keyname><forenames>Michael</forenames></author><author><keyname>Schlund</keyname><forenames>Maximilian</forenames></author></authors><title>An Extension of Parikh's Theorem beyond Idempotence</title><categories>cs.FL</categories><msc-class>08A70</msc-class><acm-class>F.4.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The commutative ambiguity of a context-free grammar G assigns to each Parikh
vector v the number of distinct leftmost derivations yielding a word with
Parikh vector v. Based on the results on the generalization of Newton's method
to omega-continuous semirings, we show how to approximate the commutative
ambiguity by means of rational formal power series, and give a lower bound on
the convergence speed of these approximations. From the latter result we deduce
that the commutative ambiguity itself is rational modulo the generalized
idempotence identity k=k+1 (for k some positive integer), and, subsequently,
that it can be represented as a weighted sum of linear sets. This extends
Parikh's well-known result that the commutative image of context-free languages
is semilinear (k=1).
  Based on the well-known relationship between context-free grammars and
algebraic systems over semirings, our results extend the work by Green et al.
on the computation of the provenance of Datalog queries over commutative
omega-continuous semirings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.2892</identifier>
 <datestamp>2013-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.2892</id><created>2011-12-13</created><updated>2013-06-14</updated><authors><author><keyname>Kschischang</keyname><forenames>Frank R.</forenames></author><author><keyname>Lutz</keyname><forenames>Tobias</forenames></author></authors><title>A Constrained Coding Approach to Error-Free Half-Duplex Relay Networks</title><categories>cs.IT math.IT</categories><comments>To appear in IEEE Transactions on Information Theory, 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the broadcast capacity of an infinite-depth tree-structured
network of error-free half-duplex-constrained relays can be achieved using
constrained coding at the source and symbol forwarding at the relays.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.2903</identifier>
 <datestamp>2011-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.2903</id><created>2011-12-13</created><authors><author><keyname>Bagon</keyname><forenames>Shai</forenames></author><author><keyname>Galun</keyname><forenames>Meirav</forenames></author></authors><title>Large Scale Correlation Clustering Optimization</title><categories>cs.CV</categories><comments>9 pages, 6 figures, 1 table</comments><acm-class>G.1.6; I.5.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Clustering is a fundamental task in unsupervised learning. The focus of this
paper is the Correlation Clustering functional which combines positive and
negative affinities between the data points. The contribution of this paper is
two fold: (i) Provide a theoretic analysis of the functional. (ii) New
optimization algorithms which can cope with large scale problems (&gt;100K
variables) that are infeasible using existing methods. Our theoretic analysis
provides a probabilistic generative interpretation for the functional, and
justifies its intrinsic &quot;model-selection&quot; capability. Furthermore, we draw an
analogy between optimizing this functional and the well known Potts energy
minimization. This analogy allows us to suggest several new optimization
algorithms, which exploit the intrinsic &quot;model-selection&quot; capability of the
functional to automatically recover the underlying number of clusters. We
compare our algorithms to existing methods on both synthetic and real data. In
addition we suggest two new applications that are made possible by our
algorithms: unsupervised face identification and interactive multi-object
segmentation by rough boundary delineation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.2930</identifier>
 <datestamp>2011-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.2930</id><created>2011-12-13</created><updated>2011-12-14</updated><authors><author><keyname>Friggstad</keyname><forenames>Zachary</forenames></author></authors><title>Multiple Traveling Salesmen in Asymmetric Metrics</title><categories>cs.DS</categories><comments>19 Pages, 3 Figures. First revision fixes a broken reference and adds
  to the discussion for General 2-ATSPP</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider some generalizations of the Asymmetric Traveling Salesman Path
problem. Suppose we have an asymmetric metric G = (V,A) with two distinguished
nodes s,t. We are also given a positive integer k. The goal is to find k paths
of minimum total cost from s to t whose union spans all nodes. We call this the
k-Person Asymmetric Traveling Salesmen Path problem (k-ATSPP). Our main result
for k-ATSPP is a bicriteria approximation that, for some parameter b &gt;= 1 we
may choose, finds between k and k + k/b paths of total length O(b log |V|)
times the optimum value of an LP relaxation based on the Held-Karp relaxation
for the Traveling Salesman problem. On one extreme this is an O(log
|V|)-approximation that uses up to 2k paths and on the other it is an O(k log
|V|)-approximation that uses exactly k paths.
  Next, we consider the case where we have k pairs of nodes (s_1,t_1), ...,
(s_k,t_k). The goal is to find an s_i-t_i path for every pair such that each
node of G lies on at least one of these paths. Simple approximation algorithms
are presented for the special cases where the metric is symmetric or where s_i
= t_i for each i. We also show that the problem can be approximated within a
factor O(log n) when k=2. On the other hand, we demonstrate that the general
problem cannot be approximated within any bounded ratio unless P = NP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.2949</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.2949</id><created>2011-12-13</created><updated>2012-03-28</updated><authors><author><keyname>Bremner</keyname><forenames>Murray R.</forenames></author><author><keyname>Hu</keyname><forenames>Jiaxiong</forenames></author></authors><title>The fundamental invariants of 3 x 3 x 3 arrays</title><categories>math.AC cs.SC math.CO math.RT</categories><comments>17 pages; revised version has more references, corrected typos, one
  simplified proof, and ancillary files containing the three fundamental
  invariants</comments><msc-class>13A50 (Primary) 15A72, 17B10 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We determine the three fundamental invariants in the entries of a $3 \times 3
\times 3$ array over $\mathbb{C}$ as explicit polynomials in the 27 variables
$x_{ijk}$ for $1 \le i, j, k \le 3$. By the work of Vinberg on $\theta$-groups,
it is known that these homogeneous polynomials have degrees 6, 9 and 12; they
freely generate the algebra of invariants for the Lie group $SL_3(\mathbb{C})
\times SL_3(\mathbb{C}) \times SL_3(\mathbb{C})$ acting irreducibly on its
natural representation $\mathbb{C}^3 \otimes \mathbb{C}^3 \otimes
\mathbb{C}^3$. These generators have respectively 1152, 9216 and 209061 terms;
we find compact expressions in terms of the orbits of the finite group $(S_3
\times S_3 \times S_3) \rtimes S_3$ acting on monomials of weight zero for the
action of the Lie algebra $\mathfrak{sl}_3(\mathbb{C}) \oplus
\mathfrak{sl}_3(\mathbb{C}) \oplus \mathfrak{sl}_3(\mathbb{C})$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.2950</identifier>
 <datestamp>2011-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.2950</id><created>2011-12-13</created><authors><author><keyname>Crolard</keyname><forenames>Tristan</forenames><affiliation>LACL</affiliation></author><author><keyname>Polonowski</keyname><forenames>Emmanuel</forenames><affiliation>LACL</affiliation></author></authors><title>Deriving a Hoare-Floyd logic for non-local jumps from a
  formulae-as-types notion of control</title><categories>cs.LO</categories><comments>The 22nd Nordic Workshop on Programming Theory, Turku : Finland
  (2010)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We derive a Hoare-Floyd logic for non-local jumps and mutable higher-order
procedural variables from a formul{\ae}-as-types notion of control for
classical logic. The main contribution of this work is the design of an
imperative dependent type system for non-local jumps which corresponds to
classical logic but where the famous consequence rule is still derivable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.2954</identifier>
 <datestamp>2012-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.2954</id><created>2011-12-13</created><updated>2012-04-03</updated><authors><author><keyname>Penunuri</keyname><forenames>F.</forenames></author><author><keyname>Peon-Escalante</keyname><forenames>R.</forenames></author><author><keyname>Villanueva</keyname><forenames>C.</forenames></author><author><keyname>Cruz-Villar</keyname><forenames>Carlos A.</forenames></author></authors><title>Synthesis of Spherical 4R Mechanism for Path Generation using
  Differential Evolution</title><categories>cs.CE</categories><comments>Submitted to Mechanism and Machine Theory</comments><journal-ref>Mechanism and Machine Theory 57 (2012) 62-70</journal-ref><doi>10.1016/j.mechmachtheory.2012.07.003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of path generation for the spherical 4R mechanism is solved using
the Differential Evolution algorithm (DE). Formulas for the spherical geodesics
are employed in order to obtain the parametric equation for the generated
trajectory. Direct optimization of the objective function gives the solution to
the path generation task without prescribed timing. Therefore, there is no need
to separate this task into two stages to make the optimization. Moreover, the
order defect problem can be solved without difficulty by means of manipulations
of the individuals in the DE algorithm. Two examples of optimum synthesis
showing the simplicity and effectiveness of this approach are included.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.2957</identifier>
 <datestamp>2015-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.2957</id><created>2011-12-13</created><authors><author><keyname>Schneider</keyname><forenames>Christian M.</forenames></author><author><keyname>Mihaljev</keyname><forenames>Tamara</forenames></author><author><keyname>Herrmann</keyname><forenames>Hans J.</forenames></author></authors><title>Inverse targeting -- an effective immunization strategy</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI physics.comp-ph</categories><doi>10.1209/0295-5075/98/46002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new method to immunize populations or computer networks against
epidemics which is more efficient than any method considered before. The
novelty of our method resides in the way of determining the immunization
targets. First we identify those individuals or computers that contribute the
least to the disease spreading measured through their contribution to the size
of the largest connected cluster in the social or a computer network. The
immunization process follows the list of identified individuals or computers in
inverse order, immunizing first those which are most relevant for the epidemic
spreading. We have applied our immunization strategy to several model networks
and two real networks, the Internet and the collaboration network of high
energy physicists. We find that our new immunization strategy is in the case of
model networks up to 14%, and for real networks up to 33% more efficient than
immunizing dynamically the most connected nodes in a network. Our strategy is
also numerically efficient and can therefore be applied to large systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.2962</identifier>
 <datestamp>2014-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.2962</id><created>2011-12-13</created><authors><author><keyname>Huijse</keyname><forenames>Pablo</forenames></author><author><keyname>Est&#xe9;vez</keyname><forenames>Pablo A.</forenames></author><author><keyname>Zegers</keyname><forenames>Pablo</forenames></author><author><keyname>Pr&#xed;ncipe</keyname><forenames>Jos&#xe9;</forenames></author><author><keyname>Protopapas</keyname><forenames>Pavlos</forenames></author></authors><title>Period Estimation in Astronomical Time Series Using Slotted Correntropy</title><categories>cs.IT astro-ph.IM math.IT stat.ML</categories><journal-ref>IEEE Signal Processing Letters, vol. 18, no. 6, pp. 371-374, year
  2011</journal-ref><doi>10.1109/LSP.2011.2141987</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In this letter, we propose a method for period estimation in light curves
from periodic variable stars using correntropy. Light curves are astronomical
time series of stellar brightness over time, and are characterized as being
noisy and unevenly sampled. We propose to use slotted time lags in order to
estimate correntropy directly from irregularly sampled time series. A new
information theoretic metric is proposed for discriminating among the peaks of
the correntropy spectral density. The slotted correntropy method outperformed
slotted correlation, string length, VarTools (Lomb-Scargle periodogram and
Analysis of Variance), and SigSpec applications on a set of light curves drawn
from the MACHO survey.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.2972</identifier>
 <datestamp>2014-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.2972</id><created>2011-12-13</created><updated>2014-04-13</updated><authors><author><keyname>Jakovetic</keyname><forenames>Dusan</forenames></author><author><keyname>Xavier</keyname><forenames>Joao</forenames></author><author><keyname>Moura</keyname><forenames>Jose M. F.</forenames></author></authors><title>Fast Distributed Gradient Methods</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study distributed optimization problems when $N$ nodes minimize the sum of
their individual costs subject to a common vector variable. The costs are
convex, have Lipschitz continuous gradient (with constant $L$), and bounded
gradient. We propose two fast distributed gradient algorithms based on the
centralized Nesterov gradient algorithm and establish their convergence rates
in terms of the per-node communications $\mathcal{K}$ and the per-node gradient
evaluations $k$. Our first method, Distributed Nesterov Gradient, achieves
rates $O\left({\log \mathcal{K}}/{\mathcal{K}}\right)$ and $O\left({\log
k}/{k}\right)$. Our second method, Distributed Nesterov gradient with Consensus
iterations, assumes at all nodes knowledge of $L$ and $\mu(W)$ -- the second
largest singular value of the $N \times N$ doubly stochastic weight matrix $W$.
It achieves rates $O\left({1}/{\mathcal{K}^{2-\xi}}\right)$ and
$O\left({1}/{k^2}\right)$ ($\xi&gt;0$ arbitrarily small). Further, we give with
both methods explicit dependence of the convergence constants on $N$ and $W$.
Simulation examples illustrate our findings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.2974</identifier>
 <datestamp>2011-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.2974</id><created>2011-12-13</created><authors><author><keyname>Madelaine</keyname><forenames>Florent</forenames></author><author><keyname>Martin</keyname><forenames>Barnaby</forenames></author><author><keyname>Stacho</keyname><forenames>Juraj</forenames></author></authors><title>Constraint Satisfaction with Counting Quantifiers</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We initiate the study of constraint satisfaction problems (CSPs) in the
presence of counting quantifiers, which may be seen as variants of CSPs in the
mould of quantified CSPs (QCSPs). We show that a single counting quantifier
strictly between exists^1:=exists and exists^n:=forall (the domain being of
size n) already affords the maximal possible complexity of QCSPs (which have
both exists and forall), being Pspace-complete for a suitably chosen template.
Next, we focus on the complexity of subsets of counting quantifiers on clique
and cycle templates. For cycles we give a full trichotomy -- all such problems
are in L, NP-complete or Pspace-complete. For cliques we come close to a
similar trichotomy, but one case remains outstanding. Afterwards, we consider
the generalisation of CSPs in which we augment the extant quantifier
exists^1:=exists with the quantifier exists^j (j not 1). Such a CSP is already
NP-hard on non-bipartite graph templates. We explore the situation of this
generalised CSP on bipartite templates, giving various conditions for both
tractability and hardness -- culminating in a classification theorem for
general graphs. Finally, we use counting quantifiers to solve the complexity of
a concrete QCSP whose complexity was previously open.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.2988</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.2988</id><created>2011-12-13</created><updated>2012-06-23</updated><authors><author><keyname>Achler</keyname><forenames>Tsvi</forenames></author></authors><title>Supervised Generative Reconstruction: An Efficient Way To Flexibly Store
  and Recognize Patterns</title><categories>cs.CV</categories><comments>2 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Matching animal-like flexibility in recognition and the ability to quickly
incorporate new information remains difficult. Limits are yet to be adequately
addressed in neural models and recognition algorithms. This work proposes a
configuration for recognition that maintains the same function of conventional
algorithms but avoids combinatorial problems. Feedforward recognition
algorithms such as classical artificial neural networks and machine learning
algorithms are known to be subject to catastrophic interference and forgetting.
Modifying or learning new information (associations between patterns and
labels) causes loss of previously learned information. I demonstrate using
mathematical analysis how supervised generative models, with feedforward and
feedback connections, can emulate feedforward algorithms yet avoid catastrophic
interference and forgetting. Learned information in generative models is stored
in a more intuitive form that represents the fixed points or solutions of the
network and moreover displays similar difficulties as cognitive phenomena.
Brain-like capabilities and limits associated with generative models suggest
the brain may perform recognition and store information using a similar
approach. Because of the central role of recognition, progress understanding
the underlying principles may reveal significant insight on how to better study
and integrate with the brain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.2993</identifier>
 <datestamp>2014-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.2993</id><created>2011-12-13</created><updated>2014-04-05</updated><authors><author><keyname>Heilman</keyname><forenames>Steven</forenames></author><author><keyname>Jagannath</keyname><forenames>Aukosh</forenames></author><author><keyname>Naor</keyname><forenames>Assaf</forenames></author></authors><title>Solution of the propeller conjecture in $\mathbb{R}^3$</title><categories>cs.CC math.FA math.MG</categories><journal-ref>Discrete &amp; Computational Geometry. 50 (2013), no. 2, 263-305</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is shown that every measurable partition ${A_1,..., A_k}$ of
$\mathbb{R}^3$ satisfies $$\sum_{i=1}^k||\int_{A_i}
xe^{-\frac12||x||_2^2}dx||_2^2\le 9\pi^2.\qquad(*)$$ Let ${P_1,P_2,P_3}$ be the
partition of $\mathbb{R}^2$ into $120^\circ$ sectors centered at the origin.
The bound is sharp, with equality holding if $A_i=P_i\times \mathbb{R}$ for
$i\in {1,2,3}$ and $A_i=\emptyset$ for $i\in \{4,...,k\}$ (up to measure zero
corrections, orthogonal transformations and renumbering of the sets
$\{A_1,...,A_k\}$). This settles positively the 3-dimensional Propeller
Conjecture of Khot and Naor (FOCS 2008). The proof of reduces the problem to a
finite set of numerical inequalities which are then verified with full rigor in
a computer-assisted fashion. The main consequence (and motivation) of $(*)$ is
complexity-theoretic: the Unique Games hardness threshold of the Kernel
Clustering problem with $4 \times 4$ centered and spherical hypothesis matrix
equals $\frac{2\pi}{3}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3010</identifier>
 <datestamp>2015-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3010</id><created>2011-12-13</created><updated>2015-02-08</updated><authors><author><keyname>Gurumoorthy</keyname><forenames>Karthik S.</forenames></author><author><keyname>Rangarajan</keyname><forenames>Anand</forenames></author></authors><title>A new variational principle for the Euclidean distance function: Linear
  approach to the non-linear eikonal problem</title><categories>cs.CV math.NA</categories><msc-class>65D18, 65M80</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a fast convolution-based technique for computing an approximate,
signed Euclidean distance function $S$ on a set of 2D and 3D grid locations.
Instead of solving the non-linear, static Hamilton-Jacobi equation ($\|\nabla
S\|=1$), our solution stems from first solving for a scalar field $\phi$ in a
linear differential equation and then deriving the solution for $S$ by taking
the negative logarithm. In other words, when $S$ and $\phi$ are related by
$\phi = \exp \left(-\frac{S}{\tau} \right)$ and $\phi$ satisfies a specific
linear differential equation corresponding to the extremum of a variational
problem, we obtain the approximate Euclidean distance function $S = -\tau
\log(\phi)$ which converges to the true solution in the limit as $\tau
\rightarrow 0$. This is in sharp contrast to techniques like the fast marching
and fast sweeping methods which directly solve the Hamilton-Jacobi equation by
the Godunov upwind discretization scheme. Our linear formulation results in a
closed-form solution to the approximate Euclidean distance function expressible
as a discrete convolution, and hence efficiently computable using the fast
Fourier transform (FFT). Our solution also circumvents the need for spatial
discretization of the derivative operator. As $\tau\rightarrow0$ we show the
convergence of our results to the true solution and also bound the error for a
given value of $\tau$. The differentiability of our solution allows us to
compute---using a set of convolutions---the first and second derivatives of the
approximate distance function. In order to determine the sign of the distance
function (defined to be positive inside a closed region and negative outside),
we compute the winding number in 2D and the topological degree in 3D, whose
computations can also be performed via fast convolutions. We demonstrate the
efficacy of our method through a set of experimental results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3018</identifier>
 <datestamp>2011-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3018</id><created>2011-12-13</created><authors><author><keyname>Tereso</keyname><forenames>Marco</forenames></author><author><keyname>Bernardino</keyname><forenames>Jorge</forenames></author></authors><title>Open Source CRM Systems for SMEs</title><categories>cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Customer Relationship Management (CRM) systems are very common in large
companies. However, CRM systems are not very common in Small and Medium
Enterprises (SMEs). Most SMEs do not implement CRM systems due to several
reasons, such as lack of knowledge about CRM or lack of financial resources to
implement CRM systems. SMEs have to start implementing Information Systems (IS)
technology into their business operations in order to improve business values
and gain more competitive advantage over rivals. CRM system has the potential
to help improve the business value and competitive capabilities of SMEs. Given
the high fixed costs of normal activity of companies, we intend to promote free
and viable solutions for small and medium businesses. In this paper, we explain
the reasons why SMEs do not implement CRM system and the benefits of using open
source CRM system in SMEs. We also describe the functionalities of top open
source CRM systems, examining the applicability of these tools in fitting the
needs of SMEs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3052</identifier>
 <datestamp>2011-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3052</id><created>2011-12-13</created><authors><author><keyname>Honnappa</keyname><forenames>Harsha</forenames></author><author><keyname>Jain</keyname><forenames>Rahul</forenames></author></authors><title>Strategic Arrivals into Queueing Networks: The Network Concert Queueing
  Game</title><categories>cs.GT cs.SY math.OC math.PR</categories><comments>20 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Queueing networks are typically modelled assuming that the arrival process is
exogenous, and unaffected by admission control, scheduling policies, etc. In
many situations, however, users choose the time of their arrival strategically,
taking delay and other metrics into account. In this paper, we develop a
framework to study such strategic arrivals into queueing networks. We start by
deriving a functional strong law of large numbers (FSLLN) approximation to the
queueing network. In the fluid limit derived, we then study the population game
wherein users strategically choose when to arrive, and upon arrival which of
the K queues to join. The queues start service at given times, which can
potentially be different. We characterize the (strategic) arrival process at
each of the queues, and the price of anarchy of the ensuing strategic arrival
game. We then extend the analysis to multiple populations of users, each with a
different cost metric. The equilibrium arrival profile and price of anarchy are
derived. Finally, we present the methodology for exact equilibrium analysis.
This, however, is tractable for only some simple cases such as two users
arriving at a two node queueing network, which we then present.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3053</identifier>
 <datestamp>2011-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3053</id><created>2011-12-13</created><authors><author><keyname>Clairambault</keyname><forenames>Pierre</forenames></author></authors><title>Estimation of the length of interactions in arena game semantics</title><categories>cs.LO</categories><comments>Foundations of Software Science and Computational Structures 14th
  International Conference, FOSSACS 2011, Saarbr\&quot;ucken : Germany (2011)</comments><proxy>ccsd</proxy><doi>10.1007/978-3-642-19805-2_23</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We estimate the maximal length of interactions between strategies in HO/N
game semantics, in the spirit of the work by Schwichtenberg and Beckmann for
the length of reduction in simply typed lambdacalculus. Because of the
operational content of game semantics, the bounds presented here also apply to
head linear reduction on lambda-terms and to the execution of programs by
abstract machines (PAM/KAM), including in presence of computational effects
such as non-determinism or ground type references. The proof proceeds by
extracting from the games model a combinatorial rewriting rule on trees of
natural numbers, which can then be analyzed independently of game semantics or
lambda-calculus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3059</identifier>
 <datestamp>2014-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3059</id><created>2011-12-13</created><authors><author><keyname>Cueva</keyname><forenames>Paul</forenames></author><author><keyname>Hovden</keyname><forenames>Robert</forenames></author><author><keyname>Mundy</keyname><forenames>Julia A.</forenames></author><author><keyname>Xin</keyname><forenames>Huolin L.</forenames></author><author><keyname>Muller</keyname><forenames>David A.</forenames></author></authors><title>Data Processing For Atomic Resolution EELS</title><categories>cond-mat.mtrl-sci cs.CV physics.data-an</categories><journal-ref>Microscopy and Microanalysis, Vol. 18 pp 667-675 (2012)</journal-ref><doi>10.1017/S1431927612000244</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The high beam current and sub-angstrom resolution of aberration-corrected
scanning transmission electron microscopes has enabled electron energy loss
spectroscopic (EELS) mapping with atomic resolution. These spectral maps are
often dose-limited and spatially oversampled, leading to low counts/channel and
are thus highly sensitive to errors in background estimation. However, by
taking advantage of redundancy in the dataset map one can improve background
estimation and increase chemical sensitivity. We consider two such approaches-
linear combination of power laws and local background averaging-that reduce
background error and improve signal extraction. Principal components analysis
(PCA) can also be used to analyze spectrum images, but the poor
peak-to-background ratio in EELS can lead to serious artifacts if raw EELS data
is PCA filtered. We identify common artifacts and discuss alternative
approaches. These algorithms are implemented within the Cornell Spectrum
Imager, an open source software package for spectroscopic analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3062</identifier>
 <datestamp>2011-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3062</id><created>2011-12-13</created><authors><author><keyname>Ney</keyname><forenames>Miriam</forenames></author><author><keyname>Kloss</keyname><forenames>Guy K.</forenames></author><author><keyname>Schreiber</keyname><forenames>Andreas</forenames></author></authors><title>Using Provenance to support Good Laboratory Practice in Grid
  Environments</title><categories>cs.DC cs.CE cs.DB</categories><comments>Book Chapter for &quot;Data Provenance and Data Management for eScience,&quot;
  of Studies in Computational Intelligence series, Springer. 25 pages, 8
  figures</comments><acm-class>C.2.4; H.3.4; H.5.3; H.2.1; K.4.3; E.5</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Conducting experiments and documenting results is daily business of
scientists. Good and traceable documentation enables other scientists to
confirm procedures and results for increased credibility. Documentation and
scientific conduct are regulated and termed as &quot;good laboratory practice.&quot;
Laboratory notebooks are used to record each step in conducting an experiment
and processing data. Originally, these notebooks were paper based. Due to
computerised research systems, acquired data became more elaborate, thus
increasing the need for electronic notebooks with data storage, computational
features and reliable electronic documentation. As a new approach to this, a
scientific data management system (DataFinder) is enhanced with features for
traceable documentation. Provenance recording is used to meet requirements of
traceability, and this information can later be queried for further analysis.
DataFinder has further important features for scientific documentation: It
employs a heterogeneous and distributed data storage concept. This enables
access to different types of data storage systems (e. g. Grid data
infrastructure, file servers). In this chapter we describe a number of building
blocks that are available or close to finished development. These components
are intended for assembling an electronic laboratory notebook for use in Grid
environments, while retaining maximal flexibility on usage scenarios as well as
maximal compatibility overlap towards each other. Through the usage of such a
system, provenance can successfully be used to trace the scientific workflow of
preparation, execution, evaluation, interpretation and archiving of research
data. The reliability of research results increases and the research process
remains transparent to remote research partners.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3066</identifier>
 <datestamp>2011-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3066</id><created>2011-12-13</created><authors><author><keyname>Ensor</keyname><forenames>Andrew</forenames></author><author><keyname>Lillo</keyname><forenames>Felipe</forenames></author></authors><title>Counting the Number of Minimal Paths in Weighted Coloured-Edge Graphs</title><categories>math.CO cs.DM</categories><msc-class>05C38, 05C22</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A weighted coloured-edge graph is a graph for which each edge is assigned
both a positive weight and a discrete colour, and can be used to model
transportation and computer networks in which there are multiple transportation
modes. In such a graph paths are compared by their total weight in each colour,
resulting in a Pareto set of minimal paths from one vertex to another. This
paper will give a tight upper bound on the cardinality of a minimal set of
paths for any weighted coloured-edge graph. Additionally, a bound is presented
on the expected number of minimal paths in weighted bicoloured-edge graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3096</identifier>
 <datestamp>2015-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3096</id><created>2011-12-13</created><authors><author><keyname>Wang</keyname><forenames>Rui</forenames></author><author><keyname>Tao</keyname><forenames>Meixia</forenames></author></authors><title>Joint Source and Relay Precoding Designs for MIMO Two-Way Relaying Based
  on MSE Criterion</title><categories>cs.IT math.IT</categories><comments>32 pages, 10 figures</comments><doi>10.1109/TSP.2011.2178598</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Properly designed precoders can significantly improve the spectral efficiency
of multiple-input multiple-output (MIMO) relay systems. In this paper, we
investigate joint source and relay precoding design based on the
mean-square-error (MSE) criterion in MIMO two-way relay systems, where two
multi-antenna source nodes exchange information via a multi-antenna
amplify-and-forward relay node. This problem is non-convex and its optimal
solution remains unsolved. Aiming to find an efficient way to solve the
problem, we first decouple the primal problem into three tractable
sub-problems, and then propose an iterative precoding design algorithm based on
alternating optimization. The solution to each sub-problem is optimal and
unique, thus the convergence of the iterative algorithm is guaranteed.
Secondly, we propose a structured precoding design to lower the computational
complexity. The proposed precoding structure is able to parallelize the
channels in the multiple access (MAC) phase and broadcast (BC) phase. It thus
reduces the precoding design to a simple power allocation problem. Lastly, for
the special case where only a single data stream is transmitted from each
source node, we present a source-antenna-selection (SAS) based precoding design
algorithm. This algorithm selects only one antenna for transmission from each
source and thus requires lower signalling overhead. Comprehensive simulation is
conducted to evaluate the effectiveness of all the proposed precoding designs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3110</identifier>
 <datestamp>2011-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3110</id><created>2011-12-13</created><authors><author><keyname>Ensor</keyname><forenames>Andrew</forenames></author><author><keyname>Hall</keyname><forenames>Seth</forenames></author></authors><title>GPU-based Image Analysis on Mobile Devices</title><categories>cs.GR cs.CV</categories><comments>Proceedings of Image and Vision Computing New Zealand 2011</comments><acm-class>I.3.1; I.4.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the rapid advances in mobile technology many mobile devices are capable
of capturing high quality images and video with their embedded camera. This
paper investigates techniques for real-time processing of the resulting images,
particularly on-device utilizing a graphical processing unit. Issues and
limitations of image processing on mobile devices are discussed, and the
performance of graphical processing units on a range of devices measured
through a programmable shader implementation of Canny edge detection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3115</identifier>
 <datestamp>2011-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3115</id><created>2011-12-13</created><authors><author><keyname>Whitacre</keyname><forenames>James M.</forenames></author><author><keyname>Atamas</keyname><forenames>Sergei P.</forenames></author></authors><title>The Diversity Paradox: How Nature Resolves an Evolutionary Dilemma</title><categories>nlin.AO cs.AI q-bio.PE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Adaptation to changing environments is a hallmark of biological systems.
Diversity in traits is necessary for adaptation and can influence the survival
of a population faced with novelty. In habitats that remain stable over many
generations, stabilizing selection reduces trait differences within
populations, thereby appearing to remove the diversity needed for heritable
adaptive responses in new environments. Paradoxically, field studies have
documented numerous populations under long periods of stabilizing selection and
evolutionary stasis that have rapidly evolved under changed environmental
conditions. In this article, we review how cryptic genetic variation (CGV)
resolves this diversity paradox by allowing populations in a stable environment
to gradually accumulate hidden genetic diversity that is revealed as trait
differences when environments change. Instead of being in conflict,
environmental stasis supports CGV accumulation and thus appears to facilitate
rapid adaptation in new environments as suggested by recent CGV studies.
Similarly, degeneracy has been found to support both genetic and non-genetic
adaptation at many levels of biological organization. Degenerate, as opposed to
diverse or redundant, ensembles appear functionally redundant in certain
environmental contexts but functionally diverse in others. CGV and degeneracy
paradigms for adaptation are integrated in this review, revealing a common set
of principles that support adaptation at multiple levels of biological
organization. Though a discussion of simulation studies, molecular-based
experimental systems, principles from population genetics, and field
experiments, we demonstrate that CGV and degeneracy reflect complementary
top-down and bottom-up, respectively, conceptualizations of the same basic
phenomenon and arguably capture a universal feature of biological adaptive
processes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3117</identifier>
 <datestamp>2011-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3117</id><created>2011-12-13</created><authors><author><keyname>Whitacre</keyname><forenames>James</forenames></author><author><keyname>Bender</keyname><forenames>Axel</forenames></author></authors><title>Pervasive Flexibility in Living Technologies through Degeneracy Based
  Design</title><categories>nlin.AO cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The capacity to adapt can greatly influence the success of systems that need
to compensate for damaged parts, learn how to achieve robust performance in new
environments, or exploit novel opportunities that originate from new
technological interfaces or emerging markets. Many of the conditions in which
technology is required to adapt cannot be anticipated during its design stage,
creating a significant challenge for the designer. Inspired by the study of a
range of biological systems, we propose that degeneracy - the realization of
multiple, functionally versatile components with contextually overlapping
functional redundancy - will support adaptation in technologies because it
effects pervasive flexibility, evolutionary innovation, and homeostatic
robustness. We provide examples of degeneracy in a number of rudimentary living
technologies from military socio-technical systems to swarm robotics and we
present design principles - including protocols, loose regulatory coupling, and
functional versatility - that allow degeneracy to arise in both biological and
man-made systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3134</identifier>
 <datestamp>2011-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3134</id><created>2011-12-14</created><authors><author><keyname>Feizi-Derakhshi</keyname><forenames>Mohammad-Reza</forenames></author><author><keyname>Roohany</keyname><forenames>Azade</forenames></author></authors><title>Proposing Cluster_Similarity Method in Order to Find as Much Better
  Similarities in Databases</title><categories>cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Different ways of entering data into databases result in duplicate records
that cause increasing of databases' size. This is a fact that we cannot ignore
it easily. There are several methods that are used for this purpose. In this
paper, we have tried to increase the accuracy of operations by using cluster
similarity instead of direct similarity of fields. So that clustering is done
on fields of database and according to accomplished clustering on fields,
similarity degree of records is obtained. In this method by using present
information in database, more logical similarity is obtained for deficient
information that in general, the method of cluster similarity could improve
operations 24% compared with previous methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3138</identifier>
 <datestamp>2012-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3138</id><created>2011-12-14</created><authors><author><keyname>Alibart</keyname><forenames>F.</forenames></author><author><keyname>Pleutin</keyname><forenames>S.</forenames></author><author><keyname>Bichler</keyname><forenames>O.</forenames></author><author><keyname>Gamrat</keyname><forenames>C.</forenames></author><author><keyname>Serrano-Gotarredona</keyname><forenames>T.</forenames></author><author><keyname>Linares-Barranco</keyname><forenames>B.</forenames></author><author><keyname>Vuillaume</keyname><forenames>D.</forenames></author></authors><title>A memristive nanoparticle/organic hybrid synapstor for neuro-inspired
  computing</title><categories>cond-mat.mes-hall cond-mat.dis-nn cond-mat.mtrl-sci cs.ET q-bio.NC</categories><comments>A single pdf file, with the full paper and the supplementary
  information; Adv. Func. Mater., on line Dec. 13 (2011)</comments><journal-ref>Adv. Func. Mater., 22, 609-616 (2012)</journal-ref><doi>10.1002/adfm.201101935</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A large effort is devoted to the research of new computing paradigms
associated to innovative nanotechnologies that should complement and/or propose
alternative solutions to the classical Von Neumann/CMOS association. Among
various propositions, Spiking Neural Network (SNN) seems a valid candidate. (i)
In terms of functions, SNN using relative spike timing for information coding
are deemed to be the most effective at taking inspiration from the brain to
allow fast and efficient processing of information for complex tasks in
recognition or classification. (ii) In terms of technology, SNN may be able to
benefit the most from nanodevices, because SNN architectures are intrinsically
tolerant to defective devices and performance variability. Here we demonstrate
Spike-Timing-Dependent Plasticity (STDP), a basic and primordial learning
function in the brain, with a new class of synapstor (synapse-transistor),
called Nanoparticle Organic Memory Field Effect Transistor (NOMFET). We show
that this learning function is obtained with a simple hybrid material made of
the self-assembly of gold nanoparticles and organic semiconductor thin films.
Beyond mimicking biological synapses, we also demonstrate how the shape of the
applied spikes can tailor the STDP learning function. Moreover, the experiments
and modeling show that this synapstor is a memristive device. Finally, these
synapstors are successfully coupled with a CMOS platform emulating the pre- and
post-synaptic neurons, and a behavioral macro-model is developed on usual
device simulator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3153</identifier>
 <datestamp>2013-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3153</id><created>2011-12-14</created><updated>2013-01-01</updated><authors><author><keyname>Wu</keyname><forenames>Baofeng</forenames></author><author><keyname>Zhou</keyname><forenames>Kai</forenames></author><author><keyname>Liu</keyname><forenames>Zhuojun</forenames></author></authors><title>A new proof to complexity of dual basis of a type I optimal normal basis</title><categories>cs.DM math.CO</categories><comments>7 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The complexity of dual basis of a type I optimal normal basis of
$\mathbb{F}_{q^n}$ over $\mathbb{F}_{q}$ was determined to be $3n-3$ or $3n-2$
according as $q$ is even or odd, respectively, by Z.-X. Wan and K. Zhou in
2007. We give a new proof to this result by clearly deriving the dual of a type
I optimal normal basis with the aid of a lemma on the dual of a polynomial
basis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3166</identifier>
 <datestamp>2012-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3166</id><created>2011-12-14</created><updated>2012-11-29</updated><authors><author><keyname>Sommer</keyname><forenames>Stefan</forenames></author><author><keyname>Nielsen</keyname><forenames>Mads</forenames></author><author><keyname>Darkner</keyname><forenames>Sune</forenames></author><author><keyname>Pennec</keyname><forenames>Xavier</forenames></author></authors><title>Higher-Order Momentum Distributions and Locally Affine LDDMM
  Registration</title><categories>cs.CV cs.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To achieve sparse parametrizations that allows intuitive analysis, we aim to
represent deformation with a basis containing interpretable elements, and we
wish to use elements that have the description capacity to represent the
deformation compactly. To accomplish this, we introduce in this paper
higher-order momentum distributions in the LDDMM registration framework. While
the zeroth order moments previously used in LDDMM only describe local
displacement, the first-order momenta that are proposed here represent a basis
that allows local description of affine transformations and subsequent compact
description of non-translational movement in a globally non-rigid deformation.
The resulting representation contains directly interpretable information from
both mathematical and modeling perspectives. We develop the mathematical
construction of the registration framework with higher-order momenta, we show
the implications for sparse image registration and deformation description, and
we provide examples of how the parametrization enables registration with a very
low number of parameters. The capacity and interpretability of the
parametrization using higher-order momenta lead to natural modeling of
articulated movement, and the method promises to be useful for quantifying
ventricle expansion and progressing atrophy during Alzheimer's disease.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3168</identifier>
 <datestamp>2011-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3168</id><created>2011-12-14</created><authors><author><keyname>Bilotta</keyname><forenames>Stefano</forenames></author><author><keyname>Pergola</keyname><forenames>Elisa</forenames></author><author><keyname>Pinzani</keyname><forenames>Renzo</forenames></author></authors><title>A new approach to cross-bifix-free sets</title><categories>cs.FL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cross-bifix-free sets are sets of words such that no prefix of any word is a
suffix of any other word. In this paper, we introduce a general constructive
method for the sets of cross-bifix-free binary words of fixed length. It
enables us to determine a cross-bifix-free words subset which has the property
to be non-expandable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3173</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3173</id><created>2011-12-14</created><updated>2012-01-02</updated><authors><author><keyname>Norousi</keyname><forenames>Ramin</forenames></author><author><keyname>Wickles</keyname><forenames>Stephan</forenames></author><author><keyname>Becker</keyname><forenames>Thomas</forenames></author><author><keyname>Beckmann</keyname><forenames>Roland</forenames></author><author><keyname>Schmid</keyname><forenames>Volker J.</forenames></author><author><keyname>Tresch</keyname><forenames>Achim</forenames></author></authors><title>Automatic post-picking improves particle image detection from Cryo-EM
  micrographs</title><categories>cs.CV q-bio.BM</categories><comments>14 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cryo-electron microscopy (cryo-EM) studies using single particle
reconstruction is extensively used to reveal structural information of
macromolecular complexes. Aiming at the highest achievable resolution, state of
the art electron microscopes acquire thousands of high-quality images. Having
collected these data, each single particle must be detected and windowed out.
Several fully- or semi-automated approaches have been developed for the
selection of particle images from digitized micrographs. However they still
require laborious manual post processing, which will become the major
bottleneck for next generation of electron microscopes. Instead of focusing on
improvements in automated particle selection from micrographs, we propose a
post-picking step for classifying small windowed images, which are output by
common picking software. A supervised strategy for the classification of
windowed micrograph images into particles and non-particles reduces the manual
workload by orders of magnitude. The method builds on new powerful image
features, and the proper training of an ensemble classifier. A few hundred
training samples are enough to achieve a human-like classification performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3198</identifier>
 <datestamp>2011-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3198</id><created>2011-12-14</created><authors><author><keyname>Clairambault</keyname><forenames>Pierre</forenames></author></authors><title>Isomorphisms of types in the presence of higher-order references</title><categories>cs.LO cs.GT</categories><comments>Twenty-Sixth Annual IEEE Symposium on Logic In Computer Science (LICS
  2011), Toronto : Canada (2011)</comments><proxy>ccsd</proxy><doi>10.1109/LICS.2011.32</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the problem of type isomorphisms in a programming language
with higher-order references. We first recall the game-theoretic model of
higher-order references by Abramsky, Honda and McCusker. Solving an open
problem by Laurent, we show that two finitely branching arenas are isomorphic
if and only if they are geometrically the same, up to renaming of moves
(Laurent's forest isomorphism). We deduce from this an equational theory
characterizing isomorphisms of types in a finitary language with higher order
references. We show however that Laurent's conjecture does not hold on
infinitely branching arenas, yielding a non-trivial type isomorphism in the
extension of this language with natural numbers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3208</identifier>
 <datestamp>2012-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3208</id><created>2011-12-14</created><updated>2012-09-05</updated><authors><author><keyname>Aktas</keyname><forenames>Tugcan</forenames></author><author><keyname>Yilmaz</keyname><forenames>A. Ozgur</forenames></author><author><keyname>Aktas</keyname><forenames>Emre</forenames></author></authors><title>Practical Methods for Wireless Network Coding with Multiple Unicast
  Transmissions</title><categories>cs.IT math.IT</categories><comments>29 pages, 9 figures, Submitted to the IEEE Transactions on
  Communications on 14.12.2011, revised on 18.05.2012 and on 04.09.2012. arXiv
  admin note: text overlap with arXiv:1110.0594</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a simple yet effective wireless network coding and decoding
technique for a multiple unicast network. It utilizes spatial diversity through
cooperation between nodes which carry out distributed encoding operations
dictated by generator matrices of linear block codes. In order to exemplify the
technique, we make use of greedy codes over the binary field and show that the
arbitrary diversity orders can be flexibly assigned to nodes. Furthermore, we
present the optimal detection rule for the given model that accounts for
intermediate node errors and suggest a low-complexity network decoder using the
sum-product (SP) algorithm. The proposed SP detector exhibits near optimal
performance. We also show asymptotic superiority of network coding over a
method that utilizes the wireless channel in a repetitive manner without
network coding (NC) and give related rate-diversity trade-off curves. Finally,
we extend the given encoding method through selective encoding in order to
obtain extra coding gains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3212</identifier>
 <datestamp>2011-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3212</id><created>2011-12-14</created><authors><author><keyname>Liu</keyname><forenames>Zhong</forenames></author><author><keyname>Chen</keyname><forenames>Shengyao</forenames></author><author><keyname>Xi</keyname><forenames>Feng</forenames></author></authors><title>A Compressed Sensing Framework of Frequency-Sparse Signals through
  Chaotic Systems</title><categories>cs.IT math.IT nlin.CD</categories><comments>20 pages, 10 figures, submitted to international journal of
  bifurcation and chaos</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a compressed sensing (CS) framework for the acquisition
and reconstruction of frequency-sparse signals with chaotic dynamical systems.
The sparse signal is acting as an excitation term of a discrete-time chaotic
system and the compressed measurement is obtained by downsampling the system
output. The reconstruction is realized through the estimation of the excitation
coefficients with principle of impulsive chaos synchronization. The -norm
regularized nonlinear least squares is used to find the estimation. The
proposed framework is easily implementable and creates secure measurements. The
Henon map is used as an example to illustrate the principle and the
performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3244</identifier>
 <datestamp>2011-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3244</id><created>2011-12-14</created><updated>2011-12-16</updated><authors><author><keyname>Fomin</keyname><forenames>Fedor V.</forenames></author><author><keyname>Gaspers</keyname><forenames>Serge</forenames></author><author><keyname>Golovach</keyname><forenames>Petr</forenames></author><author><keyname>Suchan</keyname><forenames>Karol</forenames></author><author><keyname>Szeider</keyname><forenames>Stefan</forenames></author><author><keyname>van Leeuwen</keyname><forenames>Erik Jan</forenames></author><author><keyname>Vatshelle</keyname><forenames>Martin</forenames></author><author><keyname>Villanger</keyname><forenames>Yngve</forenames></author></authors><title>k-Gap Interval Graphs</title><categories>cs.DS cs.CC cs.DM</categories><comments>LATIN 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We initiate the study of a new parameterization of graph problems. In a
multiple interval representation of a graph, each vertex is associated to at
least one interval of the real line, with an edge between two vertices if and
only if an interval associated to one vertex has a nonempty intersection with
an interval associated to the other vertex. A graph on n vertices is a k-gap
interval graph if it has a multiple interval representation with at most n+k
intervals in total. In order to scale up the nice algorithmic properties of
interval graphs (where k=0), we parameterize graph problems by k, and find FPT
algorithms for several problems, including Feedback Vertex Set, Dominating Set,
Independent Set, Clique, Clique Cover, and Multiple Interval Transversal. The
Coloring problem turns out to be W[1]-hard and we design an XP algorithm for
the recognition problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3257</identifier>
 <datestamp>2012-10-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3257</id><created>2011-12-14</created><updated>2012-10-09</updated><authors><author><keyname>Perduca</keyname><forenames>Vittorio</forenames></author><author><keyname>Nuel</keyname><forenames>Gr&#xe9;gory</forenames></author></authors><title>Exact Computation of Kullback-Leibler Distance for Hidden Markov Trees
  and Models</title><categories>cs.IT math.IT</categories><comments>The present work is currently undergoing a major revision; a new
  version will be soon updated. Please do not use the present version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We suggest new recursive formulas to compute the exact value of the
Kullback-Leibler distance (KLD) between two general Hidden Markov Trees (HMTs).
For homogeneous HMTs with regular topology, such as homogeneous Hidden Markov
Models (HMMs), we obtain a closed-form expression for the KLD when no evidence
is given. We generalize our recursive formulas to the case of HMMs conditioned
on the observable variables. Our proposed formulas are validated through
several numerical examples in which we compare the exact KLD value with Monte
Carlo estimations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3265</identifier>
 <datestamp>2012-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3265</id><created>2011-12-14</created><updated>2012-06-22</updated><authors><author><keyname>Gong</keyname><forenames>Neil Zhenqiang</forenames><affiliation>Runting</affiliation></author><author><keyname>Talwalkar</keyname><forenames>Ameet</forenames><affiliation>Runting</affiliation></author><author><keyname>Mackey</keyname><forenames>Lester</forenames><affiliation>Runting</affiliation></author><author><keyname>Huang</keyname><forenames>Ling</forenames><affiliation>Runting</affiliation></author><author><keyname>Shin</keyname><forenames>Eui Chul Richard</forenames><affiliation>Runting</affiliation></author><author><keyname>Stefanov</keyname><forenames>Emil</forenames><affiliation>Runting</affiliation></author><author><keyname>Elaine</keyname><affiliation>Runting</affiliation></author><author><keyname>Shi</keyname></author><author><keyname>Song</keyname><forenames>Dawn</forenames></author></authors><title>Jointly Predicting Links and Inferring Attributes using a
  Social-Attribute Network (SAN)</title><categories>cs.SI physics.soc-ph</categories><comments>9 pages, 4 figures and 4 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The effects of social influence and homophily suggest that both network
structure and node attribute information should inform the tasks of link
prediction and node attribute inference. Recently, Yin et al. proposed
Social-Attribute Network (SAN), an attribute-augmented social network, to
integrate network structure and node attributes to perform both link prediction
and attribute inference. They focused on generalizing the random walk with
restart algorithm to the SAN framework and showed improved performance. In this
paper, we extend the SAN framework with several leading supervised and
unsupervised link prediction algorithms and demonstrate performance improvement
for each algorithm on both link prediction and attribute inference. Moreover,
we make the novel observation that attribute inference can help inform link
prediction, i.e., link prediction accuracy is further improved by first
inferring missing attributes. We comprehensively evaluate these algorithms and
compare them with other existing algorithms using a novel, large-scale Google+
dataset, which we make publicly available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3307</identifier>
 <datestamp>2011-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3307</id><created>2011-12-14</created><authors><author><keyname>Kosut</keyname><forenames>Oliver</forenames></author><author><keyname>Tong</keyname><forenames>Lang</forenames></author><author><keyname>Tse</keyname><forenames>David</forenames></author></authors><title>Polytope Codes Against Adversaries in Networks</title><categories>cs.IT math.IT</categories><comments>63 pages. Submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Network coding is studied when an adversary controls a subset of nodes in the
network of limited quantity but unknown location. This problem is shown to be
more difficult than when the adversary controls a given number of edges in the
network, in that linear codes are insufficient. To solve the node problem, the
class of Polytope Codes is introduced. Polytope Codes are constant composition
codes operating over bounded polytopes in integer vector fields. The polytope
structure creates additional complexity, but it induces properties on marginal
distributions of code vectors so that validities of codewords can be checked by
internal nodes of the network. It is shown that Polytope Codes achieve a
cut-set bound for a class of planar networks. It is also shown that this
cut-set bound is not always tight, and a tighter bound is given for an example
network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3308</identifier>
 <datestamp>2012-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3308</id><created>2011-12-14</created><updated>2012-05-31</updated><authors><author><keyname>Cerina</keyname><forenames>Federica</forenames></author><author><keyname>De Leo</keyname><forenames>Vincenzo</forenames></author><author><keyname>Barthelemy</keyname><forenames>Marc</forenames></author><author><keyname>Chessa</keyname><forenames>Alessandro</forenames></author></authors><title>Spatial correlations in attribute communities</title><categories>physics.soc-ph cs.SI</categories><comments>10 pages and 7 figures</comments><journal-ref>PLoS ONE 7(5): e37507 (2012)</journal-ref><doi>10.1371/journal.pone.0037507</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Community detection is an important tool for exploring and classifying the
properties of large complex networks and should be of great help for spatial
networks. Indeed, in addition to their location, nodes in spatial networks can
have attributes such as the language for individuals, or any other
socio-economical feature that we would like to identify in communities. We
discuss in this paper a crucial aspect which was not considered in previous
studies which is the possible existence of correlations between space and
attributes. Introducing a simple toy model in which both space and node
attributes are considered, we discuss the effect of space-attribute
correlations on the results of various community detection methods proposed for
spatial networks in this paper and in previous studies. When space is
irrelevant, our model is equivalent to the stochastic block model which has
been shown to display a detectability-non detectability transition. In the
regime where space dominates the link formation process, most methods can fail
to recover the communities, an effect which is particularly marked when
space-attributes correlations are strong. In this latter case, community
detection methods which remove the spatial component of the network can miss a
large part of the community structure and can lead to incorrect results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3323</identifier>
 <datestamp>2011-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3323</id><created>2011-12-14</created><authors><author><keyname>Klassen</keyname><forenames>Toryn Qwyllyn</forenames></author><author><keyname>Woelfel</keyname><forenames>Philipp</forenames></author></authors><title>Independence of Tabulation-Based Hash Classes</title><categories>cs.DS</categories><comments>12 pages with 2 page appendix showing experimental results</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A tabulation-based hash function maps a key into d derived characters
indexing random values in tables that are then combined with bitwise xor
operations to give the hash. Thorup and Zhang (2004) presented d-wise
independent tabulation-based hash classes that use linear maps over finite
fields to map a key, considered as a vector (a,b), to derived characters. We
show that a variant where the derived characters are a+b*i for i=0,..., q-1
(using integer arithmetic) yielding (2d-1)-wise independence. Our analysis is
based on an algebraic property that characterizes k-wise independence of
tabulation-based hashing schemes, and combines this characterization with a
geometric argument. We also prove a non-trivial lower bound on the number of
derived characters necessary for k-wise independence with our and related hash
classes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3324</identifier>
 <datestamp>2015-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3324</id><created>2011-12-14</created><authors><author><keyname>Hoffmann</keyname><forenames>Till</forenames></author><author><keyname>Porter</keyname><forenames>Mason A.</forenames></author><author><keyname>Lambiotte</keyname><forenames>Renaud</forenames></author></authors><title>Generalized Master Equations for Non-Poisson Dynamics on Networks</title><categories>physics.soc-ph cs.SI math.DS</categories><journal-ref>Phys. Rev. E 86, 046102 (2012)</journal-ref><doi>10.1103/PhysRevE.86.046102</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The traditional way of studying temporal networks is to aggregate the
dynamics of the edges to create a static weighted network. This implicitly
assumes that the edges are governed by Poisson processes, which is not
typically the case in empirical temporal networks. Consequently, we examine the
effects of non-Poisson inter-event statistics on the dynamics of edges, and we
apply the concept of a generalized master equation to the study of
continuous-time random walks on networks. We show that the equation reduces to
the standard rate equations when the underlying process is Poisson and that the
stationary solution is determined by an effective transition matrix whose
leading eigenvector is easy to calculate. We discuss the implications of our
work for dynamical processes on temporal networks and for the construction of
network diagnostics that take into account their nontrivial stochastic nature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3330</identifier>
 <datestamp>2011-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3330</id><created>2011-12-14</created><authors><author><keyname>Ambainis</keyname><forenames>Andris</forenames></author><author><keyname>Backurs</keyname><forenames>Arturs</forenames></author><author><keyname>Balodis</keyname><forenames>Kaspars</forenames></author><author><keyname>Kravcenko</keyname><forenames>Dmitry</forenames></author><author><keyname>Ozols</keyname><forenames>Raitis</forenames></author><author><keyname>Smotrovs</keyname><forenames>Juris</forenames></author><author><keyname>Virza</keyname><forenames>Madars</forenames></author></authors><title>Quantum strategies are better than classical in almost any XOR game</title><categories>quant-ph cs.GT</categories><comments>22 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We initiate a study of random instances of nonlocal games. We show that
quantum strategies are better than classical for almost any 2-player XOR game.
More precisely, for large n, the entangled value of a random 2-player XOR game
with n questions to every player is at least 1.21... times the classical value,
for 1-o(1) fraction of all 2-player XOR games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3337</identifier>
 <datestamp>2011-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3337</id><created>2011-12-14</created><authors><author><keyname>Ambainis</keyname><forenames>Andris</forenames></author><author><keyname>Backurs</keyname><forenames>Arturs</forenames></author><author><keyname>Nahimovs</keyname><forenames>Nikolajs</forenames></author><author><keyname>Ozols</keyname><forenames>Raitis</forenames></author><author><keyname>Rivosh</keyname><forenames>Alexander</forenames></author></authors><title>Search by quantum walks on two-dimensional grid without amplitude
  amplification</title><categories>quant-ph cs.CC cs.DS</categories><comments>22 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study search by quantum walk on a finite two dimensional grid. The
algorithm of Ambainis, Kempe, Rivosh (quant-ph/0402107) takes O(\sqrt{N log N})
steps and finds a marked location with probability O(1/log N) for grid of size
\sqrt{N} * \sqrt{N}. This probability is small, thus amplitude amplification is
needed to achieve \Theta(1) success probability. The amplitude amplification
adds an additional O(\sqrt{log N}) factor to the number of steps, making it
O(\sqrt{N} log N).
  In this paper, we show that despite a small probability to find a marked
location, the probability to be within an O(\sqrt{N}) neighbourhood (at an
O(\sqrt[4]{N}) distance) of the marked location is \Theta(1). This allows to
skip amplitude amplification step and leads to an O(\sqrt{log N}) speed-up.
  We describe the results of numerical experiments supporting this idea, and we
prove this fact analytically.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3353</identifier>
 <datestamp>2011-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3353</id><created>2011-12-14</created><authors><author><keyname>Heldt</keyname><forenames>Daniel</forenames></author><author><keyname>Knauer</keyname><forenames>Kolja</forenames></author><author><keyname>Ueckerdt</keyname><forenames>Torsten</forenames></author></authors><title>On the bend-number of planar and outerplanar graphs</title><categories>math.CO cs.DM</categories><comments>appears in proceedings of 10th Latin American Symposium on
  Theoretical Informatics (LATIN 2012)</comments><msc-class>05C62</msc-class><acm-class>G.2.1; F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The bend-number b(G) of a graph G is the minimum k such that G may be
represented as the edge intersection graph of a set of grid paths with at most
k bends. We confirm a conjecture of Biedl and Stern showing that the maximum
bend-number of outerplanar graphs is 2. Moreover we improve the formerly known
lower and upper bound for the maximum bend-number of planar graphs from 2 and 5
to 3 and 4, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3366</identifier>
 <datestamp>2011-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3366</id><created>2011-12-14</created><authors><author><keyname>Ensor</keyname><forenames>Andrew</forenames></author><author><keyname>Lillo</keyname><forenames>Felipe</forenames></author></authors><title>Partial order approach to compute shortest paths in multimodal networks</title><categories>cs.OH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many networked systems involve multiple modes of transport. Such systems are
called multimodal, and examples include logistic networks, biomedical
phenomena, manufacturing process and telecommunication networks. Existing
techniques for determining optimal paths in multimodal networks have either
required heuristics or else application-specific constraints to obtain
tractable problems, removing the multimodal traits of the network during
analysis. In this paper weighted coloured--edge graphs are introduced to model
multimodal networks, where colours represent the modes of transportation.
Optimal paths are selected using a partial order that compares the weights in
each colour, resulting in a Pareto optimal set of shortest paths. This approach
is shown to be tractable through experimental analyses for random and real
multimodal networks without the need to apply heuristics or constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3415</identifier>
 <datestamp>2012-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3415</id><created>2011-12-14</created><authors><author><keyname>Yagan</keyname><forenames>Osman</forenames></author></authors><title>Performance of the Eschenauer-Gligor key distribution scheme under an
  ON/OFF channel</title><categories>cs.IT math.CO math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory in November,
  2011</comments><journal-ref>IEEE Transactions on Information Theory, Volume: 58, Issue: 6
  Pages: 3821-3835, June 2012</journal-ref><doi>10.1109/TIT.2012.2189353</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the secure connectivity of wireless sensor networks under the
random key distribution scheme of Eschenauer and Gligor. Unlike recent work
which was carried out under the assumption of full visibility, here we assume a
(simplified) communication model where unreliable wireless links are
represented as on/off channels. We present conditions on how to scale the model
parameters so that the network i) has no secure node which is isolated and ii)
is securely connected, both with high probability when the number of sensor
nodes becomes large. The results are given in the form of full zero-one laws,
and constitute the first complete analysis of the EG scheme under non-full
visibility. Through simulations these zero-one laws are shown to be valid also
under a more realistic communication model, i.e., the disk model. The relations
to the Gupta and Kumar's conjecture on the connectivity of geometric random
graphs with randomly deleted edges are also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3426</identifier>
 <datestamp>2012-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3426</id><created>2011-12-15</created><updated>2012-05-22</updated><authors><author><keyname>Vaze</keyname><forenames>Rahul</forenames></author></authors><title>Percolation on the Signal to Interference Ratio Graph with Fading</title><categories>cs.IT math.IT</categories><comments>Withdrawn</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A wireless communication network is considered where any two nodes are
connected if the signal-to-interference ratio (SIR) between them is greater
than a threshold. We consider the the path-loss plus fading model of wireless
signal propagation. Assuming that the nodes of the wireless network are
distributed as a Poisson point process (PPP), percolation (formation of an
unbounded connected cluster) on the resulting SIR graph is studied as a
function of the density of the PPP. We study the super critical regime of
percolation and show that for a small enough threshold, there exists a closed
interval of densities for which percolation happens with non-zero probability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3435</identifier>
 <datestamp>2011-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3435</id><created>2011-12-15</created><authors><author><keyname>Raheja</keyname><forenames>Supriya</forenames></author><author><keyname>Dhadich</keyname><forenames>Reena</forenames></author><author><keyname>Rajpal</keyname><forenames>Smita</forenames></author></authors><title>An Alternative Interpretation of Linguistic Variables as Linguistic
  Finite Automata</title><categories>cs.FL</categories><comments>International Journal of Computer Science &amp; Issues, Aug 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Linguistic variables represent crisp information in a form and precision
appropriate for the problem. For example, to answer the question &quot;How are you?&quot;
one may say &quot;I am fine.&quot; the linguistic variables like &quot;fine&quot;, so common in
everyday speech. In this paper an alternative interpretation of linguistic
variables is introduced with the notion of a linguistic description of a value
or set of values. The use of linguistic variables in many applications reduces
the overall computation complexity of the application. Linguistic variables
have been shown to be particularly useful in complex non-linear applications.
Here we are applying the concept of reasoning with Linguistic Quantifiers to
define the Linguistic Finite Automata along with the expansion of \delta^{\box}
and \lambda^{\box} over \delta and \lambda.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3446</identifier>
 <datestamp>2015-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3446</id><created>2011-12-15</created><updated>2012-05-15</updated><authors><author><keyname>Kim</keyname><forenames>Jong Min</forenames></author><author><keyname>Lee</keyname><forenames>Ok Kyun</forenames></author><author><keyname>Ye</keyname><forenames>Jong Chul</forenames></author></authors><title>Improving Noise Robustness in Subspace-based Joint Sparse Recovery</title><categories>cs.IT math.IT</categories><msc-class>94A20</msc-class><doi>10.1109/TSP.2012.2211591</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a multiple measurement vector problem (MMV), where multiple signals share
a common sparse support and are sampled by a common sensing matrix, we can
expect joint sparsity to enable a further reduction in the number of required
measurements. While a diversity gain from joint sparsity had been demonstrated
earlier in the case of a convex relaxation method using an $l_1/l_2$ mixed norm
penalty, only recently was it shown that similar diversity gain can be achieved
by greedy algorithms if we combine greedy steps with a MUSIC-like subspace
criterion. However, the main limitation of these hybrid algorithms is that they
often require a large number of snapshots or a high signal-to-noise ratio (SNR)
for an accurate subspace as well as partial support estimation. One of the main
contributions of this work is to show that the noise robustness of these
algorithms can be significantly improved by allowing sequential subspace
estimation and support filtering, even when the number of snapshots is
insufficient. Numerical simulations show that a novel sequential compressive
MUSIC (sequential CS-MUSIC) that combines the sequential subspace estimation
and support filtering steps significantly outperforms the existing greedy
algorithms and is quite comparable with computationally expensive state-of-art
algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3455</identifier>
 <datestamp>2013-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3455</id><created>2011-12-15</created><updated>2013-05-17</updated><authors><author><keyname>Ghilezan</keyname><forenames>Silvia</forenames><affiliation>LIP</affiliation></author><author><keyname>Ivetic</keyname><forenames>Jelena</forenames><affiliation>LIP</affiliation></author><author><keyname>Lescanne</keyname><forenames>Pierre</forenames><affiliation>LIP</affiliation></author><author><keyname>Likavec</keyname><forenames>Silvia</forenames></author></authors><title>Resource control and strong normalisation</title><categories>math.LO cs.LO</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce the \emph{resource control cube}, a system consisting of eight
intuitionistic lambda calculi with either implicit or explicit control of
resources and with either natural deduction or sequent calculus. The four
calculi of the cube that correspond to natural deduction have been proposed by
Kesner and Renaud and the four calculi that correspond to sequent lambda
calculi are introduced in this paper. The presentation is parameterized with
the set of resources (weakening or contraction), which enables a uniform
treatment of the eight calculi of the cube. The simply typed resource control
cube, on the one hand, expands the Curry-Howard correspondence to
intuitionistic natural deduction and intuitionistic sequent logic with implicit
or explicit structural rules and, on the other hand, is related to
substructural logics. We propose a general intersection type system for the
resource control cube calculi. Our main contribution is a characterisation of
strong normalisation of reductions in this cube. First, we prove that
typeability implies strong normalisation in the ''natural deduction base&quot; of
the cube by adapting the reducibility method. We then prove that typeability
implies strong normalisation in the ''sequent base&quot; of the cube by using a
combination of well-orders and a suitable embedding in the ''natural deduction
base&quot;. Finally, we prove that strong normalisation implies typeability in the
cube using head subject expansion. All proofs are general and can be made
specific to each calculus of the cube by instantiating the set of resources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3456</identifier>
 <datestamp>2014-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3456</id><created>2011-12-15</created><authors><author><keyname>Clairambault</keyname><forenames>Pierre</forenames><affiliation>CSE</affiliation></author><author><keyname>Dybjer</keyname><forenames>Peter</forenames><affiliation>CSE</affiliation></author></authors><title>The Biequivalence of Locally Cartesian Closed Categories and
  Martin-L\&quot;of Type Theories</title><categories>cs.LO math.CT</categories><comments>TLCA 2011 - 10th Typed Lambda Calculi and Applications, Novi Sad :
  Serbia (2011)</comments><proxy>ccsd</proxy><doi>10.1017/S0960129513000881</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Seely's paper &quot;Locally cartesian closed categories and type theory&quot; contains
a well-known result in categorical type theory: that the category of locally
cartesian closed categories is equivalent to the category of Martin-L\&quot;of type
theories with Pi-types, Sigma-types and extensional identity types. However,
Seely's proof relies on the problematic assumption that substitution in types
can be interpreted by pullbacks. Here we prove a corrected version of Seely's
theorem: that the B\'enabou-Hofmann interpretation of Martin-L\&quot;of type theory
in locally cartesian closed categories yields a biequivalence of 2-categories.
To facilitate the technical development we employ categories with families as a
substitute for syntactic Martin-L\&quot;of type theories. As a second result we
prove that if we remove Pi-types the resulting categories with families are
biequivalent to left exact categories.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3471</identifier>
 <datestamp>2014-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3471</id><created>2011-12-15</created><updated>2014-01-11</updated><authors><author><keyname>Nair</keyname><forenames>Girish N.</forenames></author></authors><title>A Nonstochastic Information Theory for Communication and State
  Estimation</title><categories>cs.SY cs.IT math.IT math.OC</categories><journal-ref>IEEE Transactions on Automatic Control 58 (2013) 1497-1510</journal-ref><doi>10.1109/TAC.2013.2241491</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In communications, unknown variables are usually modelled as random
variables, and concepts such as independence, entropy and information are
defined in terms of the underlying probability distributions. In contrast,
control theory often treats uncertainties and disturbances as bounded unknowns
having no statistical structure. The area of networked control combines both
fields, raising the question of whether it is possible to construct meaningful
analogues of stochastic concepts such as independence, Markovness, entropy and
information without assuming a probability space. This paper introduces a
framework for doing so, leading to the construction of a maximin information
functional for nonstochastic variables. It is shown that the largest maximin
information rate through a memoryless, error-prone channel in this framework
coincides with the block-coding zero-error capacity of the channel. Maximin
information is then used to derive tight conditions for uniformly estimating
the state of a linear time-invariant system over such a channel, paralleling
recent results of Matveev and Savkin.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3475</identifier>
 <datestamp>2012-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3475</id><created>2011-12-15</created><authors><author><keyname>Cardanobile</keyname><forenames>Stefano</forenames></author><author><keyname>Pernice</keyname><forenames>Volker</forenames></author><author><keyname>Deger</keyname><forenames>Moritz</forenames></author><author><keyname>Rotter</keyname><forenames>Stefan</forenames></author></authors><title>Discovering universal statistical laws of complex networks</title><categories>physics.soc-ph cs.SI q-bio.QM</categories><journal-ref>PLoS ONE 7(6): e37911 (2012)</journal-ref><doi>10.1371/journal.pone.0037911</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Different network models have been suggested for the topology underlying
complex interactions in natural systems. These models are aimed at replicating
specific statistical features encountered in real-world networks. However, it
is rarely considered to which degree the results obtained for one particular
network class can be extrapolated to real-world networks. We address this issue
by comparing different classical and more recently developed network models
with respect to their generalisation power, which we identify with large
structural variability and absence of constraints imposed by the construction
scheme. After having identified the most variable networks, we address the
issue of which constraints are common to all network classes and are thus
suitable candidates for being generic statistical laws of complex networks. In
fact, we find that generic, not model-related dependencies between different
network characteristics do exist. This allows, for instance, to infer global
features from local ones using regression models trained on networks with high
generalisation power. Our results confirm and extend previous findings
regarding the synchronisation properties of neural networks. Our method seems
especially relevant for large networks, which are difficult to map completely,
like the neural networks in the brain. The structure of such large networks
cannot be fully sampled with the present technology. Our approach provides a
method to estimate global properties of under-sampled networks with good
approximation. Finally, we demonstrate on three different data sets (C.
elegans' neuronal network, R. prowazekii's metabolic network, and a network of
synonyms extracted from Roget's Thesaurus) that real-world networks have
statistical relations compatible with those obtained using regression models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3506</identifier>
 <datestamp>2013-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3506</id><created>2011-12-15</created><updated>2013-11-06</updated><authors><author><keyname>Crowston</keyname><forenames>Robert</forenames></author><author><keyname>Jones</keyname><forenames>Mark</forenames></author><author><keyname>Mnich</keyname><forenames>Matthias</forenames></author></authors><title>Max-Cut Parameterized Above the Edwards-Erd\H{o}s Bound</title><categories>cs.DS cs.CC cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the boundary of tractability for the Max-Cut problem in graphs. Our
main result shows that Max-Cut above the Edwards-Erd\H{o}s bound is
fixed-parameter tractable: we give an algorithm that for any connected graph
with n vertices and m edges finds a cut of size m/2 + (n-1)/4 + k in time
2^O(k)n^4, or decides that no such cut exists. This answers a long-standing
open question from parameterized complexity that has been posed several times
over the past 15 years. Our algorithm is asymptotically optimal, under the
Exponential Time Hypothesis, and is strengthened by a polynomial-time
computable kernel of polynomial size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3516</identifier>
 <datestamp>2011-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3516</id><created>2011-12-15</created><authors><author><keyname>Fan</keyname><forenames>Zhong</forenames></author><author><keyname>Kulkarni</keyname><forenames>Parag</forenames></author><author><keyname>Gormus</keyname><forenames>Sedat</forenames></author><author><keyname>Efthymiou</keyname><forenames>Costas</forenames></author><author><keyname>Kalogridis</keyname><forenames>Georgios</forenames></author><author><keyname>Sooriyabandara</keyname><forenames>Mahesh</forenames></author><author><keyname>Zhu</keyname><forenames>Ziming</forenames></author><author><keyname>Lambotharan</keyname><forenames>Sangarapillai</forenames></author><author><keyname>Chin</keyname><forenames>Woon Hau</forenames></author></authors><title>Smart Grid Communications: Overview of Research Challenges, Solutions,
  and Standardization Activities</title><categories>cs.NI cs.DC</categories><comments>To be published in IEEE Communications Surveys and Tutorials</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Optimization of energy consumption in future intelligent energy networks (or
Smart Grids) will be based on grid-integrated near-real-time communications
between various grid elements in generation, transmission, distribution and
loads. This paper discusses some of the challenges and opportunities of
communications research in the areas of smart grid and smart metering. In
particular, we focus on some of the key communications challenges for realizing
interoperable and future-proof smart grid/metering networks, smart grid
security and privacy, and how some of the existing networking technologies can
be applied to energy management. Finally, we also discuss the coordinated
standardization efforts in Europe to harmonize communications standards and
protocols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3523</identifier>
 <datestamp>2011-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3523</id><created>2011-12-15</created><authors><author><keyname>Dobrev</keyname><forenames>Stefan</forenames></author><author><keyname>Kranakis</keyname><forenames>Evangelos</forenames></author><author><keyname>Krizanc</keyname><forenames>Danny</forenames></author><author><keyname>Morales-Ponce</keyname><forenames>Oscar</forenames></author><author><keyname>Stacho</keyname><forenames>Ladislav</forenames></author></authors><title>Approximating the Edge Length of 2-Edge Connected Planar Geometric
  Graphs on a Set of Points</title><categories>cs.DM cs.CG</categories><comments>This is the extended version of a paper with the same title that will
  appear in the proceedings of the 10th Latin American Theoretical Informatics
  Symposium (LATIN 2012), April 16-20, 2012, Arequipa, Peru</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a set $P$ of $n$ points in the plane, we solve the problems of
constructing a geometric planar graph spanning $P$ 1) of minimum degree 2, and
2) which is 2-edge connected, respectively, and has max edge length bounded by
a factor of 2 times the optimal; we also show that the factor 2 is best
possible given appropriate connectivity conditions on the set $P$,
respectively. First, we construct in $O(n\log{n})$ time a geometric planar
graph of minimum degree 2 and max edge length bounded by 2 times the optimal.
This is then used to construct in $O(n\log n)$ time a 2-edge connected
geometric planar graph spanning $P$ with max edge length bounded by $\sqrt{5}$
times the optimal, assuming that the set $P$ forms a connected Unit Disk Graph.
Second, we prove that 2 times the optimal is always sufficient if the set of
points forms a 2 edge connected Unit Disk Graph and give an algorithm that runs
in $O(n^2)$ time. We also show that for $k \in O(\sqrt{n})$, there exists a set
$P$ of $n$ points in the plane such that even though the Unit Disk Graph
spanning $P$ is $k$-vertex connected, there is no 2-edge connected geometric
planar graph spanning $P$ even if the length of its edges is allowed to be up
to 17/16.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3535</identifier>
 <datestamp>2011-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3535</id><created>2011-12-15</created><authors><author><keyname>Sukhov</keyname><forenames>A. M.</forenames></author><author><keyname>Chemodanov</keyname><forenames>D. Yu.</forenames></author></authors><title>Variation principle and the universal metric of dynamic routing</title><categories>cs.NI</categories><comments>4 pages, 3 figures, 14 equations</comments><report-no>SSAU-OI-12-2011</report-no><msc-class>70G75, 94A99</msc-class><acm-class>C.2.2; C.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper the variation principles from theoretical physics is considered
that would describe the process of routing in computer networks. The total
traffic which is currently served on all hops of the route has been chosen as
the quantity to minimize. Universal metric function has been found for dynamic
routing taking into account the packet loss effect. An attempt to derive the
metric of the most popular dynamic routing protocols such as RIP, OSPF, EIGRP
from universal metric was made.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3555</identifier>
 <datestamp>2011-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3555</id><created>2011-12-15</created><updated>2011-12-15</updated><authors><author><keyname>Sun</keyname><forenames>Yajuan</forenames></author><author><keyname>Lin</keyname><forenames>Hai</forenames></author><author><keyname>Chen</keyname><forenames>Ben. M.</forenames></author></authors><title>Decentralized Supervisory Control of Discrete Event Systems for
  Bisimulation Equivalence</title><categories>cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In decentralized systems, branching behaviors naturally arise due to
communication, unmodeled dynamics and system abstraction, which can not be
adequately captured by the traditional sequencing-based language equivalence.
As a finer behavior equivalence than language equivalence, bisimulation not
only allows the full set of branching behaviors but also explicitly specifies
the properties in terms of temporal logic such as CTL* and mu-calculus. This
observation motivates us to consider the decentralized control of discrete
event systems (DESs) for bisimulation equivalence in this paper, where the
plant and the specification are taken to be nondeterministic and the supervisor
is taken to be deterministic. An automata-based control framework is
formalized, upon which we develop three architectures with respect to different
decision fusion rules for the decentralized bisimilarity control, named a
conjunctive architecture, a disjunctive architecture and a general
architecture. Under theses three architectures, necessary and sufficient
conditions for the existence of decentralized bisimilarity supervisors are
derived respectively, which extend the traditional results of supervisory
control from language equivalence to bisimulation equivalence. It is shown that
these conditions can be verified with exponential complexity. Furthermore, the
synthesis of bisimilarity supervisors is presented when the existence condition
holds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3599</identifier>
 <datestamp>2011-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3599</id><created>2011-12-15</created><authors><author><keyname>Shen</keyname><forenames>Yuan</forenames></author><author><keyname>Mazuelas</keyname><forenames>Santiago</forenames></author><author><keyname>Win</keyname><forenames>Moe Z.</forenames></author></authors><title>Cooperative Network Navigation: Fundamental Limit and its Geometrical
  Interpretation</title><categories>cs.IT math.IT</categories><comments>11 pages, 7 figures, to appear in IEEE Journal on Selected Areas of
  Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Localization and tracking of moving nodes via network navigation gives rise
to a new paradigm, where nodes exploit both temporal and spatial cooperation to
infer their positions based on intra- and inter-node measurements. While such
cooperation can significantly improve the performance, it imposes intricate
information processing that impedes network design and operation. In this
paper, we establish a theoretical framework for cooperative network navigation
and determine the fundamental limits of navigation accuracy using equivalent
Fisher information analysis. We then introduce the notion of carry-over
information, and provide a geometrical interpretation of the navigation
information and its evolution in time. Our framework unifies the navigation
information obtained from temporal and spatial cooperation, leading to a deep
understanding of information evolution in the network and benefit of
cooperation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3610</identifier>
 <datestamp>2011-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3610</id><created>2011-12-15</created><authors><author><keyname>Johnson</keyname><forenames>Will</forenames></author></authors><title>The Combinatorial Game Theory of Well-Tempered Scoring Games</title><categories>math.CO cs.GT</categories><comments>60 pages, 21 figures</comments><msc-class>91A46</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the class of &quot;well-tempered&quot; integer-valued scoring games, which
have the property that the parity of the length of the game is independent of
the line of play. We consider disjunctive sums of these games, and develop a
theory for them analogous to the standard theory of disjunctive sums of
normal-play partizan games. We show that the monoid of well-tempered scoring
games modulo indistinguishability is cancellative but not a group, and we
describe its structure in terms of the group of normal-play partizan games. We
also classify Boolean-valued well-tempered scoring games, showing that there
are exactly seventy, up to equivalence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3611</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3611</id><created>2011-12-15</created><updated>2011-12-15</updated><authors><author><keyname>Chuzhoy</keyname><forenames>Julia</forenames></author><author><keyname>Makarychev</keyname><forenames>Yury</forenames></author><author><keyname>Vijayaraghavan</keyname><forenames>Aravindan</forenames></author><author><keyname>Zhou</keyname><forenames>Yuan</forenames></author></authors><title>Approximation Algorithms and Hardness of the k-Route Cut Problem</title><categories>cs.DS cs.CC</categories><comments>To appear in the Symposium on Discrete Algorithms (SODA) 2012. 44
  pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the k-route cut problem: given an undirected edge-weighted graph
G=(V,E), a collection {(s_1,t_1),(s_2,t_2),...,(s_r,t_r)} of source-sink pairs,
and an integer connectivity requirement k, the goal is to find a minimum-weight
subset E' of edges to remove, such that the connectivity of every pair (s_i,
t_i) falls below k. Specifically, in the edge-connectivity version, EC-kRC, the
requirement is that there are at most (k-1) edge-disjoint paths connecting s_i
to t_i in G \ E', while in the vertex-connectivity version, NC-kRC, the same
requirement is for vertex-disjoint paths. Prior to our work, poly-logarithmic
approximation algorithms have been known for the special case where k &gt;= 3, but
no non-trivial approximation algorithms were known for any value k&gt;3, except in
the single-source setting. We show an O(k log^{3/2}r)-approximation algorithm
for EC-kRC with uniform edge weights, and several polylogarithmic bi-criteria
approximation algorithms for EC-kRC and NC-kRC, where the connectivity
requirement k is violated by a constant factor. We complement these upper
bounds by proving that NC-kRC is hard to approximate to within a factor of
k^{eps} for some fixed eps&gt;0.
  We then turn to study a simpler version of NC-kRC, where only one source-sink
pair is present. We give a simple bi-criteria approximation algorithm for this
case, and show evidence that even this restricted version of the problem may be
hard to approximate. For example, we prove that the single source-sink pair
version of NC-kRC has no constant-factor approximation, assuming Feige's Random
k-AND assumption.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3644</identifier>
 <datestamp>2012-10-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3644</id><created>2011-12-15</created><authors><author><keyname>Seshadhri</keyname><forenames>C.</forenames></author><author><keyname>Kolda</keyname><forenames>Tamara G.</forenames></author><author><keyname>Pinar</keyname><forenames>Ali</forenames></author></authors><title>Community structure and scale-free collections of Erd\&quot;os-R\'enyi graphs</title><categories>cs.SI physics.soc-ph</categories><journal-ref>Physical Review E 85(5):056109, 2012</journal-ref><doi>10.1103/PhysRevE.85.056109</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Community structure plays a significant role in the analysis of social
networks and similar graphs, yet this structure is little understood and not
well captured by most models. We formally define a community to be a subgraph
that is internally highly connected and has no deeper substructure. We use
tools of combinatorics to show that any such community must contain a dense
Erd\&quot;os-R\'enyi (ER) subgraph. Based on mathematical arguments, we hypothesize
that any graph with a heavy-tailed degree distribution and community structure
must contain a scale free collection of dense ER subgraphs. These theoretical
observations corroborate well with empirical evidence. From this, we propose
the Block Two-Level Erd\&quot;os-R\'enyi (BTER) model, and demonstrate that it
accurately captures the observable properties of many real-world social
networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3670</identifier>
 <datestamp>2012-04-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3670</id><created>2011-12-15</created><updated>2012-04-12</updated><authors><author><keyname>Danescu-Niculescu-Mizil</keyname><forenames>Cristian</forenames></author><author><keyname>Lee</keyname><forenames>Lillian</forenames></author><author><keyname>Pang</keyname><forenames>Bo</forenames></author><author><keyname>Kleinberg</keyname><forenames>Jon</forenames></author></authors><title>Echoes of power: Language effects and power differences in social
  interaction</title><categories>cs.SI cs.CL physics.soc-ph</categories><comments>v3 is the camera-ready for the Proceedings of WWW 2012. Changes from
  v2 include additional technical analysis. See
  http://www.cs.cornell.edu/~cristian/www2012 for data and more info</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Understanding social interaction within groups is key to analyzing online
communities. Most current work focuses on structural properties: who talks to
whom, and how such interactions form larger network structures. The
interactions themselves, however, generally take place in the form of natural
language --- either spoken or written --- and one could reasonably suppose that
signals manifested in language might also provide information about roles,
status, and other aspects of the group's dynamics. To date, however, finding
such domain-independent language-based signals has been a challenge.
  Here, we show that in group discussions power differentials between
participants are subtly revealed by how much one individual immediately echoes
the linguistic style of the person they are responding to. Starting from this
observation, we propose an analysis framework based on linguistic coordination
that can be used to shed light on power relationships and that works
consistently across multiple types of power --- including a more &quot;static&quot; form
of power based on status differences, and a more &quot;situational&quot; form of power in
which one individual experiences a type of dependence on another. Using this
framework, we study how conversational behavior can reveal power relationships
in two very different settings: discussions among Wikipedians and arguments
before the U.S. Supreme Court.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3680</identifier>
 <datestamp>2013-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3680</id><created>2011-12-15</created><updated>2013-02-20</updated><authors><author><keyname>Chen</keyname><forenames>Po-An</forenames></author><author><keyname>de Keijzer</keyname><forenames>Bart</forenames></author><author><keyname>Kempe</keyname><forenames>David</forenames></author><author><keyname>Schaefer</keyname><forenames>Guido</forenames></author></authors><title>The Robust Price of Anarchy of Altruistic Games</title><categories>cs.GT</categories><comments>WINE'11</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the inefficiency of equilibria for various classes of games when
players are (partially) altruistic. We model altruistic behavior by assuming
that player i's perceived cost is a convex combination of 1-\alpha_i times his
direct cost and \alpha_i times the social cost. Tuning the parameters \alpha_i
allows smooth interpolation between purely selfish and purely altruistic
behavior. Within this framework, we study altruistic extensions of linear
congestion games, fair cost-sharing games and valid utility games.
  We derive (tight) bounds on the price of anarchy of these games for several
solution concepts. Thereto, we suitably adapt the smoothness notion introduced
by Roughgarden and show that it captures the essential properties to determine
the robust price of anarchy of these games. Our bounds show that for congestion
games and cost-sharing games, the worst-case robust price of anarchy increases
with increasing altruism, while for valid utility games, it remains constant
and is not affected by altruism. However, the increase in the price of anarchy
is not a universal phenomenon: for symmetric singleton linear congestion games,
we derive a bound on the pure price of anarchy that decreases as the level of
altruism increases. Since the bound is also strictly lower than the robust
price of anarchy, it exhibits a natural example in which Nash equilibria are
more efficient than more permissive notions of equilibrium.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3691</identifier>
 <datestamp>2011-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3691</id><created>2011-12-15</created><authors><author><keyname>Wang</keyname><forenames>Zhen</forenames></author><author><keyname>Lin</keyname><forenames>Felix Xiaozhu</forenames></author><author><keyname>Zhong</keyname><forenames>Lin</forenames></author><author><keyname>Chishtie</keyname><forenames>Mansoor</forenames></author></authors><title>How Far Can Client-Only Solutions Go for Mobile Browser Speed?</title><categories>cs.NI</categories><report-no>TR1215-2011, Rice University and Texas Instruments</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mobile browser is known to be slow because of the bottleneck in resource
loading. Client-only solutions to improve resource loading are attractive
because they are immediately deployable, scalable, and secure. We present the
first publicly known treatment of client-only solutions to understand how much
they can improve mobile browser speed without infrastructure support.
Leveraging an unprecedented set of web usage data collected from 24 iPhone
users continuously over one year, we examine the three fundamental, orthogonal
approaches a client-only solution can take: caching, prefetching, and
speculative loading, which is first proposed and studied in this work.
Speculative loading predicts and speculatively loads the subresources needed to
open a web page once its URL is given. We show that while caching and
prefetching are highly limited for mobile browsing, speculative loading can be
significantly more effective. Empirically, we show that client-only solutions
can improve the browser speed by about 1.4 second on average for web sites
visited by the 24 iPhone users. We also report the design, realization, and
evaluation of speculative loading in a WebKit-based browser called Tempo. On
average, Tempo can reduce browser delay by 1 second (~20%).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3692</identifier>
 <datestamp>2011-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3692</id><created>2011-12-15</created><authors><author><keyname>Huber</keyname><forenames>Mark</forenames></author><author><keyname>Schott</keyname><forenames>Sarah</forenames></author></authors><title>Random construction of interpolating sets for high dimensional
  integration</title><categories>math.PR cs.DS stat.CO</categories><comments>14 pages, 1 figure</comments><msc-class>Primary 60K35, Secondary 60K35</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many high dimensional integrals can be reduced to the problem of finding the
relative measures of two sets. Often one set will be exponentially larger than
the other, making it difficult to compare the sizes. A standard method of
dealing with this problem is to interpolate between the sets with a sequence of
nested sets where neighboring sets have relative measures bounded above by a
constant. Choosing such a well balanced sequence can be very difficult in
practice. Here a new approach that automatically creates such sets is
presented. These well balanced sets allow for faster approximation algorithms
for integrals and sums, and better tempering and annealing Markov chains for
generating random samples. Applications such as finding the partition function
of the Ising model and normalizing constants for posterior distributions in
Bayesian methods are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3697</identifier>
 <datestamp>2012-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3697</id><created>2011-12-15</created><authors><author><keyname>Binder</keyname><forenames>Alexander</forenames></author><author><keyname>Nakajima</keyname><forenames>Shinichi</forenames></author><author><keyname>Kloft</keyname><forenames>Marius</forenames></author><author><keyname>M&#xfc;ller</keyname><forenames>Christina</forenames></author><author><keyname>Samek</keyname><forenames>Wojciech</forenames></author><author><keyname>Brefeld</keyname><forenames>Ulf</forenames></author><author><keyname>M&#xfc;ller</keyname><forenames>Klaus-Robert</forenames></author><author><keyname>Kawanabe</keyname><forenames>Motoaki</forenames></author></authors><title>Insights from Classifying Visual Concepts with Multiple Kernel Learning</title><categories>cs.CV</categories><comments>18 pages, 8 tables, 4 figures, format deviating from plos one
  submission format requirements for aesthetic reasons</comments><journal-ref>PLoS ONE 7(8): e38897, 2012</journal-ref><doi>10.1371/journal.pone.0038897</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Combining information from various image features has become a standard
technique in concept recognition tasks. However, the optimal way of fusing the
resulting kernel functions is usually unknown in practical applications.
Multiple kernel learning (MKL) techniques allow to determine an optimal linear
combination of such similarity matrices. Classical approaches to MKL promote
sparse mixtures. Unfortunately, so-called 1-norm MKL variants are often
observed to be outperformed by an unweighted sum kernel. The contribution of
this paper is twofold: We apply a recently developed non-sparse MKL variant to
state-of-the-art concept recognition tasks within computer vision. We provide
insights on benefits and limits of non-sparse MKL and compare it against its
direct competitors, the sum kernel SVM and the sparse MKL. We report empirical
results for the PASCAL VOC 2009 Classification and ImageCLEF2010 Photo
Annotation challenge data sets. About to be submitted to PLoS ONE.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3712</identifier>
 <datestamp>2011-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3712</id><created>2011-12-16</created><authors><author><keyname>Cho</keyname><forenames>Youngmin</forenames></author><author><keyname>Saul</keyname><forenames>Lawrence K.</forenames></author></authors><title>Analysis and Extension of Arc-Cosine Kernels for Large Margin
  Classification</title><categories>cs.LG</categories><comments>Preprint submitted to Neural Networks</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate a recently proposed family of positive-definite kernels that
mimic the computation in large neural networks. We examine the properties of
these kernels using tools from differential geometry; specifically, we analyze
the geometry of surfaces in Hilbert space that are induced by these kernels.
When this geometry is described by a Riemannian manifold, we derive results for
the metric, curvature, and volume element. Interestingly, though, we find that
the simplest kernel in this family does not admit such an interpretation. We
explore two variations of these kernels that mimic computation in neural
networks with different activation functions. We experiment with these new
kernels on several data sets and highlight their general trends in performance
for classification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3714</identifier>
 <datestamp>2011-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3714</id><created>2011-12-16</created><authors><author><keyname>Cho</keyname><forenames>Youngmin</forenames></author><author><keyname>Saul</keyname><forenames>Lawrence K.</forenames></author></authors><title>Nonnegative Matrix Factorization for Semi-supervised Dimensionality
  Reduction</title><categories>cs.LG</categories><comments>Preprint submitted to Machine Learning Journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show how to incorporate information from labeled examples into nonnegative
matrix factorization (NMF), a popular unsupervised learning algorithm for
dimensionality reduction. In addition to mapping the data into a space of lower
dimensionality, our approach aims to preserve the nonnegative components of the
data that are important for classification. We identify these components from
the support vectors of large-margin classifiers and derive iterative updates to
preserve them in a semi-supervised version of NMF. These updates have a simple
multiplicative form like their unsupervised counterparts; they are also
guaranteed at each iteration to decrease their loss function---a weighted sum
of I-divergences that captures the trade-off between unsupervised and
supervised learning. We evaluate these updates for dimensionality reduction
when they are used as a precursor to linear classification. In this role, we
find that they yield much better performance than their unsupervised
counterparts. We also find one unexpected benefit of the low dimensional
representations discovered by our approach: often they yield more accurate
classifiers than both ordinary and transductive SVMs trained in the original
input space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3725</identifier>
 <datestamp>2011-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3725</id><created>2011-12-16</created><authors><author><keyname>Jamous</keyname><forenames>Mamoun M.</forenames></author><author><keyname>Deris</keyname><forenames>Safaai Bin</forenames></author></authors><title>Web Services Non-Functional Classification to Enhance Discovery Speed</title><categories>cs.DC</categories><comments>6 pages, 6 figures, 1 table</comments><journal-ref>IJCSI International Journal of Computer Science Issues, Vol. 8,
  Issue 4, July 2011</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Recently, the use and deployment of web services has dramatically increased.
This is due to the easiness, interoperability, and flexibility that web
services offer to the software systems, which other software structures don't
support or support poorly. Web services discovery became more important and
research conducted in this area became more critical. With the increasing
number of published and publicly available web services, speed in web service
discovery process is becoming an issue which cannot be neglected. This paper
proposes a generic non-functional based web services classification algorithm.
Classification algorithm depends on information supplied by web service
provider at the registration time. Authors have proved mathematically and
experimentally the usefulness and efficiency of proposed algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3726</identifier>
 <datestamp>2011-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3726</id><created>2011-12-16</created><authors><author><keyname>Michel</keyname><forenames>Christine</forenames><affiliation>LIESP</affiliation></author><author><keyname>Lavou&#xe9;</keyname><forenames>Elise</forenames><affiliation>EA3713</affiliation></author></authors><title>KM and WEB 2.0 methods for project-based learning. MESHAT : a monitoring
  and experience sharing tool</title><categories>cs.CY</categories><comments>arXiv admin note: substantial text overlap with arXiv:0911.0310</comments><proxy>ccsd</proxy><journal-ref>Multiple Perspectives on Problem Solving and Learning in the
  Digital Age, Ifenthaler D., Isaias P., Spector J.M., Kinshuk, Sampson D.
  (Ed.) (2011) 49-66</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Our work aims at studying tools offered to learners and tutors involved in
face-to-face or blended project-based learning activities. To understand better
the needs and expectations of each actor, we are especially interested in the
specific case of project management training. The results of a course
observation show that the lack of monitoring and expertise transfer tools
involves important dysfunctions in the course organisation and therefore
dissatisfaction for tutors and students (in particular about the acquisition of
knowledge and expertise). So as to solve this problem, we propose a
personalised platform (according to the actor: project group, student or
tutor), which gives information to monitor activities and supports the
acquisition and transfer of expertise. This platform is based on Knowledge
Management (KM) and Web 2.0 concepts to support the dynamic building of
knowledge. KM is used to define the learning process (based on the experiential
learning theory) and the way the individual knowledge building is monitored
(based on metacognitive concepts). Web 2.0 is used to define the way the
experience is shared. We make the hypothesis that this approach improves the
acquisition of complex skills (e.g. management, communication and
collaboration), which requires a behavioural evolution. We aim at making the
students become able 'to learn to learn' and evolve according to contexts. We
facilitate their ability to have a critical analysis of their actions according
to the situations they encounter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3730</identifier>
 <datestamp>2011-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3730</id><created>2011-12-16</created><authors><author><keyname>Paolini</keyname><forenames>Enrico</forenames></author><author><keyname>Flanagan</keyname><forenames>Mark F.</forenames></author><author><keyname>Chiani</keyname><forenames>Marco</forenames></author><author><keyname>Fossorier</keyname><forenames>Marc P. C.</forenames></author></authors><title>Stability of Iterative Decoding of Multi-Edge Type Doubly-Generalized
  LDPC Codes Over the BEC</title><categories>cs.IT math.IT</categories><comments>6 pages, 3 figures. Presented at Globecom 2011, Houston, TX</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using the EXIT chart approach, a necessary and sufficient condition is
developed for the local stability of iterative decoding of multi-edge type
(MET) doubly-generalized low-density parity-check (D-GLDPC) code ensembles. In
such code ensembles, the use of arbitrary linear block codes as component codes
is combined with the further design of local Tanner graph connectivity through
the use of multiple edge types. The stability condition for these code
ensembles is shown to be succinctly described in terms of the value of the
spectral radius of an appropriately defined polynomial matrix.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3740</identifier>
 <datestamp>2011-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3740</id><created>2011-12-16</created><authors><author><keyname>Valancius</keyname><forenames>Vytautas</forenames></author><author><keyname>Lumezanu</keyname><forenames>Cristian</forenames></author><author><keyname>Feamster</keyname><forenames>Nick</forenames></author><author><keyname>Johari</keyname><forenames>Ramesh</forenames></author><author><keyname>Vazirani</keyname><forenames>Vijay V.</forenames></author></authors><title>Modeling Tiered Pricing in the Internet Transit Market</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  ISPs are increasingly selling &quot;tiered&quot; contracts, which offer Internet
connectivity to wholesale customers in bundles, at rates based on the cost of
the links that the traffic in the bundle is traversing. Although providers have
already begun to implement and deploy tiered pricing contracts, little is known
about how such pricing affects ISPs and their customers. While contracts that
sell connectivity on finer granularities improve market efficiency, they are
also more costly for ISPs to implement and more difficult for customers to
understand. In this work we present two contributions: (1) we develop a novel
way of mapping traffic and topology data to a demand and cost model; and (2) we
fit this model on three large real-world networks: an European transit ISP, a
content distribution network, and an academic research network, and run
counterfactuals to evaluate the effects of different pricing strategies on both
the ISP profit and the consumer surplus. We highlight three core findings.
First, ISPs gain most of the profits with only three or four pricing tiers and
likely have little incentive to increase granularity of pricing even further.
Second, we show that consumer surplus follows closely, if not precisely, the
increases in ISP profit with more pricing tiers. Finally, the common ISP
practice of structuring tiered contracts according to the cost of carrying the
traffic flows (e.g., offering a discount for traffic that is local) can be
suboptimal and that dividing contracts based on both traffic demand and the
cost of carrying it into only three or four tiers yields near-optimal profit
for the ISP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3741</identifier>
 <datestamp>2012-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3741</id><created>2011-12-16</created><updated>2012-01-04</updated><authors><author><keyname>Hanawal</keyname><forenames>Manjesh Kumar</forenames></author><author><keyname>Altman</keyname><forenames>Eitan</forenames></author><author><keyname>Baccelli</keyname><forenames>Francois</forenames></author></authors><title>Stochastic Geometry based Medium Access Games in Mobile Ad hoc Networks</title><categories>cs.GT cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the performance of Mobile Ad hoc Networks (MANETs) when
the nodes, that form a Poisson point process, selfishly choose their Medium
Access Probability (MAP). We consider goodput and delay as the performance
metric that each node is interested in optimizing taking into account the
transmission energy costs. We introduce a pricing scheme based on the
transmission energy requirements and compute the symmetric Nash equilibria of
the game in closed form. It is shown that by appropriately pricing the nodes,
the selfish behavior of the nodes can be used to achieve the social optimum at
equilibrium. The Price of Anarchy is then analyzed for these games. For the
game with delay based utility, we bound the price of anarchy and study the
effect of the price factor. For the game with goodput based utility, it is
shown that price of anarchy is infinite at the price factor that achieves the
global optima.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3756</identifier>
 <datestamp>2011-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3756</id><created>2011-12-16</created><authors><author><keyname>El-Zawawy</keyname><forenames>Mohamed A.</forenames></author></authors><title>Probabilistic pointer analysis for multithreaded programs</title><categories>cs.PL cs.LO</categories><comments>12 pages</comments><journal-ref>ScienceAsia 37 (2011): 344-354</journal-ref><doi>10.2306/scienceasia1513-1874.2011.37.344</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The use of pointers and data-structures based on pointers results in circular
memory references that are interpreted by a vital compiler analysis, namely
pointer analysis. For a pair of memory references at a program point, a typical
pointer analysis specifies if the points-to relation between them may exist,
definitely does not exist, or definitely exists. The &quot;may be&quot; case, which
describes the points-to relation for most of the pairs, cannot be dealt with by
most compiler optimizations. This is so to guarantee the soundness of these
optimizations. However, the &quot;may be&quot; case can be capitalized by the modern
class of speculative optimizations if the probability that two memory
references alias can be measured. Focusing on multithreading, a prevailing
technique of programming, this paper presents a new flow-sensitive technique
for probabilistic pointer analysis of multithreaded programs. The proposed
technique has the form of a type system and calculates the probability of every
points-to relation at each program point. The key to our approach is to
calculate the points-to information via a post-type derivation. The use of type
systems has the advantage of associating each analysis results with a
justification (proof) for the correctness of the results. This justification
has the form of a type derivation and is very much required in applications
like certified code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3758</identifier>
 <datestamp>2012-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3758</id><created>2011-12-16</created><updated>2012-03-30</updated><authors><author><keyname>Mousavi</keyname><forenames>Hamoon</forenames></author><author><keyname>Shallit</keyname><forenames>Jeffrey</forenames></author></authors><title>Filtrations of Formal Languages by Arithmetic Progressions</title><categories>cs.FL</categories><comments>revision correcting some typos</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A filtration of a formal language L by a sequence s maps L to the set of
words formed by taking the letters of words of L indexed only by s. We consider
the languages resulting from filtering by all arithmetic progressions. If L is
regular, it is easy to see that only finitely many distinct languages result.
By contrast, there exist CFL's that give infinitely many distinct languages as
a result. We use our technique to show that the operation diag, which extracts
the diagonal of words of square length arranged in a square array, preserves
regularity but does not preserve context-freeness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3765</identifier>
 <datestamp>2011-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3765</id><created>2011-12-16</created><authors><author><keyname>Greiner</keyname><forenames>Gero</forenames></author><author><keyname>Jacob</keyname><forenames>Riko</forenames></author></authors><title>The Efficiency of MapReduce in Parallel External Memory</title><categories>cs.DC cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Since its introduction in 2004, the MapReduce framework has become one of the
standard approaches in massive distributed and parallel computation. In
contrast to its intensive use in practise, theoretical footing is still limited
and only little work has been done yet to put MapReduce on a par with the major
computational models. Following pioneer work that relates the MapReduce
framework with PRAM and BSP in their macroscopic structure, we focus on the
functionality provided by the framework itself, considered in the parallel
external memory model (PEM). In this, we present upper and lower bounds on the
parallel I/O-complexity that are matching up to constant factors for the
shuffle step. The shuffle step is the single communication phase where all
information of one MapReduce invocation gets transferred from map workers to
reduce workers. Hence, we move the focus towards the internal communication
step in contrast to previous work. The results we obtain further carry over to
the BSP* model. On the one hand, this shows how much complexity can be &quot;hidden&quot;
for an algorithm expressed in MapReduce compared to PEM. On the other hand, our
results bound the worst-case performance loss of the MapReduce approach in
terms of I/O-efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3779</identifier>
 <datestamp>2011-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3779</id><created>2011-12-16</created><authors><author><keyname>Cruz</keyname><forenames>Flavio</forenames></author><author><keyname>Rocha</keyname><forenames>Ricardo</forenames></author></authors><title>Single Time-Stamped Tries for Retroactive Call Subsumption</title><categories>cs.PL</categories><comments>Online Proceedings of the 11th International Colloquium on
  Implementation of Constraint LOgic Programming Systems (CICLOPS 2011),
  Lexington, KY, U.S.A., July 10, 2011</comments><acm-class>D.1.6; D.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tabling is an evaluation strategy for Prolog programs that works by storing
answers in a table space and then by using them in similar subgoals. Some
tabling engines use call by subsumption, where it is determined that a subgoal
will consume answers from a more general subgoal in order to reduce the search
space and increase efficiency. We designed an extension, named Retroactive Call
Subsumption (RCS), that implements call by subsumption independently of the
call order, thus allowing a more general subgoal to force previous called
subgoals to become answer consumers. For this extension, we propose a new table
space design, the Single Time Stamped Trie (STST), that is organized to make
answer sharing across subsumed/subsuming subgoals simple and efficient. In this
paper, we present the new STST table space design and we discuss the main
modifications made to the original Time Stamped Tries approach to
non-retroactive call by subsumption. In experimental results, with programs
that stress some deficiencies of the new STST design, some overheads may be
observed, however the results achieved with more realistic programs greatly
offset these overheads.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3780</identifier>
 <datestamp>2011-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3780</id><created>2011-12-16</created><authors><author><keyname>Raimundo</keyname><forenames>Jo&#xe3;o</forenames></author><author><keyname>Rocha</keyname><forenames>Ricardo</forenames></author></authors><title>Global Trie for Subterms</title><categories>cs.PL</categories><comments>Online Proceedings of the 11th International Colloquium on
  Implementation of Constraint LOgic Programming Systems (CICLOPS 2011),
  Lexington, KY, U.S.A., July 10, 2011</comments><acm-class>D.1.6; D.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A critical component in the implementation of an efficient tabling system is
the design of the table space. The most popular and successful data structure
for representing tables is based on a two-level trie data structure, where one
trie level stores the tabled subgoal calls and the other stores the computed
answers. The Global Trie (GT) is an alternative table space organization
designed with the intent to reduce the tables's memory usage, namely by storing
terms in a global trie, thus preventing repeated representations of the same
term in different trie data structures. In this paper, we propose an extension
to the GT organization, named Global Trie for Subterms (GT-ST), where compound
subterms in term arguments are represented as unique entries in the GT.
Experiments results using the YapTab tabling system show that GT-ST support has
potential to achieve significant reductions on memory usage, for programs with
increasing compound subterms in term arguments, without compromising the
execution time for other programs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3782</identifier>
 <datestamp>2011-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3782</id><created>2011-12-16</created><authors><author><keyname>Tarau</keyname><forenames>Paul</forenames></author></authors><title>Computing with Hereditarily Finite Sequences</title><categories>cs.PL</categories><comments>Online Proceedings of the 11th International Colloquium on
  Implementation of Constraint LOgic Programming Systems (CICLOPS 2011),
  Lexington, KY, U.S.A., July 10, 2011</comments><acm-class>D.1.6; D.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  e use Prolog as a flexible meta-language to provide executable specifications
of some fundamental mathematical objects and their transformations. In the
process, isomorphisms are unraveled between natural numbers and combinatorial
objects (rooted ordered trees representing hereditarily finite sequences and
rooted ordered binary trees representing G\&quot;odel's System {\bf T} types).
  This paper focuses on an application that can be seen as an unexpected
&quot;paradigm shift&quot;: we provide recursive definitions showing that the resulting
representations are directly usable to perform symbolically arbitrary-length
integer computations.
  Besides the theoretically interesting fact of &quot;breaking the
arithmetic/symbolic barrier&quot;, the arithmetic operations performed with symbolic
objects like trees or types turn out to be genuinely efficient -- we derive
implementations with asymptotic performance comparable to ordinary bitstring
implementations of arbitrary-length integer arithmetic.
  The source code of the paper, organized as a literate Prolog program, is
available at \url{http://logic.cse.unt.edu/tarau/research/2011/pPAR.pl}
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3783</identifier>
 <datestamp>2011-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3783</id><created>2011-12-16</created><authors><author><keyname>Moura</keyname><forenames>Paulo</forenames></author><author><keyname>Dias</keyname><forenames>Artur Miguel</forenames></author></authors><title>L-FLAT: Logtalk Toolkit for Formal Languages and Automata Theory</title><categories>cs.PL</categories><comments>Online Proceedings of the 11th International Colloquium on
  Implementation of Constraint LOgic Programming Systems (CICLOPS 2011),
  Lexington, KY, U.S.A., July 10, 2011</comments><acm-class>D.1.6; D.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe L-FLAT, a Logtalk Toolkit for teaching Formal Languages and
Automata Theory. L-FLAT supports the definition of \textsl{alphabets}, the
definition of \textsl{orders} over alphabet symbols, the partial definition of
\textsl{languages} using unit tests, and the definition of \textsl{mechanisms},
which implement language generators or language recognizers. Supported
mechanisms include \textsl{predicates}, \textsl{regular expressions},
\textsl{finite automata}, \textsl{context-free grammars}, \textsl{Turing
machines}, and \textsl{push-down automata}. L-FLAT entities are implemented
using the object-oriented features of Logtalk, providing a highly portable and
easily extendable framework. The use of L-FLAT in educational environments is
enhanced by supporting Mooshak, a web application that features automatic
grading of submitted programs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3784</identifier>
 <datestamp>2011-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3784</id><created>2011-12-16</created><authors><author><keyname>Csorba</keyname><forenames>J&#xe1;nos</forenames></author><author><keyname>Zombori</keyname><forenames>Zsolt</forenames></author><author><keyname>Szeredi</keyname><forenames>P&#xe9;ter</forenames></author></authors><title>Using Constraint Handling Rules to Provide Static Type Analysis for the
  Q Functional Language</title><categories>cs.PL</categories><comments>Online Proceedings of the 11th International Colloquium on
  Implementation of Constraint LOgic Programming Systems (CICLOPS 2011),
  Lexington, KY, U.S.A., July 10, 2011</comments><acm-class>D.1.6; D.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe an application of Prolog: a type checking tool for the Q
functional language. Q is a terse vector processing language, a descendant of
APL, which is getting more and more popular, especially in financial
applications. Q is a dynamically typed language, much like Prolog. Extending Q
with static typing improves both the readability of programs and programmer
productivity, as type errors are discovered by the tool at compile time, rather
than through debugging the program execution.
  The type checker uses constraints that are handled by Prolog Constraint
Handling Rules. During the analysis, we determine the possible type values for
each program expression and detect inconsistencies. As most built-in function
names of Q are overloaded, i.e. their meaning depends on the argument types, a
quite complex system of constraints had to be implemented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3785</identifier>
 <datestamp>2011-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3785</id><created>2011-12-16</created><authors><author><keyname>Mantadelis</keyname><forenames>Theofrastos</forenames></author><author><keyname>Janssens</keyname><forenames>Gerda</forenames></author></authors><title>Nesting Probabilistic Inference</title><categories>cs.PL</categories><comments>Online Proceedings of the 11th International Colloquium on
  Implementation of Constraint LOgic Programming Systems (CICLOPS 2011),
  Lexington, KY, U.S.A., July 10, 2011</comments><acm-class>D.1.6; D.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When doing inference in ProbLog, a probabilistic extension of Prolog, we
extend SLD resolution with some additional bookkeeping. This additional
information is used to compute the probabilistic results for a probabilistic
query. In Prolog's SLD, goals are nested very naturally. In ProbLog's SLD,
nesting probabilistic queries interferes with the probabilistic bookkeeping. In
order to support nested probabilistic inference we propose the notion of a
parametrised ProbLog engine. Nesting becomes possible by suspending and
resuming instances of ProbLog engines. With our approach we realise several
extensions of ProbLog such as meta-calls, negation, and answers of
probabilistic goals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3786</identifier>
 <datestamp>2011-12-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3786</id><created>2011-12-16</created><updated>2011-12-23</updated><authors><author><keyname>Van Overveldt</keyname><forenames>Timon</forenames></author><author><keyname>Demoen</keyname><forenames>Bart</forenames></author></authors><title>High-Level Multi-Threading in hProlog</title><categories>cs.PL</categories><comments>Online Proceedings of the 11th International Colloquium on
  Implementation of Constraint LOgic Programming Systems (CICLOPS 2011),
  Lexington, KY, U.S.A., July 10, 2011</comments><acm-class>D.1.6; D.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new high-level interface to multi-threading in Prolog, implemented in
hProlog, is described. Modern CPUs often contain multiple cores and through
high-level multi-threading a programmer can leverage this power without having
to worry about low-level details. Two common types of high-level explicit
parallelism are discussed: independent and-parallelism and competitive
or-parallelism. A new type of explicit parallelism, pipeline parallelism, is
proposed. This new type can be used in certain cases where independent
and-parallelism and competitive or-parallelism cannot be used.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3787</identifier>
 <datestamp>2011-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3787</id><created>2011-12-16</created><authors><author><keyname>Campagna</keyname><forenames>Dario</forenames></author><author><keyname>Sarna-Starosta</keyname><forenames>Beata</forenames></author><author><keyname>Schrijvers</keyname><forenames>Tom</forenames></author></authors><title>Approximating Constraint Propagation in Datalog</title><categories>cs.PL</categories><comments>Online Proceedings of the 11th International Colloquium on
  Implementation of Constraint LOgic Programming Systems (CICLOPS 2011),
  Lexington, KY, U.S.A., July 10, 2011</comments><acm-class>D.1.6; D.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a technique exploiting Datalog with aggregates to improve the
performance of programs with arithmetic (in)equalities. Our approach employs a
source-to-source program transformation which approximates the propagation
technique from Constraint Programming. The experimental evaluation of the
approach shows good run time speed-ups on a range of non-recursive as well as
recursive programs. Furthermore, our technique improves upon the previously
reported in the literature constraint magic set transformation approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3788</identifier>
 <datestamp>2011-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3788</id><created>2011-12-16</created><authors><author><keyname>Tarau</keyname><forenames>Paul</forenames></author></authors><title>Bijective Term Encodings</title><categories>cs.PL</categories><comments>Online Proceedings of the 11th International Colloquium on
  Implementation of Constraint LOgic Programming Systems (CICLOPS 2011),
  Lexington, KY, U.S.A., July 10, 2011</comments><acm-class>D.1.6; D.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We encode/decode Prolog terms as unique natural numbers. Our encodings have
the following properties: a) are bijective b) natural numbers always decode to
syntactically valid terms c) they work in low polynomial time in the bitsize of
the representations d) the bitsize of our encodings is within constant factor
of the syntactic representation of the input.
  We describe encodings of term algebras with finite signature as well as
algorithms that separate the &quot;structure&quot; of a term, a natural number encoding
of a list of balanced parenthesis, from its &quot;content&quot;, a list of atomic terms
and Prolog variables. The paper is organized as a literate Prolog program
available from \url{http://logic.cse.unt.edu/tarau/research/2011/bijenc.pl}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3789</identifier>
 <datestamp>2011-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3789</id><created>2011-12-16</created><authors><author><keyname>Alqaddoumi</keyname><forenames>Abdulla</forenames></author><author><keyname>Pontelli</keyname><forenames>Enrico</forenames></author></authors><title>An Implementation of Bubbling</title><categories>cs.PL</categories><comments>Online Proceedings of the 11th International Colloquium on
  Implementation of Constraint LOgic Programming Systems (CICLOPS 2011),
  Lexington, KY, U.S.A., July 10, 2011</comments><acm-class>D.1.6; D.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Non-determinism is of great importance in functional logic programming. It
provides expressiveness and efficiency to functional logic computations. In
this paper we describe an implementation of the multi-paradigm functional logic
language Curry. The evaluation strategy employed by the implementation is based
on definitional trees and needed narrowing for deterministic operations, while
non-deterministic operations will depend on the graph transformation, bubbling.
Bubbling preserves the completeness of non-deterministic operations and avoids
unnecessary large-scale reconstruction of expressions done by other approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3791</identifier>
 <datestamp>2012-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3791</id><created>2011-12-16</created><updated>2012-03-31</updated><authors><author><keyname>Ahadpour</keyname><forenames>Sodeif</forenames></author><author><keyname>Sadra</keyname><forenames>Yaser</forenames></author><author><keyname>ArastehFard</keyname><forenames>Zahra</forenames></author></authors><title>A Novel Chaotic Image Encryption using Generalized Threshold Function</title><categories>cs.CR physics.data-an</categories><comments>7 pages, 5 figures, Published in international Journal of Computer
  Applications (March 2012)</comments><journal-ref>International Journal of Computer Applications 42(18):25-31, March
  2012</journal-ref><doi>10.5120/5794-8110</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, after reviewing the main points of image encryption and
threshold function, we introduce the methods of chaotic image encryption based
on pseudorandom bit padding that the bits be generated by the novel generalized
threshold function (segmentation and self-similarity) methods. These methods
decrease periodic effect of the ergodic dynamical systems in randomness of the
chaotic image encryption. The essential idea of this paper is that given
threshold functions of the ergodic dynamical systems. To evaluate the security
of the cipher image of this scheme, the key space analysis, the correlation of
two adjacent pixels and differential attack were performed. This scheme tries
to improve the problem of failure of encryption such as small key space and
level of security.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3805</identifier>
 <datestamp>2012-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3805</id><created>2011-12-16</created><updated>2012-10-01</updated><authors><author><keyname>Jacobs</keyname><forenames>Bart</forenames><affiliation>Radboud University Nijmegen</affiliation></author><author><keyname>Mandemaker</keyname><forenames>Jorik</forenames><affiliation>Radboud University Nijmegen</affiliation></author></authors><title>The Expectation Monad in Quantum Foundations</title><categories>math.CT cs.OH</categories><comments>In Proceedings QPL 2011, arXiv:1210.0298</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 95, 2012, pp. 143-182</journal-ref><doi>10.4204/EPTCS.95.12</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The expectation monad is introduced abstractly via two composable
adjunctions, but concretely captures measures. It turns out to sit in between
known monads: on the one hand the distribution and ultrafilter monad, and on
the other hand the continuation monad. This expectation monad is used in two
probabilistic analogues of fundamental results of Manes and Gelfand for the
ultrafilter monad: algebras of the expectation monad are convex compact
Hausdorff spaces, and are dually equivalent to so-called Banach effect
algebras. These structures capture states and effects in quantum foundations,
and also the duality between them. Moreover, the approach leads to a new
re-formulation of Gleason's theorem, expressing that effects on a Hilbert space
are free effect modules on projections, obtained via tensoring with the unit
interval.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3810</identifier>
 <datestamp>2012-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3810</id><created>2011-12-16</created><updated>2012-05-21</updated><authors><author><keyname>Ngo</keyname><forenames>Hien Quoc</forenames></author><author><keyname>Larsson</keyname><forenames>Erik G.</forenames></author><author><keyname>Marzetta</keyname><forenames>Thomas L.</forenames></author></authors><title>Energy and Spectral Efficiency of Very Large Multiuser MIMO Systems</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE Transactions on Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A multiplicity of autonomous terminals simultaneously transmits data streams
to a compact array of antennas. The array uses imperfect channel-state
information derived from transmitted pilots to extract the individual data
streams. The power radiated by the terminals can be made inversely proportional
to the square-root of the number of base station antennas with no reduction in
performance. In contrast if perfect channel-state information were available
the power could be made inversely proportional to the number of antennas. Lower
capacity bounds for maximum-ratio combining (MRC), zero-forcing (ZF) and
minimum mean-square error (MMSE) detection are derived. A MRC receiver normally
performs worse than ZF and MMSE. However as power levels are reduced, the
cross-talk introduced by the inferior maximum-ratio receiver eventually falls
below the noise level and this simple receiver becomes a viable option. The
tradeoff between the energy efficiency (as measured in bits/J) and spectral
efficiency (as measured in bits/channel use/terminal) is quantified. It is
shown that the use of moderately large antenna arrays can improve the spectral
and energy efficiency with orders of magnitude compared to a single-antenna
system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3833</identifier>
 <datestamp>2011-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3833</id><created>2011-12-16</created><authors><author><keyname>Armstrong</keyname><forenames>Alasdair</forenames></author><author><keyname>Foster</keyname><forenames>Simon</forenames></author><author><keyname>Struth</keyname><forenames>Georg</forenames></author></authors><title>Dependently Typed Programming based on Automated Theorem Proving</title><categories>cs.PL</categories><acm-class>D.1.1; F.3.1; F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mella is a minimalistic dependently typed programming language and
interactive theorem prover implemented in Haskell. Its main purpose is to
investigate the effective integration of automated theorem provers in a pure
and simple setting. Such integrations are essential for supporting program
development in dependently typed languages. We integrate the equational theorem
prover Waldmeister and test it on more than 800 proof goals from the TPTP
library. In contrast to previous approaches, the reconstruction of Waldmeister
proofs within Mella is quite robust and does not generate a significant
overhead to proof search. Mella thus yields a template for integrating more
expressive theorem provers in more sophisticated languages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3839</identifier>
 <datestamp>2013-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3839</id><created>2011-12-16</created><updated>2012-04-27</updated><authors><author><keyname>Farokhi</keyname><forenames>Farhad</forenames></author><author><keyname>Langbort</keyname><forenames>Cedric</forenames></author><author><keyname>Johansson</keyname><forenames>Karl H.</forenames></author></authors><title>Optimal Structured Static State-Feedback Control Design with Limited
  Model Information for Fully-Actuated Systems</title><categories>math.OC cs.SY</categories><comments>Extension of this article's results for disturbance accommodation
  problem can be found in arXiv:1112.5032</comments><journal-ref>Automatica, Volume 49, Issue 2, February 2013, Pages 326-337</journal-ref><doi>10.1016/j.automatica.2012.10.004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce the family of limited model information control design methods,
which construct controllers by accessing the plant's model in a constrained
way, according to a given design graph. We investigate the closed-loop
performance achievable by such control design methods for fully-actuated
discrete-time linear time-invariant systems, under a separable quadratic cost.
We restrict our study to control design methods which produce structured static
state feedback controllers, where each subcontroller can at least access the
state measurements of those subsystems that affect its corresponding subsystem.
We compute the optimal control design strategy (in terms of the competitive
ratio and domination metrics) when the control designer has access to the local
model information and the global interconnection structure of the
plant-to-be-controlled. Lastly, we study the trade-off between the amount of
model information exploited by a control design method and the best closed-loop
performance (in terms of the competitive ratio) of controllers it can produce.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3844</identifier>
 <datestamp>2011-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3844</id><created>2011-12-16</created><authors><author><keyname>Sa&#x11f;lam</keyname><forenames>&#xd6;zg&#xfc;r</forenames></author><author><keyname>Dalkili&#xe7;</keyname><forenames>Mehmet Emin</forenames></author></authors><title>Cross Layer Implementation of Key Establishment and Configuration
  Protocols in WSN</title><categories>cs.DC cs.CR</categories><comments>16 pages, 12 figures</comments><msc-class>68M99</msc-class><acm-class>C.2.1</acm-class><journal-ref>IJCSI, Vol. 8 Issue 6 No 2, November 2011, pp. 86-101</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Security in Wireless Sensor Networks (WSN) can be achieved by establishing
shared keys among the neighbor sensor nodes to create secure communication
links. The protocol to be used for such a pairwise key establishment is a key
factor determining the energy to be consumed by each sensor node during the
secure network configuration. On the other hand, to achieve the optimum network
configuration, nodes may not need to establish pairwise keys with all of their
neighbors. Because, links to be established are defined by the network
configuration protocol and as long as the network connectivity requirements are
satisfied, number of links to be secured can be limited accordingly. In this
sense, key establishment and network configuration performances are related to
each other and this cross relation should be taken into consideration while
implementing security for WSN. In this paper, we have investigated the cross
layer relations and performance figures of the selected randomized
pre-distribution and public key based key establishment protocols with the
configuration protocol we proposed in a separate publication. Simulation
results indicate that total network configuration energy cost can be reduced by
reducing the number of links to be secured without affecting the global network
connectivity performance. Results also show that the energy and resilience
performances of the public key establishment can be better than the key
pre-distribution for a given set of network configuration parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3867</identifier>
 <datestamp>2012-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3867</id><created>2011-12-16</created><authors><author><keyname>Adami</keyname><forenames>Christoph</forenames></author></authors><title>The use of information theory in evolutionary biology</title><categories>q-bio.PE cs.IT math.IT q-bio.NC</categories><comments>25 pages, 7 figures. To appear in &quot;The Year in Evolutionary Biology&quot;,
  of the Annals of the NY Academy of Sciences</comments><journal-ref>Annals NY Acad. Sciences 1256 (2012) 49-65</journal-ref><doi>10.1111/j.1749-6632.2011.06422.x</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Information is a key concept in evolutionary biology. Information is stored
in biological organism's genomes, and used to generate the organism as well as
to maintain and control it. Information is also &quot;that which evolves&quot;. When a
population adapts to a local environment, information about this environment is
fixed in a representative genome. However, when an environment changes,
information can be lost. At the same time, information is processed by animal
brains to survive in complex environments, and the capacity for information
processing also evolves. Here I review applications of information theory to
the evolution of proteins as well as to the evolution of information processing
in simulated agents that adapt to perform a complex task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3873</identifier>
 <datestamp>2011-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3873</id><created>2011-12-16</created><authors><author><keyname>Friot</keyname><forenames>Nicolas</forenames></author><author><keyname>Guyeux</keyname><forenames>Christophe</forenames></author><author><keyname>Bahi</keyname><forenames>Jacques M.</forenames></author></authors><title>Chaotic iterations for steganography: Stego-security and
  topological-security</title><categories>cs.CR cs.MM math.DS math.GN</categories><comments>15 pages; 3 figures; SECRYPT 2011: International Conference on
  Security and Cryptography, Seville, Spain, 18-21 July</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper is proposed a novel steganographic scheme based on chaotic
iterations. This research work takes place into the information hiding security
fields. We show that the proposed scheme is stego-secure, which is the highest
level of security in a well defined and studied category of attack called
&quot;watermark-only attack&quot;. Additionally, we prove that this scheme presents
topological properties so that it is one of the firsts able to face, at least
partially, an adversary when considering the others categories of attacks
defined in the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3874</identifier>
 <datestamp>2011-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3874</id><created>2011-12-16</created><authors><author><keyname>Guyeux</keyname><forenames>Christophe</forenames></author><author><keyname>Friot</keyname><forenames>Nicolas</forenames></author><author><keyname>Bahi</keyname><forenames>Jacques M.</forenames></author></authors><title>Chaotic iterations versus Spread-spectrum: topological-security and
  stego-security</title><categories>cs.CR cs.MM math.DS math.GN</categories><comments>2 figures; 10 pages; IIH-MSP 2010: The Sixth International Conference
  on Intelligent Information Hiding and Multimedia Signal Processing, October
  15-17, 2010 Darmstadt, Germany</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new framework for information hiding security, called topological-security,
has been proposed in a previous study. It is based on the evaluation of
unpredictability of the scheme, whereas existing notions of security, as
stego-security, are more linked to information leaks. It has been proven that
spread-spectrum techniques, a well-known stego-secure scheme, are
topologically-secure too. In this paper, the links between the two notions of
security is deepened and the usability of topological-security is clarified, by
presenting a novel data hiding scheme that is twice stego and
topological-secure. This last scheme has better scores than spread-spectrum
when evaluating qualitative and quantitative topological-security properties.
Incidentally, this result shows that the new framework for security tends to
improve the ability to compare data hiding scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3877</identifier>
 <datestamp>2011-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3877</id><created>2011-12-16</created><authors><author><keyname>Malathi</keyname><forenames>S.</forenames></author><author><keyname>Sridhar</keyname><forenames>S.</forenames></author></authors><title>A Classical Fuzzy Approach for Software Effort Estimation on Machine
  Learning Technique</title><categories>cs.SE</categories><comments>5 pages, 2 figures, 4 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Software Cost Estimation with resounding reliability,productivity and
development effort is a challenging and onerous task. This has incited the
software community to give much needed thrust and delve into extensive research
in software effort estimation for evolving sophisticated methods. Estimation by
analogy is one of the expedient techniques in software effort estimation field.
However, the methodology utilized for the estimation of software effort by
analogy is not able to handle the categorical data in an explicit and precise
manner. A new approach has been developed in this paper to estimate software
effort for projects represented by categorical or numerical data using
reasoning by analogy and fuzzy approach. The existing historical data sets,
analyzed with fuzzy logic, produce accurate results in comparison to the data
set analyzed with the earlier methodologies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3880</identifier>
 <datestamp>2012-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3880</id><created>2011-12-16</created><updated>2012-02-06</updated><authors><author><keyname>Menzel</keyname><forenames>Michael</forenames></author><author><keyname>Ranjan</keyname><forenames>Rajiv</forenames></author></authors><title>CloudGenius: Automated Decision Support for Migrating Multi-Component
  Enterprise Applications to Clouds</title><categories>cs.DC</categories><comments>technical report</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the key problems in migrating multi-component enterprise applications
to Clouds is selecting the best mix of VM images and Cloud infrastructure
services. A migration process has to ensure that Quality of Service (QoS)
requirements are met, while satisfying conflicting selection criteria, e.g.
throughput and cost. When selecting Cloud services, application engineers must
consider heterogeneous sets of criteria and complex dependencies across
multiple layers impossible to resolve manually. To overcome this challenge, we
present the generic recommender framework CloudGenius and an implementation
that leverage well known multi-criteria decision making technique Analytic
Hierarchy Process to automate the selection process based on a model, factors,
and QoS requirements related to enterprise applications. In particular, we
introduce a structured migration process for multi-component enterprise
applications, clearly identify the most important criteria relevant to the
selection problem and present a multi-criteria-based selection algorithm.
Experiments with the software prototype CumulusGenius show time complexities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3925</identifier>
 <datestamp>2012-10-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3925</id><created>2011-12-16</created><updated>2012-10-23</updated><authors><author><keyname>Je&#x159;&#xe1;bek</keyname><forenames>Emil</forenames></author></authors><title>Root finding with threshold circuits</title><categories>cs.DS cs.LO</categories><comments>19 pages, 1 figure</comments><acm-class>F.2.1; F.1.3; F.4.1</acm-class><journal-ref>Theoretical Computer Science 462 (2012), pp. 59--69</journal-ref><doi>10.1016/j.tcs.2012.09.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that for any constant d, complex roots of degree d univariate
rational (or Gaussian rational) polynomials---given by a list of coefficients
in binary---can be computed to a given accuracy by a uniform TC^0 algorithm (a
uniform family of constant-depth polynomial-size threshold circuits). The basic
idea is to compute the inverse function of the polynomial by a power series. We
also discuss an application to the theory VTC^0 of bounded arithmetic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3946</identifier>
 <datestamp>2012-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3946</id><created>2011-12-16</created><updated>2012-01-04</updated><authors><author><keyname>Zhang</keyname><forenames>Hui</forenames></author><author><keyname>Cai</keyname><forenames>Jian-Feng</forenames></author><author><keyname>Cheng</keyname><forenames>Lizhi</forenames></author><author><keyname>Zhu</keyname><forenames>Jubo</forenames></author></authors><title>Strongly Convex Programming for Exact Matrix Completion and Robust
  Principal Component Analysis</title><categories>cs.IT cs.LG math.IT</categories><comments>17 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The common task in matrix completion (MC) and robust principle component
analysis (RPCA) is to recover a low-rank matrix from a given data matrix. These
problems gained great attention from various areas in applied sciences
recently, especially after the publication of the pioneering works of Cand`es
et al.. One fundamental result in MC and RPCA is that nuclear norm based convex
optimizations lead to the exact low-rank matrix recovery under suitable
conditions. In this paper, we extend this result by showing that strongly
convex optimizations can guarantee the exact low-rank matrix recovery as well.
The result in this paper not only provides sufficient conditions under which
the strongly convex models lead to the exact low-rank matrix recovery, but also
guides us on how to choose suitable parameters in practical algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.3972</identifier>
 <datestamp>2013-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.3972</id><created>2011-12-16</created><authors><author><keyname>Vassev</keyname><forenames>Emil</forenames></author><author><keyname>Mokhov</keyname><forenames>Serguei A.</forenames></author></authors><title>Developing Autonomic Properties for Distributed Pattern-Recognition
  Systems with ASSL: A Distributed MARF Case Study</title><categories>cs.DC cs.CV cs.SE</categories><comments>28 pages; 16 figures; Submitted and accepted in 2010; to appear in
  &quot;E. Vassev and S. A. Mokhov. Development and evaluation of autonomic
  properties for pattern-recognition systems with ASSL -- a distributed MARF
  case study. Transactions on Computational Science, Special Issue on Advances
  in Autonomic Computing: Formal Engineering Methods for Nature-Inspired
  Computing Systems, XV (LNCS7050).&quot;</comments><journal-ref>J. Trans. on Comput. Sci. XV, Springer-Verlag,130-157</journal-ref><doi>10.1007/978-3-642-28525-7_5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we discuss our research towards developing special properties
that introduce autonomic behavior in pattern-recognition systems. In our
approach we use ASSL (Autonomic System Specification Language) to formally
develop such properties for DMARF (Distributed Modular Audio Recognition
Framework). These properties enhance DMARF with an autonomic middleware that
manages the four stages of the framework's pattern-recognition pipeline. DMARF
is a biologically inspired system employing pattern recognition, signal
processing, and natural language processing helping us process audio, textual,
or imagery data needed by a variety of scientific applications, e.g., biometric
applications. In that context, the notion go autonomic DMARF (ADMARF) can be
employed by autonomous and robotic systems that theoretically require
less-to-none human intervention other than data collection for pattern analysis
and observing the results. In this article, we explain the ASSL specification
models for the autonomic properties of DMARF.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4002</identifier>
 <datestamp>2013-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4002</id><created>2011-12-16</created><updated>2012-08-03</updated><authors><author><keyname>Yagan</keyname><forenames>Osman</forenames></author><author><keyname>Qian</keyname><forenames>Dajun</forenames></author><author><keyname>Zhang</keyname><forenames>Junshan</forenames></author><author><keyname>Cochran</keyname><forenames>Douglas</forenames></author></authors><title>Conjoining Speeds up Information Diffusion in Overlaying Social-Physical
  Networks</title><categories>cs.SI physics.soc-ph</categories><comments>14 pages, 4 figures</comments><journal-ref>IEEE Journal on Selected Areas in Communications (JSAC): Special
  Issue on Network Science, 31(6):1038-1048, June 2013</journal-ref><doi>10.1109/JSAC.2013.130606</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the diffusion of information in an overlaying social-physical
network. Specifically, we consider the following set-up: There is a physical
information network where information spreads amongst people through
conventional communication media (e.g., face-to-face communication, phone
calls), and conjoint to this physical network, there are online social networks
where information spreads via web sites such as Facebook, Twitter, FriendFeed,
YouTube, etc. We quantify the size and the critical threshold of information
epidemics in this conjoint social-physical network by assuming that information
diffuses according to the SIR epidemic model. One interesting finding is that
even if there is no percolation in the individual networks, percolation (i.e.,
information epidemics) can take place in the conjoint social-physical network.
We also show, both analytically and experimentally, that the fraction of
individuals who receive an item of information (started from an arbitrary node)
is significantly larger in the conjoint social-physical network case, as
compared to the case where the networks are disjoint. These findings reveal
that conjoining the physical network with online social networks can have a
dramatic impact on the speed and scale of information diffusion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4006</identifier>
 <datestamp>2011-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4006</id><created>2011-12-16</created><authors><author><keyname>Daskalakis</keyname><forenames>Constantinos</forenames></author><author><keyname>Weinberg</keyname><forenames>S. Matthew</forenames></author></authors><title>On Optimal Multi-Dimensional Mechanism Design</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We efficiently solve the optimal multi-dimensional mechanism design problem
for independent bidders with arbitrary demand constraints when either the
number of bidders is a constant or the number of items is a constant. In the
first setting, we need that each bidder's values for the items are sampled from
a possibly correlated, item-symmetric distribution, allowing different
distributions for each bidder. In the second setting, we allow the values of
each bidder for the items to be arbitrarily correlated, but assume that the
distribution of bidder types is bidder-symmetric.
  For all eps&gt;0, we obtain an additive eps-approximation, when the value
distributions are bounded, or a multiplicative (1-eps)-approximation when the
value distributions are unbounded, but satisfy the Monotone Hazard Rate
condition, covering a widely studied class of distributions in Economics. Our
runtime is polynomial in max{#items,#bidders}, and not the size of the support
of the joint distribution of all bidders' values for all items, which is
typically exponential in both the number of items and the number of bidders.
Our mechanisms are randomized, explicitly price bundles, and can sometimes
accommodate budget constraints.
  Our results are enabled by establishing several new tools and structural
properties of Bayesian mechanisms. We provide a symmetrization technique
turning any truthful mechanism into one that has the same revenue and respects
all symmetries in the underlying value distributions. We also prove that
item-symmetric mechanisms satisfy a natural monotonicity property which, unlike
cyclic-monotonicity, can be harnessed algorithmically. Finally, we provide a
technique that turns any given eps-BIC mechanism (i.e. one where incentive
constraints are violated by eps) into a truly-BIC mechanism at the cost of
O(sqrt{eps}) revenue. We expect our tools to be used beyond the settings we
consider here.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4011</identifier>
 <datestamp>2013-04-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4011</id><created>2011-12-16</created><authors><author><keyname>Bamieh</keyname><forenames>Bassam</forenames></author><author><keyname>Jovanovi&#x107;</keyname><forenames>Mihailo R.</forenames></author><author><keyname>Mitra</keyname><forenames>Partha</forenames></author><author><keyname>Patterson</keyname><forenames>Stacy</forenames></author></authors><title>Coherence in Large-Scale Networks: Dimension-Dependent Limitations of
  Local Feedback</title><categories>math.OC cs.MA cs.SY</categories><comments>To appear in IEEE Trans. Automat. Control; 15 pages, 2 figures</comments><journal-ref>IEEE Trans. Automat. Control (2012), vol. 57, no. 9, pp. 2235-2249</journal-ref><doi>10.1109/TAC.2012.2202052</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider distributed consensus and vehicular formation control problems.
Specifically we address the question of whether local feedback is sufficient to
maintain coherence in large-scale networks subject to stochastic disturbances.
We define macroscopic performance measures which are global quantities that
capture the notion of coherence; a notion of global order that quantifies how
closely the formation resembles a solid object. We consider how these measures
scale asymptotically with network size in the topologies of regular lattices in
1, 2 and higher dimensions, with vehicular platoons corresponding to the 1
dimensional case. A common phenomenon appears where a higher spatial dimension
implies a more favorable scaling of coherence measures, with a dimensions of 3
being necessary to achieve coherence in consensus and vehicular formations
under certain conditions. In particular, we show that it is impossible to have
large coherent one dimensional vehicular platoons with only local feedback. We
analyze these effects in terms of the underlying energetic modes of motion,
showing that they take the form of large temporal and spatial scales resulting
in an accordion-like motion of formations. A conclusion can be drawn that in
low spatial dimensions, local feedback is unable to regulate large-scale
disturbances, but it can in higher spatial dimensions. This phenomenon is
distinct from, and unrelated to string instability issues which are commonly
encountered in control problems for automated highways.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4014</identifier>
 <datestamp>2011-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4014</id><created>2011-12-16</created><authors><author><keyname>Cao</keyname><forenames>Zhengjun</forenames></author><author><keyname>Cao</keyname><forenames>Hanyue</forenames></author></authors><title>Note on fast division algorithm for polynomials using Newton iteration</title><categories>cs.SC</categories><comments>5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The classical division algorithm for polynomials requires $O(n^2)$ operations
for inputs of size $n$. Using reversal technique and Newton iteration, it can
be improved to $O({M}(n))$, where ${M}$ is a multiplication time. But the
method requires that the degree of the modulo, $x^l$, should be the power of 2.
If $l$ is not a power of 2 and $f(0)=1$, Gathen and Gerhard suggest to compute
the inverse,$f^{-1}$, modulo $x^{\lceil l/2^r\rceil}, x^{\lceil
l/2^{r-1}\rceil},..., x^{\lceil l/2\rceil}, x^l$, separately. But they did not
specify the iterative step. In this note, we show that the original Newton
iteration formula can be directly used to compute $f^{-1}\,{mod}\,x^{l}$
without any additional cost, when $l$ is not a power of 2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4016</identifier>
 <datestamp>2011-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4016</id><created>2011-12-16</created><authors><author><keyname>Nguyen</keyname><forenames>Phuc V.</forenames></author></authors><title>The Study and Approach of Software Re-Engineering</title><categories>cs.SE</categories><comments>9 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The nature of software re-engineering is to improve or transform existing
software so it can be understood, controlled and reused as new software. Needs,
the necessity of re-engineering software has greatly increased. The system
software has become obsolete no longer used in architecture, platform they're
running, stable and consistent they support the development and support needs
change. Software re-engineering is vital to restore and reuse the things
inherent in the existing software, put the cost of software maintenance to the
lowest in the control and establish a basis for the development of software in
the future.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4017</identifier>
 <datestamp>2011-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4017</id><created>2011-12-16</created><authors><author><keyname>Nguyen</keyname><forenames>Phuc V.</forenames><affiliation>Ho Chi Minh City's Vietnamese Communist Party Committee</affiliation></author></authors><title>ITIL frameworks to ITD Company for improving capabilities in service
  management</title><categories>cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  IT operates in dynamic environments with the need always to change and adapt.
There is a need to improve performance. Many gaps were found when we conduct
the IT audit and we tried to seek to close gaps in capabilities. One way to the
close these gaps is the adoption of good practices in wide industry use. There
are several sources for good practices including public frameworks and
standards such as ITIL, COBIT, CMMI, eSCM-SP, PRINCE2, ISO 9000, ISO/IEC 20000
and ISO/IEC 27001, etc. The paper propose ITIL frameworks to ITD Company for
improving capabilities in service management.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4018</identifier>
 <datestamp>2011-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4018</id><created>2011-12-16</created><authors><author><keyname>Nguyen</keyname><forenames>Phuc V.</forenames></author></authors><title>Mobile IP and protocol authentication extension</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mobile IP is an open standard, defined by the Internet Engineering Task Force
(IETF) RFC 3220. By using Mobile IP, you can keep the same IP address, stay
connected, and maintain ongoing applications while roaming between IP networks.
Mobile IP is scalable for the Internet because it is based on IP - any media
that can support IP can support Mobile IP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4019</identifier>
 <datestamp>2011-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4019</id><created>2011-12-16</created><authors><author><keyname>Nguyen</keyname><forenames>Phuc V.</forenames></author></authors><title>Legal Resources Information System for Information Agencies of
  Specialized Libraries</title><categories>cs.DL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, the rapid development of information technology and
communication has a strong impact to industry information - the library. The
mission of the industry when in fact the great social place to see the library
as knowledge management. Vietnam is in the process of building the rule of law
socialist orientation and improves the legal system. So in the current
development process, the law library plays an important role in the retention,
dissemination and provision of legal information service of legislative,
executive and judiciary, particularly especially research, teaching and
learning of law school. But the response of the legal information library
information agencies remains limited compared to the increasing demand of
users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4020</identifier>
 <datestamp>2011-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4020</id><created>2011-12-16</created><authors><author><keyname>Mirzal</keyname><forenames>Andri</forenames></author></authors><title>Clustering and Latent Semantic Indexing Aspects of the Nonnegative
  Matrix Factorization</title><categories>cs.LG</categories><comments>28 pages, 5 figures</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper provides a theoretical support for clustering aspect of the
nonnegative matrix factorization (NMF). By utilizing the Karush-Kuhn-Tucker
optimality conditions, we show that NMF objective is equivalent to graph
clustering objective, so clustering aspect of the NMF has a solid
justification. Different from previous approaches which usually discard the
nonnegativity constraints, our approach guarantees the stationary point being
used in deriving the equivalence is located on the feasible region in the
nonnegative orthant. Additionally, since clustering capability of a matrix
decomposition technique can sometimes imply its latent semantic indexing (LSI)
aspect, we will also evaluate LSI aspect of the NMF by showing its capability
in solving the synonymy and polysemy problems in synthetic datasets. And more
extensive evaluation will be conducted by comparing LSI performances of the NMF
and the singular value decomposition (SVD), the standard LSI method, using some
standard datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4031</identifier>
 <datestamp>2011-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4031</id><created>2011-12-17</created><authors><author><keyname>Hilage</keyname><forenames>Tejaswini</forenames></author><author><keyname>Kulkarni</keyname><forenames>R. V.</forenames></author></authors><title>Application of Data Mining Techniques to a Selected Business
  Organisation with Special Reference to Buying Behaviour</title><categories>cs.DB cs.AI</categories><comments>16</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Data mining is a new concept &amp; an exploration and analysis of large data
sets, in order to discover meaningful patterns and rules. Many organizations
are now using the data mining techniques to find out meaningful patterns from
the database. The present paper studies how data mining techniques can be apply
to the large database. These data mining techniques give certain behavioral
pattern from the database. The results which come after analysis of the
database are useful for organization. This paper examines the result after
applying association rule mining technique, rule induction technique and
Apriori algorithm. These techniques are applied to the database of shopping
mall. Market basket analysis is performing by the above mentioned techniques
and some important results are found such as buying behavior.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4033</identifier>
 <datestamp>2011-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4033</id><created>2011-12-17</created><authors><author><keyname>Moses</keyname><forenames>William K.</forenames><suffix>Jr.</suffix></author><author><keyname>Rangan</keyname><forenames>C. Pandu</forenames></author></authors><title>Rational Secret Sharing over an Asynchronous Broadcast Channel with
  Information Theoretic Security</title><categories>cs.CR cs.GT</categories><comments>18 pages, 2 tables</comments><journal-ref>International Journal of Network Security &amp; Its Applications
  (IJNSA), Volume 3, Number 6, November 2011, pp. 1-18</journal-ref><doi>10.5121/ijnsa.2011.3601</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of rational secret sharing introduced by Halpern and
Teague [1], where the players involved in secret sharing play only if it is to
their advantage. This can be characterized in the form of preferences. Players
would prefer to get the secret than to not get it and secondly with lesser
preference, they would like as few other players to get the secret as possible.
Several positive results have already been published to efficiently solve the
problem of rational secret sharing but only a handful of papers have touched
upon the use of an asynchronous broadcast channel. [2] used cryptographic
primitives, [3] used an interactive dealer, and [4] used an honest minority of
players in order to handle an asynchronous broadcast channel.
  In our paper, we propose an m-out-of-n rational secret sharing scheme which
can function over an asynchronous broadcast channel without the use of
cryptographic primitives and with a non-interactive dealer. This is possible
because our scheme uses a small number, k+1, of honest players. The protocol is
resilient to coalitions of size up to k and furthermore it is
{\epsilon}-resilient to coalitions of size up to and including m-1. The
protocol will have a strict Nash equilibrium with probability Pr((k+1)/n) and
an {\epsilon}-Nash equilibrium with probability Pr((n-k-1)/n) . Furthermore,
our protocol is immune to backward induction.
  Later on in the paper, we extend our results to include malicious players as
well.
  We also show that our protocol handles the possibility of a player deviating
in order to force another player to get a wrong value in what we believe to be
a more time efficient manner than was done in Asharov and Lindell [5].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4035</identifier>
 <datestamp>2011-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4035</id><created>2011-12-17</created><authors><author><keyname>Chen</keyname><forenames>Hongyang</forenames></author><author><keyname>Ouyang</keyname><forenames>Robin Wentao</forenames></author><author><keyname>Wang</keyname><forenames>Chen</forenames></author></authors><title>Distributed Source Localization in Wireless Underground Sensor Networks</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE TPDS SI on CPS</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Node localization plays an important role in many practical applications of
wireless underground sensor networks (WUSNs), such as finding the locations of
earthquake epicenters, underground explosions, and microseismic events in
mines. It is more difficult to obtain the time-difference-of-arrival (TDOA)
measurements in WUSNs than in terrestrial wireless sensor networks because of
the unfavorable channel characteristics in the underground environment. The
robust Chinese remainder theorem (RCRT) has been shown to be an effective tool
for solving the phase ambiguity problem and frequency estimation problem in
wireless sensor networks. In this paper, the RCRT is used to robustly estimate
TDOA or range difference in WUSNs and therefore improves the ranging accuracy
in such networks. After obtaining the range difference, distributed source
localization algorithms based on a diffusion strategy are proposed to decrease
the communication cost while satisfying the localization accuracy requirement.
Simulation results confirm the validity and e?ciency of the proposed methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4037</identifier>
 <datestamp>2011-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4037</id><created>2011-12-17</created><authors><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author><author><keyname>Bornmann</keyname><forenames>Lutz</forenames></author></authors><title>Testing Differences Statistically with the Leiden Ranking</title><categories>cs.CY</categories><comments>Letter to the Editor</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Leiden Ranking 2011/2012 provides the Proportion top-10% publications (PP
top 10%) as a new indicator. This indicator allows for testing the difference
between two ranks for statistical significance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4049</identifier>
 <datestamp>2011-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4049</id><created>2011-12-17</created><authors><author><keyname>Pakala</keyname><forenames>Hara Gopal Mani</forenames></author><author><keyname>Varaprasad</keyname><forenames>Dr. Plh</forenames></author><author><keyname>Kvsvn</keyname><forenames>Dr. Raju</forenames></author><author><keyname>Khan</keyname><forenames>Dr. Ibrahim</forenames></author></authors><title>An Adaptive Design Methodology for Reduction of Product Development Risk</title><categories>cs.SE</categories><comments>21 pages, 9 figures</comments><journal-ref>International Journal of Ad hoc, Sensor &amp; Ubiquitous Computing
  (IJASUC) Vol.2, No.3, September 2011, p35-55</journal-ref><doi>10.5121/ijasuc.2011.2303</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Embedded systems interaction with environment inherently complicates
understanding of requirements and their correct implementation. However,
product uncertainty is highest during early stages of development. Design
verification is an essential step in the development of any system, especially
for Embedded System. This paper introduces a novel adaptive design methodology,
which incorporates step-wise prototyping and verification. With each adaptive
step product-realization level is enhanced while decreasing the level of
product uncertainty, thereby reducing the overall costs. The back-bone of this
frame-work is the development of Domain Specific Operational (DOP) Model and
the associated Verification Instrumentation for Test and Evaluation, developed
based on the DOP model. Together they generate functionally valid test-sequence
for carrying out prototype evaluation. With the help of a case study 'Multimode
Detection Subsystem' the application of this method is sketched. The design
methodologies can be compared by defining and computing a generic performance
criterion like Average design-cycle Risk. For the case study, by computing
Average design-cycle Risk, it is shown that the adaptive method reduces the
product development risk for a small increase in the total design cycle time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4055</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4055</id><created>2011-12-17</created><authors><author><keyname>P&#x142;aczek</keyname><forenames>Bart&#x142;omiej</forenames></author></authors><title>Fuzzy cellular model for on-line traffic simulation</title><categories>cs.ET cs.SY nlin.CG</categories><comments>The original publication is available at http://www.springerlink.com</comments><journal-ref>P{\l}aczek, B., Fuzzy Cellular Model for On-Line Traffic
  Simulation. Lecture Notes in Computer Science 6068. Springer-Verlag, Berlin,
  Heidelberg, pp. 553-560, 2010</journal-ref><doi>10.1007/978-3-642-14403-5_59</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a fuzzy cellular model of road traffic that was
intended for on-line applications in traffic control. The presented model uses
fuzzy sets theory to deal with uncertainty of both input data and simulation
results. Vehicles are modelled individually, thus various classes of them can
be taken into consideration. In the proposed approach, all parameters of
vehicles are described by means of fuzzy numbers. The model was implemented in
a simulation of vehicles queue discharge process. Changes of the queue length
were analysed in this experiment and compared to the results of NaSch cellular
automata model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4057</identifier>
 <datestamp>2011-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4057</id><created>2011-12-17</created><authors><author><keyname>P&#x142;aczek</keyname><forenames>Bart&#x142;omiej</forenames></author></authors><title>Performance Evaluation of Road Traffic Control Using a Fuzzy Cellular
  Model</title><categories>cs.AI cs.SY</categories><comments>The final publication is available at http://www.springerlink.com</comments><journal-ref>P{\l}aczek, B., Performance Evaluation of Road Traffic Control
  Using a Fuzzy Cellular Model. Lecture Notes in Artificial Intelligence 6679.
  Springer-Verlag, Berlin Heidelberg, pp. 59-66, 2011</journal-ref><doi>10.1007/978-3-642-21222-2_8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper a method is proposed for performance evaluation of road traffic
control systems. The method is designed to be implemented in an on-line
simulation environment, which enables optimisation of adaptive traffic control
strategies. Performance measures are computed using a fuzzy cellular traffic
model, formulated as a hybrid system combining cellular automata and fuzzy
calculus. Experimental results show that the introduced method allows the
performance to be evaluated using imprecise traffic measurements. Moreover, the
fuzzy definitions of performance measures are convenient for uncertainty
determination in traffic control decisions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4060</identifier>
 <datestamp>2011-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4060</id><created>2011-12-17</created><authors><author><keyname>P&#x142;aczek</keyname><forenames>Bart&#x142;omiej</forenames></author></authors><title>A real time vehicles detection algorithm for vision based sensors</title><categories>cs.CV</categories><comments>The final publication is available at http://www.springerlink.com</comments><journal-ref>P{\l}aczek B., A real time vehicles detection algorithm for vision
  based sensors, Lecture Notes in Computer Science 6375, Springer-Verlag,
  Berlin Heidelberg, 2010, pp. 211-218</journal-ref><doi>10.1007/978-3-642-15907-7_26</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A vehicle detection plays an important role in the traffic control at
signalised intersections. This paper introduces a vision-based algorithm for
vehicles presence recognition in detection zones. The algorithm uses linguistic
variables to evaluate local attributes of an input image. The image attributes
are categorised as vehicle, background or unknown features. Experimental
results on complex traffic scenes show that the proposed algorithm is effective
for a real-time vehicles detection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4064</identifier>
 <datestamp>2011-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4064</id><created>2011-12-17</created><authors><author><keyname>P&#x142;aczek</keyname><forenames>Bart&#x142;omiej</forenames></author></authors><title>Vehicles Recognition Using Fuzzy Descriptors of Image Segments</title><categories>cs.CV</categories><comments>The final publication is available at http://www.springerlink.com</comments><journal-ref>P{\l}aczek, B.: Vehicles Recognition Using Fuzzy Descriptors of
  Image Segments. Computer Recognition Systems 3, Advances in Intelligent and
  Soft Computing , vol. 57/2009, pp. 79--86. Springer-Verlag, Berlin Heidelberg
  (2009)</journal-ref><doi>10.1007/978-3-540-93905-4_10</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper a vision-based vehicles recognition method is presented.
Proposed method uses fuzzy description of image segments for automatic
recognition of vehicles recorded in image data. The description takes into
account selected geometrical properties and shape coefficients determined for
segments of reference image (vehicle model). The proposed method was
implemented using reasoning system with fuzzy rules. A vehicles recognition
algorithm was developed based on the fuzzy rules describing shape and
arrangement of the image segments that correspond to visible parts of a
vehicle. An extension of the algorithm with set of fuzzy rules defined for
different reference images (and various vehicle shapes) enables vehicles
classification in traffic scenes. The devised method is suitable for
application in video sensors for road traffic control and surveillance systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4076</identifier>
 <datestamp>2011-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4076</id><created>2011-12-17</created><authors><author><keyname>Sofotasios</keyname><forenames>Paschalis C.</forenames></author><author><keyname>Freear</keyname><forenames>Steven</forenames></author></authors><title>Closed-Form Bounds to the Rice and Incomplete Toronto Functions and
  Incomplete Lipschitz-Hankel Integrals</title><categories>cs.IT math.IT</categories><comments>18 pages, 6 Figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article provides novel analytical results for the Rice function, the
incomplete Toronto function and the incomplete Lipschitz-Hankel Integrals.
Firstly, upper and lower bounds are derived for the Rice function, $Ie(k,x)$.
Secondly, explicit expressions are derived for the incomplete Toronto function,
$T_{B}(m,n,r)$, and the incomplete Lipschitz-Hankel Integrals of the modified
Bessel function of the first kind, $Ie_{\mu,n}(a,z)$, for the case that $n$ is
an odd multiple of 0.5 and $m \geq n$. By exploiting these expressions, tight
upper and lower bounds are subsequently proposed for both $T_{B}(m,n,r)$
function and $Ie_{\mu,n}(a,z)$ integrals. Importantly, all new representations
are expressed in closed-form whilst the proposed bounds are shown to be rather
tight. Based on these features, it is evident that the offered results can be
utilized effectively in analytical studies related to wireless communications.
Indicative applications include, among others, the performance evaluation of
digital communications over fading channels and the information-theoretic
analysis of multiple-input multiple-output systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4082</identifier>
 <datestamp>2012-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4082</id><created>2011-12-17</created><updated>2012-01-30</updated><authors><author><keyname>Hill</keyname><forenames>Theodore P.</forenames></author><author><keyname>Rogers</keyname><forenames>Erika</forenames></author></authors><title>Gender Gaps in the Mathematical Sciences: The Creativity Factor</title><categories>math.HO cs.GL physics.ed-ph physics.soc-ph</categories><comments>14 pages, 2 figures</comments><msc-class>01A80, 01A07, 01A99</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article presents an overview, and recent history, of studies of gender
gaps in the mathematically-intensive sciences. Included are several statistics
about gender differences in science, and about public resources aimed at
addressing them. We then examine the role that gender differences in creativity
play in explaining the recent and current gender differences in the
mathematical sciences, and identify several constructive suggestions aimed at
improving analytical creativity output in research institutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4084</identifier>
 <datestamp>2013-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4084</id><created>2011-12-17</created><updated>2012-05-24</updated><authors><author><keyname>Mastronarde</keyname><forenames>Nicholas</forenames></author><author><keyname>Kanoun</keyname><forenames>Karim</forenames></author><author><keyname>Atienza</keyname><forenames>David</forenames></author><author><keyname>Frossard</keyname><forenames>Pascal</forenames></author><author><keyname>van der Schaar</keyname><forenames>Mihaela</forenames></author></authors><title>Markov Decision Process Based Energy-Efficient On-Line Scheduling for
  Slice-Parallel Video Decoders on Multicore Systems</title><categories>cs.MM</categories><journal-ref>IEEE Trans. on Multimedia, vol. 15, no. 2, pp. 268-278, Feb. 2013</journal-ref><doi>10.1109/TMM.2012.2231668</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of energy-efficient on-line scheduling for
slice-parallel video decoders on multicore systems. We assume that each of the
processors are Dynamic Voltage Frequency Scaling (DVFS) enabled such that they
can independently trade off performance for power, while taking the video
decoding workload into account. In the past, scheduling and DVFS policies in
multi-core systems have been formulated heuristically due to the inherent
complexity of the on-line multicore scheduling problem. The key contribution of
this report is that we rigorously formulate the problem as a Markov decision
process (MDP), which simultaneously takes into account the on-line scheduling
and per-core DVFS capabilities; the power consumption of the processor cores
and caches; and the loss tolerant and dynamic nature of the video decoder's
traffic. In particular, we model the video traffic using a Direct Acyclic Graph
(DAG) to capture the precedence constraints among frames in a Group of Pictures
(GOP) structure, while also accounting for the fact that frames have different
display/decoding deadlines and non-deterministic decoding complexities. The
objective of the MDP is to minimize long-term power consumption subject to a
minimum Quality of Service (QoS) constraint related to the decoder's
throughput. Although MDPs notoriously suffer from the curse of dimensionality,
we show that, with appropriate simplifications and approximations, the
complexity of the MDP can be mitigated. We implement a slice-parallel version
of H.264 on a multiprocessor ARM (MPARM) virtual platform simulator, which
provides cycle-accurate and bus signal-accurate simulation for different
processors. We use this platform to generate realistic video decoding traces
with which we evaluate the proposed on-line scheduling algorithm in Matlab.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4090</identifier>
 <datestamp>2015-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4090</id><created>2011-12-17</created><updated>2015-10-23</updated><authors><author><keyname>Koyluoglu</keyname><forenames>O. Ozan</forenames></author><author><keyname>Soundararajan</keyname><forenames>Rajiv</forenames></author><author><keyname>Vishwanath</keyname><forenames>Sriram</forenames></author></authors><title>State Amplification Subject To Masking Constraints</title><categories>cs.IT cs.CR math.IT</categories><comments>Revised version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers a state dependent broadcast channel with one
transmitter, Alice, and two receivers, Bob and Eve. The problem is to
effectively convey (&quot;amplify&quot;) the channel state sequence to Bob while
&quot;masking&quot; it from Eve. The extent to which the state sequence cannot be masked
from Eve is referred to as leakage. This can be viewed as a secrecy problem,
where we desire that the channel state itself be minimally leaked to Eve while
being communicated to Bob. The paper is aimed at characterizing the trade-off
region between amplification and leakage rates for such a system. An achievable
coding scheme is presented, wherein the transmitter transmits a partial state
information over the channel to facilitate the amplification process. For the
case when Bob observes a stronger signal than Eve, the achievable coding scheme
is enhanced with secure refinement. Outer bounds on the trade-off region are
also derived, and used in characterizing some special case results. In
particular, the optimal amplification-leakage rate difference, called as
differential amplification capacity, is characterized for the reversely
degraded discrete memoryless channel, the degraded binary, and the degraded
Gaussian channels. In addition, for the degraded Gaussian model, the extremal
corner points of the trade-off region are characterized, and the gap between
the outer bound and achievable rate-regions is shown to be less than half a bit
for a wide set of channel parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4099</identifier>
 <datestamp>2011-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4099</id><created>2011-12-17</created><authors><author><keyname>Salih</keyname><forenames>Nadir K.</forenames></author><author><keyname>Zang</keyname><forenames>Tianyi</forenames></author><author><keyname>Sun</keyname><forenames>Mingrui</forenames></author></authors><title>Multi databases in Health Care Networks</title><categories>cs.OH</categories><comments>5 Pages,1 Figures</comments><journal-ref>IJCSI International Journal of Computer Science Issues, Vol. 8,
  Issue 6, No 3, November 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  E-Health is a relatively recent term for healthcare practice supported by
electronic processes and communication, dating back to at least 1999. E-Health
is greatly impacting on information distribution and availability within the
health services, hospitals and to the public. E-health was introduced as the
death of telemedicine, because - in the context of a broad availability of
medical information systems that can interconnect and communicate -
telemedicine will no longer exist as a specific field. The same could also be
said for any other traditional field in medical informatics, including
information systems and electronic patient records. E-health presents itself as
a common name for all such technological fields. In this paper we focuses in
multi database by determined some sites and distributed it in Homogenous way.
This will be followed by an illustrative example as related works. Finally, the
paper concludes with general remarks and a statement of further work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4105</identifier>
 <datestamp>2012-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4105</id><created>2011-12-17</created><updated>2012-04-03</updated><authors><author><keyname>Phillips</keyname><forenames>Jeff M.</forenames></author></authors><title>epsilon-Samples of Kernels</title><categories>cs.CG cs.DS cs.LG</categories><comments>13 pages, 2 figures. Cleaned up writing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the worst case error of kernel density estimates via subset
approximation. A kernel density estimate of a distribution is the convolution
of that distribution with a fixed kernel (e.g. Gaussian kernel). Given a subset
(i.e. a point set) of the input distribution, we can compare the kernel density
estimates of the input distribution with that of the subset and bound the worst
case error. If the maximum error is eps, then this subset can be thought of as
an eps-sample (aka an eps-approximation) of the range space defined with the
input distribution as the ground set and the fixed kernel representing the
family of ranges. Interestingly, in this case the ranges are not binary, but
have a continuous range (for simplicity we focus on kernels with range of
[0,1]); these allow for smoother notions of range spaces.
  It turns out, the use of this smoother family of range spaces has an added
benefit of greatly decreasing the size required for eps-samples. For instance,
in the plane the size is O((1/eps^{4/3}) log^{2/3}(1/eps)) for disks (based on
VC-dimension arguments) but is only O((1/eps) sqrt{log (1/eps)}) for Gaussian
kernels and for kernels with bounded slope that only affect a bounded domain.
These bounds are accomplished by studying the discrepancy of these &quot;kernel&quot;
range spaces, and here the improvement in bounds are even more pronounced. In
the plane, we show the discrepancy is O(sqrt{log n}) for these kernels, whereas
for balls there is a lower bound of Omega(n^{1/4}).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4106</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4106</id><created>2011-12-17</created><updated>2012-08-01</updated><authors><author><keyname>Chugh</keyname><forenames>Ravi</forenames></author><author><keyname>Herman</keyname><forenames>David</forenames></author><author><keyname>Jhala</keyname><forenames>Ranjit</forenames></author></authors><title>Dependent Types for JavaScript</title><categories>cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present Dependent JavaScript (DJS), a statically-typed dialect of the
imperative, object-oriented, dynamic language. DJS supports the particularly
challenging features such as run-time type-tests, higher-order functions,
extensible objects, prototype inheritance, and arrays through a combination of
nested refinement types, strong updates to the heap, and heap unrolling to
precisely track prototype hierarchies. With our implementation of DJS, we
demonstrate that the type system is expressive enough to reason about a variety
of tricky idioms found in small examples drawn from several sources, including
the popular book JavaScript: The Good Parts and the SunSpider benchmark suite.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4109</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4109</id><created>2011-12-17</created><updated>2012-12-17</updated><authors><author><keyname>Guruswami</keyname><forenames>Venkatesan</forenames></author><author><keyname>Sinop</keyname><forenames>Ali Kemal</forenames></author></authors><title>Approximating Non-Uniform Sparsest Cut via Generalized Spectra</title><categories>cs.DS</categories><comments>16 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give an approximation algorithm for non-uniform sparsest cut with the
following guarantee: For any $\epsilon,\delta \in (0,1)$, given cost and demand
graphs with edge weights $C, D$ respectively, we can find a set $T\subseteq V$
with $\frac{C(T,V\setminus T)}{D(T,V\setminus T)}$ at most
$\frac{1+\epsilon}{\delta}$ times the optimal non-uniform sparsest cut value,
in time $2^{r/(\delta\epsilon)}\poly(n)$ provided $\lambda_r \ge
\Phi^*/(1-\delta)$. Here $\lambda_r$ is the $r$'th smallest generalized
eigenvalue of the Laplacian matrices of cost and demand graphs; $C(T,V\setminus
T)$ (resp. $D(T,V\setminus T)$) is the weight of edges crossing the
$(T,V\setminus T)$ cut in cost (resp. demand) graph and $\Phi^*$ is the
sparsity of the optimal cut. In words, we show that the non-uniform sparsest
cut problem is easy when the generalized spectrum grows moderately fast. To the
best of our knowledge, there were no results based on higher order spectra for
non-uniform sparsest cut prior to this work.
  Even for uniform sparsest cut, the quantitative aspects of our result are
somewhat stronger than previous methods. Similar results hold for other
expansion measures like edge expansion, normalized cut, and conductance, with
the $r$'th smallest eigenvalue of the normalized Laplacian playing the role of
$\lambda_r$ in the latter two cases.
  Our proof is based on an l1-embedding of vectors from a semi-definite program
from the Lasserre hierarchy. The embedded vectors are then rounded to a cut
using standard threshold rounding. We hope that the ideas connecting
$\ell_1$-embeddings to Lasserre SDPs will find other applications. Another
aspect of the analysis is the adaptation of the column selection paradigm from
our earlier work on rounding Lasserre SDPs [GS11] to pick a set of edges rather
than vertices. This feature is important in order to extend the algorithms to
non-uniform sparsest cut.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4113</identifier>
 <datestamp>2013-04-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4113</id><created>2011-12-17</created><authors><author><keyname>Lin</keyname><forenames>Fu</forenames></author><author><keyname>Fardad</keyname><forenames>Makan</forenames></author><author><keyname>Jovanovi&#x107;</keyname><forenames>Mihailo R.</forenames></author></authors><title>Optimal Control of Vehicular Formations with Nearest Neighbor
  Interactions</title><categories>math.OC cs.MA cs.SY</categories><comments>To appear in IEEE Trans. Automat. Control; 15 pages, 10 figures</comments><journal-ref>IEEE Trans. Automat. Control (2012), vol. 57, no. 9, pp. 2203-2218</journal-ref><doi>10.1109/TAC.2011.2181790</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the design of optimal localized feedback gains for
one-dimensional formations in which vehicles only use information from their
immediate neighbors. The control objective is to enhance coherence of the
formation by making it behave like a rigid lattice. For the single-integrator
model with symmetric gains, we establish convexity, implying that the globally
optimal controller can be computed efficiently. We also identify a class of
convex problems for double-integrators by restricting the controller to
symmetric position and uniform diagonal velocity gains. To obtain the optimal
non-symmetric gains for both the single- and the double-integrator models, we
solve a parameterized family of optimal control problems ranging from an easily
solvable problem to the problem of interest as the underlying parameter
increases. When this parameter is kept small, we employ perturbation analysis
to decouple the matrix equations that result from the optimality conditions,
thereby rendering the unique optimal feedback gain. This solution is used to
initialize a homotopy-based Newton's method to find the optimal localized gain.
To investigate the performance of localized controllers, we examine how the
coherence of large-scale stochastically forced formations scales with the
number of vehicles. We establish several explicit scaling relationships and
show that the best performance is achieved by a localized controller that is
both non-symmetric and spatially-varying.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4131</identifier>
 <datestamp>2011-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4131</id><created>2011-12-18</created><updated>2011-12-20</updated><authors><author><keyname>C&#xe9;nac</keyname><forenames>Peggy</forenames><affiliation>IMB</affiliation></author><author><keyname>Chauvin</keyname><forenames>Brigitte</forenames><affiliation>LM-Versailles</affiliation></author><author><keyname>Paccaut</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>LAMFA</affiliation></author><author><keyname>Pouyanne</keyname><forenames>Nicolas</forenames><affiliation>LM-Versailles</affiliation></author></authors><title>Uncommon Suffix Tries</title><categories>math.PR cs.DS</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Common assumptions on the source producing the words inserted in a suffix
trie with $n$ leaves lead to a $\log n$ height and saturation level. We provide
an example of a suffix trie whose height increases faster than a power of $n$
and another one whose saturation level is negligible with respect to $\log n$.
Both are built from VLMC (Variable Length Markov Chain) probabilistic sources;
they are easily extended to families of sources having the same properties. The
first example corresponds to a &quot;logarithmic infinite comb&quot; and enjoys a non
uniform polynomial mixing. The second one corresponds to a &quot;factorial infinite
comb&quot; for which mixing is uniform and exponential.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4133</identifier>
 <datestamp>2012-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4133</id><created>2011-12-18</created><authors><author><keyname>Labatut</keyname><forenames>Vincent</forenames><affiliation>Le2i</affiliation></author><author><keyname>Cherifi</keyname><forenames>Hocine</forenames><affiliation>Le2i</affiliation></author></authors><title>Evaluation of Performance Measures for Classifiers Comparison</title><categories>cs.LG</categories><proxy>ccsd</proxy><journal-ref>Ubiquitous Computing and Communication Journal, 6:21-34, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The selection of the best classification algorithm for a given dataset is a
very widespread problem, occuring each time one has to choose a classifier to
solve a real-world problem. It is also a complex task with many important
methodological decisions to make. Among those, one of the most crucial is the
choice of an appropriate measure in order to properly assess the classification
performance and rank the algorithms. In this article, we focus on this specific
task. We present the most popular measures and compare their behavior through
discrimination plots. We then discuss their properties from a more theoretical
perspective. It turns out several of them are equivalent for classifiers
comparison purposes. Futhermore. they can also lead to interpretation problems.
Among the numerous measures proposed over the years, it appears that the
classical overall success rate and marginal rates are the more suitable for
classifier comparison task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4134</identifier>
 <datestamp>2012-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4134</id><created>2011-12-18</created><authors><author><keyname>Orman</keyname><forenames>G&#xfc;nce Keziban</forenames><affiliation>Le2i, BIT Lab</affiliation></author><author><keyname>Labatut</keyname><forenames>Vincent</forenames><affiliation>Le2i</affiliation></author><author><keyname>Cherifi</keyname><forenames>Hocine</forenames><affiliation>Le2i</affiliation></author></authors><title>On Accuracy of Community Structure Discovery Algorithms</title><categories>cs.SI physics.soc-ph</categories><proxy>ccsd</proxy><journal-ref>Journal of Convergence Information Technology 6(11):283-292, 2011</journal-ref><doi>10.4156/jcit.vol6.issue11.32</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Community structure discovery in complex networks is a quite challenging
problem spanning many applications in various disciplines such as biology,
social network and physics. Emerging from various approaches numerous
algorithms have been proposed to tackle this problem. Nevertheless little
attention has been devoted to compare their efficiency on realistic simulated
data. To better understand their relative performances, we evaluate
systematically eleven algorithms covering the main approaches. The Normalized
Mutual Information (NMI) measure is used to assess the quality of the
discovered community structure from controlled artificial networks with
realistic topological properties. Results show that along with the network
size, the average proportion of intra-community to inter-community links is the
most influential parameter on performances. Overall, &quot;Infomap&quot; is the leading
algorithm, followed by &quot;Walktrap&quot;, &quot;SpinGlass&quot; and &quot;Louvain&quot; which also achieve
good consistency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4135</identifier>
 <datestamp>2011-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4135</id><created>2011-12-18</created><authors><author><keyname>Abdelouahad</keyname><forenames>Abdelkaher Ait</forenames><affiliation>GSCM-LRIT</affiliation></author><author><keyname>Hassouni</keyname><forenames>Mohammed El</forenames><affiliation>DESTEC</affiliation></author><author><keyname>Cherifi</keyname><forenames>Hocine</forenames><affiliation>Le2i</affiliation></author><author><keyname>Aboutajdine</keyname><forenames>Driss</forenames><affiliation>GSCM-LRIT</affiliation></author></authors><title>A Reduced Reference Image Quality Measure Using Bessel K Forms Model for
  Tetrolet Coefficients</title><categories>cs.CV</categories><proxy>ccsd</proxy><journal-ref>Journal of Convergence Information Technology 6 (2011) 216, 224</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we introduce a Reduced Reference Image Quality Assessment
(RRIQA) measure based on the natural image statistic approach. A new adaptive
transform called &quot;Tetrolet&quot; is applied to both reference and distorted images.
To model the marginal distribution of tetrolet coefficients Bessel K Forms
(BKF) density is proposed. Estimating the parameters of this distribution
allows to summarize the reference image with a small amount of side
information. Five distortion measures based on the BKF parameters of the
original and processed image are used to predict quality scores. A comparison
between these measures is presented showing a good consistency with human
judgment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4149</identifier>
 <datestamp>2011-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4149</id><created>2011-12-18</created><authors><author><keyname>Qureshi</keyname><forenames>Jalaluddin</forenames></author><author><keyname>Foh</keyname><forenames>Chuan Heng</forenames></author><author><keyname>Cai</keyname><forenames>Jianfei</forenames></author></authors><title>Joint Network Coding for Interfering Wireless Multicast Networks</title><categories>cs.IT cs.NI math.IT</categories><comments>This publication is an extension of: J. Qureshi, C. H. Foh and J.
  Cai, &quot;Cooperative Retransmissions Through Collisions,&quot; IEEE ICC 2011, Kyoto,
  Japan</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interference in wireless networks is one of the key-capacity limiting factor.
The multicast capacity of an ad- hoc wireless network decreases with an
increasing number of transmitting and/or receiving nodes within a fixed area.
Digital Network Coding (DNC) has been shown to improve the multicast capacity
of non-interfering wireless network. However recently proposed Physical-layer
Network Coding (PNC) and Analog Network Coding (ANC) has shown that it is
possible to decode an unknown packet from the collision of two packet, when one
of the colliding packet is known a priori. Taking advantage of such collision
decoding scheme, in this paper we propose a Joint Network Coding based
Cooperative Retransmission (JNC- CR) scheme, where we show that ANC along with
DNC can offer a much higher retransmission gain than that attainable through
either ANC, DNC or Automatic Repeat reQuest (ARQ) based retransmission. This
scheme can be applied for two wireless multicast groups interfering with each
other. Because of the broadcast nature of the wireless transmission, receivers
of different multicast group can opportunistically listen and cache packets
from the interfering transmitter. These cached packets, along with the packets
the receiver receives from its transmitter can then be used for decoding the
JNC packet. We validate the higher retransmission gain performance of JNC with
an optimal DNC scheme, using simulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4164</identifier>
 <datestamp>2014-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4164</id><created>2011-12-18</created><updated>2014-09-01</updated><authors><author><keyname>Minaee</keyname><forenames>Shervin</forenames></author><author><keyname>Fotouhi</keyname><forenames>Mehran</forenames></author><author><keyname>Khalaj</keyname><forenames>Babak Hossein</forenames></author></authors><title>A Geometric Approach For Fully Automatic Chromosome Segmentation</title><categories>cs.CV</categories><comments>This paper has been revised</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A fundamental task in human chromosome analysis is chromosome segmentation.
Segmentation plays an important role in chromosome karyotyping. The first step
in segmentation is to remove intrusive objects such as stain debris and other
noises. The next step is detection of touching and overlapping chromosomes, and
the final step is separation of such chromosomes. Common methods for separation
between touching chromosomes are interactive and require human intervention for
correct separation between touching and overlapping chromosomes. In this paper,
a geometric-based method is used for automatic detection of touching and
overlapping chromosomes and separating them. The proposed scheme performs
segmentation in two phases. In the first phase, chromosome clusters are
detected using three geometric criteria, and in the second phase, chromosome
clusters are separated using a cut-line. Most of earlier methods did not work
properly in case of chromosome clusters that contained more than two
chromosomes. Our method, on the other hand, is quite efficient in separation of
such chromosome clusters. At each step, one separation will be performed and
this algorithm is repeated until all individual chromosomes are separated.
Another important point about the proposed method is that it uses the geometric
features of chromosomes which are independent of the type of images and it can
easily be applied to any type of images such as binary images and does not
require multispectral images as well. We have applied our method to a database
containing 62 touching and partially overlapping chromosomes and a success rate
of 91.9% is achieved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4167</identifier>
 <datestamp>2011-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4167</id><created>2011-12-18</created><authors><author><keyname>Hoydis</keyname><forenames>Jakob</forenames></author><author><keyname>Couillet</keyname><forenames>Romain</forenames></author><author><keyname>Debbah</keyname><forenames>Merouane</forenames></author></authors><title>Iterative Deterministic Equivalents for the Performance Analysis of
  Communication Systems</title><categories>cs.IT math.IT</categories><comments>submitted to the IEEE Transactions on Information Theory, 43 pages, 4
  figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article, we introduce iterative deterministic equivalents as a novel
technique for the performance analysis of communication systems whose channels
are modeled by complex combinations of independent random matrices. This
technique extends the deterministic equivalent approach for the study of
functionals of large random matrices to a broader class of random matrix models
which naturally arise as channel models in wireless communications. We present
two specific applications: First, we consider a multi-hop amplify-and-forward
(AF) MIMO relay channel with noise at each stage and derive deterministic
approximations of the mutual information after the Kth hop. Second, we study a
MIMO multiple access channel (MAC) where the channel between each transmitter
and the receiver is represented by the double-scattering channel model. We
provide deterministic approximations of the mutual information, the
signal-to-interference-plus-noise ratio (SINR) and sum-rate with
minimum-mean-square-error (MMSE) detection and derive the asymptotically
optimal precoding matrices. In both scenarios, the approximations can be
computed by simple and provably converging fixed-point algorithms and are shown
to be almost surely tight in the limit when the number of antennas at each node
grows infinitely large. Simulations suggest that the approximations are
accurate for realistic system dimensions. The technique of iterative
deterministic equivalents can be easily extended to other channel models of
interest and is, therefore, also a new contribution to the field of random
matrix theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4190</identifier>
 <datestamp>2011-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4190</id><created>2011-12-18</created><authors><author><keyname>Beckwith</keyname><forenames>Laura</forenames></author><author><keyname>Cunha</keyname><forenames>J&#xe1;come</forenames></author><author><keyname>Fernandes</keyname><forenames>Jo&#xe3;o Paulo</forenames></author><author><keyname>Saraiva</keyname><forenames>Jo&#xe3;o</forenames></author></authors><title>An Empirical Study on End-users Productivity Using Model-based
  Spreadsheets</title><categories>cs.HC</categories><comments>14 Pages, 9 Colour Figures, 2 Tables; Proc. European Spreadsheet
  Risks Int. Grp. (EuSpRIG) 2011, ISBN 978-0-9566256-9-4</comments><proxy>Grenville Croll</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spreadsheets are widely used, and studies have shown that most end-user
spreadsheets contain nontrivial errors. To improve end-users productivity,
recent research proposes the use of a model-driven engineering approach to
spreadsheets. In this paper we conduct the first systematic empirical study to
assess the effectiveness and efficiency of this approach. A set of spreadsheet
end users worked with two different model-based spreadsheets, and we present
and analyze here the results achieved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4191</identifier>
 <datestamp>2011-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4191</id><created>2011-12-18</created><authors><author><keyname>Flood</keyname><forenames>Derek</forenames></author><author><keyname>Harrison</keyname><forenames>Rachel</forenames></author><author><keyname>McDaid</keyname><forenames>Kevin</forenames></author></authors><title>Spreadsheets on the Move: An Evaluation of Mobile Spreadsheets</title><categories>cs.HC</categories><comments>12 Pages, 7 Tables, 1 Colour Figure; Proc. European Spreadsheet Risks
  Int. Grp. (EuSpRIG) 2011 ISBN 978-0-9566256-9-4</comments><proxy>Grenville Croll</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The power of mobile devices has increased dramatically in the last few years.
These devices are becoming more sophisticated allowing users to accomplish a
wide variety of tasks while on the move. The increasingly mobile nature of
business has meant that more users will need access to spreadsheets while away
from their desktop and laptop computers. Existing mobile applications suffer
from a number of usability issues that make using spreadsheets in this way more
difficult. This work represents the first evaluation of mobile spreadsheet
applications. Through a pilot survey the needs and experiences of experienced
spreadsheet users was examined. The range of spreadsheet apps available for the
iOS platform was also evaluated in light of these users' needs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4210</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4210</id><created>2011-12-18</created><authors><author><keyname>Park</keyname><forenames>Hyunggon</forenames></author><author><keyname>Thomos</keyname><forenames>Nikolaos</forenames></author><author><keyname>Frossard</keyname><forenames>Pascal</forenames></author></authors><title>Approximate Decoding Approaches for Network Coded Correlated Data</title><categories>cs.NI cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers a framework where data from correlated sources are
transmitted with help of network coding in ad-hoc network topologies. The
correlated data are encoded independently at sensors and network coding is
employed in the intermediate nodes in order to improve the data delivery
performance. In such settings, we focus on the problem of reconstructing the
sources at decoder when perfect decoding is not possible due to losses or
bandwidth bottlenecks. We first show that the source data similarity can be
used at decoder to permit decoding based on a novel and simple approximate
decoding scheme. We analyze the influence of the network coding parameters and
in particular the size of finite coding fields on the decoding performance. We
further determine the optimal field size that maximizes the expected decoding
performance as a trade-off between information loss incurred by limiting the
resolution of the source data and the error probability in the reconstructed
data. Moreover, we show that the performance of the approximate decoding
improves when the accuracy of the source model increases even with simple
approximate decoding techniques. We provide illustrative examples about the
possible of our algorithms that can be deployed in sensor networks and
distributed imaging applications. In both cases, the experimental results
confirm the validity of our analysis and demonstrate the benefits of our low
complexity solution for delivery of correlated data sources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4214</identifier>
 <datestamp>2011-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4214</id><created>2011-12-18</created><authors><author><keyname>Ye</keyname><forenames>Shunyuan</forenames></author><author><keyname>Shen</keyname><forenames>Yanming</forenames></author><author><keyname>Panwar</keyname><forenames>Shivendra</forenames></author></authors><title>A Distributed Scheduling Algorithm for High-Speed Switching Systems</title><categories>cs.NI</categories><comments>15 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given the rapid increase in traffic, greater demands have been put on
research in high-speed switching systems. Such systems have to simultaneously
meet several constraints, e.g., high throughput, low delay and low complexity.
This makes it challenging to design an efficient scheduling algorithm, and has
consequently drawn considerable research interest. However, previous results
either cannot provide a 100% throughput guarantee without a speedup, or require
a complex centralized scheduler. In this paper, we design a distributed 100%
throughput algorithm for crosspoint buffered switches, called DISQUO, with very
limited message passing. We prove that DISQUO can achieve 100% throughput for
any admissible Bernoulli traffic, with a low time complexity of O(1) per port
and a few bits message exchanging in every time slot. To the best of our
knowledge, it is the first distributed algorithm that can provide a 100%
throughput for a crosspoint buffered switch.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4221</identifier>
 <datestamp>2015-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4221</id><created>2011-12-18</created><authors><author><keyname>Nielsen</keyname><forenames>Frank</forenames></author><author><keyname>Nock</keyname><forenames>Richard</forenames></author></authors><title>A closed-form expression for the Sharma-Mittal entropy of exponential
  families</title><categories>cs.IT math.IT</categories><comments>9 pages, 3 figures; Journal of Physics A: Mathematical and
  Theoretical, December 2011. IOP</comments><doi>10.1088/1751-8113/45/3/032003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Sharma-Mittal entropies generalize the celebrated Shannon, R\'enyi and
Tsallis entropies. We report a closed-form formula for the Sharma-Mittal
entropies and relative entropies for arbitrary exponential family
distributions. We instantiate explicitly the formula for the case of the
multivariate Gaussian distributions and discuss on its estimation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4232</identifier>
 <datestamp>2012-10-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4232</id><created>2011-12-18</created><updated>2012-10-16</updated><authors><author><keyname>Lavretsky</keyname><forenames>Eugene</forenames></author><author><keyname>Gibson</keyname><forenames>Travis E.</forenames></author></authors><title>Projection Operator in Adaptive Systems</title><categories>nlin.AO cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The projection algorithm is frequently used in adaptive control and this note
presents a detailed analysis of its properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4236</identifier>
 <datestamp>2012-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4236</id><created>2011-12-18</created><updated>2012-02-24</updated><authors><author><keyname>Sukhavasi</keyname><forenames>Ravi Teja</forenames></author><author><keyname>Hassibi</keyname><forenames>Babak</forenames></author></authors><title>Error Correcting Codes for Distributed Control</title><categories>cs.IT math.IT math.OC</categories><comments>39 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of stabilizing an unstable plant over a noisy communication link
is an increasingly important one that arises in applications of networked
control systems. Although the work of Schulman and Sahai over the past two
decades, and their development of the notions of &quot;tree codes&quot;\phantom{} and
&quot;anytime capacity&quot;, provides the theoretical framework for studying such
problems, there has been scant practical progress in this area because explicit
constructions of tree codes with efficient encoding and decoding did not exist.
To stabilize an unstable plant driven by bounded noise over a noisy channel one
needs real-time encoding and real-time decoding and a reliability which
increases exponentially with decoding delay, which is what tree codes
guarantee. We prove that linear tree codes occur with high probability and, for
erasure channels, give an explicit construction with an expected decoding
complexity that is constant per time instant. We give novel sufficient
conditions on the rate and reliability required of the tree codes to stabilize
vector plants and argue that they are asymptotically tight. This work takes an
important step towards controlling plants over noisy channels, and we
demonstrate the efficacy of the method through several examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4237</identifier>
 <datestamp>2011-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4237</id><created>2011-12-18</created><authors><author><keyname>Yasuoka</keyname><forenames>Hirotoshi</forenames></author><author><keyname>Terauchi</keyname><forenames>Tachio</forenames></author></authors><title>On Bounding Problems of Quantitative Information Flow</title><categories>cs.CR</categories><comments>To appear in Journal of Computer Security, IOS Press. arXiv admin
  note: substantial text overlap with arXiv:1004.0062</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Researchers have proposed formal definitions of quantitative information flow
based on information theoretic notions such as the Shannon entropy, the min
entropy, the guessing entropy, belief, and channel capacity. This paper
investigates the hardness of precisely checking the quantitative information
flow of a program according to such definitions. More precisely, we study the
&quot;bounding problem&quot; of quantitative information flow, defined as follows: Given
a program M and a positive real number q, decide if the quantitative
information flow of M is less than or equal to q. We prove that the bounding
problem is not a k-safety property for any k (even when q is fixed, for the
Shannon-entropy-based definition with the uniform distribution), and therefore
is not amenable to the self-composition technique that has been successfully
applied to checking non-interference. We also prove complexity theoretic
hardness results for the case when the program is restricted to loop-free
boolean programs. Specifically, we show that the problem is PP-hard for all
definitions, showing a gap with non-interference which is coNP-complete for the
same class of programs. The paper also compares the results with the recently
proved results on the comparison problems of quantitative information flow.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4238</identifier>
 <datestamp>2011-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4238</id><created>2011-12-18</created><authors><author><keyname>Chandrashekar</keyname><forenames>Praveen</forenames></author><author><keyname>Garg</keyname><forenames>Ashish</forenames></author></authors><title>Vertex-centroid finite volume scheme on tetrahedral grids for
  conservation laws</title><categories>cs.NA cs.CE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Vertex-centroid schemes are cell-centered finite volume schemes for
conservation laws which make use of vertex values to construct high resolution
schemes. The vertex values must be obtained through a consistent averaging
(interpolation) procedure. A modified interpolation scheme is proposed which is
better than existing schemes in giving positive weights in the interpolation
formula. A simplified reconstruction scheme is also proposed which is also more
accurate and efficient. For scalar conservation laws, we develop limited
versions of the schemes which are stable in maximum norm by constructing
suitable limiters. The schemes are applied to compressible flows governed by
the Euler equations of inviscid gas dynamics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4243</identifier>
 <datestamp>2011-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4243</id><created>2011-12-19</created><authors><author><keyname>Shi</keyname><forenames>Ziqiang</forenames></author><author><keyname>Han</keyname><forenames>Jiqing</forenames></author><author><keyname>Zheng</keyname><forenames>Tieran</forenames></author><author><keyname>Deng</keyname><forenames>Shiwen</forenames></author></authors><title>Online Learning for Classification of Low-rank Representation Features
  and Its Applications in Audio Segment Classification</title><categories>cs.LG cs.MM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a novel framework based on trace norm minimization for audio
segment is proposed. In this framework, both the feature extraction and
classification are obtained by solving corresponding convex optimization
problem with trace norm regularization. For feature extraction, robust
principle component analysis (robust PCA) via minimization a combination of the
nuclear norm and the $\ell_1$-norm is used to extract low-rank features which
are robust to white noise and gross corruption for audio segments. These
low-rank features are fed to a linear classifier where the weight and bias are
learned by solving similar trace norm constrained problems. For this
classifier, most methods find the weight and bias in batch-mode learning, which
makes them inefficient for large-scale problems. In this paper, we propose an
online framework using accelerated proximal gradient method. This framework has
a main advantage in memory cost. In addition, as a result of the regularization
formulation of matrix classification, the Lipschitz constant was given
explicitly, and hence the step size estimation of general proximal gradient
method was omitted in our approach. Experiments on real data sets for
laugh/non-laugh and applause/non-applause classification indicate that this
novel framework is effective and noise robust.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4250</identifier>
 <datestamp>2013-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4250</id><created>2011-12-19</created><authors><author><keyname>Singh</keyname><forenames>Shubh Narayan</forenames></author><author><keyname>Krishna</keyname><forenames>K. V.</forenames></author></authors><title>The Rank and Hanna Neumann Property of Some Submonoids of a Free Monoid</title><categories>cs.FL math.RA</categories><comments>Contributed talk titled &quot;On the rank of the intersection of two
  submonoids of a free monoid&quot; at A$^3$: Abstract Algebra and Algorithms
  Conference, Eger, Hungary, August 14-17, 2011</comments><msc-class>68Q70, 68Q45, 20M35</msc-class><journal-ref>Ann. Math. Inform., 40, 113-123, 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work aims at further investigations on the work of Giambruno and Restivo
to find the rank of the intersection of two finitely generated submonoids of a
free monoid. In this connection, we obtain the rank of a finitely generated
submonoid of a free monoid that is accepted by semi-flower automaton with two
bpi's. Further, when the product automaton of two deterministic semi-flower
automata with a unique bpi is semi-flower with two bpi's, we obtain a
sufficient condition on the product automaton in order to satisfy the Hanna
Neumann property.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4253</identifier>
 <datestamp>2011-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4253</id><created>2011-12-19</created><authors><author><keyname>Bruckstein</keyname><forenames>Alfred M.</forenames></author><author><keyname>Etzion</keyname><forenames>Tuvi</forenames></author><author><keyname>Giryes</keyname><forenames>Raja</forenames></author><author><keyname>Gordon</keyname><forenames>Noam</forenames></author><author><keyname>Holt</keyname><forenames>Robert J.</forenames></author><author><keyname>Shuldiner</keyname><forenames>Doron</forenames></author></authors><title>Simple and Robust Binary Self-Location Patterns</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A simple method to generate a two-dimensional binary grid pattern, which
allows for absolute and accurate self-location in a finite planar region, is
proposed. The pattern encodes position information in a local way so that
reading a small number of its black or white pixels at any place provides
sufficient data from which the location can be decoded both efficiently and
robustly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4256</identifier>
 <datestamp>2013-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4256</id><created>2011-12-19</created><updated>2012-08-07</updated><authors><author><keyname>Singh</keyname><forenames>Shubh Narayan</forenames></author><author><keyname>Krishna</keyname><forenames>K. V.</forenames></author></authors><title>A Sufficient Condition for Hanna Neumann Property of Submonoids of a
  Free Monoid</title><categories>cs.FL</categories><msc-class>68Q70, 68Q45, 20M35</msc-class><journal-ref>Semigroup Forum, 86(3): 537-554, 2013</journal-ref><doi>10.1007/s00233-012-9449-4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using automata-theoretic approach, Giambruno and Restivo have investigated on
the intersection of two finitely generated submonoids of the free monoid over a
finite alphabet. In particular, they have obtained Hanna Neumann property for a
special class of submonoids generated by finite prefix sets. This work
continues their work and provides a sufficient condition for Hanna Neumann
property for the entire class of submonoids generated by finite prefix sets. In
this connection, a general rank formula for the submonoids which are accepted
by semi-flower automata is also obtained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4258</identifier>
 <datestamp>2013-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4258</id><created>2011-12-19</created><updated>2013-01-30</updated><authors><author><keyname>Soltanolkotabi</keyname><forenames>Mahdi</forenames></author><author><keyname>Cand&#xe9;s</keyname><forenames>Emmanuel J.</forenames></author></authors><title>A geometric analysis of subspace clustering with outliers</title><categories>cs.IT cs.LG math.IT math.ST stat.ML stat.TH</categories><comments>Published in at http://dx.doi.org/10.1214/12-AOS1034 the Annals of
  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical
  Statistics (http://www.imstat.org)</comments><proxy>vtex</proxy><report-no>IMS-AOS-AOS1034</report-no><journal-ref>Annals of Statistics 2012, Vol. 40, No. 4, 2195-2238</journal-ref><doi>10.1214/12-AOS1034</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the problem of clustering a collection of unlabeled data
points assumed to lie near a union of lower-dimensional planes. As is common in
computer vision or unsupervised learning applications, we do not know in
advance how many subspaces there are nor do we have any information about their
dimensions. We develop a novel geometric analysis of an algorithm named sparse
subspace clustering (SSC) [In IEEE Conference on Computer Vision and Pattern
Recognition, 2009. CVPR 2009 (2009) 2790-2797. IEEE], which significantly
broadens the range of problems where it is provably effective. For instance, we
show that SSC can recover multiple subspaces, each of dimension comparable to
the ambient dimension. We also prove that SSC can correctly cluster data points
even when the subspaces of interest intersect. Further, we develop an extension
of SSC that succeeds when the data set is corrupted with possibly
overwhelmingly many outliers. Underlying our analysis are clear geometric
insights, which may bear on other sparse recovery problems. A numerical study
complements our theoretical analysis and demonstrates the effectiveness of
these methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4261</identifier>
 <datestamp>2012-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4261</id><created>2011-12-19</created><authors><author><keyname>Chandrasekhar</keyname><forenames>T.</forenames></author><author><keyname>Thangavel</keyname><forenames>K.</forenames></author><author><keyname>Elayaraja</keyname><forenames>E.</forenames></author></authors><title>Performance Analysis of Enhanced Clustering Algorithm for Gene
  Expression Data</title><categories>cs.LG cs.CE cs.DB</categories><comments>ISSN (Online): 1694-0814 http://www.IJCSI.org</comments><journal-ref>IJCSI International Journal of Computer Science Issues, Vol. 8,
  Issue 6, No 3, November 2011</journal-ref><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Microarrays are made it possible to simultaneously monitor the expression
profiles of thousands of genes under various experimental conditions. It is
used to identify the co-expressed genes in specific cells or tissues that are
actively used to make proteins. This method is used to analysis the gene
expression, an important task in bioinformatics research. Cluster analysis of
gene expression data has proved to be a useful tool for identifying
co-expressed genes, biologically relevant groupings of genes and samples. In
this paper we applied K-Means with Automatic Generations of Merge Factor for
ISODATA- AGMFI. Though AGMFI has been applied for clustering of Gene Expression
Data, this proposed Enhanced Automatic Generations of Merge Factor for ISODATA-
EAGMFI Algorithms overcome the drawbacks of AGMFI in terms of specifying the
optimal number of clusters and initialization of good cluster centroids.
Experimental results on Gene Expression Data show that the proposed EAGMFI
algorithms could identify compact clusters with perform well in terms of the
Silhouette Coefficients cluster measure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4264</identifier>
 <datestamp>2011-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4264</id><created>2011-12-19</created><authors><author><keyname>Bil&#xf2;</keyname><forenames>Davide</forenames></author><author><keyname>Gual&#xe0;</keyname><forenames>Luciano</forenames></author><author><keyname>Proietti</keyname><forenames>Guido</forenames></author></authors><title>Bounded-Distance Network Creation Games</title><categories>cs.GT</categories><comments>17 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A network creation game simulates a decentralized and non-cooperative
building of a communication network. Informally, there are $n$ players sitting
on the network nodes, which attempt to establish a reciprocal communication by
activating, incurring a certain cost, any of their incident links. The goal of
each player is to have all the other nodes as close as possible in the
resulting network, while buying as few links as possible. According to this
intuition, any model of the game must then appropriately address a balance
between these two conflicting objectives. Motivated by the fact that a player
might have a strong requirement about its centrality in the network, in this
paper we introduce a new setting in which if a player maintains its (either
maximum or average) distance to the other nodes within a given associated
bound, then its cost is simply equal to the number of activated edges,
otherwise its cost is unbounded. We study the problem of understanding the
structure of associated pure Nash equilibria of the resulting games, that we
call MaxBD and SumBD, respectively. For both games, we show that computing the
best response of a player is an NP-hard problem. Next, we show that when
distance bounds associated with players are non-uniform, then equilibria can be
arbitrarily bad. On the other hand, for MaxBD, we show that when nodes have a
uniform bound $R$ on the maximum distance, then the Price of Anarchy (PoA) is
lower and upper bounded by 2 and $O(n^{\frac{1}{\lfloor\log_3 R\rfloor+1}})$
for $R \geq 3$, while for the interesting case R=2, we are able to prove that
the PoA is $\Omega(\sqrt{n})$ and $O(\sqrt{n \log n})$. For the uniform SumBD
we obtain similar (asymptotically) results, and moreover we show that the PoA
becomes constant as soon as the bound on the average distance is
$n^{\omega(\frac{1}{\sqrt{\log n}})}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4271</identifier>
 <datestamp>2013-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4271</id><created>2011-12-19</created><updated>2013-07-01</updated><authors><author><keyname>Ajouli</keyname><forenames>Akram</forenames><affiliation>LINA, INRIA - EMN</affiliation></author><author><keyname>Cohen</keyname><forenames>Julien</forenames><affiliation>LINA</affiliation></author></authors><title>Refactoring Composite to Visitor and Inverse Transformation in Java</title><categories>cs.SE</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe how to use refactoring tools to transform a Java program
conforming to the Composite design pattern into a program conforming to the
Visitor design pattern with the same external behavior. We also describe the
inverse transformation. We use the refactoring tool provided by IntelliJ IDEA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4294</identifier>
 <datestamp>2012-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4294</id><created>2011-12-19</created><updated>2012-03-13</updated><authors><author><keyname>Farokhi</keyname><forenames>F.</forenames></author><author><keyname>Langbort</keyname><forenames>C.</forenames></author><author><keyname>Johansson</keyname><forenames>K. H.</forenames></author></authors><title>Optimal Disturbance Accommodation with Limited Model Information</title><categories>math.OC cs.SY</categories><comments>Fixed Typos, Updated Introduction and References. This manuscript is
  an early version of the results presented in arXiv:1112.5032 prepared for the
  presentation at the American Control Conference 2012</comments><journal-ref>Proceedings of the American Control Conference, pp. 4757-4764,
  2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The design of optimal dynamic disturbance accommodation controller with
limited model information is considered. We adapt the family of limited model
information control design strategies, defined earlier by the authors, to
handle dynamic controllers. This family of limited model information design
strategies construct subcontrollers distributively by accessing only local
plant model information. The closed-loop performance of the dynamic controllers
that they can produce are studied using a performance metric called the
competitive ratio which is the worst case ratio of the cost a control design
strategy to the cost of the optimal control design with full model information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4295</identifier>
 <datestamp>2011-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4295</id><created>2011-12-19</created><authors><author><keyname>Datta</keyname><forenames>Samir</forenames></author><author><keyname>Pratap</keyname><forenames>Rameshwar</forenames></author></authors><title>Computing Bits of Algebraic Numbers</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We initiate the complexity theoretic study of the problem of computing the
bits of (real) algebraic numbers. This extends the work of Yap on computing the
bits of transcendental numbers like \pi, in Logspace.
  Our main result is that computing a bit of a fixed real algebraic number is
in C=NC1\subseteq Logspace when the bit position has a verbose (unary)
representation and in the counting hierarchy when it has a succinct (binary)
representation.
  Our tools are drawn from elementary analysis and numerical analysis, and
include the Newton-Raphson method. The proof of our main result is entirely
elementary, preferring to use the elementary Liouville's theorem over the much
deeper Roth's theorem for algebraic numbers.
  We leave the possibility of proving non-trivial lower bounds for the problem
of computing the bits of an algebraic number given the bit position in binary,
as our main open question. In this direction we show very limited progress by
proving a lower bound for rationals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4303</identifier>
 <datestamp>2011-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4303</id><created>2011-12-19</created><authors><author><keyname>Balaz</keyname><forenames>Antun</forenames></author><author><keyname>Prnjat</keyname><forenames>Ognjen</forenames></author><author><keyname>Vudragovic</keyname><forenames>Dusan</forenames></author><author><keyname>Slavnic</keyname><forenames>Vladimir</forenames></author><author><keyname>Liabotis</keyname><forenames>Ioannis</forenames></author><author><keyname>Atanassov</keyname><forenames>Emanouil</forenames></author><author><keyname>Jakimovski</keyname><forenames>Boro</forenames></author><author><keyname>Savic</keyname><forenames>Mihajlo</forenames></author></authors><title>Development of Grid e-Infrastructure in South-Eastern Europe</title><categories>cs.DC cs.NI cs.SI physics.comp-ph</categories><comments>22 pages, 12 figures, 4 tables</comments><journal-ref>J. Grid Comput. 9, 135 (2011)</journal-ref><doi>10.1007/s10723-011-9185-0</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Over the period of 6 years and three phases, the SEE-GRID programme has
established a strong regional human network in the area of distributed
scientific computing and has set up a powerful regional Grid infrastructure. It
attracted a number of user communities and applications from diverse fields
from countries throughout the South-Eastern Europe. From the infrastructure
point view, the first project phase has established a pilot Grid infrastructure
with more than 20 resource centers in 11 countries. During the subsequent two
phases of the project, the infrastructure has grown to currently 55 resource
centers with more than 6600 CPUs and 750 TBs of disk storage, distributed in 16
participating countries. Inclusion of new resource centers to the existing
infrastructure, as well as a support to new user communities, has demanded
setup of regionally distributed core services, development of new monitoring
and operational tools, and close collaboration of all partner institution in
managing such a complex infrastructure. In this paper we give an overview of
the development and current status of SEE-GRID regional infrastructure and
describe its transition to the NGI-based Grid model in EGI, with the strong SEE
regional collaboration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4312</identifier>
 <datestamp>2012-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4312</id><created>2011-12-19</created><authors><author><keyname>Kivel&#xe4;</keyname><forenames>Mikko</forenames></author><author><keyname>Pan</keyname><forenames>Raj Kumar</forenames></author><author><keyname>Kaski</keyname><forenames>Kimmo</forenames></author><author><keyname>Kert&#xe9;sz</keyname><forenames>J&#xe1;nos</forenames></author><author><keyname>Saram&#xe4;ki</keyname><forenames>Jari</forenames></author><author><keyname>Karsai</keyname><forenames>M&#xe1;rton</forenames></author></authors><title>Multiscale Analysis of Spreading in a Large Communication Network</title><categories>physics.soc-ph cs.SI physics.data-an</categories><journal-ref>J. Stat. Mech. (2012) P03005</journal-ref><doi>10.1088/1742-5468/2012/03/P03005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In temporal networks, both the topology of the underlying network and the
timings of interaction events can be crucial in determining how some dynamic
process mediated by the network unfolds. We have explored the limiting case of
the speed of spreading in the SI model, set up such that an event between an
infectious and susceptible individual always transmits the infection. The speed
of this process sets an upper bound for the speed of any dynamic process that
is mediated through the interaction events of the network. With the help of
temporal networks derived from large scale time-stamped data on mobile phone
calls, we extend earlier results that point out the slowing-down effects of
burstiness and temporal inhomogeneities. In such networks, links are not
permanently active, but dynamic processes are mediated by recurrent events
taking place on the links at specific points in time. We perform a multi-scale
analysis and pinpoint the importance of the timings of event sequences on
individual links, their correlations with neighboring sequences, and the
temporal pathways taken by the network-scale spreading process. This is
achieved by studying empirically and analytically different characteristic
relay times of links, relevant to the respective scales, and a set of temporal
reference models that allow for removing selected time-domain correlations one
by one.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4323</identifier>
 <datestamp>2011-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4323</id><created>2011-12-19</created><updated>2011-12-29</updated><authors><author><keyname>Serafino</keyname><forenames>Loris</forenames></author></authors><title>Between theory and practice: guidelines for an optimization scheme with
  genetic algorithms - Part I: single-objective continuous global optimization</title><categories>cs.NE</categories><comments>21 pages, 1 figure. Rearranged section 2. Other minor changes
  throughout the paper and in references</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The rapid advances in the field of optimization methods in many pure and
applied science pose the difficulty of keeping track of the developments as
well as selecting an appropriate technique that best suits the problem in-hand.
From a practitioner point of view is rightful to wander &quot;which optimization
method is the best for my problem?&quot;. Looking at the optimization process as a
&quot;system&quot; of intercon- nected parts, in this paper are collected some ideas
about how to tackle an optimization problem using a class of tools from
evolutionary computations called Genetic Algorithms. Despite the number of
optimization techniques available nowadays the author of this paper thinks that
Genetic Algorithms still play a central role for their versatility, robustness,
theoretical framework and simplicity of use. The paper can be considered a
&quot;collection of tips&quot; (from literature and personal experience) for the
non-computer-scientist that has to deal with optimization problems both in the
science and engineering practice. No original methods or algorithms are
proposed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4339</identifier>
 <datestamp>2011-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4339</id><created>2011-12-19</created><authors><author><keyname>Chihani</keyname><forenames>Bachir</forenames></author><author><keyname>Denis</keyname><forenames>Collange</forenames></author></authors><title>A Multipath Transport Protocol for Future Internet</title><categories>cs.NI</categories><comments>Accepted paper International Conference on Networking and Future
  Internet (ICNFI'11), Paris : France (2011)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A Multipath Transport Protocol for Future Internet
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4344</identifier>
 <datestamp>2011-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4344</id><created>2011-12-19</created><authors><author><keyname>Zappella</keyname><forenames>Giovanni</forenames></author></authors><title>A Scalable Multiclass Algorithm for Node Classification</title><categories>cs.LG cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a scalable algorithm, MUCCA, for multiclass node classification
in weighted graphs. Unlike previously proposed methods for the same task, MUCCA
works in time linear in the number of nodes. Our approach is based on a
game-theoretic formulation of the problem in which the test labels are
expressed as a Nash Equilibrium of a certain game. However, in order to achieve
scalability, we find the equilibrium on a spanning tree of the original graph.
Experiments on real-world data reveal that MUCCA is much faster than its
competitors while achieving a similar predictive performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4394</identifier>
 <datestamp>2011-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4394</id><created>2011-12-19</created><authors><author><keyname>Duvenaud</keyname><forenames>David</forenames></author><author><keyname>Nickisch</keyname><forenames>Hannes</forenames></author><author><keyname>Rasmussen</keyname><forenames>Carl Edward</forenames></author></authors><title>Additive Gaussian Processes</title><categories>stat.ML cs.LG</categories><comments>Appearing in Neural Information Processing Systems 2011</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We introduce a Gaussian process model of functions which are additive. An
additive function is one which decomposes into a sum of low-dimensional
functions, each depending on only a subset of the input variables. Additive GPs
generalize both Generalized Additive Models, and the standard GP models which
use squared-exponential kernels. Hyperparameter learning in this model can be
seen as Bayesian Hierarchical Kernel Learning (HKL). We introduce an expressive
but tractable parameterization of the kernel function, which allows efficient
evaluation of all input interaction terms, whose number is exponential in the
input dimension. The additional structure discoverable by this model results in
increased interpretability, as well as state-of-the-art predictive power in
regression tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4396</identifier>
 <datestamp>2011-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4396</id><created>2011-12-19</created><authors><author><keyname>Prot</keyname><forenames>D.</forenames></author><author><keyname>Bellenguez-Morineau</keyname><forenames>O.</forenames></author><author><keyname>Lahlou</keyname><forenames>C.</forenames></author></authors><title>A note on the paper &quot;Minimizing total tardiness on parallel machines
  with preemptions&quot; by Kravchenko and Werner [2010]</title><categories>cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this note, we point out two major errors in the paper &quot;Minimizing total
tardiness on parallel machines with preemptions&quot; by Kravchenko and Werner
[2010]. More precisely, they proved that both problems P|pmtn|sum(Tj) and P|rj,
pj = p, pmtn|sum(Tj) are NP-Hard. We give a counter-example to their proofs,
letting the complexity of these two problems open.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4400</identifier>
 <datestamp>2013-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4400</id><created>2011-12-19</created><updated>2013-09-18</updated><authors><author><keyname>Prot</keyname><forenames>D.</forenames></author><author><keyname>Bellenguez-Morineau</keyname><forenames>O.</forenames></author><author><keyname>Lahlou</keyname><forenames>C.</forenames></author></authors><title>New complexity results for parallel identical machine scheduling
  problems with preemption, release dates and regular criteria</title><categories>cs.DM</categories><report-no>11/8/AUTO</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we are interested in parallel identical machine scheduling
problems with preemption and release dates in case of a regular criterion to be
minimized. We show that solutions having a permutation flow shop structure are
dominant if there exists an optimal solution with completion times scheduled in
the same order as the release dates, or if there is no release date. We also
prove that, for a subclass of these problems, the completion times of all jobs
can be ordered in an optimal solution. Using these two results, we provide new
results on polynomially solvable problems and hence refine the boundary between
P and NP for these problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4410</identifier>
 <datestamp>2011-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4410</id><created>2011-12-19</created><authors><author><keyname>Ruiz-Vega</keyname><forenames>F.</forenames></author><author><keyname>Clemente</keyname><forenames>M. C.</forenames></author><author><keyname>Otero</keyname><forenames>P.</forenames></author><author><keyname>Paris</keyname><forenames>J. F.</forenames></author></authors><title>Ricean Shadowed Statistical Characterization of Shallow Water Acoustic
  Channels for Wireless Communications</title><categories>physics.data-an cs.SD</categories><comments>3 pages, 2 figures, one table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this letter, the statistical behaviour of the shallow water acoustic
channel for wireless communications is shown to be well characterized by the
Ricean shadowed distribution, which has never been proposed for communication
purposes on this type of channel. This characterization is clearly motivated
from statistical and physical perspectives and has both theoretical and
practical advantages compared to previously proposed models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4411</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4411</id><created>2011-12-19</created><updated>2013-05-02</updated><authors><author><keyname>Faug&#xe8;re</keyname><forenames>Jean-Charles</forenames></author><author><keyname>Din</keyname><forenames>Mohab Safey El</forenames></author><author><keyname>Spaenlehauer</keyname><forenames>Pierre-Jean</forenames></author></authors><title>On the Complexity of the Generalized MinRank Problem</title><categories>cs.SC</categories><comments>29 pages</comments><msc-class>68W30, 13P10, 13P15, 68W40</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the complexity of solving the \emph{generalized MinRank problem},
i.e. computing the set of points where the evaluation of a polynomial matrix
has rank at most $r$. A natural algebraic representation of this problem gives
rise to a \emph{determinantal ideal}: the ideal generated by all minors of size
$r+1$ of the matrix. We give new complexity bounds for solving this problem
using Gr\&quot;obner bases algorithms under genericity assumptions on the input
matrix. In particular, these complexity bounds allow us to identify families of
generalized MinRank problems for which the arithmetic complexity of the solving
process is polynomial in the number of solutions. We also provide an algorithm
to compute a rational parametrization of the variety of a 0-dimensional and
radical system of bi-degree $(D,1)$. We show that its complexity can be bounded
by using the complexity bounds for the generalized MinRank problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4419</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4419</id><created>2011-12-19</created><updated>2013-01-30</updated><authors><author><keyname>Fomin</keyname><forenames>Fedor V.</forenames></author><author><keyname>Kratsch</keyname><forenames>Stefan</forenames></author><author><keyname>Pilipczuk</keyname><forenames>Marcin</forenames></author><author><keyname>Pilipczuk</keyname><forenames>Micha&#x142;</forenames></author><author><keyname>Villanger</keyname><forenames>Yngve</forenames></author></authors><title>Subexponential fixed-parameter tractability of cluster editing</title><categories>cs.CC cs.DS</categories><comments>The new version contains results accepted for publication on the 30th
  Symposium on Theoretical Aspects of Computer Science (STACS 2013) under title
  'Tight bounds for Parameterized Complexity of Cluster Editing'</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the Correlation Clustering, also known as Cluster Editing, we are given an
undirected n-vertex graph G and a positive integer k. The task is to decide if
G can be transformed into a cluster graph, i.e., a disjoint union of cliques,
by changing at most k adjacencies, i.e. by adding/deleting at most k edges. We
give a subexponential algorithm that, in time 2^O(sqrt(pk)) + n^O(1) decides
whether G can be transformed into a cluster graph with p cliques by changing at
most k adjacencies. We complement our algorithmic findings by the following
tight lower bounds on the asymptotic behaviour of our algorithm. We show that,
unless ETH fails, for any constant 0 &lt; s &lt;= 1, there is p = Theta(k^s) such
that there is no algorithm deciding in time 2^o(sqrt(pk)) n^O(1) whether G can
be transformed into a cluster graph with p cliques by changing at most k
adjacencies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4422</identifier>
 <datestamp>2012-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4422</id><created>2011-12-19</created><updated>2012-03-20</updated><authors><author><keyname>Valdez</keyname><forenames>L. D.</forenames></author><author><keyname>Macri</keyname><forenames>P. A.</forenames></author><author><keyname>Braunstein</keyname><forenames>L. A.</forenames></author></authors><title>Intermittent social distancing strategy for epidemic control</title><categories>physics.soc-ph cs.SI</categories><comments>In press in Physical Review E</comments><doi>10.1103/PhysRevE.85.036108</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the critical effect of an intermittent social distancing strategy on
the propagation of epidemics in adaptive complex networks. We characterize the
effect of our strategy in the framework of the susceptible-infected-recovered
model. In our model, based on local information, a susceptible individual
interrupts the contact with an infected individual with a probability $\sigma$
and restores it after a fixed time $t_{b}$. We find that, depending on the
network topology, in our social distancing strategy there exists a cutoff
threshold $\sigma_{c}$ beyond which the epidemic phase disappears. Our results
are supported by a theoretical framework and extensive simulations of the
model. Furthermore we show that this strategy is very efficient because it
leads to a &quot;susceptible herd behavior&quot; that protects a large fraction of
susceptibles individuals. We explain our results using percolation arguments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4428</identifier>
 <datestamp>2011-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4428</id><created>2011-12-19</created><authors><author><keyname>Ben-Zvi</keyname><forenames>Ido</forenames></author></authors><title>Causality, Knowledge and Coordination in Distributed Systems</title><categories>cs.LO cs.DC</categories><comments>PhD Dissertation</comments><report-no>PHD-2011-09</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Effecting coordination across remote sites in a distributed system is an
essential part of distributed computing, and also an inherent challenge. In
1978, an analysis of communication in asynchronous systems was suggested by
Leslie Lamport. Lamport's analysis determines a notion of temporal precedence,
a sort of weak notion of time, which is otherwise missing in asynchronous
systems. This notion has been extensively utilized in various applications.
  Yet the analysis is limited to systems that are asynchronous. In this thesis
we go beyond by investigating causality in synchronous systems. In such
systems, the boundaries of causal influence are not charted out exclusively by
message passing. Here time itself, passing at a uniform (or almost uniform)
rate for all processes, is also a medium by which causal influence may fan out.
This thesis studies, and characterizes, the combinations of time and message
passing that govern causal influence in synchronous systems.
  It turns out that knowledge based analysis [FHMV] provides a well tailored
formal framework within which causal notions can be studied. As we show, the
formal notion of knowledge is highly appropriate for characterizing causal
influence in terms of information flow, broadening the analysis of Chandy and
Misra in [ChM].
  We define several generic classes of coordination problems that pose various
temporal ordering requirements on the participating processes. These
coordination problems provide natural generalizations of real life
requirements. We then analyze the causal conditions that underlie suitable
solutions to these problems. The analysis is conducted in two stages: first,
the temporal ordering requirements are reduced to epistemic conditions. Then,
these epistemic conditions are characterized in terms of the causal
communication patterns that are necessary and sufficient to bring them about.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4434</identifier>
 <datestamp>2012-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4434</id><created>2011-12-19</created><updated>2012-04-25</updated><authors><author><keyname>Arias-Castro</keyname><forenames>Ery</forenames></author><author><keyname>Salmon</keyname><forenames>Joseph</forenames></author><author><keyname>Willett</keyname><forenames>Rebecca</forenames></author></authors><title>Oracle inequalities and minimax rates for non-local means and related
  adaptive kernel-based methods</title><categories>math.ST cs.CV cs.IT math.IT stat.TH</categories><comments>49 pages, 15 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes a novel theoretical characterization of the performance
of non-local means (NLM) for noise removal. NLM has proven effective in a
variety of empirical studies, but little is understood fundamentally about how
it performs relative to classical methods based on wavelets or how various
parameters (e.g., patch size) should be chosen. For cartoon images and images
which may contain thin features and regular textures, the error decay rates of
NLM are derived and compared with those of linear filtering, oracle estimators,
variable-bandwidth kernel methods, Yaroslavsky's filter and wavelet
thresholding estimators. The trade-off between global and local search for
matching patches is examined, and the bias reduction associated with the local
polynomial regression version of NLM is analyzed. The theoretical results are
validated via simulations for 2D images corrupted by additive white Gaussian
noise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4438</identifier>
 <datestamp>2011-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4438</id><created>2011-12-19</created><authors><author><keyname>Lonardi</keyname><forenames>Stefano</forenames></author><author><keyname>Duma</keyname><forenames>Denisa</forenames></author><author><keyname>Alpert</keyname><forenames>Matthew</forenames></author><author><keyname>Cordero</keyname><forenames>Francesca</forenames></author><author><keyname>Beccuti</keyname><forenames>Marco</forenames></author><author><keyname>Bhat</keyname><forenames>Prasanna R.</forenames></author><author><keyname>Wu</keyname><forenames>Yonghui</forenames></author><author><keyname>Ciardo</keyname><forenames>Gianfranco</forenames></author><author><keyname>Alsaihati</keyname><forenames>Burair</forenames></author><author><keyname>Ma</keyname><forenames>Yaqin</forenames></author><author><keyname>Wanamaker</keyname><forenames>Steve</forenames></author><author><keyname>Resnik</keyname><forenames>Josh</forenames></author><author><keyname>Close</keyname><forenames>Timothy J.</forenames></author></authors><title>Barcoding-free BAC Pooling Enables Combinatorial Selective Sequencing of
  the Barley Gene Space</title><categories>q-bio.GN cs.CE cs.DM cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new sequencing protocol that combines recent advances in
combinatorial pooling design and second-generation sequencing technology to
efficiently approach de novo selective genome sequencing. We show that
combinatorial pooling is a cost-effective and practical alternative to
exhaustive DNA barcoding when dealing with hundreds or thousands of DNA
samples, such as genome-tiling gene-rich BAC clones. The novelty of the
protocol hinges on the computational ability to efficiently compare hundreds of
million of short reads and assign them to the correct BAC clones so that the
assembly can be carried out clone-by-clone. Experimental results on simulated
data for the rice genome show that the deconvolution is extremely accurate
(99.57% of the deconvoluted reads are assigned to the correct BAC), and the
resulting BAC assemblies have very high quality (BACs are covered by contigs
over about 77% of their length, on average). Experimental results on real data
for a gene-rich subset of the barley genome confirm that the deconvolution is
accurate (almost 70% of left/right pairs in paired-end reads are assigned to
the same BAC, despite being processed independently) and the BAC assemblies
have good quality (the average sum of all assembled contigs is about 88% of the
estimated BAC length).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4451</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4451</id><created>2011-12-19</created><updated>2012-02-17</updated><authors><author><keyname>Vichare</keyname><forenames>Abhijat</forenames></author></authors><title>What is an OS?</title><categories>cs.OS</categories><comments>Major changes: Improvised the discussion of the implicit assumptions,
  added a sketch of a theory of an OS, and added a figure. Comments welcome. 32
  pages, 5 figures. Submitted</comments><acm-class>D.4.7</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While the engineering of operating systems is well understood, their formal
structure and properties are not. The latter needs a clear definition of the
purpose of an OS and an identification of the core. In this paper I offer
definitions of the OS, processes and files, and present a few useful
principles. The principles allow us to identify work like closure and
continuation algorithms, in programming languages that is useful for the OS
problem. The definitions and principles should yield a symbolic, albeit
semiquantitative, framework that encompasses practice. Towards that end I
specialise the definitions to describe conventional OSes and identify the core
operations for a single computer OS that can be used to express their
algorithms. The assumptions underlying the algorithms offer the design space
framework. The paging and segmentation algorithms for conventional OSes are
extracted from the framework as a check. Among the insights the emerge is that
an OS is a constructive proof of equivalence between models of computation.
Clear and useful definitions and principles are the first step towards a fully
quantitative structure of an OS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4454</identifier>
 <datestamp>2011-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4454</id><created>2011-12-19</created><authors><author><keyname>Shir</keyname><forenames>Ofer M.</forenames></author><author><keyname>Roslund</keyname><forenames>Jonathan</forenames></author><author><keyname>Whitley</keyname><forenames>Darrell</forenames></author><author><keyname>Rabitz</keyname><forenames>Herschel</forenames></author></authors><title>Evolutionary Hessian Learning: Forced Optimal Covariance Adaptive
  Learning (FOCAL)</title><categories>cs.NE cs.NA quant-ph</categories><acm-class>I.2.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Covariance Matrix Adaptation Evolution Strategy (CMA-ES) has been the
most successful Evolution Strategy at exploiting covariance information; it
uses a form of Principle Component Analysis which, under certain conditions, is
suggested to converge to the correct covariance matrix, formulated as the
inverse of the mathematically well-defined Hessian matrix. However, in
practice, there exist conditions where CMA-ES converges to the global optimum
(accomplishing its primary goal) while it does not learn the true covariance
matrix (missing an auxiliary objective), likely due to step-size deficiency.
These circumstances can involve high-dimensional landscapes with large
condition numbers. This paper introduces a novel technique entitled Forced
Optimal Covariance Adaptive Learning (FOCAL), with the explicit goal of
determining the Hessian at the global basin of attraction. It begins by
introducing theoretical foundations to the inverse relationship between the
learned covariance and the Hessian matrices. FOCAL is then introduced and
demonstrated to retrieve the Hessian matrix with high fidelity on both model
landscapes and experimental Quantum Control systems, which are observed to
possess a non-separable, non-quadratic search landscape. The recovered Hessian
forms are corroborated by physical knowledge of the systems. This study
constitutes an example for Natural Computing successfully serving other
branches of natural sciences, and introducing at the same time a powerful
generic method for any high-dimensional continuous search seeking landscape
information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4456</identifier>
 <datestamp>2011-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4456</id><created>2011-12-19</created><authors><author><keyname>Mas</keyname><forenames>Massimiliano Dal</forenames></author></authors><title>Cluster Analysis for a Scale-Free Folksodriven Structure Network</title><categories>cs.SI cs.IR physics.soc-ph</categories><comments>9 pages, 4 figures; for details see: http://www.maxdalmas.com</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Folksonomy is said to provide a democratic tagging system that reflects the
opinions of the general public, but it is not a classification system and it is
hard to make sense of. It would be necessary to share a representation of
contexts by all the users to develop a social and collaborative matching. The
solution could be to help the users to choose proper tags thanks to a dynamical
driven system of folksonomy that could evolve during the time. This paper uses
a cluster analysis to measure a new concept of a structure called
&quot;Folksodriven&quot;, which consists of tags, source and time. Many approaches
include in their goals the use of folksonomy that could evolve during time to
evaluate characteristics. This paper describes an alternative where the goal is
to develop a weighted network of tags where link strengths are based on the
frequencies of tag co-occurrence, and studied the weight distributions and
connectivity correlations among nodes in this network. The paper proposes and
analyzes the network structure of the Folksodriven tags thought as folksonomy
tags suggestions for the user on a dataset built on chosen websites. It is
observed that the hypergraphs of the Folksodriven are highly connected and that
the relative path lengths are relatively low, facilitating thus the
serendipitous discovery of interesting contents for the users. Then its
characteristics, Clustering Coefficient, is compared with random networks. The
goal of this paper is a useful analysis of the use of folksonomies on some well
known and extensive web sites with real user involvement. The advantages of the
new tagging method using folksonomy are on a new interesting method to be
employed by a knowledge management system.
  *** This paper has been accepted to the International Conference on Social
Computing and its Applications (SCA 2011) - Sydney Australia, 12-14 December
2011 ***
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4523</identifier>
 <datestamp>2011-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4523</id><created>2011-12-19</created><authors><author><keyname>Roune</keyname><forenames>Bjarke Hammersholt</forenames></author><author><keyname>de Cabez&#xf3;n</keyname><forenames>Eduardo S&#xe1;enz</forenames></author></authors><title>Complexity and Algorithms for Euler Characteristic of Simplicial
  Complexes</title><categories>cs.CG cs.CC cs.DS cs.MS cs.SC math.AC math.CO</categories><comments>28 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of computing the Euler characteristic of an abstract
simplicial complex given by its vertices and facets. We show that this problem
is #P-complete and present two new practical algorithms for computing Euler
characteristic. The two new algorithms are derived using combinatorial
commutative algebra and we also give a second description of them that requires
no algebra. We present experiments showing that the two new algorithms can be
implemented to be faster than previous Euler characteristic implementations by
a large margin.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4536</identifier>
 <datestamp>2011-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4536</id><created>2011-12-19</created><authors><author><keyname>B&#xf6;cker</keyname><forenames>Sebastian</forenames></author><author><keyname>Bui</keyname><forenames>Quang Bao Anh</forenames></author><author><keyname>Nicolas</keyname><forenames>Francois</forenames></author><author><keyname>Truss</keyname><forenames>Anke</forenames></author></authors><title>Intractability of the Minimum-Flip Supertree problem and its variants</title><categories>cs.CC</categories><comments>To be submitted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computing supertrees is a central problem in phylogenetics. The supertree
method that is by far the most widely used today was introduced in 1992 and is
called Matrix Representation with Parsimony analysis (MRP). Matrix
Representation using Flipping (MRF)}, which was introduced in 2002, is an
interesting variant of MRP: MRF is arguably more relevant that MRP and various
efficient implementations of MRF have been presented. From a theoretical point
of view, implementing MRF or MRP is solving NP-hard optimization problems. The
aim of this paper is to study the approximability and the fixed-parameter
tractability of the optimization problem corresponding to MRF, namely
Minimum-Flip Supertree. We prove strongly negative results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4539</identifier>
 <datestamp>2011-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4539</id><created>2011-12-19</created><authors><author><keyname>Nakasato</keyname><forenames>Naohito</forenames></author></authors><title>Implementation of a Parallel Tree Method on a GPU</title><categories>astro-ph.IM astro-ph.GA cs.PF</categories><comments>Journal of Computational Science, 2011; See our recent update at
  http://galaxy.u-aizu.ac.jp/trac/note/wiki/Octree_On_GPU</comments><doi>10.1016/j.jocs.2011.01.006</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The kd-tree is a fundamental tool in computer science. Among other
applications, the application of kd-tree search (by the tree method) to the
fast evaluation of particle interactions and neighbor search is highly
important, since the computational complexity of these problems is reduced from
O(N^2) for a brute force method to O(N log N) for the tree method, where N is
the number of particles. In this paper, we present a parallel implementation of
the tree method running on a graphics processing unit (GPU). We present a
detailed description of how we have implemented the tree method on a Cypress
GPU. An optimization that we found important is localized particle ordering to
effectively utilize cache memory. We present a number of test results and
performance measurements. Our results show that the execution of the tree
traversal in a force calculation on a GPU is practical and efficient.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4553</identifier>
 <datestamp>2012-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4553</id><created>2011-12-19</created><updated>2012-09-07</updated><authors><author><keyname>Truong</keyname><forenames>Kien T.</forenames></author><author><keyname>Sartori</keyname><forenames>Philippe</forenames></author><author><keyname>Heath</keyname><forenames>Robert W.</forenames><suffix>Jr</suffix></author></authors><title>Cooperative Algorithms for MIMO Amplify-and-Forward Relay Networks</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Transactions on Signal Processing in December 2011,
  revised in April 2012 and in September 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interference alignment is a signaling technique that provides high
multiplexing gain in the interference channel. It can be extended to multi-hop
interference channels, where relays aid transmission between sources and
destinations. In addition to coverage extension and capacity enhancement,
relays increase the multiplexing gain in the interference channel. In this
paper, three cooperative algorithms are proposed for a multiple-antenna
amplify-and-forward (AF) relay interference channel. The algorithms design the
transmitters and relays so that interference at the receivers can be aligned
and canceled. The first algorithm minimizes the sum power of enhanced noise
from the relays and interference at the receivers. The second and third
algorithms rely on a connection between mean square error and mutual
information to solve the end-to-end sum-rate maximization problem with either
equality or inequality power constraints via matrix-weighted sum mean square
error minimization. The resulting iterative algorithms converge to stationary
points of the corresponding optimization problems. Simulations show that the
proposed algorithms achieve higher end-to-end sum-rates and multiplexing gains
that existing strategies for AF relays, decode-and-forward relays, and direct
transmission. The first algorithm outperforms the other algorithms at high
signal-to-noise ratio (SNR) but performs worse than them at low SNR. Thanks to
power control, the third algorithm outperforms the second algorithm at the cost
of overhead.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4572</identifier>
 <datestamp>2011-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4572</id><created>2011-12-20</created><authors><author><keyname>Cai</keyname><forenames>Yang</forenames></author><author><keyname>Daskalakis</keyname><forenames>Constantinos</forenames></author><author><keyname>Weinberg</keyname><forenames>S. Matthew</forenames></author></authors><title>An Algorithmic Characterization of Multi-Dimensional Mechanisms</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We obtain a characterization of feasible, Bayesian, multi-item multi-bidder
auctions with independent, additive bidders as distributions over hierarchical
mechanisms. Combined with cyclic-monotonicity our results provide a complete
characterization of feasible, Bayesian Incentive Compatible (BIC) auctions for
this setting.
  Our characterization is enabled by a novel, constructive proof of Border's
theorem, and a new generalization of this theorem to independent (but not
necessarily iid) bidders. For one item and independent bidders, we show that
any feasible reduced form auction can be implemented as a distribution over
hierarchical mechanisms. We also give a polytime algorithm for determining
feasibility of a reduced form, or finding a separation hyperplane from feasible
reduced forms. Finally, we provide polytime algorithms to find and exactly
sample from a distribution over hierarchical mechanisms consistent with a given
feasible reduced form.
  Our results generalize to multi-item reduced forms for independent, additive
bidders. For multiple items, additive bidders with hard demand constraints, and
arbitrary value correlation across items or bidders, we give a proper
generalization of Border's theorem, and characterize feasible reduced forms as
multicommodity flows in related multicommodity flow instances. We show that our
generalization holds for a broader class of feasibility constraints, including
intersections of any two matroids.
  As a corollary we obtain revenue-optimal, BIC mechanisms in multi-item
multi-bidder settings, when each bidder has arbitrarily correlated values over
the items and additive valuations over bundles, and bidders are independent.
Their runtime is polynomial in the total number of bidder types (instead of
type profiles), and is improved to poly(#items, #bidders) using recent
structural results on optimal BIC auctions in item-symmetric settings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4578</identifier>
 <datestamp>2011-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4578</id><created>2011-12-20</created><authors><author><keyname>Kreft</keyname><forenames>Sebastian</forenames><affiliation>advisor</affiliation></author><author><keyname>Navarro</keyname><forenames>Gonzalo</forenames><affiliation>advisor</affiliation></author></authors><title>Self-Index based on LZ77 (thesis)</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Domains like bioinformatics, version control systems, collaborative editing
systems (wiki), and others, are producing huge data collections that are very
repetitive. That is, there are few differences between the elements of the
collection. This fact makes the compressibility of the collection extremely
high. For example, a collection with all different versions of a Wikipedia
article can be compressed up to the 0.1% of its original space, using the
Lempel-Ziv 1977 (LZ77) compression scheme.
  Many of these repetitive collections handle huge amounts of text data. For
that reason, we require a method to store them efficiently, while providing the
ability to operate on them. The most common operations are the extraction of
random portions of the collection and the search for all the occurrences of a
given pattern inside the whole collection.
  A self-index is a data structure that stores a text in compressed form and
allows to find the occurrences of a pattern efficiently. On the other hand,
self-indexes can extract any substring of the collection, hence they are able
to replace the original text. One of the main goals when using these indexes is
to store them within main memory.
  In this thesis we present a scheme for random text extraction from text
compressed with a Lempel-Ziv parsing. Additionally, we present a variant of
LZ77, called LZ-End, that efficiently extracts text using space close to that
of LZ77.
  The main contribution of this thesis is the first self-index based on
LZ77/LZ-End and oriented to repetitive texts, which outperforms the state of
the art (the RLCSA self-index) in many aspects. Finally, we present a corpus of
repetitive texts, coming from several application domains. We aim at providing
a standard set of texts for research and experimentation, hence this corpus is
publicly available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4597</identifier>
 <datestamp>2015-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4597</id><created>2011-12-20</created><authors><author><keyname>Wang</keyname><forenames>Wen-Qiang</forenames></author><author><keyname>Zhang</keyname><forenames>Qian-Ming</forenames></author><author><keyname>Zhou</keyname><forenames>Tao</forenames></author></authors><title>Evaluating Network Models: A Likelihood Analysis</title><categories>physics.soc-ph cs.SI physics.data-an</categories><comments>6 pages, 2 figures, 3 tables</comments><journal-ref>EPL 92 (2012) 28004</journal-ref><doi>10.1209/0295-5075/98/28004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many models are put forward to mimic the evolution of real networked systems.
A well-accepted way to judge the validity is to compare the modeling results
with real networks subject to several structural features. Even for a specific
real network, we cannot fairly evaluate the goodness of different models since
there are too many structural features while there is no criterion to select
and assign weights on them. Motivated by the studies on link prediction
algorithms, we propose a unified method to evaluate the network models via the
comparison of the likelihoods of the currently observed network driven by
different models, with an assumption that the higher the likelihood is, the
better the model is. We test our method on the real Internet at the Autonomous
System (AS) level, and the results suggest that the Generalized Linear
Preferential (GLP) model outperforms the Tel Aviv Network Generator (Tang),
while both two models are better than the Barab\'asi-Albert (BA) and
Erd\&quot;os-R\'enyi (ER) models. Our method can be further applied in determining
the optimal values of parameters that correspond to the maximal likelihood.
Experiment indicates that the parameters obtained by our method can better
capture the characters of newly-added nodes and links in the AS-level Internet
than the original methods in the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4604</identifier>
 <datestamp>2011-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4604</id><created>2011-12-20</created><authors><author><keyname>Brinkmann</keyname><forenames>Steffen</forenames></author><author><keyname>Gracia</keyname><forenames>Jos&#xe9;</forenames></author><author><keyname>Niethammer</keyname><forenames>Christoph</forenames></author><author><keyname>Keller</keyname><forenames>Rainer</forenames></author></authors><title>TEMANEJO - a debugger for task based parallel programming models</title><categories>cs.DC cs.SE</categories><comments>8 pages, presented at ParCO 2011, Ghent, Belgium</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the program Temanejo, a debugger for task based parallelisation
models such as StarSs. The challenge in debugging StarSs applications lies in
the fact that tasks are scheduled at runtime, i.e dynamically in accordance to
the data dependencies between them. Our tool assists the programmer in the
debugging process by visualising the task dependency graph and allowing to
control the scheduling of tasks. The toolset consists of the library Ayudame
which communicates with the StarSs runtime on one side and of the debugger
Temanejo on the other side which communicates with Ayudame. Temanejo provides a
graphical user interface with which the application can be analysed and
controlled.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4607</identifier>
 <datestamp>2011-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4607</id><created>2011-12-20</created><authors><author><keyname>Afkanpour</keyname><forenames>Arash</forenames></author><author><keyname>Szepesvari</keyname><forenames>Csaba</forenames></author><author><keyname>Bowling</keyname><forenames>Michael</forenames></author></authors><title>Alignment Based Kernel Learning with a Continuous Set of Base Kernels</title><categories>cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The success of kernel-based learning methods depend on the choice of kernel.
Recently, kernel learning methods have been proposed that use data to select
the most appropriate kernel, usually by combining a set of base kernels. We
introduce a new algorithm for kernel learning that combines a {\em continuous
set of base kernels}, without the common step of discretizing the space of base
kernels. We demonstrate that our new method achieves state-of-the-art
performance across a variety of real-world datasets. Furthermore, we explicitly
demonstrate the importance of combining the right dictionary of kernels, which
is problematic for methods based on a finite set of base kernels chosen a
priori. Our method is not the first approach to work with continuously
parameterized kernels. However, we show that our method requires substantially
less computation than previous such approaches, and so is more amenable to
multiple dimensional parameterizations of base kernels, which we demonstrate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4620</identifier>
 <datestamp>2012-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4620</id><created>2011-12-20</created><authors><author><keyname>P&#x142;aczek</keyname><forenames>Bart&#x142;omiej</forenames></author></authors><title>Selective data collection in vehicular networks for traffic control
  applications</title><categories>cs.NI</categories><comments>Preprint submitted to Transportation Research Part C: Emerging
  Technologies November 30, 2010; Bart{\l}omiej P{\l}aczek, Selective data
  collection in vehicular networks for traffic control applications,
  Transportation Research Part C: Emerging Technologies, 2011</comments><journal-ref>Transportation Research Part C 23 (2012) pp. 14-28</journal-ref><doi>10.1016/j.trc.2011.12.007</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Vehicular sensor network (VSN) is an emerging technology, which combines
wireless communication offered by vehicular ad hoc networks (VANET) with
sensing devices installed in vehicles. VSN creates a huge opportunity to extend
the road-side sensor infrastructure of existing traffic control systems. The
efficient use of the wireless communication medium is one of the basic issues
in VSN applications development. This paper introduces a novel method of
selective data collection for traffic control applications, which provides a
significant reduction in data amounts transmitted through VSN. The underlying
idea is to detect the necessity of data transfers on the basis of uncertainty
determination of the traffic control decisions. According to the proposed
approach, sensor data are transmitted from vehicles to the control node only at
selected time moments. Data collected in VSN are processed using on-line
traffic simulation technique, which enables traffic flow prediction,
performance evaluation of control strategies and uncertainty estimation. If
precision of the resulting information is insufficient, the optimal control
strategy cannot be derived without ambiguity. As a result the control decision
becomes uncertain and it is a signal informing that new traffic data from VSN
are necessary to provide more precise prediction and to reduce the uncertainty
of decision. The proposed method can be applied in traffic control systems of
different types e.g. traffic signals, variable speed limits, and dynamic route
guidance. The effectiveness of this method is illustrated in an experimental
study on traffic control at signalised intersection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4625</identifier>
 <datestamp>2013-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4625</id><created>2011-12-20</created><updated>2013-05-20</updated><authors><author><keyname>Smarandache</keyname><forenames>Roxana</forenames></author></authors><title>Pseudocodewords from Bethe Permanents</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It was recently conjectured that a vector with components equal to the Bethe
permanent of certain submatrices of a parity-check matrix is a pseudocodeword.
In this paper we prove a stronger version of this conjecture for some important
cases and investigate the families of pseudocodewords obtained by using the
Bethe permanent. We also highlight some interesting properties of the permanent
of block matrices and their effects on pseudocodewords.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4626</identifier>
 <datestamp>2012-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4626</id><created>2011-12-20</created><updated>2012-12-06</updated><authors><author><keyname>K&#xe4;mper</keyname><forenames>Jan-Hinrich</forenames></author><author><keyname>Kobourov</keyname><forenames>Stephen G.</forenames></author><author><keyname>N&#xf6;llenburg</keyname><forenames>Martin</forenames></author></authors><title>Circular-Arc Cartograms</title><categories>cs.CG</categories><comments>10 pages, 14 figures, extended version of proceedings paper in
  PacificVis 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new circular-arc cartogram model in which countries are drawn as
polygons with circular arcs instead of straight-line segments. Given a
political map and values associated with each country in the map, a cartogram
is a distorted map in which the areas of the countries are proportional to the
corresponding values. In the circular-arc cartogram model straight-line
segments can be replaced by circular arcs in order to modify the areas of the
polygons, while the corners of the polygons remain fixed. The countries in
circular-arc cartograms have the aesthetically pleasing appearance of clouds or
snowflakes, depending on whether their edges are bent outwards or inwards. This
makes it easy to determine whether a country has grown or shrunk, just by its
overall shape. We show that determining whether a given map and given
area-values can be realized as a circular-arc cartogram is an NP-hard problem.
Next we describe a heuristic method for constructing circular-arc cartograms,
which uses a max-flow computation on the dual graph of the map, along with a
computation of the straight skeleton of the underlying polygonal decomposition.
Our method is implemented and produces cartograms that, while not yet perfectly
accurate, achieve many of the desired areas in our real-world examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4628</identifier>
 <datestamp>2011-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4628</id><created>2011-12-20</created><authors><author><keyname>Shah</keyname><forenames>Habib</forenames></author><author><keyname>Ghazali</keyname><forenames>Rozaida</forenames></author><author><keyname>Nawi</keyname><forenames>Nazri Mohd</forenames></author></authors><title>Using Artificial Bee Colony Algorithm for MLP Training on Earthquake
  Time Series Data Prediction</title><categories>cs.NE cs.AI cs.LG</categories><comments>8 pages,8 figures;
  http://www.journalofcomputing.org/volume-3-issue-6-june-2011</comments><journal-ref>Journal of Computing, 3, 6 (2011), 135-142</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nowadays, computer scientists have shown the interest in the study of social
insect's behaviour in neural networks area for solving different combinatorial
and statistical problems. Chief among these is the Artificial Bee Colony (ABC)
algorithm. This paper investigates the use of ABC algorithm that simulates the
intelligent foraging behaviour of a honey bee swarm. Multilayer Perceptron
(MLP) trained with the standard back propagation algorithm normally utilises
computationally intensive training algorithms. One of the crucial problems with
the backpropagation (BP) algorithm is that it can sometimes yield the networks
with suboptimal weights because of the presence of many local optima in the
solution space. To overcome ABC algorithm used in this work to train MLP
learning the complex behaviour of earthquake time series data trained by BP,
the performance of MLP-ABC is benchmarked against MLP training with the
standard BP. The experimental result shows that MLP-ABC performance is better
than MLP-BP for time series data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4631</identifier>
 <datestamp>2012-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4631</id><created>2011-12-20</created><updated>2012-04-09</updated><authors><author><keyname>P&#x142;aczek</keyname><forenames>Bart&#x142;omiej</forenames></author></authors><title>Fuzzy cellular model of signal controlled traffic stream</title><categories>cs.DM cs.SY nlin.CG</categories><comments>18 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Microscopic traffic models have recently gained considerable importance as a
mean of optimising traffic control strategies. Computationally efficient and
sufficiently accurate microscopic traffic models have been developed based on
the cellular automata theory. However, the real-time application of the
available cellular automata models in traffic control systems is a difficult
task due to their discrete and stochastic nature. This paper introduces a novel
method of traffic streams modelling, which combines cellular automata and fuzzy
calculus. The introduced fuzzy cellular traffic model eliminates main drawbacks
of the cellular automata approach i.e. necessity of multiple Monte Carlo
simulations and calibration issues. Experimental results show that the
evolution of a simulated traffic stream in the proposed fuzzy cellular model is
consistent with that observed for stochastic cellular automata. The comparison
of both methods confirms that the computational cost of traffic simulation is
considerably lower for the proposed model. The model is suitable for real-time
applications in traffic control systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4632</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4632</id><created>2011-12-20</created><updated>2012-07-06</updated><authors><author><keyname>Emek</keyname><forenames>Yuval</forenames></author><author><keyname>Langner</keyname><forenames>Tobias</forenames></author><author><keyname>Wattenhofer</keyname><forenames>Roger</forenames></author></authors><title>The Price of Matching Selfish Vertices</title><categories>cs.CG</categories><comments>We changed the perspective of our paper and now look at the
  minimum-cost perfect matching problem through the price of anarchy (PoA) and
  price of stability (PoS) lens. Our previous results can be seen as analyzing
  the PoS of minimum-cost perfect matching and we now added an analysis of the
  PoA of this problem</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze the setting of minimum-cost perfect matchings with selfish
vertices through the price of anarchy (PoA) and price of stability (PoS) lens.
The underlying solution concept used for this analysis is the Gale-Shapley
stable matching notion, where the preferences are determined so that each
player (vertex) wishes to minimize the cost of her own matching edge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4644</identifier>
 <datestamp>2012-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4644</id><created>2011-12-20</created><updated>2012-01-06</updated><authors><author><keyname>Kiefer</keyname><forenames>Stefan</forenames></author><author><keyname>Murawski</keyname><forenames>Andrzej S.</forenames></author><author><keyname>Ouaknine</keyname><forenames>Jo&#xeb;l</forenames></author><author><keyname>Wachter</keyname><forenames>Bj&#xf6;rn</forenames></author><author><keyname>Worrell</keyname><forenames>James</forenames></author></authors><title>On the Complexity of the Equivalence Problem for Probabilistic Automata</title><categories>cs.FL</categories><comments>technical report for a FoSSaCS'12 paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Checking two probabilistic automata for equivalence has been shown to be a
key problem for efficiently establishing various behavioural and anonymity
properties of probabilistic systems. In recent experiments a randomised
equivalence test based on polynomial identity testing outperformed
deterministic algorithms. In this paper we show that polynomial identity
testing yields efficient algorithms for various generalisations of the
equivalence problem. First, we provide a randomized NC procedure that also
outputs a counterexample trace in case of inequivalence. Second, we show how to
check for equivalence two probabilistic automata with (cumulative) rewards. Our
algorithm runs in deterministic polynomial time, if the number of reward
counters is fixed. Finally we show that the equivalence problem for
probabilistic visibly pushdown automata is logspace equivalent to the
Arithmetic Circuit Identity Testing problem, which is to decide whether a
polynomial represented by an arithmetic circuit is identically zero.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4645</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4645</id><created>2011-12-20</created><authors><author><keyname>Magnien</keyname><forenames>Cl&#xe9;mence</forenames></author><author><keyname>Medem</keyname><forenames>Am&#xe9;lie</forenames></author><author><keyname>Tarissan</keyname><forenames>Fabien</forenames></author></authors><title>Towards realistic modeling of IP-level routing topology dynamics</title><categories>cs.NI</categories><comments>12 pages, In submission</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many works have studied the Internet topology, but few have investigated the
question of how it evolves over time. This paper focuses on the Internet
routing IP-level topology and proposes a first step towards realistic modeling
of its dynamics. We study periodic measurements of routing trees from a single
monitor to a fixed destination set and identify invariant properties of its
dynamics. We then propose a simple model for the underlying mechanisms of the
topology dynamics. Simulations show that it effectively captures the observed
behaviors, thus providing key insights of relevant mechanisms governing the
Internet routing dynamics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4671</identifier>
 <datestamp>2014-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4671</id><created>2011-12-20</created><updated>2012-08-11</updated><authors><author><keyname>Brent</keyname><forenames>Richard P.</forenames></author></authors><title>Finding D-optimal designs by randomised decomposition and switching</title><categories>math.CO cs.DS stat.CO</categories><comments>18 pages, 3 figures, 5 tables (figures corrected in v4). v5 added a
  reference and made minor improvements. Presented at the International
  Workshop on Hadamard Matrices held in honour of Kathy Horadam's 60th
  birthday, Melbourne, Nov. 2011. Data files are available at
  http://maths.anu.edu.au/~brent/maxdet/</comments><msc-class>05B20 (Primary) 15B34, 68R05 (Secondary)</msc-class><acm-class>F.2.1</acm-class><journal-ref>Australasian Journal of Combinatorics 55 (2013), 15-30. Erratum
  http://maths-people.anu.edu.au/~brent/pub/pub245_errata.html</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Hadamard maximal determinant (maxdet) problem is to find the maximum
determinant D(n) of a square {+1, -1} matrix of given order n. Such a matrix
with maximum determinant is called a saturated D-optimal design. We consider
some cases where n &gt; 2 is not divisible by 4, so the Hadamard bound is not
attainable, but bounds due to Barba or Ehlich and Wojtas may be attainable. If
R is a matrix with maximal (or conjectured maximal) determinant, then G = RR^T
is the corresponding Gram matrix. For the cases that we consider, maximal or
conjectured maximal Gram matrices are known. We show how to generate many
Hadamard equivalence classes of solutions from a given Gram matrix G, using a
randomised decomposition algorithm and row/column switching. In particular, we
consider orders 26, 27 and 33, and obtain new saturated D-optimal designs (for
order 26) and new conjectured saturated D-optimal designs (for orders 27 and
33).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4703</identifier>
 <datestamp>2011-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4703</id><created>2011-12-20</created><authors><author><keyname>Trt&#xed;k</keyname><forenames>Marek</forenames></author></authors><title>Abstracting Path Conditions for Effective Symbolic Execution</title><categories>cs.SC</categories><acm-class>D.2.4; D.2.5; F.3.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an algorithm for tests generation tools based on symbolic
execution. The algorithm is supposed to help in situations, when a tool is
repeatedly failing to cover some code by tests. The algorithm then provides the
tool a necessary condition strongly narrowing space of program paths, which
must be checked for reaching the uncovered code. We also discuss integration of
the algorithm into the tools and we provide experimental results showing a
potential of the algorithm to be valuable in the tools, when properly
implemented there.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4708</identifier>
 <datestamp>2011-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4708</id><created>2011-12-16</created><authors><author><keyname>Hollander</keyname><forenames>Christopher D.</forenames></author><author><keyname>Garibay</keyname><forenames>Ivan</forenames></author></authors><title>Transformation Networks: How Innovation and the Availability of
  Technology can Increase Economic Performance</title><categories>cs.SI</categories><comments>12 pages. Submitted to CompleNet 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A transformation network describes how one set of resources can be
transformed into another via technological processes. Transformation networks
in economics are useful because they can highlight areas for future
innovations, both in terms of new products, new production techniques, or
better efficiency. They also make it easy to detect areas where an economy
might be fragile. In this paper, we use computational simulations to
investigate how the density of a transformation network affects the economic
performance, as measured by the gross domestic product (GDP), of an artificial
economy. Our results show that on average, the GDP of our economy increases as
the density of the transformation network increases. We also find that while
the average performance increases, the maximum possible performance decreases
and the minimum possible performance increases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4718</identifier>
 <datestamp>2011-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4718</id><created>2011-12-20</created><authors><author><keyname>Britton</keyname><forenames>Tom</forenames></author><author><keyname>Lindenstrand</keyname><forenames>David</forenames></author></authors><title>Inhomogeneous epidemics on weighted networks</title><categories>math.PR cs.SI physics.soc-ph</categories><msc-class>60</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A social (sexual) network is modeled by an extension of the configuration
model to the situation where edges have weights, e.g. reflecting the number of
sex-contacts between the individuals. An epidemic model is defined on the
network such that individuals are heterogeneous in terms of how susceptible and
infectious they are. The basic reproduction number R_0 is derived and studied
for various examples, but also the size and probability of a major outbreak.
The qualitative conclusion is that R_0 gets larger as the community becomes
more heterogeneous but that different heterogeneities (degree distribution,
weight, susceptibility and infectivity) can sometimes have the cumulative
effect of homogenizing the community, thus making $R_0$ smaller. The effect on
the probability and final size of an outbreak is more complicated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4722</identifier>
 <datestamp>2012-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4722</id><created>2011-12-20</created><updated>2012-10-18</updated><authors><author><keyname>Gr&#xfc;new&#xe4;lder</keyname><forenames>Steffen</forenames></author><author><keyname>Baldassarre</keyname><forenames>Luca</forenames></author><author><keyname>Pontil</keyname><forenames>Massimiliano</forenames></author><author><keyname>Gretton</keyname><forenames>Arthur</forenames></author><author><keyname>Lever</keyname><forenames>Guy</forenames></author></authors><title>Modeling transition dynamics in MDPs with RKHS embeddings of conditional
  distributions</title><categories>cs.LG</categories><comments>The article can now be found under arXiv:1206.4655. We combined both
  versions and are withdrawing this version because of the resulting redundancy</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new, nonparametric approach to estimating the value function in
reinforcement learning. This approach makes use of a recently developed
representation of conditional distributions as functions in a reproducing
kernel Hilbert space. Such representations bypass the need for estimating
transition probabilities, and apply to any domain on which kernels can be
defined. Our approach avoids the need to approximate intractable integrals
since expectations are represented as RKHS inner products whose computation has
linear complexity in the sample size. Thus, we can efficiently perform value
function estimation in a wide variety of settings, including finite state
spaces, continuous states spaces, and partially observable tasks where only
sensor measurements are available. A second advantage of the approach is that
we learn the conditional distribution representation from a training sample,
and do not require an exhaustive exploration of the state space. We prove
convergence of our approach either to the optimal policy, or to the closest
projection of the optimal policy in our model class, under reasonable
assumptions. In experiments, we demonstrate the performance of our algorithm on
a learning task in a continuous state space (the under-actuated pendulum), and
on a navigation problem where only images from a sensor are observed. We
compare with least-squares policy iteration where a Gaussian process is used
for value function estimation. Our algorithm achieves better performance in
both tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4742</identifier>
 <datestamp>2011-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4742</id><created>2011-12-20</created><authors><author><keyname>Chihani</keyname><forenames>Bachir</forenames></author><author><keyname>Collange</keyname><forenames>Denis</forenames></author></authors><title>Simulation-based study of MPTCP (Multipath TCP)</title><categories>cs.NI</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Our current world is revolutionned by the networks which are interconnecting
any machine to any other one. Nowadays equipments are plugged to the network by
the way of many different network adapters (Ethernet, wifi, GSM), and network
equipments are more and more interconnected to each other creating a highly
mesh network. Thus, redundant paths are created between any two endpoints
enabling multipath or the use of multiple paths to handle a communication. The
benefits of multipath are the enhancement of robustness against failure, and
minimizing communication cost. In the present work, we will talk about some
solutions of multipath applied to the transport level. We will expose the most
important problem facing multipath which is packet reordering, and we will also
expose results of our simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4758</identifier>
 <datestamp>2013-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4758</id><created>2011-12-20</created><authors><author><keyname>Pauls</keyname><forenames>Scott D.</forenames></author><author><keyname>Remondini</keyname><forenames>Daniel</forenames></author></authors><title>A measure of centrality based on the spectrum of the Laplacian</title><categories>physics.data-an cs.SI physics.soc-ph</categories><comments>12 pages, 6 figures, 2 tables</comments><doi>10.1103/PhysRevE.85.066127</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a family of new centralities, the k-spectral centralities.
k-Spectral centrality is a measurement of importance with respect to the
deformation of the graph Laplacian associated with the graph. Due to this
connection, k-spectral centralities have various interpretations in terms of
spectrally determined information.
  We explore this centrality in the context of several examples. While for
sparse unweighted networks 1-spectral centrality behaves similarly to other
standard centralities, for dense weighted networks they show different
properties. In summary, the k-spectral centralities provide a novel and useful
measurement of relevance (for single network elements as well as whole
subnetworks) distinct from other known measures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4773</identifier>
 <datestamp>2011-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4773</id><created>2011-12-20</created><authors><author><keyname>Yang</keyname><forenames>Han-Xin</forenames></author><author><keyname>Wang</keyname><forenames>Wen-Xu</forenames></author><author><keyname>Lai</keyname><forenames>Ying-Cheng</forenames></author><author><keyname>Wang</keyname><forenames>Bing-Hong</forenames></author></authors><title>Greedy routing on networks of mobile agents</title><categories>cs.NI physics.data-an</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we design a greedy routing on networks of mobile agents. In
the greedy routing algorithm, every time step a packet in agent $i$ is
delivered to the agent $j$ whose distance from the destination is shortest
among searched neighbors of agent $i$. Based on the greedy routing, we study
the traffic dynamics and traffic-driven epidemic spreading on networks of
mobile agents. We find that the transportation capacity of networks and the
epidemic threshold increase as the communication radius increases. For moderate
moving speed, the transportation capacity of networks is the highest and the
epidemic threshold maintains a large value. These results can help controlling
the traffic congestion and epidemic spreading on mobile networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4775</identifier>
 <datestamp>2011-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4775</id><created>2011-12-20</created><authors><author><keyname>Tariq</keyname><forenames>Usman</forenames></author><author><keyname>Malik</keyname><forenames>Yasir</forenames></author><author><keyname>Hong</keyname><forenames>Man-Pyo</forenames></author></authors><title>NACS: non-overlapping AP's caching scheme to reduce handoff in 802.11
  wireless LAN</title><categories>cs.NI</categories><comments>6 Pages, 6 Figures, Conference Pager</comments><doi>10.1109/ICON.2005.1635434</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the escalation of the IEEE 802.11 based wireless networks, voice over IP
and analogous applications are also used over wireless networks. Recently, the
wireless LAN systems are spaciously deployed for public Internet services. In
public wireless LAN systems, reliable user authentication and mobility support
are indispensable issues. When a mobile device budges out the range of one
access point (AP) and endeavor to connect to new AP, it performs handoff.
Contemporarily, PNC and SNC were proposed to propagate the MN context to the
entire neighboring AP's on the wireless network with the help of neighbor
graph. In this paper, we proposed a non-overlapping AP's caching scheme (NACS),
which propagates the mobile node context to those AP's which do not overlap
with the current AP. To capture the topology of non-overlapping AP's in the
wireless network, non-overlapping graph (NOG) is generated at each AP.
Simulation results shows that NACS reduces the signaling cost of propagating
the MN context to the neighbor AP's in the wireless network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4788</identifier>
 <datestamp>2013-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4788</id><created>2011-12-20</created><updated>2012-09-26</updated><authors><author><keyname>Fritz</keyname><forenames>Tobias</forenames></author><author><keyname>Chaves</keyname><forenames>Rafael</forenames></author></authors><title>Entropic Inequalities and Marginal Problems</title><categories>cs.IT math.IT math.PR quant-ph</categories><comments>26 pages, 3 figures</comments><msc-class>94A17, 60A05</msc-class><journal-ref>IEEE Trans. on Information Theory, vol. 59, pages 803 - 817 (2013)</journal-ref><doi>10.1109/TIT.2012.2222863</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A marginal problem asks whether a given family of marginal distributions for
some set of random variables arises from some joint distribution of these
variables. Here we point out that the existence of such a joint distribution
imposes non-trivial conditions already on the level of Shannon entropies of the
given marginals. These entropic inequalities are necessary (but not sufficient)
criteria for the existence of a joint distribution. For every marginal problem,
a list of such Shannon-type entropic inequalities can be calculated by
Fourier-Motzkin elimination, and we offer a software interface to a
Fourier-Motzkin solver for doing so. For the case that the hypergraph of given
marginals is a cycle graph, we provide a complete analytic solution to the
problem of classifying all relevant entropic inequalities, and use this result
to bound the decay of correlations in stochastic processes. Furthermore, we
show that Shannon-type inequalities for differential entropies are not relevant
for continuous-variable marginal problems; non-Shannon-type inequalities are,
both in the discrete and in the continuous case. In contrast to other
approaches, our general framework easily adapts to situations where one has
additional (conditional) independence requirements on the joint distribution,
as in the case of graphical models. We end with a list of open problems.
  A complementary article discusses applications to quantum nonlocality and
contextuality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4791</identifier>
 <datestamp>2011-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4791</id><created>2011-12-20</created><authors><author><keyname>Damian</keyname><forenames>Mirela</forenames></author><author><keyname>Demaine</keyname><forenames>Erik</forenames></author><author><keyname>Flatland</keyname><forenames>Robin</forenames></author></authors><title>Unfolding Orthogonal Polyhedra with Quadratic Refinement: The
  Delta-Unfolding Algorithm</title><categories>cs.CG cs.DM</categories><comments>15 pages, 10 figures</comments><acm-class>F.2.2; I.3.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that every orthogonal polyhedron homeomorphic to a sphere can be
unfolded without overlap while using only polynomially many (orthogonal) cuts.
By contrast, the best previous such result used exponentially many cuts. More
precisely, given an orthogonal polyhedron with n vertices, the algorithm cuts
the polyhedron only where it is met by the grid of coordinate planes passing
through the vertices, together with Theta(n^2) additional coordinate planes
between every two such grid planes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4811</identifier>
 <datestamp>2011-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4811</id><created>2011-12-20</created><authors><author><keyname>Singh</keyname><forenames>Jaspreet</forenames></author><author><keyname>Madhow</keyname><forenames>Upamanyu</forenames></author></authors><title>Phase-Quantized Block Noncoherent Communication</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Analog-to-digital conversion (ADC) is a key bottleneck in scaling DSP-centric
receiver architectures to multiGigabit/s speeds. Recent information-theoretic
results, obtained under ideal channel conditions (perfect synchronization, no
dispersion), indicate that low-precision ADC (1-4 bits) could be a suitable
choice for designing such high speed systems. In this work, we study the impact
of employing low-precision ADC in a {\it carrier asynchronous} system.
Specifically, we consider transmission over the block noncoherent Additive
White Gaussian Noise (AWGN) channel, and investigate the achievable performance
under low-precision output quantization. We focus attention on an architecture
in which the receiver quantizes {\it only the phase} of the received signal:
this has the advantage of being implementable without automatic gain control,
using multiple 1-bit ADCs preceded by analog multipliers. For standard uniform
Phase Shift Keying (PSK) modulation, we study the structure of the transition
density of the resulting phase-quantized block noncoherent channel. Several
results, based on the symmetry inherent in the channel model, are provided to
characterize this transition density. Low-complexity procedures for computing
the channel capacity, and for block demodulation, are obtained using these
results. Numerical computations are performed to compare the performance of
quantized and unquantized systems, for different quantization precisions, and
different block lengths. It is observed, for example, that with QPSK
modulation, 8-bin phase quantization of the received signal recovers about
80-85% of the capacity attained with unquantized observations, while 12-bin
phase quantization recovers more than 90% of the unquantized capacity.
Dithering the constellation is shown to improve the performance in the face of
drastic quantization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4826</identifier>
 <datestamp>2011-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4826</id><created>2011-12-20</created><authors><author><keyname>Perc</keyname><forenames>Matjaz</forenames></author></authors><title>Does strong heterogeneity promote cooperation by group interactions?</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI q-bio.PE</categories><comments>12 pages, 4 figures; accepted for publication in New Journal of
  Physics [related work available at http://arxiv.org/abs/0708.1746 and
  http://www.matjazperc.com/]</comments><journal-ref>New J. Phys. 13 (2011) 123027</journal-ref><doi>10.1088/1367-2630/13/12/123027</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Previous research has highlighted the importance of strong heterogeneity for
the successful evolution of cooperation in games governed by pairwise
interactions. Here we determine to what extent this is true for games governed
by group interactions. We therefore study the evolution of cooperation in the
public goods game on the square lattice, the triangular lattice and the random
regular graph, whereby the payoffs are distributed either uniformly or
exponentially amongst the players by assigning to them individual scaling
factors that determine the share of the public good they will receive. We find
that uniformly distributed public goods are more successful in maintaining high
levels of cooperation than exponentially distributed public goods. This is not
in agreement with previous results on games governed by pairwise interactions,
indicating that group interactions may be less susceptible to the promotion of
cooperation by means of strong heterogeneity as originally assumed, and that
the role of strongly heterogeneous states should be reexamined for other types
of games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4876</identifier>
 <datestamp>2012-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4876</id><created>2011-12-20</created><updated>2012-01-11</updated><authors><author><keyname>Blinovsky</keyname><forenames>Vladimir</forenames></author></authors><title>Random Coding Bound for the Reliability Function in Quantum Channel:
  General Case</title><categories>cs.IT math.IT</categories><comments>This paper has been withdrawn by the author due to make correct
  version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We complete the proof of conjecture, which allows to complete the derivation
of the random coding bound for the reliability function in quantum channel in
the case of arbitrary signal states
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4879</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4879</id><created>2011-12-20</created><updated>2013-04-17</updated><authors><author><keyname>Niesen</keyname><forenames>Urs</forenames></author><author><keyname>Maddah-Ali</keyname><forenames>Mohammad</forenames></author></authors><title>Interference Alignment: From Degrees-of-Freedom to Constant-Gap Capacity
  Approximations</title><categories>cs.IT math.IT</categories><comments>56 pages, to appear in IEEE Transactions on Information Theory</comments><journal-ref>IEEE Transactions on Information Theory, vol. 59, pp. 4855 - 4888,
  August 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interference alignment is a key technique for communication scenarios with
multiple interfering links. In several such scenarios, interference alignment
was used to characterize the degrees-of-freedom of the channel. However, these
degrees-of-freedom capacity approximations are often too weak to make accurate
predictions about the behavior of channel capacity at finite signal-to-noise
ratios (SNRs). The aim of this paper is to significantly strengthen these
results by showing that interference alignment can be used to characterize
capacity to within a constant gap. We focus on real, time-invariant,
frequency-flat X-channels. The only known solutions achieving the
degrees-of-freedom of this channel are either based on real interference
alignment or on layer-selection schemes. Neither of these solutions seems
sufficient for a constant-gap capacity approximation.
  In this paper, we propose a new communication scheme and show that it
achieves the capacity of the Gaussian X-channel to within a constant gap. To
aid in this process, we develop a novel deterministic channel model. This
deterministic model depends on the 0.5log(SNR) most-significant bits of the
channel coefficients rather than only the single most-significant bit used in
conventional deterministic models. The proposed deterministic model admits a
wider range of achievable schemes that can be translated to the Gaussian
channel. For this deterministic model, we find an approximately optimal
communication scheme. We then translate this scheme for the deterministic
channel to the original Gaussian X-channel and show that it achieves capacity
to within a constant gap. This is the first constant-gap result for a general,
fully-connected network requiring interference alignment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4881</identifier>
 <datestamp>2014-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4881</id><created>2011-12-20</created><updated>2012-06-28</updated><authors><author><keyname>Sperber</keyname><forenames>Steven</forenames></author><author><keyname>Voight</keyname><forenames>John</forenames></author></authors><title>Computing zeta functions of sparse nondegenerate hypersurfaces</title><categories>math.AG cs.SC math.NT</categories><comments>37 pages; minor revision</comments><doi>10.1112/S1461157012001179</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using the cohomology theory of Dwork, as developed by Adolphson and Sperber,
we exhibit a deterministic algorithm to compute the zeta function of a
nondegenerate hypersurface defined over a finite field. This algorithm is
particularly well-suited to work with polynomials in small characteristic that
have few monomials (relative to their dimension). Our method covers toric,
affine, and projective hypersurfaces and also can be used to compute the
L-function of an exponential sum.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4883</identifier>
 <datestamp>2011-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4883</id><created>2011-12-20</created><authors><author><keyname>Fish</keyname><forenames>Alexander</forenames></author><author><keyname>Gurevich</keyname><forenames>Shamgar</forenames></author><author><keyname>Hadani</keyname><forenames>Ronny</forenames></author><author><keyname>Sayeed</keyname><forenames>Akbar</forenames></author><author><keyname>Schwartz</keyname><forenames>Oded</forenames></author></authors><title>Computing the Matched Filter in Linear Time</title><categories>cs.IT math.IT</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A fundamental problem in wireless communication is the time-frequency shift
(TFS) problem: Find the time-frequency shift of a signal in a noisy
environment. The shift is the result of time asynchronization of a sender with
a receiver, and of non-zero speed of a sender with respect to a receiver. A
classical solution of a discrete analog of the TFS problem is called the
matched filter algorithm. It uses a pseudo-random waveform S(t) of the length
p, and its arithmetic complexity is O(p^{2} \cdot log (p)), using fast Fourier
transform. In these notes we introduce a novel approach of designing new
waveforms that allow faster matched filter algorithm. We use techniques from
group representation theory to design waveforms S(t), which enable us to
introduce two fast matched filter (FMF) algorithms, called the flag algorithm,
and the cross algorithm. These methods solve the TFS problem in O(p\cdot log
(p)) operations. We discuss applications of the algorithms to mobile
communication, GPS, and radar.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4895</identifier>
 <datestamp>2012-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4895</id><created>2011-12-20</created><updated>2012-10-11</updated><authors><author><keyname>Ghauch</keyname><forenames>Ziad G.</forenames></author></authors><title>3D Finite Element Analysis of HMA Overlay Mix Design to Control
  Reflective Cracking</title><categories>cs.CE</categories><comments>14 pages, 6 figures, table 2</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This study examines the effectiveness of HMA overlay design strategies for
the purpose of controlling the development of reflective cracking. A parametric
study was conducted using a 3D Finite Element (FE) model of a rigid pavement
section including Linear Viscoelastic (LVE) material properties for the Hot Mix
Asphalt (HMA) overlay and non-uniform tire-pavement contact stresses. Several
asphalt mixtures were tested in the surface, intermediate, and leveling course
of the HMA overlay. Results obtained show that no benefits can be anticipated
by using either Polymer-Modified (PM) or Dense-Graded (DG) mixtures instead of
Standard Binder (SB) mixtures in the surface or intermediate course. For the
leveling course, the use of a PM asphalt binder was found beneficial in terms
of mitigating reflective cracking. As compared to the SB mix, the use of PM
asphalt mixture in the leveling course reduced the level of longitudinal
tensile stress at the bottom of the HMA overlay above the PCC joint by
approximately 30%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4897</identifier>
 <datestamp>2012-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4897</id><created>2011-12-20</created><updated>2012-08-30</updated><authors><author><keyname>Kari</keyname><forenames>Lila</forenames></author><author><keyname>Kopecki</keyname><forenames>Steffen</forenames></author></authors><title>Deciding Whether a Regular Language is Generated by a Splicing System</title><categories>cs.FL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Splicing as a binary word/language operation is inspired by the DNA
recombination under the action of restriction enzymes and ligases, and was
first introduced by Tom Head in 1987. Shortly thereafter, it was proven that
the languages generated by (finite) splicing systems form a proper subclass of
the class of regular languages. However, the question of whether or not one can
decide if a given regular language is generated by a splicing system remained
open. In this paper we give a positive answer to this question. Namely, we
prove that, if a language is generated by a splicing system, then it is also
generated by a splicing system whose size is a function of the size of the
syntactic monoid of the input language, and which can be effectively
constructed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4906</identifier>
 <datestamp>2011-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4906</id><created>2011-12-20</created><authors><author><keyname>Yaeger</keyname><forenames>Larry</forenames></author><author><keyname>Griffith</keyname><forenames>Virgil</forenames></author><author><keyname>Sporns</keyname><forenames>Olaf</forenames></author></authors><title>Passive and Driven Trends in the Evolution of Complexity</title><categories>cs.NE q-bio.PE</categories><comments>8 pages; In Bullock, S. et al. eds. Artificial Life XI: Proceedings
  of the Eleventh International Conference on the Simulation and Synthesis of
  Living Systems. MIT Press. Cambridge, MA. 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The nature and source of evolutionary trends in complexity is difficult to
assess from the fossil record, and the driven vs. passive nature of such trends
has been debated for decades. There are also questions about how effectively
artificial life software can evolve increasing levels of complexity. We extend
our previous work demonstrating an evolutionary increase in an information
theoretic measure of neural complexity in an artificial life system
(Polyworld), and introduce a new technique for distinguishing driven from
passive trends in complexity. Our experiments show that evolution can and does
select for complexity increases in a driven fashion, in some circumstances, but
under other conditions it can also select for complexity stability. It is
suggested that the evolution of complexity is entirely driven---just not in a
single direction---at the scale of species. This leaves open the question of
evolutionary trends at larger scales.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4909</identifier>
 <datestamp>2011-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4909</id><created>2011-12-20</created><authors><author><keyname>Ikeda</keyname><forenames>Yuichi</forenames></author><author><keyname>Ikegami</keyname><forenames>Takashi</forenames></author><author><keyname>Kataoka</keyname><forenames>Kazuto</forenames></author><author><keyname>Ogimoto</keyname><forenames>Kazuhiko</forenames></author></authors><title>A Unit Commitment Model with Demand Response for the Integration of
  Renewable Energies</title><categories>cs.SY</categories><comments>submitted to 2012 IEEE Power &amp; Energy Society General Meeting</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The output of renewable energy fluctuates significantly depending on weather
conditions. We develop a unit commitment model to analyze requirements of the
forecast output and its error for renewable energies. Our model obtains the
time series for the operational state of thermal power plants that would
maximize the profits of an electric power utility by taking into account both
the forecast of output its error for renewable energies and the demand response
of consumers. We consider a power system consisting of thermal power plants,
photovoltaic systems (PV), and wind farms and analyze the effect of the
forecast error on the operation cost and reserves. We confirm that the
operation cost was increases with the forecast error. The effect of a sudden
decrease in wind power is also analyzed. More thermal power plants need to be
operated to generate power to absorb this sudden decrease in wind power. The
increase in the number of operating thermal power plants within a short period
does not affect the total operation cost significantly; however the
substitution of thermal power plants by wind farms or PV systems is not
expected to be very high. Finally, the effects of the demand response in the
case of a sudden decrease in wind power are analyzed. We confirm that the
number of operating thermal power plants is reduced by the demand response. A
power utility has to continue thermal power plants for ensuring supply-demand
balance; some of these plants can be decommissioned after installing a large
number of wind farms or PV systems, if the demand response is applied using an
appropriate price structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4915</identifier>
 <datestamp>2011-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4915</id><created>2011-12-20</created><authors><author><keyname>Blackburn</keyname><forenames>Jeremy</forenames></author><author><keyname>Simha</keyname><forenames>Ramanuja</forenames></author><author><keyname>Kourtellis</keyname><forenames>Nicolas</forenames></author><author><keyname>Zuo</keyname><forenames>Xiang</forenames></author><author><keyname>Long</keyname><forenames>Clayton</forenames></author><author><keyname>Ripeanu</keyname><forenames>Matei</forenames></author><author><keyname>Skvoretz</keyname><forenames>John</forenames></author><author><keyname>Iamnitchi</keyname><forenames>Adriana</forenames></author></authors><title>Cheaters in the Steam Community Gaming Social Network</title><categories>cs.SI cs.CY physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Online gaming is a multi-billion dollar industry that entertains a large,
global population. One unfortunate phenomenon, however, poisons the competition
and the fun: cheating. The costs of cheating span from industry-supported
expenditures to detect and limit cheating, to victims' monetary losses due to
cyber crime.
  This paper studies cheaters in the Steam Community, an online social network
built on top of the world's dominant digital game delivery platform. We
collected information about more than 12 million gamers connected in a global
social network, of which more than 700 thousand have their profiles flagged as
cheaters. We also collected in-game interaction data of over 10 thousand
players from a popular multiplayer gaming server. We show that cheaters are
well embedded in the social and interaction networks: their network position is
largely undistinguishable from that of fair players. We observe that the
cheating behavior appears to spread through a social mechanism: the presence
and the number of cheater friends of a fair player is correlated with the
likelihood of her becoming a cheater in the future. Also, we observe that there
is a social penalty involved with being labeled as a cheater: cheaters are
likely to switch to more restrictive privacy settings once they are tagged and
they lose more friends than fair players. Finally, we observe that the number
of cheaters is not correlated with the geographical, real-world population
density, or with the local popularity of the Steam Community.
  This analysis can ultimately inform the design of mechanisms to deal with
anti-social behavior (e.g., spamming, automated collection of data) in generic
online social networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4941</identifier>
 <datestamp>2011-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4941</id><created>2011-12-21</created><authors><author><keyname>Zhang</keyname><forenames>Yu</forenames></author><author><keyname>Li</keyname><forenames>Chengqing</forenames></author><author><keyname>Wong</keyname><forenames>Kwok-Wo</forenames></author><author><keyname>Shu</keyname><forenames>Shi</forenames></author><author><keyname>Chen</keyname><forenames>Guanrong</forenames></author></authors><title>Cryptanalyzing a chaos-based image encryption algorithm using alternate
  structure</title><categories>cs.CR</categories><comments>19 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, a chaos-based image encryption algorithm using alternate structure
(IEAS) was proposed. This paper focuses on differential cryptanalysis of the
algorithm and finds that some properties of IEAS can support a differential
attack to recover equivalent secret key with a little small number of known
plain-images. Detailed approaches of the cryptanalysis for cryptanalyzing IEAS
of the lower round number are presented and the breaking method can be extended
to the case of higher round number. Both theoretical analysis and experiment
results are provided to support vulnerability of IEAS against differential
attack. In addition, some other security defects of IEAS, including
insensitivity with respect to changes of plain-images and insufficient size of
key space, are also reported.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4944</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4944</id><created>2011-12-21</created><updated>2013-04-30</updated><authors><author><keyname>Meric</keyname><forenames>Hugo</forenames></author><author><keyname>Lacan</keyname><forenames>J&#xe9;r&#xf4;me</forenames></author><author><keyname>Arnal</keyname><forenames>Fabrice</forenames></author><author><keyname>Lesthievent</keyname><forenames>Guy</forenames></author><author><keyname>Boucheret</keyname><forenames>Marie-Laure</forenames></author></authors><title>Combining Adaptive Coding and Modulation with Hierarchical Modulation in
  Satcom Systems</title><categories>cs.NI</categories><comments>10 pages, double column, submitted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the design of a broadcast system in order to maximise the
throughput. This task is usually challenging due to the channel variability.
Forty years ago, Cover introduced and compared two schemes: time sharing and
superposition coding. Even if the second scheme was proved to be optimal for
some channels, modern satellite communications systems such as DVB-SH and
DVB-S2 mainly rely on time sharing strategy to optimize the throughput. They
consider hierarchical modulation, a practical implementation of superposition
coding, but only for unequal error protection or backward compatibility
purposes. We propose in this article to combine time sharing and hierarchical
modulation together and show how this scheme can improve the performance in
terms of available rate. We introduce the hierarchical 16-APSK to boost the
performance of the DVB-S2 standard. We also evaluate various strategies to
group the receivers in pairs when using hierarchical modulation. Finally, we
show in a realistic use case based on DVB-S2 that the combined scheme can
provide throughput gains greater than 10% compared to the best time sharing
strategy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4955</identifier>
 <datestamp>2012-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4955</id><created>2011-12-21</created><updated>2012-06-11</updated><authors><author><keyname>Avci</keyname><forenames>Serhat Nazim</forenames></author><author><keyname>Ayanoglu</keyname><forenames>Ender</forenames></author></authors><title>Coded Path Protection: Efficient Conversion of Sharing to Coding</title><categories>cs.NI</categories><comments>12 pages, an extended version of the paper in IEEE ICC 2012
  conference. It includes the proof of the proposed coding technique</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Link failures in wide area networks are common and cause significant data
losses. Mesh-based protection schemes offer high capacity efficiency but they
are slow and require complex signaling. Additionally, real-time reconfiguration
of a cross-connect threatens their transmission integrity. On the other hand,
coding-based protection schemes are proactive. Therefore, they have higher
restoration speed, lower signaling complexity, and higher transmission
integrity. This paper introduces a coding-based protection scheme, named Coded
Path Protection (CPP). In CPP, a backup copy of the primary data is encoded
with other data streams, resulting in capacity savings. This paper presents an
optimal and simple capacity placement and coding group formation algorithm. The
algorithm converts the sharing structure of any solution of a Shared Path
Protection (SPP) technique into a coding structure with minimum extra capacity.
We conducted quantitative and qualitative comparisons of our technique with the
SPP and, another technique, known as p-cycle protection. Simulation results
confirm that the CPP is significantly faster than the SPP and p-cycle
techniques. CPP incurs marginal extra capacity on top of SPP. Its capacity
efficiency is lower than the p-cycle technique for dense networks but can be
higher for sparse networks. In addition, unlike p-cycle protection, CPP is
inherently suitable for the wavelength continuity constraint in optical
networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4980</identifier>
 <datestamp>2011-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4980</id><created>2011-12-21</created><authors><author><keyname>Rosenfeld</keyname><forenames>Meni</forenames></author></authors><title>Analysis of Bitcoin Pooled Mining Reward Systems</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we describe the various scoring systems used to calculate
rewards of participants in Bitcoin pooled mining, explain the problems each
were designed to solve and analyze their respective advantages and
disadvantages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.4993</identifier>
 <datestamp>2011-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.4993</id><created>2011-12-21</created><authors><author><keyname>Abreu</keyname><forenames>Salvador</forenames></author><author><keyname>Costa</keyname><forenames>Vitor Santos</forenames></author></authors><title>Online Proceedings of the 11th International Colloquium on
  Implementation of Constraint LOgic Programming Systems (CICLOPS 2011),
  Lexington, KY, U.S.A., July 10, 2011</title><categories>cs.PL</categories><acm-class>D.1.6; D.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  These are the revised versions of the papers presented at CICLOPS 2011, a
workshop colocated with ICLP 2011.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5000</identifier>
 <datestamp>2011-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5000</id><created>2011-12-21</created><authors><author><keyname>Khedker</keyname><forenames>Uday P.</forenames></author><author><keyname>Mycroft</keyname><forenames>Alan</forenames></author><author><keyname>Rawat</keyname><forenames>Prashant Singh</forenames></author></authors><title>Lazy Pointer Analysis</title><categories>cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Flow- and context-sensitive pointer analysis is generally considered too
expensive for large programs; most tools relax one or both of the requirements
for scalability. We formulate a flow- and context-sensitive points-to analysis
that is lazy in the following sense: points-to information is computed only for
live pointers and its propagation is sparse (restricted to live ranges of
respective pointers). Further, our analysis (a) uses strong liveness,
effectively including dead code elimination; (b) afterwards calculates
must-points-to information from may-points-to information instead of using a
mutual fixed-point; and (c) uses value-based termination of call strings during
interprocedural analysis (which reduces the number of call strings
significantly).
  A naive implementation of our analysis within GCC-4.6.0 gave analysis time
and size of points-to measurements for SPEC2006. Using liveness reduced the
amount of points-to information by an order of magnitude with no loss of
precision. For all programs under 30kLoC we found that the results were much
more precise than gcc's analysis. What comes as a pleasant surprise however, is
the fact that below this cross-over point, our naive linked-list implementation
is faster than a flow- and context-insensitive analysis which is primarily used
for efficiency. We speculate that lazy flow- and context-sensitive analyses may
be not only more precise, but also more efficient, than current approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5032</identifier>
 <datestamp>2013-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5032</id><created>2011-12-21</created><authors><author><keyname>Farokhi</keyname><forenames>F.</forenames></author><author><keyname>Langbort</keyname><forenames>C.</forenames></author><author><keyname>Johansson</keyname><forenames>K. H.</forenames></author></authors><title>Decentralized Disturbance Accommodation with Limited Plant Model
  Information</title><categories>math.OC cs.SY</categories><journal-ref>SIAM Journal on Control and Optimization, 51(2), pp. 1543-1573,
  2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The design of optimal disturbance accommodation and servomechanism
controllers with limited plant model information is considered in this paper.
Their closed-loop performance are compared using a performance metric called
competitive ratio which is the worst-case ratio of the cost of a given control
design strategy to the cost of the optimal control design with full model
information. It was recently shown that when it comes to designing optimal
centralized or partially structured decentralized state-feedback controllers
with limited model information, the best control design strategy in terms of
competitive ratio is a static one. This is true even though the optimal
structured decentralized state-feedback controller with full model information
is dynamic. In this paper, we show that, in contrast, the best limited model
information control design strategy for the disturbance accommodation problem
gives a dynamic controller. We find an explicit minimizer of the competitive
ratio and we show that it is undominated, that is, there is no other control
design strategy that performs better for all possible plants while having the
same worst-case ratio. This optimal controller can be separated into a static
feedback law and a dynamic disturbance observer. For constant disturbances, it
is shown that this structure corresponds to proportional-integral control.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5071</identifier>
 <datestamp>2011-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5071</id><created>2011-12-21</created><authors><author><keyname>Duchon</keyname><forenames>Philippe</forenames><affiliation>INRIA Bordeaux - Sud-Ouest, LaBRI</affiliation></author></authors><title>Random generation of combinatorial structures: Boltzmann samplers and
  beyond</title><categories>cs.DS math.CO</categories><comments>Winter Simulation Conference (2011)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Boltzmann model for the random generation of &quot;decomposable&quot; combinatorial
structures is a set of techniques that allows for efficient random sampling
algorithms for a large class of families of discrete objects. The usual
requirement of sampling uniformly from the set of objects of a given size is
somehow relaxed, though uniformity among objects of each size is still ensured.
Generating functions, rather than the enumeration sequences they are based on,
are the crucial ingredient. We give a brief description of the general theory,
as well as a number of newer developments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5083</identifier>
 <datestamp>2013-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5083</id><created>2011-12-21</created><updated>2013-04-11</updated><authors><author><keyname>Dutykh</keyname><forenames>Denys</forenames><affiliation>LAMA</affiliation></author><author><keyname>Kalisch</keyname><forenames>Henrik</forenames></author></authors><title>Boussinesq modeling of surface waves due to underwater landslides</title><categories>physics.class-ph cs.NA math.AP math.NA physics.ao-ph physics.comp-ph physics.flu-dyn physics.geo-ph</categories><comments>32 pages, 16 Figures, 68 references. Other author's papers can be
  downloaded at http://www.denys-dutykh.com/</comments><proxy>ccsd</proxy><journal-ref>Nonlin. Processes Geophys. 20 (2013) 267-285</journal-ref><doi>10.5194/npg-20-267-2013</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consideration is given to the influence of an underwater landslide on waves
at the surface of a shallow body of fluid. The equations of motion which govern
the evolution of the barycenter of the landslide mass include various
dissipative effects due to bottom friction, internal energy dissipation, and
viscous drag. The surface waves are studied in the Boussinesq scaling, with
time-dependent bathymetry. A numerical model for the Boussinesq equations is
introduced which is able to handle time-dependent bottom topography, and the
equations of motion for the landslide and surface waves are solved
simultaneously. The numerical solver for the Boussinesq equations can also be
restricted to implement a shallow-water solver, and the shallow-water and
Boussinesq configurations are compared. A particular bathymetry is chosen to
illustrate the general method, and it is found that the Boussinesq system
predicts larger wave run-up than the shallow-water theory in the example
treated in this paper. It is also found that the finite fluid domain has a
significant impact on the behavior of the wave run-up.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5089</identifier>
 <datestamp>2012-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5089</id><created>2011-12-21</created><authors><author><keyname>Anashin</keyname><forenames>Vladimir</forenames></author></authors><title>Automata finiteness criterion in terms of van der Put series of automata
  functions</title><categories>cs.FL math.NT</categories><msc-class>68Q70 (Primary) 11E95, 11B85 (Secondary)</msc-class><journal-ref>p-Adic Numbers, Ultrametric Analysis and Applications, 2012, Vol.
  4, No. 2, pp. 151-160</journal-ref><doi>10.1134/S2070046612020070</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the paper we develop the $p$-adic theory of discrete automata. Every
automaton $\mathfrak A$ (transducer) whose input/output alphabets consist of
$p$ symbols can be associated to a continuous (in fact, 1-Lipschitz) map from
$p$-adic integers to $p$ integers, the automaton function $f_\mathfrak A$. The
$p$-adic theory (in particular, the $p$-adic ergodic theory) turned out to be
very efficient in a study of properties of automata expressed via properties of
automata functions. In the paper we prove a criterion for finiteness of the
number of states of automaton in terms of van der Put series of the automaton
function. The criterion displays connections between $p$-adic analysis and the
theory of automata sequences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5096</identifier>
 <datestamp>2014-03-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5096</id><created>2011-12-21</created><updated>2012-10-26</updated><authors><author><keyname>Anashin</keyname><forenames>Vladimir</forenames></author></authors><title>The Non-Archimedean Theory of Discrete Systems</title><categories>math.DS cs.FL cs.LO</categories><comments>The extended version of the talk given at MACIS-2011</comments><msc-class>37A25 (Primary) 11B52, 11E95, 11K41, 11K45, 68Q70 (Secondary)</msc-class><journal-ref>Mathematics in Computer Science, 2012, vol. 6, no. 4, p. 375--393</journal-ref><doi>10.1007/s11786-012-0132-7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the paper, we study behavior of discrete dynamical systems (automata)
w.r.t. transitivity; that is, speaking loosely, we consider how diverse may be
behavior of the system w.r.t. variety of word transformations performed by the
system: We call a system completely transitive if, given arbitrary pair $a,b$
of finite words that have equal lengths, the system $\mathfrak A$, while
evolution during (discrete) time, at a certain moment transforms $a$ into $b$.
To every system $\mathfrak A$, we put into a correspondence a family $\mathcal
F_{\mathfrak A}$ of continuous maps of a suitable non-Archimedean metric space
and show that the system is completely transitive if and only if the family
$\mathcal F_{\mathfrak A}$ is ergodic w.r.t. the Haar measure; then we find
easy-to-verify conditions the system must satisfy to be completely transitive.
The theory can be applied to analyze behavior of straight-line computer
programs (in particular, pseudo-random number generators that are used in
cryptography and simulations) since basic CPU instructions (both numerical and
logical) can be considered as continuous maps of a (non-Archimedean) metric
space $\mathbb Z_2$ of 2-adic integers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5116</identifier>
 <datestamp>2011-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5116</id><created>2011-12-21</created><authors><author><keyname>Chaumont</keyname><forenames>Nicolas</forenames></author><author><keyname>Adami</keyname><forenames>Christoph</forenames></author></authors><title>Evolution of sustained foraging in 3D environments with physics</title><categories>cs.NE q-bio.NC q-bio.PE</categories><comments>18 pages, 15 figures. Supplementary Materials available at
  http://tinyurl.com/autonomous-foragers-supplement</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Artificially evolving foraging behavior in simulated legged animals has
proved to be a notoriously difficult task. Here, we co-evolve the morphology
and controller for virtual organisms in a three-dimensional physically
realistic environment to produce goal-directed legged locomotion. We show that
following and reaching multiple food sources can evolve de novo, by evaluating
each organism on multiple food sources placed on a basic pattern that is
gradually randomized across generations. We devised a strategy of evolutionary
&quot;staging&quot;, where the best organism from a set of evolutionary experiments using
a particular fitness function is used to seed a new set, with a fitness
function that is progressively altered to better challenge organisms as
evolution improves them. We find that an organism's efficiency at reaching the
first food source does not predict its ability at finding subsequent ones
because foraging efficiency crucially depends on the position of the last food
source reached, an effect illustrated by &quot;foraging maps&quot; that capture the
organism's controller state, body position, and orientation. Our best evolved
foragers are able to reach multiple food sources over 90% of the time on
average, a behavior that is key to any biologically realistic simulation where
a self-sustaining population has to survive by collecting food sources in
three-dimensional, physical environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5121</identifier>
 <datestamp>2011-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5121</id><created>2011-12-21</created><authors><author><keyname>Anderson</keyname><forenames>Katharine</forenames></author></authors><title>Collaboration Network Formation and the Demand for Problem Solvers with
  Heterogenous Skills</title><categories>physics.soc-ph cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Collaboration networks provide a method for examining the structure of
collaborative communities. The model I present in this paper connects an
individual's skill set to her position in the collaboration network, and
changes in the distribution of skills to the structure of the collaboration
network as a whole. I show that individuals with a useful combination of skills
will have a disproportionate number of links in the network, resulting in a
skewed degree distribution. The degree distribution becomes more skewed as
problems become more difficult, leading to a community dominated by a few
high-degree superstars.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5136</identifier>
 <datestamp>2011-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5136</id><created>2011-12-21</created><authors><author><keyname>Li</keyname><forenames>Ye</forenames></author><author><keyname>Danish</keyname><forenames>Matthew</forenames></author><author><keyname>West</keyname><forenames>Richard</forenames></author></authors><title>Quest-V: A Virtualized Multikernel for High-Confidence Systems</title><categories>cs.OS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper outlines the design of `Quest-V', which is implemented as a
collection of separate kernels operating together as a distributed system on a
chip. Quest-V uses virtualization techniques to isolate kernels and prevent
local faults from affecting remote kernels. This leads to a high-confidence
multikernel approach, where failures of system subcomponents do not render the
entire system inoperable. A virtual machine monitor for each kernel keeps track
of shadow page table mappings that control immutable memory access
capabilities. This ensures a level of security and fault tolerance in
situations where a service in one kernel fails, or is corrupted by a malicious
attack. Communication is supported between kernels using shared memory regions
for message passing. Similarly, device driver data structures are shareable
between kernels to avoid the need for complex I/O virtualization, or
communication with a dedicated kernel responsible for I/O. In Quest-V, device
interrupts are delivered directly to a kernel, rather than via a monitor that
determines the destination. Apart from bootstrapping each kernel, handling
faults and managing shadow page tables, the monitors are not needed. This
differs from conventional virtual machine systems in which a central monitor,
or hypervisor, is responsible for scheduling and management of host resources
amongst a set of guest kernels. In this paper we show how Quest-V can implement
novel fault isolation and recovery techniques that are not possible with
conventional systems. We also show how the costs of using virtualization for
isolation of system services does not add undue overheads to the overall system
performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5152</identifier>
 <datestamp>2011-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5152</id><created>2011-12-21</created><authors><author><keyname>Ercetin</keyname><forenames>Ozgur</forenames></author><author><keyname>Memis</keyname><forenames>Mehmet Ozerk</forenames></author></authors><title>Comments on &quot;Capacity with explicit delay guarantees for generic sources
  over correlated Rayleigh channel&quot;</title><categories>cs.NI</categories><comments>7 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address a major flaw in the abovementioned paper, which proposes to
calculate effective capacity of random channels by the use of central limit
theorem. We analytically show that the authors are incorrect in finding the
effective capacity by first taking the limit of cumulative random process
rather than taking the limit of moment generating function of the same process.
We later quantify our results over a correlated ON-OFF process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5153</identifier>
 <datestamp>2013-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5153</id><created>2011-12-21</created><updated>2013-06-12</updated><authors><author><keyname>Woodruff</keyname><forenames>David P.</forenames></author><author><keyname>Zhang</keyname><forenames>Qin</forenames></author></authors><title>Tight Bounds for Distributed Functional Monitoring</title><categories>cs.DS</categories><comments>Added a formal embedding argument in Section 3.2.2. This embedding
  argument required some other changes in Section 3, causing us to relax the
  definition of k-GAP-MAJ to k-APPROX-SUM, which is a similar problem. We still
  use the original k-GAP_MAJ in Section 6.1. Section 4 also now has missing
  details regarding the predictor</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We resolve several fundamental questions in the area of distributed
functional monitoring, initiated by Cormode, Muthukrishnan, and Yi (SODA,
2008). In this model there are $k$ sites each tracking their input and
communicating with a central coordinator that continuously maintain an
approximate output to a function $f$ computed over the union of the inputs. The
goal is to minimize the communication.
  We show the randomized communication complexity of estimating the number of
distinct elements up to a $1+\eps$ factor is $\tilde{\Omega}(k/\eps^2)$,
improving the previous $\Omega(k + 1/\eps^2)$ bound and matching known upper
bounds up to a logarithmic factor. For the $p$-th frequency moment $F_p$, $p &gt;
1$, we improve the previous $\Omega(k + 1/\eps^2)$ communication bound to
$\tilde{\Omega}(k^{p-1}/\eps^2)$. We obtain similar improvements for heavy
hitters, empirical entropy, and other problems. We also show that we can
estimate $F_p$, for any $p &gt; 1$, using $\tilde{O}(k^{p-1}\poly(\eps^{-1}))$
communication. This greatly improves upon the previous
$\tilde{O}(k^{2p+1}N^{1-2/p} \poly(\eps^{-1}))$ bound of Cormode,
Muthukrishnan, and Yi for general $p$, and their $\tilde{O}(k^2/\eps +
k^{1.5}/\eps^3)$ bound for $p = 2$. For $p = 2$, our bound resolves their main
open question.
  Our lower bounds are based on new direct sum theorems for approximate
majority, and yield significant improvements to problems in the data stream
model, improving the bound for estimating $F_p, p &gt; 2,$ in $t$ passes from
$\tilde{\Omega}(n^{1-2/p}/(\eps^{2/p} t))$ to
$\tilde{\Omega}(n^{1-2/p}/(\eps^{4/p} t))$, giving the first bound for
estimating $F_0$ in $t$ passes of $\Omega(1/(\eps^2 t))$ bits of space that
does not use the gap-hamming problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5200</identifier>
 <datestamp>2011-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5200</id><created>2011-12-21</created><authors><author><keyname>Matherat</keyname><forenames>Philippe</forenames></author><author><keyname>Jaekel</keyname><forenames>Marc-Thierry</forenames></author></authors><title>Relativistic causality and clockless circuits</title><categories>cs.DC gr-qc</categories><comments>25 pages, 5 figures</comments><report-no>LPTENS 11/32</report-no><journal-ref>ACM J. Emerg. Technol. Comput. Syst. 7, 4, Article 20 (December
  2011)</journal-ref><doi>10.1145/2043643.2043650</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Time plays a crucial role in the performance of computing systems. The
accurate modelling of logical devices, and of their physical implementations,
requires an appropriate representation of time and of all properties that
depend on this notion. The need for a proper model, particularly acute in the
design of clockless delay-insensitive (DI) circuits, leads one to reconsider
the classical descriptions of time and of the resulting order and causal
relations satisfied by logical operations. This questioning meets the
criticisms of classical spacetime formulated by Einstein when founding
relativity theory and is answered by relativistic conceptions of time and
causality. Applying this approach to clockless circuits and considering the
trace formalism, we rewrite Udding's rules which characterize communications
between DI components. We exhibit their intrinsic relation with relativistic
causality. For that purpose, we introduce relativistic generalizations of
traces, called R-traces, which provide a pertinent description of
communications and compositions of DI components.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5215</identifier>
 <datestamp>2011-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5215</id><created>2011-12-21</created><authors><author><keyname>Zhou</keyname><forenames>Tianyi</forenames></author><author><keyname>Tao</keyname><forenames>Dacheng</forenames></author></authors><title>Bilateral Random Projections</title><categories>stat.ML cs.DS</categories><comments>17 pages, 3 figures, technical report</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Low-rank structure have been profoundly studied in data mining and machine
learning. In this paper, we show a dense matrix $X$'s low-rank approximation
can be rapidly built from its left and right random projections $Y_1=XA_1$ and
$Y_2=X^TA_2$, or bilateral random projection (BRP). We then show power scheme
can further improve the precision. The deterministic, average and deviation
bounds of the proposed method and its power scheme modification are proved
theoretically. The effectiveness and the efficiency of BRP based low-rank
approximation is empirically verified on both artificial and real datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5239</identifier>
 <datestamp>2011-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5239</id><created>2011-12-22</created><authors><author><keyname>Bahi</keyname><forenames>Jacques M.</forenames></author><author><keyname>Couturier</keyname><forenames>Rapha&#xeb;l</forenames></author><author><keyname>Guyeux</keyname><forenames>Christophe</forenames></author><author><keyname>H&#xe9;am</keyname><forenames>Pierre-Cyrille</forenames></author></authors><title>Efficient and Cryptographically Secure Generation of Chaotic
  Pseudorandom Numbers on GPU</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a new pseudorandom number generator (PRNG) on
graphics processing units (GPU). This PRNG is based on the so-called chaotic
iterations. It is firstly proven to be chaotic according to the Devaney's
formulation. We thus propose an efficient implementation for GPU that
successfully passes the BigCrush tests, deemed to be the hardest battery of
tests in TestU01. Experiments show that this PRNG can generate about 20 billion
of random numbers per second on Tesla C1060 and NVidia GTX280 cards. It is then
established that, under reasonable assumptions, the proposed PRNG can be
cryptographically secure. A chaotic version of the Blum-Goldwasser asymmetric
key encryption scheme is finally proposed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5245</identifier>
 <datestamp>2011-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5245</id><created>2011-12-22</created><authors><author><keyname>Bahi</keyname><forenames>Jacques M.</forenames></author><author><keyname>Guyeux</keyname><forenames>Christophe</forenames></author><author><keyname>Heam</keyname><forenames>Pierre-Cyrille</forenames></author></authors><title>A Complexity Approach for Steganalysis</title><categories>cs.CR cs.CC</categories><comments>Submitted to the Journ\`ees Codes et St\'eganographie 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this proposal for the Journ\`ees Codes et St\'eganographie 2012, we define
a new rigorous approach for steganalysis based on the complexity theory. It is
similar to the definitions of security that can be found for hash functions,
PRNG, and so on. We propose here a notion of \emph{secure hiding} and we give a
first secure hiding scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5246</identifier>
 <datestamp>2013-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5246</id><created>2011-12-22</created><updated>2013-07-21</updated><authors><author><keyname>Menahem</keyname><forenames>Eitan</forenames></author><author><keyname>Rokach</keyname><forenames>Lior</forenames></author><author><keyname>Elovici</keyname><forenames>Yuval</forenames></author></authors><title>Combining One-Class Classifiers via Meta-Learning</title><categories>cs.LG</categories><comments>To appear in CIKM 2013. Related to both Ensemble learning and
  one-class learning. Length: 10 pages</comments><acm-class>K.3.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Selecting the best classifier among the available ones is a difficult task,
especially when only instances of one class exist. In this work we examine the
notion of combining one-class classifiers as an alternative for selecting the
best classifier. In particular, we propose two new one-class classification
performance measures to weigh classifiers and show that a simple ensemble that
implements these measures can outperform the most popular one-class ensembles.
Furthermore, we propose a new one-class ensemble scheme, TUPSO, which uses
meta-learning to combine one-class classifiers. Our experiments demonstrate the
superiority of TUPSO over all other tested ensembles and show that the TUPSO
performance is statistically indistinguishable from that of the hypothetical
best classifier.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5252</identifier>
 <datestamp>2012-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5252</id><created>2011-12-22</created><updated>2012-06-02</updated><authors><author><keyname>Lambiotte</keyname><forenames>Renaud</forenames></author><author><keyname>Rosvall</keyname><forenames>Martin</forenames></author></authors><title>Ranking and clustering of nodes in networks with smart teleportation</title><categories>cs.SI physics.soc-ph</categories><comments>10 pages, 7 figures</comments><journal-ref>Phys. Rev. E 85, 056107 (2012)</journal-ref><doi>10.1103/PhysRevE.85.056107</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Random teleportation is a necessary evil for ranking and clustering directed
networks based on random walks. Teleportation enables ergodic solutions, but
the solutions must necessarily depend on the exact implementation and
parametrization of the teleportation. For example, in the commonly used
PageRank algorithm, the teleportation rate must trade off a heavily biased
solution with a uniform solution. Here we show that teleportation to links
rather than nodes enables a much smoother trade-off and effectively more robust
results. We also show that, by not recording the teleportation steps of the
random walker, we can further reduce the effect of teleportation with dramatic
effects on clustering.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5255</identifier>
 <datestamp>2012-03-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5255</id><created>2011-12-22</created><updated>2012-03-20</updated><authors><author><keyname>Ibsen-Jensen</keyname><forenames>Rasmus</forenames></author><author><keyname>Miltersen</keyname><forenames>Peter Bro</forenames></author></authors><title>Solving simple stochastic games with few coin toss positions</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Gimbert and Horn gave an algorithm for solving simple stochastic games with
running time O(r! n) where n is the number of positions of the simple
stochastic game and r is the number of its coin toss positions. Chatterjee et
al. pointed out that a variant of strategy iteration can be implemented to
solve this problem in time 4^r r^{O(1)} n^{O(1)}. In this paper, we show that
an algorithm combining value iteration with retrograde analysis achieves a time
bound of O(r 2^r (r log r + n)), thus improving both time bounds. While the
algorithm is simple, the analysis leading to this time bound is involved, using
techniques of extremal combinatorics to identify worst case instances for the
algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5282</identifier>
 <datestamp>2012-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5282</id><created>2011-12-22</created><authors><author><keyname>Wu</keyname><forenames>Yuanxin</forenames></author><author><keyname>Zhang</keyname><forenames>Hongliang</forenames></author><author><keyname>Wu</keyname><forenames>Meiping</forenames></author><author><keyname>Hu</keyname><forenames>Xiaoping</forenames></author><author><keyname>Hu</keyname><forenames>Dewen</forenames></author></authors><title>Observability of Strapdown INS Alignment: A Global Perspective</title><categories>cs.RO cs.SY</categories><comments>25 pages; IEEE Trans. on Aerospace and Electronic Systems, Jan. 2012</comments><journal-ref>IEEE Trans. on Aerospace and Electronic Systems, 48(1), pp.
  78-102, 2012</journal-ref><doi>10.1109/TAES.2012.6129622</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Alignment of the strapdown inertial navigation system (INS) has strong
nonlinearity, even worse when maneuvers, e.g., tumbling techniques, are
employed to improve the alignment. There is no general rule to attack the
observability of a nonlinear system, so most previous works addressed the
observability of the corresponding linearized system by implicitly assuming
that the original nonlinear system and the linearized one have identical
observability characteristics. Strapdown INS alignment is a nonlinear system
that has its own characteristics. Using the inherent properties of strapdown
INS, e.g., the attitude evolution on the SO(3) manifold, we start from the
basic definition and develop a global and constructive approach to investigate
the observability of strapdown INS static and tumbling alignment, highlighting
the effects of the attitude maneuver on observability. We prove that strapdown
INS alignment, considering the unknown constant sensor biases, will be
completely observable if the strapdown INS is rotated successively about two
different axes and will be nearly observable for finite known unobservable
states (no more than two) if it is rotated about a single axis. Observability
from a global perspective provides us with insights into and a clearer picture
of the problem, shedding light on previous theoretical results on strapdown INS
alignment that were not comprehensive or consistent.. The reporting of
inconsistencies calls for a review of all linearization-based observability
studies in the vast literature. Extensive simulations with constructed ideal
observers and an extended Kalman filter are carried out, and the numerical
results accord with the analysis. The conclusions can also assist in designing
the optimal tumbling strategy and the appropriate state observer in practice to
maximize the alignment performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5283</identifier>
 <datestamp>2011-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5283</id><created>2011-12-22</created><authors><author><keyname>Wu</keyname><forenames>Yuanxin</forenames></author><author><keyname>Xiao</keyname><forenames>Zhenxiong</forenames></author></authors><title>On Position Translation Vector</title><categories>cs.RO</categories><comments>7 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper derives a new &quot;position translation vector&quot; (PTV) with remarkably
simpler rate equation, and proves its connections with Savage's PTV.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5297</identifier>
 <datestamp>2012-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5297</id><created>2011-12-22</created><updated>2012-03-05</updated><authors><author><keyname>Tanizawa</keyname><forenames>Toshihiro</forenames></author><author><keyname>Havlin</keyname><forenames>Shlomo</forenames></author><author><keyname>Stanley</keyname><forenames>H. Eugene</forenames></author></authors><title>Robustness of onion-like correlated networks against targeted attacks</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><comments>12 pages, 8 figures</comments><doi>10.1103/PhysRevE.85.046109</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, it was found by Schneider et al. [Proc. Natl. Acad. Sci. USA, 108,
3838 (2011)], using simulations, that scale-free networks with &quot;onion
structure&quot; are very robust against targeted high degree attacks. The onion
structure is a network where nodes with almost the same degree are connected.
Motivated by this work, we propose and analyze, based on analytical
considerations, an onion-like candidate for a nearly optimal structure against
simultaneous random and targeted high degree node attacks. The nearly optimal
structure can be viewed as a hierarchically interconnected random regular
graphs, the degrees and populations of which are specified by the degree
distribution. This network structure exhibits an extremely assortative
degree-degree correlation and has a close relationship to the &quot;onion
structure.&quot; After deriving a set of exact expressions that enable us to
calculate the critical percolation threshold and the giant component of a
correlated network for an arbitrary type of node removal, we apply the theory
to the cases of random scale-free networks that are highly vulnerable against
targeted high degree node removal. Our results show that this vulnerability can
be significantly reduced by implementing this onion-like type of degree-degree
correlation without much undermining the almost complete robustness against
random node removal. We also investigate in detail the robustness enhancement
due to assortative degree-degree correlation by introducing a joint
degree-degree probability matrix that interpolates between an uncorrelated
network structure and the onion-like structure proposed here by tuning a single
control parameter. The optimal values of the control parameter that maximize
the robustness against simultaneous random and targeted attacks are also
determined. Our analytical calculations are supported by numerical simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5298</identifier>
 <datestamp>2011-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5298</id><created>2011-12-22</created><authors><author><keyname>Werner</keyname><forenames>Tomas</forenames></author></authors><title>Zero-Temperature Limit of a Convergent Algorithm to Minimize the Bethe
  Free Energy</title><categories>cs.CV</categories><comments>Research Report</comments><report-no>CTU--CMP--2011--14</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  After the discovery that fixed points of loopy belief propagation coincide
with stationary points of the Bethe free energy, several researchers proposed
provably convergent algorithms to directly minimize the Bethe free energy.
These algorithms were formulated only for non-zero temperature (thus finding
fixed points of the sum-product algorithm) and their possible extension to zero
temperature is not obvious. We present the zero-temperature limit of the
double-loop algorithm by Heskes, which converges a max-product fixed point. The
inner loop of this algorithm is max-sum diffusion. Under certain conditions,
the algorithm combines the complementary advantages of the max-product belief
propagation and max-sum diffusion (LP relaxation): it yields good approximation
of both ground states and max-marginals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5309</identifier>
 <datestamp>2012-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5309</id><created>2011-12-22</created><updated>2012-11-04</updated><authors><author><keyname>Schmidhuber</keyname><forenames>J&#xfc;rgen</forenames></author></authors><title>POWERPLAY: Training an Increasingly General Problem Solver by
  Continually Searching for the Simplest Still Unsolvable Problem</title><categories>cs.AI cs.LG</categories><comments>21 pages, additional connections to previous work, references to
  first experiments with POWERPLAY</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most of computer science focuses on automatically solving given computational
problems. I focus on automatically inventing or discovering problems in a way
inspired by the playful behavior of animals and humans, to train a more and
more general problem solver from scratch in an unsupervised fashion. Consider
the infinite set of all computable descriptions of tasks with possibly
computable solutions. The novel algorithmic framework POWERPLAY (2011)
continually searches the space of possible pairs of new tasks and modifications
of the current problem solver, until it finds a more powerful problem solver
that provably solves all previously learned tasks plus the new one, while the
unmodified predecessor does not. Wow-effects are achieved by continually making
previously learned skills more efficient such that they require less time and
space. New skills may (partially) re-use previously learned skills. POWERPLAY's
search orders candidate pairs of tasks and solver modifications by their
conditional computational (time &amp; space) complexity, given the stored
experience so far. The new task and its corresponding task-solving skill are
those first found and validated. The computational costs of validating new
tasks need not grow with task repertoire size. POWERPLAY's ongoing search for
novelty keeps breaking the generalization abilities of its present solver. This
is related to Goedel's sequence of increasingly powerful formal theories based
on adding formerly unprovable statements to the axioms without affecting
previously provable theorems. The continually increasing repertoire of problem
solving procedures can be exploited by a parallel search for solutions to
additional externally posed tasks. POWERPLAY may be viewed as a greedy but
practical implementation of basic principles of creativity. A first
experimental analysis can be found in separate papers [53,54].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5314</identifier>
 <datestamp>2011-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5314</id><created>2011-12-22</created><authors><author><keyname>Koch</keyname><forenames>Tobias</forenames></author><author><keyname>Lapidoth</keyname><forenames>Amos</forenames></author></authors><title>One-Bit Quantizers for Fading Channels</title><categories>cs.IT math.IT</categories><comments>4 pages. To be presented at the 2012 International Zurich Seminar on
  Communications (IZS)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study channel capacity when a one-bit quantizer is employed at the output
of the discrete-time average-power-limited Rayleigh-fading channel. We focus on
the low signal-to-noise ratio regime, where communication at very low spectral
efficiencies takes place, as in Spread Spectrum and Ultra-Wideband
communications. We demonstrate that, in this regime, the best one-bit quantizer
does not reduce the asymptotic capacity of the coherent channel, but it does
reduce that of the noncoherent channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5352</identifier>
 <datestamp>2013-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5352</id><created>2011-12-22</created><updated>2013-01-21</updated><authors><author><keyname>Malladi</keyname><forenames>Hari Krishna</forenames></author><author><keyname>Dukkipati</keyname><forenames>Ambedkar</forenames></author></authors><title>A Preprocessor Based on Clause Normal Forms and Virtual Substitutions to
  Parallelize Cylindrical Algebraic Decomposition</title><categories>cs.DM</categories><comments>8 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Cylindrical Algebraic Decomposition (CAD) algorithm is a comprehensive
tool to perform quantifier elimination over real closed fields. CAD has doubly
exponential running time, making it infeasible for practical purposes. We
propose to use the notions of clause normal forms and virtual substitutions to
develop a preprocessor for CAD, that will enable an input-level parallelism. We
study the performance of CAD in the presence of the preprocessor by extensive
experimentation. Since parallelizability of CAD depends on the structure of
given prenex formula, we introduce some structural notions to study the
performance of CAD with the proposed preprocessor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5355</identifier>
 <datestamp>2011-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5355</id><created>2011-12-22</created><authors><author><keyname>Zaoui</keyname><forenames>Imane</forenames></author><author><keyname>Chiadmi</keyname><forenames>Dalila</forenames></author><author><keyname>Benhlima</keyname><forenames>Laila</forenames></author></authors><title>2P-Med: Building a Personalization Platform for Mediation Systems</title><categories>cs.IR</categories><comments>In IJEST (International Journal of Engeneering Science and
  Technologies) ISSN: 0975-5462 Vol. 3 No. 5 May 2011, 4488-4497</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nowadays, with the increasing number of integrated data sources, there is a
real trend to personalize mediation systems to improve user satisfaction. To
make these systems user sensitive, we propose a personalization platform called
2P-Med. 2P-Med allows personalizing any mediation system used in any domain
following a cyclic process. The process includes building and managing adequate
user profiles and sources profiles, content and quality matching, source
selection, adapting the mediator responses to user preferences and handling
user feedbacks. In this paper, we describe 2P-Med architecture and highlight
its main functionalities. We also illustrate the operation of the platform
through personalizing source selection in a travel planning assistant.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5359</identifier>
 <datestamp>2011-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5359</id><created>2011-12-22</created><authors><author><keyname>Kelk</keyname><forenames>Steven</forenames></author><author><keyname>van Iersel</keyname><forenames>Leo</forenames></author><author><keyname>Lekic</keyname><forenames>Nela</forenames></author><author><keyname>Linz</keyname><forenames>Simone</forenames></author><author><keyname>Scornavacca</keyname><forenames>Celine</forenames></author><author><keyname>Stougie</keyname><forenames>Leen</forenames></author></authors><title>Cycle killer... qu'est-ce que c'est? On the comparative approximability
  of hybridization number and directed feedback vertex set</title><categories>math.CO cs.DS q-bio.QM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the problem of computing the hybridization number of two rooted
binary phylogenetic trees on the same set of taxa X has a constant factor
polynomial-time approximation if and only if the problem of computing a
minimum-size feedback vertex set in a directed graph (DFVS) has a constant
factor polynomial-time approximation. The latter problem, which asks for a
minimum number of vertices to be removed from a directed graph to transform it
into a directed acyclic graph, is one of the problems in Karp's seminal 1972
list of 21 NP-complete problems. However, despite considerable attention from
the combinatorial optimization community it remains to this day unknown whether
a constant factor polynomial-time approximation exists for DFVS. Our result
thus places the (in)approximability of hybridization number in a much broader
complexity context, and as a consequence we obtain that hybridization number
inherits inapproximability results from the problem Vertex Cover. On the
positive side, we use results from the DFVS literature to give an O(log r log
log r) approximation for hybridization number, where r is the value of an
optimal solution to the hybridization number problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5370</identifier>
 <datestamp>2011-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5370</id><created>2011-12-22</created><authors><author><keyname>Laha</keyname><forenames>Arijit</forenames></author></authors><title>Enhancing Support for Knowledge Works: A relatively unexplored vista of
  computing research</title><categories>cs.AI cs.HC</categories><comments>12 pages</comments><acm-class>I.2.0; I.2.1; H.5.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let us envision a new class of IT systems, the &quot;Support Systems for Knowledge
Works&quot; or SSKW. An SSKW can be defined as a system built for providing
comprehensive support to human knowledge-workers while performing instances of
complex knowledge-works of a particular type within a particular domain of
professional activities To get an idea what an SSKW-enabled work environment
can be like, let us look into a hypothetical scenario that depicts the
interaction between a physician and a patient-care SSKW during the activity of
diagnosing a patient.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5381</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5381</id><created>2011-12-22</created><authors><author><keyname>Fierens</keyname><forenames>Daan</forenames></author></authors><title>Improving the Efficiency of Approximate Inference for Probabilistic
  Logical Models by means of Program Specialization</title><categories>cs.AI</categories><comments>17 pages</comments><acm-class>I.2.2; G.3; D.1.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the task of performing probabilistic inference with probabilistic
logical models. Many algorithms for approximate inference with such models are
based on sampling. From a logic programming perspective, sampling boils down to
repeatedly calling the same queries on a knowledge base composed of a static
part and a dynamic part. The larger the static part, the more redundancy there
is in these repeated calls. This is problematic since inefficient sampling
yields poor approximations.
  We show how to apply logic program specialization to make sampling-based
inference more efficient. We develop an algorithm that specializes the
definitions of the query predicates with respect to the static part of the
knowledge base. In experiments on real-world data we obtain speedups of up to
an order of magnitude, and these speedups grow with the data-size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5396</identifier>
 <datestamp>2012-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5396</id><created>2011-12-22</created><updated>2012-01-08</updated><authors><author><keyname>Alaei</keyname><forenames>Saeed</forenames></author><author><keyname>Hajiaghayi</keyname><forenames>Mohammad T.</forenames></author><author><keyname>Liaghat</keyname><forenames>Vahid</forenames></author><author><keyname>Pei</keyname><forenames>Dan</forenames></author><author><keyname>Saha</keyname><forenames>Barna</forenames></author></authors><title>AdCell: Ad Allocation in Cellular Networks</title><categories>cs.DS</categories><journal-ref>ESA 2011: 311-322</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With more than four billion usage of cellular phones worldwide, mobile
advertising has become an attractive alternative to online advertisements. In
this paper, we propose a new targeted advertising policy for Wireless Service
Providers (WSPs) via SMS or MMS- namely {\em AdCell}. In our model, a WSP
charges the advertisers for showing their ads. Each advertiser has a valuation
for specific types of customers in various times and locations and has a limit
on the maximum available budget. Each query is in the form of time and location
and is associated with one individual customer. In order to achieve a
non-intrusive delivery, only a limited number of ads can be sent to each
customer. Recently, new services have been introduced that offer location-based
advertising over cellular network that fit in our model (e.g., ShopAlerts by
AT&amp;T) .
  We consider both online and offline version of the AdCell problem and develop
approximation algorithms with constant competitive ratio. For the online
version, we assume that the appearances of the queries follow a stochastic
distribution and thus consider a Bayesian setting. Furthermore, queries may
come from different distributions on different times. This model generalizes
several previous advertising models such as online secretary problem
\cite{HKP04}, online bipartite matching \cite{KVV90,FMMM09} and AdWords
\cite{saberi05}. ...
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5404</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5404</id><created>2011-12-22</created><authors><author><keyname>Kar</keyname><forenames>Purushottam</forenames></author><author><keyname>Jain</keyname><forenames>Prateek</forenames></author></authors><title>Similarity-based Learning via Data Driven Embeddings</title><categories>cs.LG stat.ML</categories><comments>To appear in the proceedings of NIPS 2011, 14 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of classification using similarity/distance functions
over data. Specifically, we propose a framework for defining the goodness of a
(dis)similarity function with respect to a given learning task and propose
algorithms that have guaranteed generalization properties when working with
such good functions. Our framework unifies and generalizes the frameworks
proposed by [Balcan-Blum ICML 2006] and [Wang et al ICML 2007]. An attractive
feature of our framework is its adaptability to data - we do not promote a
fixed notion of goodness but rather let data dictate it. We show, by giving
theoretical guarantees that the goodness criterion best suited to a problem can
itself be learned which makes our approach applicable to a variety of domains
and problems. We propose a landmarking-based approach to obtaining a classifier
from such learned goodness criteria. We then provide a novel diversity based
heuristic to perform task-driven selection of landmark points instead of random
selection. We demonstrate the effectiveness of our goodness criteria learning
method as well as the landmark selection heuristic on a variety of
similarity-based learning datasets and benchmark UCI datasets on which our
method consistently outperforms existing approaches by a significant margin.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5407</identifier>
 <datestamp>2013-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5407</id><created>2011-12-22</created><updated>2013-02-11</updated><authors><author><keyname>Xu</keyname><forenames>Yangyang</forenames></author></authors><title>Alternating proximal gradient method for nonnegative matrix
  factorization</title><categories>cs.IT math.IT math.OC</categories><comments>The paper has been withdrawn since an extension of the work has been
  submitted in SIAM imaging analysis</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nonnegative matrix factorization has been widely applied in face recognition,
text mining, as well as spectral analysis. This paper proposes an alternating
proximal gradient method for solving this problem. With a uniformly positive
lower bound assumption on the iterates, any limit point can be proved to
satisfy the first-order optimality conditions. A Nesterov-type extrapolation
technique is then applied to accelerate the algorithm. Though this technique is
at first used for convex program, it turns out to work very well for the
non-convex nonnegative matrix factorization problem. Extensive numerical
experiments illustrate the efficiency of the alternating proximal gradient
method and the accleration technique. Especially for real data tests, the
accelerated method reveals high superiority to state-of-the-art algorithms in
speed with comparable solution qualities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5424</identifier>
 <datestamp>2011-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5424</id><created>2011-12-22</created><authors><author><keyname>Shir</keyname><forenames>Ofer M.</forenames></author><author><keyname>Roslund</keyname><forenames>Jonathan</forenames></author><author><keyname>Leghtas</keyname><forenames>Zaki</forenames></author><author><keyname>Rabitz</keyname><forenames>Herschel</forenames></author></authors><title>Quantum Control Experiments as a Testbed for Evolutionary
  Multi-Objective Algorithms</title><categories>cs.NE math-ph math.MP quant-ph</categories><acm-class>I.2.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Experimental multi-objective Quantum Control is an emerging topic within the
broad physics and chemistry applications domain of controlling quantum
phenomena. This realm offers cutting edge ultrafast laser laboratory
applications, which pose multiple objectives, noise, and possibly constraints
on the high-dimensional search. In this study we introduce the topic of
Multi-Observable Quantum Control (MOQC), and consider specific systems to be
Pareto optimized subject to uncertainty, either experimentally or by means of
simulated systems. The latter include a family of mathematical test-functions
with a practical link to MOQC experiments, which are introduced here for the
first time. We investigate the behavior of the multi-objective version of the
Covariance Matrix Adaptation Evolution Strategy (MO-CMA-ES) and assess its
performance on computer simulations as well as on laboratory closed-loop
experiments. Overall, we propose a comprehensive study on experimental
evolutionary Pareto optimization in high-dimensional continuous domains, draw
some practical conclusions concerning the impact of fitness disturbance on
algorithmic behavior, and raise several theoretical issues in the broad
evolutionary multi-objective context.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5427</identifier>
 <datestamp>2012-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5427</id><created>2011-12-22</created><authors><author><keyname>Pershin</keyname><forenames>Y. V.</forenames></author><author><keyname>Di Ventra</keyname><forenames>M.</forenames></author></authors><title>Teaching Memory Circuit Elements via Experiment-Based Learning</title><categories>physics.ins-det cond-mat.mes-hall cs.ET</categories><comments>IEEE Circuits and Systems Magazine (in press)</comments><journal-ref>IEEE Circuits and Systems Magazine 12(1), 64-74 (2012)</journal-ref><doi>10.1109/MCAS.2011.2181096</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The class of memory circuit elements which comprises memristive,
memcapacitive, and meminductive systems, is gaining considerable attention in a
broad range of disciplines. This is due to the enormous flexibility these
elements provide in solving diverse problems in analog/neuromorphic and
digital/quantum computation; the possibility to use them in an integrated
computing-memory paradigm, massively-parallel solution of different
optimization problems, learning, neural networks, etc. The time is therefore
ripe to introduce these elements to the next generation of physicists and
engineers with appropriate teaching tools that can be easily implemented in
undergraduate teaching laboratories. In this paper, we suggest the use of
easy-to-build emulators to provide a hands-on experience for the students to
learn the fundamental properties and realize several applications of these
memelements. We provide explicit examples of problems that could be tackled
with these emulators that range in difficulty from the demonstration of the
basic properties of memristive, memcapacitive, and meminductive systems to
logic/computation and cross-bar memory. The emulators can be built from
off-the-shelf components, with a total cost of a few tens of dollars, thus
providing a relatively inexpensive platform for the implementation of these
exercises in the classroom. We anticipate that this experiment-based learning
can be easily adopted and expanded by the instructors with many more case
studies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5441</identifier>
 <datestamp>2015-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5441</id><created>2011-12-22</created><authors><author><keyname>Snyder</keyname><forenames>John C.</forenames></author><author><keyname>Rupp</keyname><forenames>Matthias</forenames></author><author><keyname>Hansen</keyname><forenames>Katja</forenames></author><author><keyname>M&#xfc;ller</keyname><forenames>Klaus-Robert</forenames></author><author><keyname>Burke</keyname><forenames>Kieron</forenames></author></authors><title>Finding Density Functionals with Machine Learning</title><categories>physics.comp-ph cs.LG physics.chem-ph stat.ML</categories><comments>4 pages, 4 figures, 1 table. The Supplemental Material is included at
  the end of the manuscript (2 pages, 3 tables)</comments><doi>10.1103/PhysRevLett.108.253002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Machine learning is used to approximate density functionals. For the model
problem of the kinetic energy of non-interacting fermions in 1d, mean absolute
errors below 1 kcal/mol on test densities similar to the training set are
reached with fewer than 100 training densities. A predictor identifies if a
test density is within the interpolation region. Via principal component
analysis, a projected functional derivative finds highly accurate
self-consistent densities. Challenges for application of our method to real
electronic structure problems are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5472</identifier>
 <datestamp>2012-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5472</id><created>2011-12-22</created><updated>2012-02-21</updated><authors><author><keyname>Brodal</keyname><forenames>Gerth St&#xf8;lting</forenames></author><author><keyname>Kejlberg-Rasmussen</keyname><forenames>Casper</forenames></author></authors><title>Cache-Oblivious Implicit Predecessor Dictionaries with the Working Set
  Property</title><categories>cs.DS</categories><comments>An extended abstract is accepted at STACS 2012, this is the full
  version of that paper with the same name &quot;Cache-Oblivious Implicit
  Predecessor Dictionaries with the Working-Set Property&quot;, Symposium on
  Theoretical Aspects of Computer Science 2012</comments><acm-class>E.1</acm-class><doi>10.4230/LIPIcs.STACS.2012.112</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In this paper we present an implicit dynamic dictionary with the working-set
property, supporting insert(e) and delete(e) in O(log n) time, predecessor(e)
in O(log l_{p(e)}) time, successor(e) in O(log l_{s(e)}) time and search(e) in
O(log min(l_{p(e)},l_{e}, l_{s(e)})) time, where n is the number of elements
stored in the dictionary, l_{e} is the number of distinct elements searched for
since element e was last searched for and p(e) and s(e) are the predecessor and
successor of e, respectively. The time-bounds are all worst-case. The
dictionary stores the elements in an array of size n using no additional space.
In the cache-oblivious model the log is base B and the cache-obliviousness is
due to our black box use of an existing cache-oblivious implicit dictionary.
This is the first implicit dictionary supporting predecessor and successor
searches in the working-set bound. Previous implicit structures required O(log
n) time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5485</identifier>
 <datestamp>2012-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5485</id><created>2011-12-22</created><updated>2012-07-22</updated><authors><author><keyname>Gebhardt</keyname><forenames>Volker</forenames></author><author><keyname>Gonz&#xe1;lez-Meneses</keyname><forenames>Juan</forenames></author></authors><title>Generating random braids</title><categories>math.GR cs.DM math.CO</categories><msc-class>20F36 (Primary) 20F10, 05A15, 68W20, 68R05 (Secondary)</msc-class><journal-ref>Journal of Combinatorial Theory, Series A 120 (2013), pp. 111-128</journal-ref><doi>10.1016/j.jcta.2012.07.003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an algorithm to generate positive braids of a given length as
words in Artin generators with a uniform probability. The complexity of this
algorithm is polynomial in the number of strands and in the length of the
generated braids.
  As a byproduct, we describe a finite state automaton accepting the language
of lexicographically minimal representatives of positive braids that has the
minimal possible number of states, and we prove that its number of states is
exponential in the number of strands.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5493</identifier>
 <datestamp>2011-12-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5493</id><created>2011-12-22</created><authors><author><keyname>Scoville</keyname><forenames>John</forenames></author></authors><title>Critical Data Compression</title><categories>cs.IT cs.AI cs.MM math.IT</categories><comments>99 pages, 31 figures</comments><acm-class>I.4.2; I.5.0; I.5.1; I.2.6; I.2.10; H.5.5; E.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new approach to data compression is developed and applied to multimedia
content. This method separates messages into components suitable for both
lossless coding and 'lossy' or statistical coding techniques, compressing
complex objects by separately encoding signals and noise. This is demonstrated
by compressing the most significant bits of data exactly, since they are
typically redundant and compressible, and either fitting a maximally likely
noise function to the residual bits or compressing them using lossy methods.
Upon decompression, the significant bits are decoded and added to a noise
function, whether sampled from a noise model or decompressed from a lossy code.
This results in compressed data similar to the original. For many test images,
a two-part image code using JPEG2000 for lossy coding and PAQ8l for lossless
coding produces less mean-squared error than an equal length of JPEG2000.
Computer-generated images typically compress better using this method than
through direct lossy coding, as do many black and white photographs and most
color photographs at sufficiently high quality levels. Examples applying the
method to audio and video coding are also demonstrated. Since two-part codes
are efficient for both periodic and chaotic data, concatenations of roughly
similar objects may be encoded efficiently, which leads to improved inference.
Applications to artificial intelligence are demonstrated, showing that signals
using an economical lossless code have a critical level of redundancy which
leads to better description-based inference than signals which encode either
insufficient data or too much detail.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5505</identifier>
 <datestamp>2013-01-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5505</id><created>2011-12-22</created><updated>2013-01-17</updated><authors><author><keyname>Rizvandi</keyname><forenames>Nikzad Babaii</forenames></author><author><keyname>Taheri</keyname><forenames>Javid</forenames></author><author><keyname>Zomaya</keyname><forenames>Albert Y.</forenames></author><author><keyname>Moraveji</keyname><forenames>Reza</forenames></author></authors><title>A Study on Using Uncertain Time Series Matching Algorithms in MapReduce
  Applications</title><categories>cs.DC cs.AI cs.LG cs.PF</categories><comments>12 pages a version has been accepted to journal of &quot;Concurrency and
  Computation: Practice and Experience&quot;, available online from the University
  of Sydney at http://www.nicta.com.au/pub?doc=4744</comments><report-no>TR672- University of Sydney</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study CPU utilization time patterns of several Map-Reduce
applications. After extracting running patterns of several applications, the
patterns with their statistical information are saved in a reference database
to be later used to tweak system parameters to efficiently execute unknown
applications in future. To achieve this goal, CPU utilization patterns of new
applications along with its statistical information are compared with the
already known ones in the reference database to find/predict their most
probable execution patterns. Because of different patterns lengths, the Dynamic
Time Warping (DTW) is utilized for such comparison; a statistical analysis is
then applied to DTWs' outcomes to select the most suitable candidates.
Moreover, under a hypothesis, another algorithm is proposed to classify
applications under similar CPU utilization patterns. Three widely used text
processing applications (WordCount, Distributed Grep, and Terasort) and another
application (Exim Mainlog parsing) are used to evaluate our hypothesis in
tweaking system parameters in executing similar applications. Results were very
promising and showed effectiveness of our approach on 5-node Map-Reduce
platform
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5507</identifier>
 <datestamp>2014-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5507</id><created>2011-12-22</created><updated>2014-09-13</updated><authors><author><keyname>Vogelstein</keyname><forenames>Joshua T.</forenames></author><author><keyname>Conroy</keyname><forenames>John M.</forenames></author><author><keyname>Lyzinski</keyname><forenames>Vince</forenames></author><author><keyname>Podrazik</keyname><forenames>Louis J.</forenames></author><author><keyname>Kratzer</keyname><forenames>Steven G.</forenames></author><author><keyname>Harley</keyname><forenames>Eric T.</forenames></author><author><keyname>Fishkind</keyname><forenames>Donniell E.</forenames></author><author><keyname>Vogelstein</keyname><forenames>R. Jacob</forenames></author><author><keyname>Priebe</keyname><forenames>Carey E.</forenames></author></authors><title>Fast Approximate Quadratic Programming for Large (Brain) Graph Matching</title><categories>math.OC cs.DS q-bio.NC</categories><comments>17 pages, 5 figures, 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quadratic assignment problems (QAPs) arise in a wide variety of domains,
ranging from operations research to graph theory to computer vision to
neuroscience. In the age of big data, graph valued data is becoming more
prominent, and with it, a desire to run algorithms on ever larger graphs.
Because QAP is NP-hard, exact algorithms are intractable. Approximate
algorithms necessarily employ an accuracy/efficiency trade-off. We developed a
fast approximate quadratic assignment algorithm (FAQ). FAQ finds a local optima
in (worst case) time cubic in the number of vertices, similar to other
approximate QAP algorithms. We demonstrate empirically that our algorithm is
faster and achieves a lower objective value on over 80% of the suite of QAP
benchmarks, compared with the previous state-of-the-art. Applying the
algorithms to our motivating example, matching C. elegans connectomes
(brain-graphs), we find that FAQ achieves the optimal performance in record
time, whereas none of the others even find the optimum.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5508</identifier>
 <datestamp>2014-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5508</id><created>2011-12-22</created><updated>2014-10-27</updated><authors><author><keyname>Chakrabarty</keyname><forenames>Deeparnab</forenames></author><author><keyname>Kannan</keyname><forenames>Sampath</forenames></author><author><keyname>Tian</keyname><forenames>Kevin</forenames></author></authors><title>Variance on the Leaves of a Tree Markov Random Field: Detecting
  Character Dependencies in Phylogenies</title><categories>q-bio.PE cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Stochastic models of evolution (Markov random fields on trivalent trees)
generally assume that different characters (different runs of the stochastic
process) are independent and identically distributed. In this paper we take the
first steps towards addressing dependent characters. Specifically we show that,
under certain technical assumptions regarding the evolution of individual
characters, we can detect any significant, history independent, correlation
between any pair of multistate characters. For the special case of the
Cavender-Farris-Neyman (CFN) model on two states with symmetric transition
matrices, our analysis needs milder assumptions. To perform the analysis, we
need to prove a new concentration result for multistate random variables of a
Markov random field on arbitrary trivalent trees: we show that the random
variable counting the number of leaves in any particular subset of states has
variance that is subquadratic in the number of leaves.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5524</identifier>
 <datestamp>2014-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5524</id><created>2011-12-23</created><updated>2014-06-12</updated><authors><author><keyname>Dujmovi&#x107;</keyname><forenames>Vida</forenames></author><author><keyname>Joret</keyname><forenames>Gwena&#xeb;l</forenames></author><author><keyname>Kozik</keyname><forenames>Jakub</forenames></author><author><keyname>Wood</keyname><forenames>David R.</forenames></author></authors><title>Nonrepetitive Colouring via Entropy Compression</title><categories>math.CO cs.DM</categories><comments>v4: Minor changes made following helpful comments by the referees</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A vertex colouring of a graph is \emph{nonrepetitive} if there is no path
whose first half receives the same sequence of colours as the second half. A
graph is nonrepetitively $k$-choosable if given lists of at least $k$ colours
at each vertex, there is a nonrepetitive colouring such that each vertex is
coloured from its own list. It is known that every graph with maximum degree
$\Delta$ is $c\Delta^2$-choosable, for some constant $c$. We prove this result
with $c=1$ (ignoring lower order terms). We then prove that every subdivision
of a graph with sufficiently many division vertices per edge is nonrepetitively
5-choosable. The proofs of both these results are based on the Moser-Tardos
entropy-compression method, and a recent extension by Grytczuk, Kozik and Micek
for the nonrepetitive choosability of paths. Finally, we prove that every graph
with pathwidth $k$ is nonrepetitively $O(k^{2})$-colourable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5534</identifier>
 <datestamp>2015-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5534</id><created>2011-12-23</created><authors><author><keyname>Wang</keyname><forenames>Yubo</forenames></author><author><keyname>Xiao</keyname><forenames>Gaoxi</forenames></author><author><keyname>Liu</keyname><forenames>Jian</forenames></author></authors><title>Dynamics of competing ideas in complex social systems</title><categories>physics.soc-ph cs.SI math.DS</categories><comments>23 pages, 13 figures, accepted for publication in New Journal of
  Physics</comments><doi>10.1088/1367-2630/14/1/013015</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Individuals accepting an idea may intentionally or unintentionally impose
influences in a certain neighborhood area, making other individuals within the
area less likely or even impossible to accept other competing ideas. Depending
on whether such influences strictly prohibit neighborhood individuals from
accepting other ideas or not, we classify them into exclusive and non-exclusive
influences, respectively. Our study reveals for the first time the rich and
complex dynamics of two competing ideas with neighborhood influences in
scale-free social networks: depending on whether they have exclusive or
non-exclusive influences, the final state varies from multiple coexistence to
founder control to exclusion, with different sizes of population accepting each
of the ideas respectively. Such results provide insights helpful for better
understanding the spread (and the control of spread) of ideas in human society.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5557</identifier>
 <datestamp>2012-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5557</id><created>2011-12-23</created><updated>2012-11-21</updated><authors><author><keyname>Vaze</keyname><forenames>Rahul</forenames></author></authors><title>Competitive Ratio Analysis of Online Algorithms to Minimize Data
  Transmission Time in Energy Harvesting Communication System</title><categories>cs.IT math.IT</categories><comments>accepted for publication in IEEE INFOCOM 2013 to be held in Turin,
  Italy, Apr 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the optimal online packet scheduling problem in a single-user
energy harvesting wireless communication system, where energy is harvested from
natural renewable sources, making future energy arrivals instants and amounts
random in nature. The most general case of arbitrary energy arrivals is
considered where neither the future energy arrival instants or amount, nor
their distribution is known. The problem considered is to adaptively change the
transmission rate according to the causal energy arrival information, such that
the time by which all packets are delivered is minimized. We assume that all
bits have arrived and are ready at the source before the transmission begins.
For a minimization problem, the utility of an online algorithm is tested by
finding its competitive ratio or competitiveness that is defined to be the
maximum of the ratio of the gain of the online algorithm with the optimal
offline algorithm over all input sequences. We derive a lower and upper bound
on the competitive ratio of any online algorithm to minimize the total
transmission time in an energy harvesting system. The upper bound is obtained
using a `lazy' transmission policy that chooses its transmission power to
minimize the transmission time assuming that no further energy arrivals are
going to occur in future. The lazy transmission policy is shown to be strictly
two-competitive. We also derive an adversarial lower bound that shows that
competitive ratio of any online algorithm is at least 1.325.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5588</identifier>
 <datestamp>2013-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5588</id><created>2011-12-23</created><updated>2012-02-29</updated><authors><author><keyname>Kreutzer</keyname><forenames>Moritz</forenames></author><author><keyname>Hager</keyname><forenames>Georg</forenames></author><author><keyname>Wellein</keyname><forenames>Gerhard</forenames></author><author><keyname>Fehske</keyname><forenames>Holger</forenames></author><author><keyname>Basermann</keyname><forenames>Achim</forenames></author><author><keyname>Bishop</keyname><forenames>Alan R.</forenames></author></authors><title>Sparse matrix-vector multiplication on GPGPU clusters: A new storage
  format and a scalable implementation</title><categories>cs.DC cs.MS cs.NA cs.PF</categories><comments>10 pages, 5 figures. Added reference to other recent sparse matrix
  formats</comments><doi>10.1109/IPDPSW.2012.211</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sparse matrix-vector multiplication (spMVM) is the dominant operation in many
sparse solvers. We investigate performance properties of spMVM with matrices of
various sparsity patterns on the nVidia &quot;Fermi&quot; class of GPGPUs. A new &quot;padded
jagged diagonals storage&quot; (pJDS) format is proposed which may substantially
reduce the memory overhead intrinsic to the widespread ELLPACK-R scheme. In our
test scenarios the pJDS format cuts the overall spMVM memory footprint on the
GPGPU by up to 70%, and achieves 95% to 130% of the ELLPACK-R performance.
Using a suitable performance model we identify performance bottlenecks on the
node level that invalidate some types of matrix structures for efficient
multi-GPGPU parallelization. For appropriate sparsity patterns we extend
previous work on distributed-memory parallel spMVM to demonstrate a scalable
hybrid MPI-GPGPU code, achieving efficient overlap of communication and
computation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5594</identifier>
 <datestamp>2011-12-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5594</id><created>2011-12-23</created><authors><author><keyname>Farivar</keyname><forenames>Masoud</forenames></author><author><keyname>Neal</keyname><forenames>Russell</forenames></author><author><keyname>Clarke</keyname><forenames>Christopher</forenames></author><author><keyname>Low</keyname><forenames>Steven</forenames></author></authors><title>Optimal Inverter VAR Control in Distribution Systems with High PV
  Penetration</title><categories>cs.ET</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The intent of the study detailed in this paper is to demonstrate the benefits
of inverter var control on a fast timescale to mitigate rapid and large voltage
fluctuations due to the high penetration of photovoltaic generation and the
resulting reverse power flow. Our approach is to formulate the volt/var control
as a radial optimal power flow (OPF) problem to minimize line losses and energy
consumption, subject to constraints on voltage magnitudes. An efficient
solution to the radial OPF problem is presented and used to study the structure
of optimal inverter var injection and the net benefits, taking into account the
additional cost of inverter losses when operating at non-unity power factor.
This paper will illustrate how, depending on the circuit topology and its
loading condition, the inverter's optimal reactive power injection is not
necessarily monotone with respect to their real power output. The results are
demonstrated on a distribution feeder on the Southern California Edison system
that has a very light load and a 5 MW photovoltaic (PV) system installed away
from the substation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5605</identifier>
 <datestamp>2011-12-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5605</id><created>2011-12-23</created><authors><author><keyname>Banday</keyname><forenames>M. Tariq</forenames></author><author><keyname>Shah</keyname><forenames>N. A.</forenames></author></authors><title>A Study of CAPTCHAs for Securing Web Services</title><categories>cs.CR cs.CY</categories><comments>9 Pages</comments><acm-class>K.6.5; D.4.6; K.4.2</acm-class><journal-ref>Banday, M.T., Shah, N.A. (2009). &quot;A Study of CAPTCHAs for Securing
  Web Services,&quot; IJSDIA International Journal of Secure Digital Information
  Age, ISSN: 0975-1823, 1(2), pp. 66-74, available online at:
  http://ijsdia.org/main/?page_id=6</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Atomizing various Web activities by replacing human to human interactions on
the Internet has been made indispensable due to its enormous growth. However,
bots also known as Web-bots which have a malicious intend and pretending to be
humans pose a severe threat to various services on the Internet that implicitly
assume a human interaction. Accordingly, Web service providers before allowing
access to such services use various Human Interaction Proof's (HIPs) to
authenticate that the user is a human and not a bot. Completely Automated
Public Turing test to tell Computers and Humans Apart (CAPTCHA) is a class of
HIPs tests and are based on Artificial Intelligence. These tests are easier for
humans to qualify and tough for bots to simulate. Several Web services use
CAPTCHAs as a defensive mechanism against automated Web-bots. In this paper, we
review the existing CAPTCHA schemes that have been proposed or are being used
to protect various Web services. We classify them in groups and compare them
with each other in terms of security and usability. We present general method
used to generate and break text-based and image-based CAPTCHAs. Further, we
discuss various security and usability issues in CAPTCHA design and provide
guidelines for improving their robustness and usability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5608</identifier>
 <datestamp>2011-12-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5608</id><created>2011-12-23</created><authors><author><keyname>Banday</keyname><forenames>M. Tariq</forenames></author><author><keyname>Qadri</keyname><forenames>Jameel A.</forenames></author><author><keyname>Jan</keyname><forenames>Tariq. R.</forenames></author><author><keyname>Shah</keyname><forenames>Nisar. A.</forenames></author></authors><title>Detecting Threat E-mails using Bayesian Approach</title><categories>cs.CR</categories><comments>10 Pages</comments><acm-class>K.6.5; D.4.6; K.4.2</acm-class><journal-ref>Banday, M.T., Qadri, J.A., Jan, T.R. and Shah, N.A. (2009).
  &quot;Detecting Threat E-mails using Bayesian Approach,&quot; International Journal of
  Secure Digital Information Age, ISSN: 0975-1823, 1(2), pp. 103-113</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fraud and terrorism have a close connect in terms of the processes that
enables and promote them. In the era of Internet, its various services that
include Web, e-mail, social networks, blogs, instant messaging, chats, etc. are
used in terrorism not only for communication but also for i) creation of
ideology, ii) resource gathering, iii) recruitment, indoctrination and
training, iv) creation of terror network, and v) information gathering. A major
challenge for law enforcement and intelligence agencies is efficient and
accurate gathering of relevant and growing volume of crime data. This paper
reports on use of established Na\&quot;ive Bayesian filter for classification of
threat e-mails. Efficiency in filtering threat e-mail by use of three different
Na\&quot;ive Bayesian filter approaches i.e. single keywords, weighted multiple
keywords and weighted multiple keywords with keyword context matching are
evaluated on a threat e-mail corpus created by extracting data from sources
that are very close to terrorism.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5621</identifier>
 <datestamp>2011-12-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5621</id><created>2011-12-23</created><authors><author><keyname>Banday</keyname><forenames>M. Tariq</forenames></author><author><keyname>Qadri</keyname><forenames>Jameel A.</forenames></author></authors><title>SPAM -- Technological and Legal Aspects</title><categories>cs.CR</categories><acm-class>K.6.5; K.4.4; D.4.6; K.4.2</acm-class><journal-ref>Banday, M.T., Qadri, J.A. (2006). &quot;SPAM - Technological and Legal
  Aspects,&quot; Kashmir University Law Review (KULR), ISSN: 0975-6639, XIII (XIII),
  pp. 231-264</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper an attempt is made to review technological, economical and
legal aspects of the spam in detail. The technical details will include
different techniques of spam control e.g., filtering techniques, Genetic
Algorithm, Memory Based Classifier, Support Vector Machine Method, etc. The
economic aspect includes Shaping/Rate Throttling Approach/Economic Filtering
and Pricing/Payment based spam control. Finally, the paper discusses the legal
provisions for the control of spam. The scope of the legal options is limited
to USA, European Union, New Zealand, Canada, Britain and Australia.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5625</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5625</id><created>2011-12-23</created><updated>2012-02-16</updated><authors><author><keyname>Gon&#xe7;alves</keyname><forenames>Wesley Nunes</forenames></author><author><keyname>Martinez</keyname><forenames>Alexandre Souto</forenames></author><author><keyname>Bruno</keyname><forenames>Odemir Martinez</forenames></author></authors><title>Complex network classification using partially self-avoiding
  deterministic walks</title><categories>physics.data-an cs.SI physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Complex networks have attracted increasing interest from various fields of
science. It has been demonstrated that each complex network model presents
specific topological structures which characterize its connectivity and
dynamics. Complex network classification rely on the use of representative
measurements that model topological structures. Although there are a large
number of measurements, most of them are correlated. To overcome this
limitation, this paper presents a new measurement for complex network
classification based on partially self-avoiding walks. We validate the
measurement on a data set composed by 40.000 complex networks of four
well-known models. Our results indicate that the proposed measurement improves
correct classification of networks compared to the traditional ones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5627</identifier>
 <datestamp>2011-12-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5627</id><created>2011-12-23</created><authors><author><keyname>Balakrishnan</keyname><forenames>Sivaraman</forenames></author><author><keyname>Rinaldo</keyname><forenames>Alessandro</forenames></author><author><keyname>Sheehy</keyname><forenames>Don</forenames></author><author><keyname>Singh</keyname><forenames>Aarti</forenames></author><author><keyname>Wasserman</keyname><forenames>Larry</forenames></author></authors><title>Minimax Rates for Homology Inference</title><categories>stat.ML cs.LG</categories><comments>16 pages, 4 figures. Artificial Intelligence and Statistics, AISTATS
  2012, Accepted as oral presentation</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Often, high dimensional data lie close to a low-dimensional submanifold and
it is of interest to understand the geometry of these submanifolds. The
homology groups of a manifold are important topological invariants that provide
an algebraic summary of the manifold. These groups contain rich topological
information, for instance, about the connected components, holes, tunnels and
sometimes the dimension of the manifold. In this paper, we consider the
statistical problem of estimating the homology of a manifold from noisy samples
under several different noise models. We derive upper and lower bounds on the
minimax risk for this problem. Our upper bounds are based on estimators which
are constructed from a union of balls of appropriate radius around carefully
selected points. In each case we establish complementary lower bounds using Le
Cam's lemma.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5629</identifier>
 <datestamp>2011-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5629</id><created>2011-12-23</created><updated>2011-12-27</updated><authors><author><keyname>Eriksson</keyname><forenames>Brian</forenames></author><author><keyname>Balzano</keyname><forenames>Laura</forenames></author><author><keyname>Nowak</keyname><forenames>Robert</forenames></author></authors><title>High-Rank Matrix Completion and Subspace Clustering with Missing Data</title><categories>cs.IT cs.LG math.IT stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the problem of completing a matrix with many missing
entries under the assumption that the columns of the matrix belong to a union
of multiple low-rank subspaces. This generalizes the standard low-rank matrix
completion problem to situations in which the matrix rank can be quite high or
even full rank. Since the columns belong to a union of subspaces, this problem
may also be viewed as a missing-data version of the subspace clustering
problem. Let X be an n x N matrix whose (complete) columns lie in a union of at
most k subspaces, each of rank &lt;= r &lt; n, and assume N &gt;&gt; kn. The main result of
the paper shows that under mild assumptions each column of X can be perfectly
recovered with high probability from an incomplete version so long as at least
CrNlog^2(n) entries of X are observed uniformly at random, with C&gt;1 a constant
depending on the usual incoherence conditions, the geometrical arrangement of
subspaces, and the distribution of columns over the subspaces. The result is
illustrated with numerical experiments and an application to Internet distance
matrix completion and topology identification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5630</identifier>
 <datestamp>2011-12-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5630</id><created>2011-12-23</created><authors><author><keyname>Wang</keyname><forenames>Ye</forenames></author><author><keyname>Rane</keyname><forenames>Shantanu</forenames></author><author><keyname>Draper</keyname><forenames>Stark C.</forenames></author><author><keyname>Ishwar</keyname><forenames>Prakash</forenames></author></authors><title>A Theoretical Analysis of Authentication, Privacy and Reusability Across
  Secure Biometric Systems</title><categories>cs.IT cs.CR math.IT</categories><comments>15 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a theoretical framework for the analysis of privacy and security
tradeoffs in secure biometric authentication systems. We use this framework to
conduct a comparative information-theoretic analysis of two biometric systems
that are based on linear error correction codes, namely fuzzy commitment and
secure sketches. We derive upper bounds for the probability of false rejection
($P_{FR}$) and false acceptance ($P_{FA}$) for these systems. We use mutual
information to quantify the information leaked about a user's biometric
identity, in the scenario where one or multiple biometric enrollments of the
user are fully or partially compromised. We also quantify the probability of
successful attack ($P_{SA}$) based on the compromised information. Our analysis
reveals that fuzzy commitment and secure sketch systems have identical $P_{FR},
P_{FA}, P_{SA}$ and information leakage, but secure sketch systems have lower
storage requirements. We analyze both single-factor (keyless) and two-factor
(key-based) variants of secure biometrics, and consider the most general
scenarios in which a single user may provide noisy biometric enrollments at
several access control devices, some of which may be subsequently compromised
by an attacker. Our analysis highlights the revocability and reusability
properties of key-based systems and exposes a subtle design tradeoff between
reducing information leakage from compromised systems and preventing successful
attacks on systems whose data have not been compromised.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5636</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5636</id><created>2011-12-23</created><authors><author><keyname>Bul&#xe1;nek</keyname><forenames>Jan</forenames></author><author><keyname>Kouck&#xfd;</keyname><forenames>Michal</forenames></author><author><keyname>Saks</keyname><forenames>Michael</forenames></author></authors><title>Tight lower bounds for online labeling problem</title><categories>cs.DS</categories><comments>24 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the file maintenance problem (also called the online labeling
problem) in which n integer items from the set {1,...,r} are to be stored in an
array of size m &gt;= n. The items are presented sequentially in an arbitrary
order, and must be stored in the array in sorted order (but not necessarily in
consecutive locations in the array). Each new item must be stored in the array
before the next item is received. If r&lt;=m then we can simply store item j in
location j but if r&gt;m then we may have to shift the location of stored items to
make space for a newly arrived item. The algorithm is charged each time an item
is stored in the array, or moved to a new location. The goal is to minimize the
total number of such moves done by the algorithm. This problem is non-trivial
when n=&lt;m&lt;r.
  In the case that m=Cn for some C&gt;1, algorithms for this problem with cost
O(log(n)^2) per item have been given [IKR81, Wil92, BCD+02]. When m=n,
algorithms with cost O(log(n)^3) per item were given [Zha93, BS07]. In this
paper we prove lower bounds that show that these algorithms are optimal, up to
constant factors. Previously, the only lower bound known for this range of
parameters was a lower bound of \Omega(log(n)^2) for the restricted class of
smooth algorithms [DSZ05a, Zha93].
  We also provide an algorithm for the sparse case: If the number of items is
polylogarithmic in the array size then the problem can be solved in amortized
constant time per item.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5638</identifier>
 <datestamp>2011-12-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5638</id><created>2011-12-23</created><authors><author><keyname>Vural</keyname><forenames>Elif</forenames></author><author><keyname>Frossard</keyname><forenames>Pascal</forenames></author></authors><title>Discretization of Parametrizable Signal Manifolds</title><categories>cs.CV</categories><journal-ref>IEEE Transactions on Image Processing, vol. 20, no. 12, Dec. 2011</journal-ref><doi>10.1109/TIP.2011.2155077</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Transformation-invariant analysis of signals often requires the computation
of the distance from a test pattern to a transformation manifold. In
particular, the estimation of the distances between a transformed query signal
and several transformation manifolds representing different classes provides
essential information for the classification of the signal. In many
applications the computation of the exact distance to the manifold is costly,
whereas an efficient practical solution is the approximation of the manifold
distance with the aid of a manifold grid. In this paper, we consider a setting
with transformation manifolds of known parameterization. We first present an
algorithm for the selection of samples from a single manifold that permits to
minimize the average error in the manifold distance estimation. Then we propose
a method for the joint discretization of multiple manifolds that represent
different signal classes, where we optimize the transformation-invariant
classification accuracy yielded by the discrete manifold representation.
Experimental results show that sampling each manifold individually by
minimizing the manifold distance estimation error outperforms baseline sampling
solutions with respect to registration and classification accuracy. Performing
an additional joint optimization on all samples improves the classification
performance further. Moreover, given a fixed total number of samples to be
selected from all manifolds, an asymmetric distribution of samples to different
manifolds depending on their geometric structures may also increase the
classification accuracy in comparison with the equal distribution of samples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5640</identifier>
 <datestamp>2013-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5640</id><created>2011-12-23</created><updated>2012-10-30</updated><authors><author><keyname>Vural</keyname><forenames>Elif</forenames></author><author><keyname>Frossard</keyname><forenames>Pascal</forenames></author></authors><title>Learning Smooth Pattern Transformation Manifolds</title><categories>cs.CV</categories><journal-ref>IEEE Transactions on Image Processing, vol. 22, no. 4, pp.
  1311-1325, 2013</journal-ref><doi>10.1109/TIP.2012.2227768</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Manifold models provide low-dimensional representations that are useful for
processing and analyzing data in a transformation-invariant way. In this paper,
we study the problem of learning smooth pattern transformation manifolds from
image sets that represent observations of geometrically transformed signals. In
order to construct a manifold, we build a representative pattern whose
transformations accurately fit various input images. We examine two objectives
of the manifold building problem, namely, approximation and classification. For
the approximation problem, we propose a greedy method that constructs a
representative pattern by selecting analytic atoms from a continuous dictionary
manifold. We present a DC (Difference-of-Convex) optimization scheme that is
applicable to a wide range of transformation and dictionary models, and
demonstrate its application to transformation manifolds generated by rotation,
translation and anisotropic scaling of a reference pattern. Then, we generalize
this approach to a setting with multiple transformation manifolds, where each
manifold represents a different class of signals. We present an iterative
multiple manifold building algorithm such that the classification accuracy is
promoted in the learning of the representative patterns. Experimental results
suggest that the proposed methods yield high accuracy in the approximation and
classification of data compared to some reference methods, while the invariance
to geometric transformations is achieved due to the transformation manifold
model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5659</identifier>
 <datestamp>2011-12-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5659</id><created>2011-12-23</created><authors><author><keyname>Daskalakis</keyname><forenames>Constantinos</forenames></author><author><keyname>Diakonikolas</keyname><forenames>Ilias</forenames></author><author><keyname>Servedio</keyname><forenames>Rocco A.</forenames></author><author><keyname>Valiant</keyname><forenames>Gregory</forenames></author><author><keyname>Valiant</keyname><forenames>Paul</forenames></author></authors><title>Testing $k$-Modal Distributions: Optimal Algorithms via Reductions</title><categories>cs.DS math.PR math.ST stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give highly efficient algorithms, and almost matching lower bounds, for a
range of basic statistical problems that involve testing and estimating the L_1
distance between two k-modal distributions $p$ and $q$ over the discrete domain
$\{1,\dots,n\}$. More precisely, we consider the following four problems: given
sample access to an unknown k-modal distribution $p$,
  Testing identity to a known or unknown distribution:
  1. Determine whether $p = q$ (for an explicitly given k-modal distribution
$q$) versus $p$ is $\eps$-far from $q$;
  2. Determine whether $p=q$ (where $q$ is available via sample access) versus
$p$ is $\eps$-far from $q$;
  Estimating $L_1$ distance (&quot;tolerant testing'') against a known or unknown
distribution:
  3. Approximate $d_{TV}(p,q)$ to within additive $\eps$ where $q$ is an
explicitly given k-modal distribution $q$;
  4. Approximate $d_{TV}(p,q)$ to within additive $\eps$ where $q$ is available
via sample access.
  For each of these four problems we give sub-logarithmic sample algorithms,
that we show are tight up to additive $\poly(k)$ and multiplicative
$\polylog\log n+\polylog k$ factors. Thus our bounds significantly improve the
previous results of \cite{BKR:04}, which were for testing identity of
distributions (items (1) and (2) above) in the special cases k=0 (monotone
distributions) and k=1 (unimodal distributions) and required $O((\log n)^3)$
samples.
  As our main conceptual contribution, we introduce a new reduction-based
approach for distribution-testing problems that lets us obtain all the above
results in a unified way. Roughly speaking, this approach enables us to
transform various distribution testing problems for k-modal distributions over
$\{1,\dots,n\}$ to the corresponding distribution testing problems for
unrestricted distributions over a much smaller domain $\{1,\dots,\ell\}$ where
$\ell = O(k \log n).$
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5670</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5670</id><created>2011-12-23</created><authors><author><keyname>Botchev</keyname><forenames>Mike A.</forenames></author></authors><title>Residual, restarting and Richardson iteration for the matrix
  exponential, revised</title><categories>math.NA cs.CE physics.comp-ph</categories><comments>24 pages</comments><msc-class>65F60, 65F10, 65F30, 65N22, 65L05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A well-known problem in computing some matrix functions iteratively is the
lack of a clear, commonly accepted residual notion. An important matrix
function for which this is the case is the matrix exponential. Suppose the
matrix exponential of a given matrix times a given vector has to be computed.
We develop the approach of Druskin, Greenbaum and Knizhnerman (1998) and
interpret the sought-after vector as the value of a vector function satisfying
the linear system of ordinary differential equations (ODE) whose coefficients
form the given matrix. The residual is then defined with respect to the
initial-value problem for this ODE system. The residual introduced in this way
can be seen as a backward error. We show how the residual can be computed
efficiently within several iterative methods for the matrix exponential. This
completely resolves the question of reliable stopping criteria for these
methods. Further, we show that the residual concept can be used to construct
new residual-based iterative methods. In particular, a variant of the
Richardson method for the new residual appears to provide an efficient way to
restart Krylov subspace methods for evaluating the matrix exponential.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5671</identifier>
 <datestamp>2011-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5671</id><created>2011-12-23</created><authors><author><keyname>Strej&#x10d;ek</keyname><forenames>Jan</forenames></author><author><keyname>Trt&#xed;k</keyname><forenames>Marek</forenames></author></authors><title>Abstracting Path Conditions</title><categories>cs.SC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a symbolic-execution-based algorithm that for a given program and
a given program location produces a nontrivial necessary condition on input
values to drive the program execution to the given location. We also propose an
application of necessary conditions in contemporary bug-finding and
test-generation tools. Experimental results show that the presented technique
can significantly improve performance of the tools.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5679</identifier>
 <datestamp>2011-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5679</id><created>2011-12-23</created><authors><author><keyname>Khan</keyname><forenames>Muhammad Fahad</forenames></author><author><keyname>Beg</keyname><forenames>Saira</forenames></author></authors><title>Transferring Voice using SMS over GSM Network</title><categories>cs.NI</categories><comments>3 pages, 3 figures, 1 Table, International Journal,
  http://www.journalofcomputing.org/volume-3-issue-4-april-2011</comments><journal-ref>International journal of computing ISSN 2151-9617 Volume 3, Issue
  4, April 2011</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The paper presents a methodology of transmitting voice in SMS (Short Message
Service) over GSM network. Usually SMS contents are text based and limited to
140 bytes. It supports national and international roaming, but also supported
by other telecommunication such as TDMA (Time Division Multiple Access), CDMA
(Code Division Multiple Access) as well. It can sent/ receive simultaneously
with other services. Such features make it favorable for this methodology. For
this an application is developed using J2ME platform which is supported by all
mobile phones in the world. This algorithm's test is conducted on N95 having
Symbian Operating System (OS).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5683</identifier>
 <datestamp>2012-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5683</id><created>2011-12-23</created><authors><author><keyname>Yang</keyname><forenames>Zimo</forenames></author><author><keyname>Zhou</keyname><forenames>Tao</forenames></author></authors><title>Epidemic Spreading in Weighted Networks: An Edge-Based Mean-Field
  Solution</title><categories>physics.soc-ph cs.SI physics.data-an</categories><comments>7 pages, 5 figures</comments><journal-ref>Physical Review E 85 (2012) 056106</journal-ref><doi>10.1103/PhysRevE.85.056106</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Weight distribution largely impacts the epidemic spreading taking place on
top of networks. This paper studies a susceptible-infected-susceptible model on
regular random networks with different kinds of weight distributions.
Simulation results show that the more homogeneous weight distribution leads to
higher epidemic prevalence, which, unfortunately, could not be captured by the
traditional mean-field approximation. This paper gives an edge-based mean-field
solution for general weight distribution, which can quantitatively reproduce
the simulation results. This method could find its applications in
characterizing the non-equilibrium steady states of dynamical processes on
weighted networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5703</identifier>
 <datestamp>2011-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5703</id><created>2011-12-24</created><authors><author><keyname>Pandey</keyname><forenames>Kavita</forenames></author><author><keyname>Swaroop</keyname><forenames>Abhishek</forenames></author></authors><title>A Comprehensive Performance Analysis of Proactive, Reactive and Hybrid
  MANETs Routing Protocols</title><categories>cs.NI</categories><journal-ref>IJCSI Volume 8, Issue 6, November 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A mobile Ad-hoc network (MANET) is a dynamic multi hop wireless network
established by a group of nodes in which there is no central administration.
Due to mobility of nodes and dynamic network topology, the routing is one of
the most important challenges in ad-hoc networks. Several routing algorithms
for MANETs have been proposed by the researchers which have been classified
into various categories, however, the most prominent categories are proactive,
reactive and hybrid. The performance comparison of routing protocols for MANETs
has been presented by other researcher also, however, none of these works
considers proactive, reactive and hybrid protocols together. In this paper, the
performance of proactive (DSDV), reactive (DSR and AODV) and hybrid (ZRP)
routing protocols has been compared. The performance differentials are analyzed
on the basis of throughput, average delay, routing overhead and number of
packets dropped with a variation of number of nodes, pause time and mobility.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5716</identifier>
 <datestamp>2015-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5716</id><created>2011-12-24</created><authors><author><keyname>Chouvardas</keyname><forenames>Symeon</forenames></author><author><keyname>Slavakis</keyname><forenames>Konstantinos</forenames></author><author><keyname>Kopsinis</keyname><forenames>Yannis</forenames></author><author><keyname>Theodoridis</keyname><forenames>Sergios</forenames></author></authors><title>A Sparsity-Aware Adaptive Algorithm for Distributed Learning</title><categories>cs.IT math.IT</categories><doi>10.1109/TSP.2012.2204987</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a sparsity-aware adaptive algorithm for distributed learning
in diffusion networks is developed. The algorithm follows the set-theoretic
estimation rationale. At each time instance and at each node of the network, a
closed convex set, known as property set, is constructed based on the received
measurements; this defines the region in which the solution is searched for. In
this paper, the property sets take the form of hyperslabs. The goal is to find
a point that belongs to the intersection of these hyperslabs. To this end,
sparsity encouraging variable metric projections onto the hyperslabs have been
adopted. Moreover, sparsity is also imposed by employing variable metric
projections onto weighted $\ell_1$ balls. A combine adapt cooperation strategy
is adopted. Under some mild assumptions, the scheme enjoys monotonicity,
asymptotic optimality and strong convergence to a point that lies in the
consensus subspace. Finally, numerical examples verify the validity of the
proposed scheme, compared to other algorithms, which have been developed in the
context of sparse adaptive learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5717</identifier>
 <datestamp>2012-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5717</id><created>2011-12-24</created><updated>2012-01-09</updated><authors><author><keyname>Jeannerod</keyname><forenames>Claude-Pierre</forenames></author><author><keyname>Pernet</keyname><forenames>Cl&#xe9;ment</forenames></author><author><keyname>Storjohann</keyname><forenames>Arne</forenames></author></authors><title>Rank-profile revealing Gaussian elimination and the CUP matrix
  decomposition</title><categories>cs.MS cs.SC</categories><comments>35 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Transforming a matrix over a field to echelon form, or decomposing the matrix
as a product of structured matrices that reveal the rank profile, is a
fundamental building block of computational exact linear algebra. This paper
surveys the well known variations of such decompositions and transformations
that have been proposed in the literature. We present an algorithm to compute
the CUP decomposition of a matrix, adapted from the LSP algorithm of Ibarra,
Moran and Hui (1982), and show reductions from the other most common Gaussian
elimination based matrix transformations and decompositions to the CUP
decomposition. We discuss the advantages of the CUP algorithm over other
existing algorithms by studying time and space complexities: the asymptotic
time complexity is rank sensitive, and comparing the constants of the leading
terms, the algorithms for computing matrix invariants based on the CUP
decomposition are always at least as good except in one case. We also show that
the CUP algorithm, as well as the computation of other invariants such as
transformation to reduced column echelon form using the CUP algorithm, all work
in place, allowing for example to compute the inverse of a matrix on the same
storage as the input matrix.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5728</identifier>
 <datestamp>2011-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5728</id><created>2011-12-24</created><authors><author><keyname>Qadri</keyname><forenames>Jameel A.</forenames></author><author><keyname>Banday</keyname><forenames>M. Tariq</forenames></author></authors><title>Web Accessibility - A timely recognized challenge</title><categories>cs.CY</categories><comments>6 Pages</comments><acm-class>H.5.3</acm-class><journal-ref>Qadri, J.A., Banday, M.T. (2009). &quot;Web Accessibility - A timely
  recognized challenge,&quot; The Business Review, ISSN: 0972-8384, 14(1&amp;2), pp.
  99-102</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Web Accessibility for disabled people has posed a challenge to the civilized
societies that claim to uphold the principles of equal opportunity and
nondiscrimination. Certain concrete measures have been taken to narrow down the
digital divide between normal and disabled users of Internet technology. The
efforts have resulted in enactment of legislations and laws and mass awareness
about the discriminatory nature of the accessibility issue, besides the efforts
have resulted in the development of commensurate technological tools to develop
and test the Web accessibility. World Wide Web consortium's (W3C) Web
Accessibility Initiative (WAI) has framed a comprehensive document comprising
of set of guidelines to make the Web sites accessible to the users with
disabilities. This paper is about the issues and aspects surrounding Web
Accessibility. The details and scope are kept limited to comply with the aim of
the paper which is to create awareness and to provide basis for in-depth
investigation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5732</identifier>
 <datestamp>2011-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5732</id><created>2011-12-24</created><authors><author><keyname>Banday</keyname><forenames>M. Tariq</forenames></author><author><keyname>Qadri</keyname><forenames>Jameel A.</forenames></author></authors><title>Phishing - A Growing Threat to E-Commerce</title><categories>cs.CR</categories><comments>8 Pages</comments><acm-class>K.4.4; K.6.5; D.4.6; K.4.2</acm-class><journal-ref>Banday, M.T., Qadri, J.A. (2007). &quot;Phishing - A Growing Threat to
  E-Commerce,&quot; The Business Review, ISSN: 0972-8384, 12(2), pp. 76-83</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In today's business environment, it is difficult to imagine a workplace
without access to the web, yet a variety of email born viruses, spyware,
adware, Trojan horses, phishing attacks, directory harvest attacks, DoS
attacks, and other threats combine to attack businesses and customers. This
paper is an attempt to review phishing - a constantly growing and evolving
threat to Internet based commercial transactions. Various phishing approaches
that include vishing, spear phishng, pharming, keyloggers, malware, web
Trojans, and others will be discussed. This paper also highlights the latest
phishing analysis made by Anti-Phishing Working Group (APWG) and Korean
Internet Security Center.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5741</identifier>
 <datestamp>2011-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5741</id><created>2011-12-24</created><authors><author><keyname>Blais</keyname><forenames>Eric</forenames></author><author><keyname>Weinstein</keyname><forenames>Amit</forenames></author><author><keyname>Yoshida</keyname><forenames>Yuichi</forenames></author></authors><title>Partially Symmetric Functions are Efficiently Isomorphism-Testable</title><categories>cs.DS cs.CC math.CO</categories><comments>22 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a function f: {0,1}^n \to {0,1}, the f-isomorphism testing problem
requires a randomized algorithm to distinguish functions that are identical to
f up to relabeling of the input variables from functions that are far from
being so. An important open question in property testing is to determine for
which functions f we can test f-isomorphism with a constant number of queries.
Despite much recent attention to this question, essentially only two classes of
functions were known to be efficiently isomorphism testable: symmetric
functions and juntas.
  We unify and extend these results by showing that all partially symmetric
functions---functions invariant to the reordering of all but a constant number
of their variables---are efficiently isomorphism-testable. This class of
functions, first introduced by Shannon, includes symmetric functions, juntas,
and many other functions as well. We conjecture that these functions are
essentially the only functions efficiently isomorphism-testable.
  To prove our main result, we also show that partial symmetry is efficiently
testable. In turn, to prove this result we had to revisit the junta testing
problem. We provide a new proof of correctness of the nearly-optimal junta
tester. Our new proof replaces the Fourier machinery of the original proof with
a purely combinatorial argument that exploits the connection between sets of
variables with low influence and intersecting families.
  Another important ingredient in our proofs is a new notion of symmetric
influence. We use this measure of influence to prove that partial symmetry is
efficiently testable and also to construct an efficient sample extractor for
partially symmetric functions. We then combine the sample extractor with the
testing-by-implicit-learning approach to complete the proof that partially
symmetric functions are efficiently isomorphism-testable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5745</identifier>
 <datestamp>2011-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5745</id><created>2011-12-24</created><authors><author><keyname>Houlsby</keyname><forenames>Neil</forenames></author><author><keyname>Husz&#xe1;r</keyname><forenames>Ferenc</forenames></author><author><keyname>Ghahramani</keyname><forenames>Zoubin</forenames></author><author><keyname>Lengyel</keyname><forenames>M&#xe1;t&#xe9;</forenames></author></authors><title>Bayesian Active Learning for Classification and Preference Learning</title><categories>stat.ML cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Information theoretic active learning has been widely studied for
probabilistic models. For simple regression an optimal myopic policy is easily
tractable. However, for other tasks and with more complex models, such as
classification with nonparametric models, the optimal solution is harder to
compute. Current approaches make approximations to achieve tractability. We
propose an approach that expresses information gain in terms of predictive
entropies, and apply this method to the Gaussian Process Classifier (GPC). Our
approach makes minimal approximations to the full information theoretic
objective. Our experimental performance compares favourably to many popular
active learning algorithms, and has equal or lower computational complexity. We
compare well to decision theoretic approaches also, which are privy to more
information and require much more computational time. Secondly, by developing
further a reformulation of binary preference learning to a classification
problem, we extend our algorithm to Gaussian Process preference learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5749</identifier>
 <datestamp>2011-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5749</id><created>2011-12-24</created><authors><author><keyname>Knill</keyname><forenames>Oliver</forenames></author></authors><title>On the Dimension and Euler characteristic of random graphs</title><categories>math.PR cs.CG cs.DM cs.NI math.CO</categories><comments>18 pages, 14 figures, 4 tables</comments><msc-class>05C80, 05C82, 05C10, 90B15, 57M15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The inductive dimension dim(G) of a finite undirected graph G=(V,E) is a
rational number defined inductively as 1 plus the arithmetic mean of the
dimensions of the unit spheres dim(S(x)) at vertices x primed by the
requirement that the empty graph has dimension -1. We look at the distribution
of the random variable &quot;dim&quot; on the Erdos-Renyi probability space G(n,p), where
each of the n(n-1)/2 edges appears independently with probability p. We show
here that the average dimension E[dim] is a computable polynomial of degree
n(n-1)/2 in p. The explicit formulas allow experimentally to explore limiting
laws for the dimension of large graphs. We also study the expectation E[X] of
the Euler characteristic X, considered as a random variable on G(n,p). We look
experimentally at the statistics of curvature K(v) and local dimension dim(v) =
1+dim(S(v)) which satisfy the Gauss-Bonnet formula X(G) = sum K(v) and by
definition dim(G) = sum dim(v)/|V|. We also look at the signature functions
f(p)=E[dim], g(p)=E[X] and matrix values functions A(p) = Cov[{dim(v),dim(w)],
B(p) = Cov[K(v),K(w)] on the probability space G(p) of all subgraphs of a host
graph G=(V,E) with the same vertex set V, where each edge is turned on with
probability p. If G is the complete graph or a union of cyclic graphs with have
explicit formulas for the signature polynomials f and g.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5756</identifier>
 <datestamp>2011-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5756</id><created>2011-12-24</created><authors><author><keyname>Tannious</keyname><forenames>Ramy Abdallah</forenames></author><author><keyname>Nosratinia</keyname><forenames>Aria</forenames></author></authors><title>Relay-Assisted Interference Channel: Degrees of Freedom</title><categories>cs.IT math.IT</categories><comments>7 double-column pages, 3 figures, accepted in IEEE Transactions on
  Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the degrees of freedom of the interference channel in
the presence of a dedicated MIMO relay. The relay is used to manage the
interference at the receivers. It is assumed that all nodes including the relay
have channel state information only for their own links and that the relay has
M (greater than or equal to K) antennas in a K-user network. We pose the
question: What is the benefit of exploiting the direct links from the source to
destinations compared to a simpler two-hop strategy. To answer this question,
we first establish the degrees of freedom of the interference channel with a
MIMO relay, showing that a K-pair network with a MIMO relay has K/2 degrees of
freedom. Thus, appropriate signaling in a two-hop scenario captures the degrees
of freedom without the need for the direct links. We then consider more
sophisticated encoding strategies in search of other ways to exploit the direct
links. Using a number of hybrid encoding strategies, we obtain non-asymptotic
achievable sum-rates. We investigate the case where the relay (unlike other
nodes) has access to abundant power, showing that when sources have power P and
the relay is allowed power proportional to O(P^2), the full degrees of freedom
K are available to the network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5760</identifier>
 <datestamp>2011-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5760</id><created>2011-12-24</created><authors><author><keyname>Boja</keyname><forenames>Catalin</forenames></author></authors><title>Security Survey of Internet Browsers Data Managers</title><categories>cs.CR</categories><comments>11 pages, 5 figures, 6 tables</comments><acm-class>K.6.5</acm-class><journal-ref>Journal Of Mobile, Embedded And Distributed Systems, 3(3),
  109-119. Available at:
  http://www.jmeds.eu/index.php/jmeds/article/view/Security-Survey-of-Internet-Browsers-Data-Managers.
  Date accessed: 25 Dec. 2011</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The paper analyses current versions of top three used Internet browsers and
compare their security levels to a research done in 2006. The security is
measured by analyzing how user data is stored. Data recorded during different
browsing sessions and by different password management functions it is
considered sensitive data. The paper describes how the browser protects the
sensitive data and how an attacker or a forensic analyst can access it.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5761</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5761</id><created>2011-12-24</created><updated>2012-02-21</updated><authors><author><keyname>Rosu</keyname><forenames>Grigore</forenames><affiliation>University of Illinois at Urbana-Champaign</affiliation></author><author><keyname>Chen</keyname><forenames>Feng</forenames><affiliation>University of Illinois at Urbana-Champaign</affiliation></author></authors><title>Semantics and Algorithms for Parametric Monitoring</title><categories>cs.PL cs.LO cs.SE</categories><comments>This paper will appear in LMCS. It is an extended version of a paper
  presented in TACAS'09</comments><proxy>LMCS</proxy><acm-class>D.1.5, D.2.1, D.2.4, D.2.5, D.3.1, F.3.1, F.3.2</acm-class><journal-ref>Logical Methods in Computer Science, Volume 8, Issue 1 (February
  23, 2012) lmcs:710</journal-ref><doi>10.2168/LMCS-8(1:9)2012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Analysis of execution traces plays a fundamental role in many program
analysis approaches, such as runtime verification, testing, monitoring, and
specification mining. Execution traces are frequently parametric, i.e., they
contain events with parameter bindings. Each parametric trace usually consists
of many meaningful trace slices merged together, each slice corresponding to
one parameter binding. This gives a semantics-based solution to parametric
trace analysis. A general-purpose parametric trace slicing technique is
introduced, which takes each event in the parametric trace and dispatches it to
its corresponding trace slices. This parametric trace slicing technique can be
used in combination with any conventional, non-parametric trace analysis
technique, by applying the later on each trace slice. As an instance, a
parametric property monitoring technique is then presented. The presented
parametric trace slicing and monitoring techniques have been implemented and
extensively evaluated. Measurements of runtime overhead confirm that the
generality of the discussed techniques does not come at a performance expense
when compared with existing parametric trace monitoring systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5762</identifier>
 <datestamp>2012-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5762</id><created>2011-12-24</created><updated>2012-12-02</updated><authors><author><keyname>Figueiredo</keyname><forenames>Daniel</forenames></author><author><keyname>Nain</keyname><forenames>Philippe</forenames></author><author><keyname>Ribeiro</keyname><forenames>Bruno</forenames></author><author><keyname>Silva</keyname><forenames>Edmundo de Souza e</forenames></author><author><keyname>Towsley</keyname><forenames>Don</forenames></author></authors><title>Characterizing Continuous Time Random Walks on Time Varying Graphs</title><categories>cs.SI physics.soc-ph</categories><report-no>UM-CS-2012-011v2</report-no><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this paper we study the behavior of a continuous time random walk (CTRW)
on a stationary and ergodic time varying dynamic graph. We establish conditions
under which the CTRW is a stationary and ergodic process. In general, the
stationary distribution of the walker depends on the walker rate and is
difficult to characterize. However, we characterize the stationary distribution
in the following cases: i) the walker rate is significantly larger or smaller
than the rate in which the graph changes (time-scale separation), ii) the
walker rate is proportional to the degree of the node that it resides on
(coupled dynamics), and iii) the degrees of node belonging to the same
connected component are identical (structural constraints). We provide examples
that illustrate our theoretical findings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5767</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5767</id><created>2011-12-24</created><updated>2012-10-13</updated><authors><author><keyname>Islam</keyname><forenames>Muhammad Nazmul</forenames></author><author><keyname>Mandayam</keyname><forenames>Narayan</forenames></author><author><keyname>Kompella</keyname><forenames>Sastry</forenames></author></authors><title>Optimal Resource Allocation and Relay Selection in Bandwidth Exchange
  Based Cooperative Forwarding</title><categories>cs.IT math.IT</categories><comments>8 pages, 7 figures</comments><journal-ref>Proceedings of WiOpt 2012 (Page 192-199)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate joint optimal relay selection and resource
allocation under bandwidth exchange (BE) enabled incentivized cooperative
forwarding in wireless networks. We consider an autonomous network where N
nodes transmit data in the uplink to an access point (AP) / base station (BS).
We consider the scenario where each node gets an initial amount (equal, optimal
based on direct path or arbitrary) of bandwidth, and uses this bandwidth as a
flexible incentive for two hop relaying. We focus on alpha-fair network utility
maximization (NUM) and outage reduction in this environment. Our contribution
is two-fold. First, we propose an incentivized forwarding based resource
allocation algorithm which maximizes the global utility while preserving the
initial utility of each cooperative node. Second, defining the link weight of
each relay pair as the utility gain due to cooperation (over noncooperation),
we show that the optimal relay selection in alpha-fair NUM reduces to the
maximum weighted matching (MWM) problem in a non-bipartite graph. Numerical
results show that the proposed algorithms provide 20- 25% gain in spectral
efficiency and 90-98% reduction in outage probability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5771</identifier>
 <datestamp>2012-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5771</id><created>2011-12-25</created><updated>2012-01-12</updated><authors><author><keyname>Shen</keyname><forenames>Zuowei</forenames></author><author><keyname>Xu</keyname><forenames>Zhiqiang</forenames></author></authors><title>On B-spline framelets derived from the unitary extension principle</title><categories>math.FA cs.CV cs.IT math.IT</categories><comments>28 pages</comments><msc-class>42c40, 65T60, 41A15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spline wavelet tight frames of Ron-Shen have been used widely in frame based
image analysis and restorations. However, except for the tight frame property
and the approximation order of the truncated series, there are few other
properties of this family of spline wavelet tight frames to be known. This
paper is to present a few new properties of this family that will provide
further understanding of it and, hopefully, give some indications why it is
efficient in image analysis and restorations. In particular, we present a
recurrence formula of computing generators of higher order spline wavelet tight
frames from the lower order ones. We also represent each generator of spline
wavelet tight frames as certain order of derivative of some univariate box
spline. With this, we further show that each generator of sufficiently high
order spline wavelet tight frames is close to a right order of derivative of a
properly scaled Gaussian function. This leads to the result that the wavelet
system generated by a finitely many consecutive derivatives of a properly
scaled Gaussian function forms a frame whose frame bounds can be almost tight.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5774</identifier>
 <datestamp>2011-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5774</id><created>2011-12-25</created><authors><author><keyname>Attiogb&#xe9;</keyname><forenames>Christian</forenames><affiliation>LINA</affiliation></author></authors><title>Dynamic Composition of Evolving Process Types</title><categories>cs.SE</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Classical approaches like process algebras or labelled transition systems
deal with static composition to model non-trivial concurrent or distributed
systems; this is not sufficient for systems with dynamic architecture and with
variable number of components. We introduce a method to guide the modelling and
the dynamic composition of processes to build large distributed systems with
dynamic adhoc architecture. The modelling and the composition are based on an
event-based approach that favour the decoupling of the system components. The
composition uses the sharing of abstract communication channels. The method is
appropriate to deal with evolving processes (with mobility, mutation). The
event-B method is used for practical support. A fauna and its evolution are
considered as a working system; this system presents some specificities, its
behaviour is not foreseeable, it has an adhoc (not statically fixed)
architecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5790</identifier>
 <datestamp>2011-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5790</id><created>2011-12-25</created><authors><author><keyname>Alhazmi</keyname><forenames>Hanan</forenames></author><author><keyname>Akkari</keyname><forenames>Nadine</forenames></author></authors><title>An Overview of Context-Aware Vertical Handover Schemes in Heterogeneous
  Networks</title><categories>cs.NI</categories><comments>12 pages, 9 figures, Journal</comments><journal-ref>International Journal of Computer Science &amp; Engineering Survey
  (IJCSES) Vol.2, No.4, November 2011</journal-ref><doi>10.5121/ijcses.2011.2403</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As wireless access technologies grow rapidly, the recent studies have focused
on granting mobile users the ability of roaming across different wireless
networks in a seamless manner thus offering seamless mobility. The different
characteristics of each wireless technology with regards to QoS brought many
challenges for provisioning the continuous services (audio/video streaming) in
a seamless way. In this paper, we intend to review the existing context-aware
methods which offered solutions for service continuity. We looked at the types
of context information used in each solution. Through this study, it is clear
that context awareness plays a significant role in handover process in order to
satisfy users demanding seamless services. Therefore, the goal of this paper is
to compare the existing methods grouped as general, IMS based, and WLAN/WiMAX
solutions in terms of several criteria, such as interworking architecture,
service continuity, and QoS provisioning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5799</identifier>
 <datestamp>2011-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5799</id><created>2011-12-25</created><authors><author><keyname>Kamyabpour</keyname><forenames>Najmeh</forenames></author><author><keyname>Hoang</keyname><forenames>Doan B.</forenames></author></authors><title>A study on Modeling of Dependency between Configuration Parameters and
  Overall Energy Consumption in Wireless Sensor Network (WSN)</title><categories>cs.NI</categories><comments>16 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study a new approach to model the overall Energy
Consumption (EC) in Wireless Sensor Networks (WSN). First, we extract
parameters involving in the EC of WSNs. The dependency between configuration
parameters and the average residual energy of a specific application is then
investigated. Our approach has three key steps: profiling, parameter reduction,
and modeling. In profiling, a sensor network simulator is re-run 800 times with
different values of the configuration parameters in order to profile the
average residual energy in nodes. In the parameter reduction, three statistical
analyses (p-value, linear and non-linear correlation) are applied to the
outcome of profiled experiments in order to separate the effective parameters
on WSN residual energy. Finally, linear regression is used to model the
relation between the chosen effective parameters and the residual energy. The
evaluation based on running the simulator for another 200 times with different
values of the effective parameters shows that the model can predict the
residual energy of nodes in WSN with average error of less than 13%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5800</identifier>
 <datestamp>2011-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5800</id><created>2011-12-25</created><authors><author><keyname>Kamyabpour</keyname><forenames>Najmeh</forenames></author><author><keyname>Hoang</keyname><forenames>Doan B.</forenames></author></authors><title>Modeling overall energy consumption in Wireless Sensor Networks</title><categories>cs.NI</categories><comments>This paper has been published in PDCAT 2010 8 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Minimizing the energy consumption of a wireless sensor network application is
crucial for effective realization of the intended application in terms of cost,
lifetime, and functionality. However, the minimizing task is hardly possible as
no overall energy cost function is available for optimization. Optimizing a
specific component of the total energy cost does not help in reducing the total
energy cost as this reduction may be negated by an increase in the energy
consumption of other components of the application. Recently we proposed
Hierarchy Energy Driven Architecture as a robust architecture that takes into
account all principal energy constituents of wireless sensor network
applications. Based on the proposed architecture, this paper presents a single
overall model and proposes a feasible formulation to express the overall energy
consumption of a generic wireless sensor network application in terms of its
energy constituents. The formulation offers a concrete expression for
evaluating the performance of a wireless sensor network application, optimizing
its constituent's operations, and designing more energy-efficient applications.
The paper also presents simulation results to demonstrate the feasibility of
our model and energy formulation
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5840</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5840</id><created>2011-12-26</created><updated>2014-08-10</updated><authors><author><keyname>Bergstra</keyname><forenames>J. A.</forenames></author></authors><title>Informatics Perspectives on Decision Taking, a Case Study on Resolving
  Process Product Ambiguity</title><categories>cs.OH</categories><comments>First revision; many minior improvements have been made, concluding
  section has been replaced</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A decision is an act or event of decision taking. Decision making always
includes decision taking, the latter not involving significant exchanges with
non-deciding agents. A decision outcome is a piece of storable information
constituting the result of a decision. Decision outcomes are typed, for
instance: plan, command, assertion, or boolean reply to a question. Decision
outcomes are seen by an audience and autonomous actions from the audience is
supposed to realize the putting into effect of a decision outcome, thus leading
to so-called decision effects. Decision outcomes are supposedly expected by the
decider. Using a model or a theory concerning the causal chain leading from a
decision outcome to one or more decision effects may support a decision taker
decision taker in predicting plausible decision effects for candidate decision
outcomes. Decision taking is positioned amidst many related notions including:
decision making, decision process, decision making process, decision process
making, decision engineering, decision progression, and decision progression
production.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5895</identifier>
 <datestamp>2011-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5895</id><created>2011-12-26</created><authors><author><keyname>Duarte-Carvajalino</keyname><forenames>Julio</forenames></author><author><keyname>Sapiro</keyname><forenames>Guillermo</forenames></author><author><keyname>Yu</keyname><forenames>Guoshen</forenames></author><author><keyname>Carin</keyname><forenames>Lawrence</forenames></author></authors><title>Online Adaptive Statistical Compressed Sensing of Gaussian Mixture
  Models</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A framework of online adaptive statistical compressed sensing is introduced
for signals following a mixture model. The scheme first uses non-adaptive
measurements, from which an online decoding scheme estimates the model
selection. As soon as a candidate model has been selected, an optimal sensing
scheme for the selected model continues to apply. The final signal
reconstruction is calculated from the ensemble of both the non-adaptive and the
adaptive measurements. For signals generated from a Gaussian mixture model, the
online adaptive sensing algorithm is given and its performance is analyzed. On
both synthetic and real image data, the proposed adaptive scheme considerably
reduces the average reconstruction error with respect to standard statistical
compressed sensing that uses fully random measurements, at a marginally
increased computational complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5904</identifier>
 <datestamp>2013-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5904</id><created>2011-12-26</created><updated>2012-06-29</updated><authors><author><keyname>Asano</keyname><forenames>Tetsuo</forenames></author><author><keyname>Buchin</keyname><forenames>Kevin</forenames></author><author><keyname>Buchin</keyname><forenames>Maike</forenames></author><author><keyname>Korman</keyname><forenames>Matias</forenames></author><author><keyname>Mulzer</keyname><forenames>Wolfgang</forenames></author><author><keyname>Rote</keyname><forenames>G&#xfc;nter</forenames></author><author><keyname>Schulz</keyname><forenames>Andr&#xe9;</forenames></author></authors><title>Memory-Constrained Algorithms for Simple Polygons</title><categories>cs.CG</categories><comments>Preprint appeared in EuroCG 2012</comments><journal-ref>Computational Geometry: Theory and Applications (CGTA), 46(8),
  2013, pp. 959-969</journal-ref><doi>10.1016/j.comgeo.2013.04.005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A constant-workspace algorithm has read-only access to an input array and may
use only O(1) additional words of $O(\log n)$ bits, where $n$ is the size of
the input. We assume that a simple $n$-gon is given by the ordered sequence of
its vertices. We show that we can find a triangulation of a plane straight-line
graph in $O(n^2)$ time. We also consider preprocessing a simple polygon for
shortest path queries when the space constraint is relaxed to allow $s$ words
of working space. After a preprocessing of $O(n^2)$ time, we are able to solve
shortest path queries between any two points inside the polygon in $O(n^2/s)$
time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5906</identifier>
 <datestamp>2011-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5906</id><created>2011-12-26</created><authors><author><keyname>Peterson</keyname><forenames>G. J.</forenames></author><author><keyname>Dill</keyname><forenames>K. A.</forenames></author></authors><title>Power-law distribution functions derived from maximum entropy and a
  symmetry relationship</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI physics.data-an</categories><comments>5 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Power-law distributions are common, particularly in social physics. Here, we
explore whether power-laws might arise as a consequence of a general
variational principle for stochastic processes. We describe communities of
'social particles', where the cost of adding a particle to the community is
shared equally between the particle joining the cluster and the particles that
are already members of the cluster. Power-law probability distributions of
community sizes arise as a natural consequence of the maximization of entropy,
subject to this 'equal cost sharing' rule. We also explore a generalization in
which there is unequal sharing of the costs of joining a community.
Distributions change smoothly from exponential to power-law as a function of a
sharing-inequality quantity. This work gives an interpretation of power-law
distributions in terms of shared costs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5908</identifier>
 <datestamp>2011-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5908</id><created>2011-12-26</created><authors><author><keyname>Gardezi</keyname><forenames>Jaffer</forenames></author><author><keyname>Bertossi</keyname><forenames>Leopoldo</forenames></author></authors><title>Query Answering under Matching Dependencies for Data Cleaning:
  Complexity and Algorithms</title><categories>cs.DB cs.LO</categories><comments>Conference submission, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Matching dependencies (MDs) have been recently introduced as declarative
rules for entity resolution (ER), i.e. for identifying and resolving duplicates
in relational instance $D$. A set of MDs can be used as the basis for a
possibly non-deterministic mechanism that computes a duplicate-free instance
from $D$. The possible results of this process are the clean, &quot;minimally
resolved instances&quot; (MRIs). There might be several MRIs for $D$, and the
&quot;resolved answers&quot; to a query are those that are shared by all the MRIs. We
investigate the problem of computing resolved answers. We look at various sets
of MDs, developing syntactic criteria for determining (in)tractability of the
resolved answer problem, including a dichotomy result. For some tractable
classes of MDs and conjunctive queries, we present a query rewriting
methodology that can be used to retrieve the resolved answers. We also
investigate connections with &quot;consistent query answering&quot;, deriving further
tractability results for MD-based ER.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5917</identifier>
 <datestamp>2011-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5917</id><created>2011-12-26</created><authors><author><keyname>Myint</keyname><forenames>Julia</forenames></author><author><keyname>Naing</keyname><forenames>Thinn Thu</forenames></author></authors><title>Management of Data Replication for PC Cluster-based Cloud Storage System</title><categories>cs.DC cs.NI</categories><journal-ref>International Journal on Cloud Computing: Services and
  Architecture (IJCCSA), Vol.1,No.3, November 2011, 31-41</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Storage systems are essential building blocks for cloud computing
infrastructures. Although high performance storage servers are the ultimate
solution for cloud storage, the implementation of inexpensive storage system
remains an open issue. To address this problem, the efficient cloud storage
system is implemented with inexpensive and commodity computer nodes that are
organized into PC cluster based datacenter. Hadoop Distributed File System
(HDFS) is an open source cloud based storage platform and designed to be
deployed in low-cost hardware. PC Cluster based Cloud Storage System is
implemented with HDFS by enhancing replication management scheme. Data objects
are distributed and replicated in a cluster of commodity nodes located in the
cloud. This system provides optimum replica number as well as weighting and
balancing among the storage server nodes. The experimental results show that
storage can be balanced depending on the available disk space, expected
availability and failure probability of each node in PC cluster.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5945</identifier>
 <datestamp>2012-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5945</id><created>2011-12-27</created><authors><author><keyname>Nepusz</keyname><forenames>Tam&#xe1;s</forenames></author><author><keyname>Vicsek</keyname><forenames>Tam&#xe1;s</forenames></author></authors><title>Controlling edge dynamics in complex networks</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><comments>Preprint. 24 pages, 4 figures, 2 tables. Source code available at
  http://github.com/ntamas/netctrl</comments><journal-ref>Nature Physics 8, 568--573 (2012)</journal-ref><doi>10.1038/nphys2327</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The interaction of distinct units in physical, social, biological and
technological systems naturally gives rise to complex network structures.
Networks have constantly been in the focus of research for the last decade,
with considerable advances in the description of their structural and dynamical
properties. However, much less effort has been devoted to studying the
controllability of the dynamics taking place on them. Here we introduce and
evaluate a dynamical process defined on the edges of a network, and demonstrate
that the controllability properties of this process significantly differ from
simple nodal dynamics. Evaluation of real-world networks indicates that most of
them are more controllable than their randomized counterparts. We also find
that transcriptional regulatory networks are particularly easy to control.
Analytic calculations show that networks with scale-free degree distributions
have better controllability properties than uncorrelated networks, and
positively correlated in- and out-degrees enhance the controllability of the
proposed dynamics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5947</identifier>
 <datestamp>2011-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5947</id><created>2011-12-27</created><authors><author><keyname>Ivanov</keyname><forenames>Sergiu</forenames></author><author><keyname>Verlan</keyname><forenames>Sergey</forenames></author></authors><title>Random Context and Semi-Conditional Insertion-Deletion Systems</title><categories>cs.FL cs.CC cs.CL cs.DM</categories><msc-class>68Q05, 68Q10, 68Q17</msc-class><acm-class>F.4.3; F.1.1; F.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article we introduce the operations of insertion and deletion working
in a random-context and semi-conditional manner. We show that the conditional
use of rules strictly increase the computational power. In the case of
semi-conditional insertion-deletion systems context-free insertion and deletion
rules of one symbol are sufficient to get the computational completeness. In
the random context case our results expose an asymmetry between the
computational power of insertion and deletion rules: systems of size $(2,0,0;
1,1,0)$ are computationally complete, while systems of size $(1,1,0;2,0,0)$
(and more generally of size $(1,1,0;p,1,1)$) are not. This is particularly
interesting because other control mechanisms like graph-control or matrix
control used together with insertion-deletion systems do not present such
asymmetry.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5953</identifier>
 <datestamp>2011-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5953</id><created>2011-12-27</created><authors><author><keyname>Rezki</keyname><forenames>Zouheir</forenames></author><author><keyname>Alouini</keyname><forenames>Mohamed-Slim</forenames></author></authors><title>Secure Diversity-Multiplexing Tradeoff of Zero-Forcing Transmit Scheme
  at Finite-SNR</title><categories>cs.CR cs.IT math.IT</categories><comments>10 pages and 5 figures. To appear IEEE Transactions on Communications
  2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we address the finite Signal-to-Noise Ratio (SNR)
Diversity-Multiplexing Tradeoff (DMT) of the Multiple Input Multiple Output
(MIMO) wiretap channel, where a Zero-Forcing (ZF) transmit scheme, that intends
to send the secret information in the orthogonal space of the eavesdropper
channel, is used. First, we introduce the secrecy multiplexing gain at
finite-SNR that generalizes the definition at high-SNR. Then, we provide upper
and lower bounds on the outage probability under secrecy constraint, from which
secrecy diversity gain estimates of ZF are derived. Through asymptotic
analysis, we show that the upper bound underestimates the secrecy diversity
gain, whereas the lower bound is tight at high-SNR, and thus its related
diversity gain estimate is equal to the actual asymptotic secrecy diversity
gain of the MIMO wiretap channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5957</identifier>
 <datestamp>2012-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5957</id><created>2011-12-27</created><updated>2012-09-09</updated><authors><author><keyname>Ahmed</keyname><forenames>Eya Ben</forenames></author><author><keyname>Nabli</keyname><forenames>Ahlem</forenames></author><author><keyname>Gargouri</keyname><forenames>Fa&#xef;ez</forenames></author></authors><title>Usage Des Mesures Pour La G\'en\'eration Des R\`egles d'Associations
  Cycliques</title><categories>cs.DB</categories><comments>18 pages, 3 figures; 7 \`eme journ\'ees Francophones sur les
  Entrep\^ots de donn\'ees et l'Analyse en ligne (EDA'2011)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The online analytical processing (OLAP) does not provide any explanation of
correlations discovered between data. Thus, the coupling of OLAP and data
mining, especially association rules, is considered as an efficient solution to
this problem. In this context, we mainly focus on a particular class of
association rules which is the cyclic association rules. These rules aimed to
discover patterns that display regular variation over user-defined intervals.
Generally,the generated patterns do not take an advantage from the
specificities of the multidimensional context namely, the consideration of the
measures and their aggregations. In this paper, we introduce a novel method for
extracting cyclic association rules from measures, and we redefine the
evaluation metrics of association rules quality inspired of the temporal
summarizability of measures concept through the integration of appropriate
aggregation functions. To prove the usefulness of our approach, we conduct an
empirical study on a real data warehouse.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5959</identifier>
 <datestamp>2011-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5959</id><created>2011-12-27</created><authors><author><keyname>Jaume</keyname><forenames>M. A.</forenames></author><author><keyname>Paradells</keyname><forenames>J.</forenames></author></authors><title>Disseny d'un prototipus de xarxa MESH sense fils multir\'adio i
  multicanal sobre OLSR modificat amb canal de senyalitzaci\'o dedicat</title><categories>cs.NI</categories><comments>pages 243</comments><msc-class>28-00</msc-class><acm-class>I.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless mesh cubes are used to improve the channel signaling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5980</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5980</id><created>2011-12-27</created><updated>2012-06-24</updated><authors><author><keyname>Khor</keyname><forenames>Susan</forenames></author></authors><title>Search space analysis with Wang-Landau sampling and slow adaptive walks</title><categories>cs.NE</categories><comments>This is the final version which would have appeared in GECCO'12
  Companion, July 7-11, 2012, Philadelphia, PA, USA as part of a workshop but
  was withdrawn due to funding problems</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Two complementary techniques for analyzing search spaces are proposed: (i) an
algorithm to detect search points with potential to be local optima; and (ii) a
slightly adjusted Wang-Landau sampling algorithm to explore larger search
spaces. The detection algorithm assumes that local optima are points which are
easier to reach and harder to leave by a slow adaptive walker. A slow adaptive
walker moves to a nearest fitter point. Thus, points with larger outgoing step
sizes relative to incoming step sizes are marked using the local optima score
formulae as potential local optima points (PLOPs). Defining local optima in
these more general terms allows their detection within the closure of a subset
of a search space, and the sampling of a search space unshackled by a
particular move set. Tests are done with NK and HIFF problems to confirm that
PLOPs detected in the manner proposed retain characteristics of local optima,
and that the adjusted Wang-Landau samples are more representative of the search
space than samples produced by choosing points uniformly at random. While our
approach shows promise, more needs to be done to reduce its computation cost
that it may pave a way toward analyzing larger search spaces of practical
meaning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5995</identifier>
 <datestamp>2012-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5995</id><created>2011-12-27</created><updated>2012-11-01</updated><authors><author><keyname>Jeon</keyname><forenames>Jeongho</forenames></author><author><keyname>Ephremides</keyname><forenames>Anthony</forenames></author></authors><title>On the Stability of Random Multiple Access with Stochastic Energy
  Harvesting</title><categories>cs.IT math.IT</categories><comments>The material in this paper was presented in part at the IEEE
  International Symposium on Information Theory, Saint Petersburg, Russia, Aug.
  2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the random access of nodes having energy
harvesting capability and a battery to store the harvested energy. Each node
attempts to transmit the head-of-line packet in the queue if its battery is
nonempty. The packet and energy arrivals into the queue and the battery are all
modeled as a discrete-time stochastic process. The main contribution of this
paper is the exact characterization of the stability region of the packet
queues given the energy harvesting rates when a pair of nodes are randomly
accessing a common channel having multipacket reception (MPR) capability. The
channel with MPR capability is a generalized form of the wireless channel
modeling which allows probabilistic receptions of the simultaneously
transmitted packets. The results obtained in this paper are fairly general as
the cases with unlimited energy for transmissions both with the collision
channel and the channel with MPR capability can be derived from ours as special
cases. Furthermore, we study the impact of the finiteness of the batteries on
the achievable stability region.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.5997</identifier>
 <datestamp>2015-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.5997</id><created>2011-12-27</created><updated>2015-12-11</updated><authors><author><keyname>Mistani</keyname><forenames>Sina Akbari</forenames></author><author><keyname>Minaee</keyname><forenames>Shervin</forenames></author><author><keyname>Fatemizadeh</keyname><forenames>Emad</forenames></author></authors><title>Multispectral Palmprint Recognition Using a Hybrid Feature</title><categories>cs.CV</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Personal identification problem has been a major field of research in recent
years. Biometrics-based technologies that exploit fingerprints, iris, face,
voice and palmprints, have been in the center of attention to solve this
problem. Palmprints can be used instead of fingerprints that have been of the
earliest of these biometrics technologies. A palm is covered with the same skin
as the fingertips but has a larger surface, giving us more information than the
fingertips. The major features of the palm are palm-lines, including principal
lines, wrinkles and ridges. Using these lines is one of the most popular
approaches towards solving the palmprint recognition problem. Another robust
feature is the wavelet energy of palms. In this paper we used a hybrid feature
which combines both of these features. %Moreover, multispectral analysis is
applied to improve the performance of the system. At the end, minimum distance
classifier is used to match test images with one of the training samples. The
proposed algorithm has been tested on a well-known multispectral palmprint
dataset and achieved an average accuracy of 98.8\%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.6000</identifier>
 <datestamp>2013-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.6000</id><created>2011-12-27</created><authors><author><keyname>Jeon</keyname><forenames>Jeongho</forenames></author><author><keyname>Ephremides</keyname><forenames>Anthony</forenames></author></authors><title>Neighbor Discovery in a Wireless Sensor Network: Multipacket Reception
  Capability and Physical-Layer Signal Processing</title><categories>cs.NI</categories><comments>The material in this paper was presented in part at the 48th Annual
  Allerton Conference on Communication, Control, and Computing (Monticello,
  IL), Sept. 2010</comments><journal-ref>JOURNAL OF COMMUNICATIONS AND NETWORKS, VOL. 14, NO. 5, OCTOBER
  2012</journal-ref><doi>10.1109/JCN.2012.00015</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In randomly deployed networks, such as sensor networks, an important problem
for each node is to discover its \textit{neighbor} nodes so that the
connectivity amongst nodes can be established. In this paper, we consider this
problem by incorporating the physical layer parameters in contrast to the most
of the previous work which assumed a collision channel. Specifically, the pilot
signals that nodes transmit are successfully decoded if the strength of the
received signal relative to the interference is sufficiently high. Thus, each
node must extract signal parameter information from the superposition of an
unknown number of received signals. This problem falls naturally in the purview
of random set theory (RST) which generalizes standard probability theory by
assigning \textit{sets}, rather than values, to random outcomes. The
contributions in the paper are twofold: first, we introduce the realistic
effect of physical layer considerations in the evaluation of the performance of
\textit{logical} discovery algorithms; such an introduction is necessary for
the accurate assessment of how an algorithm performs. Secondly, given the
\textit{double} uncertainty of the environment (that is, the lack of knowledge
of the number of neighbors along with the lack of knowledge of the individual
signal parameters), we adopt the viewpoint of RST and demonstrate its advantage
relative to classical matched filter detection method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.6007</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.6007</id><created>2011-12-27</created><updated>2013-06-02</updated><authors><author><keyname>Landsberg</keyname><forenames>J. M.</forenames></author><author><keyname>Ottaviani</keyname><forenames>Giorgio</forenames></author></authors><title>New lower bounds for the border rank of matrix multiplication</title><categories>cs.CC math.AG</categories><comments>9 pages. Version 1 contained an error in the proof of its main
  theorem and in the course of fixing it we proved a stronger statement. v3:
  proof of main theorem moved up</comments><msc-class>03D15, 68Q17, 14N99</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The border rank of the matrix multiplication operator for n by n matrices is
a standard measure of its complexity. Using techniques from algebraic geometry
and representation theory, we show the border rank is at least 2n^2-n. Our
bounds are better than the previous lower bound (due to Lickteig in 1985) of
3/2 n^2+ n/2 -1 for all n&gt;2. The bounds are obtained by finding new equations
that bilinear maps of small border rank must satisfy, i.e., new equations for
secant varieties of triple Segre products, that matrix multiplication fails to
satisfy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.6008</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.6008</id><created>2011-12-27</created><updated>2014-02-26</updated><authors><author><keyname>Sitharam</keyname><forenames>Meera</forenames></author><author><keyname>Wang</keyname><forenames>Menghan</forenames></author><author><keyname>Gao</keyname><forenames>Heping</forenames></author></authors><title>Cayley configuration spaces of 2D mechanisms, Part I: extreme points,
  continuous motion paths and minimal representations</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider longstanding questions concerning configuration spaces of 1-dof
tree-decomposable linkages in 2D. By employing the notion Cayley configuration
space, i.e., a set of intervals of realizable distance-values for an
independent non-edge, we answer the following. (1) How to measure the
complexity of the configuration space and efficiently compute that of low
algebraic complexity? (2) How to restrict the Cayley configuration space to be
a single interval? (3) How to efficiently obtain continuous motion paths
between realizations? (4) How to bijectively represent of the Cartesian
realization space as a curve in an ambient space of minimum dimension? (5) How
robust is the complexity measure (1) and how to efficiently classify linkages
according to it?
  In Part I of this paper, we deal with problems (1)-(4) by introducing the
notions of (a) Cayley size, the number of intervals in the Cayley configuration
space, (b) Cayley computational complexity of computing the interval endpoints,
and (c) Cayley (algebraic) complexity of describing the interval endpoints.
Specifically (i) We give an algorithm to find the interval endpoints of a
Cayley configuration spac. For graphs with low Cayley complexity, we give the
following. (ii) A natural, minimal set of local orientations, whose
specification guarantees Cayley size of 1 and $O(|V|^2)$ Cayley computational
complexity. Specifying fewer local orientations results in a superpolynomial
blow-up of both Cayley size and computational complexity, provided P is
different from NP. (iii) An algorithm--for generic linkages--to find a path of
continuous motion (provided exists) between two given realizations, in time
linear in a natural measure of path length. (iv) A canonical bijective
representation of the Cartesian realization space in minimal ambient dimension,
also for generic linkages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.6009</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.6009</id><created>2011-12-27</created><updated>2012-11-06</updated><authors><author><keyname>Sitharam</keyname><forenames>Meera</forenames></author><author><keyname>Wang</keyname><forenames>Menghan</forenames></author><author><keyname>Gao</keyname><forenames>Heping</forenames></author></authors><title>Cayley Configuration Spaces of 1-dof Tree-decomposable Linkages, Part
  II: Combinatorial Characterization of Complexity</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We continue to study Cayley configuration spaces of 1-dof linkages in 2D
begun in Part I of this paper, i.e. the set of attainable lengths for a
non-edge. In Part II, we focus on the algebraic complexity of describing
endpoints of the intervals in the set, i.e., the Cayley complexity.
  Specifically, We focus on Cayley configuration spaces of a natural class of
1-dof linkages, called 1-dof tree-decomposable linkages. The underlying graphs
G satisfy the following: for some base non-edge f, G \cup f is
quadratic-radically solvable (QRS), meaning that G \cup f is minimally rigid,
and given lengths \bar{l} of all edges, the corresponding linkage (G \cup f,
\bar{l}) can be simply realized by ruler and compass starting from f. It is
clear that the Cayley complexity only depends on the graph G and possibly the
non-edge f. Here we ask whether the Cayley complexity depends on the choice of
a base non-edge f. We answer this question in the negative, thereby showing
that low Cayley complexity is a property of the graph G (independent of the
non-edge f).
  Then, we give a simple characterization of graphs with low Cayley complexity,
leading to an efficient algorithmic characterization, i.e. an efficient
algorithm for recognizing such graphs.
  Next, we show a surprising result that (graph) planarity is equivalent to low
Cayley complexity for a natural subclass of 1-dof triangle-decomposable graphs.
While this is a finite forbidden minor graph characterization of low Cayley
complexity, we provide counterexamples showing impossibility of such finite
forbidden minor characterizations when the above subclass is enlarged.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.6028</identifier>
 <datestamp>2013-11-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.6028</id><created>2011-12-27</created><updated>2013-11-11</updated><authors><author><keyname>Peixoto</keyname><forenames>Tiago P.</forenames></author></authors><title>Entropy of stochastic blockmodel ensembles</title><categories>cond-mat.stat-mech cs.SI physics.data-an physics.soc-ph</categories><comments>16 pages, 7 figures</comments><journal-ref>Phys. Rev. E 85, 056122 (2012)</journal-ref><doi>10.1103/PhysRevE.85.056122</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Stochastic blockmodels are generative network models where the vertices are
separated into discrete groups, and the probability of an edge existing between
two vertices is determined solely by their group membership. In this paper, we
derive expressions for the entropy of stochastic blockmodel ensembles. We
consider several ensemble variants, including the traditional model as well as
the newly introduced degree-corrected version [Karrer et al. Phys. Rev. E 83,
016107 (2011)], which imposes a degree sequence on the vertices, in addition to
the block structure. The imposed degree sequence is implemented both as &quot;soft&quot;
constraints, where only the expected degrees are imposed, and as &quot;hard&quot;
constraints, where they are required to be the same on all samples of the
ensemble. We also consider generalizations to multigraphs and directed graphs.
We illustrate one of many applications of this measure by directly deriving a
log-likelihood function from the entropy expression, and using it to infer
latent block structure in observed data. Due to the general nature of the
ensembles considered, the method works well for ensembles with intrinsic degree
correlations (i.e. with entropic origin) as well as extrinsic degree
correlations, which go beyond the block structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.6032</identifier>
 <datestamp>2011-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.6032</id><created>2011-12-27</created><authors><author><keyname>Ruderman</keyname><forenames>Daniel L.</forenames></author></authors><title>A self-rendering digital image encoding</title><categories>cs.GR</categories><comments>7 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Without careful long-term preservation digital data may be lost to a number
of factors, including physical media decay, lack of suitable decoding
equipment, and the absence of software. When raw data can be read but lack
suitable annotations as to provenance, the ability to interpret them is more
straightforward if they can be assessed through simple visual techniques. In
this regard digital images are a special case since their data have a natural
representation on two-dimensional media surfaces. This paper presents a novel
binary image pixel encoding that produces an approximate analog rendering of
encoded images when the image bits are arranged spatially in an appropriate
manner. This simultaneous digital and analog representation acts to inseparably
annotate bits as image data, which may contribute to the longevity of
so-encoded images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.6045</identifier>
 <datestamp>2013-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.6045</id><created>2011-12-27</created><authors><author><keyname>Amancio</keyname><forenames>Diego R.</forenames></author><author><keyname>Altmann</keyname><forenames>Eduardo G.</forenames></author><author><keyname>Oliveira</keyname><forenames>Osvaldo N.</forenames><suffix>Jr.</suffix></author><author><keyname>Costa</keyname><forenames>Luciano da F.</forenames></author></authors><title>Comparing intermittency and network measurements of words and their
  dependency on authorship</title><categories>physics.soc-ph cs.CL cs.SI physics.data-an</categories><journal-ref>New J. Phys. (2011) 13 123024</journal-ref><doi>10.1088/1367-2630/13/12/123024</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many features from texts and languages can now be inferred from statistical
analyses using concepts from complex networks and dynamical systems. In this
paper we quantify how topological properties of word co-occurrence networks and
intermittency (or burstiness) in word distribution depend on the style of
authors. Our database contains 40 books from 8 authors who lived in the 19th
and 20th centuries, for which the following network measurements were obtained:
clustering coefficient, average shortest path lengths, and betweenness. We
found that the two factors with stronger dependency on the authors were the
skewness in the distribution of word intermittency and the average shortest
paths. Other factors such as the betweeness and the Zipf's law exponent show
only weak dependency on authorship. Also assessed was the contribution from
each measurement to authorship recognition using three machine learning
methods. The best performance was a ca. 65 % accuracy upon combining complex
network and intermittency features with the nearest neighbor algorithm. From a
detailed analysis of the interdependence of the various metrics it is concluded
that the methods used here are complementary for providing short- and
long-scale perspectives of texts, which are useful for applications such as
identification of topical words and information retrieval.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.6047</identifier>
 <datestamp>2011-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.6047</id><created>2011-12-27</created><authors><author><keyname>Zhou</keyname><forenames>Jianqin</forenames></author><author><keyname>Liu</keyname><forenames>Jun</forenames></author><author><keyname>Liu</keyname><forenames>Wanquan</forenames></author></authors><title>Characterization of $2^n$-periodic binary sequences with fixed 3-error
  or 4-error linear complexity</title><categories>cs.CR</categories><comments>7 pages</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The linear complexity and the $k$-error linear complexity of a sequence have
been used as important security measures for key stream sequence strength in
linear feedback shift register design. By using the sieve method of
combinatorics, the $k$-error linear complexity distribution of $2^n$-periodic
binary sequences is investigated based on Games-Chan algorithm.
  First, for $k=2,3$, the complete counting functions on the $k$-error linear
complexity of $2^n$-periodic binary sequences with linear complexity less than
$2^n$ are characterized. Second, for $k=3,4$, the complete counting functions
on the $k$-error linear complexity of $2^n$-periodic binary sequences with
linear complexity $2^n$ are presented. Third, for $k=4,5$, the complete
counting functions on the $k$-error linear complexity of $2^n$-periodic binary
sequences with linear complexity less than $2^n$ are derived. As a consequence
of these results, the counting functions for the number of $2^n$-periodic
binary sequences with the 3-error linear complexity are obtained, and the
complete counting functions on the 4-error linear complexity of $2^n$-periodic
binary sequences are obvious.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.6063</identifier>
 <datestamp>2013-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.6063</id><created>2011-12-28</created><updated>2012-09-04</updated><authors><author><keyname>Takahashi</keyname><forenames>Yasuhiro</forenames></author><author><keyname>Tani</keyname><forenames>Seiichiro</forenames></author></authors><title>Collapse of the Hierarchy of Constant-Depth Exact Quantum Circuits</title><categories>quant-ph cs.CC</categories><comments>19 pages, 4 figures; v2: one theorem added, title changed, text
  substantially rewritten</comments><journal-ref>Proceedings of the 28th IEEE Conference on Computational
  Complexity (CCC 2013), pp.168-178, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the quantum complexity class QNC^0_f of quantum operations
implementable exactly by constant-depth polynomial-size quantum circuits with
unbounded fan-out gates (called QNC^0_f circuits). Our main result is that the
quantum OR operation is in QNC^0_f, which is an affirmative answer to the
question of Hoyer and Spalek. In sharp contrast to the strict hierarchy of the
classical complexity classes: NC^0 \subsetneq AC^0 \subsetneq TC^0, our result
with Hoyer and Spalek's one implies the collapse of the hierarchy of the
corresponding quantum ones: QNC^0_f = QAC^0_f = QTC^0_f. Then, we show that
there exists a constant-depth subquadratic-size quantum circuit for the quantum
threshold operation. This implies the size difference between the QNC^0_f and
QTC^0_f circuits for implementing the same quantum operation. Lastly, we show
that, if the quantum Fourier transform modulo a prime is in QNC^0_f, there
exists a polynomial-time exact classical algorithm for a discrete logarithm
problem using a QNC^0_f oracle. This implies that, under a plausible
assumption, there exists a classically hard problem that is solvable exactly by
a QNC^0_f circuit with gates for the quantum Fourier transform.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.6090</identifier>
 <datestamp>2015-03-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.6090</id><created>2011-12-28</created><authors><author><keyname>Davies</keyname><forenames>Philip</forenames></author><author><keyname>Newell</keyname><forenames>David</forenames></author><author><keyname>Davies</keyname><forenames>Abigail</forenames></author><author><keyname>Karagozlu</keyname><forenames>Damla</forenames></author></authors><title>Multi-Connected Ontologies</title><categories>cs.DL</categories><comments>8 pages, 13 figures, submitted to IARIA MMEDIA2012 Conference,
  Chamonix, France</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ontologies have been used for the purpose of bringing system and consistency
to subject and knowledge areas. We present a criticism of the present
mathematical structure of ontologies and indicate that they are not sufficient
in their present form to represent the many different valid expressions of a
subject knowledge domain. We propose an alternative structure for ontologies
based on a richer multi connected complex network which contains the present
ontology structure as a projection. We demonstrate how this new multi connected
ontology should be represented as an asymmetric probability matrix.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.6096</identifier>
 <datestamp>2011-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.6096</id><created>2011-12-28</created><authors><author><keyname>Morara</keyname><forenames>Massimo</forenames></author><author><keyname>Mauro</keyname><forenames>Jacopo</forenames></author><author><keyname>Gabbrielli</keyname><forenames>Maurizio</forenames></author></authors><title>Solving XCSP problems by using Gecode</title><categories>cs.PL</categories><comments>5 pages, http://ceur-ws.org/Vol-810 CILC 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Gecode is one of the most efficient libraries that can be used for constraint
solving. However, using it requires dealing with C++ programming details. On
the other hand several formats for representing constraint networks have been
proposed. Among them, XCSP has been proposed as a format based on XML which
allows us to represent constraints defined either extensionally or
intensionally, permits global constraints and has been the standard format of
the international competition of constraint satisfaction problems solvers. In
this paper we present a plug-in for solving problems specified in XCSP by
exploiting the Gecode solver. This is done by dynamically translating
constraints into Gecode library calls, thus avoiding the need to interact with
C++.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.6098</identifier>
 <datestamp>2011-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.6098</id><created>2011-12-28</created><authors><author><keyname>Carrascal</keyname><forenames>Juan Pablo</forenames></author><author><keyname>Riederer</keyname><forenames>Christopher</forenames></author><author><keyname>Erramilli</keyname><forenames>Vijay</forenames></author><author><keyname>Cherubini</keyname><forenames>Mauro</forenames></author><author><keyname>de Oliveira</keyname><forenames>Rodrigo</forenames></author></authors><title>Your browsing behavior for a Big Mac: Economics of Personal Information
  Online</title><categories>cs.HC cs.CY cs.SI</categories><comments>11 Pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most online services (Google, Facebook etc.) operate by providing a service
to users for free, and in return they collect and monetize personal information
(PI) of the users. This operational model is inherently economic, as the &quot;good&quot;
being traded and monetized is PI. This model is coming under increased scrutiny
as online services are moving to capture more PI of users, raising serious
privacy concerns. However, little is known on how users valuate different types
of PI while being online, as well as the perceptions of users with regards to
exploitation of their PI by online service providers.
  In this paper, we study how users valuate different types of PI while being
online, while capturing the context by relying on Experience Sampling. We were
able to extract the monetary value that 168 participants put on different
pieces of PI. We find that users value their PI related to their offline
identities more (3 times) than their browsing behavior. Users also value
information pertaining to financial transactions and social network
interactions more than activities like search and shopping. We also found that
while users are overwhelmingly in favor of exchanging their PI in return for
improved online services, they are uncomfortable if these same providers
monetize their PI.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.6108</identifier>
 <datestamp>2012-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.6108</id><created>2011-12-28</created><authors><author><keyname>Crokidakis</keyname><forenames>Nuno</forenames></author><author><keyname>Forgerini</keyname><forenames>Fabricio L.</forenames></author></authors><title>Competition among reputations in the 2D Sznajd model: Spontaneous
  emergence of democratic states</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><comments>7 pages, 8 figures, contribution to the 2nd School and Conference on
  Computational Modelling, Rio de Janeiro, September 2010 - to appear in
  Brazilian Journal of Physics</comments><journal-ref>Braz. J. Phys. 42, 125 (2012)</journal-ref><doi>10.1007/s13538-011-0055-9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a modification in the Sznajd sociophysics model defined on the
square lattice. For this purpose, we consider reputation-a mechanism limiting
the agents' persuasive power. The reputation is introduced as a time-dependent
score, which can be positive or negative. This mechanism avoids dictatorship
(full consensus, all spins parallel) for a wide range of model parameters. We
consider two different situations: case 1, in which the agents' reputation
increases for each persuaded neighbor, and case 2, in which the agents'
reputation increases for each persuasion and decreases when a neighbor keeps
his opinion. Our results show that the introduction of reputation avoids full
consensus even for initial densities of up spins greater than 1/2. The
relaxation times follow a log-normal-like distribution in both cases, but they
are larger in case 2 due to the competition among reputations. In addition, we
show that the usual phase transition occurs and depends on the initial
concentration $d$ of individuals with the same opinion, but the critical points
$d_{c}$ in the two cases are different.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.6117</identifier>
 <datestamp>2011-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.6117</id><created>2011-12-28</created><authors><author><keyname>Seong-Ho</keyname><affiliation>Paul</affiliation></author><author><keyname>Hur</keyname></author><author><keyname>Rao</keyname><forenames>Bhaskar D.</forenames></author><author><keyname>Rim</keyname><forenames>Min-Joong</forenames></author><author><keyname>Zeidler</keyname><forenames>James R.</forenames></author></authors><title>On the optimal frequency selectivity to maximize multiuser diversity in
  an OFDMA scheduling system</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider an orthogonal frequency division multiple access (OFDMA)
scheduling system. A scheduling unit block consists of contiguous multiple
subcarriers. Users are scheduled based on their block average throughput in a
proportional fair way. The multiuser diversity gain increases with the degree
and dynamic range of channel fluctuations. %Lack of diversity in a limited
frequency selective channel may decrease the sum rate. However, a decrease of
the block average throughput in a too much selective channel may lessen the sum
rate as well. In this paper, we first study optimal channel selectivity in view
of maximizing the maximum of the block average throughput of an arbitrary user.
Based on this study, we then propose a method to determine a per-user optimal
cyclic delay when cyclic delay diversity (CDD) is used to enhance the sum rate
by increasing channel selectivity for a limited fluctuating channel. We show
that the proposed technique achieves better performance than a conventional
fixed cyclic delay scheme and that the throughput is very close to the optimal
sum rate possible with CDD.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.6128</identifier>
 <datestamp>2012-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.6128</id><created>2011-12-28</created><updated>2012-01-09</updated><authors><author><keyname>Gallozzi</keyname><forenames>Stefano</forenames></author></authors><title>Holographic Grid Cloud, a futurable high storage technology for the next
  generation astronomical facilities</title><categories>astro-ph.IM cs.DC</categories><comments>15 pages, 5 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the immediate future holographic technology will be available to store a
very large amount of data in HVD (Holographic Versatile Disk) devices. This
technology make extensive use of the WORM (Write-Once-Read-Many) paradigm: this
means that such devices allow for a simultaneous and parallel reading of
millions of volumetric pixels (i.e. voxels). This characteristic will make
accessible wherever the acquired data from a telescope (or satellite) in a
quite-simultaneous way.
  With the support of this new technology the aim of this paper is to identify
the guidelines for the implementation of a distributed RAID system, a sort of
&quot;storage block&quot; to distribute astronomical data over different geographical
sites acting as a single remote device as an effect of a property of
distributed computing, the abstraction of resources. The end user will only
have to take care on connecting in a opportune and secure mode (using personal
certificates) to the remote device and will have access to all (or part) of
this potential technology.
  A Storage-Block+Services engineered on such a platform will allow rapid
scalability of resources, creating a &quot;network-distributed cloud&quot; of services
for an instrument or a mission. It is recommended the use of a dedicated
grid-infrastructure within each single cloud to enhance some critical tasks and
to speed-up services working on the redundant, encrypted and compressed
scientific data. The power, the accessibility, the degree of parallelism and of
redundancy will only depend on the number of distributed storage-blocks: the
higher this amount, the greater will be throughput of the IT-system. A
storage-block of this kind is a meeting point between two technologies and two
antithetical computing paradigms: the Grid-Computing and Cloud-Computing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.6140</identifier>
 <datestamp>2013-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.6140</id><created>2011-12-28</created><updated>2013-11-14</updated><authors><author><keyname>Samal</keyname><forenames>R.</forenames></author><author><keyname>Valla</keyname><forenames>T.</forenames></author></authors><title>The guarding game is E-complete</title><categories>cs.GT cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The guarding game is a game in which several cops try to guard a region in a
(directed or undirected) graph against Robber. Robber and the cops are placed
on the vertices of the graph; they take turns in moving to adjacent vertices
(or staying), cops inside the guarded region, Robber on the remaining vertices
(the robber-region). The goal of Robber is to enter the guarded region at a
vertex with no cop on it. The problem is to determine whether for a given graph
and given number of cops the cops are able to prevent Robber from entering the
guarded region. Fomin et al. [Fomin, Golovach, Hall, Mihalak, Vicari, Widmayer:
How to Guard a Graph? Algorithmica 61(4), 839--856 (2011)] proved that the
problem is NP-complete when the robber-region is restricted to a tree. Further
they prove that is it PSPACE-complete when the robber-region is restricted to a
directed acyclic graph, and they ask about the problem complexity for arbitrary
graphs. In this paper we prove that the problem is E-complete for arbitrary
directed graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.6160</identifier>
 <datestamp>2013-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.6160</id><created>2011-12-28</created><updated>2013-08-03</updated><authors><author><keyname>Turner</keyname><forenames>Katharine</forenames></author></authors><title>Cone fields and topological sampling in manifolds with bounded curvature</title><categories>cs.CG math.AT math.DG</categories><comments>20 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Often noisy point clouds are given as an approximation of a particular
compact set of interest. A finite point cloud is a compact set. This paper
proves a reconstruction theorem which gives a sufficient condition, as a bound
on the Hausdorff distance between two compact sets, for when certain offsets of
these two sets are homotopic in terms of the absence of {\mu}-critical points
in an annular region. Since an offset of a set deformation retracts to the set
itself provided that there are no critical points of the distance function
nearby, we can use this theorem to show when the offset of a point cloud is
homotopy equivalent to the set it is sampled from. The ambient space can be any
Riemannian manifold but we focus on ambient manifolds which have nowhere
negative curvature. In the process, we prove stability theorems for
{\mu}-critical points when the ambient space is a manifold.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.6178</identifier>
 <datestamp>2011-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.6178</id><created>2011-12-28</created><authors><author><keyname>Simon</keyname><forenames>Laurent S. R.</forenames><affiliation>INRIA - IRISA</affiliation></author><author><keyname>Vincent</keyname><forenames>Emmanuel</forenames><affiliation>INRIA - IRISA</affiliation></author></authors><title>A general framework for online audio source separation</title><categories>cs.SD</categories><comments>International conference on Latente Variable Analysis and Signal
  Separation (2012)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of online audio source separation. Existing
algorithms adopt either a sliding block approach or a stochastic gradient
approach, which is faster but less accurate. Also, they rely either on spatial
cues or on spectral cues and cannot separate certain mixtures. In this paper,
we design a general online audio source separation framework that combines both
approaches and both types of cues. The model parameters are estimated in the
Maximum Likelihood (ML) sense using a Generalised Expectation Maximisation
(GEM) algorithm with multiplicative updates. The separation performance is
evaluated as a function of the block size and the step size and compared to
that of an offline algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.6179</identifier>
 <datestamp>2013-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.6179</id><created>2011-12-28</created><authors><author><keyname>Poinsot</keyname><forenames>Laurent</forenames><affiliation>LIPN</affiliation></author></authors><title>The Tutte-Grothendieck group of a convergent alphabetic rewriting system</title><categories>cs.DM math.GR</categories><comments>17 pages</comments><proxy>ccsd</proxy><journal-ref>ISRN Combinatorics 2013 (2013) 1-11</journal-ref><doi>10.1155/2013/574578</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The two operations, deletion and contraction of an edge, on multigraphs
directly lead to the Tutte polynomial which satisfies a universal problem. As
observed by Brylawski in terms of order relations, these operations may be
interpreted as a particular instance of a general theory which involves
universal invariants like the Tutte polynomial, and a universal group, called
the Tutte-Grothendieck group. In this contribution, Brylawski's theory is
extended in two ways: first of all, the order relation is replaced by a string
rewriting system, and secondly, commutativity by partial commutations (that
permits a kind of interpolation between non commutativity and full
commutativity). This allows us to clarify the relations between the semigroup
subject to rewriting and the Tutte-Grothendieck group: the later is actually
the Grothendieck group completion of the former, up to the free adjunction of a
unit (this was even not mention by Brylawski), and normal forms may be seen as
universal invariants. Moreover we prove that such universal constructions are
also possible in case of a non convergent rewriting system, outside the scope
of Brylawski's work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.6209</identifier>
 <datestamp>2012-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.6209</id><created>2011-12-28</created><updated>2012-07-12</updated><authors><author><keyname>Le</keyname><forenames>Quoc V.</forenames></author><author><keyname>Ranzato</keyname><forenames>Marc'Aurelio</forenames></author><author><keyname>Monga</keyname><forenames>Rajat</forenames></author><author><keyname>Devin</keyname><forenames>Matthieu</forenames></author><author><keyname>Chen</keyname><forenames>Kai</forenames></author><author><keyname>Corrado</keyname><forenames>Greg S.</forenames></author><author><keyname>Dean</keyname><forenames>Jeff</forenames></author><author><keyname>Ng</keyname><forenames>Andrew Y.</forenames></author></authors><title>Building high-level features using large scale unsupervised learning</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of building high- level, class-specific feature
detectors from only unlabeled data. For example, is it possible to learn a face
detector using only unlabeled images? To answer this, we train a 9-layered
locally connected sparse autoencoder with pooling and local contrast
normalization on a large dataset of images (the model has 1 bil- lion
connections, the dataset has 10 million 200x200 pixel images downloaded from
the Internet). We train this network using model parallelism and asynchronous
SGD on a clus- ter with 1,000 machines (16,000 cores) for three days. Contrary
to what appears to be a widely-held intuition, our experimental re- sults
reveal that it is possible to train a face detector without having to label
images as containing a face or not. Control experiments show that this feature
detector is robust not only to translation but also to scaling and out-of-plane
rotation. We also find that the same network is sensitive to other high-level
concepts such as cat faces and human bod- ies. Starting with these learned
features, we trained our network to obtain 15.8% accu- racy in recognizing
20,000 object categories from ImageNet, a leap of 70% relative im- provement
over the previous state-of-the-art.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.6210</identifier>
 <datestamp>2012-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.6210</id><created>2011-12-28</created><updated>2012-02-03</updated><authors><author><keyname>Marjane</keyname><forenames>Abdelaziz</forenames></author></authors><title>Vectorial FCSR constructed on totally ramified extension of the p-adic
  numbers</title><categories>cs.IT cs.CR math.IT</categories><comments>18 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we introduce a vectorial conception of d-FCSRs to build these
registers over any finite field. We describe the structure of d-vectorial FCSRs
and we develop an analysis to obtain basic properties like periodicity and the
existence of maximal length sequences. To illustrate these vectorial d-FCSRs,
we present simple examples and we compare with those of Goresky, Klapper and
Xu. Keywords: LFSR, FCSR, vectorial FCSR, d-FCSR, sequences, periodicity,
p-adic, ?-adic, maximal period.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.6212</identifier>
 <datestamp>2015-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.6212</id><created>2011-12-28</created><updated>2012-05-31</updated><authors><author><keyname>Zhao</keyname><forenames>Xiaochuan</forenames></author><author><keyname>Tu</keyname><forenames>Sheng-Yuan</forenames></author><author><keyname>Sayed</keyname><forenames>Ali H.</forenames></author></authors><title>Diffusion Adaptation over Networks under Imperfect Information Exchange
  and Non-stationary Data</title><categories>math.OC cs.SI physics.soc-ph stat.CO</categories><comments>36 pages, 7 figures, to appear in IEEE Transactions on Signal
  Processing, June 2012</comments><doi>10.1109/TSP.2012.2192928</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Adaptive networks rely on in-network and collaborative processing among
distributed agents to deliver enhanced performance in estimation and inference
tasks. Information is exchanged among the nodes, usually over noisy links. The
combination weights that are used by the nodes to fuse information from their
neighbors play a critical role in influencing the adaptation and tracking
abilities of the network. This paper first investigates the mean-square
performance of general adaptive diffusion algorithms in the presence of various
sources of imperfect information exchanges, quantization errors, and model
non-stationarities. Among other results, the analysis reveals that link noise
over the regression data modifies the dynamics of the network evolution in a
distinct way, and leads to biased estimates in steady-state. The analysis also
reveals how the network mean-square performance is dependent on the combination
weights. We use these observations to show how the combination weights can be
optimized and adapted. Simulation results illustrate the theoretical findings
and match well with theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.6219</identifier>
 <datestamp>2011-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.6219</id><created>2011-12-28</created><authors><author><keyname>Rafi</keyname><forenames>Muhammad</forenames></author><author><keyname>Shaikh</keyname><forenames>M. Shahid</forenames></author><author><keyname>Farooq</keyname><forenames>Amir</forenames></author></authors><title>Document Clustering based on Topic Maps</title><categories>cs.IR cs.AI</categories><journal-ref>International Journal of Computer Applications 12(1):32-36,
  December 2010</journal-ref><doi>10.5120/1640-2204</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Importance of document clustering is now widely acknowledged by researchers
for better management, smart navigation, efficient filtering, and concise
summarization of large collection of documents like World Wide Web (WWW). The
next challenge lies in semantically performing clustering based on the semantic
contents of the document. The problem of document clustering has two main
components: (1) to represent the document in such a form that inherently
captures semantics of the text. This may also help to reduce dimensionality of
the document, and (2) to define a similarity measure based on the semantic
representation such that it assigns higher numerical values to document pairs
which have higher semantic relationship. Feature space of the documents can be
very challenging for document clustering. A document may contain multiple
topics, it may contain a large set of class-independent general-words, and a
handful class-specific core-words. With these features in mind, traditional
agglomerative clustering algorithms, which are based on either Document Vector
model (DVM) or Suffix Tree model (STC), are less efficient in producing results
with high cluster quality. This paper introduces a new approach for document
clustering based on the Topic Map representation of the documents. The document
is being transformed into a compact form. A similarity measure is proposed
based upon the inferred information through topic maps data and structures. The
suggested method is implemented using agglomerative hierarchal clustering and
tested on standard Information retrieval (IR) datasets. The comparative
experiment reveals that the proposed approach is effective in improving the
cluster quality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.6220</identifier>
 <datestamp>2012-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.6220</id><created>2011-12-28</created><updated>2012-08-07</updated><authors><author><keyname>Mahajan</keyname><forenames>Aditya</forenames></author></authors><title>Optimal decentralized control of coupled subsystems with control sharing</title><categories>cs.SY math.OC</categories><comments>Submitted to IEEE Transactions on Automatic Control</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Subsystems that are coupled due to dynamics and costs arise naturally in
various communication applications. In many such applications the control
actions are shared between different control stations giving rise to a
\emph{control sharing} information structure. Previous studies of
control-sharing have concentrated on the linear quadratic Gaussian setup and a
solution approach tailored to continuous valued control actions. In this paper
a three step solution approach for finite valued control actions is presented.
In the first step, a person-by-person approach is used to identify redundant
data or a sufficient statistic for local information at each control station.
In the second step, the common-information based approach of Nayyar et al.\
(2011) is used to find a sufficient statistic for the common information shared
between all control stations and to obtain a dynamic programming decomposition.
In the third step, the specifics of the model are used to simplify the
sufficient statistic and the dynamic program. As an example, an exact solution
of a two-user multiple access broadcast system is presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.6222</identifier>
 <datestamp>2012-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.6222</id><created>2011-12-28</created><updated>2012-01-10</updated><authors><author><keyname>Rafi</keyname><forenames>Muhammad</forenames></author><author><keyname>Maujood</keyname><forenames>M.</forenames></author><author><keyname>Fazal</keyname><forenames>M. M.</forenames></author><author><keyname>Ali</keyname><forenames>S. M.</forenames></author></authors><title>A comparison of two suffix tree-based document clustering algorithms</title><categories>cs.IR cs.AI</categories><comments>Information and Emerging Technologies (ICIET), 2010 International
  Conference</comments><doi>10.1109/2010.5625688</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Document clustering as an unsupervised approach extensively used to navigate,
filter, summarize and manage large collection of document repositories like the
World Wide Web (WWW). Recently, focuses in this domain shifted from traditional
vector based document similarity for clustering to suffix tree based document
similarity, as it offers more semantic representation of the text present in
the document. In this paper, we compare and contrast two recently introduced
approaches to document clustering based on suffix tree data model. The first is
an Efficient Phrase based document clustering, which extracts phrases from
documents to form compact document representation and uses a similarity measure
based on common suffix tree to cluster the documents. The second approach is a
frequent word/word meaning sequence based document clustering, it similarly
extracts the common word sequence from the document and uses the common
sequence/ common word meaning sequence to perform the compact representation,
and finally, it uses document clustering approach to cluster the compact
documents. These algorithms are using agglomerative hierarchical document
clustering to perform the actual clustering step, the difference in these
approaches are mainly based on extraction of phrases, model representation as a
compact document, and the similarity measures used for clustering. This paper
investigates the computational aspect of the two algorithms, and the quality of
results they produced.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.6231</identifier>
 <datestamp>2011-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.6231</id><created>2011-12-29</created><authors><author><keyname>Chen</keyname><forenames>Shuangping</forenames></author><author><keyname>Li</keyname><forenames>Jun</forenames></author><author><keyname>Zhou</keyname><forenames>Mi</forenames></author></authors><title>Low and Upper Bound of Approximate Sequence for the Entropy Rate of
  Binary Hidden Markov Processes</title><categories>cs.IT math.IT</categories><comments>6 pages, in Chinese</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the paper, the approximate sequence for entropy of some binary hidden
Markov models has been found to have two bound sequences, the low bound
sequence and the upper bound sequence. The error bias of the approximate
sequence is bound by a geometric sequence with a scale factor less than 1 which
decreases quickly to zero. It helps to understand the convergence of entropy
rate of generic hidden Markov models, and it provides a theoretical base for
estimating the entropy rate of some hidden Markov models at any accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.6234</identifier>
 <datestamp>2013-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.6234</id><created>2011-12-29</created><updated>2013-01-05</updated><authors><author><keyname>Xu</keyname><forenames>Weiyu</forenames></author><author><keyname>Wang</keyname><forenames>Meng</forenames></author><author><keyname>Cai</keyname><forenames>Jianfeng</forenames></author><author><keyname>Tang</keyname><forenames>Ao</forenames></author></authors><title>Sparse Recovery from Nonlinear Measurements with Applications in Bad
  Data Detection for Power Networks</title><categories>cs.IT cs.LG cs.SY math.IT</categories><comments>journal. arXiv admin note: substantial text overlap with
  arXiv:1105.0442</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the problem of sparse recovery from nonlinear
measurements, which has applications in state estimation and bad data detection
for power networks. An iterative mixed $\ell_1$ and $\ell_2$ convex program is
used to estimate the true state by locally linearizing the nonlinear
measurements. When the measurements are linear, through using the almost
Euclidean property for a linear subspace, we derive a new performance bound for
the state estimation error under sparse bad data and additive observation
noise. As a byproduct, in this paper we provide sharp bounds on the almost
Euclidean property of a linear subspace, using the &quot;escape-through-the-mesh&quot;
theorem from geometric functional analysis. When the measurements are
nonlinear, we give conditions under which the solution of the iterative
algorithm converges to the true state even though the locally linearized
measurements may not be the actual nonlinear measurements. We numerically
evaluate our iterative convex programming approach to perform bad data
detections in nonlinear electrical power networks problems. We are able to use
semidefinite programming to verify the conditions for convergence of the
proposed iterative sparse recovery algorithms from nonlinear measurements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.6235</identifier>
 <datestamp>2011-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.6235</id><created>2011-12-29</created><authors><author><keyname>Arias-Castro</keyname><forenames>Ery</forenames></author></authors><title>Detecting a Vector Based on Linear Measurements</title><categories>math.ST cs.IT math.IT stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a situation where the state of a system is represented by a
real-valued vector. Under normal circumstances, the vector is zero, while an
event manifests as non-zero entries in this vector, possibly few. Our interest
is in the design of algorithms that can reliably detect events (i.e., test
whether the vector is zero or not) with the least amount of information. We
place ourselves in a situation, now common in the signal processing literature,
where information about the vector comes in the form of noisy linear
measurements. We derive information bounds in an active learning setup and
exhibit some simple near-optimal algorithms. In particular, our results show
that the task of detection within this setting is at once much easier, simpler
and different than the tasks of estimation and support recovery.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.6254</identifier>
 <datestamp>2011-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.6254</id><created>2011-12-29</created><authors><author><keyname>Pal</keyname><forenames>Soumitra</forenames></author><author><keyname>Ranade</keyname><forenames>Abhiram</forenames></author></authors><title>Scheduling Light-trails in WDM Rings</title><categories>cs.DC</categories><comments>19 pages, 4 figures, Submitted to Journal of Parallel and Distributed
  Computing (JPDC) on June 22, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of scheduling communication on optical WDM
(wavelength division multiplexing) networks using the light-trails technology.
We seek to design scheduling algorithms such that the given transmission
requests can be scheduled using minimum number of wavelengths (optical
channels). We provide algorithms and close lower bounds for two versions of the
problem on an $n$ processor linear array/ring network. In the {\em stationary}
version, the pattern of transmissions (given) is assumed to not change over
time. For this, a simple lower bound is $c$, the congestion or the maximum
total traffic required to pass through any link. We give an algorithm that
schedules the transmissions using $O(c+\log{n})$ wavelengths. We also show a
pattern for which $\Omega(c+\log{n}/\log\log{n})$ wavelengths are needed. In
the {\em on-line} version, the transmissions arrive and depart dynamically, and
must be scheduled without upsetting the previously scheduled transmissions. For
this case we give an on-line algorithm which has competitive ratio
$\Theta(\log{n})$. We show that this is optimal in the sense that every on-line
algorithm must have competitive ratio $\Omega(\log{n})$. We also give an
algorithm that appears to do well in simulation (for the classes of traffic we
consider), but which has competitive ratio between $\Omega(\log^2n/\log
\log{n})$ and $O(\log^2n)$. We present detailed simulations of both our
algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.6255</identifier>
 <datestamp>2011-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.6255</id><created>2011-12-29</created><authors><author><keyname>Cygan</keyname><forenames>Marek</forenames></author><author><keyname>Pilipczuk</keyname><forenames>Marcin</forenames></author><author><keyname>Pilipczuk</keyname><forenames>Micha&#x142;</forenames></author></authors><title>On group feedback vertex set parameterized by the size of the cutset</title><categories>cs.DS</categories><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the parameterized complexity of a robust generalization of the
classical Feedback Vertex Set problem, namely the Group Feedback Vertex Set
problem; we are given a graph G with edges labeled with group elements, and the
goal is to compute the smallest set of vertices that hits all cycles of G that
evaluate to a non-null element of the group. This problem generalizes not only
Feedback Vertex Set, but also Subset Feedback Vertex Set, Multiway Cut and Odd
Cycle Transversal. Completing the results of Guillemot [Discr. Opt. 2011], we
provide a fixed-parameter algorithm for the parameterization by the size of the
cutset only. Our algorithm works even if the group is given as a
polynomial-time oracle.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.6256</identifier>
 <datestamp>2012-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.6256</id><created>2011-12-29</created><updated>2012-01-31</updated><authors><author><keyname>Li</keyname><forenames>Mingfei</forenames></author><author><keyname>Ma</keyname><forenames>Christoffer</forenames></author><author><keyname>Ning</keyname><forenames>Li</forenames></author></authors><title>(1+epsilon)-Distance Oracle for Planar Labeled Graph</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a vertex-labeled graph, each vertex $v$ is attached with a label from a
set of labels. The vertex-label query desires the length of the shortest path
from the given vertex to the set of vertices with the given label. We show how
to construct an oracle if the given graph is planar, such that
$O(\frac{1}{\epsilon}n\log n)$ storing space is needed, and any vertex-label
query could be answered in $O(\frac{1}{\epsilon}\log n\log \rho)$ time with
stretch $1+\epsilon$. $\rho$ is the radius of the given graph, which is half of
the diameter. For the case that $\rho = O(\log n)$, we construct an oracle that
achieves $O(\log n)$ query time, without changing the order of storing space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.6263</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.6263</id><created>2011-12-29</created><updated>2012-05-25</updated><authors><author><keyname>Bardet</keyname><forenames>Magali</forenames></author><author><keyname>Faug&#xe8;re</keyname><forenames>Jean-Charles</forenames></author><author><keyname>Salvy</keyname><forenames>Bruno</forenames></author><author><keyname>Spaenlehauer</keyname><forenames>Pierre-Jean</forenames></author></authors><title>On the Complexity of Solving Quadratic Boolean Systems</title><categories>cs.SC cs.CR</categories><comments>25 pages</comments><msc-class>68W40, 13P10, 13P15, 94A60</msc-class><acm-class>I.1.2; D.4.6</acm-class><journal-ref>Journal of Complexity, vol. 29, n. 1, pp. 53-75, 2013</journal-ref><doi>10.1016/j.jco.2012.07.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A fundamental problem in computer science is to find all the common zeroes of
$m$ quadratic polynomials in $n$ unknowns over $\mathbb{F}_2$. The
cryptanalysis of several modern ciphers reduces to this problem. Up to now, the
best complexity bound was reached by an exhaustive search in $4\log_2 n\,2^n$
operations. We give an algorithm that reduces the problem to a combination of
exhaustive search and sparse linear algebra. This algorithm has several
variants depending on the method used for the linear algebra step. Under
precise algebraic assumptions on the input system, we show that the
deterministic variant of our algorithm has complexity bounded by
$O(2^{0.841n})$ when $m=n$, while a probabilistic variant of the Las Vegas type
has expected complexity $O(2^{0.792n})$. Experiments on random systems show
that the algebraic assumptions are satisfied with probability very close to~1.
We also give a rough estimate for the actual threshold between our method and
exhaustive search, which is as low as~200, and thus very relevant for
cryptographic applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.6265</identifier>
 <datestamp>2013-04-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.6265</id><created>2011-12-29</created><updated>2013-04-22</updated><authors><author><keyname>Hrubes</keyname><forenames>Pavel</forenames></author><author><keyname>Tzameret</keyname><forenames>Iddo</forenames></author></authors><title>Short Proofs for the Determinant Identities</title><categories>cs.CC cs.LO</categories><comments>46 pages; Revision and corrections to Section 7. Addition of short
  proofs for the Cayley-Hamilton theorem. Other minor changes</comments><msc-class>68Q17, 68Q15, 03F20, 03D15, 15A15</msc-class><acm-class>F.1.3; F.2.2; F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study arithmetic proof systems P_c(F) and P_f(F) operating with arithmetic
circuits and arithmetic formulas, respectively, that prove polynomial
identities over a field F. We establish a series of structural theorems about
these proof systems, the main one stating that P_c(F) proofs can be balanced:
if a polynomial identity of syntactic degree d and depth k has a P_c(F) proof
of size s, then it also has a P_c(F) proof of size poly(s,d) and depth
O(k+\log^2 d + \log d\cd \log s). As a corollary, we obtain a quasipolynomial
simulation of P_c(F) by P_f(F), for identities of a polynomial syntactic
degree.
  Using these results we obtain the following: consider the identities det(XY)
= det(X)det(Y) and det(Z)= z_{11}... z_{nn}, where X,Y and Z are nxn square
matrices and Z is a triangular matrix with z_{11},..., z_{nn} on the diagonal
(and det is the determinant polynomial). Then we can construct a
polynomial-size arithmetic circuit det such that the above identities have
P_c(F) proofs of polynomial-size and O(\log^2 n) depth. Moreover, there exists
an arithmetic formula det of size n^{O(\log n)} such that the above identities
have P_f(F) proofs of size n^{O(\log n)}.
  This yields a solution to a basic open problem in propositional proof
complexity, namely, whether there are polynomial-size NC^2-Frege proofs for the
determinant identities and the hard matrix identities, as considered, e.g., in
Soltys and Cook (2004) (cf., Beame and Pitassi (1998)). We show that matrix
identities like AB=I {\to} BA=I (for matrices over the two element field) as
well as basic properties of the determinant have polynomial-size NC^2-Frege
proofs, and quasipolynomial-size Frege proofs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.6269</identifier>
 <datestamp>2011-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.6269</id><created>2011-12-29</created><authors><author><keyname>M.</keyname><forenames>Dhananjay D.</forenames></author><author><keyname>Rao</keyname><forenames>C. V. Guru</forenames></author><author><keyname>Muralikrishna</keyname><forenames>I. V.</forenames></author></authors><title>Automated PolyU Palmprint sample Registration and Coarse Classification</title><categories>cs.CV</categories><comments>6 PAGES</comments><journal-ref>IJCSI International Journal of Computer Science Issues, Vol. 8,
  Issue 6, No 3, November 2011 ISSN (Online): 1694-0814 www.IJCSI.org</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Biometric based authentication for secured access to resources has gained
importance, due to their reliable, invariant and discriminating features.
Palmprint is one such biometric entity. Prior to classification and
identification registering a sample palmprint is an important activity. In this
paper we propose a computationally effective method for automated registration
of samples from PlolyU palmprint database. In our approach we preprocess the
sample and trace the border to find the nearest point from center of sample.
Angle between vector representing the nearest point and vector passing through
the center is used for automated palm sample registration. The angle of
inclination between start and end point of heart line and life line is used for
basic classification of palmprint samples in left class and right class.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.6275</identifier>
 <datestamp>2014-02-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.6275</id><created>2011-12-29</created><updated>2012-02-05</updated><authors><author><keyname>Mogavero</keyname><forenames>Fabio</forenames></author><author><keyname>Murano</keyname><forenames>Aniello</forenames></author><author><keyname>Perelli</keyname><forenames>Giuseppe</forenames></author><author><keyname>Vardi</keyname><forenames>Moshe Y.</forenames></author></authors><title>Reasoning About Strategies: On the Model-Checking Problem</title><categories>cs.LO cs.MA math.LO</categories><msc-class>68Q60 (Primary) 03B70 (Secondary) 03B44, 03B60</msc-class><acm-class>F.3.1; F.4.1</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In open systems verification, to formally check for reliability, one needs an
appropriate formalism to model the interaction between agents and express the
correctness of the system no matter how the environment behaves. An important
contribution in this context is given by modal logics for strategic ability, in
the setting of multi-agent games, such as ATL, ATL\star, and the like.
Recently, Chatterjee, Henzinger, and Piterman introduced Strategy Logic, which
we denote here by CHP-SL, with the aim of getting a powerful framework for
reasoning explicitly about strategies. CHP-SL is obtained by using first-order
quantifications over strategies and has been investigated in the very specific
setting of two-agents turned-based games, where a non-elementary model-checking
algorithm has been provided. While CHP-SL is a very expressive logic, we claim
that it does not fully capture the strategic aspects of multi-agent systems. In
this paper, we introduce and study a more general strategy logic, denoted SL,
for reasoning about strategies in multi-agent concurrent games. We prove that
SL includes CHP-SL, while maintaining a decidable model-checking problem. In
particular, the algorithm we propose is computationally not harder than the
best one known for CHP-SL. Moreover, we prove that such a problem for SL is
NonElementarySpace-hard. This negative result has spurred us to investigate
here syntactic fragments of SL, strictly subsuming ATL\star, with the hope of
obtaining an elementary model-checking problem. Among the others, we study the
sublogics SL[NG], SL[BG], and SL[1G]. They encompass formulas in a special
prenex normal form having, respectively, nested temporal goals, Boolean
combinations of goals and, a single goal at a time. About these logics, we
prove that the model-checking problem for SL[1G] is 2ExpTime-complete, thus not
harder than the one for ATL\star.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.6281</identifier>
 <datestamp>2011-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.6281</id><created>2011-12-29</created><authors><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author><author><keyname>Bornmann</keyname><forenames>Lutz</forenames></author></authors><title>Percentile Ranks and the Integrated Impact Indicator (I3)</title><categories>cs.CY</categories><comments>A shorter version appears as a Letter to the Editor of the Journal of
  the American Society for Information Science and Technology (in press)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We tested Rousseau's (in press) recent proposal to define percentile classes
in the case of the Integrated Impact Indicator (I3) so that the largest number
in a set always belongs to the highest (100th) percentile rank class. In the
case a set of nine uncited papers and one with citation, however, the uncited
papers would all be placed in the 90th percentile rank. A lowly-cited document
set would thus be advantaged when compared with a highly-cited one.
Notwithstanding our reservations, we extended the program for computing I3 in
Web-of-Science data (at http://www.leydesdorff.net/software/i3) with this
option; the quantiles without a correction are now the default. As Rousseau
mentions, excellence indicators (e.g., the top-10%) can be considered as
special cases of I3: only two percentile rank classes are distinguished for the
evaluation. Both excellence and impact indicators can be tested statistically
using the z-test for independent proportions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.6286</identifier>
 <datestamp>2012-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.6286</id><created>2011-12-29</created><authors><author><keyname>Vlieger</keyname><forenames>Esther</forenames></author><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author></authors><title>Visualization and Analysis of Frames in Collections of Messages: Content
  Analysis and the Measurement of Meaning</title><categories>cs.CL</categories><comments>Forthcoming in: Manuel Mora, Ovsei Gelman, Annette Steenkamp, and
  Maresh S. Raisinghani (Eds.), Research Methodologies, Innovations and
  Philosophies in Systems Engineering and Information Systems, Hershey PA:
  Information Science Reference, 2012, pp. 322-340, doi:
  10.4018/978-1-4666-0179-6.ch16</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A step-to-step introduction is provided on how to generate a semantic map
from a collection of messages (full texts, paragraphs or statements) using
freely available software and/or SPSS for the relevant statistics and the
visualization. The techniques are discussed in the various theoretical contexts
of (i) linguistics (e.g., Latent Semantic Analysis), (ii) sociocybernetics and
social systems theory (e.g., the communication of meaning), and (iii)
communication studies (e.g., framing and agenda-setting). We distinguish
between the communication of information in the network space (social network
analysis) and the communication of meaning in the vector space. The vector
space can be considered a generated as an architecture by the network of
relations in the network space; words are then not only related, but also
positioned. These positions are expected rather than observed and therefore one
can communicate meaning. Knowledge can be generated when these meanings can
recursively be communicated and therefore also further codified.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.6291</identifier>
 <datestamp>2011-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.6291</id><created>2011-12-29</created><authors><author><keyname>Masci</keyname><forenames>Jonathan</forenames></author><author><keyname>Migliore</keyname><forenames>Davide</forenames></author><author><keyname>Bronstein</keyname><forenames>Michael M.</forenames></author><author><keyname>Schmidhuber</keyname><forenames>J&#xfc;rgen</forenames></author></authors><title>Descriptor learning for omnidirectional image matching</title><categories>cs.CV cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Feature matching in omnidirectional vision systems is a challenging problem,
mainly because complicated optical systems make the theoretical modelling of
invariance and construction of invariant feature descriptors hard or even
impossible. In this paper, we propose learning invariant descriptors using a
training set of similar and dissimilar descriptor pairs. We use the
similarity-preserving hashing framework, in which we are trying to map the
descriptor data to the Hamming space preserving the descriptor similarity on
the training set. A neural network is used to solve the underlying optimization
problem. Our approach outperforms not only straightforward descriptor matching,
but also state-of-the-art similarity-preserving hashing methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.6320</identifier>
 <datestamp>2015-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.6320</id><created>2011-12-23</created><updated>2012-06-12</updated><authors><author><keyname>Hassani</keyname><forenames>S. Hamed</forenames></author><author><keyname>Macris</keyname><forenames>Nicolas</forenames></author><author><keyname>Urbanke</keyname><forenames>Rudiger</forenames></author></authors><title>Threshold Saturation in Spatially Coupled Constraint Satisfaction
  Problems</title><categories>cs.CC cond-mat.stat-mech cs.IT math.IT</categories><doi>10.1007/s10955-012-0664-x</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider chains of random constraint satisfaction models that are
spatially coupled across a finite window along the chain direction. We
investigate their phase diagram at zero temperature using the survey
propagation formalism and the interpolation method. We prove that the SAT-UNSAT
phase transition threshold of an infinite chain is identical to the one of the
individual standard model, and is therefore not affected by spatial coupling.
We compute the survey propagation complexity using population dynamics as well
as large degree approximations, and determine the survey propagation threshold.
We find that a clustering phase survives coupling. However, as one increases
the range of the coupling window, the survey propagation threshold increases
and saturates towards the phase transition threshold. We also briefly discuss
other aspects of the problem. Namely, the condensation threshold is not
affected by coupling, but the dynamic threshold displays saturation towards the
condensation one. All these features may provide a new avenue for obtaining
better provable algorithmic lower bounds on phase transition thresholds of the
individual standard model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.6326</identifier>
 <datestamp>2011-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.6326</id><created>2011-12-29</created><authors><author><keyname>Machicao</keyname><forenames>Marina Jeaneth</forenames></author><author><keyname>Marco</keyname><forenames>Anderson G.</forenames></author><author><keyname>Bruno</keyname><forenames>Odemir M.</forenames></author></authors><title>Chaotic Encryption Method Based on Life-Like Cellular Automata</title><categories>math.DS cs.CR physics.data-an</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a chaotic encryption method based on Cellular Automata(CA),
specifically on the family called the &quot;Life-Like&quot; type. Thus, the encryption
process lying on the pseudo-random numbers generated (PRNG) by each CA's
evolution, which transforms the password as the initial conditions to encrypt
messages. Moreover, is explored the dynamical behavior of CA to reach a &quot;good&quot;
quality as PRNG based on measures to quantify &quot;how chaotic a dynamical system
is&quot;, through the combination of the entropy, Lyapunov exponent, and Hamming
distance. Finally, we present the detailed security analysis based on
experimental tests: DIEHARD and ENT suites, as well as Fouriers Power Spectrum,
used as a security criteria.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.6335</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.6335</id><created>2011-12-29</created><updated>2011-12-30</updated><authors><author><keyname>Sviridenko</keyname><forenames>Alexander</forenames></author><author><keyname>Shcherbina</keyname><forenames>Oleg</forenames></author></authors><title>Block local elimination algorithms for solving sparse discrete
  optimization problems</title><categories>cs.DM</categories><comments>arXiv admin note: substantial text overlap with arXiv:0901.3882</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Block elimination algorithms for solving sparse discrete optimization
problems are considered. The numerical example is provided. The benchmarking is
done in order to define real computational capabilities of block elimination
algorithms combined with SYMPHONY solver. Analysis of the results show that for
sufficiently large number of blocks and small enough size of separators between
the blocks for staircase integer linear programming problem the local
elimination algorithms in combination with a solver for solving subproblems in
blocks allow to solve such problems much faster than used solver itself for
solving the whole problem. Also the capabilities of postoptimal analysis (warm
starting) are considered for solving packages of integer linear programming
problems for corresponding blocks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.6344</identifier>
 <datestamp>2011-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.6344</id><created>2011-12-29</created><authors><author><keyname>Hossain</keyname><forenames>Ashraf</forenames></author></authors><title>On the Impact of Energy Dissipation Model on Characteristic Distance in
  Wireless Networks</title><categories>cs.IT math.IT</categories><comments>3 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we investigate the dependency of characteristic distance on
energy dissipation model. Both the many-to-one and any-to-any communication
paradigm have been presented for performance analysis. Characteristic distance
has been derived for three different cases. This study will be useful for
designing an energy-efficient wireless network where nodes are
energy-constrained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.6361</identifier>
 <datestamp>2011-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.6361</id><created>2011-12-29</created><authors><author><keyname>Colini-Baldeschi</keyname><forenames>Riccardo</forenames></author><author><keyname>Henzinger</keyname><forenames>Monika</forenames></author><author><keyname>Leonardi</keyname><forenames>Stefano</forenames></author><author><keyname>Starnberger</keyname><forenames>Martin</forenames></author></authors><title>On Multiple Round Sponsored Search Auctions with Budgets</title><categories>cs.GT</categories><comments>28 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a sponsored search auction the advertisement slots on a search result page
are generally ordered by click-through rate. Bidders have a valuation, which is
usually assumed to be linear in the click-through rate, a budget constraint,
and receive at most one slot per search result page (round). We study
multi-round sponsored search auctions, where the different rounds are linked
through the budget constraints of the bidders and the valuation of a bidder for
all rounds is the sum of the valuations for the individual rounds. All
mechanisms published so far either study one-round sponsored search auctions or
the setting where every round has only one slot and all slots have the same
click-through rate, which is identical to a multi-item auction.
  This paper contains the following three results: (1) We give the first
mechanism for the multi-round sponsored search problem where different slots
have different click-through rates. Our mechanism is incentive compatible in
expectation, individually rational in expectation, Pareto optimal in
expectation, and also ex-post Pareto optimal for each realized outcome. (2)
Additionally we study the combinatorial setting, where each bidder is only
interested in a subset of the rounds. We give a deterministic, incentive
compatible, individually rational, and Pareto optimal mechanism for the setting
where all slots have the same click-through rate. (3) We present an
impossibility result for auctions where bidders have diminishing marginal
valuations. Specifically, we show that even for the multi-unit (one slot per
round) setting there is no incentive compatible, individually rational, and
Pareto optimal mechanism for private diminishing marginal valuations and public
budgets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.6367</identifier>
 <datestamp>2011-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.6367</id><created>2011-12-29</created><authors><author><keyname>Rahman</keyname><forenames>Md. Saifur</forenames></author><author><keyname>Wagner</keyname><forenames>Aaron B.</forenames></author></authors><title>Rate Region of the Vector Gaussian One-Helper Source-Coding Problem</title><categories>cs.IT math.IT</categories><comments>36 pages; 2 figures; submitted to IEEE Transactions on Information
  Theory; material in this paper was presented in part at the 49th Annual
  Allerton Conference on Communications, Control, and Computing, University of
  Illinois, Urbana-Champaign, Sept. 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We determine the rate region of the vector Gaussian one-helper source-coding
problem under a covariance matrix distortion constraint. The rate region is
achieved by a simple scheme that separates the lossy vector quantization from
the lossless spatial compression. The converse is established by extending and
combining three analysis techniques that have been employed in the past to
obtain partial results for the problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.6371</identifier>
 <datestamp>2011-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.6371</id><created>2011-12-29</created><authors><author><keyname>Fabbri</keyname><forenames>Ricardo</forenames></author><author><keyname>Gon&#xe7;alves</keyname><forenames>Wesley N.</forenames></author><author><keyname>Lopes</keyname><forenames>Francisco J. P.</forenames></author><author><keyname>Bruno</keyname><forenames>Odemir M.</forenames></author></authors><title>Multi-q Analysis of Image Patterns</title><categories>physics.data-an cs.AI cs.CV physics.comp-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the use of the Tsallis Entropy versus the classic
Boltzmann-Gibbs-Shannon entropy for classifying image patterns. Given a
database of 40 pattern classes, the goal is to determine the class of a given
image sample. Our experiments show that the Tsallis entropy encoded in a
feature vector for different $q$ indices has great advantage over the
Boltzmann-Gibbs-Shannon entropy for pattern classification, boosting
recognition rates by a factor of 3. We discuss the reasons behind this success,
shedding light on the usefulness of the Tsallis entropy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.6382</identifier>
 <datestamp>2011-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.6382</id><created>2011-12-21</created><authors><author><keyname>Guo</keyname><forenames>Feng</forenames></author></authors><title>SDPTools: High Precision SDP Solver in Maple</title><categories>math.OC cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Semidefinite programs are an important class of convex optimization problems.
It can be solved efficiently by SDP solvers in Matlab, such as SeDuMi, SDPT3,
DSDP. However, since we are running fixed precision SDP solvers in Matlab, for
some applications, due to the numerical error, we can not get good results.
SDPTools is a Maple package to solve SDP in high precision. We apply SDPTools
to the certification of the global optimum of rational functions. For the Rumps
Model Problem, we obtain the best numerical results so far.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.6384</identifier>
 <datestamp>2011-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.6384</id><created>2011-12-29</created><authors><author><keyname>Moortgat</keyname><forenames>Michael</forenames></author><author><keyname>Moot</keyname><forenames>Richard</forenames></author></authors><title>Proof nets for the Lambek-Grishin calculus</title><categories>cs.CL</categories><comments>Revised version to appear as a chapter in E. Grefenstette, C. Heunen,
  and M. Sadrzadeh (eds.) 'Compositional Methods in Physics and Linguistics',
  Oxford University Press</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Grishin's generalization of Lambek's Syntactic Calculus combines a
non-commutative multiplicative conjunction and its residuals (product, left and
right division) with a dual family: multiplicative disjunction, right and left
difference. Interaction between these two families takes the form of linear
distributivity principles. We study proof nets for the Lambek-Grishin calculus
and the correspondence between these nets and unfocused and focused versions of
its sequent calculus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.6399</identifier>
 <datestamp>2011-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.6399</id><created>2011-12-29</created><authors><author><keyname>Boots</keyname><forenames>Byron</forenames></author><author><keyname>Gordon</keyname><forenames>Geoffrey J.</forenames></author></authors><title>Two-Manifold Problems</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, there has been much interest in spectral approaches to learning
manifolds---so-called kernel eigenmap methods. These methods have had some
successes, but their applicability is limited because they are not robust to
noise. To address this limitation, we look at two-manifold problems, in which
we simultaneously reconstruct two related manifolds, each representing a
different view of the same data. By solving these interconnected learning
problems together and allowing information to flow between them, two-manifold
algorithms are able to succeed where a non-integrated approach would fail: each
view allows us to suppress noise in the other, reducing bias in the same way
that an instrumental variable allows us to remove bias in a {linear}
dimensionality reduction problem. We propose a class of algorithms for
two-manifold problems, based on spectral decomposition of cross-covariance
operators in Hilbert space. Finally, we discuss situations where two-manifold
problems are useful, and demonstrate that solving a two-manifold problem can
aid in learning a nonlinear dynamical system from limited data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.6411</identifier>
 <datestamp>2012-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.6411</id><created>2011-12-29</created><authors><author><keyname>Johnson</keyname><forenames>Christopher C.</forenames></author><author><keyname>Jalali</keyname><forenames>Ali</forenames></author><author><keyname>Ravikumar</keyname><forenames>Pradeep</forenames></author></authors><title>High-dimensional Sparse Inverse Covariance Estimation using Greedy
  Methods</title><categories>cs.LG math.ST stat.ML stat.TH</categories><comments>Accepted to AI STAT 2012 for Oral Presentation</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider the task of estimating the non-zero pattern of the
sparse inverse covariance matrix of a zero-mean Gaussian random vector from a
set of iid samples. Note that this is also equivalent to recovering the
underlying graph structure of a sparse Gaussian Markov Random Field (GMRF). We
present two novel greedy approaches to solving this problem. The first
estimates the non-zero covariates of the overall inverse covariance matrix
using a series of global forward and backward greedy steps. The second
estimates the neighborhood of each node in the graph separately, again using
greedy forward and backward steps, and combines the intermediate neighborhoods
to form an overall estimate. The principal contribution of this paper is a
rigorous analysis of the sparsistency, or consistency in recovering the
sparsity pattern of the inverse covariance matrix. Surprisingly, we show that
both the local and global greedy methods learn the full structure of the model
with high probability given just $O(d\log(p))$ samples, which is a
\emph{significant} improvement over state of the art $\ell_1$-regularized
Gaussian MLE (Graphical Lasso) that requires $O(d^2\log(p))$ samples. Moreover,
the restricted eigenvalue and smoothness conditions imposed by our greedy
methods are much weaker than the strong irrepresentable conditions required by
the $\ell_1$-regularization based methods. We corroborate our results with
extensive simulations and examples, comparing our local and global greedy
methods to the $\ell_1$-regularized Gaussian MLE as well as the Neighborhood
Greedy method to that of nodewise $\ell_1$-regularized linear regression
(Neighborhood Lasso).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1112.6414</identifier>
 <datestamp>2012-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1112.6414</id><created>2011-12-29</created><updated>2012-04-22</updated><authors><author><keyname>Xie</keyname><forenames>J.</forenames></author><author><keyname>Emenheiser</keyname><forenames>J.</forenames></author><author><keyname>Kirby</keyname><forenames>M.</forenames></author><author><keyname>Sreenivasan</keyname><forenames>S.</forenames></author><author><keyname>Szymanski</keyname><forenames>B. K.</forenames></author><author><keyname>Korniss</keyname><forenames>G.</forenames></author></authors><title>Evolution of opinions on social networks in the presence of competing
  committed groups</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><comments>23 pages: 15 pages + 7 figures (main text), 8 pages + 1 figure + 1
  table (supplementary info)</comments><journal-ref>PLoS ONE 7(3): e33215 (2012)</journal-ref><doi>10.1371/journal.pone.0033215</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Public opinion is often affected by the presence of committed groups of
individuals dedicated to competing points of view. Using a model of pairwise
social influence, we study how the presence of such groups within social
networks affects the outcome and the speed of evolution of the overall opinion
on the network. Earlier work indicated that a single committed group within a
dense social network can cause the entire network to quickly adopt the group's
opinion (in times scaling logarithmically with the network size), so long as
the committed group constitutes more than about 10% of the population (with the
findings being qualitatively similar for sparse networks as well). Here we
study the more general case of opinion evolution when two groups committed to
distinct, competing opinions $A$ and $B$, and constituting fractions $p_A$ and
$p_B$ of the total population respectively, are present in the network. We show
for stylized social networks (including Erd\H{o}s-R\'enyi random graphs and
Barab\'asi-Albert scale-free networks) that the phase diagram of this system in
parameter space $(p_A,p_B)$ consists of two regions, one where two stable
steady-states coexist, and the remaining where only a single stable
steady-state exists. These two regions are separated by two fold-bifurcation
(spinodal) lines which meet tangentially and terminate at a cusp (critical
point). We provide further insights to the phase diagram and to the nature of
the underlying phase transitions by investigating the model on infinite
(mean-field limit), finite complete graphs and finite sparse networks. For the
latter case, we also derive the scaling exponent associated with the
exponential growth of switching times as a function of the distance from the
critical point.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0011</identifier>
 <datestamp>2012-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0011</id><created>2011-12-29</created><authors><author><keyname>Savov</keyname><forenames>Ivan</forenames></author><author><keyname>Wilde</keyname><forenames>Mark M.</forenames></author><author><keyname>Vu</keyname><forenames>Mai</forenames></author></authors><title>Partial decode-forward for quantum relay channels</title><categories>quant-ph cs.IT math.IT</categories><comments>7 pages, submission to the 2012 International Symposium on
  Information Theory (ISIT 2012), Boston, MA, USA</comments><journal-ref>Proceedings of the 2012 IEEE International Symposium on
  Information Theory (ISIT 2012), pages 731-735, Cambridge, MA, USA</journal-ref><doi>10.1109/ISIT.2012.6284655</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A relay channel is one in which a Source and Destination use an intermediate
Relay station in order to improve communication rates. We propose the study of
relay channels with classical inputs and quantum outputs and prove that a
&quot;partial decode and forward&quot; strategy is achievable. We divide the channel uses
into many blocks and build codes in a randomized, block-Markov manner within
each block. The Relay performs a standard Holevo-Schumacher-Westmoreland
quantum measurement on each block in order to decode part of the Source's
message and then forwards this partial message in the next block. The
Destination performs a novel &quot;sliding-window&quot; quantum measurement on two
adjacent blocks in order to decode the Source's message. This strategy achieves
non-trivial rates for classical communication over a quantum relay channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0017</identifier>
 <datestamp>2012-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0017</id><created>2011-12-29</created><updated>2012-02-01</updated><authors><author><keyname>Fiziev</keyname><forenames>Plamen P.</forenames></author><author><keyname>Staicova</keyname><forenames>Denitsa R.</forenames></author></authors><title>Solving systems of transcendental equations involving the Heun functions</title><categories>cs.NA astro-ph.IM gr-qc</categories><comments>17 pages, 4 figures. Typos corrected, one figure added, some sections
  revised. The article is a rework of the internal report arXiv:1005.5375</comments><report-no>SU-TH/29-12-2011</report-no><msc-class>G.1.0, G.1.5</msc-class><journal-ref>American Journal of Computational Mathematics Vol. 02 : 02, pp.95
  (2012)</journal-ref><doi>10.4236/ajcm.2012.22013</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Heun functions have wide application in modern physics and are expected
to succeed the hypergeometrical functions in the physical problems of the 21st
century. The numerical work with those functions, however, is complicated and
requires filling the gaps in the theory of the Heun functions and also,
creating new algorithms able to work with them efficiently.
  We propose a new algorithm for solving a system of two nonlinear
transcendental equations with two complex variables based on the M\&quot;uller
algorithm. The new algorithm is particularly useful in systems featuring the
Heun functions and for them, the new algorithm gives distinctly better results
than Newton's and Broyden's methods.
  As an example for its application in physics, the new algorithm was used to
find the quasi-normal modes (QNM) of Schwarzschild black hole described by the
Regge-Wheeler equation. The numerical results obtained by our method are
compared with the already published QNM frequencies and are found to coincide
to a great extent with them. Also discussed are the QNM of the Kerr black hole,
described by the Teukolsky Master equation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0022</identifier>
 <datestamp>2013-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0022</id><created>2011-12-23</created><updated>2013-10-03</updated><authors><author><keyname>Chaari</keyname><forenames>Lotfi</forenames></author><author><keyname>M&#xe9;riaux</keyname><forenames>S&#xe9;bastien</forenames></author><author><keyname>Pesquet</keyname><forenames>Jean-Christophe</forenames></author><author><keyname>Ciuciu</keyname><forenames>Philippe</forenames></author></authors><title>Spatio-temporal wavelet regularization for parallel MRI reconstruction:
  application to functional MRI</title><categories>stat.AP cs.CV physics.med-ph</categories><comments>arXiv admin note: substantial text overlap with arXiv:1103.3532</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Parallel MRI is a fast imaging technique that enables the acquisition of
highly resolved images in space or/and in time. The performance of parallel
imaging strongly depends on the reconstruction algorithm, which can proceed
either in the original k-space (GRAPPA, SMASH) or in the image domain
(SENSE-like methods). To improve the performance of the widely used SENSE
algorithm, 2D- or slice-specific regularization in the wavelet domain has been
deeply investigated. In this paper, we extend this approach using 3D-wavelet
representations in order to handle all slices together and address
reconstruction artifacts which propagate across adjacent slices. The gain
induced by such extension (3D-Unconstrained Wavelet Regularized -SENSE:
3D-UWR-SENSE) is validated on anatomical image reconstruction where no temporal
acquisition is considered. Another important extension accounts for temporal
correlations that exist between successive scans in functional MRI (fMRI). In
addition to the case of 2D+t acquisition schemes addressed by some other
methods like kt-FOCUSS, our approach allows us to deal with 3D+t acquisition
schemes which are widely used in neuroimaging. The resulting 3D-UWR-SENSE and
4D-UWR-SENSE reconstruction schemes are fully unsupervised in the sense that
all regularization parameters are estimated in the maximum likelihood sense on
a reference scan. The gain induced by such extensions is illustrated on both
anatomical and functional image reconstruction, and also measured in terms of
statistical sensitivity for the 4D-UWR-SENSE approach during a fast
event-related fMRI protocol. Our 4D-UWR-SENSE algorithm outperforms the SENSE
reconstruction at the subject and group levels (15 subjects) for different
contrasts of interest (eg, motor or computation tasks) and using different
parallel acceleration factors (R=2 and R=4) on 2x2x3mm3 EPI images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0023</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0023</id><created>2011-12-29</created><authors><author><keyname>Siek</keyname><forenames>Jeremy G.</forenames></author><author><keyname>Vitousek</keyname><forenames>Michael M.</forenames></author><author><keyname>Turner</keyname><forenames>Jonathan D.</forenames></author></authors><title>Effects for Funargs</title><categories>cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Stack allocation and first-class functions don't naturally mix together. In
this paper we show that a type and effect system can be the detergent that
helps these features form a nice emulsion. Our interest in this problem comes
from our work on the Chapel language, but this problem is also relevant to
lambda expressions in C++ and blocks in Objective C. The difficulty in mixing
first-class functions and stack allocation is a tension between safety,
efficiency, and simplicity. To preserve safety, one must worry about functions
outliving the variables they reference: the classic upward funarg problem.
There are systems which regain safety but lose programmer-predictable
efficiency, and ones that provide both safety and efficiency, but give up
simplicity by exposing regions to the programmer. In this paper we present a
simple design that combines a type and effect system, for safety, with
function-local storage, for control over efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0024</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0024</id><created>2011-12-29</created><authors><author><keyname>Silkensen</keyname><forenames>Erik</forenames></author><author><keyname>Siek</keyname><forenames>Jeremy G.</forenames></author></authors><title>Well-typed Islands Parse Faster</title><categories>cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the problem of specifying and parsing the syntax of
domain-specific languages (DSLs) in a modular, user-friendly way. That is, we
want to enable the design of composable DSLs that combine the natural syntax of
external DSLs with the easy implementation of internal DSLs. The challenge in
parsing composable DSLs is that the composition of several (individually
unambiguous) languages is likely to contain ambiguities. In this paper, we
present the design of a system that uses a type-oriented variant of island
parsing to efficiently parse the syntax of composable DSLs. In particular, we
show how type-oriented island parsing is constant time with respect to the
number of DSLs imported. We also show how to use our tool to implement DSLs on
top of a host language such as Typed Racket.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0027</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0027</id><created>2011-12-29</created><authors><author><keyname>Siek</keyname><forenames>Jeremy G.</forenames></author></authors><title>The C++0x &quot;Concepts&quot; Effort</title><categories>cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  C++0x is the working title for the revision of the ISO standard of the C++
programming language that was originally planned for release in 2009 but that
was delayed to 2011. The largest language extension in C++0x was &quot;concepts&quot;,
that is, a collection of features for constraining template parameters. In
September of 2008, the C++ standards committee voted the concepts extension
into C++0x, but then in July of 2009, the committee voted the concepts
extension back out of C++0x.
  This article is my account of the technical challenges and debates within the
&quot;concepts&quot; effort in the years 2003 to 2009. To provide some background, the
article also describes the design space for constrained parametric
polymorphism, or what is colloquially know as constrained generics. While this
article is meant to be generally accessible, the writing is aimed toward
readers with background in functional programming and programming language
theory. This article grew out of a lecture at the Spring School on Generic and
Indexed Programming at the University of Oxford, March 2010.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0035</identifier>
 <datestamp>2014-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0035</id><created>2011-12-29</created><updated>2014-06-03</updated><authors><author><keyname>Lerner</keyname><forenames>Vladimir S.</forenames></author></authors><title>The information path functional approach for solution of a controllable
  stochastic problem</title><categories>cs.SY cs.IT math.DS math.IT nlin.AO</categories><comments>39 pages including 5 figures</comments><msc-class>93B52, 93E03, 93E15, 93E30</msc-class><acm-class>H.1.1</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We study a stochastic control system, described by Ito controllable equation,
and evaluate the solutions by an entropy functional (EF), defined by the
equation functions of controllable drift and diffusion. Considering a control
problem for this functional, we solve the EF control variation problem (VP),
which leads to both a dynamic approximation of the process entropy functional
by an information path functional (IPF) and information dynamic model (IDM) of
the stochastic process. The IPF variation equations allow finding the optimal
control functions, applied to both stochastic system and the IDM for joint
solution of the identification and optimal control problems, combined with
state consolidation. In this optimal dual strategy, the IPF optimum predicts
each current control action not only in terms of total functional path goal,
but also by setting for each following control action the renovated values of
this functional controllable drift and diffusion, identified during the optimal
movement, which concurrently correct this goal. The VP information invariants
allow optimal encoding of the identified dynamic model operator and control.
The introduced method of cutting off the process by applying an impulse control
estimates the cutoff information, accumulated by the process inner connections
between its states. It has shown that such a functional information measure
contains more information than the sum of Shannon entropies counted for all
process separated states, and provides information measure of Feller kernel.
Examples illustrate the procedure of solving these problems, which has been
implemented in practice. Key words: Entropy and information path functionals,
variation equations, information invariants, controllable dynamics, impulse
controls, cutting off the diffusion process, identification, cooperation,
encoding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0040</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0040</id><created>2011-12-23</created><authors><author><keyname>Grend&#xe1;r</keyname><forenames>M.</forenames></author><author><keyname>&#x160;kutov&#xe1;</keyname><forenames>J.</forenames></author><author><keyname>&#x160;pitalsk&#xfd;</keyname><forenames>V.</forenames></author></authors><title>Spam filtering by quantitative profiles</title><categories>cs.IR stat.AP</categories><comments>supplementary material including the commented R source code can be
  found at http://www.savbb.sk/~grendar/spam/Supplement.html</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Instead of the 'bag-of-words' representation, in the quantitative profile
approach to spam filtering and email categorization, an email is represented by
an m-dimensional vector of numbers, with m fixed in advance. Inspired by Sroufe
et al. [Sroufe, P., Phithakkitnukoon, S., Dantu, R., and Cangussu, J. (2010).
Email shape analysis. In \emph{LNCS}, 5935, pp. 18-29] two instances of
quantitative profiles are considered: line profile and character profile.
Performance of these profiles is studied on the TREC 2007, CEAS 2008 and a
private corpuses. At low computational costs, the two quantitative profiles
achieve performance that is at least comparable to that of heuristic rules and
naive Bayes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0041</identifier>
 <datestamp>2012-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0041</id><created>2011-12-29</created><updated>2012-02-24</updated><authors><author><keyname>Cheng</keyname><forenames>Zhu</forenames></author><author><keyname>Wang</keyname><forenames>Zhan</forenames></author><author><keyname>Liu</keyname><forenames>Haitao</forenames></author><author><keyname>Ahmadi</keyname><forenames>Majid</forenames></author></authors><title>An Amendment of Fast Subspace Tracking Methods</title><categories>math.NA cs.NE</categories><comments>4 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tuning stepsize between convergence rate and steady state error level or
stability is a problem in some subspace tracking schemes. Methods in DPM and
OJA class may show sparks in their steady state error sometimes, even with a
rather small stepsize. By a study on the schemes' updating formula, it is found
that the update only happens in a specific plane but not all the subspace
basis. Through an analysis on relationship between the vectors in that plane,
an amendment as needed is made on the algorithm routine to fix the problem by
constricting the stepsize at every update step. The simulation confirms
elimination of the sparks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0043</identifier>
 <datestamp>2012-03-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0043</id><created>2011-12-29</created><updated>2012-03-09</updated><authors><author><keyname>Francis</keyname><forenames>Mathew C.</forenames></author><author><keyname>Gon&#xe7;alves</keyname><forenames>Daniel</forenames></author><author><keyname>Ochem</keyname><forenames>Pascal</forenames></author></authors><title>The Maximum Clique Problem in Multiple Interval Graphs</title><categories>cs.DM cs.CC</categories><comments>22 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multiple interval graphs are variants of interval graphs where instead of a
single interval, each vertex is assigned a set of intervals on the real line.
We study the complexity of the MAXIMUM CLIQUE problem in several classes of
multiple interval graphs. The MAXIMUM CLIQUE problem, or the problem of finding
the size of the maximum clique, is known to be NP-complete for $t$-interval
graphs when $t\geq 3$ and polynomial-time solvable when $t=1$. The problem is
also known to be NP-complete in $t$-track graphs when $t\geq 4$ and
polynomial-time solvable when $t\leq 2$. We show that MAXIMUM CLIQUE is already
NP-complete for unit 2-interval graphs and unit 3-track graphs. Further, we
show that the problem is APX-complete for 2-interval graphs, 3-track graphs,
unit 3-interval graphs and unit 4-track graphs. We also introduce two new
classes of graphs called $t$-circular interval graphs and $t$-circular track
graphs and study the complexity of the MAXIMUM CLIQUE problem in them. On the
positive side, we present a polynomial time $t$-approximation algorithm for
WEIGHTED MAXIMUM CLIQUE on $t$-interval graphs, improving earlier work with
approximation ratio $4t$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0066</identifier>
 <datestamp>2012-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0066</id><created>2011-12-30</created><authors><author><keyname>Alam</keyname><forenames>Md. Jawaherul</forenames></author><author><keyname>Biedl</keyname><forenames>Therese</forenames></author><author><keyname>Felsner</keyname><forenames>Stefan</forenames></author><author><keyname>Kaufmann</keyname><forenames>Michael</forenames></author><author><keyname>Kobourov</keyname><forenames>Stephen G.</forenames></author><author><keyname>Ueckerdt</keyname><forenames>Torsten</forenames></author></authors><title>Computing Cartograms with Optimal Complexity</title><categories>cs.DM cs.CG cs.DS</categories><comments>18 pages, 7 figures</comments><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a rectilinear dual of a planar graph vertices are represented by simple
rectilinear polygons and edges are represented by side-contact between the
corresponding polygons. A rectilinear dual is called a cartogram if the area of
each region is equal to a pre-specified weight of the corresponding vertex. The
complexity of a cartogram is determined by the maximum number of corners (or
sides) required for any polygon. In a series of papers the polygonal complexity
of such representations for maximal planar graphs has been reduced from the
initial 40 to 34, then to 12 and very recently to the currently best known 10.
Here we describe a construction with 8-sided polygons, which is optimal in
terms of polygonal complexity as 8-sided polygons are sometimes necessary.
Specifically, we show how to compute the combinatorial structure and how to
refine the representation into an area-universal rectangular layout in linear
time. The exact cartogram can be computed from the area-universal rectangular
layout with numerical iteration, or can be approximated with a hill-climbing
heuristic.
  We also describe an alternative construction for Hamiltonian maximal planar
graphs, which allows us to directly compute the cartograms in linear time.
Moreover, we prove that even for Hamiltonian graphs 8-sided rectilinear
polygons are necessary, by constructing a non-trivial lower bound example. The
complexity of the cartograms can be reduced to 6 if the Hamiltonian path has
the extra property that it is one-legged, as in outer-planar graphs. Thus, we
have optimal representations (in terms of both polygonal complexity and running
time) for Hamiltonian maximal planar and maximal outer-planar graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0067</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0067</id><created>2011-12-30</created><authors><author><keyname>Vallam</keyname><forenames>Rohith Dwarakanath</forenames></author><author><keyname>Subramanian</keyname><forenames>C. A.</forenames></author><author><keyname>Narayanam</keyname><forenames>Ramasuri</forenames></author><author><keyname>Narahari</keyname><forenames>Y.</forenames></author><author><keyname>Narasimha</keyname><forenames>Srinath</forenames></author></authors><title>Topologies and Price of Stability of Complex Strategic Networks with
  Localized Payoffs : Analytical and Simulation Studies</title><categories>cs.SI cs.DM physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze a network formation game in a strategic setting where payoffs of
individuals depend only on their immediate neighbourhood. We call these payoffs
as localized payoffs. In this game, the payoff of each individual captures (1)
the gain from immediate neighbors, (2) the bridging benefits, and (3) the cost
to form links. This implies that the payoff of each individual can be computed
using only its single-hop neighbourhood information. Based on this simple model
of network formation, our study explores the structure of networks that form,
satisfying one or both of the properties, namely, pairwise stability and
efficiency. We analytically prove the pairwise stability of several interesting
network structures, notably, the complete bi-partite network, complete
equi-k-partite network, complete network and cycle network, under various
configurations of the model. We validate and extend these results through
extensive simulations. We characterize topologies of efficient networks by
drawing upon classical results from extremal graph theory and discover that the
Turan graph (or the complete equi-bi-partite network) is the unique efficient
network under many configurations of parameters. We examine the tradeoffs
between topologies of pairwise stable networks and efficient networks using the
notion of price of stability, which is the ratio of the sum of payoffs of the
players in an optimal pairwise stable network to that of an efficient network.
Interestingly, we find that price of stability is equal to 1 for almost all
configurations of parameters in the proposed model; and for the rest of the
configurations of the parameters, we obtain a lower bound of 0.5 on the price
of stability. This leads to another key insight of this paper: under mild
conditions, efficient networks will form when strategic individuals choose to
add or delete links based on only localized payoffs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0070</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0070</id><created>2011-12-30</created><authors><author><keyname>Zheng</keyname><forenames>Wenni</forenames></author><author><keyname>Bo</keyname><forenames>Pengbo</forenames></author><author><keyname>Liu</keyname><forenames>Yang</forenames></author><author><keyname>Wang</keyname><forenames>Wenping</forenames></author></authors><title>Fast B-spline Curve Fitting by L-BFGS</title><categories>cs.GR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel method for fitting planar B-spline curves to unorganized
data points. In traditional methods, optimization of control points and foot
points are performed in two very time-consuming steps in each iteration: 1)
control points are updated by setting up and solving a linear system of
equations; and 2) foot points are computed by projecting each data point onto a
B-spline curve. Our method uses the L-BFGS optimization method to optimize
control points and foot points simultaneously and therefore it does not need to
perform either matrix computation or foot point projection in every iteration.
As a result, our method is much faster than existing methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0073</identifier>
 <datestamp>2014-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0073</id><created>2011-12-30</created><updated>2014-11-04</updated><authors><author><keyname>Boutsidis</keyname><forenames>Christos</forenames></author></authors><title>On Truncated-SVD-like Sparse Solutions to Least-Squares Problems of
  Arbitrary Dimensions</title><categories>cs.DS math.NA</categories><comments>This paper has been withdrawn by the author. This article has been
  replaced by another submission: arXiv:1312.7499</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe two algorithms for computing a sparse solution to a least-squares
problem where the coefficient matrix can have arbitrary dimensions. We show
that the solution vector obtained by our algorithms is close to the solution
vector obtained via the truncated SVD approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0081</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0081</id><created>2011-12-30</created><authors><author><keyname>Zhang</keyname><forenames>Hao</forenames></author><author><keyname>Liu</keyname><forenames>Yuan</forenames></author><author><keyname>Tao</keyname><forenames>Meixia</forenames></author></authors><title>Resource Allocation with Subcarrier Pairing in OFDMA Two-Way Relay
  Networks</title><categories>cs.IT math.IT</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This study considers an orthogonal frequency-division multiple-access
(OFDMA)-based multi-user two-way relay network where multiple mobile stations
(MSs) communicate with a common base station (BS) via multiple relay stations
(RSs). We study the joint optimization problem of subcarrier-pairing based
relay-power allocation, relay selection, and subcarrier assignment. The problem
is formulated as a mixed integer programming problem. By using the dual method,
we propose an efficient algorithm to solve the problem in an asymptotically
optimal manner. Simulation results show that the proposed method can improve
system performance significantly over the conventional methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0110</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0110</id><created>2011-12-30</created><authors><author><keyname>Shin</keyname><forenames>Joonwoo</forenames></author><author><keyname>Moon</keyname><forenames>Jaekyun</forenames></author></authors><title>Weighted-Sum-Rate-Maximizing Linear Transceiver Filters for the K-User
  MIMO Interference Channel</title><categories>cs.IT math.IT</categories><comments>19 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This letter is concerned with transmit and receive filter optimization for
the K-user MIMO interference channel. Specifically, linear transmit and receive
filter sets are designed which maximize the weighted sum rate while allowing
each transmitter to utilize only the local channel state information. Our
approach is based on extending the existing method of minimizing the weighted
mean squared error (MSE) for the MIMO broadcast channel to the K-user
interference channel at hand. For the case of the individual transmitter power
constraint, however, a straightforward generalization of the existing method
does not reveal a viable solution. It is in fact shown that there exists no
closed-form solution for the transmit filter but simple one-dimensional
parameter search yields the desired solution. Compared to the direct filter
optimization using gradient-based search, our solution requires considerably
less computational complexity and a smaller amount of feedback resources while
achieving essentially the same level of weighted sum rate. A modified filter
design is also presented which provides desired robustness in the presence of
channel uncertainty
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0119</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0119</id><created>2011-12-30</created><authors><author><keyname>Lin</keyname><forenames>Chi</forenames></author><author><keyname>Wu</keyname><forenames>Guowei</forenames></author><author><keyname>Xia</keyname><forenames>Feng</forenames></author><author><keyname>Li</keyname><forenames>Mingchu</forenames></author><author><keyname>Yao</keyname><forenames>Lin</forenames></author><author><keyname>Pei</keyname><forenames>Zhongyi</forenames></author></authors><title>Energy Efficient Ant Colony Algorithms for Data Aggregation in Wireless
  Sensor Networks</title><categories>cs.NI</categories><comments>To appear in Journal of Computer and System Sciences</comments><msc-class>68M14</msc-class><acm-class>C.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a family of ant colony algorithms called DAACA for data
aggregation has been presented which contains three phases: the initialization,
packet transmission and operations on pheromones. After initialization, each
node estimates the remaining energy and the amount of pheromones to compute the
probabilities used for dynamically selecting the next hop. After certain rounds
of transmissions, the pheromones adjustment is performed periodically, which
combines the advantages of both global and local pheromones adjustment for
evaporating or depositing pheromones. Four different pheromones adjustment
strategies are designed to achieve the global optimal network lifetime, namely
Basic-DAACA, ES-DAACA, MM-DAACA and ACS-DAACA. Compared with some other data
aggregation algorithms, DAACA shows higher superiority on average degree of
nodes, energy efficiency, prolonging the network lifetime, computation
complexity and success ratio of one hop transmission. At last we analyze the
characteristic of DAACA in the aspects of robustness, fault tolerance and
scalability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0120</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0120</id><created>2011-12-30</created><authors><author><keyname>Chen</keyname><forenames>Zhikui</forenames></author><author><keyname>Xia</keyname><forenames>Feng</forenames></author><author><keyname>Huang</keyname><forenames>Tao</forenames></author><author><keyname>Bu</keyname><forenames>Fanyu</forenames></author><author><keyname>Wang</keyname><forenames>Haozhe</forenames></author></authors><title>A Localization Method for the Internet of Things</title><categories>cs.NI</categories><comments>To appear in Journal of Supercomputing. arXiv admin note: substantial
  text overlap with arXiv:1011.3097</comments><msc-class>68M14</msc-class><acm-class>C.2</acm-class><doi>10.1007/s11227-011-0693-2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many localization algorithms and systems have been developed by means of
wireless sensor networks for both indoor and outdoor environments. To achieve
higher localization accuracy, extra hardware equipments are utilized by most of
the existing localization solutions, which increase the cost and considerably
limit the location-based applications. The Internet of Things (IOT) integrates
many technologies, such as Internet, Zigbee, Bluetooth, infrared, WiFi, GPRS,
3G, etc, which can enable different ways to obtain the location information of
various objects. Location-based service is a primary service of the IOT, while
localization accuracy is a key issue. In this paper, a higher accuracy
localization scheme is proposed which can effectively satisfy diverse
requirements for many indoor and outdoor location services. The proposed scheme
composes of two phases: 1) partition phase, in which the target region is split
into small grids; 2) localization refinement phase, in which a higher accuracy
of localization can be obtained by applying an algorithm designed in the paper.
A trial system is set up to verify correctness of the proposed scheme and
furthermore to illustrate its feasibility and availability. The experimental
results show that the proposed scheme can improve the localization accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0127</identifier>
 <datestamp>2013-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0127</id><created>2011-12-30</created><updated>2013-06-21</updated><authors><author><keyname>Avron</keyname><forenames>Haim</forenames></author><author><keyname>Boutsidis</keyname><forenames>Christos</forenames></author></authors><title>Faster Subset Selection for Matrices and Applications</title><categories>cs.DS cs.NA</categories><comments>To appear in SIAM Journal on Matrix Analysis and Applications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study subset selection for matrices defined as follows: given a matrix
$\matX \in \R^{n \times m}$ ($m &gt; n$) and an oversampling parameter $k$ ($n \le
k \le m$), select a subset of $k$ columns from $\matX$ such that the
pseudo-inverse of the subsampled matrix has as smallest norm as possible. In
this work, we focus on the Frobenius and the spectral matrix norms. We describe
several novel (deterministic and randomized) approximation algorithms for this
problem with approximation bounds that are optimal up to constant factors.
Additionally, we show that the combinatorial problem of finding a low-stretch
spanning tree in an undirected graph corresponds to subset selection, and
discuss various implications of this reduction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0140</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0140</id><created>2011-12-30</created><authors><author><keyname>Bhadauria</keyname><forenames>Vijendra Singh</forenames></author><author><keyname>Sharma</keyname><forenames>Sanjeev</forenames></author><author><keyname>Patel</keyname><forenames>Ravindra</forenames></author></authors><title>A Comparative Study of Location Management Schemes: Challenges and
  Guidelines</title><categories>cs.NI</categories><comments>7 pages, 3 figures</comments><journal-ref>International Journal on Computer Science and Engineering (IJCSE),
  ISSN : 0975-3397, Vol. 3 No. 7 July 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the key issues in mobile communication is to find the current location
of mobile terminal (MT) to deliver the services, which is called as location
management (LM). Increasing users and diverse services demand for a
high-quality skeleton for LM. As an MT moves within a cellular network, it
registers its new location to the nearest base station (BS). When a call
arrives for an MT, the network searches the target MT in the area where it was
last registered. This paper presents comprehensive classification of existing
major LM schemes, their comparative study and factors influencing their
performance. Finally, guidelines for developing and rating a LM scheme are
suggested with the help of LPCIC rule, which is the main contribution of this
paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0148</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0148</id><created>2011-12-30</created><authors><author><keyname>Park</keyname><forenames>Hong Ju</forenames></author><author><keyname>Ayanoglu</keyname><forenames>Ender</forenames></author></authors><title>An Upper Bound to the Marginal PDF of the Ordered Eigenvalues of Wishart
  Matrices</title><categories>cs.IT math.IT</categories><comments>6 pages, 2 figures</comments><report-no>CPCC-111230</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Diversity analysis of a number of Multiple-Input Multiple-Output (MIMO)
applications requires the calculation of the expectation of a function whose
variables are the ordered multiple eigenvalues of a Wishart matrix. In order to
carry out this calculation, we need the marginal pdf of an arbitrary subset of
the ordered eigenvalues. In this letter, we derive an upper bound to the
marginal pdf of the eigenvalues. The derivation is based on the multiple
integration of the well-known joint pdf, which is very complicated due to the
exponential factors of the joint pdf. We suggest an alternative function that
provides simpler calculation of the multiple integration. As a result, the
marginal pdf is shown to be bounded by a multivariate polynomial with a given
degree. After a standard bounding procedure in a Pairwise Error Probability
(PEP) analysis, by applying the marginal pdf to the calculation of the
expectation, the diversity order for a number of MIMO systems can be obtained
in a simple manner. Simulation results that support the analysis are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0160</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0160</id><created>2011-12-30</created><authors><author><keyname>Shan</keyname><forenames>Mei</forenames></author><author><keyname>Xuan</keyname><forenames>Zhou</forenames></author><author><keyname>Yifan</keyname><forenames>Zhu</forenames></author><author><keyname>Zhenghu</keyname><forenames>Zu</forenames></author><author><keyname>Tao</keyname><forenames>Zheng</forenames></author><author><keyname>Boukhanovsky</keyname><forenames>A. V.</forenames></author><author><keyname>Sloot</keyname><forenames>P. M. A</forenames></author></authors><title>Simulating City-level Airborne Infectious Diseases</title><categories>cs.OH physics.soc-ph</categories><comments>20 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the exponential growth in the world population and the constant increase
in human mobility, the danger of outbreaks of epidemics is rising. Especially
in high density urban areas such as public transport and transfer points, where
people come in close proximity of each other, we observe a dramatic increase in
the transmission of airborne viruses and related pathogens. It is essential to
have a good understanding of the `transmission highways' in such areas, in
order to prevent or to predict the spreading of infectious diseases. The
approach we take is to combine as much information as is possible, from all
relevant sources and integrate this in a simulation environment that allows for
scenario testing and decision support. In this paper we lay out a novel
approach to study Urban Airborne Disease spreading by combining traffic
information, with geo-spatial data, infection dynamics and spreading
characteristics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0178</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0178</id><created>2011-12-30</created><authors><author><keyname>Aly</keyname><forenames>Salah A.</forenames></author></authors><title>Distributed Data Collection and Storage Algorithms for Collaborative
  Learning Vision Sensor Devices with Applications to Pilgrimage</title><categories>cs.NI cs.IT math.IT</categories><comments>arXiv admin note: substantial text overlap with arXiv:0908.4419</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work presents novel distributed data collection systems and storage
algorithms for collaborative learning wireless sensor networks (WSNs). In a
large WSN, consider $n$ collaborative sensor devices distributed randomly to
acquire information and learn about a certain field. Such sensors have less
power, small bandwidth, and short memory, and they might disappear from the
network after certain time of operations. The goal of this work is to design
efficient strategies to learn about the field by collecting sensed data from
these $n$ sensors with less computational overhead and efficient storage
encoding operations.
  In this data collection system, we propose two distributed data storage
algorithms (DSA's) to solve this problem with the means of network flooding and
connectivity among sensor devices. In the first algorithm denoted, DSA-I, it's
assumed that the total number of nodes is known for each node in the network.
We show that this algorithm is efficient in terms of the encoding/decoding
operations. Furthermore, every node uses network flooding to disseminate its
data throughout the network using mixing time approximately O(n). In the second
algorithm denoted, DSA-II, it's assumed that the total number of nodes is not
known for each learning sensor, hence dissemination of the data does not depend
on the value of $n$. In this case we show that the encoding operations take
$O(C\mu^2)$, where $\mu$ is the mean degree of the network graph and $C$ is a
system parameter. Performance of these two algorithms match the derived
theoretical results. Finally, we show how to deploy these algorithms for
monitoring and measuring certain phenomenons in American-made camp tents
located in Minna field in south-east side of Makkah.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0205</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0205</id><created>2011-12-30</created><authors><author><keyname>Wu</keyname><forenames>Guowei</forenames></author><author><keyname>Lu</keyname><forenames>Dongze</forenames></author><author><keyname>Xia</keyname><forenames>Feng</forenames></author><author><keyname>Yao</keyname><forenames>Lin</forenames></author></authors><title>A Fault-Tolerant Emergency-Aware Access Control Scheme for
  Cyber-Physical Systems</title><categories>cs.NI cs.DC</categories><msc-class>68M14</msc-class><acm-class>C.2.4</acm-class><journal-ref>Information Technology and Control, 2011, Vol.40, No.1, pp. 29-40</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Access control is an issue of paramount importance in cyber-physical systems
(CPS). In this paper, an access control scheme, namely FEAC, is presented for
CPS. FEAC can not only provide the ability to control access to data in normal
situations, but also adaptively assign emergency-role and permissions to
specific subjects and inform subjects without explicit access requests to
handle emergency situations in a proactive manner. In FEAC, emergency-group and
emergency-dependency are introduced. Emergencies are processed in sequence
within the group and in parallel among groups. A priority and dependency model
called PD-AGM is used to select optimal response-action execution path aiming
to eliminate all emergencies that occurred within the system. Fault-tolerant
access control polices are used to address failure in emergency management. A
case study of the hospital medical care application shows the effectiveness of
FEAC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0206</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0206</id><created>2011-12-30</created><authors><author><keyname>Qiu</keyname><forenames>Tie</forenames></author><author><keyname>Wang</keyname><forenames>Wei</forenames></author><author><keyname>Xia</keyname><forenames>Feng</forenames></author><author><keyname>Wu</keyname><forenames>Guowei</forenames></author><author><keyname>Zhou</keyname><forenames>Yu</forenames></author></authors><title>A Failure Self-recovery Strategy with Balanced Energy Consumption for
  Wireless Ad Hoc Networks</title><categories>cs.NI</categories><comments>To appear in Journal of Computers, Jan 2012</comments><msc-class>68M14</msc-class><acm-class>C.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In energy constrained wireless sensor networks, it is significant to make
full use of the limited energy and maximize the network lifetime even when
facing some unexpected situation. In this paper, all sensor nodes are grouped
into clusters, and for each cluster, it has a mobile cluster head to manage the
whole cluster. We consider an emergent situation that one of the mobile cluster
heads is broken down, and hence the whole cluster is consequently out of work.
An efficient approach is proposed for recovering the failure cluster by
selecting multiple static sensor nodes as the cluster heads to collect packets
and transmit them to the sink node. Improved simulated annealing algorithm is
utilized to achieve the uniform deployment of the cluster heads. The new
cluster heads are dynamically changed in order to keep balanced energy
consumption. Among the new cluster heads, packets are transmitted through
multi-hop forwarding path which is cost-lowest path found by Dijkstra's
algorithm. A balanced energy consumption model is provided to help find the
cost-lowest path and prolong the lifetime of the network. The forwarding path
is updated dynamically according to the cost of the path and residual energy of
the node in that path. The experimental results show that the failure cluster
is recovered and the lifetime of the cluster is prolonged.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0207</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0207</id><created>2011-12-30</created><authors><author><keyname>Wu</keyname><forenames>Guowei</forenames></author><author><keyname>Xia</keyname><forenames>Feng</forenames></author><author><keyname>Yao</keyname><forenames>Lin</forenames></author><author><keyname>Zhang</keyname><forenames>Yan</forenames></author><author><keyname>Zhu</keyname><forenames>Yanwei</forenames></author></authors><title>A Hop-by-hop Cross-layer Congestion Control Scheme for Wireless Sensor
  Networks</title><categories>cs.NI</categories><msc-class>68M14</msc-class><acm-class>C.2</acm-class><journal-ref>Journal of Software, Dec 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Congestions in wireless sensor networks (WSNs) could potentially cause packet
loss, throughput impairment and energy waste. To address this issue, a
hop-by-hop cross-layer congestion control scheme (HCCC) built on
contention-based MAC protocol is proposed in this paper. According to MAC-layer
channel information including buffer occupancy ratio and congestion degree of
local node, HCCC dynamically adjusts channel access priority in MAC layer and
data transmission rate of the node to tackle the problem of congestion.
Simulations have been conducted to compare HCCC against closely-related
existing schemes. The results show that HCCC exhibits considerable superiority
in terms of packets loss ratio, throughput and energy efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0210</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0210</id><created>2011-12-30</created><authors><author><keyname>Xia</keyname><forenames>Feng</forenames></author><author><keyname>Gao</keyname><forenames>Ruixia</forenames></author><author><keyname>Wang</keyname><forenames>Linqiang</forenames></author><author><keyname>Hao</keyname><forenames>Ruonan</forenames></author></authors><title>Real-Time Performance Analysis of Infrastructure-based IEEE 802.11
  Distributed Coordination Function</title><categories>cs.NI</categories><msc-class>68M20</msc-class><acm-class>C.2.2</acm-class><journal-ref>Control Engineering and Applied Informatics, Vol.13, No.3, pp.
  74-81, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the increasing popularity of wireless networks, wireless local area
networks (WLANs) have attracted significant research interest, which play a
critical role in providing anywhere and anytime connectivity. For WLANs the
IEEE 802.11 standard is the most mature technology and has been widely adopted
for wireless networks. This paper analyzes real-time performance of the IEEE
802.11 standard that adopts the MAC protocol of Distributed Coordination
Function (DCF) operating in infrastructure mode. Extensive simulations have
been done to examine how the network performance in terms of realtime metrics
including effective data rate, latency and packet loss rate will be impacted by
some critical parameters (e.g. CWmin and packet payload). The results are
presented and analyzed. The analysis of simulation results can provide support
for parameter configuration and optimization of WLANs for realtime
applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0213</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0213</id><created>2011-12-30</created><authors><author><keyname>Wang</keyname><forenames>Jin</forenames></author><author><keyname>Abid</keyname><forenames>Hassan</forenames></author><author><keyname>Lee</keyname><forenames>Sungyoung</forenames></author><author><keyname>Shu</keyname><forenames>Lei</forenames></author><author><keyname>Xia</keyname><forenames>Feng</forenames></author></authors><title>A Secured Health Care Application Architecture for Cyber-Physical
  Systems</title><categories>cs.NI</categories><msc-class>68M14</msc-class><acm-class>C.0</acm-class><journal-ref>Control Engineering and Applied Informatics, Vol.13, No.3, pp.
  101-108, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cyber-physical systems (CPS) can be viewed as a new generation of systems
with integrated control, communication and computational capabilities. Like the
internet transformed how humans interact with one another, cyber-physical
systems will transform how people interact with the physical world. Currently,
the study of CPS is still in its infancy and there exist many research issues
and challenges ranging from electricity power, health care, transportation and
smart building etc. In this paper, an introduction of CPeSC3 (cyber physical
enhanced secured wireless sensor networks (WSNs) integrated cloud computing for
u-life care) architecture and its application to the health care monitoring and
decision support systems is given. The proposed CPeSC3 architecture is composed
of three main components, namely 1) communication core, 2) computation core,
and 3) resource scheduling and management core. Detailed analysis and
explanation are given for relevant models such as cloud computing, real time
scheduling and security models. Finally, a medical health care application
scenario is presented based on our practical test-bed which has been built for
3 years.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0215</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0215</id><created>2011-12-30</created><authors><author><keyname>Xia</keyname><forenames>Feng</forenames></author><author><keyname>Hao</keyname><forenames>Ruonan</forenames></author><author><keyname>Cao</keyname><forenames>Yang</forenames></author><author><keyname>Xue</keyname><forenames>Lei</forenames></author></authors><title>ART-GAS: An Adaptive and Real-Time GTS Allocation Scheme for IEEE
  802.15.4</title><categories>cs.NI</categories><comments>The Asian Internet Engineering Conference (AINTEC 2011), ACM,
  November 2011, Bangkok, Thailand</comments><msc-class>68M12</msc-class><acm-class>C.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  IEEE 802.15.4 supports a Guaranteed Time Slot (GTS) allocation mechanism for
time-critical and delay-sensitive data transmissions in Wireless Personal Area
Networks (WPANs). However, the inflexible first-come-first-served GTS
allocation policy and the passive deallocation mechanism significantly reduce
network efficiency. In this paper, we propose an Adaptive and Real-Time GTS
Allocation Scheme (ART-GAS) to provide differentiated services for devices with
different priorities, which guarantees data transmissions for time-sensitive
and high-traffic devices. The bandwidth utilization in IEEE 802.15.4-based PAN
is improved. Simulation results show that our ART-GAS algorithm significantly
outperforms the existing GTS mechanism specified in IEEE 802.15.4.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0216</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0216</id><created>2011-12-30</created><authors><author><keyname>Xia</keyname><forenames>Feng</forenames></author><author><keyname>Ma</keyname><forenames>Jianhua</forenames></author></authors><title>Building Smart Communities with Cyber-Physical Systems</title><categories>cs.SI cs.AI cs.CY</categories><comments>ACM UBICOMP Symposium on Social and Community Intelligence (SCI),
  Beijing, China, September 2011</comments><msc-class>68M14</msc-class><acm-class>K.4; H.5.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There is a growing trend towards the convergence of cyber-physical systems
(CPS) and social computing, which will lead to the emergence of smart
communities composed of various objects (including both human individuals and
physical things) that interact and cooperate with each other. These smart
communities promise to enable a number of innovative applications and services
that will improve the quality of life. This position paper addresses some
opportunities and challenges of building smart communities characterized by
cyber-physical and social intelligence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0218</identifier>
 <datestamp>2012-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0218</id><created>2011-12-30</created><authors><author><keyname>Ding</keyname><forenames>Fangwei</forenames></author><author><keyname>Xia</keyname><forenames>Feng</forenames></author><author><keyname>Zhang</keyname><forenames>Wei</forenames></author><author><keyname>Zhao</keyname><forenames>Xuhai</forenames></author><author><keyname>Ma</keyname><forenames>Chengchuan</forenames></author></authors><title>Monitoring Energy Consumption of Smartphones</title><categories>cs.NI</categories><comments>The 1st International Workshop on Sensing, Networking, and Computing
  with Smartphones (PhoneCom), IEEE, Dalian, China, Oct 19-22, 2011</comments><msc-class>68M20</msc-class><acm-class>C.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the rapid development of new and innovative applications for mobile
devices like smartphones, advances in battery technology have not kept pace
with rapidly growing energy demands. Thus energy consumption has become a more
and more important issue of mobile devices. To meet the requirements of saving
energy, it is critical to monitor and analyze the energy consumption of
applications on smartphones. For this purpose, we develop a smart energy
monitoring system called SEMO for smartphones using Android operating system.
It can profile mobile applications with battery usage information, which is
vital for both developers and users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0219</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0219</id><created>2011-12-30</created><authors><author><keyname>Xia</keyname><forenames>Feng</forenames></author><author><keyname>Zhang</keyname><forenames>Wei</forenames></author><author><keyname>Ding</keyname><forenames>Fangwei</forenames></author><author><keyname>Hao</keyname><forenames>Ruonan</forenames></author></authors><title>A-GPS Assisted Wi-Fi Access Point Discovery on Mobile Devices for Energy
  Saving</title><categories>cs.NI</categories><comments>IEEE Global Information Infrastructure Symposium (GIIS 2011), August
  2011, Da Nang, Vietnam</comments><msc-class>68M10</msc-class><acm-class>C.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mobile devices have been shipped with multiple wireless network interfaces in
order to meet their diverse communication and networking demands. In this
paper, we propose an A-GPS assisted scheme that discovers the nearest Wi-Fi
network access points (APs) by using user's location information. This allows
the user to switch to the Wi-Fi interface in an intelligent manner when she/he
arrives at the nearest Wi-Fi network AP. Therefore, it avoids the long periods
in idle state and greatly reduces the number of unnecessary Wi-Fi scans on the
mobile device. The experimental results demonstrate that our scheme effectively
saves energy for mobile devices integrated with Wi-Fi and cellular interfaces.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0226</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0226</id><created>2011-12-31</created><authors><author><keyname>Zhang</keyname><forenames>Ning</forenames></author><author><keyname>Tatemura</keyname><forenames>Junichi</forenames></author><author><keyname>Patel</keyname><forenames>Jignesh M.</forenames></author><author><keyname>Hac&#x131;g&#xfc;m&#xfc;&#x15f;</keyname><forenames>Hakan</forenames></author></authors><title>Towards Cost-Effective Storage Provisioning for DBMSs</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 4, pp.
  274-285 (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Data center operators face a bewildering set of choices when considering how
to provision resources on machines with complex I/O subsystems. Modern I/O
subsystems often have a rich mix of fast, high performing, but expensive SSDs
sitting alongside with cheaper but relatively slower (for random accesses)
traditional hard disk drives. The data center operators need to determine how
to provision the I/O resources for specific workloads so as to abide by
existing Service Level Agreements (SLAs), while minimizing the total operating
cost (TOC) of running the workload, where the TOC includes the amortized
hardware costs and the run time energy costs. The focus of this paper is on
introducing this new problem of TOC-based storage allocation, cast in a
framework that is compatible with traditional DBMS query optimization and query
processing architecture. We also present a heuristic-based solution to this
problem, called DOT. We have implemented DOT in PostgreSQL, and experiments
using TPC-H and TPC-C demonstrate significant TOC reduction by DOT in various
settings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0227</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0227</id><created>2011-12-31</created><authors><author><keyname>Roh</keyname><forenames>Hongchan</forenames></author><author><keyname>Park</keyname><forenames>Sanghyun</forenames></author><author><keyname>Kim</keyname><forenames>Sungho</forenames></author><author><keyname>Shin</keyname><forenames>Mincheol</forenames></author><author><keyname>Lee</keyname><forenames>Sang-Won</forenames></author></authors><title>B+-tree Index Optimization by Exploiting Internal Parallelism of
  Flash-based Solid State Drives</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 4, pp.
  286-297 (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Previous research addressed the potential problems of the hard-disk oriented
design of DBMSs of flashSSDs. In this paper, we focus on exploiting potential
benefits of flashSSDs. First, we examine the internal parallelism issues of
flashSSDs by conducting benchmarks to various flashSSDs. Then, we suggest
algorithm-design principles in order to best benefit from the internal
parallelism. We present a new I/O request concept, called psync I/O that can
exploit the internal parallelism of flashSSDs in a single process. Based on
these ideas, we introduce B+-tree optimization methods in order to utilize
internal parallelism. By integrating the results of these methods, we present a
B+-tree variant, PIO B-tree. We confirmed that each optimization method
substantially enhances the index performance. Consequently, PIO B-tree enhanced
B+-tree's insert performance by a factor of up to 16.3, while improving
point-search performance by a factor of 1.2. The range search of PIO B-tree was
up to 5 times faster than that of the B+-tree. Moreover, PIO B-tree
outperformed other flash-aware indexes in various synthetic workloads. We also
confirmed that PIO B-tree outperforms B+-tree in index traces collected inside
the Postgresql DBMS with TPC-C benchmark.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0228</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0228</id><created>2011-12-31</created><authors><author><keyname>Larson</keyname><forenames>Per-&#xc5;ke</forenames></author><author><keyname>Blanas</keyname><forenames>Spyros</forenames></author><author><keyname>Diaconu</keyname><forenames>Cristian</forenames></author><author><keyname>Freedman</keyname><forenames>Craig</forenames></author><author><keyname>Patel</keyname><forenames>Jignesh M.</forenames></author><author><keyname>Zwilling</keyname><forenames>Mike</forenames></author></authors><title>High-Performance Concurrency Control Mechanisms for Main-Memory
  Databases</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 4, pp.
  298-309 (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A database system optimized for in-memory storage can support much higher
transaction rates than current systems. However, standard concurrency control
methods used today do not scale to the high transaction rates achievable by
such systems. In this paper we introduce two efficient concurrency control
methods specifically designed for main-memory databases. Both use
multiversioning to isolate read-only transactions from updates but differ in
how atomicity is ensured: one is optimistic and one is pessimistic. To avoid
expensive context switching, transactions never block during normal processing
but they may have to wait before commit to ensure correct serialization
ordering. We also implemented a main-memory optimized version of single-version
locking. Experimental results show that while single-version locking works well
when transactions are short and contention is low performance degrades under
more demanding conditions. The multiversion schemes have higher overhead but
are much less sensitive to hotspots and the presence of long-running
transactions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0229</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0229</id><created>2011-12-31</created><authors><author><keyname>Ma</keyname><forenames>Shuai</forenames></author><author><keyname>Cao</keyname><forenames>Yang</forenames></author><author><keyname>Fan</keyname><forenames>Wenfei</forenames></author><author><keyname>Huai</keyname><forenames>Jinpeng</forenames></author><author><keyname>Wo</keyname><forenames>Tianyu</forenames></author></authors><title>Capturing Topology in Graph Pattern Matching</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 4, pp.
  310-321 (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graph pattern matching is often defined in terms of subgraph isomorphism, an
NP-complete problem. To lower its complexity, various extensions of graph
simulation have been considered instead. These extensions allow pattern
matching to be conducted in cubic-time. However, they fall short of capturing
the topology of data graphs, i.e., graphs may have a structure drastically
different from pattern graphs they match, and the matches found are often too
large to understand and analyze. To rectify these problems, this paper proposes
a notion of strong simulation, a revision of graph simulation, for graph
pattern matching. (1) We identify a set of criteria for preserving the topology
of graphs matched. We show that strong simulation preserves the topology of
data graphs and finds a bounded number of matches. (2) We show that strong
simulation retains the same complexity as earlier extensions of simulation, by
providing a cubic-time algorithm for computing strong simulation. (3) We
present the locality property of strong simulation, which allows us to
effectively conduct pattern matching on distributed graphs. (4) We
experimentally verify the effectiveness and efficiency of these algorithms,
using real-life data and synthetic data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0230</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0230</id><created>2011-12-31</created><authors><author><keyname>Pawlik</keyname><forenames>Mateusz</forenames></author><author><keyname>Augsten</keyname><forenames>Nikolaus</forenames></author></authors><title>RTED: A Robust Algorithm for the Tree Edit Distance</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 4, pp.
  334-345 (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the classical tree edit distance between ordered labeled trees,
which is defined as the minimum-cost sequence of node edit operations that
transform one tree into another. The state-of-the-art solutions for the tree
edit distance are not satisfactory. The main competitors in the field either
have optimal worst-case complexity, but the worst case happens frequently, or
they are very efficient for some tree shapes, but degenerate for others. This
leads to unpredictable and often infeasible runtimes. There is no obvious way
to choose between the algorithms. In this paper we present RTED, a robust tree
edit distance algorithm. The asymptotic complexity of RTED is smaller or equal
to the complexity of the best competitors for any input instance, i.e., RTED is
both efficient and worst-case optimal. We introduce the class of LRH
(Left-Right-Heavy) algorithms, which includes RTED and the fastest tree edit
distance algorithms presented in literature. We prove that RTED outperforms all
previously proposed LRH algorithms in terms of runtime complexity. In our
experiments on synthetic and real world data we empirically evaluate our
solution and compare it to the state-of-the-art.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0231</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0231</id><created>2011-12-31</created><authors><author><keyname>Amsterdamer</keyname><forenames>Yael</forenames></author><author><keyname>Davidson</keyname><forenames>Susan B.</forenames></author><author><keyname>Deutch</keyname><forenames>Daniel</forenames></author><author><keyname>Milo</keyname><forenames>Tova</forenames></author><author><keyname>Stoyanovich</keyname><forenames>Julia</forenames></author><author><keyname>Tannen</keyname><forenames>Val</forenames></author></authors><title>Putting Lipstick on Pig: Enabling Database-style Workflow Provenance</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 4, pp.
  346-357 (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Workflow provenance typically assumes that each module is a &quot;black-box&quot;, so
that each output depends on all inputs (coarse-grained dependencies).
Furthermore, it does not model the internal state of a module, which can change
between repeated executions. In practice, however, an output may depend on only
a small subset of the inputs (fine-grained dependencies) as well as on the
internal state of the module. We present a novel provenance framework that
marries database-style and workflow-style provenance, by using Pig Latin to
expose the functionality of modules, thus capturing internal state and
fine-grained dependencies. A critical ingredient in our solution is the use of
a novel form of provenance graph that models module invocations and yields a
compact representation of fine-grained workflow provenance. It also enables a
number of novel graph transformation operations, allowing to choose the desired
level of granularity in provenance querying (ZoomIn and ZoomOut), and
supporting &quot;what-if&quot; workflow analytic queries. We implemented our approach in
the Lipstick system and developed a benchmark in support of a systematic
performance evaluation. Our results demonstrate the feasibility of tracking and
querying fine-grained workflow provenance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0232</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0232</id><created>2011-12-31</created><authors><author><keyname>Gao</keyname><forenames>Jun</forenames></author><author><keyname>Jin</keyname><forenames>Ruoming</forenames></author><author><keyname>Zhou</keyname><forenames>Jiashuai</forenames></author><author><keyname>Yu</keyname><forenames>Jeffrey Xu</forenames></author><author><keyname>Jiang</keyname><forenames>Xiao</forenames></author><author><keyname>Wang</keyname><forenames>Tengjiao</forenames></author></authors><title>Relational Approach for Shortest Path Discovery over Large Graphs</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 4, pp.
  358-369 (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the rapid growth of large graphs, we cannot assume that graphs can still
be fully loaded into memory, thus the disk-based graph operation is inevitable.
In this paper, we take the shortest path discovery as an example to investigate
the technique issues when leveraging existing infrastructure of relational
database (RDB) in the graph data management. Based on the observation that a
variety of graph search queries can be implemented by iterative operations
including selecting frontier nodes from visited nodes, making expansion from
the selected frontier nodes, and merging the expanded nodes into the visited
ones, we introduce a relational FEM framework with three corresponding
operators to implement graph search tasks in the RDB context. We show new
features such as window function and merge statement introduced by recent SQL
standards can not only simplify the expression but also improve the performance
of the FEM framework. In addition, we propose two optimization strategies
specific to shortest path discovery inside the FEM framework. First, we take a
bi-directional set Dijkstra's algorithm in the path finding. The bi-directional
strategy can reduce the search space, and set Dijkstra's algorithm finds the
shortest path in a set-at-a-time fashion. Second, we introduce an index named
SegTable to preserve the local shortest segments, and exploit SegTable to
further improve the performance. The final extensive experimental results
illustrate our relational approach with the optimization strategies achieves
high scalability and performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0233</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0233</id><created>2011-12-31</created><authors><author><keyname>Barsky</keyname><forenames>Marina</forenames></author><author><keyname>Kim</keyname><forenames>Sangkyum</forenames></author><author><keyname>Weninger</keyname><forenames>Tim</forenames></author><author><keyname>Han</keyname><forenames>Jiawei</forenames></author></authors><title>Mining Flipping Correlations from Large Datasets with Taxonomies</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 4, pp.
  370-381 (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we introduce a new type of pattern -- a flipping correlation
pattern. The flipping patterns are obtained from contrasting the correlations
between items at different levels of abstraction. They represent surprising
correlations, both positive and negative, which are specific for a given
abstraction level, and which &quot;flip&quot; from positive to negative and vice versa
when items are generalized to a higher level of abstraction. We design an
efficient algorithm for finding flipping correlations, the Flipper algorithm,
which outperforms naive pattern mining methods by several orders of magnitude.
We apply Flipper to real-life datasets and show that the discovered patterns
are non-redundant, surprising and actionable. Flipper finds strong contrasting
correlations in itemsets with low-to-medium support, while existing techniques
cannot handle the pattern discovery in this frequency range.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0234</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0234</id><created>2011-12-31</created><authors><author><keyname>K&#xf6;nig</keyname><forenames>Arnd Christian</forenames></author><author><keyname>Ding</keyname><forenames>Bolin</forenames></author><author><keyname>Chaudhuri</keyname><forenames>Surajit</forenames></author><author><keyname>Narasayya</keyname><forenames>Vivek</forenames></author></authors><title>A Statistical Approach Towards Robust Progress Estimation</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 4, pp.
  382-393 (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The need for accurate SQL progress estimation in the context of decision
support administration has led to a number of techniques proposed for this
task. Unfortunately, no single one of these progress estimators behaves
robustly across the variety of SQL queries encountered in practice, meaning
that each technique performs poorly for a significant fraction of queries. This
paper proposes a novel estimator selection framework that uses a statistical
model to characterize the sets of conditions under which certain estimators
outperform others, leading to a significant increase in estimation robustness.
The generality of this framework also enables us to add a number of novel
&quot;special purpose&quot; estimators which increase accuracy further. Most importantly,
the resulting model generalizes well to queries very different from the ones
used to train it. We validate our findings using a large number of industrial
real-life and benchmark workloads.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0253</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0253</id><created>2011-12-31</created><authors><author><keyname>Ganguly</keyname><forenames>Sumit</forenames></author></authors><title>A Lower Bound for Estimating High Moments of a Data Stream</title><categories>cs.DS cs.CC</categories><comments>5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show an improved lower bound for the Fp estimation problem in a data
stream setting for p&gt;2. A data stream is a sequence of items from the domain
[n] with possible repetitions. The frequency vector x is an n-dimensional
non-negative integer vector x such that x(i) is the number of occurrences of i
in the sequence. Given an accuracy parameter Omega(n^{-1/p}) &lt; \epsilon &lt; 1,
the problem of estimating Fp is to estimate \norm{x}_p^p = \sum_{i \in [n]}
\abs{x(i)}^p correctly to within a relative accuracy of 1\pm \epsilon with high
constant probability in an online fashion and using as little space as
possible. The current space lower bound for this problem is Omega(n^{1-2/p}
\epsilon^{-2/p}+ n^{1-2/p}\epsilon^{-4/p}/ \log^{O(1)}(n)+ (\epsilon^{-2} +
\log (n))). The first term in the lower bound expression was proved in
\cite{B-YJKS:stoc02,cks:ccc03}, the second in \cite{wz:arxiv11} and the third
in \cite{wood:soda04}. In this note, we show an Omega(p^2 n^{1-2/p}
\epsilon^{-2}/\log (n)) bits space bound, for Omega(pn^{-1/p}) \le \epsilon \le
1/10.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0274</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0274</id><created>2011-12-31</created><authors><author><keyname>Urbano</keyname><forenames>Juli&#xe1;n</forenames></author><author><keyname>Marrero</keyname><forenames>M&#xf3;nica</forenames></author><author><keyname>Mart&#xed;n</keyname><forenames>Diego</forenames></author><author><keyname>Morato</keyname><forenames>Jorge</forenames></author></authors><title>Overview of EIREX 2010: Computing</title><categories>cs.IR</categories><comments>10 pages, 4 figures, 6 tables</comments><acm-class>K.3.2; H.3.4</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The first Information Retrieval Education through Experimentation track
(EIREX 2010) was run at the University Carlos III of Madrid, during the 2010
spring semester. EIREX 2010 is the first in a series of experiments designed to
foster new Information Retrieval (IR) education methodologies and resources,
with the specific goal of teaching undergraduate IR courses from an
experimental perspective. For an introduction to the motivation behind the
EIREX experiments, see the first sections of [Urbano et al., 2011]. For
information on other editions of EIREX and related data, see the website at
http://ir.kr.inf.uc3m.es/eirex/. The EIREX series have the following goals: a)
to help students get a view of the Information Retrieval process as they would
find it in a real-world scenario, either industrial or academic; b) to make
students realize the importance of laboratory experiments in Computer Science
and have them initiated in their execution and analysis; c) to create a public
repository of resources to teach Information Retrieval courses; d) to seek the
collaboration and active participation of other Universities in this endeavor.
This overview paper summarizes the results of the EIREX 2010 track, focusing on
the creation of the test collection and the analysis to assess its reliability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0292</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0292</id><created>2011-12-31</created><authors><author><keyname>Graziano</keyname><forenames>Vincent</forenames></author><author><keyname>Gomez</keyname><forenames>Faustino</forenames></author><author><keyname>Ring</keyname><forenames>Mark</forenames></author><author><keyname>Schmidhuber</keyname><forenames>Juergen</forenames></author></authors><title>T-Learning</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditional Reinforcement Learning (RL) has focused on problems involving
many states and few actions, such as simple grid worlds. Most real world
problems, however, are of the opposite type, Involving Few relevant states and
many actions. For example, to return home from a conference, humans identify
only few subgoal states such as lobby, taxi, airport etc. Each valid behavior
connecting two such states can be viewed as an action, and there are trillions
of them. Assuming the subgoal identification problem is already solved, the
quality of any RL method---in real-world settings---depends less on how well it
scales with the number of states than on how well it scales with the number of
actions. This is where our new method T-Learning excels, by evaluating the
relatively few possible transits from one state to another in a
policy-independent way, rather than a huge number of state-action pairs, or
states in traditional policy-dependent ways. Illustrative experiments
demonstrate that performance improvements of T-Learning over Q-learning can be
arbitrarily large.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0295</identifier>
 <datestamp>2012-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0295</id><created>2011-12-31</created><updated>2012-03-08</updated><authors><author><keyname>Brzozowski</keyname><forenames>Janusz</forenames></author><author><keyname>Tamm</keyname><forenames>Hellis</forenames></author></authors><title>Quotient Complexities of Atoms of Regular Languages</title><categories>cs.FL</categories><comments>17 pages, 2 figures, 9 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An atom of a regular language L with n (left) quotients is a non-empty
intersection of uncomplemented or complemented quotients of L, where each of
the n quotients appears in a term of the intersection. The quotient complexity
of L, which is the same as the state complexity of L, is the number of
quotients of L. We prove that, for any language L with quotient complexity n,
the quotient complexity of any atom of L with r complemented quotients has an
upper bound of 2^n-1 if r=0 or r=n, and 1+\sum_{k=1}^{r} \sum_{h=k+1}^{k+n-r}
C_{h}^{n} \cdot C_{k}^{h} otherwise, where C_j^i is the binomial coefficient.
For each n\ge 1, we exhibit a language whose atoms meet these bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0301</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0301</id><created>2011-12-31</created><authors><author><keyname>Zhang</keyname><forenames>Honggang</forenames></author><author><keyname>Vasudevan</keyname><forenames>Sudarshan</forenames></author></authors><title>Design and Analysis of Coalitions in Data Swarming Systems</title><categories>cs.NI</categories><comments>9 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We design and analyze a mechanism for forming coalitions of peers in a data
swarming system where peers have heterogeneous upload capacities. A coalition
is a set of peers that explicitly cooperate with other peers inside the
coalition via choking, data replication, and capacity allocation strategies.
Further, each peer interacts with other peers outside its coalition via
potentially distinct choking, data replication, and capacity allocation
strategies. Following on our preliminary work in IEEE ICNP 2011 that
demonstrated significant performance benefits of coalitions, we present here a
comprehensive analysis of the choking and data replication strategies for
coalitions.
  We first develop an analytical model to understand a simple random choking
strategy as a within-coalition strategy and show that it accurately predicts a
coalition's performance. Our analysis formally shows that the random choking
strategy can help a coalition achieve near-optimal performance by optimally
choosing the re-choking interval lengths and the number unchoke slots. Further,
our analytical model can be easily adapted to model a BitTorrent-like swarm. We
also introduce a simple data replication strategy which significantly improves
data availability within a coalition as compared to the rarest-first piece
replication strategy employed in BitTorrent systems. We further propose a
cooperation-aware better response strategy that achieves convergence of the
dynamic coalition formation process when peers freely join or leave any
coalition. Finally, using extensive simulations, we demonstrate improvements in
the performance of a swarming system due to coalition formation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0304</identifier>
 <datestamp>2014-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0304</id><created>2011-12-31</created><updated>2013-01-31</updated><authors><author><keyname>Xu</keyname><forenames>Xiaodong</forenames></author><author><keyname>Radziszowski</keyname><forenames>Stanis&#x142;aw</forenames></author></authors><title>Bounds on Shannon Capacity and Ramsey Numbers from Product of Graphs</title><categories>math.CO cs.IT math.IT</categories><comments>8 pages</comments><msc-class>05C55, 94A24, 05C35</msc-class><journal-ref>IEEE Transactions on Information Theory, 59(8) (2013) 4767-4770</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this note we study Shannon capacity of channels in the context of
classical Ramsey numbers. We overview some of the results on capacity of noisy
channels modelled by graphs, and how some constructions may contribute to our
knowledge of this capacity.
  We present an improvement to the constructions by Abbott and Song and thus
establish new lower bounds for a special type of multicolor Ramsey numbers. We
prove that our construction implies that the supremum of the Shannon capacity
over all graphs with independence number 2 cannot be achieved by any finite
graph power. This can be generalized to graphs with any bounded independence
number.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0320</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0320</id><created>2011-12-31</created><updated>2013-02-20</updated><authors><author><keyname>Sun</keyname><forenames>Yin</forenames></author><author><keyname>Mao</keyname><forenames>Zhoujia</forenames></author><author><keyname>Zhong</keyname><forenames>Xiaofeng</forenames></author><author><keyname>Xiao</keyname><forenames>Yuanzhang</forenames></author><author><keyname>Zhou</keyname><forenames>Shidong</forenames></author><author><keyname>Shroff</keyname><forenames>Ness B.</forenames></author></authors><title>Optimal Distributed Resource Allocation for Decode-and-Forward Relay
  Networks</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a distributed resource allocation algorithm to jointly
optimize the power allocation, channel allocation and relay selection for
decode-and-forward (DF) relay networks with a large number of sources, relays,
and destinations. The well-known dual decomposition technique cannot directly
be applied to resolve this problem, because the achievable data rate of DF
relaying is not strictly concave, and thus the local resource allocation
subproblem may have non-unique solutions. We resolve this non-strict concavity
problem by using the idea of the proximal point method, which adds quadratic
terms to make the objective function strictly concave. However, the proximal
solution adds an extra layer of iterations over typical duality based
approaches, which can significantly slow down the speed of convergence. To
address this key weakness, we devise a fast algorithm without the need for this
additional layer of iterations, which converges to the optimal solution. Our
algorithm only needs local information exchange, and can easily adapt to
variations of network size and topology. We prove that our distributed resource
allocation algorithm converges to the optimal solution. A channel resource
adjustment method is further developed to provide more channel resources to the
bottleneck links and realize traffic load balance. Numerical results are
provided to illustrate the benefits of our algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0328</identifier>
 <datestamp>2012-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0328</id><created>2011-12-31</created><authors><author><keyname>Diamant</keyname><forenames>Emanuel</forenames></author></authors><title>Let us first agree on what the term &quot;semantics&quot; means: An unorthodox
  approach to an age-old debate</title><categories>cs.AI q-bio.NC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditionally, semantics has been seen as a feature of human language. The
advent of the information era has led to its widespread redefinition as an
information feature. Contrary to this praxis, I define semantics as a special
kind of information. Revitalizing the ideas of Bar-Hillel and Carnap I have
recreated and re-established the notion of semantics as the notion of Semantic
Information. I have proposed a new definition of information (as a description,
a linguistic text, a piece of a story or a tale) and a clear segregation
between two different types of information - physical and semantic information.
I hope, I have clearly explained the (usually obscured and mysterious)
interrelations between data and physical information as well as the relation
between physical information and semantic information. Consequently, usually
indefinable notions of &quot;information&quot;, &quot;knowledge&quot;, &quot;memory&quot;, &quot;learning&quot; and
&quot;semantics&quot; have also received their suitable illumination and explanation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0330</identifier>
 <datestamp>2012-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0330</id><created>2012-01-01</created><updated>2012-10-08</updated><authors><author><keyname>Bhattacharyya</keyname><forenames>Arnab</forenames></author><author><keyname>Fischer</keyname><forenames>Eldar</forenames></author><author><keyname>Lovett</keyname><forenames>Shachar</forenames></author></authors><title>Testing Low Complexity Affine-Invariant Properties</title><categories>cs.CC math.CO</categories><comments>38 pages, appears in SODA '13</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Invariance with respect to linear or affine transformations of the domain is
arguably the most common symmetry exhibited by natural algebraic properties. In
this work, we show that any low complexity affine-invariant property of
multivariate functions over finite fields is testable with a constant number of
queries. This immediately reproves, for instance, that the Reed-Muller code
over F_p of degree d &lt; p is testable, with an argument that uses no detailed
algebraic information about polynomials except that low degree is preserved by
composition with affine maps.
  The complexity of an affine-invariant property P refers to the maximum
complexity, as defined by Green and Tao (Ann. Math. 2008), of the sets of
linear forms used to characterize P. A more precise statement of our main
result is that for any fixed prime p &gt;=2 and fixed integer R &gt;= 2, any
affine-invariant property P of functions f: F_p^n -&gt; [R] is testable, assuming
the complexity of the property is less than p. Our proof involves developing
analogs of graph-theoretic techniques in an algebraic setting, using tools from
higher-order Fourier analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0341</identifier>
 <datestamp>2012-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0341</id><created>2012-01-01</created><authors><author><keyname>Szabo</keyname><forenames>Zoltan</forenames></author><author><keyname>Poczos</keyname><forenames>Barnabas</forenames></author><author><keyname>Lorincz</keyname><forenames>Andras</forenames></author></authors><title>Collaborative Filtering via Group-Structured Dictionary Learning</title><categories>math.OC cs.LG math.ST stat.ML stat.TH</categories><comments>A compressed version of the paper has been accepted for publication
  at the 10th International Conference on Latent Variable Analysis and Source
  Separation (LVA/ICA 2012)</comments><msc-class>65K10, 90C26, 49M37 (Primary)</msc-class><acm-class>I.2.6; I.5.4</acm-class><journal-ref>International Conference on Latent Variable Analysis and Source
  Separation (LVA/ICA), vol. 7191 of LNCS, pp. 247-254, 2012</journal-ref><doi>10.1007/978-3-642-28551-6_31</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Structured sparse coding and the related structured dictionary learning
problems are novel research areas in machine learning. In this paper we present
a new application of structured dictionary learning for collaborative filtering
based recommender systems. Our extensive numerical experiments demonstrate that
the presented technique outperforms its state-of-the-art competitors and has
several advantages over approaches that do not put structured constraints on
the dictionary elements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0345</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0345</id><created>2012-01-01</created><authors><author><keyname>Marion</keyname><forenames>Jean-Yves</forenames><affiliation>LORIA</affiliation></author></authors><title>Proceedings Second Workshop on Developments in Implicit Computational
  Complexity</title><categories>cs.LO cs.CC cs.PL</categories><comments>EPTCS 75, 2012</comments><proxy>EPTCS</proxy><acm-class>F.3.2; F.3.3; F.4.1</acm-class><doi>10.4204/EPTCS.75</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This volume contains the proceedings of the Second International Workshop on
Developments in Implicit Computational complExity (DICE 2011), which took place
on April 2-3 2011 in Saarbruecken, Germany, as a satellite event of the Joint
European Conference on Theory and Practice of Software, ETAPS 2011. Implicit
Computational Complexity aims at studying computational complexity without
referring to external measuring conditions or particular machine models, but
instead by considering restrictions on programming languages or logical
principles implying complexity properties. The aim of this workshop was to
bring together researchers working on implicit computational complexity, from
its logical and semantics aspects to those related to the static analysis of
programs, so as to foster their interaction and to give newcomers an overview
of the current trends in this area.
  The first DICE workshop was held in 2010 at ETAPS and published in EPTCS,
volume 23 (http://eptcs.org/content.cgi?DICE2010).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0349</identifier>
 <datestamp>2013-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0349</id><created>2012-01-01</created><authors><author><keyname>Schmidt</keyname><forenames>Thomas C.</forenames></author><author><keyname>W&#xe4;hlisch</keyname><forenames>Matthias</forenames></author></authors><title>Why We Shouldn't Forget Multicast in Name-oriented Publish/Subscribe</title><categories>cs.NI cs.DC</categories><acm-class>C.2.1; C.2.6</acm-class><journal-ref>Thomas C. Schmidt, Matthias W\&quot;ahlisch, Dominik Charousset,
  Sebastian Meiling, On Name-based Group Communication: Challenges Concepts and
  Transparent Deployment, Computer Communications, Vol. 36, No. 15--16, pp.
  1657-1664, Sep-Oct 2013</journal-ref><doi>10.1016/j.comcom.2013.08.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Name-oriented networks introduce the vision of an information-centric,
secure, globally available publish-subscribe infrastructure. Current approaches
concentrate on unicast-based pull mechanisms and thereby fall short in
automatically updating content at receivers. In this paper, we argue that an
inclusion of multicast will grant additional benefits to the network layer,
namely efficient distribution of real-time data, a many-to-many communication
model, and simplified rendezvous processes. These aspects are comprehensively
reflected by a group-oriented naming concept that integrates the various
available group schemes and introduces new use cases. A first draft of this
name-oriented multicast access has been implemented in the HAMcast middleware.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0351</identifier>
 <datestamp>2014-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0351</id><created>2012-01-01</created><authors><author><keyname>Bogner</keyname><forenames>Simon</forenames></author><author><keyname>R&#xfc;de</keyname><forenames>Ulrich</forenames></author></authors><title>Liquid-gas-solid flows with lattice Boltzmann: Simulation of floating
  bodies</title><categories>cs.CE physics.flu-dyn</categories><comments>22 pages, Preprint submitted to Computers and Mathematics with
  Applications Special Issue ICMMES 2011, Proceedings of the Eighth
  International Conference for Mesoscopic Methods in Engineering and Science</comments><doi>10.1016/j.camwa.2012.09.012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a model for the simulation of liquid-gas-solid flows by
means of the lattice Boltzmann method. The approach is built upon previous
works for the simulation of liquid-solid particle suspensions on the one hand,
and on a liquid-gas free surface model on the other. We show how the two
approaches can be unified by a novel set of dynamic cell conversion rules. For
evaluation, we concentrate on the rotational stability of non-spherical rigid
bodies floating on a plane water surface - a classical hydrostatic problem
known from naval architecture. We show the consistency of our method in this
kind of flows and obtain convergence towards the ideal solution for the
measured heeling stability of a floating box.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0357</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0357</id><created>2012-01-01</created><authors><author><keyname>Stojanovski</keyname><forenames>Toni</forenames></author><author><keyname>Vu&#x10d;kovi&#x107;</keyname><forenames>Marko</forenames></author><author><keyname>Velinov</keyname><forenames>Ivan</forenames></author></authors><title>Empirical study of performance of data binding in ASP.NET web
  applications</title><categories>cs.SE</categories><comments>ETAI Conference, September 2011, Ohrid, Macedonia</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most developers use default properties of ASP.NET server controls when
developing web applications. ASP.NET web applications typically employ server
controls to provide dynamic web pages, and data-bound server controls to
display and maintain database data. Though the default properties allow for
fast creation of workable applications, creating a high-performance,
multi-user, and scalable web application requires careful configuring of server
controls and their enhancement using custom-made code. In providing commonly
required functionality in data-driven ASP.NET web applications such as paging,
sorting and filtering, our empirical study evaluated the impact of various
technical approaches: automatic data binding in web server controls; data
paging and sorting on web server; paging and sorting on database server;
indexed and non-indexed database columns; clustered vs. non-clustered indices.
The study observed significant performance differences between various
technical approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0360</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0360</id><created>2012-01-01</created><authors><author><keyname>Stojanovski</keyname><forenames>Toni</forenames></author><author><keyname>Krstevski</keyname><forenames>Ljupco</forenames></author></authors><title>On the Performance of Exhaustive Search with Cooperating agents</title><categories>cs.DC</categories><comments>ETAI Conference, September 2011, Ohrid, Macedonia</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite the occurrence of elegant algorithms for solving complex problem,
exhaustive search has retained its significance since many real-life problems
exhibit no regular structure and exhaustive search is the only possible
solution. The advent of high-performance computing either via multicore
processors or distributed processors emphasizes the possibility for exhaustive
search by multiple search agents. Here we analyse the performance of exhaustive
search when it is conducted by multiple search agents. Several strategies for
cooperation between the search agents are evaluated. We discover that the
performance of the search improves with the increase in the level of
cooperation. Same search performance can be achieved with homogeneous and
heterogeneous search agents provided that the length of subregions allocated to
individual search regions follow the differences in the speeds of heterogeneous
search agents.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0362</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0362</id><created>2012-01-01</created><authors><author><keyname>Kafedziski</keyname><forenames>Venceslav</forenames></author><author><keyname>Stojanovski</keyname><forenames>Toni</forenames></author></authors><title>Compressive sampling with chaotic dynamical systems</title><categories>cs.IT math.IT</categories><comments>19th Telecommunications Forum TELFOR 2011, November 2011, Belgrade,
  Serbia</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the possibility of using different chaotic sequences to
construct measurement matrices in compressive sampling. In particular, we
consider sequences generated by Chua, Lorenz and Rossler dynamical systems and
investigate the accuracy of reconstruction when using each of them to construct
measurement matrices. Chua and Lorenz sequences appear to be suitable to
construct measurement matrices. We compare the recovery rate of the original
sequence with that obtained by using Gaussian, Bernoulli and uniformly
distributed random measurement matrices. We also investigate the impact of
correlation on the recovery rate. It appears that correlation does not
influence the probability of exact reconstruction significantly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0365</identifier>
 <datestamp>2013-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0365</id><created>2012-01-01</created><authors><author><keyname>Labarre</keyname><forenames>Anthony</forenames></author></authors><title>Lower bounding edit distances between permutations</title><categories>cs.DM cs.DS</categories><journal-ref>SIAM Journal on Discrete Mathematics 27 (3), 1410-1428 (2013)</journal-ref><doi>10.1137/13090897X</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A number of fields, including the study of genome rearrangements and the
design of interconnection networks, deal with the connected problems of sorting
permutations in &quot;as few moves as possible&quot;, using a given set of allowed
operations, or computing the number of moves the sorting process requires,
often referred to as the \emph{distance} of the permutation. These operations
often act on just one or two segments of the permutation, e.g. by reversing one
segment or exchanging two segments. The \emph{cycle graph} of the permutation
to sort is a fundamental tool in the theory of genome rearrangements, and has
proved useful in settling the complexity of many variants of the above
problems. In this paper, we present an algebraic reinterpretation of the cycle
graph of a permutation $\pi$ as an even permutation $\bar{\pi}$, and show how
to reformulate our sorting problems in terms of particular factorisations of
the latter permutation. Using our framework, we recover known results in a
simple and unified way, and obtain a new lower bound on the \emph{prefix
transposition distance} (where a \emph{prefix transposition} displaces the
initial segment of a permutation), which is shown to outperform previous
results. Moreover, we use our approach to improve the best known lower bound on
the \emph{prefix transposition diameter} from $2n/3$ to $\lfloor3n/4\rfloor$,
and investigate a few relations between some statistics on $\pi$ and
$\bar{\pi}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0375</identifier>
 <datestamp>2012-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0375</id><created>2012-01-01</created><updated>2012-05-05</updated><authors><author><keyname>Tasgin</keyname><forenames>Mursel</forenames></author><author><keyname>Bingol</keyname><forenames>Haluk O.</forenames></author></authors><title>Gossip on Weighted Networks</title><categories>cs.SI nlin.AO physics.soc-ph</categories><comments>8 pages, 4 figures, 1 table</comments><acm-class>J.4</acm-class><journal-ref>Advances in Complex Systems, 15, Suppl. No. 1, 1250061, 2012</journal-ref><doi>10.1142/S0219525912500610</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate how suitable a weighted network is for gossip spreading. The
proposed model is based on the gossip spreading model introduced by Lind et.al.
on unweighted networks. Weight represents &quot;friendship.&quot; Potential spreader
prefers not to spread if the victim of gossip is a &quot;close friend&quot;. Gossip
spreading is related to the triangles and cascades of triangles. It gives more
insight about the structure of a network.
  We analyze gossip spreading on real weighted networks of human interactions.
6 co-occurrence and 7 social pattern networks are investigated. Gossip
propagation is found to be a good parameter to distinguish co-occurrence and
social pattern networks. As a comparison some miscellaneous networks and
computer generated networks based on ER, BA, WS models are also investigated.
They are found to be quite different than the human interaction networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0385</identifier>
 <datestamp>2012-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0385</id><created>2012-01-01</created><updated>2012-12-12</updated><authors><author><keyname>Doerr</keyname><forenames>Martin</forenames></author><author><keyname>Tzitzikas</keyname><forenames>Yannis</forenames></author></authors><title>Information Carriers and Identification of Information Objects: An
  Ontological Approach</title><categories>cs.DL</categories><comments>30 pages, 10 figures. Comparison to the previous version: Improved
  use of language</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Even though library and archival practice, as well as Digital Preservation,
have a long tradition in identifying information objects, the question of their
precise identity under change of carrier or migration is still a riddle to
science. The objective of this paper is to provide criteria for the unique
identification of some important kinds of information objects, independent from
the kind of carrier or specific encoding. Our approach is based on the idea
that the substance of some kinds of information objects can completely be
described in terms of discrete arrangements of finite numbers of known kinds of
symbols, such as those implied by style guides for scientific journal
submissions. Our theory is also useful for selecting or describing what has to
be preserved. This is a fundamental problem since curators and archivists would
like to formally record the decisions of what has to be preserved over time and
to decide (or verify) whether a migration (transformation) preserves the
intended information content. Furthermore, it is important for reasoning about
the authenticity of digital objects, as well as for reducing the cost of
digital preservation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0394</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0394</id><created>2012-01-01</created><authors><author><keyname>Purcaru</keyname><forenames>Elena</forenames></author><author><keyname>Toma</keyname><forenames>Cristian</forenames></author></authors><title>2D Barcode for DNA Encoding</title><categories>cs.IT math.IT</categories><comments>12 pages, 3 figures, 15 tables</comments><acm-class>E.4</acm-class><journal-ref>Purcaru, E. and Toma, C. (2011). 2D Barcode for DNA Encoding.
  Journal Of Mobile, Embedded And Distributed Systems, 3(3), 142-153. Retrieved
  from
  http://www.jmeds.eu/index.php/jmeds/article/view/2D-Barcode-for-DNA-Encoding</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The paper presents a solution for endcoding/decoding DNA information in 2D
barcodes. First part focuses on the existing techniques and symbologies in 2D
barcodes field. The 2D barcode PDF417 is presented as starting point. The
adaptations and optimizations on PDF417 and on DataMatrix lead to the solution
- DNA2DBC - DeoxyriboNucleic Acid Two Dimensional Barcode. The second part
shows the DNA2DBC encoding/decoding process step by step. In conclusions are
enumerated the most important features of 2D barcode implementation for DNA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0395</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0395</id><created>2012-01-01</created><authors><author><keyname>Popa</keyname><forenames>Marius</forenames></author></authors><title>Methods and Techniques of Quality Management for ICT Audit Processes</title><categories>cs.OH</categories><comments>9 pages, 2 figures</comments><acm-class>K.6.4</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In modern organizations, Information and Communication Technologies are used
to support the organizations' activities. To manage the quality of the
organization processes, audit processes are implemented. Also, the audit
processes can aim the quality of ICT systems themselves because their
involvement in organization processes. The paper investigates the ways in which
a quality management can be applied for audit processes in order to obtain a
high level of quality for the audit recommendations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0397</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0397</id><created>2012-01-01</created><authors><author><keyname>Popescu</keyname><forenames>Dan-Sabin</forenames></author></authors><title>Hiding Malicious Content in PDF Documents</title><categories>cs.CR</categories><comments>8 pages</comments><acm-class>I.7.2; K.6.5</acm-class><journal-ref>Popescu, D. (2011). Hiding Malicious Content in PDF Documents.
  Journal Of Mobile, Embedded And Distributed Systems, 3(3), 120-127. Retrieved
  from
  http://www.jmeds.eu/index.php/jmeds/article/view/Hiding-Malicious-Content-in-PDF-Documents</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This paper is a proof-of-concept demonstration for a specific digital
signatures vulnerability that shows the ineffectiveness of the WYSIWYS (What
You See Is What You Sign) concept. The algorithm is fairly simple: the attacker
generates a polymorphic file that has two different types of content (text, as
a PDF document for example, and image: TIFF - two of the most widely used file
formats). When the victim signs the dual content file, he/ she only sees a PDF
document and is unaware of the hidden content inside the file. After obtaining
the legally signed document from the victim, the attacker simply has to change
the extension to the other file format. This will not invalidate the digital
signature, as no bits were altered. The destructive potential of the attack is
considerable, as the Portable Document Format (PDF) is widely used in
e-government and in e-business contexts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0398</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0398</id><created>2012-01-01</created><authors><author><keyname>Chiuta</keyname><forenames>Adrian Marius</forenames></author></authors><title>AES Encryption and Decryption Using Direct3D 10 API</title><categories>cs.CR</categories><comments>7 pages, 4 figures</comments><acm-class>E.3</acm-class><journal-ref>Chiuta, A. (2011). AES Encryption and Decryption Using Direct3D 10
  API. Journal Of Mobile, Embedded And Distributed Systems, 3(2), 54-60.
  Retrieved from http://www.jmeds.eu</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Current video cards (GPUs - Graphics Processing Units) are very programmable,
have become much more powerful than the CPUs and they are very affordable. In
this paper, we present an implementation for the AES algorithm using Direct3D
10 certified GPUs. The graphics API Direct3D 10 is the first version that
allows the use of integer operations, making from the traditional GPUs (that
works only with floating point numbers), General Purpose GPUs that can be used
for a large number of algorithms, including encryption. We present the
performance of the symmetric key encryption algorithm - AES, on a middle range
GPU and on a middle range quad core CPU. On the testing system, the developed
solution is almost 3 times faster on the GPU than on one single core CPU,
showing that the GPU can perform as an efficient cryptographic accelerator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0404</identifier>
 <datestamp>2012-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0404</id><created>2012-01-01</created><updated>2012-05-17</updated><authors><author><keyname>Goel</keyname><forenames>Gagan</forenames></author><author><keyname>Mirrokni</keyname><forenames>Vahab</forenames></author><author><keyname>Leme</keyname><forenames>Renato Paes</forenames></author></authors><title>Polyhedral Clinching Auctions and the Adwords Polytope</title><categories>cs.GT</categories><comments>Accepted to STOC'12</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A central issue in applying auction theory in practice is the problem of
dealing with budget-constrained agents. A desirable goal in practice is to
design incentive compatible, individually rational, and Pareto optimal auctions
while respecting the budget constraints. Achieving this goal is particularly
challenging in the presence of nontrivial combinatorial constraints over the
set of feasible allocations.
  Toward this goal and motivated by AdWords auctions, we present an auction for
{\em polymatroidal} environments satisfying the above properties. Our auction
employs a novel clinching technique with a clean geometric description and only
needs an oracle access to the submodular function defining the polymatroid. As
a result, this auction not only simplifies and generalizes all previous
results, it applies to several new applications including AdWords Auctions,
bandwidth markets, and video on demand. In particular, our characterization of
the AdWords auction as polymatroidal constraints might be of independent
interest. This allows us to design the first mechanism for Ad Auctions taking
into account simultaneously budgets, multiple keywords and multiple slots.
  We show that it is impossible to extend this result to generic polyhedral
constraints. This also implies an impossibility result for multi-unit auctions
with decreasing marginal utilities in the presence of budget constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0409</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0409</id><created>2012-01-01</created><authors><author><keyname>Yedla</keyname><forenames>Arvind</forenames></author><author><keyname>Pfister</keyname><forenames>Henry D.</forenames></author><author><keyname>Narayanan</keyname><forenames>Krishna R.</forenames></author></authors><title>Code Design for the Noisy Slepian-Wolf Problem</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Communications. arXiv admin note:
  substantial text overlap with arXiv:1007.0931</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a noisy Slepian-Wolf problem where two correlated sources are
separately encoded (using codes of fixed rate) and transmitted over two
independent binary memoryless symmetric channels. The capacity of each channel
is characterized by a single parameter which is not known at the transmitter.
The goal is to design systems that retain near-optimal performance without
channel knowledge at the transmitter.
  It was conjectured that it may be hard to design codes that perform well for
symmetric channel conditions. In this work, we present a provable
capacity-achieving sequence of LDGM ensembles for the erasure Slepian-Wolf
problem with symmetric channel conditions. We also introduce a staggered
structure which enables codes optimized for single user channels to perform
well for symmetric channel conditions.
  We provide a generic framework for analyzing the performance of joint
iterative decoding, using density evolution. Using differential evolution, we
design punctured systematic LDPC codes to maximize the region of achievable
channel conditions. The resulting codes are then staggered to further increase
the region of achievable parameters. The main contribution of this paper is to
demonstrate that properly designed irregular LDPC codes can perform well
simultaneously over a wide range of channel parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0410</identifier>
 <datestamp>2012-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0410</id><created>2012-01-01</created><updated>2012-04-01</updated><authors><author><keyname>Cao</keyname><forenames>Zhigang</forenames></author><author><keyname>Yang</keyname><forenames>Xiaoguang</forenames></author></authors><title>A note on anti-coordination and social interactions</title><categories>cs.GT cs.CC cs.MA</categories><comments>7 pages</comments><msc-class>91-08</msc-class><acm-class>F.2.2</acm-class><doi>10.1007/s10878-012-9486-7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This note confirms a conjecture of [Bramoull\'{e}, Anti-coordination and
social interactions, Games and Economic Behavior, 58, 2007: 30-49]. The
problem, which we name the maximum independent cut problem, is a restricted
version of the MAX-CUT problem, requiring one side of the cut to be an
independent set. We show that the maximum independent cut problem does not
admit any polynomial time algorithm with approximation ratio better than
$n^{1-\epsilon}$, where $n$ is the number of nodes, and $\epsilon$ arbitrarily
small, unless P=NP. For the rather special case where each node has a degree of
at most four, the problem is still MAXSNP-hard.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0414</identifier>
 <datestamp>2012-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0414</id><created>2012-01-01</created><authors><author><keyname>Guan</keyname><forenames>Xuechong</forenames></author><author><keyname>Li</keyname><forenames>Yongming</forenames></author></authors><title>Continuity in Information Algebras</title><categories>cs.AI</categories><doi>10.1142/S0218488512500304</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this paper, the continuity and strong continuity in domain-free
information algebras and labeled information algebras are introduced
respectively. A more general concept of continuous function which is defined
between two domain-free continuous information algebras is presented. It is
shown that, with the operations combination and focusing, the set of all
continuous functions between two domain-free s-continuous information algebras
forms a new s-continuous information algebra. By studying the relationship
between domain-free information algebras and labeled information algebras, it
is demonstrated that they do correspond to each other on s-compactness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0416</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0416</id><created>2012-01-01</created><authors><author><keyname>Deng</keyname><forenames>Yuxin</forenames></author><author><keyname>Feng</keyname><forenames>Yuan</forenames></author></authors><title>Open Bisimulation for Quantum Processes</title><categories>cs.LO quant-ph</categories><comments>25 pages. Comments are welcome</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantum processes describe concurrent communicating systems that may involve
quantum information. We propose a notion of open bisimulation for quantum
processes and show that it provides both a sound and complete proof methodology
for a natural extensional behavioural equivalence between quantum processes. We
also give a modal characterisation of open bisimulation, by extending the
Hennessy-Milner logic to a quantum setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0418</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0418</id><created>2012-01-01</created><updated>2014-09-03</updated><authors><author><keyname>Jolad</keyname><forenames>Shivakumar</forenames></author><author><keyname>Roman</keyname><forenames>Ahmed</forenames></author><author><keyname>Shastry</keyname><forenames>Mahesh C.</forenames></author><author><keyname>Gadgil</keyname><forenames>Mihir</forenames></author><author><keyname>Basu</keyname><forenames>Ayanendranath</forenames></author></authors><title>A Family of Bounded Divergence Measures Based on The Bhattacharyya
  Coefficient</title><categories>math.ST cs.IT math.IT math.PR stat.TH</categories><comments>16 pages, 3 figures</comments><msc-class>94A17, 94A12, 94B70, 97K50</msc-class><acm-class>G.3; H.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new one-parameter family of divergence measures, called
bounded Bhattacharyya distance (BBD) measures, for quantifying the
dissimilarity between probability distributions. These measures are bounded,
symmetric and positive semi-definite and do not require absolute continuity. In
the asymptotic limit, BBD measure approach squared Hellinger distance. A
generalized BBD measure for multiple distributions is also introduced. We prove
an extension of a theorem of Bradt and Karlin for BBD relating Bayes error
probability and Divergence ranking. We show that BBD belongs to the class of
generalized Csiszar f-divergence and derive some properties such as curvature
and relation to Fisher Information. For distributions with vector valued
parameters, the curvature matrix is related to the Fisher-Rao metric. We derive
certain inequalities between BBD and well known measures such as Hellinger and
Jensen-Shannon divergence. We also derive Bounds on the Bayesian error
probability are established with BBD measure. We give an application of these
measures to the problem of signal detection, where we compare two monochromatic
signals, buried in white noise, differing in frequencies and amplitude.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0423</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0423</id><created>2012-01-02</created><authors><author><keyname>Jiang</keyname><forenames>Feng</forenames></author><author><keyname>Wang</keyname><forenames>Jianqi</forenames></author><author><keyname>Swindlehurst</keyname><forenames>A. Lee</forenames></author></authors><title>Interference-Aware Scheduling for Connectivity in MIMO Ad Hoc Multicast
  Networks</title><categories>cs.IT math.IT</categories><comments>34 pages, 12 figures, accepted by IEEE Transactions on Vehicular
  Technology, Dec. 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a multicast scenario involving an ad hoc network of co-channel
MIMO nodes in which a source node attempts to share a streaming message with
all nodes in the network via some pre-defined multi-hop routing tree. The
message is assumed to be broken down into packets, and the transmission is
conducted over multiple frames. Each frame is divided into time slots, and each
link in the routing tree is assigned one time slot in which to transmit its
current packet. We present an algorithm for determining the number of time
slots and the scheduling of the links in these time slots in order to optimize
the connectivity of the network, which we define to be the probability that all
links can achieve the required throughput. In addition to time multiplexing,
the MIMO nodes also employ beamforming to manage interference when links are
simultaneously active, and the beamformers are designed with the maximum
connectivity metric in mind. The effects of outdated channel state information
(CSI) are taken into account in both the scheduling and the beamforming
designs. We also derive bounds on the network connectivity and sum transmit
power in order to illustrate the impact of interference on network performance.
Our simulation results demonstrate that the choice of the number of time slots
is critical in optimizing network performance, and illustrate the significant
advantage provided by multiple antennas in improving network connectivity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0424</identifier>
 <datestamp>2012-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0424</id><created>2012-01-02</created><updated>2012-01-05</updated><authors><author><keyname>Kamyabpour</keyname><forenames>Najmeh</forenames></author><author><keyname>Hoang</keyname><forenames>Doan B.</forenames></author></authors><title>A Task Based Sensor-Centeric Model for overall Energy Consumption</title><categories>cs.NI</categories><comments>The paper has been published at PDCAT 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sensors have limited resources so it is important to manage the resources
efficiently to maximize their use. A sensor's battery is a crucial resource as
it singly determines the lifetime of sensor network applications. Since these
devices are useful only when they are able to communicate with the world, radio
transceiver of a sensor as an I/O and a costly unit plays a key role in its
lifetime. This resource often consumes a big portion of the sensor's energy as
it must be active most of the time to announce the existence of the sensor in
the network. As such the radio component has to deal with its embedded sensor
network whose parameters and operations have significant effects on the
sensor's lifetime. In existing energy models, hardware is considered, but the
environment and the network's parameters did not receive adequate attention.
Energy consumption components of traditional network architecture are often
considered individually and separately, and their influences on each other have
not been considered in these approaches. In this paper we consider all possible
tasks of a sensor in its embedded network and propose an energy management
model. We categorize these tasks in five energy consuming constituents. The
sensor's Energy Consumption (EC) is modeled on its energy consuming
constituents and their input parameters and tasks. The sensor's EC can thus be
reduced by managing and executing efficiently the tasks of its constituents.
The proposed approach can be effective for power management, and it also can be
used to guide the design of energy efficient wireless sensor networks through
network parameterization and optimization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0426</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0426</id><created>2012-01-02</created><authors><author><keyname>Jiang</keyname><forenames>Feng</forenames></author><author><keyname>Chen</keyname><forenames>Jie</forenames></author><author><keyname>Swindlehurst</keyname><forenames>A. Lee</forenames></author></authors><title>Phase-Only Analog Encoding for a Multi-Antenna Fusion Center</title><categories>cs.IT math.IT</categories><comments>4 pages, 2 figures, accepted by IEEE ICASSP 2012, Dec. 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a distributed sensor network in which the single antenna sensor
nodes observe a deterministic unknown parameter and after encoding the observed
signal with a phase parameter, the sensor nodes transmit it simultaneously to a
multi-antenna fusion center (FC). The FC optimizes the phase encoding parameter
and feeds it back to the sensor nodes such that the variance of estimation
error can be minimized. We relax the phase optimization problem to a
semidefinite programming problem and the numerical results show that the
performance of the proposed method is close to the theoretical bound. Also,
asymptotic results show that when the number of sensors is very large and the
variance of the distance between the sensor nodes and FC is small, multiple
antennas do not provide a benefit compared with a single antenna system; when
the number of antennas $M$ is large and the measurement noise at the sensor
nodes is small compared with the additive noise at the FC, the estimation error
variance can be reduced by a factor of $M$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0428</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0428</id><created>2012-01-02</created><authors><author><keyname>Likhar</keyname><forenames>Praveen</forenames></author><author><keyname>Yadav</keyname><forenames>Ravi Shankar</forenames></author><author><keyname>M</keyname><forenames>Keshava Rao</forenames></author></authors><title>Securing IEEE 802.11G WLAN Using OpenVPN and Its Impact Analysis</title><categories>cs.CR</categories><journal-ref>International Journal of Network Security &amp; Its Applications
  (IJNSA), Vol.3, No.6, November 2011, 97-113</journal-ref><doi>10.5121/ijnsa.2011.3607</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Like most advances, wireless LAN poses both opportunities and risks. The
evolution of wireless networking in recent years has raised many serious
security issues. These security issues are of great concern for this technology
as it is being subjected to numerous attacks. Because of the free-space radio
transmission in wireless networks, eavesdropping becomes easy and consequently
a security breach may result in unauthorized access, information theft,
interference and service degradation. Virtual Private Networks (VPNs) have
emerged as an important solution to security threats surrounding the use of
public networks for private communications. While VPNs for wired line networks
have matured in both research and commercial environments, the design and
deployment of VPNs for WLAN is still an evolving field. This paper presents an
approach to secure IEEE 802.11g WLAN using OpenVPN, a transport layer VPN
solution and its impact on performance of IEEE 802.11g WLAN.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0432</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0432</id><created>2012-01-02</created><authors><author><keyname>Aziz</keyname><forenames>Haris</forenames></author><author><keyname>Brill</keyname><forenames>Markus</forenames></author><author><keyname>Harrenstein</keyname><forenames>Paul</forenames></author></authors><title>Testing Substitutability of Weak Preferences</title><categories>cs.GT cs.DS</categories><comments>7 pages</comments><acm-class>J.4; I.2.11; F.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many-to-many matching models, substitutable preferences constitute the
largest domain for which a pairwise stable matching is guaranteed to exist. In
this note, we extend the recently proposed algorithm of Hatfield et al. [3] to
test substitutability of weak preferences. Interestingly, the algorithm is
faster than the algorithm of Hatfield et al. by a linear factor on the domain
of strict preferences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0435</identifier>
 <datestamp>2012-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0435</id><created>2012-01-02</created><updated>2012-01-13</updated><authors><author><keyname>Li</keyname><forenames>Yuan</forenames></author><author><keyname>Zhao</keyname><forenames>Yue</forenames></author><author><keyname>Kan</keyname><forenames>Haibin</forenames></author></authors><title>Capacity Factors of a Point-to-point Network</title><categories>cs.IT cs.NI math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate some properties on capacity factors, which were
proposed to investigate the link failure problem from network coding. A
capacity factor (CF) of a network is an edge set, deleting which will cause the
maximum flow to decrease while deleting any proper subset will not. Generally,
a $k$-CF is a minimal (not minimum) edge set which will cause the network
maximum flow decrease by $k$.
  Under point to point acyclic scenario, we characterize all the edges which
are contained in some CF, and propose an efficient algorithm to classify. And
we show that all edges on some $s$-$t$ path in an acyclic point-to-point
acyclic network are contained in some 2-CF. We also study some other properties
of CF of point to point network, and a simple relationship with CF in multicast
network.
  On the other hand, some computational hardness results relating to capacity
factors are obtained. We prove that deciding whether there is a capacity factor
of a cyclic network with size not less a given number is NP-complete, and the
time complexity of calculating the capacity rank is lowered bounded by solving
the maximal flow. Besides that, we propose the analogous definition of CF on
vertices and show it captures edge capacity factors as a special case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0458</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0458</id><created>2012-01-02</created><authors><author><keyname>Kumar</keyname><forenames>Awani</forenames></author></authors><title>Magic Knight's Tours in Higher Dimensions</title><categories>math.CO cs.DM</categories><comments>12 pages, 10 figures</comments><msc-class>05C20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A knight's tour on a board is a sequence of knight moves that visits each
square exactly once. A knight's tour on a square board is called magic knight's
tour if the sum of the numbers in each row and column is the same (magic
constant). Knight's tour in higher dimensions (n &gt; 3) is a new topic in the
age-old world of knight's tours. In this paper, it has been proved that there
can't be magic knight's tour or closed knight's tour in an odd order
n-dimensional hypercube. 3 \times 4 \times 2n-2 is the smallest cuboid (n \geq
2) and 4 \times 4 \times 4n-2 is the smallest cube in which knight's tour is
possible in n-dimensions (n \geq 3). Magic knight's tours are possible in 4
\times 4 \times 4 \times 4 and 4 \times 4 \times 4 \times 4 \times 4 hypercube.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0461</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0461</id><created>2012-01-02</created><authors><author><keyname>Dhamal</keyname><forenames>Swapnil</forenames></author><author><keyname>Bhat</keyname><forenames>Satyanath</forenames></author><author><keyname>Anoop</keyname><forenames>K. R.</forenames></author><author><keyname>Embar</keyname><forenames>Varun R</forenames></author></authors><title>Pattern Clustering using Cooperative Game Theory</title><categories>cs.GT</categories><comments>6 pages, 6 figures, published in Proceedings of Centenary Conference
  - Department of Electrical Engineering, Indian Institute of Science :
  653-658, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we approach the classical problem of clustering using solution
concepts from cooperative game theory such as Nucleolus and Shapley value. We
formulate the problem of clustering as a characteristic form game and develop a
novel algorithm DRAC (Density-Restricted Agglomerative Clustering) for
clustering. With extensive experimentation on standard data sets, we compare
the performance of DRAC with that of well known algorithms. We show an
interesting result that four prominent solution concepts, Nucleolus, Shapley
value, Gately point and \tau-value coincide for the defined characteristic form
game. This vindicates the choice of the characteristic function of the
clustering game and also provides strong intuitive foundation for our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0469</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0469</id><created>2012-01-02</created><authors><author><keyname>Sou</keyname><forenames>Kin Cheong</forenames></author><author><keyname>Sandberg</keyname><forenames>Henrik</forenames></author><author><keyname>Johansson</keyname><forenames>Karl Henrik</forenames></author></authors><title>Computing Critical $k$-tuples in Power Networks</title><categories>cs.CE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper the problem of finding the sparsest (i.e., minimum cardinality)
critical $k$-tuple including one arbitrarily specified measurement is
considered. The solution to this problem can be used to identify weak points in
the measurement set, or aid the placement of new meters. The critical $k$-tuple
problem is a combinatorial generalization of the critical measurement
calculation problem. Using topological network observability results, this
paper proposes an efficient and accurate approximate solution procedure for the
considered problem based on solving a minimum-cut (Min-Cut) problem and
enumerating all its optimal solutions. It is also shown that the sparsest
critical $k$-tuple problem can be formulated as a mixed integer linear
programming (MILP) problem. This MILP problem can be solved exactly using
available solvers such as CPLEX and Gurobi. A detailed numerical study is
presented to evaluate the efficiency and the accuracy of the proposed Min-Cut
and MILP calculations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0478</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0478</id><created>2012-01-02</created><authors><author><keyname>Dvo&#x159;&#xe1;k</keyname><forenames>Wolfgang</forenames></author></authors><title>Technical Note: Exploring \Sigma^P_2 / \Pi^P_2-hardness for
  Argumentation Problems with fixed distance to tractable classes</title><categories>cs.AI cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the complexity of reasoning in abstracts argumentation frameworks
close to graph classes that allow for efficient reasoning methods, i.e.\ to one
of the classes of acyclic, noeven, biparite and symmetric AFs. In this work we
show that certain reasoning problems on the second level of the polynomial
hierarchy still maintain their full complexity when restricted to instances of
fixed distance to one of the above graph classes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0488</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0488</id><created>2012-01-02</created><authors><author><keyname>Braverman</keyname><forenames>Mark</forenames></author><author><keyname>Grigo</keyname><forenames>Alexander</forenames></author><author><keyname>Rojas</keyname><forenames>Cristobal</forenames></author></authors><title>Noise vs computational intractability in dynamics</title><categories>cs.CC math.DS</categories><comments>ITCS 2012. 37 pages, 1 figure</comments><msc-class>37C20, 37C40</msc-class><acm-class>H.1.1; F.1.1; F.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computation plays a key role in predicting and analyzing natural phenomena.
There are two fundamental barriers to our ability to computationally understand
the long-term behavior of a dynamical system that describes a natural process.
The first one is unaccounted-for errors, which may make the system
unpredictable beyond a very limited time horizon. This is especially true for
chaotic systems, where a small change in the initial conditions may cause a
dramatic shift in the trajectories. The second one is Turing-completeness. By
the undecidability of the Halting Problem, the long-term prospects of a system
that can simulate a Turing Machine cannot be determined computationally.
  We investigate the interplay between these two forces -- unaccounted-for
errors and Turing-completeness. We show that the introduction of even a small
amount of noise into a dynamical system is sufficient to &quot;destroy&quot;
Turing-completeness, and to make the system's long-term behavior
computationally predictable. On a more technical level, we deal with long-term
statistical properties of dynamical systems, as described by invariant
measures. We show that while there are simple dynamical systems for which the
invariant measures are non-computable, perturbing such systems makes the
invariant measures efficiently computable. Thus, noise that makes the short
term behavior of the system harder to predict, may make its long term
statistical behavior computationally tractable. We also obtain some insight
into the computational complexity of predicting systems affected by random
noise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0490</identifier>
 <datestamp>2013-03-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0490</id><created>2012-01-02</created><updated>2013-03-03</updated><authors><author><keyname>Pedregosa</keyname><forenames>Fabian</forenames><affiliation>INRIA Saclay - Ile de France, LNAO</affiliation></author><author><keyname>Varoquaux</keyname><forenames>Ga&#xeb;l</forenames><affiliation>INRIA Saclay - Ile de France, LNAO</affiliation></author><author><keyname>Gramfort</keyname><forenames>Alexandre</forenames><affiliation>INRIA Saclay - Ile de France, LNAO</affiliation></author><author><keyname>Michel</keyname><forenames>Vincent</forenames><affiliation>INRIA Saclay - Ile de France, LNAO</affiliation></author><author><keyname>Thirion</keyname><forenames>Bertrand</forenames><affiliation>INRIA Saclay - Ile de France, LNAO</affiliation></author><author><keyname>Grisel</keyname><forenames>Olivier</forenames><affiliation>LAMI</affiliation></author><author><keyname>Blondel</keyname><forenames>Mathieu</forenames><affiliation>LAMI</affiliation></author><author><keyname>Prettenhofer</keyname><forenames>Peter</forenames><affiliation>LAMI</affiliation></author><author><keyname>Weiss</keyname><forenames>Ron</forenames><affiliation>LAMI</affiliation></author><author><keyname>Dubourg</keyname><forenames>Vincent</forenames><affiliation>LAMI</affiliation></author><author><keyname>Vanderplas</keyname><forenames>Jake</forenames><affiliation>LNAO</affiliation></author><author><keyname>Passos</keyname><forenames>Alexandre</forenames><affiliation>LNAO</affiliation></author><author><keyname>Cournapeau</keyname><forenames>David</forenames><affiliation>LNAO</affiliation></author><author><keyname>Brucher</keyname><forenames>Matthieu</forenames><affiliation>LNAO</affiliation></author><author><keyname>Perrot</keyname><forenames>Matthieu</forenames><affiliation>LNAO</affiliation></author><author><keyname>Duchesnay</keyname><forenames>&#xc9;douard</forenames><affiliation>LNAO</affiliation></author></authors><title>Scikit-learn: Machine Learning in Python</title><categories>cs.LG cs.MS</categories><proxy>ccsd</proxy><journal-ref>Journal of Machine Learning Research (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Scikit-learn is a Python module integrating a wide range of state-of-the-art
machine learning algorithms for medium-scale supervised and unsupervised
problems. This package focuses on bringing machine learning to non-specialists
using a general-purpose high-level language. Emphasis is put on ease of use,
performance, documentation, and API consistency. It has minimal dependencies
and is distributed under the simplified BSD license, encouraging its use in
both academic and commercial settings. Source code, binaries, and documentation
can be downloaded from http://scikit-learn.sourceforge.net.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0499</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0499</id><created>2012-01-02</created><authors><author><keyname>Verschelde</keyname><forenames>Jan</forenames></author><author><keyname>Yoffe</keyname><forenames>Genady</forenames></author></authors><title>Evaluating polynomials in several variables and their derivatives on a
  GPU computing processor</title><categories>cs.MS math.NA</categories><comments>Key words and phrases: algorithmic differentiation, compute unified
  device architecture (CUDA), graphics processing unit (GPU), massively
  parallel polynomial evaluation, Speelpenning product</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In order to obtain more accurate solutions of polynomial systems with
numerical continuation methods we use multiprecision arithmetic. Our goal is to
offset the overhead of double double arithmetic accelerating the path trackers
and in particular Newton's method with a general purpose graphics processing
unit. In this paper we describe algorithms for the massively parallel
evaluation and differentiation of sparse polynomials in several variables. We
report on our implementation of the algorithmic differentiation of products of
variables on the NVIDIA Tesla C2050 Computing Processor using the NVIDIA CUDA
compiler tools.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0533</identifier>
 <datestamp>2013-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0533</id><created>2012-01-02</created><updated>2013-05-01</updated><authors><author><keyname>Sason</keyname><forenames>Igal</forenames></author></authors><title>Tightened Exponential Bounds for Discrete Time, Conditionally Symmetric
  Martingales with Bounded Jumps</title><categories>math.PR cs.IT math.IT</categories><comments>To appear in the Statistics and Probability Letters, final version of
  the manuscript (dated May 1, 2013). Presented in part at the 2012
  International Workshop on Applied Probability (IWAP), Jerusalem, Israel, June
  2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This letter derives some new exponential bounds for discrete time, real
valued, conditionally symmetric martingales with bounded jumps. The new bounds
are extended to conditionally symmetric sub/ supermartingales, and they are
compared to some existing bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0540</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0540</id><created>2012-01-02</created><authors><author><keyname>Obua</keyname><forenames>Steven</forenames></author></authors><title>ProofPeer - A Cloud-based Interactive Theorem Proving System</title><categories>cs.MS cs.DL cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  ProofPeer strives to be a system for cloud-based interactive theorem proving.
After illustrating why such a system is needed, the paper presents some of the
design challenges that ProofPeer needs to meet to succeed. Contexts are
presented as a solution to the problem of sharing proof state among the users
of ProofPeer. Chronicles are introduced as a way to organize and version
contexts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0552</identifier>
 <datestamp>2013-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0552</id><created>2012-01-02</created><updated>2013-08-20</updated><authors><author><keyname>Schl&#xe4;pfer</keyname><forenames>Markus</forenames></author><author><keyname>Kessler</keyname><forenames>Tom</forenames></author><author><keyname>Kr&#xf6;ger</keyname><forenames>Wolfgang</forenames></author></authors><title>Reliability Analysis of Electric Power Systems Using an Object-oriented
  Hybrid Modeling Approach</title><categories>cs.SY</categories><comments>Based on the original paper presented at: 16th Power Systems
  Computation Conference, Glasgow, Scotland, July 14-18, 2008 (PSCC'08)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ongoing evolution of the electric power systems brings about the need to
cope with increasingly complex interactions of technical components and
relevant actors. In order to integrate a more comprehensive spectrum of
different aspects into a probabilistic reliability assessment and to include
time-dependent effects, this paper proposes an object-oriented hybrid approach
combining agent-based modeling techniques with classical methods such as Monte
Carlo simulation. Objects represent both technical components such as
generators and transmission lines and non-technical components such as grid
operators. The approach allows the calculation of conventional reliability
indices and the estimation of blackout frequencies. Furthermore, the influence
of the time needed to remove line overloads on the overall system reliability
can be assessed. The applicability of the approach is demonstrated by
performing simulations on the IEEE Reliability Test System 1996 and on a model
of the Swiss high-voltage grid.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0554</identifier>
 <datestamp>2014-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0554</id><created>2012-01-02</created><updated>2012-03-18</updated><authors><author><keyname>Shetler</keyname><forenames>Daniel S.</forenames></author><author><keyname>Wurtz</keyname><forenames>Michael A.</forenames></author><author><keyname>Radziszowski</keyname><forenames>Stanis&#x142;aw P.</forenames></author></authors><title>On Some Multicolor Ramsey Numbers Involving $K_3+e$ and $K_4-e$</title><categories>math.CO cs.DM</categories><comments>12 pages</comments><msc-class>05C55</msc-class><journal-ref>SIAM Journal on Discrete Mathematics, 26 (2012) 1256-1264</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Ramsey number $R(G_1, G_2, G_3)$ is the smallest positive integer $n$
such that for all 3-colorings of the edges of $K_n$ there is a monochromatic
$G_1$ in the first color, $G_2$ in the second color, or $G_3$ in the third
color. We study the bounds on various 3-color Ramsey numbers $R(G_1, G_2,
G_3)$, where $G_i \in \{K_3, K_3+e, K_4-e, K_4\}$. The minimal and maximal
combinations of $G_i$'s correspond to the classical Ramsey numbers $R_3(K_3)$
and $R_3(K_4)$, respectively, where $R_3(G) = R(G, G, G)$. Here, we focus on
the much less studied combinations between these two cases.
  Through computational and theoretical means we establish that $R(K_3, K_3,
K_4-e)=17$, and by construction we raise the lower bounds on $R(K_3, K_4-e,
K_4-e)$ and $R(K_4, K_4-e, K_4-e)$. For some $G$ and $H$ it was known that
$R(K_3, G, H)=R(K_3+e, G, H)$; we prove this is true for several more cases
including $R(K_3, K_3, K_4-e) = R(K_3+e, K_3+e, K_4-e)$.
  Ramsey numbers generalize to more colors, such as in the famous 4-color case
of $R_4(K_3)$, where monochromatic triangles are avoided. It is known that $51
\leq R_4(K_3) \leq 62$. We prove a surprising theorem stating that if
$R_4(K_3)=51$ then $R_4(K_3+e)=52$, otherwise $R_4(K_3+e)=R_4(K_3)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0557</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0557</id><created>2012-01-02</created><updated>2012-02-17</updated><authors><author><keyname>Barto</keyname><forenames>Libor</forenames><affiliation>Charles University in Prague</affiliation></author><author><keyname>Kozik</keyname><forenames>Marcin</forenames><affiliation>Jagiellonian University</affiliation></author></authors><title>Absorbing Subalgebras, Cyclic Terms, and the Constraint Satisfaction
  Problem</title><categories>cs.LO</categories><proxy>LMCS</proxy><acm-class>F.2.2, F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 8, Issue 1 (February
  20, 2012) lmcs:673</journal-ref><doi>10.2168/LMCS-8(1:7)2012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Algebraic Dichotomy Conjecture states that the Constraint Satisfaction
Problem over a fixed template is solvable in polynomial time if the algebra of
polymorphisms associated to the template lies in a Taylor variety, and is
NP-complete otherwise. This paper provides two new characterizations of
finitely generated Taylor varieties. The first characterization is using
absorbing subalgebras and the second one cyclic terms. These new conditions
allow us to reprove the conjecture of Bang-Jensen and Hell (proved by the
authors) and the characterization of locally finite Taylor varieties using weak
near-unanimity terms (proved by McKenzie and Mar\'oti) in an elementary and
self-contained way.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0562</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0562</id><created>2012-01-02</created><authors><author><keyname>Eguchi</keyname><forenames>Naohi</forenames></author></authors><title>A term-rewriting characterization of PSPACE</title><categories>math.LO cs.LO</categories><comments>In: T. Arai, C. T. Chong, R. Downey, J. Brendle, Q. Feng, H. Kikyo
  and H. Ono, editors, Proceedings of the 10th Asian Logic Conference 2008,
  World Scientific, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Isabel Oitavem has introduced a term rewriting system (TRS) which captures
the class FPS of polynomial-space computable functions. We propose an
alternative TRS for FPS. As a consequence, it is obtained that FPS is the
smallest class containing certain initial functions and closed under specific
operations. It turns out that our characterization is relatively simple and
suggests an uniform approach to the space-complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0564</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0564</id><created>2012-01-02</created><authors><author><keyname>de Haan</keyname><forenames>Ronald</forenames></author><author><keyname>Narodytska</keyname><forenames>Nina</forenames></author><author><keyname>Walsh</keyname><forenames>Toby</forenames></author></authors><title>The RegularGcc Matrix Constraint</title><categories>cs.AI</categories><comments>Submitted to CPAIOR 2012</comments><msc-class>68T20</msc-class><acm-class>I.2.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study propagation of the RegularGcc global constraint. This ensures that
each row of a matrix of decision variables satis?es a Regular constraint, and
each column satisfies a Gcc constraint. On the negative side, we prove that
propagation is NP-hard even under some strong restrictions (e.g. just 3 values,
just 4 states in the automaton, or just 5 columns to the matrix). On the
positive side, we identify two cases where propagation is fixed parameter
tractable. In addition, we show how to improve propagation over a simple
decomposition into separate Regular and Gcc constraints by identifying some
necessary but insufficient conditions for a solution. We enforce these
conditions with some additional weighted row automata. Experimental results
demonstrate the potential of these methods on some standard benchmark problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0566</identifier>
 <datestamp>2013-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0566</id><created>2012-01-02</created><updated>2013-09-18</updated><authors><author><keyname>Tosic</keyname><forenames>Ivana</forenames></author><author><keyname>Drewes</keyname><forenames>Sarah</forenames></author></authors><title>Learning joint intensity-depth sparse representations</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a method for learning overcomplete dictionaries composed
of two modalities that describe a 3D scene: image intensity and scene depth. We
propose a novel Joint Basis Pursuit (JBP) algorithm that finds related sparse
features in two modalities using conic programming and integrate it into a
two-step dictionary learning algorithm. JBP differs from related convex
algorithms because it finds joint sparsity models with different atoms and
different coefficient values for intensity and depth. This is crucial for
recovering generative models where the same sparse underlying causes (3D
features) give rise to different signals (intensity and depth). We give a
theoretical bound for the sparse coefficient recovery error obtained by JBP,
and show experimentally that JBP is far superior to the state of the art Group
Lasso algorithm. When applied to the Middlebury depth-intensity database, our
learning algorithm converges to a set of related features, such as pairs of
depth and intensity edges or image textures and depth slants. Finally, we show
that the learned dictionary and JBP achieve the state of the art depth
inpainting performance on time-of-flight 3D data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0572</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0572</id><created>2012-01-03</created><authors><author><keyname>Chermakani</keyname><forenames>Deepak Ponvel</forenames></author></authors><title>Expressing Reachability in Linear Recurrences, as Infinite Determinants
  and Rational Polynomial Equations</title><categories>cs.DM math.DS</categories><comments>4 Pages, 2 Theorems, 4 Figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present two tools, which could be useful in determining whether or not a
non-Homogenous Linear Recurrence can reach a desired rational. First, we derive
the determinant that is equal to the ith term in a non-Homogenous Linear
Recurrence. We use this to derive the infinite determinant that is zero, if and
only if, the desired rational can be reached by some term in the recurrence.
Second, we derive an infinite summation of rational Polynomials, such that this
summation can be equal to 1, if and only if, the desired rational can be
reached by some term in the recurrence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0587</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0587</id><created>2012-01-03</created><authors><author><keyname>P&#xe9;quegnat</keyname><forenames>Catherine</forenames><affiliation>ISTerre</affiliation></author><author><keyname>Jacquot</keyname><forenames>Raphael</forenames><affiliation>ISTerre</affiliation></author><author><keyname>Gueguen</keyname><forenames>Philippe</forenames><affiliation>ISTerre</affiliation></author><author><keyname>Godey</keyname><forenames>St&#xe9;phanie</forenames><affiliation>EMSC/CSEM</affiliation></author><author><keyname>Frobert</keyname><forenames>Laurent</forenames><affiliation>EMSC/CSEM</affiliation></author></authors><title>Distributed archive and single access system for accelerometric event
  data : a NERIES initiative</title><categories>physics.geo-ph cs.DL</categories><proxy>ccsd</proxy><journal-ref>Earthquake Data in Engineering Seismology (2011) 129-142</journal-ref><doi>10.1007/978-94-007-0152-6_10</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We developed a common access facility to homogeneously formatted
accelerometric event data and to the corresponding sheet of ground motion
parameters. This paper is focused on the description of the technical
development of the accelerometric data server and the link with the
accelerometric data explorer. The server is the third node of the 3-tier
architecture of the distributed archive system for accelerometric data. The
server is the link between the data users and the accelero- metric data portal.
The server follows three main steps: (1) Reading and analysis of the end-user
request; (2) Processing and converting data; and (3) Archiving and updating the
accelerometric data explorer. This paper presents the description of the data
server and the data explorer for accessing data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0595</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0595</id><created>2012-01-03</created><authors><author><keyname>Krishna</keyname><forenames>Shankara Narayanan</forenames></author><author><keyname>Narwane</keyname><forenames>Ganesh</forenames></author><author><keyname>S.</keyname><forenames>Ramesh</forenames></author><author><keyname>Mohalik</keyname><forenames>Swarup</forenames></author><author><keyname>Millo</keyname><forenames>Jean-Vivien</forenames></author></authors><title>Formalizing Traceability and Derivability in Software Product Lines</title><categories>cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the literature, the definition of product in a Software Product Line (SPL)
is based upon the notion of consistency of the constraints, imposed by
variability and traceability relations on the elements of the SPL. In this
paper, we contend that consistency does not model the natural semantics of the
implementability relation between problem and solution spaces correctly.
Therefore, we define when a feature can be {\em derived} from a set of
components . Using this, we define a product of the SPL by a &lt;specification,
architecture&gt; pair, where all the features in the specification are derived
from the components in the architecture. This notion of derivability is
formulated in a simple yet expressive, abstract model of a productline with
traceability relation. We then define a set of SPL analysis problems and show
that these problems can be encoded as Quantified Boolean Formulas. Then, QSAT
solvers like QUBE can be used to solve the analysis problems. We illustrate the
methodology on a small fragment of a realistic productline.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0597</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0597</id><created>2012-01-03</created><updated>2012-02-15</updated><authors><author><keyname>Boja&#x144;czyk</keyname><forenames>Miko&#x142;aj</forenames><affiliation>University of Warsaw</affiliation></author><author><keyname>Lasota</keyname><forenames>S&#x142;awomir</forenames><affiliation>University of Warsaw</affiliation></author></authors><title>An extension of data automata that captures XPath</title><categories>cs.LO cs.FL</categories><proxy>LMCS</proxy><acm-class>F.1.1, H.2.3</acm-class><journal-ref>Logical Methods in Computer Science, Volume 8, Issue 1 (February
  16, 2012) lmcs:672</journal-ref><doi>10.2168/LMCS-8(1:5)2012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We define a new kind of automata recognizing properties of data words or data
trees and prove that the automata capture all queries definable in Regular
XPath. We show that the automata-theoretic approach may be applied to answer
decidability and expressibility questions for XPath.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0598</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0598</id><created>2012-01-03</created><authors><author><keyname>Maugey</keyname><forenames>Thomas</forenames></author><author><keyname>Frossard</keyname><forenames>Pascal</forenames></author></authors><title>Interactive multiview video system with non-complex navigation at the
  decoder</title><categories>cs.MM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multiview video with interactive and smooth view switching at the receiver is
a challenging application with several issues in terms of effective use of
storage and bandwidth resources, reactivity of the system, quality of the
viewing experience and system complexity. The classical decoding system for
generating virtual views first projects a reference or encoded frame to a given
viewpoint and then fills in the holes due to potential occlusions. This last
step still constitutes a complex operation with specific software or hardware
at the receiver and requires a certain quantity of information from the
neighboring frames for insuring consistency between the virtual images. In this
work we propose a new approach that shifts most of the burden due to
interactivity from the decoder to the encoder, by anticipating the navigation
of the decoder and sending auxiliary information that guarantees temporal and
interview consistency. This leads to an additional cost in terms of
transmission rate and storage, which we minimize by using optimization
techniques based on the user behavior modeling. We show by experiments that the
proposed system represents a valid solution for interactive multiview systems
with classical decoders.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0610</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0610</id><created>2012-01-03</created><authors><author><keyname>Xiong</keyname><forenames>Caiming</forenames></author><author><keyname>Johnson</keyname><forenames>David</forenames></author><author><keyname>Xu</keyname><forenames>Ran</forenames></author><author><keyname>Corso</keyname><forenames>Jason J.</forenames></author></authors><title>Random Forests for Metric Learning with Implicit Pairwise Position
  Dependence</title><categories>stat.ML cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Metric learning makes it plausible to learn distances for complex
distributions of data from labeled data. However, to date, most metric learning
methods are based on a single Mahalanobis metric, which cannot handle
heterogeneous data well. Those that learn multiple metrics throughout the space
have demonstrated superior accuracy, but at the cost of computational
efficiency. Here, we take a new angle to the metric learning problem and learn
a single metric that is able to implicitly adapt its distance function
throughout the feature space. This metric adaptation is accomplished by using a
random forest-based classifier to underpin the distance function and
incorporate both absolute pairwise position and standard relative position into
the representation. We have implemented and tested our method against state of
the art global and multi-metric methods on a variety of data sets. Overall, the
proposed method outperforms both types of methods in terms of accuracy
(consistently ranked first) and is an order of magnitude faster than state of
the art multi-metric methods (16x faster in the worst case).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0626</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0626</id><created>2012-01-03</created><authors><author><keyname>H&#xe4;ggstr&#xf6;m</keyname><forenames>Olle</forenames></author><author><keyname>W&#xe4;stlund</keyname><forenames>Johan</forenames></author></authors><title>Rigorous computer analysis of the Chow-Robbins game</title><categories>math.PR cs.GT</categories><comments>10 pages</comments><msc-class>60G40, 62L15, 91A60</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Flip a coin repeatedly, and stop whenever you want. Your payoff is the
proportion of heads, and you wish to maximize this payoff in expectation. This
so-called Chow-Robbins game is amenable to computer analysis, but while
simple-minded number crunching can show that it is best to continue in a given
position, establishing rigorously that stopping is optimal seems at first sight
to require &quot;backward induction from infinity&quot;. We establish a simple upper
bound on the expected payoff in a given position, allowing efficient and
rigorous computer analysis of positions early in the game. In particular we
confirm that with 5 heads and 3 tails, stopping is optimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0638</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0638</id><created>2012-01-03</created><authors><author><keyname>Ansmann</keyname><forenames>Gerrit</forenames></author><author><keyname>Lehnertz</keyname><forenames>Klaus</forenames></author></authors><title>Constrained Randomisation of Weighted Networks</title><categories>physics.data-an cs.SI physics.soc-ph</categories><comments>11 pages, 5 figures</comments><journal-ref>Physical Review E 84, 026103 (2011)</journal-ref><doi>10.1103/PhysRevE.84.026103</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a Markov chain method to efficiently generate 'surrogate networks'
that are random under the constraint of given vertex strengths. With these
strength-preserving surrogates and with edge-weight-preserving surrogates we
investigate the clustering coefficient and the average shortest path length of
functional networks of the human brain as well as of the International Trade
Networks. We demonstrate that surrogate networks can provide additional
information about network-specific characteristics and thus help interpreting
empirical weighted networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0662</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0662</id><created>2012-01-03</created><authors><author><keyname>Weber</keyname><forenames>Steven</forenames></author><author><keyname>Andrews</keyname><forenames>Jeffrey G.</forenames></author></authors><title>Transmission capacity of wireless networks</title><categories>cs.IT cs.NI cs.PF math.IT</categories><comments>173 pages; Foundations and Trends in Networking, vol. 5, no. 2-3,
  2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Transmission capacity (TC) is a performance metric for wireless networks that
measures the spatial intensity of successful transmissions per unit area,
subject to a constraint on the permissible outage probability (where outage
occurs when the SINR at a receiver is below a threshold). This volume gives a
unified treatment of the TC framework that has been developed by the authors
and their collaborators over the past decade. The mathematical framework
underlying the analysis (reviewed in Ch. 2) is stochastic geometry: Poisson
point processes model the locations of interferers, and (stable) shot noise
processes represent the aggregate interference seen at a receiver. Ch. 3
presents TC results (exact, asymptotic, and bounds) on a simple model in order
to illustrate a key strength of the framework: analytical tractability yields
explicit performance dependence upon key model parameters. Ch. 4 presents
enhancements to this basic model --- channel fading, variable link distances,
and multi-hop. Ch. 5 presents four network design case studies well-suited to
TC: i) spectrum management, ii) interference cancellation, iii) signal
threshold transmission scheduling, and iv) power control. Ch. 6 studies the TC
when nodes have multiple antennas, which provides a contrast vs. classical
results that ignore interference.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0676</identifier>
 <datestamp>2012-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0676</id><created>2012-01-03</created><authors><author><keyname>Vitanov</keyname><forenames>Nikolay K.</forenames></author><author><keyname>Ausloos</keyname><forenames>Marcel R.</forenames></author></authors><title>Knowledge epidemics and population dynamics models for describing idea
  diffusion</title><categories>physics.soc-ph cs.SI</categories><comments>73 pages, 24 figures, 5 tables, 153 references; intended as CHAPTER 3
  in a BOOK: Models of science dynamics - encounters between complexity theory
  and information sciences, to be edited by Katy Boerner, Andrea Scharnhorst,
  and Peter van den Besselaar</comments><journal-ref>Eds. Springer Verlag Berlin Heidelberg, Ch. 3, pp. 69 - 125 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The diffusion of ideas is often closely connected to the creation and
diffusion of knowledge and to the technological evolution of society. Because
of this, knowledge creation, exchange and its subsequent transformation into
innovations for improved welfare and economic growth is briefly described from
a historical point of view. Next, three approaches are discussed for modeling
the diffusion of ideas in the areas of science and technology, through (i)
deterministic, (ii) stochastic, and (iii) statistical approaches. These are
illustrated through their corresponding population dynamics and epidemic models
relative to the spreading of ideas, knowledge and innovations. The
deterministic dynamical models are considered to be appropriate for analyzing
the evolution of large and small societal, scientific and technological systems
when the influence of fluctuations is insignificant. Stochastic models are
appropriate when the system of interest is small but when the fluctuations
become significant for its evolution. Finally statistical approaches and models
based on the laws and distributions of Lotka, Bradford, Yule, Zipf-Mandelbrot,
and others, provide much useful information for the analysis of the evolution
of systems in which development is closely connected to the process of idea
diffusion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0682</identifier>
 <datestamp>2012-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0682</id><created>2012-01-03</created><updated>2012-03-29</updated><authors><author><keyname>Babiak</keyname><forenames>Tom&#xe1;&#x161;</forenames></author><author><keyname>K&#x159;et&#xed;nsk&#xfd;</keyname><forenames>Mojm&#xed;r</forenames></author><author><keyname>&#x158;eh&#xe1;k</keyname><forenames>Vojt&#x11b;ch</forenames></author><author><keyname>Strej&#x10d;ek</keyname><forenames>Jan</forenames></author></authors><title>LTL to B\&quot;uchi Automata Translation: Fast and More Deterministic</title><categories>cs.FL cs.LO</categories><comments>Full version of the paper presented at TACAS 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce improvements in the algorithm by Gastin and Oddoux translating
LTL formulae into B\&quot;uchi automata via very weak alternating co-B\&quot;uchi
automata and generalized B\&quot;uchi automata. Several improvements are based on
specific properties of any formula where each branch of its syntax tree
contains at least one eventually operator and at least one always operator.
These changes usually result in faster translations and smaller automata. Other
improvements reduce non-determinism in the produced automata. In fact, we
modified all the steps of the original algorithm and its implementation known
as LTL2BA. Experimental results show that our modifications are real
improvements. Their implementations within an LTL2BA translation made LTL2BA
very competitive with the current version of SPOT, sometimes outperforming it
substantially.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0686</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0686</id><created>2012-01-03</created><authors><author><keyname>Liu</keyname><forenames>Ming</forenames><affiliation>IETR</affiliation></author><author><keyname>Crussi&#xe8;re</keyname><forenames>Matthieu</forenames><affiliation>IETR</affiliation></author><author><keyname>H&#xe9;lard</keyname><forenames>Jean-Fran&#xe7;ois</forenames><affiliation>IETR</affiliation></author></authors><title>A Novel Data-Aided Channel Estimation with Reduced Complexity for
  TDS-OFDM Systems</title><categories>cs.NI</categories><proxy>ccsd</proxy><journal-ref>IEEE Transactions on Broadcasting 58 (2012) 1-14</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In contrast to the classical cyclic prefix (CP)-OFDM, the time domain
synchronous (TDS)-OFDM employs a known pseudo noise (PN) sequence as guard
interval (GI). Conventional channel estimation methods for TDS-OFDM are based
on the exploitation of the PN sequence and consequently suffer from intersymbol
interference (ISI). This paper proposes a novel dataaided channel estimation
method which combines the channel estimates obtained from the PN sequence and,
most importantly, additional channel estimates extracted from OFDM data
symbols. Data-aided channel estimation is carried out using the rebuilt OFDM
data symbols as virtual training sequences. In contrast to the classical turbo
channel estimation, interleaving and decoding functions are not included in the
feedback loop when rebuilding OFDM data symbols thereby reducing the
complexity. Several improved techniques are proposed to refine the data-aided
channel estimates, namely one-dimensional (1-D)/two-dimensional (2-D) moving
average and Wiener filtering. Finally, the MMSE criteria is used to obtain the
best combination results and an iterative process is proposed to progressively
refine the estimation. Both MSE and BER simulations using specifications of the
DTMB system are carried out to prove the effectiveness of the proposed
algorithm even in very harsh channel conditions such as in the single frequency
network (SFN) case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0715</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0715</id><created>2012-01-03</created><updated>2012-08-13</updated><authors><author><keyname>Olmos</keyname><forenames>Pablo M.</forenames></author><author><keyname>Murillo-Fuentes</keyname><forenames>Juan Jos&#xe9;</forenames></author><author><keyname>P&#xe9;rez-Cruz</keyname><forenames>Fernando</forenames></author></authors><title>Tree-Structure Expectation Propagation for LDPC Decoding over the BEC</title><categories>cs.IT math.IT</categories><journal-ref>IEEE Transactions on Information Theory 2013</journal-ref><doi>10.1109/TIT.2013.2245494</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the tree-structure expectation propagation (Tree-EP) algorithm to
decode low-density parity-check (LDPC) codes over discrete memoryless channels
(DMCs). EP generalizes belief propagation (BP) in two ways. First, it can be
used with any exponential family distribution over the cliques in the graph.
Second, it can impose additional constraints on the marginal distributions. We
use this second property to impose pair-wise marginal constraints over pairs of
variables connected to a check node of the LDPC code's Tanner graph. Thanks to
these additional constraints, the Tree-EP marginal estimates for each variable
in the graph are more accurate than those provided by BP. We also reformulate
the Tree-EP algorithm for the binary erasure channel (BEC) as a peeling-type
algorithm (TEP) and we show that the algorithm has the same computational
complexity as BP and it decodes a higher fraction of errors. We describe the
TEP decoding process by a set of differential equations that represents the
expected residual graph evolution as a function of the code parameters. The
solution of these equations is used to predict the TEP decoder performance in
both the asymptotic regime and the finite-length regime over the BEC. While the
asymptotic threshold of the TEP decoder is the same as the BP decoder for
regular and optimized codes, we propose a scaling law (SL) for finite-length
LDPC codes, which accurately approximates the TEP improved performance and
facilitates its optimization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0725</identifier>
 <datestamp>2012-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0725</id><created>2012-01-03</created><updated>2012-01-17</updated><authors><author><keyname>Khelifi</keyname><forenames>Manel</forenames></author><author><keyname>Djabelkhir</keyname><forenames>Assia</forenames></author></authors><title>LMEEC: Layered Multi-Hop Energy Efficient Cluster-based Routing Protocol
  for Wireless Sensor Networks</title><categories>cs.NI</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In this paper, we propose LMEEC, a cluster-based routing protocol with low
energy consumption for wireless sensor networks. Our protocol is based on a
strategy which aims to provide a more reasonable exploitation of the selected
nodes (cluster-heads) energy. Simulation results show the effectiveness of
LMEEC in decreasing the energy consumption, and in prolonging the network
lifetime, compared to LEACH.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0737</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0737</id><created>2012-01-03</created><authors><author><keyname>Wei</keyname><forenames>Lu</forenames></author><author><keyname>Tirkkonen</keyname><forenames>Olav</forenames></author></authors><title>Spectrum Sensing in the Presence of Multiple Primary Users</title><categories>cs.IT math.IT</categories><comments>Accepted in IEEE Transactions on Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider multi-antenna cooperative spectrum sensing in cognitive radio
networks, when there may be multiple primary users. A detector based on the
spherical test is analyzed in such a scenario. Based on the moments of the
distributions involved, simple and accurate analytical formulae for the key
performance metrics of the detector are derived. The false alarm and the
detection probabilities, as well as the detection threshold and Receiver
Operation Characteristics are available in closed form. Simulations are
provided to verify the accuracy of the derived results, and to compare with
other detectors in realistic sensing scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0745</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0745</id><created>2012-01-03</created><updated>2012-06-25</updated><authors><author><keyname>Bagrow</keyname><forenames>James P.</forenames></author></authors><title>Communities and bottlenecks: Trees and treelike networks have high
  modularity</title><categories>physics.soc-ph cs.SI physics.data-an</categories><comments>9 pages, 5 figures</comments><journal-ref>Phys. Rev. E 85, 066118 (2012)</journal-ref><doi>10.1103/PhysRevE.85.066118</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Much effort has gone into understanding the modular nature of complex
networks. Communities, also known as clusters or modules, are typically
considered to be densely interconnected groups of nodes that are only sparsely
connected to other groups in the network. Discovering high quality communities
is a difficult and important problem in a number of areas. The most popular
approach is the objective function known as modularity, used both to discover
communities and to measure their strength. To understand the modular structure
of networks it is then crucial to know how such functions evaluate different
topologies, what features they account for, and what implicit assumptions they
may make. We show that trees and treelike networks can have unexpectedly and
often arbitrarily high values of modularity. This is surprising since trees are
maximally sparse connected graphs and are not typically considered to possess
modular structure, yet the nonlocal null model used by modularity assigns low
probabilities, and thus high significance, to the densities of these sparse
tree communities. We further study the practical performance of popular methods
on model trees and on a genealogical data set and find that the discovered
communities also have very high modularity, often approaching its maximum
value. Statistical tests reveal the communities in trees to be significant, in
contrast with known results for partitions of sparse, random graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0749</identifier>
 <datestamp>2013-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0749</id><created>2012-01-01</created><updated>2013-09-01</updated><authors><author><keyname>McGuire</keyname><forenames>Gary</forenames></author><author><keyname>Tugemann</keyname><forenames>Bastian</forenames></author><author><keyname>Civario</keyname><forenames>Gilles</forenames></author></authors><title>There is no 16-Clue Sudoku: Solving the Sudoku Minimum Number of Clues
  Problem</title><categories>cs.DS</categories><comments>43 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The sudoku minimum number of clues problem is the following question: what is
the smallest number of clues that a sudoku puzzle can have? For several years
it had been conjectured that the answer is 17. We have performed an exhaustive
computer search for 16-clue sudoku puzzles, and did not find any, thus proving
that the answer is indeed 17. In this article we describe our method and the
actual search. As a part of this project we developed a novel way for
enumerating hitting sets. The hitting set problem is computationally hard; it
is one of Karp's 21 classic NP-complete problems. A standard backtracking
algorithm for finding hitting sets would not be fast enough to search for a
16-clue sudoku puzzle exhaustively, even at today's supercomputer speeds. To
make an exhaustive search possible, we designed an algorithm that allowed us to
efficiently enumerate hitting sets of a suitable size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0782</identifier>
 <datestamp>2012-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0782</id><created>2012-01-03</created><authors><author><keyname>Hesselbach</keyname><forenames>Dirk</forenames></author></authors><title>Umgebungserfassungssystem fuer mobile Roboter (environment logging
  system for mobile autonomous robots)</title><categories>cs.RO cs.AR</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This diploma thesis describes the theoretical bases, the conception of the
module and the final result of the development process in application. for the
environment logging with a small mobile robot for interiors should be sketched
an economical alternative to the expensive laser scanners. the structure, color
or the material of the objects in the radius of action, as well as the
environment brightness and illuminating are to have thereby no influence on the
results of measurement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0794</identifier>
 <datestamp>2013-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0794</id><created>2012-01-03</created><updated>2013-01-07</updated><authors><author><keyname>Lafferty</keyname><forenames>John</forenames></author><author><keyname>Liu</keyname><forenames>Han</forenames></author><author><keyname>Wasserman</keyname><forenames>Larry</forenames></author></authors><title>Sparse Nonparametric Graphical Models</title><categories>stat.ML cs.LG stat.ME</categories><comments>Published in at http://dx.doi.org/10.1214/12-STS391 the Statistical
  Science (http://www.imstat.org/sts/) by the Institute of Mathematical
  Statistics (http://www.imstat.org)</comments><proxy>vtex</proxy><report-no>IMS-STS-STS391</report-no><journal-ref>Statistical Science 2012, Vol. 27, No. 4, 519-537</journal-ref><doi>10.1214/12-STS391</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present some nonparametric methods for graphical modeling. In the discrete
case, where the data are binary or drawn from a finite alphabet, Markov random
fields are already essentially nonparametric, since the cliques can take only a
finite number of values. Continuous data are different. The Gaussian graphical
model is the standard parametric model for continuous data, but it makes
distributional assumptions that are often unrealistic. We discuss two
approaches to building more flexible graphical models. One allows arbitrary
graphs and a nonparametric extension of the Gaussian; the other uses kernel
density estimation and restricts the graphs to trees and forests. Examples of
both methods are presented. We also discuss possible future research directions
for nonparametric graphical modeling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0824</identifier>
 <datestamp>2012-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0824</id><created>2012-01-04</created><authors><author><keyname>Zenil</keyname><forenames>Hector</forenames></author></authors><title>On the Dynamic Qualitative Behaviour of Universal Computation</title><categories>cs.CC math.DS nlin.CG</categories><comments>forthcoming in Complex Systems vol. 20</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We explore the possible connections between the dynamic behaviour of a system
and Turing universality in terms of the system's ability to (effectively)
transmit and manipulate information. Some arguments will be provided using a
defined compression-based transition coefficient which quantifies the
sensitivity of a system to being programmed. In the same spirit, a list of
conjectures concerning the ability of Busy Beaver Turing machines to perform
universal computation will be formulated. The main working hypothesis is that
universality is deeply connected to the qualitative behaviour of a system,
particularly to its ability to react to external stimulus--as it needs to be
programmed--and to its capacity for transmitting this information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0825</identifier>
 <datestamp>2012-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0825</id><created>2012-01-04</created><authors><author><keyname>Zenil</keyname><forenames>Hector</forenames></author></authors><title>Computer Runtimes and the Length of Proofs: On an Algorithmic
  Probabilistic Application to Waiting Times in Automatic Theorem Proving</title><categories>cs.CC cs.LO math.LO</categories><comments>forthcoming in M.J. Dinneen, B Khoussainov and A. Nies (eds),
  &quot;Computation, Physics and Beyond&quot;, LNCS, Springer (Cristian S. Calude
  festschrift)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is an experimental exploration of the relationship between the
runtimes of Turing machines and the length of proofs in formal axiomatic
systems. We compare the number of halting Turing machines of a given size to
the number of provable theorems of first-order logic of a given size, and the
runtime of the longest-running Turing machine of a given size to the proof
length of the most-difficult-to-prove theorem of a given size. It is suggested
that theorem provers are subject to the same non-linear tradeoff between time
and size as computer programs are, affording the possibility of determining
optimal timeouts and waiting times in automatic theorem proving. I provide the
statistics for some small choices of parameters for both of these systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0830</identifier>
 <datestamp>2012-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0830</id><created>2012-01-04</created><authors><author><keyname>Shukla</keyname><forenames>Srishti</forenames></author><author><keyname>Muralidharan</keyname><forenames>Vijayvaradharaj T.</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>Wireless Network-Coded Accumulate-Compute and Forward Two-Way Relaying</title><categories>cs.IT math.IT</categories><comments>17 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The design of modulation schemes for the physical layer network-coded two way
wireless relaying scenario is considered. It was observed by Koike-Akino et al.
for the two way relaying scenario, that adaptively changing the network coding
map used at the relay according to the channel conditions greatly reduces the
impact of multiple access interference which occurs at the relay during the MA
Phase and all these network coding maps should satisfy a requirement called
exclusive law. We extend this approach to an Accumulate-Compute and Forward
protocol which employs two phases: Multiple Access (MA) phase consisting of two
channel uses with independent messages in each channel use, and Broadcast (BC)
phase having one channel use. Assuming that the two users transmit points from
the same 4-PSK constellation, every such network coding map that satisfies the
exclusive law can be represented by a Latin Square with side 16, and
conversely, this relationship can be used to get the network coding maps
satisfying the exclusive law. Two methods of obtaining this network coding map
to be used at the relay are discussed. Using the structural properties of the
Latin Squares for a given set of parameters, the problem of finding all the
required maps is reduced to finding a small set of maps. Having obtained all
the Latin Squares, the set of all possible channel realizations is quantized,
depending on which one of the Latin Squares obtained optimizes the performance.
The quantization thus obtained, is shown to be the same as the one obtained in
[7] for the 2-stage bidirectional relaying.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0834</identifier>
 <datestamp>2012-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0834</id><created>2012-01-04</created><authors><author><keyname>Shavitt</keyname><forenames>Yuval</forenames></author><author><keyname>Weinsberg</keyname><forenames>Udi</forenames></author></authors><title>Topological Trends of Internet Content Providers</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Internet is constantly changing, and its hierarchy was recently shown to
become flatter. Recent studies of inter-domain traffic showed that large
content providers drive this change by bypassing tier-1 networks and reaching
closer to their users, enabling them to save transit costs and reduce reliance
of transit networks as new services are being deployed, and traffic shaping is
becoming increasingly popular.
  In this paper we take a first look at the evolving connectivity of large
content provider networks, from a topological point of view of the autonomous
systems (AS) graph. We perform a 5-year longitudinal study of the topological
trends of large content providers, by analyzing several large content providers
and comparing these trends to those observed for large tier-1 networks. We
study trends in the connectivity of the networks, neighbor diversity and
geographical spread, their hierarchy, the adoption of IXPs as a convenient
method for peering, and their centrality. Our observations indicate that
content providers gradually increase and diversify their connectivity, enabling
them to improve their centrality in the graph, and as a result, tier-1 networks
lose dominance over time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0838</identifier>
 <datestamp>2012-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0838</id><created>2012-01-04</created><updated>2012-04-05</updated><authors><author><keyname>Zeng</keyname><forenames>Jia</forenames></author></authors><title>A Topic Modeling Toolbox Using Belief Propagation</title><categories>cs.LG</categories><comments>4 pages</comments><journal-ref>Journal of Machine Learning Research (13) 2233-2236, 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Latent Dirichlet allocation (LDA) is an important hierarchical Bayesian model
for probabilistic topic modeling, which attracts worldwide interests and
touches on many important applications in text mining, computer vision and
computational biology. This paper introduces a topic modeling toolbox (TMBP)
based on the belief propagation (BP) algorithms. TMBP toolbox is implemented by
MEX C++/Matlab/Octave for either Windows 7 or Linux. Compared with existing
topic modeling packages, the novelty of this toolbox lies in the BP algorithms
for learning LDA-based topic models. The current version includes BP algorithms
for latent Dirichlet allocation (LDA), author-topic models (ATM), relational
topic models (RTM), and labeled LDA (LaLDA). This toolbox is an ongoing project
and more BP-based algorithms for various topic models will be added in the near
future. Interested users may also extend BP algorithms for learning more
complicated topic models. The source codes are freely available under the GNU
General Public Licence, Version 1.0 at https://mloss.org/software/view/399/.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0842</identifier>
 <datestamp>2012-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0842</id><created>2012-01-04</created><authors><author><keyname>Siraj</keyname><forenames>M.</forenames></author><author><keyname>Kanrar</keyname><forenames>Soumen</forenames></author></authors><title>Performance of Modeling wireless networks in realistic environment</title><categories>cs.NI</categories><comments>18 pages, 16 figures; ISSN:1985-4129</comments><journal-ref>International Journal of Computer Networks Volume:2, Issue:1,
  pages 62-79 (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A wireless network is realized by mobile devices which communicate over radio
channels. Since, experiments of real life problem with real devices are very
difficult, simulation is used very often. Among many other important properties
that have to be defined for simulative experiments, the mobility model and the
radio propagation model have to be selected carefully. Both have strong impact
on the performance of mobile wireless networks, e.g., the performance of
routing protocols varies with these models. There are many mobility and radio
propagation models proposed in literature. Each of them was developed with
different objectives and is not suited for every physical scenario. The radio
propagation models used in common wireless network simulators, in general
researcher consider simple radio propagation models and neglect obstacles in
the propagation environment. In this paper, we study the performance of
wireless networks simulation by consider different Radio propagation models
with considering obstacles in the propagation environment. In this paper we
analyzed the performance of wireless networks by OPNET Modeler .In this paper
we quantify the parameters such as throughput, packet received attenuation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0849</identifier>
 <datestamp>2012-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0849</id><created>2012-01-04</created><updated>2012-10-10</updated><authors><author><keyname>Buhrman</keyname><forenames>Harry</forenames></author><author><keyname>Christandl</keyname><forenames>Matthias</forenames></author><author><keyname>Schaffner</keyname><forenames>Christian</forenames></author></authors><title>Complete Insecurity of Quantum Protocols for Classical Two-Party
  Computation</title><categories>quant-ph cs.CR</categories><comments>v2: 6 pages, 1 figure, text identical to PRL-version (but reasonably
  formatted)</comments><journal-ref>Phys. Rev. Lett. 109, 160501 (2012)</journal-ref><doi>10.1103/PhysRevLett.109.160501</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A fundamental task in modern cryptography is the joint computation of a
function which has two inputs, one from Alice and one from Bob, such that
neither of the two can learn more about the other's input than what is implied
by the value of the function. In this Letter, we show that any quantum protocol
for the computation of a classical deterministic function that outputs the
result to both parties (two-sided computation) and that is secure against a
cheating Bob can be completely broken by a cheating Alice. Whereas it is known
that quantum protocols for this task cannot be completely secure, our result
implies that security for one party implies complete insecurity for the other.
Our findings stand in stark contrast to recent protocols for weak coin tossing,
and highlight the limits of cryptography within quantum mechanics. We remark
that our conclusions remain valid, even if security is only required to be
approximate and if the function that is computed for Bob is different from that
of Alice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0851</identifier>
 <datestamp>2012-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0851</id><created>2012-01-04</created><authors><author><keyname>Vrtanoski</keyname><forenames>Jordan</forenames></author><author><keyname>Stojanovski</keyname><forenames>Toni</forenames></author></authors><title>Order Handling in Convergent Environments</title><categories>cs.SE</categories><journal-ref>2nd International Conference on e-Education, e-Business,
  e-Management and E-Learning IC4E 2011, 7-9, January 2011, Mumbai, India. pp.
  378-382</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The rapid development of IT&amp;T technology had big impact on the traditional
telecommunications market, transforming it from monopolistic market to highly
competitive high-tech market where new services are required to be created
frequently. This paper aims to describe a design approach that puts order
management process (as part of enterprise application integration) in function
of rapid service creation. In the text we will present a framework for
collaborative order handling supporting convergent services. The design splits
the order handling processes in convergent environments in three business
process groups: order capture, order management and order fulfillment. The
paper establishes abstract framework for order handling and provides design
guidelines for transaction handling implementation based on the checkpoint and
inverse command strategy. The proposed design approach is based in a convergent
telecommunication environment. Same principles are applicable in solving
problems of collaboration in function of order processing in any given
heterogeneous environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0853</identifier>
 <datestamp>2012-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0853</id><created>2012-01-04</created><authors><author><keyname>Stojanovski</keyname><forenames>Toni</forenames></author><author><keyname>Dzekov</keyname><forenames>Tomislav</forenames></author></authors><title>Rapid Application Development Using Software Factories</title><categories>cs.SE</categories><comments>Annual proceedings at EURM, 2009, Skopje, Macedonia</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Software development is still based on manufactory production, and most of
the programming code is still hand-crafted. Software development is very far
away from the ultimate goal of industrialization in software production,
something which has been achieved long time ago in the other industries. The
lack of software industrialization creates an inability to cope with fast and
frequent changes in user requirements, and causes cost and time inefficiencies
during their implementation. Analogous to what other industries had done long
time ago, industrialization of software development has been proposed using the
concept of software factories. We have accepted this vision about software
factories, and developed our own software factory which produces three-layered
ASP.NET web applications. In this paper we report about our experience with
using this approach in the process of software development, and present
comparative results on performances and deliverables in both traditional
development and development using software factories.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0856</identifier>
 <datestamp>2015-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0856</id><created>2012-01-04</created><updated>2015-12-07</updated><authors><author><keyname>Bodirsky</keyname><forenames>Manuel</forenames></author></authors><title>Complexity Classification in Infinite-Domain Constraint Satisfaction</title><categories>cs.CC cs.AI cs.DM cs.LO math.LO</categories><comments>M\'emoire pour l'obtention d'une HDR \`a l'universit\'e Paris 7. 263
  pages. Version 2 has been prepared after the defense, and now contains the
  official header with information about the HDR jury. Versions 3-7: several
  inaccuracies have been removed</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  A constraint satisfaction problem (CSP) is a computational problem where the
input consists of a finite set of variables and a finite set of constraints,
and where the task is to decide whether there exists a satisfying assignment of
values to the variables. Depending on the type of constraints that we allow in
the input, a CSP might be tractable, or computationally hard. In recent years,
general criteria have been discovered that imply that a CSP is polynomial-time
tractable, or that it is NP-hard. Finite-domain CSPs have become a major common
research focus of graph theory, artificial intelligence, and finite model
theory. It turned out that the key questions for complexity classification of
CSPs are closely linked to central questions in universal algebra.
  This thesis studies CSPs where the variables can take values from an infinite
domain. This generalization enhances dramatically the range of computational
problems that can be modeled as a CSP. Many problems from areas that have so
far seen no interaction with constraint satisfaction theory can be formulated
using infinite domains, e.g. problems from temporal and spatial reasoning,
phylogenetic reconstruction, and operations research.
  It turns out that the universal-algebraic approach can also be applied to
study large classes of infinite-domain CSPs, yielding elegant complexity
classification results. A new tool in this thesis that becomes relevant
particularly for infinite domains is Ramsey theory. We demonstrate the
feasibility of our approach with two complete complexity classification
results: one on CSPs in temporal reasoning, the other on a generalization of
Schaefer's theorem for propositional logic to logic over graphs. We also study
the limits of complexity classification, and present classes of computational
problems provably do not exhibit a complexity dichotomy into hard and easy
problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0874</identifier>
 <datestamp>2012-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0874</id><created>2012-01-04</created><authors><author><keyname>Biernacki</keyname><forenames>Dariusz</forenames></author><author><keyname>Lenglet</keyname><forenames>Serguei</forenames></author></authors><title>Applicative Bisimulations for Delimited-Control Operators</title><categories>cs.PL</categories><comments>A long version of an article accepted at FoSSaCS 2012</comments><acm-class>D.3.1; D.3.3; F.3.2; F.3.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a behavioral theory for the untyped call-by-value lambda calculus
extended with the delimited-control operators shift and reset. For this
calculus, we discuss the possible observable behaviors and we define an
applicative bisimilarity that characterizes contextual equivalence. We then
compare the applicative bisimilarity and the CPS equivalence, a relation on
terms often used in studies of control operators. In the process, we illustrate
how bisimilarity can be used to prove equivalence of terms with
delimited-control effects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0876</identifier>
 <datestamp>2012-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0876</id><created>2012-01-04</created><authors><author><keyname>Hajdu</keyname><forenames>Andras</forenames></author><author><keyname>Hajdu</keyname><forenames>Lajos</forenames></author><author><keyname>Tijdeman</keyname><forenames>Robert</forenames></author></authors><title>Approximations of the Euclidean distance by chamfer distances</title><categories>cs.IT math.IT</categories><comments>Preprint submitted to Acta Cybernetica, 20 pages</comments><msc-class>41A50, 68U10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Chamfer distances play an important role in the theory of distance
transforms. Though the determination of the exact Euclidean distance transform
is also a well investigated area, the classical chamfering method based upon
&quot;small&quot; neighborhoods still outperforms it e.g. in terms of computation time.
In this paper we determine the best possible maximum relative error of chamfer
distances under various boundary conditions. In each case some best
approximating sequences are explicitly given. Further, because of possible
practical interest, we give all best approximating sequences in case of small
(i.e. 5 by 5 and 7 by 7) neighborhoods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0882</identifier>
 <datestamp>2012-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0882</id><created>2012-01-04</created><authors><author><keyname>Paulin</keyname><forenames>Alois</forenames></author></authors><title>Towards Self-Service Governance by Means of Information Technology</title><categories>cs.CY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a novel model for governing societies based on
modern information technology, which neither relies on manual bureaucratic
labor, nor depends on process-based e-government services for governance. We
expose the flaws of the later and argue that it is not feasible for sustainable
governance due to permanently changing laws and instead propose a model in
which people can govern themselves in a self-service manner by relying on
constellations of data stored in a network of governmental databases to which
citizen and officials have read- and write access under rules defined by
temporary valid law.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0883</identifier>
 <datestamp>2012-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0883</id><created>2012-01-04</created><authors><author><keyname>Han</keyname><forenames>Weiwei</forenames></author></authors><title>Weaknesses of a dynamic identity based authentication protocol for
  multi-server architecture</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, Li et al. proposed a dynamic identity based authentication protocol
for multi-server architecture. They claimed their protocol is secure and can
withstand various attacks. But we found some security loopholes in the
protocol. Accordingly, the current paper demonstrates that Li et al.'s protocol
is vulnerable to the replay attack, the password guessing attack and the
masquerade attack.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0887</identifier>
 <datestamp>2013-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0887</id><created>2012-01-04</created><updated>2013-08-26</updated><authors><author><keyname>Suk</keyname><forenames>Andrew</forenames></author></authors><title>Coloring intersection graphs of x-monotone curves in the plane</title><categories>math.CO cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A class of graphs G is chi-bounded if the chromatic number of the graphs in G
is bounded by some function of their clique number. We show that the class of
intersection graphs of simple x-monotone curves in the plane intersecting a
vertical line is chi-bounded. As a corollary we show that the class of
intersection graphs of rays in the plane is chi-bounded, and the class of
intersection graphs of unit segments in the plane is chi-bounded
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0891</identifier>
 <datestamp>2012-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0891</id><created>2012-01-04</created><authors><author><keyname>Li</keyname><forenames>Yangjia</forenames></author><author><keyname>Yu</keyname><forenames>Nengkun</forenames></author><author><keyname>Ying</keyname><forenames>Mingsheng</forenames></author></authors><title>Termination of Nondeterministic Quantum Programs</title><categories>cs.LO quant-ph</categories><acm-class>F.3.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We define a language-independent model of nondeterministic quantum programs
in which a quantum program consists of a finite set of quantum processes. These
processes are represented by quantum Markov chains over the common state space.
An execution of a nondeterministic quantum program is modeled by a sequence of
actions of individual processes. These actions are described by super-operators
on the state Hilbert space. At each step of an execution, a process is chosen
nondeterministically to perform the next action. A characterization of
reachable space and a characterization of diverging states of a
nondeterministic quantum program are presented. We establish a zero-one law for
termination probability of the states in the reachable space of a
nondeterministic quantum program. A combination of these results leads to a
necessary and sufficient condition for termination of nondeterministic quantum
programs. Based on this condition, an algorithm is found for checking
termination of nondeterministic quantum programs within a fixed
finite-dimensional state space. A striking difference between nondeterministic
classical and quantum programs is shown by example: it is possible that each of
several quantum programs simulates the same classical program which terminates
with probability 1, but the nondeterministic program consisting of them
terminates with probability 0 due to the interference carried in the execution
of them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0901</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0901</id><created>2012-01-04</created><updated>2014-02-10</updated><authors><author><keyname>Pompili</keyname><forenames>Filippo</forenames></author><author><keyname>Gillis</keyname><forenames>Nicolas</forenames></author><author><keyname>Absil</keyname><forenames>P. -A.</forenames></author><author><keyname>Glineur</keyname><forenames>Fran&#xe7;ois</forenames></author></authors><title>Two Algorithms for Orthogonal Nonnegative Matrix Factorization with
  Application to Clustering</title><categories>math.OC cs.IR</categories><comments>17 pages, 8 figures. New numerical experiments (document and
  synthetic data sets)</comments><journal-ref>Neurocomputing 141, pp. 15-25, 2014</journal-ref><doi>10.1016/j.neucom.2014.02.018</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Approximate matrix factorization techniques with both nonnegativity and
orthogonality constraints, referred to as orthogonal nonnegative matrix
factorization (ONMF), have been recently introduced and shown to work
remarkably well for clustering tasks such as document classification. In this
paper, we introduce two new methods to solve ONMF. First, we show athematical
equivalence between ONMF and a weighted variant of spherical k-means, from
which we derive our first method, a simple EM-like algorithm. This also allows
us to determine when ONMF should be preferred to k-means and spherical k-means.
Our second method is based on an augmented Lagrangian approach. Standard ONMF
algorithms typically enforce nonnegativity for their iterates while trying to
achieve orthogonality at the limit (e.g., using a proper penalization term or a
suitably chosen search direction). Our method works the opposite way:
orthogonality is strictly imposed at each step while nonnegativity is
asymptotically obtained, using a quadratic penalty. Finally, we show that the
two proposed approaches compare favorably with standard ONMF algorithms on
synthetic, text and image data sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0913</identifier>
 <datestamp>2012-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0913</id><created>2012-01-02</created><authors><author><keyname>Kim</keyname><forenames>Na-Rae</forenames></author><author><keyname>Chae</keyname><forenames>Chan-Byoung</forenames></author></authors><title>Novel Modulation Techniques using Isomers as Messenger Molecules for
  Molecular Communication via Diffusion</title><categories>q-bio.QM cs.CE cs.IT math.IT</categories><comments>5 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose novel modulation techniques using isomers as
messenger molecules for nano communication via diffusion. To evaluate
achievable rate performance, we compare the proposed techniques with
concentration-based and molecular-type-based methods. Analytical and numerical
results confirm that the proposed modulation techniques achieve higher data
transmission rate performance than conventional insulin based concepts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0917</identifier>
 <datestamp>2012-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0917</id><created>2012-01-04</created><authors><author><keyname>Kratochv&#xed;l</keyname><forenames>Jan</forenames></author><author><keyname>Ueckerdt</keyname><forenames>Torsten</forenames></author></authors><title>Non-crossing Connectors in the Plane</title><categories>cs.CG cs.DM math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the non-crossing connectors problem, which is stated as follows:
Given n simply connected regions R_1,...,R_n in the plane and finite point sets
P_i subset of R_i for i=1,...,n, are there non-crossing connectors y_i for
(R_i,P_i), i.e., arc-connected sets y_i with P_i subset of y_i subset of R_i
for every i=1,...,n, such that y_i and y_j are disjoint for all i different
from j?
  We prove that non-crossing connectors do always exist if the regions form a
collection of pseudo-disks, i.e., the boundaries of every pair of regions
intersect at most twice. We provide a simple polynomial-time algorithm if the
regions are axis-aligned rectangles. Finally we prove that the general problem
is NP-complete, even if the regions are convex, the boundaries of every pair of
regions intersect at most four times and P_i consists of only two points on the
boundary of R_i for i=1,...,n.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0925</identifier>
 <datestamp>2012-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0925</id><created>2011-12-30</created><authors><author><keyname>Afsari</keyname><forenames>Bijan</forenames></author><author><keyname>Tron</keyname><forenames>Roberto</forenames></author><author><keyname>Vidal</keyname><forenames>Ren&#xe9;</forenames></author></authors><title>On The Convergence of Gradient Descent for Finding the Riemannian Center
  of Mass</title><categories>math.DG cs.CV cs.NA math.NA math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of finding the global Riemannian center of mass of a set
of data points on a Riemannian manifold. Specifically, we investigate the
convergence of constant step-size gradient descent algorithms for solving this
problem. The challenge is that often the underlying cost function is neither
globally differentiable nor convex, and despite this one would like to have
guaranteed convergence to the global minimizer. After some necessary
preparations we state a conjecture which we argue is the best (in a sense
described) convergence condition one can hope for. The conjecture specifies
conditions on the spread of the data points, step-size range, and the location
of the initial condition (i.e., the region of convergence) of the algorithm.
These conditions depend on the topology and the curvature of the manifold and
can be conveniently described in terms of the injectivity radius and the
sectional curvatures of the manifold. For manifolds of constant nonnegative
curvature (e.g., the sphere and the rotation group in $\mathbb{R}^{3}$) we show
that the conjecture holds true (we do this by proving and using a comparison
theorem which seems to be of a different nature from the standard comparison
theorems in Riemannian geometry). For manifolds of arbitrary curvature we prove
convergence results which are weaker than the conjectured one (but still
superior over the available results). We also briefly study the effect of the
configuration of the data points on the speed of convergence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0940</identifier>
 <datestamp>2012-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0940</id><created>2012-01-04</created><authors><author><keyname>Bouvel</keyname><forenames>Mathilde</forenames></author><author><keyname>Chauve</keyname><forenames>Cedric</forenames></author><author><keyname>Mishna</keyname><forenames>Marni</forenames></author><author><keyname>Rossin</keyname><forenames>Dominique</forenames></author></authors><title>Average-case analysis of perfect sorting by reversals (Journal Version)</title><categories>cs.DM cs.DS math.CO q-bio.QM</categories><comments>A preliminary version of this work appeared in the proceedings of
  Combinatorial Pattern Matching (CPM) 2009. See arXiv:0901.2847; Discrete
  Mathematics, Algorithms and Applications, vol. 3(3), 2011</comments><msc-class>05A05, 05A16, 05C90, 05C05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Perfect sorting by reversals, a problem originating in computational
genomics, is the process of sorting a signed permutation to either the identity
or to the reversed identity permutation, by a sequence of reversals that do not
break any common interval. B\'erard et al. (2007) make use of strong interval
trees to describe an algorithm for sorting signed permutations by reversals.
Combinatorial properties of this family of trees are essential to the algorithm
analysis. Here, we use the expected value of certain tree parameters to prove
that the average run-time of the algorithm is at worst, polynomial, and
additionally, for sufficiently long permutations, the sorting algorithm runs in
polynomial time with probability one. Furthermore, our analysis of the subclass
of commuting scenarios yields precise results on the average length of a
reversal, and the average number of reversals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0942</identifier>
 <datestamp>2014-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0942</id><created>2012-01-04</created><updated>2012-12-06</updated><authors><author><keyname>Janouchova</keyname><forenames>Eliska</forenames></author><author><keyname>Kucerova</keyname><forenames>Anna</forenames></author></authors><title>Competitive Comparison of Optimal Designs of Experiments for
  Sampling-based Sensitivity Analysis</title><categories>cs.CE cs.NA stat.ME</categories><comments>18 pages, 15 figures, 4 tables, CSC2011 special issue, corrected and
  extended after the first review</comments><journal-ref>Computers &amp; Structures, 124, 47-60, 2013</journal-ref><doi>10.1016/j.compstruc.2013.04.009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nowadays, the numerical models of real-world structures are more precise,
more complex and, of course, more time-consuming. Despite the growth of a
computational effort, the exploration of model behaviour remains a complex
task. The sensitivity analysis is a basic tool for investigating the
sensitivity of the model to its inputs. One widely used strategy to assess the
sensitivity is based on a finite set of simulations for a given sets of input
parameters, i.e. points in the design space. An estimate of the sensitivity can
be then obtained by computing correlations between the input parameters and the
chosen response of the model. The accuracy of the sensitivity prediction
depends on the choice of design points called the design of experiments. The
aim of the presented paper is to review and compare available criteria
determining the quality of the design of experiments suitable for
sampling-based sensitivity analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0945</identifier>
 <datestamp>2012-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0945</id><created>2012-01-04</created><authors><author><keyname>Gharibi</keyname><forenames>Wajeb</forenames></author></authors><title>Symbian `vulnerability' and Mobile Threats</title><categories>cs.CR</categories><comments>4 pages; International Journal of Computer Science and Information
  Security (IJCSIS), Vol. 9, No. 10, (2011)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modern technologies are becoming ever more integrated with each other. Mobile
phones are becoming increasing intelligent, and handsets are growing ever more
like computers in functionality. We are entering a new era - the age of smart
houses, global advanced networks which encompass a wide range of devices, all
of them exchanging data with each other. Such trends clearly open new horizons
to malicious users, and the potential threats are self evident. In this paper,
we study and discuss one of the most famous mobile operating systems 'Symbian';
its vulnerabilities and recommended protection technologies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0946</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0946</id><created>2012-01-04</created><authors><author><keyname>Kehagias</keyname><forenames>Athanasios</forenames></author><author><keyname>Mitsche</keyname><forenames>Dieter</forenames></author><author><keyname>Pralat</keyname><forenames>Pawel</forenames></author></authors><title>Cops and Invisible Robbers: the Cost of Drunkenness</title><categories>cs.DM cs.GT cs.RO math.CO math.PR</categories><msc-class>68R10, 91A24</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We examine a version of the Cops and Robber (CR) game in which the robber is
invisible, i.e., the cops do not know his location until they capture him.
Apparently this game (CiR) has received little attention in the CR literature.
We examine two variants: in the first the robber is adversarial (he actively
tries to avoid capture); in the second he is drunk (he performs a random walk).
Our goal in this paper is to study the invisible Cost of Drunkenness (iCOD),
which is defined as the ratio ct_i(G)/dct_i(G), with ct_i(G) and dct_i(G) being
the expected capture times in the adversarial and drunk CiR variants,
respectively. We show that these capture times are well defined, using game
theory for the adversarial case and partially observable Markov decision
processes (POMDP) for the drunk case. We give exact asymptotic values of iCOD
for several special graph families such as $d$-regular trees, give some bounds
for grids, and provide general upper and lower bounds for general classes of
graphs. We also give an infinite family of graphs showing that iCOD can be
arbitrarily close to any value in [2,infinty). Finally, we briefly examine one
more CiR variant, in which the robber is invisible and &quot;infinitely fast&quot;; we
argue that this variant is significantly different from the Graph Search game,
despite several similarities between the two games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0949</identifier>
 <datestamp>2012-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0949</id><created>2012-01-04</created><authors><author><keyname>Gharibi</keyname><forenames>Wajeb</forenames></author></authors><title>Some Recommended Protection Technologies for Cyber Crime Based on Social
  Engineering Techniques -- Phishing</title><categories>cs.CR</categories><comments>5 pages; Journal of Communication and Computer, USA, Vol. 8, No. 7,
  (2011)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Phishing (password + fishing) is a form of cyber crime based on social
engineering and site spoofing techniques. The name of 'phishing' is a conscious
misspelling of the word 'fishing' and involves stealing confidential data from
a user's computer and subsequently using the data to steal the user's money. In
this paper, we study, discuss and propose the phishing attack stages and types,
technologies for detection of phishing web pages, and conclude our paper with
some important recommendations for preventing phishing for both consumer and
company.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0954</identifier>
 <datestamp>2012-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0954</id><created>2012-01-04</created><authors><author><keyname>Hahanov</keyname><forenames>Vladimir</forenames></author><author><keyname>Gharibi</keyname><forenames>Wajeb</forenames></author><author><keyname>Litvinova</keyname><forenames>Eugenia</forenames></author><author><keyname>Chumachenko</keyname><forenames>Svetlana</forenames></author></authors><title>Information Analysis Infrastructure for Diagnosis</title><categories>cs.AR</categories><comments>15 pages; INFORMATION: An International Interdisciplinary Journal,
  Vol. 14, No. 7, July 2011. Tokyo. arXiv admin note: substantial text overlap
  with arXiv:1105.1973</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A high-speed multiprocessor architecture for brain-like analyzing information
represented in analytic, graph- and table forms of associative relations to
search, recognize and make a decision in n-dimensional vector discrete space is
offered. Vector-logical process models of actual applications, where the
quality of solution is estimated by the proposed integral non-arithmetical
metric of the interaction between binary vectors, are described. The
theoretical proof of the metric for a vector logical space and the quality
criteria for estimating solutions is created.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0959</identifier>
 <datestamp>2012-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0959</id><created>2012-01-04</created><authors><author><keyname>Rossi</keyname><forenames>Fabrice</forenames><affiliation>LTCI</affiliation></author><author><keyname>Lechevallier</keyname><forenames>Yves</forenames><affiliation>INRIA Rocquencourt / INRIA Sophia Antipolis</affiliation></author></authors><title>Constrained variable clustering and the best basis problem in functional
  data analysis</title><categories>stat.ML cs.LG</categories><proxy>ccsd</proxy><journal-ref>Classification and Multivariate Analysis for Complex Data
  Structures 435-444 (2011)</journal-ref><doi>10.1007/978-3-642-13312-1_46</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Functional data analysis involves data described by regular functions rather
than by a finite number of real valued variables. While some robust data
analysis methods can be applied directly to the very high dimensional vectors
obtained from a fine grid sampling of functional data, all methods benefit from
a prior simplification of the functions that reduces the redundancy induced by
the regularity. In this paper we propose to use a clustering approach that
targets variables rather than individual to design a piecewise constant
representation of a set of functions. The contiguity constraint induced by the
functional nature of the variables allows a polynomial complexity algorithm to
give the optimal solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0962</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0962</id><created>2012-01-04</created><updated>2012-02-07</updated><authors><author><keyname>Pagani</keyname><forenames>Giuliano Andrea</forenames></author><author><keyname>Aiello</keyname><forenames>Marco</forenames></author></authors><title>Power Grid Network Evolutions for Local Energy Trading</title><categories>physics.soc-ph cs.CE cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The shift towards an energy Grid dominated by prosumers (consumers and
producers of energy) will inevitably have repercussions on the distribution
infrastructure. Today it is a hierarchical one designed to deliver energy from
large scale facilities to end-users. Tomorrow it will be a capillary
infrastructure at the medium and Low Voltage levels that will support local
energy trading among prosumers. In our previous work, we analyzed the Dutch
Power Grid and made an initial analysis of the economic impact topological
properties have on decentralized energy trading. In this paper, we go one step
further and investigate how different networks topologies and growth models
facilitate the emergence of a decentralized market. In particular, we show how
the connectivity plays an important role in improving the properties of
reliability and path-cost reduction. From the economic point of view, we
estimate how the topological evolutions facilitate local electricity
distribution, taking into account the main cost ingredient required for
increasing network connectivity, i.e., the price of cabling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0963</identifier>
 <datestamp>2012-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0963</id><created>2012-01-04</created><authors><author><keyname>Da Silva</keyname><forenames>Alzennyr</forenames><affiliation>INRIA Rocquencourt / INRIA Sophia Antipolis</affiliation></author><author><keyname>Lechevallier</keyname><forenames>Yves</forenames><affiliation>INRIA Rocquencourt / INRIA Sophia Antipolis</affiliation></author><author><keyname>Rossi</keyname><forenames>Fabrice</forenames><affiliation>INRIA Rocquencourt / INRIA Sophia Antipolis</affiliation></author><author><keyname>De Carvahlo</keyname><forenames>Francisco De A. T.</forenames><affiliation>CIn</affiliation></author></authors><title>Clustering Dynamic Web Usage Data</title><categories>stat.ML cs.LG</categories><proxy>ccsd</proxy><journal-ref>Innovative Applications in Data Mining (2009) 71-82</journal-ref><doi>10.1007/978-3-540-88045-5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most classification methods are based on the assumption that data conforms to
a stationary distribution. The machine learning domain currently suffers from a
lack of classification techniques that are able to detect the occurrence of a
change in the underlying data distribution. Ignoring possible changes in the
underlying concept, also known as concept drift, may degrade the performance of
the classification model. Often these changes make the model inconsistent and
regular updatings become necessary. Taking the temporal dimension into account
during the analysis of Web usage data is a necessity, since the way a site is
visited may indeed evolve due to modifications in the structure and content of
the site, or even due to changes in the behavior of certain user groups. One
solution to this problem, proposed in this article, is to update models using
summaries obtained by means of an evolutionary approach based on an intelligent
clustering approach. We carry out various clustering strategies that are
applied on time sub-periods. To validate our approach we apply two external
evaluation criteria which compare different partitions from the same data set.
Our experiments show that the proposed approach is efficient to detect the
occurrence of changes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.0979</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.0979</id><created>2012-01-04</created><authors><author><keyname>Seshia</keyname><forenames>Sanjit A.</forenames></author></authors><title>Sciduction: Combining Induction, Deduction, and Structure for
  Verification and Synthesis</title><categories>cs.LO cs.AI cs.PL</categories><acm-class>B.5.2; C.3; I.2.2; I.2.3; I.2.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Even with impressive advances in automated formal methods, certain problems
in system verification and synthesis remain challenging. Examples include the
verification of quantitative properties of software involving constraints on
timing and energy consumption, and the automatic synthesis of systems from
specifications. The major challenges include environment modeling,
incompleteness in specifications, and the complexity of underlying decision
problems.
  This position paper proposes sciduction, an approach to tackle these
challenges by integrating inductive inference, deductive reasoning, and
structure hypotheses. Deductive reasoning, which leads from general rules or
concepts to conclusions about specific problem instances, includes techniques
such as logical inference and constraint solving. Inductive inference, which
generalizes from specific instances to yield a concept, includes algorithmic
learning from examples. Structure hypotheses are used to define the class of
artifacts, such as invariants or program fragments, generated during
verification or synthesis. Sciduction constrains inductive and deductive
reasoning using structure hypotheses, and actively combines inductive and
deductive reasoning: for instance, deductive techniques generate examples for
learning, and inductive reasoning is used to guide the deductive engines.
  We illustrate this approach with three applications: (i) timing analysis of
software; (ii) synthesis of loop-free programs, and (iii) controller synthesis
for hybrid systems. Some future applications are also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1018</identifier>
 <datestamp>2015-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1018</id><created>2012-01-04</created><updated>2015-09-25</updated><authors><author><keyname>Khelifi</keyname><forenames>Manel</forenames></author><author><keyname>Djabelkhir</keyname><forenames>Assia</forenames></author></authors><title>Un protocole de routage \`a basse consommation d'\'energie selon
  l'approche de clustering pour les r\'eseaux de capteurs sans fils</title><categories>cs.NI</categories><comments>in French. International Conference on Information Systems and
  Technologies (ICIST 2011), Algeria. ICIST'2011 : 1201.1018</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper we propose a new routing protocol with low energy consumption
for wireless sensor networks based on the clustering approach. Our protocol is
based on a strategy which aims at providing a more equitable exploitation of
the selected nodes (cluster-heads) energy by distributing their load of the
managed sensors during the clustering process. In order to save the energy
dissipated while transmitting sensed data to the base station, the multi-hops
routing strategy is used to arrange the communication of the data between
cluster-heads nodes. Simulation results demonstrate that our proposed protocol
decreases the energy consumption and prolongs the network lifetime.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1038</identifier>
 <datestamp>2012-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1038</id><created>2012-01-04</created><authors><author><keyname>Alamri</keyname><forenames>Nada</forenames></author><author><keyname>Akkari</keyname><forenames>Nadine</forenames></author></authors><title>UMTS-WiMAX Vertical Handover in Next Generation Wireless Networks</title><categories>cs.NI</categories><comments>20 pages, 20 figures, 4 tables, IJDPS; Nada Alamri and Nadine
  Akkari,&quot;UMTS-WiMAX Vertical Handover in Next Generation Wireless Networks&quot;,
  International Journal for Distributed and Parallel Systems (IJDPS),2011,
  vol.2, No,6</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The vision of next generation wireless network (NGWN) is to integrate
different wireless access technologies, each with its own characteristics, into
a common IP-based core network to provide mobile user with service continuity
and seamless roaming. One of the major issues for the converged heterogeneous
networks is providing a seamless vertical handover (VHO) with QoS support. In
this paper we have reviewed the various interworking architectures and handover
scenarios between UMTS and WiMAX. Also, we have compared the proposed solutions
based on different criteria and revealed the pros and cons of each scheme. The
comparison aids to adopt a better interworking and handover mechanism in NGWN.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1039</identifier>
 <datestamp>2012-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1039</id><created>2012-01-04</created><authors><author><keyname>Larsson</keyname><forenames>Urban</forenames></author></authors><title>Impartial games emulating one-dimensional cellular automata and
  undecidability</title><categories>math.CO cs.IT math.IT nlin.CG</categories><comments>22 pages, 11 figures</comments><msc-class>91A46, 68Q80</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study two-player \emph{take-away} games whose outcomes emulate two-state
one-dimensional cellular automata, such as Wolfram's rules 60 and 110. Given an
initial string consisting of a central data pattern and periodic left and right
patterns, the rule 110 cellular automaton was recently proved Turing-complete
by Matthew Cook. Hence, many questions regarding its behavior are
algorithmically undecidable. We show that similar questions are undecidable for
our \emph{rule 110} game.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1062</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1062</id><created>2012-01-05</created><authors><author><keyname>Chan</keyname><forenames>Terence H.</forenames></author><author><keyname>Grant</keyname><forenames>Alex</forenames></author></authors><title>Network Coding Capacity Regions via Entropy Functions</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Trans. on IT</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we use entropy functions to characterise the set of
rate-capacity tuples achievable with either zero decoding error, or vanishing
decoding error, for general network coding problems. We show that when sources
are colocated, the outer bound obtained by Yeung, A First Course in Information
Theory, Section 15.5 (2002) is tight and the sets of zero-error achievable and
vanishing-error achievable rate-capacity tuples are the same. We also
characterise the set of zero-error and vanishing-error achievable rate capacity
tuples for network coding problems subject to linear encoding constraints,
routing constraints (where some or all nodes can only perform routing) and
secrecy constraints. Finally, we show that even for apparently simple networks,
design of optimal codes may be difficult. In particular, we prove that for the
incremental multicast problem and for the single-source secure network coding
problem, characterisation of the achievable set is very hard and linear network
codes may not be optimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1065</identifier>
 <datestamp>2012-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1065</id><created>2012-01-05</created><authors><author><keyname>Van</keyname><forenames>Vo Tam</forenames></author><author><keyname>Mita</keyname><forenames>Seiichi</forenames></author></authors><title>A Novel Error Correcting System Based on Product Codes for Future
  Magnetic Recording Channels</title><categories>cs.IT math.IT</categories><comments>4 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel construction of product codes for high-density magnetic
recording based on binary low-density parity check (LDPC) codes and binary
image of Reed Solomon (RS) codes. Moreover, two novel algorithms are proposed
to decode the codes in the presence of both AWGN errors and scattered hard
errors (SHEs). Simulation results show that at a bit error rate (bER) of
approximately 10^-8, our method allows improving the error performance by
approximately 1.9dB compared with that of a hard decision decoder of RS codes
of the same length and code rate. For the mixed error channel including random
noises and SHEs, the signal-to-noise ratio (SNR) is set at 5dB and 150 to 400
SHEs are randomly generated. The bit error performance of the proposed product
code shows a significant improvement over that of equivalent random LDPC codes
or serial concatenation of LDPC and RS codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1081</identifier>
 <datestamp>2012-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1081</id><created>2012-01-05</created><authors><author><keyname>Paulin</keyname><forenames>Alois</forenames></author></authors><title>Secure SQL Server - Enabling Secure Access to Remote Relational Data</title><categories>cs.CY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Secure SQL Server - SecSS, is a technology primarily developed to enable
self-service governance of states, as described in (Paulin 2012). Self-service
governance is a novel model of governance that rejects service-based public
administration and instead proposes that governed subjects manage their legal
relations in a self-service manner, based on ad-hoc determination of
eligibilities. In this article we describe the prototype SecSS and its
evaluation in a complex governmental scenario.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1085</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1085</id><created>2012-01-05</created><authors><author><keyname>Tibely</keyname><forenames>Gergely</forenames></author><author><keyname>Pollner</keyname><forenames>Peter</forenames></author><author><keyname>Vicsek</keyname><forenames>Tamas</forenames></author><author><keyname>Palla</keyname><forenames>Gergely</forenames></author></authors><title>Ontologies and tag-statistics</title><categories>physics.soc-ph cs.IR stat.AP</categories><comments>Submitted to New Journal of Physics</comments><journal-ref>New J. Phys. 14: 053009, (2012)</journal-ref><doi>10.1088/1367-2630/14/5/053009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to the increasing popularity of collaborative tagging systems, the
research on tagged networks, hypergraphs, ontologies, folksonomies and other
related concepts is becoming an important interdisciplinary topic with great
actuality and relevance for practical applications. In most collaborative
tagging systems the tagging by the users is completely &quot;flat&quot;, while in some
cases they are allowed to define a shallow hierarchy for their own tags.
However, usually no overall hierarchical organisation of the tags is given, and
one of the interesting challenges of this area is to provide an algorithm
generating the ontology of the tags from the available data. In contrast, there
are also other type of tagged networks available for research, where the tags
are already organised into a directed acyclic graph (DAG), encapsulating the
&quot;is a sub-category of&quot; type of hierarchy between each other. In this paper we
study how this DAG affects the statistical distribution of tags on the nodes
marked by the tags in various real networks. We analyse the relation between
the tag-frequency and the position of the tag in the DAG in two large
sub-networks of the English Wikipedia and a protein-protein interaction
network. We also study the tag co-occurrence statistics by introducing a 2d
tag-distance distribution preserving both the difference in the levels and the
absolute distance in the DAG for the co-occurring pairs of tags. Our most
interesting finding is that the local relevance of tags in the DAG, (i.e.,
their rank or significance as characterised by, e.g., the length of the
branches starting from them) is much more important than their global distance
from the root. Furthermore, we also introduce a simple tagging model based on
random walks on the DAG, capable of reproducing the main statistical features
of tag co-occurrence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1090</identifier>
 <datestamp>2012-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1090</id><created>2012-01-05</created><updated>2012-02-07</updated><authors><author><keyname>Shokri-Ghadikolaei</keyname><forenames>Hossein</forenames></author><author><keyname>Sheikholeslami</keyname><forenames>Fatemeh</forenames></author><author><keyname>Nasiri-Kenari</keyname><forenames>Masoumeh</forenames></author></authors><title>Distributed Multiuser Sequential Channel Sensing Schemes in Multichannel
  Cognitive Radio Networks</title><categories>cs.NI cs.PF math.PR</categories><comments>This paper has been withdrawn</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn by the author due to a crucial problem
associated with Figs. 2 and 3.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1095</identifier>
 <datestamp>2013-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1095</id><created>2012-01-05</created><authors><author><keyname>Yordzhev</keyname><forenames>Krasimir</forenames></author></authors><title>An Entertaining Example of Using the Concepts of Context-Free Grammar
  and Pushdown Automation</title><categories>cs.FL</categories><journal-ref>Open Journal of Discrete Mathematics, 2012, 2, 105-108</journal-ref><doi>10.4236/ojdm.2012.23020</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A formal-linguistic approach for solving an entertaining task is made in this
paper. The well-known task of the Hanoi towers is discussed in relation to some
concepts of discrete mathematics. A context-free grammar which generate an
algorithm for solving this task is described. A deterministic pushdown
automation which in its work imitates the work of monks in solving the task of
the Hanoi towers is built.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1096</identifier>
 <datestamp>2012-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1096</id><created>2012-01-05</created><authors><author><keyname>Murthy</keyname><forenames>Garimella Rama</forenames></author></authors><title>Gibbs-Shannon Entropy and Related Measures: Tsallis Entropy</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this research paper, it is proved that an approximation to Gibbs-Shannon
entropy measure naturally leads to Tsallis entropy for the real parameter q =2
. Several interesting measures based on the input as well as output of a
discrete memoryless channel are provided and some of the properties of those
measures are discussed. It is expected that these results will be of utility in
Information Theoretic research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1101</identifier>
 <datestamp>2012-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1101</id><created>2012-01-05</created><authors><author><keyname>Lenglet</keyname><forenames>Sergue&#xef;</forenames></author><author><keyname>Wells</keyname><forenames>J. B.</forenames></author></authors><title>Expansion for Universal Quantifiers</title><categories>cs.PL</categories><comments>Long version of the corresponding ESOP 2012 paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Expansion is an operation on typings (i.e., pairs of typing environments and
result types) defined originally in type systems for the lambda-calculus with
intersection types in order to obtain principal (i.e., most informative,
strongest) typings. In a type inference scenario, expansion allows postponing
choices for whether and how to use non-syntax-driven typing rules (e.g.,
intersection introduction) until enough information has been gathered to make
the right decision. Furthermore, these choices can be equivalent to inserting
uses of such typing rules at deeply nested positions in a typing derivation,
without needing to actually inspect or modify (or even have) the typing
derivation. Expansion has in recent years become simpler due to the use of
expansion variables (e.g., in System E).
  This paper extends expansion and expansion variables to systems with
forall-quantifiers. We present System Fs, an extension of System F with
expansion, and prove its main properties. This system turns type inference into
a constraint solving problem; this could be helpful to design a modular type
inference algorithm for System F types in the future.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1119</identifier>
 <datestamp>2012-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1119</id><created>2012-01-05</created><authors><author><keyname>Leivant</keyname><forenames>Daniel</forenames><affiliation>Indiana University and LORIA Nancy</affiliation></author><author><keyname>Ramyaa</keyname><forenames>Ramyaa</forenames><affiliation>Indiana University and Ludwig-Maximilians-Universit&#xe4;t M&#xfc;nchen</affiliation></author></authors><title>Implicit complexity for coinductive data: a characterization of
  corecurrence</title><categories>cs.CC cs.LO</categories><comments>In Proceedings DICE 2011, arXiv:1201.0345</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 75, 2012, pp. 1-14</journal-ref><doi>10.4204/EPTCS.75.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a framework for reasoning about programs that manipulate
coinductive data as well as inductive data. Our approach is based on using
equational programs, which support a seamless combination of computation and
reasoning, and using productivity (fairness) as the fundamental assertion,
rather than bi-simulation. The latter is expressible in terms of the former. As
an application to this framework, we give an implicit characterization of
corecurrence: a function is definable using corecurrence iff its productivity
is provable using coinduction for formulas in which data-predicates do not
occur negatively. This is an analog, albeit in weaker form, of a
characterization of recurrence (i.e. primitive recursion) in [Leivant, Unipolar
induction, TCS 318, 2004].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1120</identifier>
 <datestamp>2012-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1120</id><created>2012-01-05</created><authors><author><keyname>Aubert</keyname><forenames>Cl&#xe9;ment</forenames><affiliation>LIPN - UMR7030 CNRS - Universit&#xe9; Paris 13</affiliation></author></authors><title>Sublogarithmic uniform Boolean proof nets</title><categories>cs.CC cs.LO</categories><comments>In Proceedings DICE 2011, arXiv:1201.0345</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 75, 2012, pp. 15-27</journal-ref><doi>10.4204/EPTCS.75.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using a proofs-as-programs correspondence, Terui was able to compare two
models of parallel computation: Boolean circuits and proof nets for
multiplicative linear logic. Mogbil et. al. gave a logspace translation
allowing us to compare their computational power as uniform complexity classes.
This paper presents a novel translation in AC0 and focuses on a simpler
restricted notion of uniform Boolean proof nets. We can then encode
constant-depth circuits and compare complexity classes below logspace, which
were out of reach with the previous translations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1121</identifier>
 <datestamp>2012-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1121</id><created>2012-01-05</created><authors><author><keyname>Makarov</keyname><forenames>Evgeny</forenames><affiliation>INRIA</affiliation></author></authors><title>Provably Total Functions of Arithmetic with Basic Terms</title><categories>cs.LO</categories><comments>In Proceedings DICE 2011, arXiv:1201.0345</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 75, 2012, pp. 28-32</journal-ref><doi>10.4204/EPTCS.75.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new characterization of provably recursive functions of first-order
arithmetic is described. Its main feature is using only terms consisting of 0,
the successor S and variables in the quantifier rules, namely, universal
elimination and existential introduction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1122</identifier>
 <datestamp>2012-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1122</id><created>2012-01-05</created><authors><author><keyname>Capedevielle</keyname><forenames>Lucien</forenames><affiliation>ENS de Lyon</affiliation></author></authors><title>A type system for PSPACE derived from light linear logic</title><categories>cs.CC cs.LO</categories><comments>In Proceedings DICE 2011, arXiv:1201.0345</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 75, 2012, pp. 33-46</journal-ref><doi>10.4204/EPTCS.75.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a polymorphic type system for lambda calculus ensuring that
well-typed programs can be executed in polynomial space: dual light affine
logic with booleans (DLALB).
  To build DLALB we start from DLAL (which has a simple type language with a
linear and an intuitionistic type arrow, as well as one modality) which
characterizes FPTIME functions. In order to extend its expressiveness we add
two boolean constants and a conditional constructor in the same way as with the
system STAB.
  We show that the value of a well-typed term can be computed by an alternating
machine in polynomial time, thus such a term represents a program of PSPACE
(given that PSPACE = APTIME).
  We also prove that all polynomial space decision functions can be represented
in DLALB.
  Therefore DLALB characterizes PSPACE predicates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1134</identifier>
 <datestamp>2012-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1134</id><created>2012-01-05</created><updated>2012-09-06</updated><authors><author><keyname>Diaz</keyname><forenames>Jesus</forenames></author><author><keyname>Arroyo</keyname><forenames>David</forenames></author><author><keyname>Rodriguez</keyname><forenames>Francisco B.</forenames></author></authors><title>Formal security analysis of registration protocols for interactive
  systems: a methodology and a case of study</title><categories>cs.CR</categories><comments>32 pages, 7 figures, 8 listings, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we present and formally analyze CHAT-SRP (CHAos based
Tickets-Secure Registration Protocol), a protocol to provide interactive and
collaborative platforms with a cryptographically robust solution to classical
security issues. Namely, we focus on the secrecy and authenticity properties
while keeping a high usability. In this sense, users are forced to blindly
trust the system administrators and developers. Moreover, as far as we know,
the use of formal methodologies for the verification of security properties of
communication protocols isn't yet a common practice. We propose here a
methodology to fill this gap, i.e., to analyse both the security of the
proposed protocol and the pertinence of the underlying premises. In this
concern, we propose the definition and formal evaluation of a protocol for the
distribution of digital identities. Once distributed, these identities can be
used to verify integrity and source of information. We base our security
analysis on tools for automatic verification of security protocols widely
accepted by the scientific community, and on the principles they are based
upon. In addition, it is assumed perfect cryptographic primitives in order to
focus the analysis on the exchange of protocol messages. The main property of
our protocol is the incorporation of tickets, created using digests of chaos
based nonces (numbers used only once) and users' personal data. Combined with a
multichannel authentication scheme with some previous knowledge, these tickets
provide security during the whole protocol by univocally linking each
registering user with a single request. [..]
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1157</identifier>
 <datestamp>2012-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1157</id><created>2012-01-05</created><authors><author><keyname>Yordzhev</keyname><forenames>Krasimir</forenames></author><author><keyname>Markovska</keyname><forenames>Ana</forenames></author></authors><title>Method of the Multidimensional Sieve in the Practical Realization of
  some Combinatorial Algorithms</title><categories>cs.DS</categories><journal-ref>International scientific conference &quot;UNITECH 07&quot;, Gabrovo,
  Bulgaria, vol. II, 2007, 451-456</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Some difficulties regarding the application of the well-known sieve method
are considered in the case when a practical (program) realization of selecting
elements, having a particular property among the elements of a set with a
sufficiently great cardinal number(cardinality). In this paper the problem has
been resolved by using a modified version of the method, utilizing
multidimensional arrays. As a theoretical illustration of the method of the
multidimensional sieve, the problem of obtaining a single representative of
each equivalence class with respect to a given relation of equivalence and
obtaining the cardinality of the respective factor set is considered with
relevant mathematical proofs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1162</identifier>
 <datestamp>2012-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1162</id><created>2012-01-05</created><authors><author><keyname>Knill</keyname><forenames>Oliver</forenames></author></authors><title>A graph theoretical Poincare-Hopf Theorem</title><categories>math.DG cs.CG cs.DM math.GN</categories><comments>9 figures</comments><msc-class>05C10, 57M15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce the index i(v) = 1 - X(S(v)) for critical points of a locally
injective function f on the vertex set V of a simple graph G=(V,E). Here S(v) =
{w in E | (v,w) in E, f(w)-f(v)&lt;0} is the subgraph of the unit sphere at v in
G. It is the exit set of the gradient vector field. We prove that the sum of
i(v) over V is always is equal to the Euler characteristic X(G) of the graph G.
This is a discrete Poincare-Hopf theorem in a discrete Morse setting. It allows
to compute X(G) for large graphs for which other methods become impractical.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1170</identifier>
 <datestamp>2012-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1170</id><created>2012-01-05</created><authors><author><keyname>Okano</keyname><forenames>Kunihisa</forenames></author><author><keyname>Ishii</keyname><forenames>Hideaki</forenames></author></authors><title>Data Rate Limitations for Stabilization of Uncertain Systems over Lossy
  Channels</title><categories>cs.SY cs.IT math.IT math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers data rate limitations for mean square stabilization of
uncertain discrete-time linear systems via finite data rate and lossy channels.
For a plant having parametric uncertainties, a necessary condition and a
sufficient condition are derived, represented by the data rate, the packet loss
probability, uncertainty bounds on plant parameters, and the unstable
eigenvalues of the plant. The results extend those existing in the area of
networked control, and in particular, the condition is exact for the scalar
plant case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1174</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1174</id><created>2012-01-05</created><authors><author><keyname>Liao</keyname><forenames>Yongjun</forenames></author><author><keyname>Du</keyname><forenames>Wei</forenames></author><author><keyname>Geurts</keyname><forenames>Pierre</forenames></author><author><keyname>Leduc</keyname><forenames>Guy</forenames></author></authors><title>DMFSGD: A Decentralized Matrix Factorization Algorithm for Network
  Distance Prediction</title><categories>cs.NI</categories><comments>submitted to IEEE/ACM Transactions on Networking on Nov. 2011</comments><acm-class>C.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The knowledge of end-to-end network distances is essential to many Internet
applications. As active probing of all pairwise distances is infeasible in
large-scale networks, a natural idea is to measure a few pairs and to predict
the other ones without actually measuring them. This paper formulates the
distance prediction problem as matrix completion where unknown entries of an
incomplete matrix of pairwise distances are to be predicted. The problem is
solvable because strong correlations among network distances exist and cause
the constructed distance matrix to be low rank. The new formulation circumvents
the well-known drawbacks of existing approaches based on Euclidean embedding.
  A new algorithm, so-called Decentralized Matrix Factorization by Stochastic
Gradient Descent (DMFSGD), is proposed to solve the network distance prediction
problem. By letting network nodes exchange messages with each other, the
algorithm is fully decentralized and only requires each node to collect and to
process local measurements, with neither explicit matrix constructions nor
special nodes such as landmarks and central servers. In addition, we compared
comprehensively matrix factorization and Euclidean embedding to demonstrate the
suitability of the former on network distance prediction. We further studied
the incorporation of a robust loss function and of non-negativity constraints.
Extensive experiments on various publicly-available datasets of network delays
show not only the scalability and the accuracy of our approach but also its
usability in real Internet applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1175</identifier>
 <datestamp>2012-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1175</id><created>2012-01-05</created><authors><author><keyname>Karaca</keyname><forenames>Mehmet</forenames></author><author><keyname>Ercetin</keyname><forenames>Ozgur</forenames></author></authors><title>Throughput Optimal Multi-user Scheduling via Hierarchical Modulation</title><categories>cs.NI cs.IT math.IT</categories><comments>4 pages, 2 figures, submitted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the network stability problem when two users are scheduled
simultaneously. The key idea is to simultaneously transmit to more than one
users experiencing different channel conditions by employing hierarchical
modulation. For two-user scheduling problem, we develop a throughput-optimal
algorithm which can stabilize the network whenever this is possible. In
addition, we analytically prove that the proposed algorithm achieves larger
achievable rate region compared to the conventional Max-Weight algorithm which
employs uniform modulation and transmits a single user. We demonstrate the
efficacy of the algorithm on a realistic simulation environment using the
parameters of High Data Rate protocol in a Code Division Multiple Access
system. Simulation results show that with the proposed algorithm, the network
can carry higher user traffic with lower delays.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1177</identifier>
 <datestamp>2012-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1177</id><created>2012-01-05</created><authors><author><keyname>Gnang</keyname><forenames>Edinah K.</forenames></author></authors><title>Computational Tutorial on Gr\&quot;obner bases embedding Sage in LaTeX with
  SageTEX</title><categories>cs.SC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Elementary tutorial on implementation aspects of Gr\&quot;obner bases computation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1188</identifier>
 <datestamp>2012-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1188</id><created>2012-01-04</created><updated>2012-02-04</updated><authors><author><keyname>Esposito</keyname><forenames>Alfredo</forenames></author></authors><title>Autenticazione biometrica: Realt\`a e fantasia</title><categories>cs.CR</categories><comments>This paper has been withdrawn by the author. paper is missing a
  fundamental disclaimer</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Biometrical authentication systems are often presented as the best and
simplest way to reach higher security levels. But a deeper analysis shows that
several risks are hidden and the service provider adopting those system has to
carefully check its liabilities before deploying them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1192</identifier>
 <datestamp>2012-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1192</id><created>2012-01-05</created><authors><author><keyname>Bisikalo</keyname><forenames>Oleg</forenames></author><author><keyname>Kravchuk</keyname><forenames>Irina</forenames></author></authors><title>Formalization of semantic network of image constructions in electronic
  content</title><categories>cs.CL</categories><comments>4 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A formal theory based on a binary operator of directional associative
relation is constructed in the article and an understanding of an associative
normal form of image constructions is introduced. A model of a commutative
semigroup, which provides a presentation of a sentence as three components of
an interrogative linguistic image construction, is considered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1198</identifier>
 <datestamp>2012-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1198</id><created>2012-01-05</created><authors><author><keyname>Ahn</keyname><forenames>Hee-Kap</forenames></author><author><keyname>Kim</keyname><forenames>Sang-Sub</forenames></author><author><keyname>Knauer</keyname><forenames>Christian</forenames></author><author><keyname>Schlipf</keyname><forenames>Lena</forenames></author><author><keyname>Shin</keyname><forenames>Chan-Su</forenames></author><author><keyname>Vigneron</keyname><forenames>Antoine</forenames></author></authors><title>Covering and Piercing Disks with Two Centers</title><categories>cs.CG</categories><comments>14 pages, 3 figures, the results appeared in the proceedings of
  ISAAC'11</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give exact and approximation algorithms for two-center problems when the
input is a set $\mathcal{D}$ of disks in the plane. We first study the problem
of finding two smallest congruent disks such that each disk in $\mathcal{D}$
intersects one of these two disks. Then we study the problem of covering the
set $\mathcal{D}$ by two smallest congruent disks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1200</identifier>
 <datestamp>2012-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1200</id><created>2011-11-19</created><authors><author><keyname>Wagner</keyname><forenames>Noam</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author><author><keyname>Feuer</keyname><forenames>Arie</forenames></author><author><keyname>Friedman</keyname><forenames>Zvi</forenames></author></authors><title>Compressed Beamforming Applied to B-Mode Ultrasound Imaging</title><categories>cs.OH</categories><comments>4 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Emerging sonography techniques often imply increasing in the number of
transducer elements involved in the imaging process. Consequently, larger
amounts of data must be acquired and processed by the beamformer. The
significant growth in the amounts of data effects both machinery size and power
consumption. Within the classical sampling framework, state of the art systems
reduce processing rates by exploiting the bandpass bandwidth of the detected
signals. It has been recently shown, that a much more significant sample-rate
reduction may be obtained, by treating ultrasound signals within the Finite
Rate of Innovation framework. These ideas follow the spirit of Xampling, which
combines classic methods from sampling theory with recent developments in
Compressed Sensing. Applying such low-rate sampling schemes to individual
transducer elements, which detect energy reflected from biological tissues, is
limited by the noisy nature of the signals. This often results in erroneous
parameter extraction, bringing forward the need to enhance the SNR of the
low-rate samples. In our work, we manage to achieve such SNR enhancement, by
beamforming the sub-Nyquist samples obtained from multiple elements. We refer
to this process as &quot;compressed beamforming&quot;. Applying it to cardiac ultrasound
data, we successfully image macroscopic perturbations, while achieving a nearly
eight-fold reduction in sample-rate, compared to standard techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1202</identifier>
 <datestamp>2012-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1202</id><created>2012-01-05</created><authors><author><keyname>Gravier</keyname><forenames>Sylvain</forenames><affiliation>IF</affiliation></author><author><keyname>Kovse</keyname><forenames>Matjaz</forenames><affiliation>LaBRI</affiliation></author><author><keyname>Mollard</keyname><forenames>Michel</forenames><affiliation>IF</affiliation></author><author><keyname>Moncel</keyname><forenames>Julien</forenames><affiliation>LAAS</affiliation></author><author><keyname>Parreau</keyname><forenames>Aline</forenames><affiliation>IF</affiliation></author></authors><title>New results on variants of covering codes in Sierpinski graphs</title><categories>cs.DM</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study identifying codes, locating-dominating codes, and
total-dominating codes in Sierpinski graphs. We compute the minimum size of
such codes in Sierpinski graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1204</identifier>
 <datestamp>2012-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1204</id><created>2011-11-25</created><authors><author><keyname>Dhomeja</keyname><forenames>Lachhman Das</forenames></author><author><keyname>Malkani</keyname><forenames>Yasir Arfat</forenames></author><author><keyname>Shaikh</keyname><forenames>Asad Ali</forenames></author><author><keyname>Keerio</keyname><forenames>Ayaz</forenames></author></authors><title>Transparent caching of virtual stubs for improved performance in
  ubiquitous environments</title><categories>cs.OH</categories><comments>arXiv admin note: text overlap with arXiv:1108.1472 by other authors</comments><journal-ref>Lachhman Das Dhomeja, Yasir Arfat Malkani, Asad Ali Shaikh and
  Ayaz Keerio, &quot;Transparent Caching of Virtual Stubs for Improved Performance
  in Ubiquitous Environments &quot;, International Journal of UbiComp (IJU), Vol.2,
  No.4, October 2011</journal-ref><doi>10.5121/iju.2011.2401</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Context-awareness is an essential requirement for pervasive computing
applications, which enables them to adapt and perform tasks based on context.
One of the adaptive features of context-awareness is contextual
reconfiguration. Contextual reconfiguration involves discovering remote
service(s) based on context and binding them to the application components to
realize new behaviors, which may be needed to satisfy user needs or to enrich
user experience. One of the steps in the reconfiguration process involves a
remote lookup to discover the service(s) based on context. This remote lookup
process provides the largest contribution to reconfiguration time and this is
due to fact that the remote calls are much slower than local calls.
Consequently, it affects system performance. In pervasive computing
applications, this may turn out to be undesirable in terms of user experience.
Moreover, other distributed applications using the network may be affected as
every remote method call decreases the amount of bandwidth available on the
network. Various systems provide reconfiguration support and offer high-level
reconfiguration directives to develop adaptive context-aware applications, but
do not address this performance bottleneck. We address this issue and implement
seamless caching of virtual stubs within our PCRA1 for improved performance. In
this paper we present and describe our transparent caching support and also
provide its performance evaluation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1214</identifier>
 <datestamp>2015-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1214</id><created>2012-01-05</created><updated>2015-06-08</updated><authors><author><keyname>Feldman</keyname><forenames>Vitaly</forenames></author><author><keyname>Grigorescu</keyname><forenames>Elena</forenames></author><author><keyname>Reyzin</keyname><forenames>Lev</forenames></author><author><keyname>Vempala</keyname><forenames>Santosh</forenames></author><author><keyname>Xiao</keyname><forenames>Ying</forenames></author></authors><title>Statistical Algorithms and a Lower Bound for Detecting Planted Clique</title><categories>cs.CC cs.DS</categories><acm-class>F.2; G.1.6; G.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a framework for proving lower bounds on computational problems
over distributions, for a class of algorithms called statistical algorithms.
For such algorithms, access to the input distribution is limited to obtaining
an estimate of the expectation of any given function on a sample drawn randomly
from the input distribution, rather than directly accessing samples. Most
natural algorithms of interest in theory and in practice, e.g., moments-based
methods, local search, standard iterative methods for convex optimization, MCMC
and simulated annealing rely only on such estimates and can be viewed as
statistical algorithms.
  Our framework is inspired by and generalizes the statistical query model in
learning theory (Kearns, 1998). Our main application is a nearly optimal lower
bound on the complexity of any statistical algorithm for detecting planted
bipartite clique distributions (or planted dense subgraph distributions) when
the planted clique has size $O(n^{1/2-\delta})$ for any constant $\delta &gt; 0$.
Variants of this problem have been assumed to be hard for applications in
cryptography and to prove hardness of other problems; our lower bounds provide
concrete evidence of hardness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1215</identifier>
 <datestamp>2014-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1215</id><created>2012-01-05</created><updated>2012-01-10</updated><authors><author><keyname>Squartini</keyname><forenames>Tiziano</forenames></author><author><keyname>Garlaschelli</keyname><forenames>Diego</forenames></author></authors><title>Triadic motifs and dyadic self-organization in the World Trade Network</title><categories>physics.soc-ph cs.SI physics.data-an q-fin.GN</categories><comments>12 pages, 3 figures; Best Paper Award at the 6th International
  Conference on Self-Organizing Systems, Delft, The Netherlands, 15-16/03/2012</comments><journal-ref>in Self-Organizing Systems (series: Lec. Notes Comp. Science
  7166/2012), chapter 3, pp. 24-35, Springer (edited by F. A. Kuipers and P. E.
  Heegaard) (2012)</journal-ref><doi>10.1007/978-3-642-28583-7_3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In self-organizing networks, topology and dynamics coevolve in a continuous
feedback, without exogenous driving. The World Trade Network (WTN) is one of
the few empirically well documented examples of self-organizing networks: its
topology strongly depends on the GDP of world countries, which in turn depends
on the structure of trade. Therefore, understanding which are the key
topological properties of the WTN that deviate from randomness provides direct
empirical information about the structural effects of self-organization. Here,
using an analytical pattern-detection method that we have recently proposed, we
study the occurrence of triadic &quot;motifs&quot; (subgraphs of three vertices) in the
WTN between 1950 and 2000. We find that, unlike other properties, motifs are
not explained by only the in- and out-degree sequences. By contrast, they are
completely explained if also the numbers of reciprocal edges are taken into
account. This implies that the self-organization process underlying the
evolution of the WTN is almost completely encoded into the dyadic structure,
which strongly depends on reciprocity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1216</identifier>
 <datestamp>2012-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1216</id><created>2012-01-05</created><authors><author><keyname>Burgi</keyname><forenames>Pierre-Yves</forenames></author><author><keyname>Yuille</keyname><forenames>Alan L.</forenames></author><author><keyname>Grzywacz</keyname><forenames>Norberto M.</forenames></author></authors><title>Probabilistic Motion Estimation Based on Temporal Coherence</title><categories>cs.CV cs.IT math.IT</categories><comments>40 pages, 7 figures</comments><journal-ref>Neural Computation, 2000, vol. 12, no. 8, p. 1839-1867</journal-ref><doi>10.1162/089976600300015169</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  We develop a theory for the temporal integration of visual motion motivated
by psychophysical experiments. The theory proposes that input data are
temporally grouped and used to predict and estimate the motion flows in the
image sequence. This temporal grouping can be considered a generalization of
the data association techniques used by engineers to study motion sequences.
Our temporal-grouping theory is expressed in terms of the Bayesian
generalization of standard Kalman filtering. To implement the theory we derive
a parallel network which shares some properties of cortical networks. Computer
simulations of this network demonstrate that our theory qualitatively accounts
for psychophysical experiments on motion occlusion and motion outliers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1221</identifier>
 <datestamp>2012-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1221</id><created>2012-01-05</created><authors><author><keyname>Vitanyi</keyname><forenames>P. M. B.</forenames><affiliation>National Research Center for Mathematics and Computer Science in the Netherlands</affiliation></author></authors><title>Information Distance: New Developments</title><categories>cs.CV cs.IT math.IT physics.data-an</categories><comments>4 pages, Latex; Series of Publications C, Report C-2011-45,
  Department of Computer Science, University of Helsinki, pp. 71-74</comments><journal-ref>Proc. 4th Workshop on Information Theoretic Methods in Science and
  Engineering (WITSME 2011), 2011, pp. 71-74</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In pattern recognition, learning, and data mining one obtains information
from information-carrying objects. This involves an objective definition of the
information in a single object, the information to go from one object to
another object in a pair of objects, the information to go from one object to
any other object in a multiple of objects, and the shared information between
objects. This is called &quot;information distance.&quot; We survey a selection of new
developments in information distance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1223</identifier>
 <datestamp>2013-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1223</id><created>2012-01-05</created><authors><author><keyname>Vitanyi</keyname><forenames>P. M. B.</forenames><affiliation>National Research Center for Mathematics and Computer Science in the Netherlands</affiliation></author></authors><title>Turing Machines and Understanding Computational Complexity</title><categories>cs.CC</categories><comments>9 pages, 1 figure, LaTeX. To appear in: Alan Turing - His Work and
  Impact, Elsevier</comments><journal-ref>In: S. Barry Cooper, Jan van Leeuwen (eds.), &quot;Alan Turing: His
  Work and Impact&quot;, Elsevier, Amsterdam, London, New York, Tokyo, 2013,
  pp.57-63</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe the Turing Machine, list some of its many influences on the
theory of computation and complexity of computations, and illustrate its
importance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1259</identifier>
 <datestamp>2012-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1259</id><created>2011-11-22</created><authors><author><keyname>Boulet</keyname><forenames>Romain</forenames><affiliation>LMTG</affiliation></author><author><keyname>Mazzega</keyname><forenames>Pierre</forenames><affiliation>LMTG</affiliation></author><author><keyname>Bourcier</keyname><forenames>Dani&#xe8;le</forenames><affiliation>CERSA</affiliation></author></authors><title>Network Analysis of the French Environmental Code</title><categories>cs.SI cs.DL physics.soc-ph</categories><comments>AI Approaches to the Complexity of Legal Systems (AICOL 2009),
  Rotterdam : Netherlands (2009)</comments><proxy>ccsd</proxy><doi>10.1007/978-3-642-16524-5_4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We perform a detailed analysis of the network constituted by the citations in
a legal code, we search for hidden structures and properties. The graph
associated to the Environmental code has a small-world structure and it is
partitioned in several hidden communities of articles that only partially
coincide with the organization of the code as given by its table of content.
Several articles are also connected with a low number of articles but are
intermediate between large communities. The structure of the Environmental Code
is contrasting with the reference network of all the French Legal Codes that
presents a rich-club of ten codes very central to the whole French legal
system, but no small-world property. This comparison shows that the structural
properties of the reference network associated to a legal system strongly
depends on the scale and granularity of the analysis, as is the case for many
complex systems
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1262</identifier>
 <datestamp>2012-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1262</id><created>2011-11-19</created><authors><author><keyname>Boulet</keyname><forenames>Romain</forenames><affiliation>ESPACE</affiliation></author></authors><title>A Network Approach to the French System of Legal codes - Part I:
  Analysis of a Dense Network</title><categories>cs.SI physics.soc-ph</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We explore one aspect of the structure of a codified legal system at the
national level using a new type of representation to understand the strong or
weak dependencies between the various fields of law. In Part I of this study,
we analyze the graph associated with the network in which each French legal
code is a vertex and an edge is produced between two vertices when a code cites
another code at least one time. We show that this network distinguishes from
many other real networks from a high density, giving it a particular structure
that we call concentrated world and that differentiates a national legal system
(as considered with a resolution at the code level) from small-world graphs
identified in many social networks. Our analysis then shows that a few
communities (groups of highly wired vertices) of codes covering large domains
of regulation are structuring the whole system. Indeed we mainly find a central
group of influent codes, a group of codes related to social issues and a group
of codes dealing with territories and natural resources. The study of this
codified legal system is also of interest in the field of the analysis of real
networks. In particular we examine the impact of the high density on the
structural characteristics of the graph and on the ways communities are
searched for. Finally we provide an original visualization of this graph on an
hemicyle-like plot, this representation being based on a statistical reduction
of dissimilarity measures between vertices. In Part II (a following paper) we
show how the consideration of the weights attributed to each edge in the
network in proportion to the number of citations between two vertices (codes)
allows deepening the analysis of the French legal system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1272</identifier>
 <datestamp>2012-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1272</id><created>2012-01-05</created><updated>2012-07-16</updated><authors><author><keyname>Jacobs</keyname><forenames>Bart</forenames></author><author><keyname>Mandemaker</keyname><forenames>Jorik</forenames></author></authors><title>Relating Operator Spaces via Adjunctions</title><categories>cs.LO math.CT quant-ph</categories><msc-class>18C10</msc-class><acm-class>F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This chapter uses categorical techniques to describe relations between
various sets of operators on a Hilbert space, such as self-adjoint, positive,
density, effect and projection operators. These relations, including various
Hilbert-Schmidt isomorphisms of the form tr(A-), are expressed in terms of dual
adjunctions, and maps between them. Of particular interest is the connection
with quantum structures, via a dual adjunction between convex sets and effect
modules. The approach systematically uses categories of modules, via their
description as Eilenberg-Moore algebras of a monad.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1277</identifier>
 <datestamp>2012-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1277</id><created>2012-01-05</created><authors><author><keyname>Marron</keyname><forenames>Mark</forenames></author></authors><title>Structural Analysis: Shape Information via Points-To Computation</title><categories>cs.PL cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a new hybrid memory analysis, Structural Analysis,
which combines an expressive shape analysis style abstract domain with
efficient and simple points-to style transfer functions. Using data from
empirical studies on the runtime heap structures and the programmatic idioms
used in modern object-oriented languages we construct a heap analysis with the
following characteristics: (1) it can express a rich set of structural, shape,
and sharing properties which are not provided by a classic points-to analysis
and that are useful for optimization and error detection applications (2) it
uses efficient, weakly-updating, set-based transfer functions which enable the
analysis to be more robust and scalable than a shape analysis and (3) it can be
used as the basis for a scalable interprocedural analysis that produces precise
results in practice.
  The analysis has been implemented for .Net bytecode and using this
implementation we evaluate both the runtime cost and the precision of the
results on a number of well known benchmarks and real world programs. Our
experimental evaluations show that the domain defined in this paper is capable
of precisely expressing the majority of the connectivity, shape, and sharing
properties that occur in practice and, despite the use of weak updates, the
static analysis is able to precisely approximate the ideal results. The
analysis is capable of analyzing large real-world programs (over 30K bytecodes)
in less than 65 seconds and using less than 130MB of memory. In summary this
work presents a new type of memory analysis that advances the state of the art
with respect to expressive power, precision, and scalability and represents a
new area of study on the relationships between and combination of concepts from
shape and points-to analyses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1278</identifier>
 <datestamp>2012-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1278</id><created>2012-01-05</created><authors><author><keyname>Yilmaz</keyname><forenames>Ferkan</forenames></author><author><keyname>Alouini</keyname><forenames>Mohamed-Slim</forenames></author></authors><title>Novel Relations between the Ergodic Capacity and the Average Bit Error
  Rate</title><categories>cs.IT math.IT math.PR math.ST stat.TH</categories><comments>This work has been presented by Ferkan Yilmaz in IEEE International
  Symposium on Wireless Communication Systems (ISWCS 2011), Aachen, Germany,
  6th-9th November, 2011. (Including 6 pages, 2 figures)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ergodic capacity and average bit error rate have been widely used to compare
the performance of different wireless communication systems. As such recent
scientific research and studies revealed strong impact of designing and
implementing wireless technologies based on these two performance indicators.
However and to the best of our knowledge, the direct links between these two
performance indicators have not been explicitly proposed in the literature so
far. In this paper, we propose novel relations between the ergodic capacity and
the average bit error rate of an overall communication system using binary
modulation schemes for signaling with a limited bandwidth and operating over
generalized fading channels. More specifically, we show that these two
performance measures can be represented in terms of each other, without the
need to know the exact end-to-end statistical characterization of the
communication channel. We validate the correctness and accuracy of our newly
proposed relations and illustrated their usefulness by considering some
classical examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1327</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1327</id><created>2012-01-05</created><authors><author><keyname>Marron</keyname><forenames>Mark</forenames></author><author><keyname>Sanchez</keyname><forenames>Cesar</forenames></author><author><keyname>Su</keyname><forenames>Zhendong</forenames></author><author><keyname>Fahndrich</keyname><forenames>Manuel</forenames></author></authors><title>Abstracting Runtime Heaps for Program Understanding</title><categories>cs.PL cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modern programming environments provide extensive support for inspecting,
analyzing, and testing programs based on the algorithmic structure of a
program. Unfortunately, support for inspecting and understanding runtime data
structures during execution is typically much more limited. This paper provides
a general purpose technique for abstracting and summarizing entire runtime
heaps. We describe the abstract heap model and the associated algorithms for
transforming a concrete heap dump into the corresponding abstract model as well
as algorithms for merging, comparing, and computing changes between abstract
models. The abstract model is designed to emphasize high-level concepts about
heap-based data structures, such as shape and size, as well as relationships
between heap structures, such as sharing and connectivity. We demonstrate the
utility and computational tractability of the abstract heap model by building a
memory profiler. We then use this tool to check for, pinpoint, and correct
sources of memory bloat from a suite of programs from DaCapo.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1340</identifier>
 <datestamp>2012-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1340</id><created>2012-01-05</created><authors><author><keyname>Pence</keyname><forenames>William</forenames></author><author><keyname>Seaman</keyname><forenames>Rob</forenames></author><author><keyname>White</keyname><forenames>Richard L.</forenames></author></authors><title>A Tiled-Table Convention for Compressing FITS Binary Tables</title><categories>astro-ph.IM cs.DB</categories><comments>Proposed FITS Convention:
  http://fits.gsfc.nasa.gov/registry/tiletablecompression/tiletable.pdf, v1.0,
  28 October 2010, 6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This document describes a convention for compressing FITS binary tables that
is modeled after the FITS tiled-image compression method (White et al. 2009)
that has been in use for about a decade. The input table is first optionally
subdivided into tiles, each containing an equal number of rows, then every
column of data within each tile is compressed and stored as a variable-length
array of bytes in the output FITS binary table. All the header keywords from
the input table are copied to the header of the output table and remain
uncompressed for efficient access. The output compressed table contains the
same number and order of columns as in the input uncompressed binary table.
There is one row in the output table corresponding to each tile of rows in the
input table. In principle, each column of data can be compressed using a
different algorithm that is optimized for the type of data within that column,
however in the prototype implementation described here, the gzip algorithm is
used to compress every column.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1345</identifier>
 <datestamp>2012-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1345</id><created>2012-01-05</created><authors><author><keyname>Seaman</keyname><forenames>Rob</forenames></author><author><keyname>Pence</keyname><forenames>William</forenames></author><author><keyname>Rots</keyname><forenames>Arnold</forenames></author></authors><title>FITS Checksum Proposal</title><categories>astro-ph.IM cs.DB</categories><comments>Registered FITS Convention:
  http://fits.gsfc.nasa.gov/registry/checksum.html, 23 May 2002, 11 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The checksum keywords described here provide an integrity check on the
information contained in FITS HDUs. (Header and Data Units are the basic
components of FITS files, consisting of header keyword records followed by
optional associated data records). The CHECKSUM keyword is defined to have a
value that forces the 32-bit 1's complement checksum accumulated over all the
2880-byte FITS logical records in the HDU to equal negative 0. (Note that 1's
complement arithmetic has both positive and negative zero elements). Verifying
that the accumulated checksum is still equal to -0 provides a fast and fairly
reliable way to determine that the HDU has not been modified by subsequent data
processing operations or corrupted while copying or storing the file on
physical media.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1353</identifier>
 <datestamp>2012-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1353</id><created>2012-01-06</created><authors><author><keyname>Bhardwaj</keyname><forenames>Ved Prakash</forenames></author><author><keyname>Nitin</keyname></author><author><keyname>Tyagi</keyname><forenames>Vipin</forenames></author></authors><title>Minimizing the Switch and Link Conflicts in an Optical Multi-stage
  Interconnection Network</title><categories>cs.NI</categories><comments>9 pages, 6 figures</comments><journal-ref>IJCSI International Journal of Computer Science Issues, Vol. 8,
  Issue 4, No 1, July 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multistage Interconnection Networks (MINs) are very popular in switching and
communication applications. A MIN connects N inputs to N outputs and is
referred as an N \times N MIN; having size N. Optical Multistage
Interconnection Network (OMIN) represents an important class of Interconnection
networks. Crosstalk is the basic problem of OMIN. Switch Conflict and Link
Conflict are the two main reason of crosstalk. In this paper, we are
considering both problems. A number of techniques like Optical window, Improved
Window, Heuristic, Genetic, and Zero have been proposed earlier in this
research domain. In this paper, we have proposed two algorithms called Address
Selection Algorithm and Route Selection Algorithm (RSA). RSA is based on
Improved Window Method. We have applied the proposed algorithms on existing
Omega network, having shuffle-exchange connection pattern. The main
functionality of ASA and RSA is to minimize the number of switch and link
conflicts in the network and to provide conflict free routes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1355</identifier>
 <datestamp>2012-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1355</id><created>2012-01-06</created><authors><author><keyname>Kocik</keyname><forenames>Jerzy</forenames></author></authors><title>Harmonic evolutions on graphs</title><categories>math.CO cs.DM math.DS</categories><comments>16 pages, 7 figures</comments><msc-class>05C50, 15A33, 05C75, 05C85</msc-class><journal-ref>International Journal of Mathematics and Computer Science, vol 2
  no. 1 (2007), 65-82</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We define the harmonic evolution of states of a graph by iterative
application of the harmonic operator (Laplacian over $Z_2$). This provides
graphs with a new geometric context and leads to a new tool to analyze them.
The digraphs of evolutions are analyzed and classified. This construction can
also be viewed as a certain topological generalization of cellular automata.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1363</identifier>
 <datestamp>2012-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1363</id><created>2012-01-06</created><updated>2012-01-11</updated><authors><author><keyname>Sarma</keyname><forenames>Atish Das</forenames></author><author><keyname>Molla</keyname><forenames>Anisur Rahaman</forenames></author><author><keyname>Pandurangan</keyname><forenames>Gopal</forenames></author></authors><title>Near-Optimal Random Walk Sampling in Distributed Networks</title><categories>cs.DC cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Performing random walks in networks is a fundamental primitive that has found
numerous applications in communication networks such as token management, load
balancing, network topology discovery and construction, search, and
peer-to-peer membership management. While several such algorithms are
ubiquitous, and use numerous random walk samples, the walks themselves have
always been performed naively.
  In this paper, we focus on the problem of performing random walk sampling
efficiently in a distributed network. Given bandwidth constraints, the goal is
to minimize the number of rounds and messages required to obtain several random
walk samples in a continuous online fashion. We present the first round and
message optimal distributed algorithms that present a significant improvement
on all previous approaches. The theoretical analysis and comprehensive
experimental evaluation of our algorithms show that they perform very well in
different types of networks of differing topologies.
  In particular, our results show how several random walks can be performed
continuously (when source nodes are provided only at runtime, i.e., online),
such that each walk of length $\ell$ can be performed exactly in just
$\tilde{O}(\sqrt{\ell D})$ rounds, (where $D$ is the diameter of the network),
and $O(\ell)$ messages. This significantly improves upon both, the naive
technique that requires $O(\ell)$ rounds and $O(\ell)$ messages, and the
sophisticated algorithm of [DasSarma et al. PODC 2010] that has the same round
complexity as this paper but requires $\Omega(m\sqrt{\ell})$ messages (where
$m$ is the number of edges in the network). Our theoretical results are
corroborated through extensive experiments on various topological data sets.
Our algorithms are fully decentralized, lightweight, and easily implementable,
and can serve as building blocks in the design of topologically-aware networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1377</identifier>
 <datestamp>2015-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1377</id><created>2012-01-06</created><updated>2015-03-01</updated><authors><author><keyname>Dutta</keyname><forenames>Chinmoy</forenames></author><author><keyname>Radhakrishnan</keyname><forenames>Jaikumar</forenames></author></authors><title>On Zarankiewicz Problem and Depth-Two Superconcentrators</title><categories>cs.DM</categories><msc-class>97K20, 97K30, 05C35, 05C40, 05C75, 05D40</msc-class><acm-class>G.2.2; G.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show tight necessary and sufficient conditions on the sizes of small
bipartite graphs whose union is a larger bipartite graph that has no large
bipartite independent set. Our main result is a common generalization of two
classical results in graph theory: the theorem of K\H{o}v\'{a}ri, S\'{o}s and
Tur\'{a}n on the minimum number of edges in a bipartite graph that has no large
independent set, and the theorem of Hansel (also Katona and Szemer\'{e}di,
Krichevskii) on the sum of the sizes of bipartite graphs that can be used to
construct a graph (non-necessarily bipartite) that has no large independent
set.
  As an application of our results, we show how they unify the underlying
combinatorial principles developed in the proof of tight lower bounds for
depth-two superconcentrators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1383</identifier>
 <datestamp>2012-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1383</id><created>2012-01-06</created><authors><author><keyname>Khan</keyname><forenames>Muhammad Fahad</forenames></author><author><keyname>Beg</keyname><forenames>Saira</forenames></author></authors><title>Stereo image Transference &amp; Retrieval over SMS</title><categories>cs.MM</categories><comments>3 pages,3 figuers,Journal</comments><journal-ref>JOURNAL OF COMPUTING, VOLUME 3, ISSUE 7, JULY 2011, ISSN 2151-9617
  WWW.JOURNALOFCOMPUTING.ORG</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Paper presents the way of transferring stereo images using SMS over GSM
network. Generally, Stereo image is composed of two stereoscopic images in such
way that gives three dimensional affect when viewed. GSM have two short
messaging services, which can transfer images and sounds etc. Such services are
known as; MMS (Multimedia Messaging Service) and EMS (Extended Messaging
Service). EMS can send Predefined sounds, animation and images but have
limitation that it does not support widely. MMS can send much higher contents
than EMS but need 3G and other network capability in order to send large size
data up to 1000 bytes. Other limitations are Portability, content adaption etc.
Our major aim in this paper is to provide an alternative way of sending stereo
images over SMS which is widely supported than EMS. We develop an application
using J2ME Platform.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1384</identifier>
 <datestamp>2012-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1384</id><created>2012-01-06</created><updated>2012-12-12</updated><authors><author><keyname>Isozaki</keyname><forenames>Takashi</forenames></author></authors><title>A Thermodynamical Approach for Probability Estimation</title><categories>cs.LG physics.data-an stat.ME</categories><comments>22 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The issue of discrete probability estimation for samples of small size is
addressed in this study. The maximum likelihood method often suffers
over-fitting when insufficient data is available. Although the Bayesian
approach can avoid over-fitting by using prior distributions, it still has
problems with objective analysis. In response to these drawbacks, a new
theoretical framework based on thermodynamics, where energy and temperature are
introduced, was developed. Entropy and likelihood are placed at the center of
this method. The key principle of inference for probability mass functions is
the minimum free energy, which is shown to unify the two principles of maximum
likelihood and maximum entropy. Our method can robustly estimate probability
functions from small size data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1409</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1409</id><created>2012-01-06</created><authors><author><keyname>Lai</keyname><forenames>Ranch Y. Q.</forenames></author><author><keyname>Yuen</keyname><forenames>Pong C.</forenames></author><author><keyname>Lee</keyname><forenames>K. W.</forenames></author><author><keyname>Lai</keyname><forenames>J. H.</forenames></author></authors><title>Interactive Character Posing by Sparse Coding</title><categories>cs.GR cs.AI</categories><comments>Submitted to Computer Graphics Forum</comments><acm-class>I.7</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Character posing is of interest in computer animation. It is difficult due to
its dependence on inverse kinematics (IK) techniques and articulate property of
human characters . To solve the IK problem, classical methods that rely on
numerical solutions often suffer from the under-determination problem and can
not guarantee naturalness. Existing data-driven methods address this problem by
learning from motion capture data. When facing a large variety of poses
however, these methods may not be able to capture the pose styles or be
applicable in real-time environment. Inspired from the low-rank motion
de-noising and completion model in \cite{lai2011motion}, we propose a novel
model for character posing based on sparse coding. Unlike conventional
approaches, our model directly captures the pose styles in Euclidean space to
provide intuitive training error measurements and facilitate pose synthesis. A
pose dictionary is learned in training stage and based on it natural poses are
synthesized to satisfy users' constraints . We compare our model with existing
models for tasks of pose de-noising and completion. Experiments show our model
obtains lower de-noising and completion error. We also provide User
Interface(UI) examples illustrating that our model is effective for interactive
character posing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1410</identifier>
 <datestamp>2012-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1410</id><created>2012-01-06</created><authors><author><keyname>Peters</keyname><forenames>Kirstin</forenames></author><author><keyname>Nestmann</keyname><forenames>Uwe</forenames></author></authors><title>Is it a &quot;Good&quot; Encoding of Mixed Choice? (Technical Report)</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This technical report contains the proofs to the lemmata and theorems of
[PN12] as well as some additional material. As main contributions [PN12]
presents an encoding of mixed choice in the context of the pi-calculus and a
criterion to measure whether the degree of distribution in process networks is
preserved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1417</identifier>
 <datestamp>2012-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1417</id><created>2011-11-29</created><authors><author><keyname>Ekhtiyar</keyname><forenames>Hesam</forenames></author><author><keyname>Sheida</keyname><forenames>Mahdi</forenames></author><author><keyname>Amintoosi</keyname><forenames>Mahmood</forenames></author></authors><title>Picture Collage with Genetic Algorithm and Stereo vision</title><categories>cs.CV</categories><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  In this paper, a salient region extraction method for creating picture
collage based on stereo vision is proposed. Picture collage is a kind of visual
image summary to arrange all input images on a given canvas, allowing overlay,
to maximize visible visual information. The salient regions of each image are
firstly extracted and represented as a depth map. The output picture collage
shows as many visible salient regions (without being overlaid by others) from
all images as possible. A very efficient Genetic algorithm is used here for the
optimization. The experimental results showed the superior performance of the
proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1422</identifier>
 <datestamp>2012-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1422</id><created>2011-11-29</created><authors><author><keyname>Bansal</keyname><forenames>Roli</forenames></author><author><keyname>Sehgal</keyname><forenames>Priti</forenames></author><author><keyname>Bedi</keyname><forenames>Punam</forenames></author></authors><title>Minutiae Extraction from Fingerprint Images - a Review</title><categories>cs.CV cs.CR</categories><comments>12 pages; IJCSI International Journal of Computer Science Issues,
  Vol. 8, Issue 5, September 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fingerprints are the oldest and most widely used form of biometric
identification. Everyone is known to have unique, immutable fingerprints. As
most Automatic Fingerprint Recognition Systems are based on local ridge
features known as minutiae, marking minutiae accurately and rejecting false
ones is very important. However, fingerprint images get degraded and corrupted
due to variations in skin and impression conditions. Thus, image enhancement
techniques are employed prior to minutiae extraction. A critical step in
automatic fingerprint matching is to reliably extract minutiae from the input
fingerprint images. This paper presents a review of a large number of
techniques present in the literature for extracting fingerprint minutiae. The
techniques are broadly classified as those working on binarized images and
those that work on gray scale images directly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1425</identifier>
 <datestamp>2012-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1425</id><created>2011-12-16</created><authors><author><keyname>Garrot-Lavou&#xe9;</keyname><forenames>Elise</forenames><affiliation>LIESP</affiliation></author></authors><title>Interconnection of Communities of Practice: A Web Platform for Knowledge
  Management</title><categories>cs.CY cs.HC</categories><proxy>ccsd</proxy><journal-ref>Firth International Conference on Knowledge Management and
  Information Sharing (KMIS 2009), Madeira : Portugal (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Our works aim at developing a Web platform to connect various Communities of
Practice (CoPs) and to capitalise on all their knowledge. This platform
addresses CoPs interested in a same general activity, for example tutoring. For
that purpose, we propose a general model of Interconnection of Communities of
Practice (ICP), based on the concept of Constellation of Practice (CCP)
developed by Wenger (1998). The model of ICP was implemented and has been used
to develop the TE-Cap 2 platform which has, as its field of application,
educational tutoring activities. In particular, we propose an indexation and
search tool for the ICP knowledge base. The TE-Cap 2 platform has been used in
real conditions. We present the main results of this descriptive investigation
to validate this work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1427</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1427</id><created>2012-01-06</created><updated>2013-01-20</updated><authors><author><keyname>Aoun</keyname><forenames>Marc</forenames></author><author><keyname>Beekhuizen</keyname><forenames>Paul</forenames></author><author><keyname>Argyriou</keyname><forenames>Antonios</forenames></author><author><keyname>Denteneer</keyname><forenames>Dee</forenames></author><author><keyname>van der Stok</keyname><forenames>Peter</forenames></author></authors><title>Packet Skipping and Network Coding for Delay-Sensitive Network
  Communication</title><categories>cs.NI</categories><journal-ref>Performance Evaluation 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide an analytical study of the impact of packet skipping and
opportunistic network coding on the timely communication of messages through a
single network element. In a first step, we consider a single-server queueing
system with Poisson arrivals, exponential service times, and a single buffer
position. Packets arriving at a network node have a fixed deadline before which
they should reach the destination. To preserve server capacity, we introduce a
thresholding policy, based on remaining time until deadline expiration, to
decide whether to serve a packet or skip its service. The obtained goodput
improvement of the system is derived, as well as the operating conditions under
which thresholding can enhance performance. Subsequently, we focus our analysis
on a system that supports network coding instead of thresholding. We
characterize the impact of network coding at a router node on the delivery of
packets associated with deadlines. We model the router node as a queueing
system where packets arrive from two independent Poisson flows and undergo
opportunistic coding operations. We obtain an exact expression for the goodput
of the system and study the achievable gain. Finally, we provide an analytical
model that considers both network coding and packet skipping, capturing their
joint performance. A comparative analysis between the aforementioned approaches
is provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1432</identifier>
 <datestamp>2012-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1432</id><created>2012-01-06</created><updated>2012-04-27</updated><authors><author><keyname>Sadoc</keyname><forenames>Jean-Fran&#xe7;ois</forenames></author><author><keyname>Rivier</keyname><forenames>Nicolas</forenames></author><author><keyname>Charvolin</keyname><forenames>Jean</forenames></author></authors><title>Phyllotaxis: a non conventional crystalline solution to packing
  efficiency in situations with radial symmetry</title><categories>cond-mat.dis-nn cs.CG physics.atm-clus</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Phyllotaxis, the search for the most homogeneous and dense organizations of
small disks inside a large circular domain, was first developed to analyze
arrangements of leaves or florets in plants. Then it has become an object of
study not only in botany, but also in mathematics, computer simulations and
physics. Although the mathematical solution is now well known, an algorithm
setting out the centers of the small disks on a Fermat spiral, the very nature
of this organization and its properties of symmetry remain to be examined. The
purpose of this paper is to describe a phyllotactic organization of points
through its Voronoi cells and Delaunay triangulation and to refer to the
concept of defects developed in condensed matter physics. The topological
constraint of circular symmetry introduces an original inflation-deflation
symmetry taking the place of the translational and rotational symmetries of
classical crystallography.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1449</identifier>
 <datestamp>2012-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1449</id><created>2012-01-06</created><updated>2012-02-07</updated><authors><author><keyname>Ahadpour</keyname><forenames>Sodeif</forenames></author><author><keyname>Sadra</keyname><forenames>Yaser</forenames></author><author><keyname>ArastehFard</keyname><forenames>Zahra</forenames></author></authors><title>A Novel Chaotic Encryption Scheme based on Pseudorandom Bit Padding</title><categories>cs.CR</categories><comments>8 pages, 5 figures, Published in IJCSI International Journal of
  Computer Science Issues (January 2012)</comments><journal-ref>IJCSI International Journal of Computer Science Issues, Vol. 9,
  Issue 1, No 2, (2012) 449-456</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cryptography is always very important in data origin authentications, entity
authentication, data integrity and confidentiality. In recent years, a variety
of chaotic cryptographic schemes have been proposed. These schemes have typical
structure which performed the permutation and the diffusion stages,
alternatively. The random number generators are intransitive in cryptographic
schemes and be used in the diffusion functions of the image encryption for
diffused pixels of plain image. In this paper, we propose a chaotic encryption
scheme based on pseudorandom bit padding that the bits be generated by a novel
logistic pseudorandom image algorithm. To evaluate the security of the cipher
image of this scheme, the key space analysis, the correlation of two adjacent
pixels and differential attack were performed. This scheme tries to improve the
problem of failure of encryption such as small key space and level of security.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1450</identifier>
 <datestamp>2012-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1450</id><created>2012-01-06</created><authors><author><keyname>Bennett</keyname><forenames>Casey</forenames></author></authors><title>The Interaction of Entropy-Based Discretization and Sample Size: An
  Empirical Study</title><categories>stat.ML cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An empirical investigation of the interaction of sample size and
discretization - in this case the entropy-based method CAIM (Class-Attribute
Interdependence Maximization) - was undertaken to evaluate the impact and
potential bias introduced into data mining performance metrics due to variation
in sample size as it impacts the discretization process. Of particular interest
was the effect of discretizing within cross-validation folds averse to outside
discretization folds. Previous publications have suggested that discretizing
externally can bias performance results; however, a thorough review of the
literature found no empirical evidence to support such an assertion. This
investigation involved construction of over 117,000 models on seven distinct
datasets from the UCI (University of California-Irvine) Machine Learning
Library and multiple modeling methods across a variety of configurations of
sample size and discretization, with each unique &quot;setup&quot; being independently
replicated ten times. The analysis revealed a significant optimistic bias as
sample sizes decreased and discretization was employed. The study also revealed
that there may be a relationship between the interaction that produces such
bias and the numbers and types of predictor attributes, extending the &quot;curse of
dimensionality&quot; concept from feature selection into the discretization realm.
Directions for further exploration are laid out, as well some general
guidelines about the proper application of discretization in light of these
results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1462</identifier>
 <datestamp>2012-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1462</id><created>2012-01-06</created><updated>2012-11-16</updated><authors><author><keyname>Ma</keyname><forenames>Xudong</forenames></author></authors><title>Symbol-Index-Feedback Polar Coding Schemes for Low-Complexity Devices</title><categories>cs.IT math.IT</categories><comments>Accepted for publication in the Proceedings of the International
  Conference on Computing, Networking and Communications 2013, San Diego, USA,
  January 28-31, 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, a new class of error-control codes, the polar codes, have attracted
much attention. The polar codes are the first known class of capacity-achieving
codes for many important communication channels. In addition, polar codes have
low-complexity encoding algorithms. Therefore, these codes are favorable
choices for low-complexity devices, for example, in ubiquitous computing and
sensor networks. However, the polar codes fall short in terms of finite-length
error probabilities, compared with the state-of-the-art codes, such as the
low-density parity-check codes. In this paper, in order to improve the error
probabilities of the polar codes, we propose novel interactive coding schemes
using receiver feedbacks based on polar codes. The proposed coding schemes have
very low computational complexities at the transmitter side. By experimental
results, we show that the proposed coding schemes achieve significantly lower
error probabilities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1465</identifier>
 <datestamp>2012-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1465</id><created>2012-01-06</created><authors><author><keyname>Yordzhev</keyname><forenames>Krasimir</forenames></author><author><keyname>Kostadinova</keyname><forenames>Hristina</forenames></author></authors><title>Mathematical Modeling of the Weaving Structure Design</title><categories>math.RT cs.DS math.CO</categories><comments>Proceedings of the Thirty Ninth Spring Conference of the Union of
  Bulgarian Mathematicians, Albena, April 6-10, 2010</comments><msc-class>15B34, 05A05, 93A30, 68W40</msc-class><journal-ref>Mathematics and education in mathematics, v. 39, 2010, 212-220</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An equivalence relation in the set of all square binary matrices is described
in this work. It is discussed a combinatoric problem about finding the cardinal
number and the elements of the factor set according to this relation. We
examine the possibility to get some special elements of this factor set. We
propose an algorithm, which solves these problems. The results we have received
are used to describe the topology of the different weaving structures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1468</identifier>
 <datestamp>2012-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1468</id><created>2012-01-06</created><authors><author><keyname>Yordzhev</keyname><forenames>Krasimir Yankov</forenames></author></authors><title>An Example for the Use of Bitwise Operations in Programming</title><categories>cs.OH math.CO</categories><comments>Proceedings of the Thirty Eighth Spring Conference of the Union of
  Bulgarian Mathematicians, Borovetz, April 1-?5, 2009</comments><msc-class>68N15, 68R05, 05A18</msc-class><journal-ref>Mathematics and education in mathematics, v. 38 (2009), 196-202</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This piece of work presents a meaningful example for the advantages of using
bitwise operations for creating effective algorithms in programming. A task
connected with mathematical modeling in weaving industry is examined and
computed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1473</identifier>
 <datestamp>2012-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1473</id><created>2012-01-06</created><authors><author><keyname>Kostadinova</keyname><forenames>Hristina</forenames></author><author><keyname>Yordzhev</keyname><forenames>Krasimir</forenames></author></authors><title>A Representation of Binary Matrices</title><categories>cs.MS</categories><comments>Proceedings of the Thirty Ninth Spring Conference of the Union of
  Bulgarian Mathematicians, Albena, April 6-10, 2010</comments><msc-class>68N15, 68W40, 15B34</msc-class><journal-ref>Mathematics and education in mathematics, v. 39, 2010, 198-206</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article we discuss the presentation of a random binary matrix using
sequence of whole nonnegative numbers. We examine some advantages and
disadvantages of this presentation as an alternative of the standard
presentation using two-dimensional array. It is shown that the presentation of
binary matrices using ordered n-tuples of natural numbers makes the algorithms
faster and saves a lot of memory. In this work we use object-oriented
programming using the syntax and the semantic of C++ programming language.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1481</identifier>
 <datestamp>2012-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1481</id><created>2012-01-06</created><authors><author><keyname>Belouadha</keyname><forenames>Fatima-Zahra</forenames></author><author><keyname>Omrana</keyname><forenames>Hajar</forenames></author><author><keyname>Roudies</keyname><forenames>Ounsa</forenames></author></authors><title>A MDA approach for defining WS-Policy semantic non-functional properties</title><categories>cs.SE</categories><comments>8 pages, 4 figures</comments><journal-ref>International Journal of Engineering Science and Technology
  (IJEST), ISSN: 0975--5462 (online version), Subject Category: Engineering
  Science and Technology, published in volume 2 issue 6 (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A lot of works has been especially interested to the functional aspect of Web
services. Nevertheless, it is necessary to describe their non-functional
properties such as the security characteristics and the quality of service. The
WS-Policy standard was recommended in 2007 to describe Web services policies
including the non-functional properties. However, it doesn't provide any
information of their meaning necessary for automatic processes. In this paper,
we propose a Model Driven Architecture approach founded on W3C standards to
generate WSDL language based files including semantic policies. We use a
package of WSDL and WS-Policy profiles and transformations rules to generate
Web services interfaces files including policies. We extend a XML schema
profile according to SAWSDL standard to define semantic non-functional
properties domains. This work contributes to minimize the development cost of
Web services including semantic policies. Moreover, the generated services can
be automatically processed in discovery, selection and negotiation tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1507</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1507</id><created>2012-01-06</created><updated>2012-10-13</updated><authors><author><keyname>Son</keyname><forenames>Seung-Woo</forenames></author><author><keyname>Christensen</keyname><forenames>Claire</forenames></author><author><keyname>Bizhani</keyname><forenames>Golnoosh</forenames></author><author><keyname>Foster</keyname><forenames>David V.</forenames></author><author><keyname>Grassberger</keyname><forenames>Peter</forenames></author><author><keyname>Paczuski</keyname><forenames>Maya</forenames></author></authors><title>Sampling properties of directed networks</title><categories>physics.soc-ph cs.SI physics.data-an</categories><comments>21 pages, 11 figures</comments><journal-ref>Phys. Rev. E 86, 046104 (2012)</journal-ref><doi>10.1103/PhysRevE.86.046104</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For many real-world networks only a small &quot;sampled&quot; version of the original
network may be investigated; those results are then used to draw conclusions
about the actual system. Variants of breadth-first search (BFS) sampling, which
are based on epidemic processes, are widely used. Although it is well
established that BFS sampling fails, in most cases, to capture the
IN-component(s) of directed networks, a description of the effects of BFS
sampling on other topological properties are all but absent from the
literature. To systematically study the effects of sampling biases on directed
networks, we compare BFS sampling to random sampling on complete large-scale
directed networks. We present new results and a thorough analysis of the
topological properties of seven different complete directed networks (prior to
sampling), including three versions of Wikipedia, three different sources of
sampled World Wide Web data, and an Internet-based social network. We detail
the differences that sampling method and coverage can make to the structural
properties of sampled versions of these seven networks. Most notably, we find
that sampling method and coverage affect both the bow-tie structure, as well as
the number and structure of strongly connected components in sampled networks.
In addition, at low sampling coverage (i.e. less than 40%), the values of
average degree, variance of out-degree, degree auto-correlation, and link
reciprocity are overestimated by 30% or more in BFS-sampled networks, and only
attain values within 10% of the corresponding values in the complete networks
when sampling coverage is in excess of 65%. These results may cause us to
rethink what we know about the structure, function, and evolution of real-world
directed networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1512</identifier>
 <datestamp>2012-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1512</id><created>2012-01-06</created><authors><author><keyname>Ferry</keyname><forenames>James P.</forenames></author><author><keyname>Bumgarner</keyname><forenames>J. Oren</forenames></author></authors><title>Community detection and tracking on networks from a data fusion
  perspective</title><categories>cs.SI math.PR physics.soc-ph</categories><comments>40 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Community structure in networks has been investigated from many viewpoints,
usually with the same end result: a community detection algorithm of some kind.
Recent research offers methods for combining the results of such algorithms
into timelines of community evolution. This paper investigates community
detection and tracking from the data fusion perspective. We avoid the kind of
hard calls made by traditional community detection algorithms in favor of
retaining as much uncertainty information as possible. This results in a method
for directly estimating the probabilities that pairs of nodes are in the same
community. We demonstrate that this method is accurate using the LFR testbed,
that it is fast on a number of standard network datasets, and that it is has a
variety of uses that complement those of standard, hard-call methods. Retaining
uncertainty information allows us to develop a Bayesian filter for tracking
communities. We derive equations for the full filter, and marginalize it to
produce a potentially practical version. Finally, we discuss closures for the
marginalized filter and the work that remains to develop this into a
principled, efficient method for tracking time-evolving communities on
time-evolving networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1530</identifier>
 <datestamp>2012-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1530</id><created>2012-01-06</created><authors><author><keyname>Chen</keyname><forenames>Richard Li-Yang</forenames></author><author><keyname>Cohn</keyname><forenames>Amy</forenames></author><author><keyname>Fan</keyname><forenames>Neng</forenames></author><author><keyname>Pinar</keyname><forenames>Ali</forenames></author></authors><title>N-k-e Survivable Power System Design</title><categories>math.OC cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of designing (or augmenting) an electric power system
such that it satisfies the N-k-e survivability criterion while minimizing total
cost. The survivability criterion requires that at least (1-e) fraction of the
total demand can still be met even if any k (or fewer) of the system components
fail. We formulate this problem, taking into account both transmission and
generation expansion planning, as a mixed-integer program. Two algorithms are
designed and tested on modified instances from the IEEE-30-Bus and IEEE- 57-Bus
systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1547</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1547</id><created>2012-01-07</created><authors><author><keyname>Olivera</keyname><forenames>Noemi L.</forenames><affiliation>La Plata</affiliation></author><author><keyname>Proto</keyname><forenames>Araceli N.</forenames><affiliation>Buenos Aires</affiliation></author><author><keyname>Ausloos</keyname><forenames>Marcel</forenames><affiliation>Liege</affiliation></author></authors><title>Information Society: Modeling A Complex System With Scarce Data</title><categories>physics.soc-ph cs.IT cs.SI math.IT nlin.AO</categories><comments>14 pages, 12 figures, prepared for the Proceedings of The V Meeting
  on Dynamics of Social and Economic Systems</comments><journal-ref>Proceedings of The V Meeting on Dynamics of Social and Economic
  Systems 6 (2011) 443-460</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Considering electronic implications in the Information Society (IS) as a
complex system, complexity science tools are used to describe the processes
that are seen to be taking place. The sometimes troublesome relationship
between the information and communication new technologies and e-society gives
rise to different problems, some of them being unexpected. Probably, the
Digital Divide (DD) and the Internet Governance (IG) are among the most
conflictive ones of internationally based e-Affairs. Admitting that solutions
should be found for these problems, certain international policies are
required. In this context, data gathering and subsequent analysis, as well as
the construction of adequate physical models are extremely important in order
to imagine different future scenarios and suggest some subsequent control. In
the main text, mathematical modelization helps for visualizing how policies
could e.g. influence the individual and collective behavior in an empirical
social agent system. In order to show how this purpose could be achieved, two
approaches, (i) the Ising model and (ii) a generalized Lotka-Volterra model are
used for DD and IG considerations respectively. It can be concluded that the
social modelization of the e-Information Society as a complex system provides
insights about how DD can be reduced and how the a large number of weak members
of the IS could influence the outcomes of the IG.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1548</identifier>
 <datestamp>2012-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1548</id><created>2012-01-07</created><authors><author><keyname>Berberich</keyname><forenames>Eric</forenames></author><author><keyname>Emeliyanenko</keyname><forenames>Pavel</forenames></author><author><keyname>Kobel</keyname><forenames>Alexander</forenames></author><author><keyname>Sagraloff</keyname><forenames>Michael</forenames></author></authors><title>Exact Symbolic-Numeric Computation of Planar Algebraic Curves</title><categories>cs.CG cs.MS cs.SC math.AG math.GT</categories><comments>46 pages, 4 figures, submitted to Special Issue of TCS on SNC 2011.
  arXiv admin note: substantial text overlap with arXiv:1010.1386 and
  arXiv:1103.4697</comments><msc-class>14Q05 (Primary), 14h50, 14P10 (Secondary)</msc-class><acm-class>I.1.2; G.4; D.2.13</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel certified and complete algorithm to compute arrangements
of real planar algebraic curves. It provides a geometric-topological analysis
of the decomposition of the plane induced by a finite number of algebraic
curves in terms of a cylindrical algebraic decomposition. From a high-level
perspective, the overall method splits into two main subroutines, namely an
algorithm denoted Bisolve to isolate the real solutions of a zero-dimensional
bivariate system, and an algorithm denoted GeoTop to analyze a single algebraic
curve.
  Compared to existing approaches based on elimination techniques, we
considerably improve the corresponding lifting steps in both subroutines. As a
result, generic position of the input system is never assumed, and thus our
algorithm never demands for any change of coordinates. In addition, we
significantly limit the types of involved exact operations, that is, we only
use resultant and gcd computations as purely symbolic operations. The latter
results are achieved by combining techniques from different fields such as
(modular) symbolic computation, numerical analysis and algebraic geometry.
  We have implemented our algorithms as prototypical contributions to the
C++-project CGAL. They exploit graphics hardware to expedite the symbolic
computations. We have also compared our implementation with the current
reference implementations, that is, LGP and Maple's Isolate for polynomial
system solving, and CGAL's bivariate algebraic kernel for analyses and
arrangement computations of algebraic curves. For various series of challenging
instances, our exhaustive experiments show that the new implementations
outperform the existing ones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1571</identifier>
 <datestamp>2012-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1571</id><created>2012-01-07</created><updated>2012-05-07</updated><authors><author><keyname>Lu</keyname><forenames>Hongyu</forenames></author><author><keyname>Wang</keyname><forenames>Yutian</forenames></author><author><keyname>Bao</keyname><forenames>Shanglian</forenames></author></authors><title>A United Image Force for Deformable Models and Direct Transforming
  Geometric Active Contorus to Snakes by Level Sets</title><categories>cs.CV</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  A uniform distribution of the image force field around the object fasts the
convergence speed of the segmentation process. However, to achieve this aim, it
causes the force constructed from the heat diffusion model unable to indicate
the object boundaries accurately. The image force based on electrostatic field
model can perform an exact shape recovery. First, this study introduces a
fusion scheme of these two image forces, which is capable of extracting the
object boundary with high precision and fast speed. Until now, there is no
satisfied analysis about the relationship between Snakes and Geometric Active
Contours (GAC). The second contribution of this study addresses that the GAC
model can be deduced directly from Snakes model. It proves that each term in
GAC and Snakes is correspondent and has similar function. However, the two
models are expressed using different mathematics. Further, since losing the
ability of rotating the contour, adoption of level sets can limits the usage of
GAC in some circumstances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1572</identifier>
 <datestamp>2012-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1572</id><created>2012-01-07</created><authors><author><keyname>Souza</keyname><forenames>S. R.</forenames></author><author><keyname>Goncalves</keyname><forenames>S.</forenames></author></authors><title>A dynamical model for competing opinions</title><categories>physics.soc-ph cs.SI</categories><journal-ref>Physical Review E 85, 056103 (2012)</journal-ref><doi>10.1103/PhysRevE.85.056103</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an opinion model based on agents located at the vertices of a
regular lattice. Each agent has an independent opinion (among an arbitrary, but
fixed, number of choices) and its own degree of conviction. The latter changes
every time it interacts with another agent who has a different opinion. The
dynamics leads to size distributions of clusters (made up of agents which have
the same opinion and are located at contiguous spatial positions) which follow
a power law, as long as the range of the interaction between the agents is not
too short, i.e. the system self-organizes into a critical state. Short range
interactions lead to an exponential cut off in the size distribution and to
spatial correlations which cause agents which have the same opinion to be
closely grouped. When the diversity of opinions is restricted to two,
non-consensus dynamic is observed, with unequal population fractions, whereas
consensus is reached if the agents are also allowed to interact with those
which are located far from them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1587</identifier>
 <datestamp>2012-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1587</id><created>2012-01-07</created><updated>2012-03-21</updated><authors><author><keyname>Deng</keyname><forenames>Houtao</forenames></author><author><keyname>Runger</keyname><forenames>George</forenames></author></authors><title>Feature Selection via Regularized Trees</title><categories>cs.LG stat.ME stat.ML</categories><comments>8 pages; The 2012 International Joint Conference on Neural Networks
  (IJCNN), IEEE, 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a tree regularization framework, which enables many tree models to
perform feature selection efficiently. The key idea of the regularization
framework is to penalize selecting a new feature for splitting when its gain
(e.g. information gain) is similar to the features used in previous splits. The
regularization framework is applied on random forest and boosted trees here,
and can be easily applied to other tree models. Experimental studies show that
the regularized trees can select high-quality feature subsets with regard to
both strong and weak classifiers. Because tree models can naturally deal with
categorical and numerical variables, missing values, different scales between
variables, interactions and nonlinearities etc., the tree regularization
framework provides an effective and efficient feature selection solution for
many practical problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1588</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1588</id><created>2012-01-07</created><authors><author><keyname>Li</keyname><forenames>Chong</forenames></author><author><keyname>Elia</keyname><forenames>Nicola</forenames></author></authors><title>Upper Bound on the Capacity of Gaussian Channels with Noisy Feedback</title><categories>cs.IT math.IT</categories><comments>6 pages. Published on the Forty-Ninth Annual Allerton Conference on
  Communication, Control, and Computing, September 28 - September 30, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider an additive Gaussian channel with additive Gaussian noise
feedback. We derive an upper bound on the n-block capacity (defined by Cover
[1]). It is shown that this upper bound can be obtained by solving a convex
optimization problem. With stationarity assumptions on Gaussian noise
processes, we characterize the limit of the n-block upper bound and prove that
this limit is the upper bound of the noisy feedback (shannon) capacity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1589</identifier>
 <datestamp>2013-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1589</id><created>2012-01-07</created><updated>2012-03-12</updated><authors><author><keyname>Vaquero</keyname><forenames>Luis M.</forenames></author><author><keyname>Cebrian</keyname><forenames>Manuel</forenames></author></authors><title>The Weakness of Weak Ties in the Classroom</title><categories>cs.SI physics.soc-ph</categories><comments>12 pages, 5 figures</comments><journal-ref>Vaquero, L.M. &amp; Cebrian, M. The rich club phenomenon in the
  classroom. Sci. Rep. 3, 1174 (2013)</journal-ref><doi>10.1038/srep01174</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Granovetter's &quot;strength of weak ties&quot; hypothesizes that isolated social ties
offer limited access to external prospects, while heterogeneous social ties
diversify one's opportunities. We analyze the most complete record of college
student interactions to date (approximately 80,000 interactions by 290 students
-- 16 times more interactions with almost 3 times more students than previous
studies on educational networks) and compare the social interaction data with
the academic scores of the students. Our first finding is that social diversity
is negatively correlated with performance. This is explained by our second
finding: highly performing students interact in groups of similarly performing
peers. This effect is stronger the higher the student performance is. Indeed,
low performance students tend to initiate many transient interactions
independently of the performance of their target. In other words, low
performing students act disassortatively with respect to their social network,
whereas high scoring students act assortatively. Our data also reveals that
highly performing students establish persistent interactions before mid and low
performing ones and that they use more structured and longer cascades of
information from which low performing students are excluded.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1601</identifier>
 <datestamp>2015-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1601</id><created>2012-01-07</created><authors><author><keyname>Wu</keyname><forenames>Xiaolin</forenames></author><author><keyname>Zhai</keyname><forenames>Guangtao</forenames></author></authors><title>Temporal Psychovisual Modulation: a new paradigm of information display</title><categories>cs.ET</categories><doi>10.1109/MSP.2012.2219678</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We report on a new paradigm of information display that greatly extends the
utility and versatility of current optoelectronic displays. The main innovation
is to let a display of high refresh rate optically broadcast so-called atom
frames, which are designed through non-negative matrix factorization to form
bases for a class of images, and different viewers perceive selfintended images
by using display-synchronized viewing devices and their own human visual
systems to fuse appropriately weighted atom frames. This work is essentially a
scheme of temporal psychovisual modulation in visible spectrum, using an
optoelectronic modulator coupled with a biological demodulator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1603</identifier>
 <datestamp>2012-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1603</id><created>2012-01-07</created><authors><author><keyname>Hur</keyname><forenames>Youngmi</forenames></author></authors><title>Committee Algorithm: An Easy Way to Construct Wavelet Filter Banks</title><categories>math.NA cs.IT math.IT</categories><comments>4 pages, 1 figure, Accepted by ICASSP 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a lowpass filter, finding a dual lowpass filter is an essential step in
constructing non-redundant wavelet filter banks. Obtaining dual lowpass filters
is not an easy task. In this paper, we introduce a new method called committee
algorithm that builds a dual filter straightforwardly from two
easily-constructible lowpass filters. It allows to design a wide range of new
wavelet filter banks. An example based on the family of Burt-Adelson's 1-D
Laplacian filters is given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1611</identifier>
 <datestamp>2012-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1611</id><created>2012-01-08</created><authors><author><keyname>Rao</keyname><forenames>A. Ananda</forenames></author><author><keyname>Reddy</keyname><forenames>K. Narendar</forenames></author></authors><title>Identifying Clusters of Concepts in a Low Cohesive Class for Extract
  Class Refactoring Using Metrics Supplemented Agglomerative Clustering
  Technique</title><categories>cs.SE</categories><comments>10 pages, 8 figures, 4 tables; ISSN (Online): 1694-0814</comments><journal-ref>IJCSI International Journal of Computer Science Issues, Vol. 8,
  Issue 5, No 2, September 2011, 185-194</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Object oriented software with low cohesive classes can increase maintenance
cost. Low cohesive classes are likely to be introduced into the software during
initial design due to deviation from design principles and during evolution due
to software deterioration. Low cohesive class performs operations that should
be done by two or more classes. The low cohesive classes need to be identified
and refactored using extract class refactoring to improve the cohesion. In this
regard, two aspects are involved; the first one is to identify the low cohesive
classes and the second one is to identify the clusters of concepts in the low
cohesive classes for extract class refactoring. In this paper, we propose
metrics supplemented agglomerative clustering technique for covering the above
two aspects. The proposed metrics are validated using Weyuker's properties. The
approach is applied successfully on two examples and on a case study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1613</identifier>
 <datestamp>2012-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1613</id><created>2012-01-08</created><authors><author><keyname>Voyant</keyname><forenames>Cyril</forenames><affiliation>SPE, CHD Castellucio</affiliation></author><author><keyname>Muselli</keyname><forenames>Marc</forenames><affiliation>SPE</affiliation></author><author><keyname>Paoli</keyname><forenames>Christophe</forenames><affiliation>SPE</affiliation></author><author><keyname>Nivet</keyname><forenames>Marie Laure</forenames><affiliation>SPE</affiliation></author></authors><title>Numerical Weather Prediction (NWP) and hybrid ARMA/ANN model to predict
  global radiation</title><categories>cs.NE physics.data-an</categories><comments>Energy (2012) 1</comments><proxy>ccsd</proxy><doi>10.1016/j.energy.2012.01.006</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose in this paper an original technique to predict global radiation
using a hybrid ARMA/ANN model and data issued from a numerical weather
prediction model (ALADIN). We particularly look at the Multi-Layer Perceptron.
After optimizing our architecture with ALADIN and endogenous data previously
made stationary and using an innovative pre-input layer selection method, we
combined it to an ARMA model from a rule based on the analysis of hourly data
series. This model has been used to forecast the hourly global radiation for
five places in Mediterranean area. Our technique outperforms classical models
for all the places. The nRMSE for our hybrid model ANN/ARMA is 14.9% compared
to 26.2% for the na\&quot;ive persistence predictor. Note that in the stand alone
ANN case the nRMSE is 18.4%. Finally, in order to discuss the reliability of
the forecaster outputs, a complementary study concerning the confidence
interval of each prediction is proposed
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1623</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1623</id><created>2012-01-08</created><updated>2012-12-04</updated><authors><author><keyname>Gomez</keyname><forenames>Sergio</forenames></author><author><keyname>Montiel</keyname><forenames>Justo</forenames></author><author><keyname>Torres</keyname><forenames>David</forenames></author><author><keyname>Fernandez</keyname><forenames>Alberto</forenames></author></authors><title>MultiDendrograms: Variable-Group Agglomerative Hierarchical Clusterings</title><categories>cs.IR math.ST physics.comp-ph physics.data-an q-fin.CP stat.CO stat.TH</categories><comments>Article upgraded to MultiDendrograms 3.0. Software available at
  http://deim.urv.cat/~sgomez/multidendrograms.php</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  MultiDendrograms is a Java-written application that computes agglomerative
hierarchical clusterings of data. Starting from a distances (or weights)
matrix, MultiDendrograms is able to calculate its dendrograms using the most
common agglomerative hierarchical clustering methods. The application
implements a variable-group algorithm that solves the non-uniqueness problem
found in the standard pair-group algorithm. This problem arises when two or
more minimum distances between different clusters are equal during the
agglomerative process, because then different output clusterings are possible
depending on the criterion used to break ties between distances.
MultiDendrograms solves this problem implementing a variable-group algorithm
that groups more than two clusters at the same time when ties occur.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1633</identifier>
 <datestamp>2012-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1633</id><created>2012-01-08</created><authors><author><keyname>Bakhtary</keyname><forenames>Parsa</forenames></author><author><keyname>Echi</keyname><forenames>Othman</forenames></author></authors><title>On the minimality of Hamming compatible metrics</title><categories>cs.IT math.IT</categories><comments>9 pages</comments><msc-class>94A15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A Hamming compatible metric is an integer-valued metric on the words of a
finite alphabet which agrees with the usual Hamming distance for words of equal
length. We define a new Hamming compatible metric, compute the cardinality of a
sphere with respect to this metric, and show this metric is minimal in the
class of all &quot;well-behaved&quot; Hamming compatible metrics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1634</identifier>
 <datestamp>2012-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1634</id><created>2012-01-08</created><updated>2012-06-13</updated><authors><author><keyname>Mohammed</keyname><forenames>Saif Khan</forenames></author><author><keyname>Larsson</keyname><forenames>Erik G.</forenames></author></authors><title>Per-antenna Constant Envelope Precoding for Large Multi-User MIMO
  Systems</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the multi-user MIMO broadcast channel with $M$ single-antenna
users and $N$ transmit antennas under the constraint that each antenna emits
signals having constant envelope (CE). The motivation for this is that CE
signals facilitate the use of power-efficient RF power amplifiers. Analytical
and numerical results show that, under certain mild conditions on the channel
gains, for a fixed $M$, array gain is achievable even under the stringent
per-antenna CE constraint (essentially, for a fixed $M$, at sufficiently large
$N$ the total transmitted power can be reduced with increasing $N$ while
maintaining a fixed information rate to each user). Simulations for the i.i.d.
Rayleigh fading channel show that the total transmit power can be reduced
linearly with increasing $N$ (i.e., an O(N) array gain). We also propose a
precoding scheme which finds near-optimal CE signals to be transmitted, and has
O(MN) complexity. Also, in terms of the total transmit power required to
achieve a fixed desired information sum-rate, despite the stringent per-antenna
CE constraint, the proposed CE precoding scheme performs close to the
sum-capacity achieving scheme for an average-only total transmit power
constrained channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1647</identifier>
 <datestamp>2012-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1647</id><created>2012-01-08</created><authors><author><keyname>Wynn</keyname><forenames>Ed</forenames></author></authors><title>Constructing circuit codes by permuting initial sequences</title><categories>math.CO cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Two new constructions are presented for coils and snakes in the hypercube.
Improvements are made on the best known results for snake-in-the-box coils of
dimensions 9, 10 and 11, and for some other circuit codes of dimensions between
8 and 13. In the first construction, circuit codes are generated from permuted
copies of an initial transition sequence; the multiple copies constrain the
search, so that long codes can be found relatively efficiently. In the second
construction, two lower-dimensional paths are joined together with only one or
two changes in the highest dimension; this requires a search for a permutation
of the second sequence to fit around the first. It is possible to investigate
sequences of vertices of the hypercube, including circuit codes, by connecting
the corresponding vertices in an extended graph related to the hypercube. As an
example of this, invertible circuit codes are briefly discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1650</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1650</id><created>2012-01-08</created><authors><author><keyname>Cannon</keyname><forenames>Sarah</forenames></author><author><keyname>Demaine</keyname><forenames>Erik D.</forenames></author><author><keyname>Demaine</keyname><forenames>Martin L.</forenames></author><author><keyname>Eisenstat</keyname><forenames>Sarah</forenames></author><author><keyname>Patitz</keyname><forenames>Matthew J.</forenames></author><author><keyname>Schweller</keyname><forenames>Robert</forenames></author><author><keyname>Summers</keyname><forenames>Scott M.</forenames></author><author><keyname>Winslow</keyname><forenames>Andrew</forenames></author></authors><title>Two Hands Are Better Than One (up to constant factors)</title><categories>cs.CC cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the difference between the standard seeded model of tile
self-assembly, and the &quot;seedless&quot; two-handed model of tile self-assembly. Most
of our results suggest that the two-handed model is more powerful. In
particular, we show how to simulate any seeded system with a two-handed system
that is essentially just a constant factor larger. We exhibit finite shapes
with a busy-beaver separation in the number of distinct tiles required by
seeded versus two-handed, and exhibit an infinite shape that can be constructed
two-handed but not seeded. Finally, we show that verifying whether a given
system uniquely assembles a desired supertile is co-NP-complete in the
two-handed model, while it was known to be polynomially solvable in the seeded
model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1652</identifier>
 <datestamp>2012-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1652</id><created>2012-01-08</created><authors><author><keyname>Gibet</keyname><forenames>Sylvie</forenames><affiliation>VALORIA, IRISA</affiliation></author><author><keyname>Marteau</keyname><forenames>Pierre-Fran&#xe7;ois</forenames><affiliation>VALORIA, IRISA</affiliation></author><author><keyname>Duarte</keyname><forenames>Kyle</forenames><affiliation>VALORIA</affiliation></author></authors><title>Toward a Motor Theory of Sign Language Perception</title><categories>cs.CL cs.HC</categories><comments>12 pages Partiellement financ\'e par le projet ANR SignCom</comments><proxy>ccsd</proxy><journal-ref>Gesture and Sign Language in Human-Computer Interaction and
  Embodied Communication (2012) Vol. 7206, 161-172</journal-ref><doi>10.1007/978-3-642-34182-3_15</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Researches on signed languages still strongly dissociate lin- guistic issues
related on phonological and phonetic aspects, and gesture studies for
recognition and synthesis purposes. This paper focuses on the imbrication of
motion and meaning for the analysis, synthesis and evaluation of sign language
gestures. We discuss the relevance and interest of a motor theory of perception
in sign language communication. According to this theory, we consider that
linguistic knowledge is mapped on sensory-motor processes, and propose a
methodology based on the principle of a synthesis-by-analysis approach, guided
by an evaluation process that aims to validate some hypothesis and concepts of
this theory. Examples from existing studies illustrate the di erent concepts
and provide avenues for future work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1656</identifier>
 <datestamp>2013-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1656</id><created>2012-01-08</created><updated>2013-01-31</updated><authors><author><keyname>Ozen</keyname><forenames>Mehmet</forenames></author><author><keyname>&#x15e;iap</keyname><forenames>Vedat</forenames></author></authors><title>A MacWilliams type identity for m-spotty generalized Lee weight
  enumerators over $\mathbb{Z}_q$ q</title><categories>cs.IT math.IT</categories><comments>Submitted to journal on Feb 27, 2011 to Applied Mathematics Letter</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Burst errors are very common in practice. There have been many designs in
order to control and correct such errors. Recently, a new class of byte error
control codes called spotty byte error control codes has been specifically
designed to fit the large capacity memory systems that use high-density random
access memory (RAM) chips with input/output data of 8, 16, and 32 bits. The
MacWilliams identity describes how the weight enumerator of a linear code and
the weight enumerator of its dual code are related. Also, Lee metric which has
attracted many researchers due to its applications. In this paper, we combine
these two interesting topics and introduce the m-spotty generalized Lee weights
and the m-spotty generalized Lee weight enumerators of a code over Z q and
prove a MacWilliams type identity. This generalization includes both the case
of the identity given in the paper [I. Siap, MacWilliams identity for m-spotty
Lee weight enumerators, Appl. Math. Lett. 23 (1) (2010) 13-16] and the identity
given in the paper [M. \&quot;Ozen, V. \c{S}iap, The MacWilliams identity for
m-spotty weight enumerators of linear codes over finite fields, Comput. Math.
Appl. 61 (4) (2011) 1000-1004] over Z2 and Z3 as special cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1657</identifier>
 <datestamp>2012-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1657</id><created>2012-01-08</created><authors><author><keyname>Wang</keyname><forenames>Chong</forenames></author><author><keyname>Blei</keyname><forenames>David M.</forenames></author></authors><title>A Split-Merge MCMC Algorithm for the Hierarchical Dirichlet Process</title><categories>stat.ML cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The hierarchical Dirichlet process (HDP) has become an important Bayesian
nonparametric model for grouped data, such as document collections. The HDP is
used to construct a flexible mixed-membership model where the number of
components is determined by the data. As for most Bayesian nonparametric
models, exact posterior inference is intractable---practitioners use Markov
chain Monte Carlo (MCMC) or variational inference. Inspired by the split-merge
MCMC algorithm for the Dirichlet process (DP) mixture model, we describe a
novel split-merge MCMC sampling algorithm for posterior inference in the HDP.
We study its properties on both synthetic data and text corpora. We find that
split-merge MCMC for the HDP can provide significant improvements over
traditional Gibbs sampling, and we give some understanding of the data
properties that give rise to larger improvements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1661</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1661</id><created>2012-01-08</created><authors><author><keyname>Nguyen</keyname><forenames>Giang T. K.</forenames></author><author><keyname>Agarwal</keyname><forenames>Rachit</forenames></author><author><keyname>Liu</keyname><forenames>Junda</forenames></author><author><keyname>Caesar</keyname><forenames>Matthew</forenames></author><author><keyname>Godfrey</keyname><forenames>P. Brighten</forenames></author><author><keyname>Shenker</keyname><forenames>Scott</forenames></author></authors><title>Slick Packets</title><categories>cs.NI</categories><comments>This is the full version of a paper with the same title that appeared
  in ACM SIGMETRICS 2011, with the inclusion of the appendix. 16 pages</comments><acm-class>C.2.1; C.2.2; C.2.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Source-controlled routing has been proposed as a way to improve flexibility
of future network architectures, as well as simplifying the data plane.
However, if a packet specifies its path, this precludes fast local re-routing
within the network. We propose SlickPackets, a novel solution that allows
packets to slip around failures by specifying alternate paths in their headers,
in the form of compactly-encoded directed acyclic graphs. We show that this can
be accomplished with reasonably small packet headers for real network
topologies, and results in responsiveness to failures that is competitive with
past approaches that require much more state within the network. Our approach
thus enables fast failure response while preserving the benefits of
source-controlled routing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1662</identifier>
 <datestamp>2013-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1662</id><created>2012-01-08</created><updated>2013-06-24</updated><authors><author><keyname>Bayraktar</keyname><forenames>Erhan</forenames></author><author><keyname>Kravitz</keyname><forenames>Ross</forenames></author></authors><title>Quickest Search over Brownian Channels</title><categories>math.PR cs.IT math.IT math.OC</categories><comments>To appear in Stochastics. Keywords: Bayesian quickest search, optimal
  switching, optimal stopping, reflected diffusion</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we resolve an open problem proposed by Lai, Poor, Xin, and
Georgiadis (2011, IEEE Transactions on Information Theory). Consider a sequence
of Brownian Motions with unknown drift equal to one or zero, which we may be
observed one at a time. We give a procedure for finding, as quickly as
possible, a process which is a Brownian Motion with nonzero drift. This
original quickest search problem, in which the filtration itself is dependent
on the observation strategy, is reduced to a single filtration impulse control
and optimal stopping problem, which is in turn reduced to an optimal stopping
problem for a reflected diffusion, which can be explicitly solved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1666</identifier>
 <datestamp>2012-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1666</id><created>2012-01-08</created><authors><author><keyname>Jain</keyname><forenames>Rahul</forenames></author><author><keyname>Pereszlenyi</keyname><forenames>Attila</forenames></author><author><keyname>Yao</keyname><forenames>Penghui</forenames></author></authors><title>A direct product theorem for bounded-round public-coin randomized
  communication complexity</title><categories>cs.CC</categories><comments>19 pages, version 1</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we show a direct product theorm in the model of two-party
bounded-round public-coin randomized communication complexity. For a relation f
subset of X times Y times Z (X,Y,Z are finite sets), let R^{(t), pub}_e (f)
denote the two-party t-message public-coin communication complexity of f with
worst case error e. We show that for any relation f and positive integer k:
R^{(t), pub}_{1 - 2^{-Omega(k/t^2)}}(f^k) = Omega(k/t (R^{(t), pub}_{1/3}(f) -
O(t^2))) . In particular, it implies a strong direct product theorem for the
two-party constant-message public-coin randomized communication complexity of
all relations f.
  Our result for example implies a strong direct product theorem for the
pointer chasing problem. This problem has been well studied for understanding
round v/s communication trade-offs in both classical and quantum communication
protocols.
  We show our result using information theoretic arguments. Our arguments and
techniques build on the ones used in [Jain 2011], where a strong direct product
theorem for the two-party one-way public-coin communication complexity of all
relations is shown (that is the special case of our result when t=1). One key
tool used in our work and also in [Jain 2011] is a message compression
technique due to [Braverman and Rao 2011], who used it to show a direct sum
theorem for the two-party bounded-round public-coin randomized communication
complexity of all relations. Another important tool that we use is a correlated
sampling protocol, which for example, has been used in [Holenstein 2007] for
proving a parallel repetition theorem for two-prover games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1668</identifier>
 <datestamp>2012-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1668</id><created>2012-01-08</created><authors><author><keyname>Jabari</keyname><forenames>Ashraf Sadat</forenames></author><author><keyname>Keyvanpour</keyname><forenames>Mohammadreza</forenames></author></authors><title>Identifying and Analysis of Scene Mining Methods Beased on Scenes
  Extracted Features</title><categories>cs.MM</categories><journal-ref>International Journal of Engineering Science and Technology, Vol.
  3 No. 9 September 2011, 7211-7217</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Scene mining is a subset of image mining in which scenes are classified to a
distinct set of classes based on analysis of their content. In other word in
scene mining, a label is given to visual content of scene, for example,
mountain, beach. Scene mining is used in applications such as medicine, movie,
information retrieval, computer vision, recognition of traffic scene. Reviewing
of represented methods shows there are various methods in scene mining. Scene
mining applications extension and existence of various scenes, make comparison
of methods hard. Scene mining can be followed by identifying scene mining
components and representing a framework to analyzing and evaluating methods. In
this paper, at first, components of scene mining are introduced, then a
framework based on extracted features of scene is represented to classify scene
mining methods. Finally, these methods are analyzed and evaluated via a
proposal framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1670</identifier>
 <datestamp>2012-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1670</id><created>2012-01-08</created><authors><author><keyname>Emtiyaz</keyname><forenames>Siavash</forenames></author><author><keyname>Keyvanpour</keyname><forenames>MohammadReza</forenames></author></authors><title>Customers Behavior Modeling by Semi-Supervised Learning in Customer
  Relationship Management</title><categories>cs.LG</categories><journal-ref>Advances in information Sciences and Service Sciences(AISS),Volume
  3, Number 9, October 2011, 229-236</journal-ref><doi>10.4156/AISS.vol3.issue9.31</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Leveraging the power of increasing amounts of data to analyze customer base
for attracting and retaining the most valuable customers is a major problem
facing companies in this information age. Data mining technologies extract
hidden information and knowledge from large data stored in databases or data
warehouses, thereby supporting the corporate decision making process. CRM uses
data mining (one of the elements of CRM) techniques to interact with customers.
This study investigates the use of a technique, semi-supervised learning, for
the management and analysis of customer-related data warehouse and information.
The idea of semi-supervised learning is to learn not only from the labeled
training data, but to exploit also the structural information in additionally
available unlabeled data. The proposed semi-supervised method is a model by
means of a feed-forward neural network trained by a back propagation algorithm
(multi-layer perceptron) in order to predict the category of an unknown
customer (potential customers). In addition, this technique can be used with
Rapid Miner tools for both labeled and unlabeled data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1671</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1671</id><created>2012-01-08</created><authors><author><keyname>Filho</keyname><forenames>D&#xe9;cio L. Gazzoni</forenames></author><author><keyname>Abr&#xe3;o</keyname><forenames>Taufik</forenames></author><author><keyname>Tosin</keyname><forenames>Marcelo C.</forenames></author><author><keyname>Granziera</keyname><forenames>Francisco</forenames><suffix>Jr</suffix></author></authors><title>Error-Correcting Codes for Reliable Communications in Microgravity
  Platforms</title><categories>cs.IT cs.SY math.IT</categories><comments>13 pages, 3 figures, paper accepted to be published in International
  Journal of Satellite Communications Policy and Management (IJSCPM) ISSN
  (Online): 1742-7576 - ISSN (Print): 1742-7568</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The PAANDA experiment was conceived to characterize the acceleration ambient
of a rocket launched microgravity platform, specially the microgravity phase.
The recorded data was transmitted to ground stations, leading to loss of
telemetry information sent during the reentry period. Traditionally, an
error-correcting code for this channel consists of a block code with very large
block size to protect against long periods of data loss. Instead, we propose
the use of digital fountain codes along with conventional Reed-Solomon block
codes to protect against long and short burst error periods, respectively.
Aiming to use this approach for a second version of PAANDA to prevent data
corruption, we propose a model for the communication channel based on
information extracted from Cum\~a II's telemetry data, and simulate the
performance of our proposed error-correcting code under this channel model.
Simulation results show that nearly all telemetry data can be recovered,
including data from the reentry period.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1674</identifier>
 <datestamp>2012-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1674</id><created>2012-01-08</created><authors><author><keyname>Ashari</keyname><forenames>Zainab</forenames></author><author><keyname>Nordin</keyname><forenames>Anis Nurashikin</forenames></author></authors><title>Theoretical Modeling and Simulation of Phase-Locked Loop (PLL) for Clock
  Data Recovery (CDR)</title><categories>cs.AR</categories><comments>9 pages</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Modern communication and computer systems require rapid (Gbps), efficient and
large bandwidth data transfers. Agressive scaling of digital integrated systems
allow buses and communication controller circuits to be integrated with the
microprocessor on the same chip. The Peripheral Component Interconnect Express
(PCIe) protocol handles all communcation between the central processing unit
(CPU) and hardware devices. PCIe buses require efficient clock data recovery
circuits (CDR) to recover clock signals embedded in data during transmission.
This paper describes the theoretical modeling and simulation of a phase-locked
loop (PLL) used in a CDR circuit. A simple PLL architecture for a 5 GHz CDR
circuit is proposed and elaborated in this work. Simulations were carried out
using a Hardware Description Language, Verilog- AMS. The effect of jitter on
the proposed design is also simulated and evaluated in this work. It was found
that the proposed design is robust against both input and VCO jitter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1676</identifier>
 <datestamp>2014-10-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1676</id><created>2012-01-08</created><updated>2014-10-09</updated><authors><author><keyname>Dhamal</keyname><forenames>Swapnil</forenames></author><author><keyname>Narahari</keyname><forenames>Y.</forenames></author></authors><title>Sufficient Conditions for Formation of a Network Topology by
  Self-interested Agents</title><categories>cs.GT cs.SI physics.soc-ph</categories><comments>The original publication that appeared in the Proceedings of The 8th
  Workshop on Internet &amp; Network Economics, titled 'Forming Networks of
  Strategic Agents with Desired Topologies', is available at
  http://link.springer.com/chapter/10.1007/978-3-642-35311-6_39 . An extended
  version of this paper is under review in IEEE Transactions on Network Science
  and Engineering. Appears as Forming networks of strategic agents with desired
  topologies. In P. Goldberg, editor, Internet and Network Economics, Lecture
  Notes in Computer Science, pages 504-511. Springer Berlin Heidelberg, 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Networks such as organizational network of a global company play an important
role in a variety of knowledge management and information diffusion tasks. The
nodes in these networks correspond to individuals who are self-interested. The
topology of these networks often plays a crucial role in deciding the ease and
speed with which certain tasks can be accomplished using these networks.
Consequently, growing a stable network having a certain topology is of
interest. Motivated by this, we study the following important problem: given a
certain desired network topology, under what conditions would best response
(link addition/deletion) strategies played by self-interested agents lead to
formation of a pairwise stable network with only that topology. We study this
interesting reverse engineering problem by proposing a natural model of
recursive network formation. In this model, nodes enter the network
sequentially and the utility of a node captures principal determinants of
network formation, namely (1) benefits from immediate neighbors, (2) costs of
maintaining links with immediate neighbors, (3) benefits from indirect
neighbors, (4) bridging benefits, and (5) network entry fee. Based on this
model, we analyze relevant network topologies such as star graph, complete
graph, bipartite Turan graph, and multiple stars with interconnected centers,
and derive a set of sufficient conditions under which these topologies emerge
as pairwise stable networks. We also study the social welfare properties of the
above topologies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1684</identifier>
 <datestamp>2013-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1684</id><created>2012-01-08</created><updated>2013-06-16</updated><authors><author><keyname>Ong</keyname><forenames>Lawrence</forenames></author><author><keyname>Lechner</keyname><forenames>Gottfried</forenames></author><author><keyname>Johnson</keyname><forenames>Sarah J.</forenames></author><author><keyname>Kellett</keyname><forenames>Christopher M.</forenames></author></authors><title>The Three-User Finite-Field Multi-Way Relay Channel with Correlated
  Sources</title><categories>cs.IT math.IT</categories><comments>Author's final version (accepted and to appear in IEEE Transactions
  on Communications)</comments><journal-ref>IEEE Transactions on Communications, Vol. 61, No. 8, pp.
  3125-3135, Aug. 2013</journal-ref><doi>10.1109/TCOMM.2013.13.120987</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the three-user finite-field multi-way relay channel, where
the users exchange messages via a relay. The messages are arbitrarily
correlated, and the finite-field channel is linear and is subject to additive
noise of arbitrary distribution. The problem is to determine the minimum
achievable source-channel rate, defined as channel uses per source symbol
needed for reliable communication. We combine Slepian-Wolf source coding and
functional-decode-forward channel coding to obtain the solution for two classes
of source and channel combinations. Furthermore, for correlated sources that
have their common information equal their mutual information, we propose a new
coding scheme to achieve the minimum source-channel rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1695</identifier>
 <datestamp>2013-01-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1695</id><created>2012-01-09</created><authors><author><keyname>Rizvandi</keyname><forenames>Nikzad Babaii</forenames></author><author><keyname>Taheri</keyname><forenames>Javid</forenames></author><author><keyname>Zomaya</keyname><forenames>Albert Y.</forenames></author></authors><title>Some Observations on Optimal Frequency Selection in DVFS-based Energy
  Consumption Minimization</title><categories>cs.DC cs.PF</categories><comments>Journal of Parallel and Distributed Systems, August 2011</comments><journal-ref>Journal of Parallel and Distributed Computing, Volume 71, Issue 8,
  August 2011, Pages 1154-1164</journal-ref><doi>10.1016/j.jpdc.2011.01.004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, the issue of energy consumption in parallel and distributed
computing systems has attracted a great deal of attention. In response to this,
many energy-aware scheduling algorithms have been developed primarily using the
dynamic voltage-frequency scaling (DVFS) capability which has been incorporated
into recent commodity processors. Majority of these algorithms involve two
passes: schedule generation and slack reclamation. The former pass involves the
redistribution of tasks among DVFS-enabled processors based on a given cost
function that includes makespan and energy consumption; and, while the latter
pass is typically achieved by executing individual tasks with slacks at a lower
processor frequency. In this paper, a new slack reclamation algorithm is
proposed by approaching the energy reduction problem from a different angle.
Firstly, the problem of task slack reclamation by using combinations of
processors' frequencies is formulated. Secondly, several proofs are provided to
show that (1) if the working frequency set of processor is assumed to be
continues, the optimal energy will be always achieved by using only one
frequency, (2) for real processors with a discrete set of working frequencies,
the optimal energy is always achieved by using at most two frequencies, and (3)
these two frequencies are adjacent/neighbouring when processor energy
consumption is a convex function of frequency. Thirdly, a novel algorithm to
find the best combination of frequencies to result the optimal energy is
presented. The presented algorithm has been evaluated based on results obtained
from experiments with three different sets of task graphs: 3000 randomly
generated task graphs, and 600 task graphs for two popular applications
(Gauss-Jordan and LU decomposition). The results show the superiority of the
proposed algorithm in comparison with other techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1705</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1705</id><created>2012-01-09</created><updated>2012-02-15</updated><authors><author><keyname>Cousineau</keyname><forenames>Denis</forenames><affiliation>INRIA-Microsoft Research</affiliation></author></authors><title>On completeness of reducibility candidates as a semantics of strong
  normalization</title><categories>cs.LO</categories><comments>24 pages</comments><proxy>LMCS</proxy><acm-class>F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 8, Issue 1 (February
  16, 2012) lmcs:845</journal-ref><doi>10.2168/LMCS-8(1:3)2012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper defines a sound and complete semantic criterion, based on
reducibility candidates, for strong normalization of theories expressed in
minimal deduction modulo \`a la Curry. The use of Curry-style proof-terms
allows to build this criterion on the classic notion of pre-Heyting algebras
and makes that criterion concern all theories expressed in minimal deduction
modulo. Compared to using Church-style proof-terms, this method provides both a
simpler definition of the criterion and a simpler proof of its completeness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1707</identifier>
 <datestamp>2012-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1707</id><created>2012-01-09</created><authors><author><keyname>Chappell</keyname><forenames>James M.</forenames></author><author><keyname>Lohe</keyname><forenames>M. A.</forenames></author><author><keyname>von Smekal</keyname><forenames>Lorenz</forenames></author><author><keyname>Iqbal</keyname><forenames>Azhar</forenames></author><author><keyname>Abbot</keyname><forenames>Derek</forenames></author></authors><title>An improved formalism for the Grover search algorithm</title><categories>quant-ph cs.DS</categories><comments>15 pages 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Grover search algorithm is one of the two key algorithms in the field of
quantum computing, and hence it is of significant interest to describe it in
the most efficient mathematical formalism. We show firstly, that Clifford's
formalism of geometric algebra, provides a significantly more efficient
representation than the conventional Bra-ket notation, and secondly, that the
basis defined by the states of maximum and minimum weight in the Grover search
space, allows a simple visualization of the Grover search as the precession of
a spin-1/2 particle. Using this formalism we efficiently solve the exact search
problem, as well as easily representing more general search situations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1712</identifier>
 <datestamp>2012-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1712</id><created>2012-01-09</created><authors><author><keyname>Levin</keyname><forenames>Mark Sh.</forenames></author></authors><title>Morphological methods for design of modular systems (a survey)</title><categories>cs.SE math.OC</categories><comments>20 pages, 16 figures, 22 tables</comments><msc-class>90C27, 90C29, 90C59, 90C90, 90B18</msc-class><acm-class>D.2.2; A.1; H.1.1; J.6; I.2.8; G.2.1; C.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The article addresses morphological approaches to design of modular systems.
The following methods are briefly described: (i) basic version of morphological
analysis (MA), (ii) modification of MA as method of closeness to ideal
point(s), (iii reducing of MA to linear programming, (iv) multiple choice
problem, (v) quadratic assignment problem, (vi) Pareto-based MA (i.e.,
revelation of Pareto-efficient solutions), (vii) Hierarchical Morphological
Multicriteria Design (HMMD) approach, and (viii) Hierarchical Morphological
Multicriteria Design (HMMD) approach based on fuzzy estimates. The
above-mentioned methods are illustrated by schemes, models, and illustrative
examples. An additional realistic example (design of GSM network) is presented
to illustrate main considered methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1716</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1716</id><created>2012-01-09</created><updated>2012-02-15</updated><authors><author><keyname>Mazur</keyname><forenames>Tomasz</forenames><affiliation>Oxford University</affiliation></author><author><keyname>Lowe</keyname><forenames>Gavin</forenames><affiliation>Oxford University</affiliation></author></authors><title>A type reduction theory for systems with replicated components</title><categories>cs.LO</categories><proxy>LMCS</proxy><acm-class>D.1.3, D.2.4, D.3.2</acm-class><journal-ref>Logical Methods in Computer Science, Volume 8, Issue 1 (February
  16, 2012) lmcs:869</journal-ref><doi>10.2168/LMCS-8(1:4)2012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Parameterised Model Checking Problem asks whether an implementation
Impl(t) satisfies a specification Spec(t) for all instantiations of parameter
t. In general, t can determine numerous entities: the number of processes used
in a network, the type of data, the capacities of buffers, etc. The main theme
of this paper is automation of uniform verification of a subclass of PMCP with
the parameter of the first kind, i.e. the number of processes in the network.
We use CSP as our formalism. We present a type reduction theory, which, for a
given verification problem, establishes a function \phi that maps all
(sufficiently large) instantiations T of the parameter to some fixed type T^
and allows us to deduce that if Spec(T^) is refined by \phi(Impl(T)), then
(subject to certain assumptions) Spec(T) is refined by Impl(T). The theory can
be used in practice by combining it with a suitable abstraction method that
produces a t-independent process Abstr that is refined by {\phi}(Impl(T)) for
all sufficiently large T. Then, by testing (with a model checker) if the
abstract model Abstr refines Spec(T^), we can deduce a positive answer to the
original uniform verification problem. The type reduction theory relies on
symbolic representation of process behaviour. We develop a symbolic operational
semantics for CSP processes that satisfy certain normality requirements, and we
provide a set of translation rules that allow us to concretise symbolic
transition graphs. Based on this, we prove results that allow us to infer
behaviours of a process instantiated with uncollapsed types from known
behaviours of the same process instantiated with a reduced type. One of the
main advantages of our symbolic operational semantics and the type reduction
theory is their generality, which makes them applicable in a wide range of
settings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1717</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1717</id><created>2012-01-09</created><updated>2013-09-13</updated><authors><author><keyname>Chen</keyname><forenames>Wei</forenames></author><author><keyname>Fang</keyname><forenames>Wenjie</forenames></author><author><keyname>Hu</keyname><forenames>Guangda</forenames></author><author><keyname>Mahoney</keyname><forenames>Michael W.</forenames></author></authors><title>On the Hyperbolicity of Small-World and Tree-Like Random Graphs</title><categories>cs.SI cs.DM physics.soc-ph</categories><comments>The third version is the one to appear in the Journal of Internet
  Mathematics</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hyperbolicity is a property of a graph that may be viewed as being a &quot;soft&quot;
version of a tree, and recent empirical and theoretical work has suggested that
many graphs arising in Internet and related data applications have hyperbolic
properties. We consider Gromov's notion of \delta-hyperbolicity, and establish
several results for small-world and tree-like random graph models. First, we
study the hyperbolicity of Kleinberg small-world random graphs and show that
the hyperbolicity of these random graphs is not significantly improved
comparing to graph diameter even when it greatly improves decentralized
navigation. Next we study a class of tree-like graphs called ringed trees that
have constant hyperbolicity. We show that adding random links among the leaves
similar to the small-world graph constructions may easily destroy the
hyperbolicity of the graphs, except for a class of random edges added using an
exponentially decaying probability function based on the ring distance among
the leaves.
  Our study provides one of the first significant analytical results on the
hyperbolicity of a rich class of random graphs, which shed light on the
relationship between hyperbolicity and navigability of random graphs, as well
as on the sensitivity of hyperbolic {\delta} to noises in random graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1728</identifier>
 <datestamp>2012-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1728</id><created>2012-01-09</created><updated>2012-06-26</updated><authors><author><keyname>Dejter</keyname><forenames>Italo J.</forenames></author></authors><title>Worst-case efficient dominating sets in digraphs</title><categories>math.CO cs.IT math.IT</categories><comments>13 pages, 3 figures</comments><msc-class>05C69, 68R10, 94C15, 94B25</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $1\le n\in\Z$. {\it Worst-case efficient dominating sets in digraphs} are
conceived so that their presence in certain strong digraphs $\vec{ST}_n$
corresponds to that of efficient dominating sets in star graphs $ST_n$: The
fact that the star graphs $ST_n$ form a so-called dense segmental neighborly
E-chain is reflected in a corresponding fact for the digraphs $\vec{ST}_n$.
Related chains of graphs and open problems are presented as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1733</identifier>
 <datestamp>2014-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1733</id><created>2012-01-09</created><updated>2014-12-19</updated><authors><author><keyname>Komenda</keyname><forenames>Jan</forenames></author><author><keyname>Masopust</keyname><forenames>Tom&#xe1;&#x161;</forenames></author><author><keyname>van Schuppen</keyname><forenames>Jan H.</forenames></author></authors><title>On Conditional Decomposability</title><categories>cs.SY cs.FL</categories><comments>A few minor corrections</comments><msc-class>93C65, 93A99, 93B50</msc-class><journal-ref>Systems &amp; Control Letters 61 (12), 1260-1268, 2012</journal-ref><doi>10.1016/j.sysconle.2012.07.013</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The requirement of a language to be conditionally decomposable is imposed on
a specification language in the coordination supervisory control framework of
discrete-event systems. In this paper, we present a polynomial-time algorithm
for the verification whether a language is conditionally decomposable with
respect to given alphabets. Moreover, we also present a polynomial-time
algorithm to extend the common alphabet so that the language becomes
conditionally decomposable. A relationship of conditional decomposability to
nonblockingness of modular discrete-event systems is also discussed in this
paper in the general settings. It is shown that conditional decomposability is
a weaker condition than nonblockingness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1754</identifier>
 <datestamp>2012-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1754</id><created>2012-01-09</created><authors><author><keyname>Masopust</keyname><forenames>Tom&#xe1;&#x161;</forenames></author></authors><title>A Note on Undecidability of Observation Consistency for Non-Regular
  Languages</title><categories>cs.SY cs.FL</categories><msc-class>68Q45, 93C65, 93A13, 93B07</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the most interesting questions concerning hierarchical control of
discrete-event systems with partial observations is a condition under which the
language observability is preserved between the original and the abstracted
plant. Recently, we have characterized two such sufficient
conditions---observation consistency and local observation consistency. In this
paper, we prove that the condition of observation consistency is undecidable
for non-regular (linear, deterministic context-free) languages. The question
whether the condition is decidable for regular languages is open.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1755</identifier>
 <datestamp>2012-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1755</id><created>2012-01-09</created><authors><author><keyname>Bialonski</keyname><forenames>Stephan</forenames></author><author><keyname>Wendler</keyname><forenames>Martin</forenames></author><author><keyname>Lehnertz</keyname><forenames>Klaus</forenames></author></authors><title>Unraveling Spurious Properties of Interaction Networks with Tailored
  Random Networks</title><categories>physics.data-an cs.SI physics.comp-ph physics.soc-ph</categories><journal-ref>PLoS ONE, 6(8):e22826, 2011</journal-ref><doi>10.1371/journal.pone.0022826</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate interaction networks that we derive from multivariate time
series with methods frequently employed in diverse scientific fields such as
biology, quantitative finance, physics, earth and climate sciences, and the
neurosciences. Mimicking experimental situations, we generate time series with
finite length and varying frequency content but from independent stochastic
processes. Using the correlation coefficient and the maximum cross-correlation,
we estimate interdependencies between these time series. With clustering
coefficient and average shortest path length, we observe unweighted interaction
networks, derived via thresholding the values of interdependence, to possess
non-trivial topologies as compared to Erd\H{o}s-R\'{e}nyi networks, which would
indicate small-world characteristics. These topologies reflect the mostly
unavoidable finiteness of the data, which limits the reliability of typically
used estimators of signal interdependence. We propose random networks that are
tailored to the way interaction networks are derived from empirical data.
Through an exemplary investigation of multichannel electroencephalographic
recordings of epileptic seizures - known for their complex spatial and temporal
dynamics - we show that such random networks help to distinguish network
properties of interdependence structures related to seizure dynamics from those
spuriously induced by the applied methods of analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1776</identifier>
 <datestamp>2012-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1776</id><created>2012-01-09</created><updated>2012-02-26</updated><authors><author><keyname>Kesidis</keyname><forenames>George</forenames></author><author><keyname>Jin</keyname><forenames>Youngmi</forenames></author></authors><title>Stochastic Loss Aversion for Random Medium Access</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a slotted-ALOHA LAN with loss-averse, noncooperative greedy
users. To avoid non-Pareto equilibria, particularly deadlock, we assume
probabilistic loss-averse behavior. This behavior is modeled as a modulated
white noise term, in addition to the greedy term, creating a diffusion process
modeling the game. We observe that when player's modulate with their
throughput, a more efficient exploration of play-space results, and so finding
a Pareto equilibrium is more likely over a given interval of time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1784</identifier>
 <datestamp>2012-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1784</id><created>2012-01-09</created><authors><author><keyname>Martin</keyname><forenames>St&#xe9;phane</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Ahmed-Nacer</keyname><forenames>Mehdi</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Urso</keyname><forenames>Pascal</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>Abstract unordered and ordered trees CRDT</title><categories>cs.DS</categories><proxy>ccsd</proxy><report-no>RR-7825</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Trees are fundamental data structure for many areas of computer science and
system engineering. In this report, we show how to ensure eventual consistency
of optimistically replicated trees. In optimistic replication, the different
replicas of a distributed system are allowed to diverge but should eventually
reach the same value if no more mutations occur. A new method to ensure
eventual consistency is to design Conflict-free Replicated Data Types (CRDT).
In this report, we design a collection of tree CRDT using existing set CRDTs.
The remaining concurrency problems particular to tree data structure are
resolved using one or two layers of correction algorithm. For each of these
layer, we propose different and independent policies. Any combination of set
CRDT and policies can be constructed, giving to the distributed application
programmer the entire control of the behavior of the shared data in face of
concurrent mutations. We also propose to order these trees by adding a
positioning layer which is also independent to obtain a collection of ordered
tree CRDTs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1798</identifier>
 <datestamp>2012-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1798</id><created>2012-01-09</created><updated>2012-09-26</updated><authors><author><keyname>Bachoc</keyname><forenames>Christine</forenames></author><author><keyname>Ehler</keyname><forenames>Martin</forenames></author></authors><title>Tight p-fusion frames</title><categories>math.NA cs.IT math.IT</categories><doi>10.1016/j.acha.2012.07.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fusion frames enable signal decompositions into weighted linear subspace
components. For positive integers p, we introduce p-fusion frames, a sharpening
of the notion of fusion frames. Tight p-fusion frames are closely related to
the classical notions of designs and cubature formulas in Grassmann spaces and
are analyzed with methods from harmonic analysis in the Grassmannians. We
define the p-fusion frame potential, derive bounds for its value, and discuss
the connections to tight p-fusion frames.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1812</identifier>
 <datestamp>2012-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1812</id><created>2012-01-09</created><authors><author><keyname>Yu</keyname><forenames>Jiun-Hung</forenames></author><author><keyname>Loeliger</keyname><forenames>Hans-Andrea</forenames></author></authors><title>On Polynomial Remainder Codes</title><categories>cs.IT math.IT math.RA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Polynomial remainder codes are a large class of codes derived from the
Chinese remainder theorem that includes Reed-Solomon codes as a special case.
In this paper, we revisit these codes and study them more carefully than in
previous work. We explicitly allow the code symbols to be polynomials of
different degrees, which leads to two different notions of weight and distance.
  Algebraic decoding is studied in detail. If the moduli are not irreducible,
the notion of an error locator polynomial is replaced by an error factor
polynomial. We then obtain a collection of gcd-based decoding algorithms, some
of which are not quite standard even when specialized to Reed-Solomon codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1814</identifier>
 <datestamp>2014-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1814</id><created>2012-01-09</created><authors><author><keyname>Dewenter</keyname><forenames>Timo</forenames></author><author><keyname>Hartmann</keyname><forenames>Alexander K.</forenames></author></authors><title>Phase transition for cutting-plane approach to vertex-cover problem</title><categories>cond-mat.dis-nn cond-mat.stat-mech cs.CC physics.comp-ph</categories><comments>4 pages, 3 figures</comments><journal-ref>Phys. Rev. E 86, 041128 (2012)</journal-ref><doi>10.1103/PhysRevE.86.041128</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the vertex-cover problem which is an NP-hard optimization problem
and a prototypical model exhibiting phase transitions on random graphs, e.g.,
Erdoes-Renyi (ER) random graphs. These phase transitions coincide with changes
of the solution space structure, e.g, for the ER ensemble at connectivity
c=e=2.7183 from replica symmetric to replica-symmetry broken. For the
vertex-cover problem, also the typical complexity of exact branch-and-bound
algorithms, which proceed by exploring the landscape of feasible
configurations, change close to this phase transition from &quot;easy&quot; to &quot;hard&quot;. In
this work, we consider an algorithm which has a completely different strategy:
The problem is mapped onto a linear programming problem augmented by a
cutting-plane approach, hence the algorithm operates in a space OUTSIDE the
space of feasible configurations until the final step, where a solution is
found. Here we show that this type of algorithm also exhibits an &quot;easy-hard&quot;
transition around c=e, which strongly indicates that the typical hardness of a
problem is fundamental to the problem and not due to a specific representation
of the problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1829</identifier>
 <datestamp>2012-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1829</id><created>2012-01-05</created><authors><author><keyname>Zarate</keyname><forenames>Nelson</forenames></author><author><keyname>Seaman</keyname><forenames>Rob</forenames></author><author><keyname>Tody</keyname><forenames>Doug</forenames></author></authors><title>FITS Foreign File Encapsulation Convention</title><categories>astro-ph.IM cs.DB</categories><comments>Registered FITS Convention:
  http://fits.gsfc.nasa.gov/registry/foreign.html, 10 September 2007, 6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This document describes a FITS convention developed by the IRAF Group (D.
Tody, R. Seaman, and N. Zarate) at the National Optical Astronomical
Observatory (NOAO). This convention is implemented by the fgread/fgwrite tasks
in the IRAF fitsutil package. It was first used in May 1999 to encapsulate
preview PNG-format graphics files into FITS files in the NOAO High Performance
Pipeline System. A FITS extension of type 'FOREIGN' provides a mechanism for
storing an arbitrary file or tree of files in FITS, allowing it to be restored
to disk at a later time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1835</identifier>
 <datestamp>2012-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1835</id><created>2012-01-09</created><authors><author><keyname>Paolini</keyname><forenames>Enrico</forenames></author><author><keyname>Liva</keyname><forenames>Gianluigi</forenames></author><author><keyname>Chiani</keyname><forenames>Marco</forenames></author></authors><title>Graph-Based Random Access for the Collision Channel without Feedback:
  Capacity Bound</title><categories>cs.IT math.IT</categories><comments>in Proc. IEEE Globecom 2011, Houston, TX</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A random access scheme for the collision channel without feedback is
proposed. The scheme is based on erasure correcting codes for the recovery of
packet segments that are lost in collisions, and on successive interference
cancellation for resolving collisions. The proposed protocol achieves reliable
communication in the asymptotic setting and attains capacities close to 1
[packets/slot]. A capacity bound as a function of the overall rate of the
scheme is derived, and code distributions tightly approaching the bound
developed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1861</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1861</id><created>2012-01-09</created><updated>2012-05-27</updated><authors><author><keyname>Xiong</keyname><forenames>Gang</forenames></author><author><keyname>Kishore</keyname><forenames>Shalinee</forenames></author><author><keyname>Yener</keyname><forenames>Aylin</forenames></author></authors><title>Spectrum Sensing in Cognitive Radio Networks: Performance Evaluation and
  Optimization</title><categories>cs.IT math.IT math.PR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies cooperative spectrum sensing in cognitive radio networks
where secondary users collect local energy statistics and report their findings
to a secondary base station, i.e., a fusion center. First, the average error
probability is quantitively analyzed to capture the dynamic nature of both
observation and fusion channels, assuming fixed amplifier gains for relaying
local statistics to the fusion center. Second, the system level overhead of
cooperative spectrum sensing is addressed by considering both the local
processing cost and the transmission cost. Local processing cost incorporates
the overhead of sample collection and energy calculation that must be conducted
by each secondary user; the transmission cost accounts for the overhead of
forwarding the energy statistic computed at each secondary user to the fusion
center. Results show that when jointly designing the number of collected energy
samples and transmission amplifier gains, only one secondary user needs to be
actively engaged in spectrum sensing. Furthermore, when number of energy
samples or amplifier gains are fixed, closed form expressions for optimal
solutions are derived and a generalized water-filling algorithm is provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1869</identifier>
 <datestamp>2012-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1869</id><created>2012-01-09</created><authors><author><keyname>Cygan</keyname><forenames>Marek</forenames></author><author><keyname>Pilipczuk</keyname><forenames>Marcin</forenames></author><author><keyname>Pilipczuk</keyname><forenames>Micha&#x142;</forenames></author><author><keyname>Wojtaszczyk</keyname><forenames>Jakub Onufry</forenames></author></authors><title>Sitting closer to friends than enemies, revisited</title><categories>cs.DS cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Signed graphs, i.e., undirected graphs with edges labelled with a plus or
minus sign, are commonly used to model relationships in social networks.
Recently, Kermarrec and Thraves initiated the study of the problem of
appropriately visualising the network: They asked whether any signed graph can
be embedded into the metric space R^l in such a manner that every vertex is
closer to all its friends (neighbours via positive edges) than to all its
enemies (neighbours via negative edges). Interestingly, embeddability into R^1
can be expressed as a purely combinatorial problem. In this paper we pursue a
deeper study of this particular case, answering several questions posed by
Kermarrec and Thraves.
  First, we refine the approach of Kermarrec and Thraves for the case of
complete signed graphs by showing that the problem is closely related to the
recognition of proper interval graphs. Second, we prove that the general case,
whose polynomial-time tractability remained open, is in fact NP-complete.
Finally, we provide lower and upper bounds for the time complexity of the
general case: we prove that the existence of a subexponential time (in the
number of vertices and edges of the input signed graph) algorithm would violate
the Exponential Time Hypothesis, whereas a simple dynamic programming approach
gives a running time single-exponential in the number of vertices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1870</identifier>
 <datestamp>2012-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1870</id><created>2012-01-09</created><updated>2012-03-30</updated><authors><author><keyname>Seb&#x151;</keyname><forenames>Andr&#xe1;s</forenames></author><author><keyname>Vygen</keyname><forenames>Jens</forenames></author></authors><title>Shorter Tours by Nicer Ears: 7/5-approximation for graphic TSP, 3/2 for
  the path version, and 4/3 for two-edge-connected subgraphs</title><categories>cs.DM cs.DS math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove new results for approximating the graphic TSP and some related
problems. We obtain polynomial-time algorithms with improved approximation
guarantees.
  For the graphic TSP itself, we improve the approximation ratio to 7/5. For a
generalization, the connected-$T$-join problem, we obtain the first nontrivial
approximation algorithm, with ratio 3/2. This contains the graphic
$s$-$t$-path-TSP as a special case. Our improved approximation guarantee for
finding a smallest 2-edge-connected spanning subgraph is 4/3.
  The key new ingredient of all our algorithms is a special kind of
ear-decomposition optimized using forest representations of hypergraphs. The
same methods also provide the lower bounds (arising from LP relaxations) that
we use to deduce the approximation ratios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1900</identifier>
 <datestamp>2012-02-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1900</id><created>2012-01-09</created><authors><author><keyname>Wang</keyname><forenames>Zhen</forenames></author><author><keyname>Szolnoki</keyname><forenames>Attila</forenames></author><author><keyname>Perc</keyname><forenames>Matjaz</forenames></author></authors><title>Evolution of public cooperation on interdependent networks: The impact
  of biased utility functions</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI q-bio.PE</categories><comments>6 two-column pages, 6 figures; accepted for publication in
  Europhysics Letters</comments><journal-ref>EPL 97 (2012) 48001</journal-ref><doi>10.1209/0295-5075/97/48001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the evolution of public cooperation on two interdependent networks
that are connected by means of a utility function, which determines to what
extent payoffs in one network influence the success of players in the other
network. We find that the stronger the bias in the utility function, the higher
the level of public cooperation. Yet the benefits of enhanced public
cooperation on the two networks are just as biased as the utility functions
themselves. While cooperation may thrive on one network, the other may still be
plagued by defectors. Nevertheless, the aggregate level of cooperation on both
networks is higher than the one attainable on an isolated network. This
positive effect of biased utility functions is due to the suppressed feedback
of individual success, which leads to a spontaneous separation of
characteristic time scales of the evolutionary process on the two
interdependent networks. As a result, cooperation is promoted because the
aggressive invasion of defectors is more sensitive to the slowing down than the
build-up of collective efforts in sizable groups.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1928</identifier>
 <datestamp>2012-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1928</id><created>2012-01-05</created><authors><author><keyname>Costigan</keyname><forenames>Sean</forenames></author><author><keyname>Pallaris</keyname><forenames>Chris</forenames></author></authors><title>Knowledge Ecologies in International Affairs: A New Paradigm for Dialog
  and Collaboration</title><categories>cs.CY</categories><comments>15 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To have command over increasingly complicated social, political, economic and
environmental challenges, fragmentary knowledge, or rather the simple
accumulation of basic research is inadequate (Kim). International affairs
professionals operating in government, academia and the private sector are
progressively more aware that access to, and the blending of, interdisciplinary
policy-related knowledge is critical to effective problem solving and
decision-making. But how can one do so effectively?
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1935</identifier>
 <datestamp>2012-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1935</id><created>2012-01-09</created><authors><author><keyname>Balasubramanian</keyname><forenames>Anantharaman</forenames></author><author><keyname>Ly</keyname><forenames>Hung D.</forenames></author><author><keyname>Li</keyname><forenames>Shuo</forenames></author><author><keyname>Liu</keyname><forenames>Tie</forenames></author><author><keyname>Miller</keyname><forenames>Scott L.</forenames></author></authors><title>Secure Symmetrical Multilevel Diversity Coding</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE Transactions on Information Theory in May 2011.
  Minor revision made to the current version in January 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Symmetrical Multilevel Diversity Coding (SMDC) is a network compression
problem introduced by Roche (1992) and Yeung (1995). In this setting, a simple
separate coding strategy known as superposition coding was shown to be optimal
in terms of achieving the minimum sum rate (Roche, Yeung, and Hau, 1997) and
the entire admissible rate region (Yeung and Zhang, 1999) of the problem. This
paper considers a natural generalization of SMDC to the secure communication
setting with an additional eavesdropper. It is required that all sources need
to be kept perfectly secret from the eavesdropper as long as the number of
encoder outputs available at the eavesdropper is no more than a given
threshold. First, the problem of encoding individual sources is studied. A
precise characterization of the entire admissible rate region is established
via a connection to the problem of secure coding over a three-layer wiretap
network and utilizing some basic polyhedral structure of the admissible rate
region. Building on this result, it is then shown that superposition coding
remains optimal in terms of achieving the minimum sum rate for the general
secure SMDC problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1941</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1941</id><created>2012-01-09</created><authors><author><keyname>Tian</keyname><forenames>Ye</forenames></author><author><keyname>Yener</keyname><forenames>Aylin</forenames></author></authors><title>Relaying for Multiuser Networks in the Absence of Codebook Information</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work considers relay assisted transmission for multiuser networks when
the relay has no access to the codebooks used by the transmitters. The relay is
called oblivious for this reason. Of particular interest is the generalized
compress-and-forward (GCF) strategy, where the destinations jointly decode the
compression indices and the transmitted messages, and their optimality in this
setting. The relay-to-destination links are assumed to be out-of-band with
finite capacity. Two models are investigated: the multiple access relay channel
(MARC) and the interference relay channel (IFRC). For the MARC with an
oblivious relay, a new outerbound is derived and it is shown to be tight by
means of achievability of the capacity region using GCF scheme. For the IFRC
with an oblivious relay, a new strong interference condition is established,
under which the capacity region is found by deriving a new outerbound and
showing that it is achievable using GCF scheme. The result is further extended
to establish the capacity region of M-user MARC with an oblivious relay, and
multicast networks containing M sources and K destinations with an oblivious
relay.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1954</identifier>
 <datestamp>2012-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1954</id><created>2012-01-09</created><updated>2012-01-10</updated><authors><author><keyname>Chen</keyname><forenames>Shaoshi</forenames></author><author><keyname>Kauers</keyname><forenames>Manuel</forenames></author><author><keyname>Singer</keyname><forenames>Michael F.</forenames></author></authors><title>Telescopers for Rational and Algebraic Functions via Residues</title><categories>cs.SC math.AG math.CO</categories><msc-class>33F10, 68W30</msc-class><acm-class>I.1.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the problem of constructing telescopers for functions of m
variables is equivalent to the problem of constructing telescopers for
algebraic functions of m -1 variables and present a new algorithm to construct
telescopers for algebraic functions of two variables. These considerations are
based on analyzing the residues of the input. According to experiments, the
resulting algorithm for rational functions of three variables is faster than
known algorithms, at least in some examples of combinatorial interest. The
algorithm for algebraic functions implies a new bound on the order of the
telescopers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1964</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1964</id><created>2012-01-09</created><authors><author><keyname>Garhwal</keyname><forenames>Anita</forenames></author><author><keyname>Bhattacharya</keyname><forenames>Partha Pratim</forenames></author></authors><title>A Survey on Dynamic Spectrum Access Techniques for Cognitive Radio</title><categories>cs.NI cs.GT</categories><comments>arXiv admin note: text overlap with
  http://www.ijetch.org/papers/206-Z058.pdf by other authors</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Cognitive radio (CR) is a new paradigm that utilizes the available spectrum
band. The key characteristic of CR system is to sense the electromagnetic
environment to adapt their operation and dynamically vary its radio operating
parameters. The technique of dynamically accessing the unused spectrum band is
known as Dynamic Spectrum Access (DSA). The dynamic spectrum access technology
helps to minimize unused spectrum bands. In this paper, main functions of
Cognitive Radio (CR) i.e. spectrum sensing, spectrum management, spectrum
mobility and spectrum sharing are discussed. Then DSA models are discussed
along with different methods of DSA such as Command and Control, Exclusive-Use,
Shared Use of Primary Licensed User and Commons method. Game-theoretic approach
using Bertrand game model, Markovian Queuing Model for spectrum allocation in
centralized architecture and Fuzzy logic based method are also discussed and
result are shown.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1966</identifier>
 <datestamp>2012-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1966</id><created>2012-01-10</created><authors><author><keyname>Kumar</keyname><forenames>Manoj</forenames></author><author><keyname>Arya</keyname><forenames>Sandeep K.</forenames></author><author><keyname>Pandey</keyname><forenames>Sujata</forenames></author></authors><title>Single bit full adder design using 8 transistors with novel 3
  transistors XNOR gate</title><categories>cs.OH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In present work a new XNOR gate using three transistors has been presented,
which shows power dissipation of 550.7272$\mu$W in 0.35$\mu$m technology with
supply voltage of 3.3V. Minimum level for high output of 2.05V and maximum
level for low output of 0.084V have been obtained. A single bit full adder
using eight transistors has been designed using proposed XNOR cell, which shows
power dissipation of 581.542$\mu$W. Minimum level for high output of 1.97V and
maximum level for low output of 0.24V is obtained for sum output signal. For
carry signal maximum level for low output of 0.32V and minimum level for high
output of 3.2V have been achieved. Simulations have been performed by using
SPICE based on TSMC 0.35$\mu$m CMOS technology. Power consumption of proposed
XNOR gate and full adder has been compared with earlier reported circuits and
proposed circuit's shows better performance in terms of power consumption and
transistor count.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1967</identifier>
 <datestamp>2012-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1967</id><created>2012-01-10</created><authors><author><keyname>Ahmad</keyname><forenames>Faudziah</forenames></author><author><keyname>Baharom</keyname><forenames>Fauziah</forenames></author><author><keyname>Husni</keyname><forenames>Moath</forenames></author></authors><title>Investigating the Awareness of Applying the Important Web Application
  Development and Measurement Practices in Small Software Firms</title><categories>cs.SE</categories><comments>11 pages, 2 figures and 7 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper aims to discuss the pilot study and analysis of the current
development and measurement practices in Jordanian small software firms. It is
conducted because most developers build web applications without using any
specific development method and don't know how to integrate the suitable
measurements inside the process to improve and reduce defect, time and rework
of the development life cycle. Furthermore the objectives of this pilot study
are firstly; determine the real characteristics of small software firms in
Jordan. Secondly, investigate the current development and measurement
practices. Thirdly, examine the need of new development methodology for
building web application in small software firms. Consequently, Pilot survey
was conducted in Jordanian small software firms. Descriptive statistics
analysis was used to rank the development and measurements methods according to
their importance. This paper presents the data, analysis and finding based on
pilot survey. These actual findings of this survey will contribute to build new
methodology for developing web applications in small software firms taking to
account how to integrate the suitable measurement program to the whole
development process and also will provide useful information to those who are
doing research in the same area.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1968</identifier>
 <datestamp>2012-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1968</id><created>2012-01-10</created><authors><author><keyname>Kabetta</keyname><forenames>Herman</forenames></author><author><keyname>Dwiandiyanta</keyname><forenames>B. Yudi</forenames></author><author><keyname>Suyoto</keyname></author></authors><title>Information Hiding in CSS : A Secure Scheme Text-Steganography using
  Public Key Cryptosystem</title><categories>cs.CR</categories><comments>Text Steganography, Cryptography, Cascading Style Sheet (CSS), RSA
  Algorithm, public key algorithm</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In many recent years, the programming world has been introduced about a new
programming language for designing websites, it is CSS that can be be used
together with HTML to develop a web interface. And now, these two programming
languages as if inseparably from each other. As a client-side scripting, CSS is
visible by all users as the original script, but it can not be granted changed.
Website is a tool of information disseminator throughout the world, this is
certainly can be used to a secret communication by using CSS as a message
hider. This paper proposed a new scheme using web tools like CSS for hiding
informations. This is a secret communication mechanism using text steganography
techniques that is embedded messages on CSS files and is further encrypted
using RSA as a public key cryptographic algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1970</identifier>
 <datestamp>2012-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1970</id><created>2012-01-10</created><authors><author><keyname>Gupta</keyname><forenames>Neha</forenames></author><author><keyname>Singh</keyname><forenames>Sapna</forenames></author><author><keyname>Suthar</keyname><forenames>Meenakshi</forenames></author><author><keyname>Soni</keyname><forenames>Priyanka</forenames></author></authors><title>Low Power Low Voltage Bulk Driven Balanced OTA</title><categories>cs.OH</categories><comments>International Journal of VLSI design &amp; Communication Systems (VLSICS)
  Vol.2, No.4, December 2011, 131-141</comments><doi>10.5121/vlsic.2011.2411</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The last few decades, a great deal of attention has been paid to low-voltage
(LV) low-power (LP) integrated circuits design since the power consumption has
become a critical issue. Among many techniques used for the design of LV LP
analog circuits, the Bulk-driven principle offers a promising route towards
this design for many aspects mainly the simplicity and using the conventional
MOS technology to implement these designs. This paper is devoted to the
Bulk-driven (BD) principle and utilizing this principle to design LV LP
building block of Operational Transconductance Amplifier (OTA) in standard CMOS
processes and supply voltage 0.9V. The simulation results have been carried out
by the Spice simulator using the 130nm CMOS technology from TSMC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1972</identifier>
 <datestamp>2012-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1972</id><created>2012-01-10</created><authors><author><keyname>Khlifi</keyname><forenames>Abdelhakim</forenames></author><author><keyname>Bouallegue</keyname><forenames>Ridha</forenames></author></authors><title>Hybrid LS-LMMSE Channel Estimation Technique for LTE Downlink Systems</title><categories>cs.NI</categories><comments>13 pages, 11 figures</comments><journal-ref>International Journal of Next Generation Networks (IJNGN) Vol.3,
  No.4, December 2011, 1-13</journal-ref><doi>10.5121/ijngn.2011.3401</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose to improve the performance of the channel
estimation for LTE Downlink systems under the effect of the channel length. As
LTE Downlink system is a MIMO-OFDMA based system, a cyclic prefix (CP) is
inserted at the beginning of each transmitted OFDM symbol in order to mitigate
both inter-carrier interference (ICI) and inter-symbol interference (ISI). The
inserted CP is usually equal to or longer than the channel length. However, the
cyclic prefix can be shorter because of some unforeseen channel behaviour.
Previous works have shown that in the case where the cyclic prefix is equal to
or longer than the channel length, LMMSE performs better than LSE but at the
cost of computational complexity .In the other case, LMMSE performs also better
than LS only for low SNR values. However, LS shows better performance for LTE
Downlink systems for high SNR values. Therefore, we propose a hybrid LS-LMMSE
channel estimation technique robust to the channel length effect. MATLAB
Monte-Carlo simulations are used to evaluate the performance of the proposed
estimator in terms of Mean Square Error (MSE) and Bit Error Rate (BER) for 2x2
LTE Downlink systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1982</identifier>
 <datestamp>2012-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1982</id><created>2012-01-10</created><authors><author><keyname>Chen</keyname><forenames>Shaoshi</forenames></author><author><keyname>Kauers</keyname><forenames>Manuel</forenames></author></authors><title>Order-Degree Curves for Hypergeometric Creative Telescoping</title><categories>cs.SC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Creative telescoping applied to a bivariate proper hypergeometric term
produces linear recurrence operators with polynomial coefficients, called
telescopers. We provide bounds for the degrees of the polynomials appearing in
these operators. Our bounds are expressed as curves in the (r,d)-plane which
assign to every order r a bound on the degree d of the telescopers. These
curves are hyperbolas, which reflect the phenomenon that higher order
telescopers tend to have lower degree, and vice versa.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1990</identifier>
 <datestamp>2012-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1990</id><created>2012-01-10</created><authors><author><keyname>Dai</keyname><forenames>Xiongping</forenames></author></authors><title>Criteria of stabilizability for switching-control systems with solvable
  linear approximations</title><categories>cs.SY math.CA math.OC</categories><comments>32 pages; accepted by SIAM J Control &amp; Optim</comments><msc-class>93C15, 34H05, 37N35, 93D20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the stability and stabilizability of a continuous-time switched
control system that consists of the time-invariant $n$-dimensional subsystems
\dot{x}=A_ix+B_i(x)u\quad (x\in\mathbb{R}^n, t\in\mathbb{R}_+ \textrm{and}
u\in\mathbb{R}^{m_i}),\qquad \textrm{where} i\in{1,...,N} and a switching
signal $\sigma(\bcdot)\colon\mathbb{R}_+\rightarrow{1,...,N}$ which
orchestrates switching between these subsystems above, where
$A_i\in\mathbb{R}^{n\times n}, n\ge1, N\ge2, m_i\ge1$, and where
$B_i(\bcdot)\colon\mathbb{R}^n\rightarrow\mathbb{R}^{n\times m_i}$ satisfies
the condition $\|B_i(x)\|\le\bbbeta\|x\|\;\forall x\in\mathbb{R}^n$. We show
that, if ${A_1,...,A_N}$ generates a solvable Lie algebra over the field
$\mathbbm{C}$ of complex numbers and there exists an element $\bbA$ in the
convex hull $\mathrm{co}{A_1,...,A_N}$ in $\mathbb{R}^{n\times n}$ such that
the affine system $\dot{x}=\bbA x$ is exponentially stable, then there is a
constant $\bbdelta&gt;0$ for which one can design &quot;sufficiently many&quot;
piecewise-constant switching signals $\sigma(t)$ so that the switching-control
systems \dot{x}(t)=A_{\sigma(t)}x(t)+B_{\sigma(t)}(x(t))u(t),\quad
x(0)\in\mathbb{R}^n\textrm{and} t\in\mathbb{R}_+ are globally exponentially
stable, for any measurable external inputs $u(t)\in\mathbb{R}^{m_{\sigma(t)}}$
with $|u(t)|\le\bbdelta$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.1997</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.1997</id><created>2012-01-10</created><updated>2013-04-29</updated><authors><author><keyname>Srinath</keyname><forenames>K. Pavan</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>An Enhanced DMT-optimality Criterion for STBC-schemes for Asymmetric
  MIMO Systems</title><categories>cs.IT math.IT</categories><comments>To appear in the IEEE Transactions on Information Theory. The present
  version is a significantly revised version of arXiv:1201.1997v2. Manuscript
  length is 14 Pages, contains 1 Table and 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For any $n_t$ transmit, $n_r$ receive antenna ($n_t\times n_r$) MIMO system
in a quasi-static Rayleigh fading environment, it was shown by Elia et al. that
linear space-time block code-schemes (LSTBC-schemes) which have the
non-vanishing determinant (NVD) property are diversity-multiplexing gain
tradeoff (DMT)-optimal for arbitrary values of $n_r$ if they have a code-rate
of $n_t$ complex dimensions per channel use. However, for asymmetric MIMO
systems (where $n_r &lt; n_t$), with the exception of a few LSTBC-schemes, it is
unknown whether general LSTBC-schemes with NVD and a code-rate of $n_r$ complex
dimensions per channel use are DMT-optimal. In this paper, an enhanced
sufficient criterion for any STBC-scheme to be DMT-optimal is obtained, and
using this criterion, it is established that any LSTBC-scheme with NVD and a
code-rate of $\min\{n_t,n_r\}$ complex dimensions per channel use is
DMT-optimal. This result settles the DMT-optimality of several well-known,
low-ML-decoding-complexity LSTBC-schemes for certain asymmetric MIMO systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2000</identifier>
 <datestamp>2012-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2000</id><created>2012-01-10</created><authors><author><keyname>Hlineny</keyname><forenames>Petr</forenames></author><author><keyname>Moris</keyname><forenames>Ondrej</forenames></author></authors><title>Dynamic Scope-Based Dijkstra's Algorithm</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We briefly report on the current state of a new dynamic algorithm for the
route planning problem based on a concept of scope (the static variant
presented at ESA'11, HM2011A). We first motivate dynamization of the concept of
scope admissibility, and then we briefly describe a modification of the
scope-aware query algorithm of HM2011A to dynamic road networks. Finally, we
outline our future work on this concept.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2004</identifier>
 <datestamp>2012-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2004</id><created>2012-01-10</created><authors><author><keyname>Hossain</keyname><forenames>Md. Amjad</forenames></author><author><keyname>Shill</keyname><forenames>Pintu Chandra</forenames></author><author><keyname>Sarker</keyname><forenames>Bishnu</forenames></author><author><keyname>Murase</keyname><forenames>Kazuyuki</forenames></author></authors><title>Optimal Fuzzy Model Construction with Statistical Information using
  Genetic Algorithm</title><categories>cs.AI</categories><doi>10.5121/ijcsit.2011.3619</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fuzzy rule based models have a capability to approximate any continuous
function to any degree of accuracy on a compact domain. The majority of FLC
design process relies on heuristic knowledge of experience operators. In order
to make the design process automatic we present a genetic approach to learn
fuzzy rules as well as membership function parameters. Moreover, several
statistical information criteria such as the Akaike information criterion
(AIC), the Bhansali-Downham information criterion (BDIC), and the
Schwarz-Rissanen information criterion (SRIC) are used to construct optimal
fuzzy models by reducing fuzzy rules. A genetic scheme is used to design
Takagi-Sugeno-Kang (TSK) model for identification of the antecedent rule
parameters and the identification of the consequent parameters. Computer
simulations are presented confirming the performance of the constructed fuzzy
logic controller.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2007</identifier>
 <datestamp>2012-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2007</id><created>2012-01-10</created><authors><author><keyname>Kumarasamy</keyname><forenames>Saravanan</forenames></author><author><keyname>Asokan</keyname><forenames>R.</forenames></author></authors><title>Distributed Denial of Service (DDoS) Attacks Detection Mechanism</title><categories>cs.CR</categories><report-no>IJCSEIT-12-11</report-no><doi>10.5121/ijcseit.2011.1504</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pushback is a mechanism for defending against Distributed Denial-of-Service
(DDoS) attacks. DDoS attacks are treated as a congestion-control problem, but
because most such congestion is caused by malicious hosts not obeying
traditional end-to-end congestion control, the problem must be handled by the
routers. Functionality is added to each router to detect and preferentially
drop packets that probably belong to an attack. Upstream routers are also
notified to drop such packets in order that the router's resources be used to
route legitimate traffic hence term pushback. Client puzzles have been
advocated as a promising countermeasure to DoS attacks in the recent years. In
order to identify the attackers, the victim server issues a puzzle to the
client that sent the traffic. When the client is able to solve the puzzle, it
is assumed to be authentic and the traffic from it is allowed into the server.
If the victim suspects that the puzzles are solved by most of the clients, it
increases the complexity of the puzzles. This puzzle solving technique allows
the traversal of the attack traffic throughout the intermediate routers before
reaching the destination. In order to attain the advantages of both pushback
and puzzle solving techniques, a hybrid scheme called Router based Pushback
technique, which involves both the techniques to solve the problem of DDoS
attacks is proposed. In this proposal, the puzzle solving mechanism is pushed
back to the core routers rather than having at the victim. The router based
client puzzle mechanism checks the host system whether it is legitimate or not
by providing a puzzle to be solved by the suspected host.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2010</identifier>
 <datestamp>2012-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2010</id><created>2012-01-10</created><authors><author><keyname>Hasan</keyname><forenames>K. M. Azharul</forenames></author><author><keyname>Al-Mahmud</keyname></author><author><keyname>Mondal</keyname><forenames>Amit</forenames></author><author><keyname>Saha</keyname><forenames>Amit</forenames></author></authors><title>Recognizing Bangla Grammar using Predictive Parser</title><categories>cs.CL</categories><comments>13 pages, 13 figures</comments><doi>10.5121/ijcsit.2011.3605</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a Context Free Grammar (CFG) for Bangla language and hence we
propose a Bangla parser based on the grammar. Our approach is very much general
to apply in Bangla Sentences and the method is well accepted for parsing a
language of a grammar. The proposed parser is a predictive parser and we
construct the parse table for recognizing Bangla grammar. Using the parse table
we recognize syntactical mistakes of Bangla sentences when there is no entry
for a terminal in the parse table. If a natural language can be successfully
parsed then grammar checking from this language becomes possible. The proposed
scheme is based on Top down parsing method and we have avoided the left
recursion of the CFG using the idea of left factoring.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2025</identifier>
 <datestamp>2012-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2025</id><created>2012-01-10</created><authors><author><keyname>Baghbidi</keyname><forenames>Mohsen Zare</forenames></author><author><keyname>Jamshidi</keyname><forenames>Kamal</forenames></author><author><keyname>Nilchi</keyname><forenames>Ahmad Reza Naghsh</forenames></author><author><keyname>Homayouni</keyname><forenames>Saeid</forenames></author></authors><title>Improvement of Anomoly Detection Algorithms in Hyperspectral Images
  using Discrete Wavelet Transform</title><categories>cs.OH</categories><comments>13 pages, 9 figures, printed in Signal &amp; Image Processing : An
  International Journal (SIPIJ)</comments><msc-class>68U10 (Primary)</msc-class><journal-ref>Signal &amp; Image Processing : An International Journal (SIPIJ), Vol.
  2, No. 4, 2011,13-25</journal-ref><doi>10.5121/sipij.2011.2402</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Recently anomaly detection (AD) has become an important application for
target detection in hyperspectral remotely sensed images. In many applications,
in addition to high accuracy of detection we need a fast and reliable algorithm
as well. This paper presents a novel method to improve the performance of
current AD algorithms. The proposed method first calculates Discrete Wavelet
Transform (DWT) of every pixel vector of image using Daubechies4 wavelet. Then,
AD algorithm performs on four bands of &quot;Wavelet transform&quot; matrix which are the
approximation of main image. In this research some benchmark AD algorithms
including Local RX, DWRX and DWEST have been implemented on Airborne
Visible/Infrared Imaging Spectrometer (AVIRIS) hyperspectral datasets.
Experimental results demonstrate significant improvement of runtime in proposed
method. In addition, this method improves the accuracy of AD algorithms because
of DWT's power in extracting approximation coefficients of signal, which
contain the main behaviour of signal, and abandon the redundant information in
hyperspectral image data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2031</identifier>
 <datestamp>2012-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2031</id><created>2012-01-10</created><authors><author><keyname>Reddy</keyname><forenames>Ch Ram Mohan</forenames></author><author><keyname>Geetha</keyname><forenames>D. Evangelin</forenames></author><author><keyname>Srinivasa</keyname><forenames>K. G.</forenames></author><author><keyname>Kumar</keyname><forenames>T. V. Suresh</forenames></author><author><keyname>Kanth</keyname><forenames>K. Rajani</forenames></author></authors><title>General Methodology for developing UML models from UI</title><categories>cs.SE</categories><comments>16 pages,14 figures</comments><doi>10.5121/ijwsc.2011.2401</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent past every discipline and every industry have their own methods of
developing products. It may be software development, mechanics, construction,
psychology and so on. These demarcations work fine as long as the requirements
are within one discipline. However, if the project extends over several
disciplines, interfaces have to be created and coordinated between the methods
of these disciplines. Performance is an important quality aspect of Web
Services because of their distributed nature. Predicting the performance of web
services during early stages of software development is significant. In
Industry, Prototype of these applications is developed during analysis phase of
Software Development Life Cycle (SDLC). However, Performance models are
generated from UML models. Methodologies for predicting the performance from
UML models is available. Hence, In this paper, a methodology for developing Use
Case model and Activity model from User Interface is presented. The methodology
is illustrated with a case study on Amazon.com.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2034</identifier>
 <datestamp>2012-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2034</id><created>2012-01-10</created><authors><author><keyname>Reddy</keyname><forenames>Ch Ram Mohan</forenames></author><author><keyname>Geetha</keyname><forenames>D. Evangelin</forenames></author><author><keyname>Srinivasa</keyname><forenames>K. G.</forenames></author><author><keyname>Kumar</keyname><forenames>T. V. Suresh</forenames></author><author><keyname>Kanth</keyname><forenames>K. Rajani</forenames></author></authors><title>Early Performance Prediction of Web Services</title><categories>cs.PF</categories><comments>11 pages, 10 figures</comments><doi>10.5121/ijwsc.2011.2303</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Web Service is an interface which implements business logic. Performance is
an important quality aspect of Web services because of their distributed
nature. Predicting the performance of web services during early stages of
software development is significant. In this paper we model web service using
Unified Modeling Language, Use Case Diagram, Sequence Diagram, Deployment
Diagram. We obtain the Performance metrics by simulating the web services model
using a simulation tool Simulation of Multi-Tier Queuing Architecture. We have
identified the bottle neck resources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2035</identifier>
 <datestamp>2013-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2035</id><created>2012-01-10</created><updated>2012-07-19</updated><authors><author><keyname>Ouyang</keyname><forenames>Ruiyue</forenames></author><author><keyname>Andrieu</keyname><forenames>Vincent</forenames></author><author><keyname>Jayawardhana</keyname><forenames>Bayu</forenames></author></authors><title>On the Characterization of the Duhem Hysteresis Operator with Clockwise
  Input-Output Dynamics</title><categories>math.OC cs.SY</categories><comments>Pre-print, revised manuscript, 19 pages</comments><msc-class>34C55, 47N70, 93C10, 93C23</msc-class><journal-ref>Systems and Control Letters, 2013</journal-ref><doi>10.1016/j.sysconle.2012.11.022</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In this paper we investigate the dissipativity property of a certain class of
Duhem hysteresis operator, which has clockwise (CW) input-output (I/O)
behavior. In particular, we provide sufficient conditions on the Duhem operator
such that it is CW and propose an explicit construction of the corresponding
storage function satisfying dissipation inequality of CW systems. The result is
used to analyze the stability of a second order system with hysteretic friction
which is described by a Dahl model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2036</identifier>
 <datestamp>2012-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2036</id><created>2012-01-10</created><updated>2012-01-13</updated><authors><author><keyname>Granell</keyname><forenames>Clara</forenames></author><author><keyname>Gomez</keyname><forenames>Sergio</forenames></author><author><keyname>Arenas</keyname><forenames>Alex</forenames></author></authors><title>Hierarchical multiresolution method to overcome the resolution limit in
  complex networks</title><categories>physics.data-an cs.SI physics.comp-ph physics.soc-ph</categories><journal-ref>International Journal of Bifurcation and Chaos 22 (2012) 1250171</journal-ref><doi>10.1142/S0218127412501714</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The analysis of the modular structure of networks is a major challenge in
complex networks theory. The validity of the modular structure obtained is
essential to confront the problem of the topology-functionality relationship.
Recently, several authors have worked on the limit of resolution that different
community detection algorithms have, making impossible the detection of natural
modules when very different topological scales coexist in the network. Existing
multiresolution methods are not the panacea for solving the problem in extreme
situations, and also fail. Here, we present a new hierarchical multiresolution
scheme that works even when the network decomposition is very close to the
resolution limit. The idea is to split the multiresolution method for optimal
subgraphs of the network, focusing the analysis on each part independently. We
also propose a new algorithm to speed up the computational cost of screening
the mesoscale looking for the resolution parameter that best splits every
subgraph. The hierarchical algorithm is able to solve a difficult benchmark
proposed in [Lancichinetti &amp; Fortunato, 2011], encouraging the further analysis
of hierarchical methods based on the modularity quality function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2043</identifier>
 <datestamp>2012-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2043</id><created>2012-01-10</created><authors><author><keyname>Ghasemi</keyname><forenames>Mehdi</forenames></author><author><keyname>Moaiyeri</keyname><forenames>Mohammad Hossein</forenames></author><author><keyname>Navi</keyname><forenames>Keivan</forenames></author></authors><title>A New Full Adder Cell for Molecular Electronics</title><categories>cs.ET</categories><comments>13 pages, 14 figures</comments><journal-ref>International Journal of VLSI design &amp; Communication
  System(VLSICS) Vol.2, No.4, pp.1-13, Dec. 2011</journal-ref><doi>10.5121/vlsic.2011.2401</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to high power consumption and difficulties with minimizing the CMOS
transistor size, molecular electronics has been introduced as an emerging
technology. Further, there have been noticeable advances in fabrication of
molecular wires and switches and also molecular diodes can be used for
designing different logic circuits. Considering this novel technology, we use
molecules as the active components of the circuit, for transporting electric
charge. In this paper, a full adder cell based on molecular electronics is
presented. This full adder is consisted of resonant tunneling diodes and
transistors which are implemented via molecular electronics. The area occupied
by this kind of full adder would be much times smaller than the conventional
designs and it can be used as the building block of more complex molecular
arithmetic circuits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2046</identifier>
 <datestamp>2012-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2046</id><created>2012-01-10</created><authors><author><keyname>Hennemann</keyname><forenames>Stefan</forenames></author></authors><title>Evaluating the performance of geographical locations in scientific
  networks with an aggregation - randomization - re-sampling approach (ARR)</title><categories>physics.soc-ph cs.SI</categories><comments>13 pages, 4 figures, 2 tables</comments><msc-class>05C82, 90B15, 62P25, 91D30</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Knowledge creation and dissemination in science and technology systems is
perceived as a prerequisite for socio-economic development. The efficiency of
creating new knowledge is considered to have a geographical component, i.e.
some regions are more capable in scientific knowledge production than others.
This article shows a method to use a network representation of scientific
interaction to assess the relative efficiency of regions with diverse
boundaries in channeling knowledge through a science system. In a first step, a
weighted aggregate of the betweenness centrality is produced from empirical
data (aggregation). The subsequent randomization of this empirical network
produces the necessary Null-model for significance testing and normalization
(randomization). This step is repeated to yield higher confidence about the
results (re-sampling). The results are robust estimates for the relative
regional efficiency to broker knowledge, which is discussed along with
cross-sectional and longitudinal empirical examples. The network representation
acts as a straight-forward metaphor of conceptual ideas from economic geography
and neighboring disciplines. However, the procedure is not limited to
centrality measures, nor is it limited to spatial aggregates. Therefore, it
offers a wide range of application for scientometrics and beyond.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2050</identifier>
 <datestamp>2012-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2050</id><created>2012-01-10</created><authors><author><keyname>Gebreyohannes</keyname><forenames>Tina</forenames></author><author><keyname>Kim</keyname><forenames>Dong-Yoon</forenames></author></authors><title>Adaptive Noise Reduction Scheme for Salt and Pepper</title><categories>cs.CV</categories><comments>9 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a new adaptive noise reduction scheme for images corrupted by
impulse noise is presented. The proposed scheme efficiently identifies and
reduces salt and pepper noise. MAG (Mean Absolute Gradient) is used to identify
pixels which are most likely corrupted by salt and pepper noise that are
candidates for further median based noise reduction processing. Directional
filtering is then applied after noise reduction to achieve a good tradeoff
between detail preservation and noise removal. The proposed scheme can remove
salt and pepper noise with noise density as high as 90% and produce better
result in terms of qualitative and quantitative measures of images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2056</identifier>
 <datestamp>2012-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2056</id><created>2012-01-10</created><authors><author><keyname>O'Neill</keyname><forenames>Alexander</forenames></author><author><keyname>Hutter</keyname><forenames>Marcus</forenames></author><author><keyname>Shao</keyname><forenames>Wen</forenames></author><author><keyname>Sunehag</keyname><forenames>Peter</forenames></author></authors><title>Adaptive Context Tree Weighting</title><categories>cs.IT cs.LG math.IT</categories><comments>11 LaTeX pages, 7 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe an adaptive context tree weighting (ACTW) algorithm, as an
extension to the standard context tree weighting (CTW) algorithm. Unlike the
standard CTW algorithm, which weights all observations equally regardless of
the depth, ACTW gives increasing weight to more recent observations, aiming to
improve performance in cases where the input sequence is from a non-stationary
distribution. Data compression results show ACTW variants improving over CTW on
merged files from standard compression benchmark tests while never being
significantly worse on any individual file.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2073</identifier>
 <datestamp>2012-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2073</id><created>2012-01-10</created><authors><author><keyname>Aziz</keyname><forenames>Mehwish</forenames></author><author><keyname>Rafi</keyname><forenames>Muhammad</forenames></author></authors><title>Pbm: A new dataset for blog mining</title><categories>cs.AI cs.CL cs.IR</categories><comments>6; Internet and Web Engineering from: International Conference on
  Computer Engineering and Technology, 3rd (ICCET 2011)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Text mining is becoming vital as Web 2.0 offers collaborative content
creation and sharing. Now Researchers have growing interest in text mining
methods for discovering knowledge. Text mining researchers come from variety of
areas like: Natural Language Processing, Computational Linguistic, Machine
Learning, and Statistics. A typical text mining application involves
preprocessing of text, stemming and lemmatization, tagging and annotation,
deriving knowledge patterns, evaluating and interpreting the results. There are
numerous approaches for performing text mining tasks, like: clustering,
categorization, sentimental analysis, and summarization. There is a growing
need to standardize the evaluation of these tasks. One major component of
establishing standardization is to provide standard datasets for these tasks.
Although there are various standard datasets available for traditional text
mining tasks, but there are very few and expensive datasets for blog-mining
task. Blogs, a new genre in web 2.0 is a digital diary of web user, which has
chronological entries and contains a lot of useful knowledge, thus offers a lot
of challenges and opportunities for text mining. In this paper, we report a new
indigenous dataset for Pakistani Political Blogosphere. The paper describes the
process of data collection, organization, and standardization. We have used
this dataset for carrying out various text mining tasks for blogosphere, like:
blog-search, political sentiments analysis and tracking, identification of
influential blogger, and clustering of the blog-posts. We wish to offer this
dataset free for others who aspire to pursue further in this domain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2074</identifier>
 <datestamp>2012-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2074</id><created>2012-01-10</created><updated>2012-01-24</updated><authors><author><keyname>Wrobel</keyname><forenames>Jan</forenames></author></authors><title>Reflection Scan: an Off-Path Attack on TCP</title><categories>cs.CR cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper demonstrates how traffic load of a shared packet queue can be
exploited as a side channel through which protected information leaks to an
off-path attacker. The attacker sends to a victim a sequence of identical
spoofed segments. The victim responds to each segment in the sequence (the
sequence is reflected by the victim) if the segments satisfy a certain
condition tested by the attacker. The responses do not reach the attacker
directly, but induce extra load on a routing queue shared between the victim
and the attacker. Increased processing time of packets traversing the queue
reveal that the tested condition was true. The paper concentrates on the TCP,
but the approach is generic and can be effective against other protocols that
allow to construct requests which are conditionally answered by the victim. A
proof of concept was created to assess applicability of the method in real-life
scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2083</identifier>
 <datestamp>2012-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2083</id><created>2012-01-06</created><authors><author><keyname>Xu</keyname><forenames>J.</forenames><affiliation>LGeco</affiliation></author><author><keyname>Houssin</keyname><forenames>R&#xe9;my</forenames><affiliation>LGeco</affiliation></author><author><keyname>Caillaud</keyname><forenames>Emmanuel</forenames><affiliation>LGeco</affiliation></author><author><keyname>Gardoni</keyname><forenames>Micka&#xeb;l</forenames><affiliation>LGeco</affiliation></author></authors><title>Fostering continuous innovation in design with an integrated knowledge
  management approach</title><categories>cs.OH</categories><proxy>ccsd</proxy><journal-ref>Computers in Industry Journal 62, 4 (2011) 423-436</journal-ref><doi>10.1016/j.compind.2010.12.005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the global competition, companies are propelled by an immense pressure to
innovate. The trend to produce more new knowledge-intensive products or
services and the rapid progress of information technologies arouse huge
interest on knowledge management for innovation. However the strategy of
knowledge management is not widely adopted for innovation in industries due to
a lack of an effective approach of their integration. This study aims to help
the designers to innovate more efficiently based on an integrated approach of
knowledge management. Based on this integrated approach, a prototype of
distributed knowledge management system for innovation is developed. An
industrial application is presented and its initial results indicate the
applicability of the approach and the prototype in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2084</identifier>
 <datestamp>2012-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2084</id><created>2012-01-10</created><authors><author><keyname>Aziz</keyname><forenames>Mehwish</forenames></author><author><keyname>Rafi</keyname><forenames>Muhammad</forenames></author></authors><title>Sentence based semantic similarity measure for blog-posts</title><categories>cs.AI cs.IR</categories><comments>6th International Conference on Digital Content, Multimedia
  Technology and its Applications (IDC), 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Blogs-Online digital diary like application on web 2.0 has opened new and
easy way to voice opinion, thoughts, and like-dislike of every Internet user to
the World. Blogosphere has no doubt the largest user-generated content
repository full of knowledge. The potential of this knowledge is still to be
explored. Knowledge discovery from this new genre is quite difficult and
challenging as it is totally different from other popular genre of
web-applications like World Wide Web (WWW). Blog-posts unlike web documents are
small in size, thus lack in context and contain relaxed grammatical structures.
Hence, standard text similarity measure fails to provide good results. In this
paper, specialized requirements for comparing a pair of blog-posts is
thoroughly investigated. Based on this we proposed a novel algorithm for
sentence oriented semantic similarity measure of a pair of blog-posts. We
applied this algorithm on a subset of political blogosphere of Pakistan, to
cluster the blogs on different issues of political realm and to identify the
influential bloggers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2097</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2097</id><created>2012-01-10</created><updated>2013-06-14</updated><authors><author><keyname>Viglietta</keyname><forenames>Giovanni</forenames></author></authors><title>Partial Searchlight Scheduling is Strongly PSPACE-Complete</title><categories>cs.CG</categories><comments>6 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of searching a polygonal region for an unpredictably moving
intruder by a set of stationary guards, each carrying an orientable laser, is
known as the Searchlight Scheduling Problem. Determining the computational
complexity of deciding if the polygon can be searched by a given set of guards
is a long-standing open problem.
  Here we propose a generalization called the Partial Searchlight Scheduling
Problem, in which only a given subregion of the environment has to be searched,
as opposed to the entire area. We prove that the corresponding decision problem
is strongly PSPACE-complete, both in general and restricted to orthogonal
polygons where the region to be searched is a rectangle.
  Our technique is to reduce from the &quot;edge-to-edge&quot; problem for
nondeterministic constraint logic machines, after showing that the
computational power of such machines does not change if we allow &quot;asynchronous&quot;
edge reversals (as opposed to &quot;sequential&quot;).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2100</identifier>
 <datestamp>2012-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2100</id><created>2012-01-10</created><authors><author><keyname>S.</keyname><forenames>Raja Mohamed</forenames></author><author><keyname>Raviraj</keyname><forenames>P.</forenames></author></authors><title>Biologically inspired design framework for Robot in Dynamic Environments
  using Framsticks</title><categories>cs.NE</categories><comments>presented in the conference DPPR2011 at MS University, Tirunelveli,
  India; International Journal on Bioinformatics &amp; Biosciences (IJBB) Vol.1,
  No.1, December 2011</comments><msc-class>00A72</msc-class><acm-class>B.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Robot design complexity is increasing day by day especially in automated
industries. In this paper we propose biologically inspired design framework for
robots in dynamic world on the basis of Co-Evolution, Virtual Ecology, Life
time learning which are derived from biological creatures. We have created a
virtual khepera robot in Framsticks and tested its operational credibility in
terms hardware and software components by applying the above suggested
techniques. Monitoring complex and non complex behaviors in different
environments and obtaining the parameters that influence software and hardware
design of the robot that influence anticipated and unanticipated failures,
control programs of robot generation are the major concerns of our techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2102</identifier>
 <datestamp>2012-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2102</id><created>2012-01-10</created><authors><author><keyname>Malik</keyname><forenames>Yasir</forenames></author><author><keyname>Khaliq</keyname><forenames>Kishwer Abdul</forenames></author><author><keyname>Abdulrazak</keyname><forenames>Bessam</forenames></author><author><keyname>Tariq</keyname><forenames>Usman</forenames></author></authors><title>Mobile node localization in cellular networks</title><categories>cs.NI</categories><comments>10 Pages, 7 figures; ISSN:0975-3834 (Online); 0975-4679 (Print)</comments><journal-ref>IJWMN Vol. 3, No. 6, December 2011 Pg-91-100</journal-ref><doi>10.5121/ijwmn.2011.3607</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Location information is the major component in location based applications.
This information is used in different safety and service oriented applications
to provide users with services according to their Geolocation. There are many
approaches to locate mobile nodes in indoor and outdoor environments. In this
paper, we are interested in outdoor localization particularly in cellular
networks of mobile nodes and presented a localization method based on cell and
user location information. Our localization method is based on hello message
delay (sending and receiving time) and coordinate information of Base
Transceiver Station (BTSs). To validate our method across cellular network, we
implemented and simulated our method in two scenarios i.e. maintaining database
of base stations in centralize and distributed system. Simulation results show
the effectiveness of our approach and its implementation applicability in
telecommunication systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2103</identifier>
 <datestamp>2012-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2103</id><created>2012-01-10</created><authors><author><keyname>Kumarasamy</keyname><forenames>Saravanan</forenames></author><author><keyname>Gowrishankar</keyname><forenames>A.</forenames></author></authors><title>An Active Defense Mechanism for TCP SYN flooding attacks</title><categories>cs.CR</categories><report-no>CCSM-11-07</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distributed denial-of-service attacks on public servers have recently become
a serious problem. To assure that network services will not be interrupted and
more effective defense mechanisms to protect against malicious traffic,
especially SYN floods. One problem in detecting SYN flood traffic is that
server nodes or firewalls cannot distinguish the SYN packets of normal TCP
connections from those of a SYN flood attack. Another problem is single-point
defenses (e.g. firewalls) lack the scalability needed to handle an increase in
the attack traffic. We have designed a new defense mechanism to detect the SYN
flood attacks. First, we introduce a mechanism for detecting SYN flood traffic
more accurately by taking into consideration the time variation of arrival
traffic. We investigate the statistics regarding the arrival rates of both
normal TCP SYN packets and SYN flood attack packets. We then describe a new
detection mechanism based on these statistics. Through the trace driven
approach defense nodes which receive the alert messages can identify legitimate
traffic and block malicious traffic by delegating SYN/ACK packets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2107</identifier>
 <datestamp>2012-03-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2107</id><created>2012-01-10</created><authors><author><keyname>Bhat</keyname><forenames>Naagesh S.</forenames></author></authors><title>Design and ASIC implementation of DUC/DDC for communication systems</title><categories>cs.AR</categories><journal-ref>International Journal of VLSI design &amp; Communication Systems
  (VLSICS) Vol.2, No.4, December 2011</journal-ref><doi>10.5121/vlsic.2011.2410</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Communication systems use the concept of transmitting information using the
electrical distribution network as a communication channel. To enable the
transmission data signal modulated on a carrier signal is superimposed on the
electrical wires. Typical power lines are designed to handle 50/60 Hz of AC
power signal; however they can carry the signals up to 500 KHz frequency. This
work aims to aid transmission/reception of an audio signal in the spectrum from
300 Hz to 4000 Hz using PLCC on a tunable carrier frequency in the spectrum
from 200 KHz to 500 KHz. For digital amplitude modulation the sampling rate of
the carrier and the audio signal has to be matched. Tunable carrier generation
can be achieved with Direct Digital Synthesizers at a desired sampling rate.
DSP Sample rate conversion techniques are very useful to make the sampling
circuits to work on their own sampling rates which are fine for the
data/modulated-carrier signal's bandwidth. This also simplifies the complexity
of the sampling circuits. Digital Up Conversion (DUC) and Digital Down
Conversion (DDC) are DSP sample rate conversion techniques which refer to
increasing and decreasing the sampling rate of a signal respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2116</identifier>
 <datestamp>2012-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2116</id><created>2012-01-10</created><authors><author><keyname>Costa</keyname><forenames>Edgar</forenames></author><author><keyname>Harvey</keyname><forenames>David</forenames></author></authors><title>Faster deterministic integer factorization</title><categories>math.NT cs.DS</categories><comments>7 pages</comments><msc-class>11Y05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The best known unconditional deterministic complexity bound for computing the
prime factorization of an integer N is O(M_int(N^(1/4) log N)), where M_int(k)
denotes the cost of multiplying k-bit integers. This result is due to
Bostan--Gaudry--Schost, following the Pollard--Strassen approach. We show that
this bound can be improved by a factor of (log log N)^(1/2).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2118</identifier>
 <datestamp>2012-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2118</id><created>2012-01-10</created><authors><author><keyname>Blazewicz</keyname><forenames>Marek</forenames></author><author><keyname>Brandt</keyname><forenames>Steven R.</forenames></author><author><keyname>Diener</keyname><forenames>Peter</forenames></author><author><keyname>Koppelman</keyname><forenames>David M.</forenames></author><author><keyname>Kurowski</keyname><forenames>Krzysztof</forenames></author><author><keyname>L&#xf6;ffler</keyname><forenames>Frank</forenames></author><author><keyname>Schnetter</keyname><forenames>Erik</forenames></author><author><keyname>Tao</keyname><forenames>Jian</forenames></author></authors><title>A Massive Data Parallel Computational Framework for Petascale/Exascale
  Hybrid Computer Systems</title><categories>cs.DC</categories><comments>Parallel Computing 2011 (ParCo2011), 30 August -- 2 September 2011,
  Ghent, Belgium</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Heterogeneous systems are becoming more common on High Performance Computing
(HPC) systems. Even using tools like CUDA and OpenCL it is a non-trivial task
to obtain optimal performance on the GPU. Approaches to simplifying this task
include Merge (a library based framework for heterogeneous multi-core systems),
Zippy (a framework for parallel execution of codes on multiple GPUs), BSGP (a
new programming language for general purpose computation on the GPU) and
CUDA-lite (an enhancement to CUDA that transforms code based on annotations).
In addition, efforts are underway to improve compiler tools for automatic
parallelization and optimization of affine loop nests for GPUs and for
automatic translation of OpenMP parallelized codes to CUDA.
  In this paper we present an alternative approach: a new computational
framework for the development of massively data parallel scientific codes
applications suitable for use on such petascale/exascale hybrid systems built
upon the highly scalable Cactus framework. As the first non-trivial
demonstration of its usefulness, we successfully developed a new 3D CFD code
that achieves improved performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2125</identifier>
 <datestamp>2012-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2125</id><created>2012-01-10</created><authors><author><keyname>Kumar</keyname><forenames>P. Suresh</forenames></author><author><keyname>Kumar</keyname><forenames>P. Sateesh</forenames></author><author><keyname>Ramachandram</keyname><forenames>S.</forenames></author></authors><title>Purging of untrustworthy recommendations from a grid</title><categories>cs.DC</categories><comments>8 pages, 4 figures, 1 table published by IJNGN journal; International
  Journal of Next-Generation Networks (IJNGN) Vol.3, No.4, December 2011</comments><doi>10.5121/ijngn.2011.3403</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In grid computing, trust has massive significance. There is lot of research
to propose various models in providing trusted resource sharing mechanisms. The
trust is a belief or perception that various researchers have tried to
correlate with some computational model. Trust on any entity can be direct or
indirect. Direct trust is the impact of either first impression over the entity
or acquired during some direct interaction. Indirect trust is the trust may be
due to either reputation gained or recommendations received from various
recommenders of a particular domain in a grid or any other domain outside that
grid or outside that grid itself. Unfortunately, malicious indirect trust leads
to the misuse of valuable resources of the grid. This paper proposes the
mechanism of identifying and purging the untrustworthy recommendations in the
grid environment. Through the obtained results, we show the way of purging of
untrustworthy entities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2173</identifier>
 <datestamp>2012-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2173</id><created>2012-01-10</created><authors><author><keyname>Giveki</keyname><forenames>Davar</forenames></author><author><keyname>Salimi</keyname><forenames>Hamid</forenames></author><author><keyname>Bahmanyar</keyname><forenames>GholamReza</forenames></author><author><keyname>Khademian</keyname><forenames>Younes</forenames></author></authors><title>Automatic Detection of Diabetes Diagnosis using Feature Weighted Support
  Vector Machines based on Mutual Information and Modified Cuckoo Search</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Diabetes is a major health problem in both developing and developed countries
and its incidence is rising dramatically. In this study, we investigate a novel
automatic approach to diagnose Diabetes disease based on Feature Weighted
Support Vector Machines (FW-SVMs) and Modified Cuckoo Search (MCS). The
proposed model consists of three stages: Firstly, PCA is applied to select an
optimal subset of features out of set of all the features. Secondly, Mutual
Information is employed to construct the FWSVM by weighting different features
based on their degree of importance. Finally, since parameter selection plays a
vital role in classification accuracy of SVMs, MCS is applied to select the
best parameter values. The proposed MI-MCS-FWSVM method obtains 93.58% accuracy
on UCI dataset. The experimental results demonstrate that our method
outperforms the previous methods by not only giving more accurate results but
also significantly speeding up the classification procedure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2197</identifier>
 <datestamp>2015-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2197</id><created>2012-01-10</created><updated>2012-08-07</updated><authors><author><keyname>Portillo</keyname><forenames>Ignacio Gomez</forenames></author></authors><title>Cooperation and its evolution in growing systems with cultural
  reproduction</title><categories>cs.GT physics.soc-ph</categories><comments>16 pages, 2 figures. arXiv admin note: substantial text overlap with
  arXiv:1111.2470</comments><doi>10.1140/epjb/e2012-30405-7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We explore the evolution of cooperation in the framework of the evolutionary
game theory using the prisoner's dilemma as metaphor of the problem. We present
a minimal model taking into account the growing process of the systems and
individuals with imitation capacity. We consider the topological structure and
the evolution of strategies decoupled instead of a coevolutionary dynamic. We
show conditions to build up a cooperative system with real topological
structures for any natural selection intensity. When the system starts to grow,
cooperation is unstable but becomes stable as soon as the system reaches a
small core of cooperators whose size increase when the intensity of natural
selection decreases. Thus, we reduce the emergence of cooperative systems with
cultural reproduction to justify a small initial cooperative structure that we
call cooperative seed. Otherwise, given that the system grows principally as
cooperator whose cooperators inhabit the most linked parts of the system, the
benefit-cost ratio required for cooperation evolve is drastically reduced
compared to the found in static networks. In this way, we show that in systems
whose individuals have imitation capacity the growing process is essential for
the evolution of cooperation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2199</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2199</id><created>2012-01-10</created><authors><author><keyname>Beirami</keyname><forenames>Ahmad</forenames></author><author><keyname>Fekri</keyname><forenames>Faramarz</forenames></author></authors><title>Memory-Assisted Universal Source Coding</title><categories>cs.IT math.IT</categories><comments>Accepted in 2012 Data Compression Conference (DCC '12)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of the universal compression of a sequence from a library of
several small to moderate length sequences from similar context arises in many
practical scenarios, such as the compression of the storage data and the
Internet traffic. In such scenarios, it is often required to compress and
decompress every sequence individually. However, the universal compression of
the individual sequences suffers from significant redundancy overhead. In this
paper, we aim at answering whether or not having a memory unit in the middle
can result in a fundamental gain in the universal compression. We present the
problem setup in the most basic scenario consisting of a server node $S$, a
relay node $R$ (i.e., the memory unit), and a client node $C$. We assume that
server $S$ wishes to send the sequence $x^n$ to the client $C$ who has never
had any prior communication with the server, and hence, is not capable of
memorization of the source context. However, $R$ has previously communicated
with $S$ to forward previous sequences from $S$ to the clients other than $C$,
and thus, $R$ has memorized a context $y^m$ shared with $S$. Note that if the
relay node was absent the source could possibly apply universal compression to
$x^n$ and transmit to $C$ whereas the presence of memorized context at $R$ can
possibly reduce the communication overhead in $S$-$R$ link. In this paper, we
investigate the fundamental gain of the context memorization in the
memory-assisted universal compression of the sequence $x^n$ over conventional
universal source coding by providing a lower bound on the gain of
memory-assisted source coding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2201</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2201</id><created>2012-01-10</created><authors><author><keyname>Beirami</keyname><forenames>Ahmad</forenames></author><author><keyname>Nejati</keyname><forenames>Hamid</forenames></author><author><keyname>Massoud</keyname><forenames>Yehia</forenames></author></authors><title>A Performance Metric for Discrete-Time Chaos-Based Truly Random Number
  Generators</title><categories>cs.IT math.DS math.IT</categories><comments>MWSCAS08</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we develop an information entropy based metric that represents
the statistical quality of the generated binary sequence in Truly Random Number
Generators (TRNG). The metric can be used for the design and optimization of
the TRNG circuits as well as the development of efficient post-processing units
for recovering the degraded statistical characteristics of the signal due to
process variations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2205</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2205</id><created>2012-01-10</created><updated>2012-01-22</updated><authors><author><keyname>Bellare</keyname><forenames>Mihir</forenames></author><author><keyname>Tessaro</keyname><forenames>Stefano</forenames></author><author><keyname>Vardy</keyname><forenames>Alexander</forenames></author></authors><title>A Cryptographic Treatment of the Wiretap Channel</title><categories>cs.IT cs.CR math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The wiretap channel is a setting where one aims to provide
information-theoretic privacy of communicated data based solely on the
assumption that the channel from sender to adversary is &quot;noisier&quot; than the
channel from sender to receiver. It has been the subject of decades of work in
the information and coding (I&amp;C) community. This paper bridges the gap between
this body of work and modern cryptography with contributions along two fronts,
namely metrics (definitions) of security, and schemes. We explain that the
metric currently in use is weak and insufficient to guarantee security of
applications and propose two replacements. One, that we call mis-security, is a
mutual-information based metric in the I&amp;C style. The other, semantic security,
adapts to this setting a cryptographic metric that, in the cryptography
community, has been vetted by decades of evaluation and endorsed as the target
for standards and implementations. We show that they are equivalent (any scheme
secure under one is secure under the other), thereby connecting two
fundamentally different ways of defining security and providing a strong,
unified and well-founded target for designs. Moving on to schemes, results from
the wiretap community are mostly non-constructive, proving the existence of
schemes without necessarily yielding ones that are explicit, let alone
efficient, and only meeting their weak notion of security. We apply
cryptographic methods based on extractors to produce explicit, polynomial-time
and even practical encryption schemes that meet our new and stronger security
target.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2207</identifier>
 <datestamp>2012-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2207</id><created>2012-01-10</created><authors><author><keyname>Jumadinova</keyname><forenames>Janyl</forenames></author><author><keyname>Dasgupta</keyname><forenames>Prithviraj</forenames></author></authors><title>Multi-sensor Information Processing using Prediction Market-based Belief
  Aggregation</title><categories>cs.MA</categories><comments>17 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of information fusion from multiple sensors of
different types with the objective of improving the confidence of inference
tasks, such as object classification, performed from the data collected by the
sensors. We propose a novel technique based on distributed belief aggregation
using a multi-agent prediction market to solve this information fusion problem.
To monitor the improvement in the confidence of the object classification as
well as to dis-incentivize agents from misreporting information, we have
introduced a market maker that rewards the agents instantaneously as well as at
the end of the inference task, based on the quality of the submitted reports.
We have implemented the market maker's reward calculation in the form of a
scoring rule and have shown analytically that it incentivizes truthful
revelation or accurate reporting by each agent. We have experimentally verified
our technique for multi-sensor information fusion for an automated landmine
detection scenario. Our experimental results show that, for identical data
distributions and settings, using our information aggregation technique
increases the accuracy of object classification favorably as compared to two
other commonly used techniques for information fusion for landmine detection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2231</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2231</id><created>2012-01-10</created><updated>2012-03-09</updated><authors><author><keyname>Xu</keyname><forenames>Xiaoli</forenames></author><author><keyname>Thakor</keyname><forenames>Satyajit</forenames></author><author><keyname>Guan</keyname><forenames>Yong Liang</forenames></author></authors><title>Reduced Functional Dependence Graph and Its Applications</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Functional dependence graph (FDG) is an important class of directed graph
that captures the dominance relationship among a set of variables. FDG is
frequently used in calculating network coding capacity bounds. However, the
order of FDG is usually much larger than the original network and the
computational complexity of many bounds grows exponentially with the order of
FDG. In this paper, we introduce the concept of reduced FDG, which is obtained
from the original FDG by keeping only those &quot;essential&quot; edges. It is proved
that the reduced FDG gives the same capacity region/bounds with the original
FDG, but requiring much less computation. The applications of reduced FDG in
the algebraic formulation of scalar linear network coding is also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2237</identifier>
 <datestamp>2012-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2237</id><created>2012-01-10</created><authors><author><keyname>Elleithy</keyname><forenames>Abdelrahman</forenames></author><author><keyname>Liu</keyname><forenames>Gonhsin</forenames></author></authors><title>A simulation model for the lifetime of wireless sensor networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a model for the lifetime of wireless sensor
networks. The model takes into consideration several parameters such as the
total number of sensors, network size, percentage of sink nodes, location of
sensors, the mobility of sensors, and power consumption. A definition of the
life time of the network based on three different criteria is introduced;
percentage of available power to total power, percentage of alive sensors to
total sensors, and percentage of alive sink sensors to total sink sensors. A
Matlab based simulator is developed for the introduced model. A number of
wireless sensor networks scenarios are presented and discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2240</identifier>
 <datestamp>2012-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2240</id><created>2012-01-10</created><authors><author><keyname>Sarkar</keyname><forenames>Kamal</forenames></author></authors><title>Bengali text summarization by sentence extraction</title><categories>cs.IR cs.CL</categories><journal-ref>Proceedings of International Conference on Business and
  Information Management(ICBIM-2012),NIT Durgapur, PP 233-245</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Text summarization is a process to produce an abstract or a summary by
selecting significant portion of the information from one or more texts. In an
automatic text summarization process, a text is given to the computer and the
computer returns a shorter less redundant extract or abstract of the original
text(s). Many techniques have been developed for summarizing English text(s).
But, a very few attempts have been made for Bengali text summarization. This
paper presents a method for Bengali text summarization which extracts important
sentences from a Bengali document to produce a summary.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2241</identifier>
 <datestamp>2012-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2241</id><created>2012-01-10</created><authors><author><keyname>Pelikan</keyname><forenames>Martin</forenames></author><author><keyname>Hauschild</keyname><forenames>Mark W.</forenames></author></authors><title>Distance-Based Bias in Model-Directed Optimization of Additively
  Decomposable Problems</title><categories>cs.NE cs.AI</categories><report-no>MEDAL Report No. 2012001</report-no><acm-class>I.2.6; I.2.8; G.1.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For many optimization problems it is possible to define a distance metric
between problem variables that correlates with the likelihood and strength of
interactions between the variables. For example, one may define a metric so
that the dependencies between variables that are closer to each other with
respect to the metric are expected to be stronger than the dependencies between
variables that are further apart. The purpose of this paper is to describe a
method that combines such a problem-specific distance metric with information
mined from probabilistic models obtained in previous runs of estimation of
distribution algorithms with the goal of solving future problem instances of
similar type with increased speed, accuracy and reliability. While the focus of
the paper is on additively decomposable problems and the hierarchical Bayesian
optimization algorithm, it should be straightforward to generalize the approach
to other model-directed optimization techniques and other problem classes.
Compared to other techniques for learning from experience put forward in the
past, the proposed technique is both more practical and more broadly
applicable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2258</identifier>
 <datestamp>2012-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2258</id><created>2012-01-11</created><authors><author><keyname>Deng</keyname><forenames>Yuxing</forenames></author><author><keyname>Tiu</keyname><forenames>Alwen</forenames></author></authors><title>Characterisations of Testing Preorders for a Finite Probabilistic
  pi-Calculus</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider two characterisations of the may and must testing preorders for a
probabilistic extension of the finite pi-calculus: one based on notions of
probabilistic weak simulations, and the other on a probabilistic extension of a
fragment of Milner-Parrow-Walker modal logic for the pi-calculus. We base our
notions of simulations on the similar concepts used in previous work for
probabilistic CSP. However, unlike the case with CSP (or other
non-value-passing calculi), there are several possible definitions of
simulation for the probabilistic pi-calculus, which arise from different ways
of scoping the name quantification. We show that in order to capture the
testing preorders, one needs to use the &quot;earliest&quot; simulation relation (in
analogy to the notion of early (bi)simulation in the non-probabilistic case).
The key ideas in both characterisations are the notion of a &quot;characteristic
formula&quot; of a probabilistic process, and the notion of a &quot;characteristic test&quot;
for a formula. As in an earlier work on testing equivalence for the pi-calculus
by Boreale and De Nicola, we extend the language of the $\pi$-calculus with a
mismatch operator, without which the formulation of a characteristic test will
not be possible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2261</identifier>
 <datestamp>2015-03-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2261</id><created>2012-01-11</created><authors><author><keyname>Petrovic</keyname><forenames>Dan</forenames></author></authors><title>Relationships in Large-Scale Graph Computing</title><categories>cs.DS cs.IR</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In 2009 Grzegorz Czajkowski from Google's system infrastructure team has
published an article which didn't get much attention in the SEO community at
the time. It was titled &quot;Large-scale graph computing at Google&quot; and gave an
excellent insight into the future of Google's search. This article highlights
some of the little known facts which lead to transformation of Google's
algorithm in the last two years.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2267</identifier>
 <datestamp>2012-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2267</id><created>2012-01-11</created><updated>2012-02-02</updated><authors><author><keyname>Mulzer</keyname><forenames>Wolfgang</forenames></author><author><keyname>Werner</keyname><forenames>Daniel</forenames></author></authors><title>A Lower Bound for Shallow Partitions</title><categories>cs.CG cs.DM</categories><comments>6 pages, 1 figure. The result was also obtained independently by
  Peyman Afshani</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let P be a planar n-point set. A k-partition of P is a subdivision of P into
n/k parts of roughly equal size and a sequence of triangles such that each part
is contained in a triangle. A line is k-shallow if it has at most k points of P
below it.
  The crossing number of a k-partition is the maximum number of triangles in
the partition that any k-shallow line intersects. We give a lower bound of
Omega(log (n/k)/loglog(n/k)) for this crossing number, answering a 20-year old
question of Matousek.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2277</identifier>
 <datestamp>2012-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2277</id><created>2012-01-11</created><authors><author><keyname>Kan</keyname><forenames>Andrey</forenames></author><author><keyname>Chan</keyname><forenames>Jeffrey</forenames></author><author><keyname>Hayes</keyname><forenames>Conor</forenames></author><author><keyname>Hogan</keyname><forenames>Bernie</forenames></author><author><keyname>Bailey</keyname><forenames>James</forenames></author><author><keyname>Leckie</keyname><forenames>Christopher</forenames></author></authors><title>A Time Decoupling Approach for Studying Forum Dynamics</title><categories>cs.SI physics.soc-ph</categories><comments>This submission is the paper draft after a major revision, it is
  currently under review in World Wide Web journal. The supplementary data can
  be downloaded from: http://people.eng.unimelb.edu.au/akan/user-paths/supp.pdf
  (please contact the authors if that doesn't work for some reason)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Online forums are rich sources of information about user communication
activity over time. Finding temporal patterns in online forum communication
threads can advance our understanding of the dynamics of conversations. The
main challenge of temporal analysis in this context is the complexity of forum
data. There can be thousands of interacting users, who can be numerically
described in many different ways. Moreover, user characteristics can evolve
over time. We propose an approach that decouples temporal information about
users into sequences of user events and inter-event times. We develop a new
feature space to represent the event sequences as paths, and we model the
distribution of the inter-event times. We study over 30,000 users across four
Internet forums, and discover novel patterns in user communication. We find
that users tend to exhibit consistency over time. Furthermore, in our feature
space, we observe regions that represent unlikely user behaviors. Finally, we
show how to derive a numerical representation for each forum, and we then use
this representation to derive a novel clustering of multiple forums.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2288</identifier>
 <datestamp>2012-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2288</id><created>2012-01-11</created><authors><author><keyname>Dhir</keyname><forenames>Vijay</forenames></author><author><keyname>Datta</keyname><forenames>Rattan K.</forenames></author><author><keyname>Dutta</keyname><forenames>Maitreyee</forenames></author></authors><title>Nimble@ITCEcnoGrid: A Grid in Research Domain for Weather Forecasting</title><categories>cs.DC cs.NI</categories><comments>11 pages</comments><journal-ref>International Journal of Grid Computing &amp; Applications (IJGCA)
  Vol.2, No.4, December 2011, 37-47</journal-ref><doi>10.5121/ijgca.2011.2404</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computer Technology has Revolutionized Science. This has motivated scientists
to develop mathematical model to simulate salient features of Physical
universe. These models can approximate reality at many levels of scale such as
atomic nucleus, Earth's biosphere &amp; weather/climate assessment. If the computer
power is greater, the greater will be the accuracy in approximation i.e. close
will be the approximation to the reality. The speed of the computer required
for solution of such problems require computers with processing power of
teraflops to Pets flops speed.. The way to speed up the computation is to
&quot;parallelize&quot; it. One of the approach is to use multimillion dollar
Supercomputer or use Computational Grid (which is also called poor man's
supercomputer) having geographically distributed resources e.g. SETI@home (Used
to detect radio waves emitted by intelligent civilizations outside earth) has
4.6 million participants computers. There are many alternatives tools available
to achieve this goal like Globus Toolkit, Entropia, Legion, BOINC etc but they
are mainly based on Linux platform. As majority of the computers available are
windows based, so it will be easy to develop a larger network of computers
which will use the free cycles of the computer to solve the complex problem at
window platform. Nimble@ITCEcnoGrid has been developed. It includes the feature
of Inter Thread Communication which is missing in any of the toolkits
available. Nimble@ITCEcnoGrid Framework (A Fast Grid with Inter-thread
communication with Economic Based Policy) was tested for computation of 'PI' up
to 120 decimal points. Encouraged by the speed the same system has been
utilized to computes the Momentum, Thermodynamics and Continuity equations for
the Weather Forecasting using the Windows based Desktop computers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2291</identifier>
 <datestamp>2012-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2291</id><created>2012-01-11</created><updated>2012-01-12</updated><authors><author><keyname>Lopez-Ruiz</keyname><forenames>Ricardo</forenames></author><author><keyname>Sanudo</keyname><forenames>Jaime</forenames></author><author><keyname>Romera</keyname><forenames>Elvira</forenames></author><author><keyname>Calbet</keyname><forenames>Xavier</forenames></author></authors><title>Statistical Complexity and Fisher-Shannon Information. Applications</title><categories>nlin.CD cs.IT math.IT physics.atom-ph</categories><comments>71 pages, 37 figures, 3 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this chapter, a statistical measure of complexity and the Fisher-Shannon
information product are introduced and their properties are discussed. These
measures are based on the interplay between the Shannon information, or a
function of it, and the separation of the set of accessible states to a system
from the equiprobability distribution, i.e. the disequilibrium or the Fisher
information, respectively. Different applications in discrete and continuous
systems are shown. Some of them are concerned with quantum systems, from
prototypical systems such as the H-atom, the harmonic oscillator and the square
well to other ones such as He-like ions, Hooke's atoms or just the periodic
table. In all of them, these statistical indicators show an interesting
behavior able to discern and highlight some conformational properties of those
systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2292</identifier>
 <datestamp>2012-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2292</id><created>2012-01-11</created><authors><author><keyname>Borst</keyname><forenames>S. C.</forenames></author><author><keyname>Walton</keyname><forenames>N. S.</forenames></author><author><keyname>Zwart</keyname><forenames>A. P.</forenames></author></authors><title>Network iso-elasticity and weighted $\alpha$-fairness</title><categories>math.OC cs.NI math.PR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When a communication network's capacity increases, it is natural to want the
bandwidth allocated to increase to exploit this capacity. But, if the same
relative capacity increase occurs at each network resource, it is also natural
to want each user to see the same relative benefit, so the bandwidth allocated
to each route should remain proportional. We will be interested in bandwidth
allocations which scale in this \textit{iso-elastic} manner and, also, maximize
a utility function.
  Utility optimizing bandwidth allocations have been frequently studied, and a
popular choice of utility function are the weighted $\alpha$-fair utility
functions introduced by Mo and Walrand \cite{MoWa00}. Because weighted
$\alpha$-fair utility functions possess this iso-elastic property, they are
frequently used to form fluid models of bandwidth sharing networks. In this
paper, we present results that show, in many settings, the only utility
functions which are iso-elastic are weighted $\alpha$-fair utility functions.
  Thus, if bandwidth is allocated according to a network utility function which
scales with relative network changes then that utility function must be a
weighted $\alpha$-fair utility function, and hence, a control protocol that is
robust to the future relative changes in network capacity and usage ought to
allocate bandwidth inorder to maximize a weighted $\alpha$-fair utility
function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2304</identifier>
 <datestamp>2012-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2304</id><created>2012-01-11</created><authors><author><keyname>Chitra</keyname><forenames>P.</forenames><affiliation>Dept. of Information Technology, RMK Engineering College, Tamilnadu, India</affiliation></author><author><keyname>Baskaran</keyname><forenames>R.</forenames><affiliation>Dept. of Comp. Sci. and Engg. Anna University, Chennai, Tamilnadu, India</affiliation></author><author><keyname>Sarukesi</keyname><forenames>K.</forenames><affiliation>Hindustan University, Chennai, Tamilnadu, India</affiliation></author></authors><title>Query sensitive comparative summarization of search results using
  concept based segmentation</title><categories>cs.IR</categories><comments>Computer Science &amp; Engineering: An International Journal (CSEIJ),
  Vol.1, No.5, December 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Query sensitive summarization aims at providing the users with the summary of
the contents of single or multiple web pages based on the search query. This
paper proposes a novel idea of generating a comparative summary from a set of
URLs from the search result. User selects a set of web page links from the
search result produced by search engine. Comparative summary of these selected
web sites is generated. This method makes use of HTML DOM tree structure of
these web pages. HTML documents are segmented into set of concept blocks.
Sentence score of each concept block is computed with respect to the query and
feature keywords. The important sentences from the concept blocks of different
web pages are extracted to compose the comparative summary on the fly. This
system reduces the time and effort required for the user to browse various web
sites to compare the information. The comparative summary of the contents would
help the users in quick decision making.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2312</identifier>
 <datestamp>2012-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2312</id><created>2012-01-10</created><authors><author><keyname>Lakshmi</keyname><forenames>B. Seetha</forenames></author><author><keyname>Balapriya</keyname><forenames>C. D.</forenames></author><author><keyname>Soniya</keyname><forenames>R.</forenames></author></authors><title>Actor Garbage Collection in Distributed Systems using Graph
  Transformation</title><categories>cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A lot of research work has been done in the area of Garbage collection for
both uniprocessor and distributed systems. Actors are associated with activity
(thread) and hence usual garbage collection algorithms cannot be applied for
them. Hence a separate algorithm should be used to collect them. If we
transform the active reference graph into a graph which captures all the
features of actors and looks like passive reference graph then any passive
reference graph algorithm can be applied for it. But the cost of transformation
and optimization are the core issues. An attempt has been made to walk through
these issues.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2315</identifier>
 <datestamp>2013-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2315</id><created>2012-01-11</created><updated>2013-11-08</updated><authors><author><keyname>Villard</keyname><forenames>Joffrey</forenames><affiliation>Shitz</affiliation></author><author><keyname>Piantanida</keyname><forenames>Pablo</forenames><affiliation>Shitz</affiliation></author><author><keyname>Shamai</keyname><forenames>Shlomo</forenames><affiliation>Shitz</affiliation></author></authors><title>Secure Transmission of Sources over Noisy Channels with Side Information
  at the Receivers</title><categories>cs.IT math.IT</categories><comments>To appear in IEEE Transactions on Information Theory</comments><doi>10.1109/TIT.2013.2288256</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the problem of source-channel coding for secure
transmission with arbitrarily correlated side informations at both receivers.
This scenario consists of an encoder (referred to as Alice) that wishes to
compress a source and send it through a noisy channel to a legitimate receiver
(referred to as Bob). In this context, Alice must simultaneously satisfy the
desired requirements on the distortion level at Bob, and the equivocation rate
at the eavesdropper (referred to as Eve). This setting can be seen as a
generalization of the problems of secure source coding with (uncoded) side
information at the decoders, and the wiretap channel. A general outer bound on
the rate-distortion-equivocation region, as well as an inner bound based on a
pure digital scheme, is derived for arbitrary channels and side informations.
In some special cases of interest, it is proved that this digital scheme is
optimal and that separation holds. However, it is also shown through a simple
counterexample with a binary source that a pure analog scheme can outperform
the digital one while being optimal. According to these observations and
assuming matched bandwidth, a novel hybrid digital/analog scheme that aims to
gather the advantages of both digital and analog ones is then presented. In the
quadratic Gaussian setup when side information is only present at the
eavesdropper, this strategy is proved to be optimal. Furthermore, it
outperforms both digital and analog schemes, and cannot be achieved via
time-sharing. By means of an appropriate coding, the presence of any
statistical difference among the side informations, the channel noises, and the
distortion at Bob can be fully exploited in terms of secrecy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2320</identifier>
 <datestamp>2014-03-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2320</id><created>2012-01-11</created><updated>2014-03-03</updated><authors><author><keyname>Consoli</keyname><forenames>Sergio</forenames></author><author><keyname>Mladenovic</keyname><forenames>Nenad</forenames></author><author><keyname>Moreno-Perez</keyname><forenames>Jose Andres</forenames></author></authors><title>Solving the minimum labelling spanning tree problem using intelligent
  optimization</title><categories>math.OC cs.DM math.CO</categories><comments>This paper has been withdrawn by the authors due to major
  modifications on the algorithm which make obsolete and inconsistent the
  computational results reported</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a connected, undirected graph whose edges are labelled (or coloured),
the minimum labelling spanning tree (MLST) problem seeks a spanning tree whose
edges have the smallest number of distinct labels (or colours). In recent work,
the MLST problem has been shown to be NP-hard and some effective heuristics
have been proposed and analyzed. In this paper we present an intelligent
optimization algorithm to solve the problem. It is obtained by the basic
Variable Neighbourhood Search heuristic with the integration of other
complements from machine learning, statistics and experimental algorithmics, in
order to produce high-quality performance and to completely automate the
resulting optimization strategy. We present experimental results on randomly
generated graphs with different statistical properties, showing the crucial
effects of the implementation, the robustness, and the empirical scalability of
our intelligent algorithm. Furthermore, the computational experiments show that
the proposed strategy outperforms the heuristics recommended in the literature
and is able to obtain optimal or near-optimal solutions in short computational
running time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2334</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2334</id><created>2012-01-11</created><updated>2013-05-30</updated><authors><author><keyname>Jiao</keyname><forenames>Jiantao</forenames></author><author><keyname>Permuter</keyname><forenames>Haim H.</forenames></author><author><keyname>Zhao</keyname><forenames>Lei</forenames></author><author><keyname>Kim</keyname><forenames>Young-Han</forenames></author><author><keyname>Weissman</keyname><forenames>Tsachy</forenames></author></authors><title>Universal Estimation of Directed Information</title><categories>cs.IT math.IT</categories><comments>23 pages, 10 figures, to appear in IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Four estimators of the directed information rate between a pair of jointly
stationary ergodic finite-alphabet processes are proposed, based on universal
probability assignments. The first one is a Shannon--McMillan--Breiman type
estimator, similar to those used by Verd\'u (2005) and Cai, Kulkarni, and
Verd\'u (2006) for estimation of other information measures. We show the almost
sure and $L_1$ convergence properties of the estimator for any underlying
universal probability assignment. The other three estimators map universal
probability assignments to different functionals, each exhibiting relative
merits such as smoothness, nonnegativity, and boundedness. We establish the
consistency of these estimators in almost sure and $L_1$ senses, and derive
near-optimal rates of convergence in the minimax sense under mild conditions.
These estimators carry over directly to estimating other information measures
of stationary ergodic finite-alphabet processes, such as entropy rate and
mutual information rate, with near-optimal performance and provide alternatives
to classical approaches in the existing literature. Guided by these theoretical
results, the proposed estimators are implemented using the context-tree
weighting algorithm as the universal probability assignment. Experiments on
synthetic and real data are presented, demonstrating the potential of the
proposed schemes in practice and the utility of directed information estimation
in detecting and measuring causal influence and delay.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2360</identifier>
 <datestamp>2014-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2360</id><created>2012-01-11</created><updated>2014-01-17</updated><authors><author><keyname>Dell'Amico</keyname><forenames>Matteo</forenames></author><author><keyname>Michiardi</keyname><forenames>Pietro</forenames></author><author><keyname>Toka</keyname><forenames>Laszlo</forenames></author><author><keyname>Cataldi</keyname><forenames>Pasquale</forenames></author></authors><title>Adaptive Redundancy Management for Durable P2P Backup</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We design and analyze the performance of a redundancy management mechanism
for Peer-to-Peer backup applications. Armed with the realization that a backup
system has peculiar requirements -- namely, data is read over the network only
during restore processes caused by data loss -- redundancy management targets
data durability rather than attempting to make each piece of information
availabile at any time.
  In our approach each peer determines, in an on-line manner, an amount of
redundancy sufficient to counter the effects of peer deaths, while preserving
acceptable data restore times. Our experiments, based on trace-driven
simulations, indicate that our mechanism can reduce the redundancy by a factor
between two and three with respect to redundancy policies aiming for data
availability. These results imply an according increase in storage capacity and
decrease in time to complete backups, at the expense of longer times required
to restore data. We believe this is a very reasonable price to pay, given the
nature of the application.
  We complete our work with a discussion on practical issues, and their
solutions, related to which encoding technique is more suitable to support our
scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2374</identifier>
 <datestamp>2013-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2374</id><created>2012-01-11</created><updated>2013-02-20</updated><authors><author><keyname>Etessami</keyname><forenames>Kousha</forenames></author><author><keyname>Stewart</keyname><forenames>Alistair</forenames></author><author><keyname>Yannakakis</keyname><forenames>Mihalis</forenames></author></authors><title>Polynomial Time Algorithms for Multi-Type Branching Processes and
  Stochastic Context-Free Grammars</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that one can approximate the least fixed point solution for a
multivariate system of monotone probabilistic polynomial equations in time
polynomial in both the encoding size of the system of equations and in
log(1/\epsilon), where \epsilon &gt; 0 is the desired additive error bound of the
solution. (The model of computation is the standard Turing machine model.)
  We use this result to resolve several open problems regarding the
computational complexity of computing key quantities associated with some
classic and heavily studied stochastic processes, including multi-type
branching processes and stochastic context-free grammars.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2383</identifier>
 <datestamp>2012-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2383</id><created>2012-01-11</created><updated>2012-03-16</updated><authors><author><keyname>Ghosh</keyname><forenames>Rumi</forenames></author><author><keyname>Lerman</keyname><forenames>Kristina</forenames></author></authors><title>Impact of Dynamic Interactions on Multi-Scale Analysis of Community
  Structure in Networks</title><categories>cs.SI physics.comp-ph physics.data-an physics.soc-ph</categories><comments>submitted to KDD 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To find interesting structure in networks, community detection algorithms
have to take into account not only the network topology, but also dynamics of
interactions between nodes. We investigate this claim using the paradigm of
synchronization in a network of coupled oscillators. As the network evolves to
a global steady state, nodes belonging to the same community synchronize faster
than nodes belonging to different communities. Traditionally, nodes in network
synchronization models are coupled via one-to-one, or conservative
interactions. However, social interactions are often one-to-many, as for
example, in social media, where users broadcast messages to all their
followers. We formulate a novel model of synchronization in a network of
coupled oscillators in which the oscillators are coupled via one-to-many, or
non-conservative interactions. We study the dynamics of different interaction
models and contrast their spectral properties. To find multi-scale community
structure in a network of interacting nodes, we define a similarity function
that measures the degree to which nodes are synchronized and use it to
hierarchically cluster nodes. We study real-world social networks, including
networks of two social media providers. To evaluate the quality of the
discovered communities in a social media network we propose a community quality
metric based on user activity. We find that conservative and non-conservative
interaction models lead to dramatically different views of community structure
even within the same network. Our work offers a novel mathematical framework
for exploring the relationship between network structure, topology and
dynamics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2384</identifier>
 <datestamp>2013-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2384</id><created>2012-01-11</created><updated>2013-01-03</updated><authors><author><keyname>Fryer</keyname><forenames>Dashiell E. A.</forenames></author></authors><title>On the Existence of General Equilibrium in Finite Games and General Game
  Dynamics</title><categories>cs.GT math.DS</categories><comments>16 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A notion of incentive for agents is introduced which leads to a very general
notion of an equilibrium for a finite game. Sufficient conditions for the
existence of these equilibria are given. Known existence theorems are shown to
be corollaries to the main theorem of this paper. Furthermore, conditions for
the existence of equilibria in certain symmetric regions for games are also
given.
  From the notion of general equilibrium, a general family of game dynamics are
derived. This family incorporates all canonical examples of game dynamics. A
proof is given for the full generality of this system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2386</identifier>
 <datestamp>2013-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2386</id><created>2012-01-11</created><updated>2013-02-20</updated><authors><author><keyname>Butler</keyname><forenames>Brian K.</forenames></author><author><keyname>Siegel</keyname><forenames>Paul H.</forenames></author></authors><title>Bounds on the Minimum Distance of Punctured Quasi-Cyclic LDPC Codes</title><categories>cs.IT math.IT</categories><comments>13 pages, 6 figures, 6 tables. Submitted to IEEE Transactions on
  Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent work by Divsalar et al. has shown that properly designed
protograph-based low-density parity-check (LDPC) codes typically have minimum
(Hamming) distance linearly increasing with block length. This fact rests on
ensemble arguments over all possible expansions of the base protograph.
However, when implementation complexity is considered, the expansions are
frequently selected from a smaller class of structured expansions. For example,
protograph expansion by cyclically shifting connections generates a
quasi-cyclic (QC) code. Other recent work by Smarandache and Vontobel has
provided upper bounds on the minimum distance of QC codes. In this paper, we
generalize these bounds to punctured QC codes and then show how to tighten
these for certain classes of codes. We then evaluate these upper bounds for the
family of protograph codes known as AR4JA codes that have been recommended for
use in deep space communications in a standard established by the Consultative
Committee for Space Data Systems (CCSDS). At block lengths larger than 4400
bits, these upper bounds fall well below the ensemble lower bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2387</identifier>
 <datestamp>2012-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2387</id><created>2012-01-11</created><authors><author><keyname>Montpetit</keyname><forenames>Marie-Jose</forenames></author><author><keyname>Westphal</keyname><forenames>Cedric</forenames></author><author><keyname>Trossen</keyname><forenames>Dirk</forenames></author></authors><title>Network Coding Meets Information-Centric Networking</title><categories>cs.NI</categories><comments>6 pages, position paper</comments><msc-class>68M10, 90B18</msc-class><acm-class>C.2.1; H.3.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The focus of user behavior in the Internet has changed over the recent years
towards being driven by exchanging and accessing information. Many advances in
networking technologies have utilized this change by focusing on the content of
an exchange rather than the endpoints exchanging the content. Network coding
and information centric networking are two examples of these technology trends,
each being developed largely independent so far. This paper brings these areas
together in an evolutionary as well as explorative setting for a new
internetworking architecture. We outline opportunities for applying network
coding in a novel and performance-enhancing way that could eventually push
forward the case for information centric network itself.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2395</identifier>
 <datestamp>2012-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2395</id><created>2012-01-11</created><updated>2012-03-01</updated><authors><author><keyname>Hinkle</keyname><forenames>Jacob</forenames></author><author><keyname>Muralidharan</keyname><forenames>Prasanna</forenames></author><author><keyname>Fletcher</keyname><forenames>P. Thomas</forenames></author><author><keyname>Joshi</keyname><forenames>Sarang</forenames></author></authors><title>Polynomial Regression on Riemannian Manifolds</title><categories>math.ST cs.CV math.DG stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we develop the theory of parametric polynomial regression in
Riemannian manifolds and Lie groups. We show application of Riemannian
polynomial regression to shape analysis in Kendall shape space. Results are
presented, showing the power of polynomial regression on the classic rat skull
growth data of Bookstein as well as the analysis of the shape changes
associated with aging of the corpus callosum from the OASIS Alzheimer's study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2399</identifier>
 <datestamp>2012-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2399</id><created>2012-01-11</created><authors><author><keyname>Armoogum</keyname><forenames>Sheeba</forenames></author><author><keyname>Armoogum</keyname><forenames>Vinaye</forenames></author><author><keyname>Gopaul</keyname><forenames>Jayprakash</forenames></author></authors><title>The Development of a LAN for DVB-T Transmission and DVB-S Reception with
  Designed QAM Modulators and COFDM in the Island Mauritius</title><categories>cs.NI</categories><comments>20 pages, IJWMN journal paper; ISSN:0975-3834 (Online); 0975-4679
  (Print)</comments><journal-ref>International Journal of Wireless &amp; Mobile Networks (IJWMN) Vol.
  3, No. 6, December 2011, 71-90</journal-ref><doi>10.5121/ijwmn.2011.3606</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is a thorough study of a digital broadcasting system adapted to
the small mountainous island of Mauritius. A digital LAN was designed with
MPEG-2 signals. The compressed signals were transmitted using DVB-T and QAM
modulators. QAM-16 and QAM-64 modulators were designed and tested with a
simulator under critical conditions of AWGN and phase noises. Results obtained
from simulation have shown that Digital video broadcast with a single frequency
network (SFN) is possible in Mauritius with QAM-64 and QAM-16 modulators
applying COFDM mode of transmission. However, this study has also shown that
QAM-16 modulator had a better performance at low AWGN values (less than 12 dB)
and can be adopted for Mauritius Island, provided that the number of
transmitted channels is not high enough.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2416</identifier>
 <datestamp>2012-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2416</id><created>2012-01-11</created><authors><author><keyname>Machart</keyname><forenames>Pierre</forenames><affiliation>LIF</affiliation></author><author><keyname>Peel</keyname><forenames>Thomas</forenames><affiliation>LIF, LATP</affiliation></author><author><keyname>Ralaivola</keyname><forenames>Liva</forenames><affiliation>LIF</affiliation></author><author><keyname>Anthoine</keyname><forenames>Sandrine</forenames><affiliation>LATP</affiliation></author><author><keyname>Glotin</keyname><forenames>Herv&#xe9;</forenames><affiliation>LSIS</affiliation></author></authors><title>Stochastic Low-Rank Kernel Learning for Regression</title><categories>cs.LG</categories><comments>International Conference on Machine Learning (ICML'11), Bellevue
  (Washington) : United States (2011)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel approach to learn a kernel-based regression function. It
is based on the useof conical combinations of data-based parameterized kernels
and on a new stochastic convex optimization procedure of which we establish
convergence guarantees. The overall learning procedure has the nice properties
that a) the learned conical combination is automatically designed to perform
the regression task at hand and b) the updates implicated by the optimization
procedure are quite inexpensive. In order to shed light on the appositeness of
our learning strategy, we present empirical results from experiments conducted
on various benchmark datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2430</identifier>
 <datestamp>2012-06-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2430</id><created>2012-01-11</created><updated>2012-06-15</updated><authors><author><keyname>Tan</keyname><forenames>Li</forenames></author></authors><title>A Well-typed Lightweight Situation Calculus</title><categories>cs.PL cs.AI</categories><comments>In Proceedings of the 21st Workshop on Logic-based methods in
  Programming Environments (WLPE'11), ICLP 2011 Workshop, pp. 62-73, Lexington,
  Kentucky, USA, July 2011</comments><acm-class>D.1.6; D.3</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Situation calculus has been widely applied in Artificial Intelligence related
fields. This formalism is considered as a dialect of logic programming language
and mostly used in dynamic domain modeling. However, type systems are hardly
deployed in situation calculus in the literature. To achieve a correct and
sound typed program written in situation calculus, adding typing elements into
the current situation calculus will be quite helpful. In this paper, we propose
to add more typing mechanisms to the current version of situation calculus,
especially for three basic elements in situation calculus: situations, actions
and objects, and then perform rigid type checking for existing situation
calculus programs to find out the well-typed and ill-typed ones. In this way,
type correctness and soundness in situation calculus programs can be guaranteed
by type checking based on our type system. This modified version of a
lightweight situation calculus is proved to be a robust and well-typed system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2462</identifier>
 <datestamp>2012-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2462</id><created>2012-01-11</created><authors><author><keyname>Javanmard</keyname><forenames>Adel</forenames></author><author><keyname>Zhang</keyname><forenames>Li</forenames></author></authors><title>The minimax risk of truncated series estimators for symmetric convex
  polytopes</title><categories>math.ST cs.IT math.IT math.PR stat.TH</categories><comments>21 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the optimality of the minimax risk of truncated series estimators
for symmetric convex polytopes. We show that the optimal truncated series
estimator is within $O(\log m)$ factor of the optimal if the polytope is
defined by $m$ hyperplanes. This represents the first such bounds towards
general convex bodies. In proving our result, we first define a geometric
quantity, called the \emph{approximation radius}, for lower bounding the
minimax risk. We then derive our bounds by establishing a connection between
the approximation radius and the Kolmogorov width, the quantity that provides
upper bounds for the truncated series estimator. Besides, our proof contains
several ingredients which might be of independent interest: 1. The notion of
approximation radius depends on the volume of the body. It is an intuitive
notion and is flexible to yield strong minimax lower bounds; 2. The connection
between the approximation radius and the Kolmogorov width is a consequence of a
novel duality relationship on the Kolmogorov width, developed by utilizing some
deep results from convex geometry.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2471</identifier>
 <datestamp>2012-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2471</id><created>2012-01-11</created><updated>2012-05-29</updated><authors><author><keyname>Yang</keyname><forenames>Tao</forenames></author><author><keyname>Yuan</keyname><forenames>Xiaojun</forenames></author><author><keyname>Ping</keyname><forenames>Li</forenames></author><author><keyname>Collings</keyname><forenames>Iain B.</forenames></author><author><keyname>Yuan</keyname><forenames>Jinhong</forenames></author></authors><title>Eigen-Direction Alignment Based Physical-Layer Network Coding for MIMO
  Two-Way Relay Channels</title><categories>cs.IT math.IT</categories><comments>This work was partially presented at IEEE ISIT 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a novel communication strategy which incorporates
physical-layer network coding (PNC) into multiple-input multiple output (MIMO)
two-way relay channels (TWRCs). At the heart of the proposed scheme lies a new
key technique referred to as eigen-direction alignment (EDA) precoding. The EDA
precoding efficiently aligns the two-user's eigen-modes into the same
directions. Based on that, we carry out multi-stream PNC over the aligned
eigen-modes. We derive an achievable rate of the proposed EDA-PNC scheme, based
on nested lattice codes, over a MIMO TWRC. Asymptotic analysis shows that the
proposed EDA-PNC scheme approaches the capacity upper bound as the number of
user antennas increases towards infinity. For a finite number of user antennas,
we formulate the design criterion of the optimal EDA precoder and present
solutions. Numerical results show that there is only a marginal gap between the
achievable rate of the proposed EDA-PNC scheme and the capacity upper bound of
the MIMO TWRC, in the median-to-large SNR region. We also show that the
proposed EDA-PNC scheme significantly outperforms existing amplify-and-forward
and decode-and-forward based schemes for MIMO TWRCs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2473</identifier>
 <datestamp>2012-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2473</id><created>2012-01-11</created><authors><author><keyname>Hossain</keyname><forenames>Md. Sazzad</forenames></author><author><keyname>Rakib</keyname><forenames>Md. Rashedul Hasan</forenames></author><author><keyname>Rahman</keyname><forenames>Md. Motiur</forenames></author><author><keyname>Hossain</keyname><forenames>A. S. M. Delowar</forenames></author><author><keyname>Hasan</keyname><forenames>Md. Minul</forenames></author></authors><title>A New Design Technique of Reversible BCD Adder Based on NMOS With Pass
  Transistor Gates</title><categories>cs.OH</categories><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  In this paper, we have proposed a new design technique of BCD Adder using
newly constructed reversible gates are based on NMOS with pass transistor
gates, where the conventional reversible gates are based on CMOS with
transmission gates. We also compare the proposed reversible gates with the
conventional CMOS reversible gates which show that the required number of
Transistors is significantly reduced.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2474</identifier>
 <datestamp>2012-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2474</id><created>2012-01-11</created><authors><author><keyname>Ling</keyname><forenames>Yibei</forenames></author><author><keyname>Alexander</keyname><forenames>Scott</forenames></author><author><keyname>Lau</keyname><forenames>Richard</forenames></author></authors><title>On Quantification of Anchor Placement</title><categories>cs.NI cs.CC cs.DS</categories><comments>infocom 1012</comments><acm-class>F.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper attempts to answer a question: for a given traversal area, how to
quantify the geometric impact of anchor placement on localization performance.
We present a theoretical framework for quantifying the anchor placement impact.
An experimental study, as well as the field test using a UWB ranging
technology, is presented. These experimental results validate the theoretical
analysis. As a byproduct, we propose a two-phase localization method (TPLM) and
show that TPLM outperforms the least-square method in localization accuracy by
a huge margin. TPLM performs much faster than the gradient descent method and
slightly better than the gradient descent method in localization accuracy. Our
field test suggests that TPLM is more robust against noise than the
least-square and gradient descent methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2478</identifier>
 <datestamp>2012-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2478</id><created>2012-01-12</created><authors><author><keyname>Karafyllis</keyname><forenames>Iasson</forenames></author><author><keyname>Jiang</keyname><forenames>Zhong-Ping</forenames></author></authors><title>Global stabilization of nonlinear systems based on vector control
  lyapunov functions</title><categories>math.OC cs.SY</categories><comments>25 pages, to be submitted to IEEE Transactions on Automatic Control</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the use of vector Lyapunov functions for the design of
globally stabilizing feedback laws for nonlinear systems. Recent results on
vector Lyapunov functions are utilized. The main result of the paper shows that
the existence of a vector control Lyapunov function is a necessary and
sufficient condition for the existence of a smooth globally stabilizing
feedback. Applications to nonlinear systems are provided: simple and easily
checkable sufficient conditions are proposed to guarantee the existence of a
smooth globally stabilizing feedback law. The obtained results are applied to
the problem of the stabilization of an equilibrium point of a reaction network
taking place in a continuous stirred tank reactor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2481</identifier>
 <datestamp>2012-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2481</id><created>2012-01-12</created><authors><author><keyname>Prasad</keyname><forenames>K. Munivara</forenames></author><author><keyname>Reddy</keyname><forenames>A. Rama Mohan</forenames></author><author><keyname>Karthik</keyname><forenames>M. Ganesh</forenames></author></authors><title>Flooding attacks to internet threat monitors (ITM): Modeling and counter
  measures using botnet and honeypots</title><categories>cs.NI</categories><journal-ref>International Journal of Computer Science &amp; Information Technology
  (IJCSIT) Vol 3, No 6, Dec 2011, 159-172</journal-ref><doi>10.5121/ijcsit.2011.3612</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The Internet Threat Monitoring (ITM),is a globally scoped Internet monitoring
system whose goal is to measure, detect, characterize, and track threats such
as distribute denial of service(DDoS) attacks and worms. To block the
monitoring system in the internet the attackers are targeted the ITM system. In
this paper we address flooding attack against ITM system in which the attacker
attempt to exhaust the network and ITM's resources, such as network bandwidth,
computing power, or operating system data structures by sending the malicious
traffic. We propose an information-theoretic frame work that models the
flooding attacks using Botnet on ITM. Based on this model we generalize the
flooding attacks and propose an effective attack detection using Honeypots.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2483</identifier>
 <datestamp>2012-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2483</id><created>2012-01-12</created><authors><author><keyname>Li</keyname><forenames>Yonghui</forenames></author><author><keyname>Rahman</keyname><forenames>Md. Shahriar</forenames></author><author><keyname>Vucetic</keyname><forenames>Branka</forenames></author></authors><title>Duality of Channel Encoding and Decoding - Part I: Rate-1 Convolutional
  Codes</title><categories>cs.IT math.IT</categories><comments>33 pages, 19 figures, submitted to IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we revisit the forward, backward and bidirectional
Bahl-Cocke-Jelinek-Raviv (BCJR) soft-input soft-output (SISO) maximum a
posteriori probability (MAP) decoding process of rate-1 convolutional codes.
From this we establish some interesting duality properties between encoding and
decoding of rate-1 convolutional codes. We observe that the forward and
backward BCJR SISO MAP decoders can be simply represented by their dual SISO
channel encoders using shift registers in the complex number field. Similarly,
the bidirectional MAP decoding can be implemented by linearly combining the
outputs of the dual SISO encoders of the respective forward and backward
decoders. The dual encoder structures for various recursive and non-recursive
rate-1 convolutional codes are derived.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2501</identifier>
 <datestamp>2012-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2501</id><created>2012-01-12</created><updated>2012-04-06</updated><authors><author><keyname>Hassanieh</keyname><forenames>Haitham</forenames></author><author><keyname>Indyk</keyname><forenames>Piotr</forenames></author><author><keyname>Katabi</keyname><forenames>Dina</forenames></author><author><keyname>Price</keyname><forenames>Eric</forenames></author></authors><title>Nearly Optimal Sparse Fourier Transform</title><categories>cs.DS</categories><comments>28 pages, appearing at STOC 2012</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We consider the problem of computing the k-sparse approximation to the
discrete Fourier transform of an n-dimensional signal. We show:
  * An O(k log n)-time randomized algorithm for the case where the input signal
has at most k non-zero Fourier coefficients, and
  * An O(k log n log(n/k))-time randomized algorithm for general input signals.
  Both algorithms achieve o(n log n) time, and thus improve over the Fast
Fourier Transform, for any k = o(n). They are the first known algorithms that
satisfy this property. Also, if one assumes that the Fast Fourier Transform is
optimal, the algorithm for the exactly k-sparse case is optimal for any k =
n^{\Omega(1)}.
  We complement our algorithmic results by showing that any algorithm for
computing the sparse Fourier transform of a general signal must use at least
\Omega(k log(n/k)/ log log n) signal samples, even if it is allowed to perform
adaptive sampling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2504</identifier>
 <datestamp>2012-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2504</id><created>2012-01-12</created><updated>2012-03-16</updated><authors><author><keyname>Tian</keyname><forenames>Miaomiao</forenames></author><author><keyname>Huang</keyname><forenames>Liusheng</forenames></author><author><keyname>Yang</keyname><forenames>Wei</forenames></author></authors><title>On the security of an enhanced short signature scheme</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Currently, short signature is receiving significant attention since it is
particularly useful in low-bandwidth communication environments. However, most
of the short signature schemes are only based on one intractable assumption.
Recently, Su presented an identity-based short signature scheme based on
knapsack and bilinear pairing. He claimed that the signature scheme is secure
in the random oracle model. Unfortunately, in this paper, we show that his
scheme is insecure. Concretely, an adversary can forge a valid signature on any
message with respect to any identity in Su's scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2508</identifier>
 <datestamp>2012-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2508</id><created>2012-01-12</created><updated>2012-07-15</updated><authors><author><keyname>Nair</keyname><forenames>T. R. Gopalakrishnan</forenames></author><author><keyname>Vaidehi</keyname><forenames>M.</forenames></author><author><keyname>Suma</keyname><forenames>V.</forenames></author></authors><title>Improved Strategies for Enhanced Business Performance in Cloud based IT
  Industries</title><categories>cs.OH</categories><comments>this paper has a reference error</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Emergence of sophisticated technologies in IT industries has posed several
challenges such as production of products using advanced technical process for
instance Result Orientation Approach, Deployment, Assessment and Refinement
(RADAR) in a dynamic and competitive environment. The key challenge for any
engineer is therefore to develop process and products which ultimately lead
towards total customer satisfaction. Recent development in technology has
driven most of the IT industries to operate in the cloud environment due to
reduced infrastructure investment and maintenance overheads. However, existing
process in cloud lacks efficient multiple service paradigms that can provide
improved business gain. Thus, it is the responsibility of every engineer to
contribute towards effective and efficient techniques and models that can
enhance the business performance. The position of this paper is to present
several major issues prevailing in the IT industries such as delay time,
response time, performance etc., which call for immediate attention in order to
position themselves in the market. Further, this paper provides improved
strategies through efficient job scheduling and modified resource allocation
techniques for aforementioned issues in order to enhance the business
performance in cloud-based IT sectors. The simulated results provided in this
paper indicate the impact of enhanced solutions incorporated in the job
processing strategies. They further enable better performance of the cloud with
reduced delay and response time resulting towards improved throughput.
Subsequently, it increases the job acceptance ratio with respect to time and
thereby leading the industry to accomplish total customer satisfaction in
addition to the continued sustainability in the competitive business market.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2513</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2513</id><created>2012-01-12</created><authors><author><keyname>Gholami</keyname><forenames>Mohammad Reza</forenames></author><author><keyname>Str&#xf6;m</keyname><forenames>Erik G.</forenames></author><author><keyname>Wymeersch</keyname><forenames>Henk</forenames></author><author><keyname>Rydstr&#xf6;m</keyname><forenames>Mats</forenames></author></authors><title>On Geometric Upper Bounds for Positioning Algorithms in Wireless Sensor
  Networks</title><categories>cs.IT math.IT</categories><comments>29 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the possibility of upper bounding the position error of an
estimate for range based positioning algorithms in wireless sensor networks. In
this study, we argue that in certain situations when the measured distances
between sensor nodes are positively biased, e.g., in non-line-of-sight
conditions, the target node is confined to a closed bounded convex set (a
feasible set) which can be derived from the measurements. Then, we formulate
two classes of geometric upper bounds with respect to the feasible set. If an
estimate is available, either feasible or infeasible, the worst-case position
error can be defined as the maximum distance between the estimate and any point
in the feasible set (the first bound). Alternatively, if an estimate given by a
positioning algorithm is always feasible, we propose to get the maximum length
of the feasible set as the worst-case position error (the second bound). These
bounds are formulated as nonconvex optimization problems. To progress, we relax
the nonconvex problems and obtain convex problems, which can be efficiently
solved. Simulation results indicate that the proposed bounds are reasonably
tight in many situations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2515</identifier>
 <datestamp>2012-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2515</id><created>2012-01-12</created><authors><author><keyname>Hienert</keyname><forenames>Daniel</forenames></author><author><keyname>Sawitzki</keyname><forenames>Frank</forenames></author><author><keyname>Schaer</keyname><forenames>Philipp</forenames></author><author><keyname>Mayr</keyname><forenames>Philipp</forenames></author></authors><title>Integrating Interactive Visualizations in the Search Process of Digital
  Libraries and IR Systems</title><categories>cs.DL cs.IR</categories><comments>To be published as a Poster Paper in the Proceedings of ECIR 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interactive visualizations for exploring and retrieval have not yet become an
integral part of digital libraries and information retrieval systems. We have
integrated a set of interactive graphics in a real world social science digital
library. These visualizations support the exploration of search queries,
results and authors, can filter search results, show trends in the database and
can support the creation of new search queries. The use of weighted brushing
supports the identification of related metadata for search facets. We discuss
some use cases of the combination of IR systems and interactive graphics. In a
user study we verify that users can gain insights from statistical graphics
intuitively and can adopt interaction techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2523</identifier>
 <datestamp>2013-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2523</id><created>2012-01-12</created><updated>2013-04-05</updated><authors><author><keyname>Koch</keyname><forenames>Tobias</forenames></author><author><keyname>Lapidoth</keyname><forenames>Amos</forenames></author></authors><title>At Low SNR Asymmetric Quantizers Are Better</title><categories>cs.IT math.IT</categories><comments>24 pages, 3 figures. Version that will appear in the IEEE
  Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the capacity of the discrete-time Gaussian channel when its output
is quantized with a one-bit quantizer. We focus on the low signal-to-noise
ratio (SNR) regime, where communication at very low spectral efficiencies takes
place. In this regime a symmetric threshold quantizer is known to reduce
channel capacity by a factor of 2/pi, i.e., to cause an asymptotic power loss
of approximately two decibels. Here it is shown that this power loss can be
avoided by using asymmetric threshold quantizers and asymmetric signaling
constellations. To avoid this power loss, flash-signaling input distributions
are essential. Consequently, one-bit output quantization of the Gaussian
channel reduces spectral efficiency. Threshold quantizers are not only
asymptotically optimal: at every fixed SNR a threshold quantizer maximizes
capacity among all one-bit output quantizers. The picture changes on the
Rayleigh-fading channel. In the noncoherent case a one-bit output quantizer
causes an unavoidable low-SNR asymptotic power loss. In the coherent case,
however, this power loss is avoidable provided that we allow the quantizer to
depend on the fading level.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2531</identifier>
 <datestamp>2012-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2531</id><created>2012-01-12</created><authors><author><keyname>Acs</keyname><forenames>Gergely</forenames></author><author><keyname>Castelluccia</keyname><forenames>Claude</forenames></author></authors><title>DREAM: DiffeRentially privatE smArt Metering</title><categories>cs.CR</categories><comments>Shorter version appeared on Information Hiding Conference 2011</comments><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  This paper presents a new privacy-preserving smart metering system. Our
scheme is private under the differential privacy model and therefore provides
strong and provable guarantees. With our scheme, an (electricity) supplier can
periodically collect data from smart meters and derive aggregated statistics
while learning only limited information about the activities of individual
households. For example, a supplier cannot tell from a user's trace when he
watched TV or turned on heating. Our scheme is simple, efficient and practical.
Processing cost is very limited: smart meters only have to add noise to their
data and encrypt the results with an efficient stream cipher.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2542</identifier>
 <datestamp>2012-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2542</id><created>2012-01-12</created><authors><author><keyname>Christe</keyname><forenames>S. Allin</forenames></author><author><keyname>Vignesh</keyname><forenames>M.</forenames></author><author><keyname>Kandaswamy</keyname><forenames>A.</forenames></author></authors><title>An efficient FPGA implementation of MRI image filtering and tumor
  characterization using Xilinx system generator</title><categories>cs.AR cs.CV</categories><comments>15 pages,14 figures,2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an efficient architecture for various image filtering
algorithms and tumor characterization using Xilinx System Generator (XSG). This
architecture offers an alternative through a graphical user interface that
combines MATLAB, Simulink and XSG and explores important aspects concerned to
hardware implementation. Performance of this architecture implemented in
SPARTAN-3E Starter kit (XC3S500E-FG320) exceeds those of similar or greater
resources architectures. The proposed architecture reduces the resources
available on target device by 50%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2551</identifier>
 <datestamp>2012-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2551</id><created>2012-01-12</created><authors><author><keyname>Axenovich</keyname><forenames>Maria</forenames></author><author><keyname>Krug</keyname><forenames>Marcus</forenames></author><author><keyname>Osang</keyname><forenames>Georg</forenames></author><author><keyname>Rutter</keyname><forenames>Ignaz</forenames></author></authors><title>Fork-forests in bi-colored complete bipartite graphs</title><categories>cs.DM math.CO</categories><comments>5 pages, 3 figures</comments><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by the problem in [6], which studies the relative efficiency of
propositional proof systems, 2-edge colorings of complete bipartite graphs are
investigated. It is shown that if the edges of $G=K_{n,n}$ are colored with
black and white such that the number of black edges differs from the number of
white edges by at most 1, then there are at least $n(1-1/\sqrt{2})$
vertex-disjoint forks with centers in the same partite set of $G$. Here, a fork
is a graph formed by two adjacent edges of different colors. The bound is
sharp. Moreover, an algorithm running in time $O(n^2 \log n \sqrt{n
\alpha(n^2,n) \log n})$ and giving a largest such fork forest is found.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2553</identifier>
 <datestamp>2012-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2553</id><created>2012-01-12</created><updated>2012-01-16</updated><authors><author><keyname>Avanzini</keyname><forenames>Martin</forenames></author><author><keyname>Eguchi</keyname><forenames>Naohi</forenames></author><author><keyname>Moser</keyname><forenames>Georg</forenames></author></authors><title>A New Order-theoretic Characterisation of the Polytime Computable
  Functions</title><categories>cs.CC</categories><comments>Technical Report</comments><acm-class>F.2.2; F.4.1; F.4.2; D.2.4; D.2.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new order, the small polynomial path order (sPOP* for short).
The order sPOP* provides a characterisation of the class of polynomial time
computable function via term rewrite systems. Any polynomial time computable
function gives rise to a rewrite system that is compatible with sPOP*. On the
other hand any function defined by a rewrite system compatible with sPOP* is
polynomial time computable. Technically sPOP* is a tamed recursive path order
with product status. Its distinctive feature is the precise control provided.
For any rewrite system that is compatible with sPOP* that makes use of
recursion up to depth d, the (innermost) runtime complexity is bounded from
above by a polynomial of degree d.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2555</identifier>
 <datestamp>2012-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2555</id><created>2012-01-12</created><updated>2012-09-05</updated><authors><author><keyname>Dimitrakakis</keyname><forenames>Christos</forenames></author></authors><title>Sparse Reward Processes</title><categories>cs.LG stat.ML</categories><comments>14 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a class of learning problems where the agent is presented with a
series of tasks. Intuitively, if there is relation among those tasks, then the
information gained during execution of one task has value for the execution of
another task. Consequently, the agent is intrinsically motivated to explore its
environment beyond the degree necessary to solve the current task it has at
hand. We develop a decision theoretic setting that generalises standard
reinforcement learning tasks and captures this intuition. More precisely, we
consider a multi-stage stochastic game between a learning agent and an
opponent. We posit that the setting is a good model for the problem of
life-long learning in uncertain environments, where while resources must be
spent learning about currently important tasks, there is also the need to
allocate effort towards learning about aspects of the world which are not
relevant at the moment. This is due to the fact that unpredictable future
events may lead to a change of priorities for the decision maker. Thus, in some
sense, the model &quot;explains&quot; the necessity of curiosity. Apart from introducing
the general formalism, the paper provides algorithms. These are evaluated
experimentally in some exemplary domains. In addition, performance bounds are
proven for some cases of this problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2564</identifier>
 <datestamp>2012-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2564</id><created>2012-01-12</created><authors><author><keyname>Nguyen</keyname><forenames>Linh Anh</forenames></author><author><keyname>Cao</keyname><forenames>Son Thanh</forenames></author></authors><title>Query-Subquery Nets</title><categories>cs.DB cs.LO</categories><comments>24 pages</comments><acm-class>H.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We formulate query-subquery nets and use them to create the first framework
for developing algorithms for evaluating queries to Horn knowledge bases with
the properties that: the approach is goal-directed; each subquery is processed
only once and each supplement tuple, if desired, is transferred only once;
operations are done set-at-a-time; and any control strategy can be used. Our
intention is to increase efficiency of query processing by eliminating
redundant computation, increasing flexibility and reducing the number of
accesses to the secondary storage. The framework forms a generic evaluation
method called QSQN. To deal with function symbols, we use a term-depth bound
for atoms and substitutions occurring in the computation and propose to use
iterative deepening search which iteratively increases the term-depth bound. We
prove soundness and completeness of our generic evaluation method and show
that, when the term-depth bound is fixed, the method has PTIME data complexity.
We also present how tail recursion elimination can be incorporated into our
framework and propose two exemplary control strategies, one is to reduce the
number of accesses to the secondary storage, while the other is depth-first
search.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2575</identifier>
 <datestamp>2012-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2575</id><created>2012-01-12</created><updated>2012-03-04</updated><authors><author><keyname>Jeon</keyname><forenames>Sung-eok</forenames></author><author><keyname>Ji</keyname><forenames>Chuanyi</forenames></author></authors><title>Joint Approximation of Information and Distributed Link-Scheduling
  Decisions in Wireless Networks</title><categories>cs.LG cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For a large multi-hop wireless network, nodes are preferable to make
distributed and localized link-scheduling decisions with only interactions
among a small number of neighbors. However, for a slowly decaying channel and
densely populated interferers, a small size neighborhood often results in
nontrivial link outages and is thus insufficient for making optimal scheduling
decisions. A question arises how to deal with the information outside a
neighborhood in distributed link-scheduling. In this work, we develop joint
approximation of information and distributed link scheduling. We first apply
machine learning approaches to model distributed link-scheduling with complete
information. We then characterize the information outside a neighborhood in
form of residual interference as a random loss variable. The loss variable is
further characterized by either a Mean Field approximation or a normal
distribution based on the Lyapunov central limit theorem. The approximated
information outside a neighborhood is incorporated in a factor graph. This
results in joint approximation and distributed link-scheduling in an iterative
fashion. Link-scheduling decisions are first made at each individual node based
on the approximated loss variables. Loss variables are then updated and used
for next link-scheduling decisions. The algorithm repeats between these two
phases until convergence. Interactive iterations among these variables are
implemented with a message-passing algorithm over a factor graph. Simulation
results show that using learned information outside a neighborhood jointly with
distributed link-scheduling reduces the outage probability close to zero even
for a small neighborhood.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2578</identifier>
 <datestamp>2012-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2578</id><created>2012-01-12</created><authors><author><keyname>Gong</keyname><forenames>Shuping</forenames></author><author><keyname>Zhang</keyname><forenames>Zhenghao</forenames></author><author><keyname>Li</keyname><forenames>Husheng</forenames></author><author><keyname>Dimitrovski</keyname><forenames>Aleksandar D.</forenames></author></authors><title>Time Stamp Attack in Smart Grid: Physical Mechanism and Damage Analysis</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many operations in power grids, such as fault detection and event location
estimation, depend on precise timing information. In this paper, a novel time
stamp attack (TSA) is proposed to attack the timing information in smart grid.
Since many applications in smart grid utilize synchronous measurements and most
of the measurement devices are equipped with global positioning system (GPS)
for precise timing, it is highly probable to attack the measurement system by
spoofing the GPS. The effectiveness of TSA is demonstrated for three
applications of phasor measurement unit (PMU) in smart grid, namely
transmission line fault detection, voltage stability monitoring and event
locationing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2592</identifier>
 <datestamp>2013-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2592</id><created>2012-01-12</created><updated>2012-07-31</updated><authors><author><keyname>Anic</keyname><forenames>Branimir</forenames></author><author><keyname>Beattie</keyname><forenames>Christopher A.</forenames></author><author><keyname>Gugercin</keyname><forenames>Serkan</forenames></author><author><keyname>Antoulas</keyname><forenames>Athanasios C.</forenames></author></authors><title>Interpolatory Weighted-H2 Model Reduction</title><categories>math.NA cs.SY math.DS math.OC</categories><journal-ref>Automatica, Volume 49, Issue 5, 2013</journal-ref><doi>10.1016/j.automatica.2013.01.040</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces an interpolation framework for the weighted-H2 model
reduction problem. We obtain a new representation of the weighted-H2 norm of
SISO systems that provides new interpolatory first order necessary conditions
for an optimal reduced-order model. The H2 norm representation also provides an
error expression that motivates a new weighted-H2 model reduction algorithm.
Several numerical examples illustrate the effectiveness of the proposed
approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2605</identifier>
 <datestamp>2014-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2605</id><created>2012-01-12</created><updated>2012-07-02</updated><authors><author><keyname>Dai</keyname><forenames>Zhenwen</forenames></author><author><keyname>L&#xfc;cke</keyname><forenames>J&#xf6;rg</forenames></author></authors><title>Autonomous Cleaning of Corrupted Scanned Documents - A Generative
  Modeling Approach</title><categories>cs.CV cs.LG</categories><comments>oral presentation and Google Student Travel Award; IEEE conference on
  Computer Vision and Pattern Recognition 2012</comments><doi>10.1109/TPAMI.2014.2313126</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the task of cleaning scanned text documents that are strongly
corrupted by dirt such as manual line strokes, spilled ink etc. We aim at
autonomously removing dirt from a single letter-size page based only on the
information the page contains. Our approach, therefore, has to learn character
representations without supervision and requires a mechanism to distinguish
learned representations from irregular patterns. To learn character
representations, we use a probabilistic generative model parameterizing pattern
features, feature variances, the features' planar arrangements, and pattern
frequencies. The latent variables of the model describe pattern class, pattern
position, and the presence or absence of individual pattern features. The model
parameters are optimized using a novel variational EM approximation. After
learning, the parameters represent, independently of their absolute position,
planar feature arrangements and their variances. A quality measure defined
based on the learned representation then allows for an autonomous
discrimination between regular character patterns and the irregular patterns
making up the dirt. The irregular patterns can thus be removed to clean the
document. For a full Latin alphabet we found that a single page does not
contain sufficiently many character examples. However, even if heavily
corrupted by dirt, we show that a page containing a lower number of character
types can efficiently and autonomously be cleaned solely based on the
structural regularity of the characters it contains. In different examples
using characters from different alphabets, we demonstrate generality of the
approach and discuss its implications for future developments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2630</identifier>
 <datestamp>2012-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2630</id><created>2012-01-12</created><authors><author><keyname>Al-Khedher</keyname><forenames>Mohammad A.</forenames></author></authors><title>Hybrid GPS-GSM Localization of Automobile Tracking System</title><categories>cs.SY cs.AI</categories><comments>11 pages, 11 figures, 23 references</comments><journal-ref>International Journal of Computer Science and Information
  Technology, Vol. 3, No. 6, pp. 75-85, 2011</journal-ref><doi>10.5121/ijcsit.2011.3606</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An integrated GPS-GSM system is proposed to track vehicles using Google Earth
application. The remote module has a GPS mounted on the moving vehicle to
identify its current position, and to be transferred by GSM with other
parameters acquired by the automobile's data port as an SMS to a recipient
station. The received GPS coordinates are filtered using a Kalman filter to
enhance the accuracy of measured position. After data processing, Google Earth
application is used to view the current location and status of each vehicle.
This goal of this system is to manage fleet, police automobiles distribution
and car theft cautions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2654</identifier>
 <datestamp>2012-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2654</id><created>2012-01-12</created><authors><author><keyname>Cocos</keyname><forenames>Mihail</forenames></author><author><keyname>Kidman</keyname><forenames>Kent</forenames></author></authors><title>Musical Modes, Their Associated Chords and Their Musicality</title><categories>math.CO cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a mathematical way of defining musical modes and we
define the musicality of a mode as a product of three different factors. We
conclude by classifying the modes which are most musical according to our
definition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2657</identifier>
 <datestamp>2012-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2657</id><created>2012-01-12</created><updated>2012-01-13</updated><authors><author><keyname>Li</keyname><forenames>Frank</forenames></author><author><keyname>Mittal</keyname><forenames>Prateek</forenames></author><author><keyname>Caesar</keyname><forenames>Matthew</forenames></author><author><keyname>Borisov</keyname><forenames>Nikita</forenames></author></authors><title>SybilControl: Practical Sybil Defense with Computational Puzzles</title><categories>cs.NI cs.CR</categories><comments>11 pages, submitted for publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many distributed systems are subject to the Sybil attack, where an adversary
subverts system operation by emulating behavior of multiple distinct nodes.
Most recent work to address this problem leverages social networks to establish
trust relationships between users. However, the use of social networks is not
appropriate in all systems, as they can be subverted by social engineering
techniques, require nodes in a P2P network to maintain and be aware of social
network information, and may require overly optimistic assumptions about the
fast-mixing nature of social links.
  This paper explores an alternate approach. We present SybilControl, a novel,
decentralized scheme for controlling the extent of Sybil attacks. SybilControl
is an admission control mechanism for nodes in a distributed system that
requires them to periodically solve computational puzzles. SybilControl
consists of a distributed protocol to allow nodes to collectively verify the
computational work of other nodes, and mechanisms to prevent the malicious
influence of misbehaving nodes that do not perform the computational work. We
investigate the practical issues involved with deploying SybilControl into
existing DHTs, particularly with resilient lookup protocols. We evaluate
SybilControl through simulations and find that SybilControl retains low
overhead and latency. Additionally, even when the adversary controls 20% of the
system's computational resources, SybilControl-enabled DHTs can be configured
to maintain lookup performance at over 99% success rate using low communication
overhead.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2698</identifier>
 <datestamp>2012-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2698</id><created>2012-01-12</created><updated>2012-04-03</updated><authors><author><keyname>Yagan</keyname><forenames>Osman</forenames></author><author><keyname>Qian</keyname><forenames>Dajun</forenames></author><author><keyname>Zhang</keyname><forenames>Junshan</forenames></author><author><keyname>Cochran</keyname><forenames>Douglas</forenames></author></authors><title>Optimal Allocation of Interconnecting Links in Cyber-Physical Systems:
  Interdependence, Cascading Failures and Robustness</title><categories>physics.data-an cs.SI physics.soc-ph</categories><comments>13 pages, 6 figures. To appear in the Special Issue of IEEE
  Transactions on Parallel and Distributed Systems on Cyber-Physical Systems,
  2012</comments><journal-ref>IEEE Transactions on Parallel and Distributed Systems (TPDS):
  Special Issue on Cyber-Physical Systems, vol. 23, no. 9, pp. 1708-1720,
  September 2012</journal-ref><doi>10.1109/TPDS.2012.62</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a cyber-physical system consisting of two interacting networks,
i.e., a cyber-network overlaying a physical-network. It is envisioned that
these systems are more vulnerable to attacks since node failures in one network
may result in (due to the interdependence) failures in the other network,
causing a cascade of failures that would potentially lead to the collapse of
the entire infrastructure. The robustness of interdependent systems against
this sort of catastrophic failure hinges heavily on the allocation of the
(interconnecting) links that connect nodes in one network to nodes in the other
network. In this paper, we characterize the optimum inter-link allocation
strategy against random attacks in the case where the topology of each
individual network is unknown. In particular, we analyze the &quot;regular&quot;
allocation strategy that allots exactly the same number of bi-directional
inter-network links to all nodes in the system. We show, both analytically and
experimentally, that this strategy yields better performance (from a network
resilience perspective) compared to all possible strategies, including
strategies using random allocation, unidirectional inter-links, etc.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2702</identifier>
 <datestamp>2012-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2702</id><created>2012-01-12</created><authors><author><keyname>Brodal</keyname><forenames>Gerth St&#xf8;lting</forenames></author><author><keyname>Kaporis</keyname><forenames>Alexis C.</forenames></author><author><keyname>Papadopoulos</keyname><forenames>Apostolos N.</forenames></author><author><keyname>Sioutas</keyname><forenames>Spyros</forenames></author><author><keyname>Tsakalidis</keyname><forenames>Konstantinos</forenames></author><author><keyname>Tsichlas</keyname><forenames>Kostas</forenames></author></authors><title>Dynamic 3-sided Planar Range Queries with Expected Doubly Logarithmic
  Time</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work studies the problem of 2-dimensional searching for the 3-sided
range query of the form $[a, b]\times (-\infty, c]$ in both main and external
memory, by considering a variety of input distributions. We present three sets
of solutions each of which examines the 3-sided problem in both RAM and I/O
model respectively. The presented data structures are deterministic and the
expectation is with respect to the input distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2703</identifier>
 <datestamp>2012-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2703</id><created>2012-01-12</created><authors><author><keyname>Agarwal</keyname><forenames>Rachit</forenames></author><author><keyname>Godfrey</keyname><forenames>P. Brighten</forenames></author><author><keyname>Har-Peled</keyname><forenames>Sariel</forenames></author></authors><title>Faster Approximate Distance Queries and Compact Routing in Sparse Graphs</title><categories>cs.DS cs.DC cs.NI cs.SI</categories><comments>20 pages, an earlier version appeared in INFOCOM 2011, this version
  presents data structures with improved space/query-time trade-off</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A distance oracle is a compact representation of the shortest distance matrix
of a graph. It can be queried to approximate shortest paths between any pair of
vertices. Any distance oracle that returns paths of worst-case stretch (2k-1)
must require space $\Omega(n^{1 + 1/k})$ for graphs of n nodes. The hard cases
that enforce this lower bound are, however, rather dense graphs with average
degree \Omega(n^{1/k}).
  We present distance oracles that, for sparse graphs, substantially break the
lower bound barrier at the expense of higher query time. For any 1 \leq \alpha
\leq n, our distance oracles can return stretch 2 paths using O(m + n^2/\alpha)
space and stretch 3 paths using O(m + n^2/\alpha^2) space, at the expense of
O(\alpha m/n) query time. By setting appropriate values of \alpha, we get the
first distance oracles that have size linear in the size of the graph, and
return constant stretch paths in non-trivial query time. The query time can be
further reduced to O(\alpha), by using an additional O(m \alpha) space for all
our distance oracles, or at the cost of a small constant additive stretch.
  We use our stretch 2 distance oracle to present the first compact routing
scheme with worst-case stretch 2. Any compact routing scheme with stretch less
than 2 must require linear memory at some nodes even for sparse graphs; our
scheme, hence, achieves the optimal stretch with non-trivial memory
requirements. Moreover, supported by large-scale simulations on graphs
including the AS-level Internet graph, we argue that our stretch-2 scheme would
be simple and efficient to implement as a distributed compact routing protocol.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2706</identifier>
 <datestamp>2014-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2706</id><created>2012-01-12</created><updated>2012-01-17</updated><authors><author><keyname>Baydin</keyname><forenames>Atilim Gunes</forenames></author><author><keyname>de Mantaras</keyname><forenames>Ramon Lopez</forenames></author></authors><title>Evolution of Ideas: A Novel Memetic Algorithm Based on Semantic Networks</title><categories>cs.NE nlin.AO</categories><comments>Conference submission, 2012 IEEE Congress on Evolutionary Computation
  (8 pages, 7 figures)</comments><msc-class>92D15, 91E40, 68T20, 68T30</msc-class><acm-class>I.2.4; I.2.6; G.1.6; J.4; J.3</acm-class><journal-ref>In Proceedings of the IEEE Congress on Evolutionary Computation,
  CEC 2012, IEEE World Congress On Computational Intelligence, WCCI 2012,
  Brisbane, Australia, June 10-15 2012. IEEE Press, 2012, pp. 2653-2660</journal-ref><doi>10.1109/CEC.2012.6252886</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a new type of evolutionary algorithm (EA) based on the
concept of &quot;meme&quot;, where the individuals forming the population are represented
by semantic networks and the fitness measure is defined as a function of the
represented knowledge. Our work can be classified as a novel memetic algorithm
(MA), given that (1) it is the units of culture, or information, that are
undergoing variation, transmission, and selection, very close to the original
sense of memetics as it was introduced by Dawkins; and (2) this is different
from existing MA, where the idea of memetics has been utilized as a means of
local refinement by individual learning after classical global sampling of EA.
The individual pieces of information are represented as simple semantic
networks that are directed graphs of concepts and binary relations, going
through variation by memetic versions of operators such as crossover and
mutation, which utilize knowledge from commonsense knowledge bases. In
evaluating this introductory work, as an interesting fitness measure, we focus
on using the structure mapping theory of analogical reasoning from psychology
to evolve pieces of information that are analogous to a given base information.
Considering other possible fitness measures, the proposed representation and
algorithm can serve as a computational tool for modeling memetic theories of
knowledge, such as evolutionary epistemology and cultural selection theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2711</identifier>
 <datestamp>2015-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2711</id><created>2012-01-12</created><updated>2012-07-16</updated><authors><author><keyname>Murtagh</keyname><forenames>Fionn</forenames></author></authors><title>Ultrametric Model of Mind, I: Review</title><categories>cs.AI</categories><comments>20 pages, 2 figures, 46 references. arXiv admin note: substantial
  text overlap with arXiv:0709.0116, arXiv:0805.2744, and arXiv:1105.0121 (V3:
  2 typos corrected)</comments><msc-class>68T01</msc-class><acm-class>I.2.0; I.2.3; J.4</acm-class><journal-ref>p-Adic Numbers, Ultrametric Analysis and Applications, 4, 193-206,
  2012</journal-ref><doi>10.1134/S2070046612030041</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We mathematically model Ignacio Matte Blanco's principles of symmetric and
asymmetric being through use of an ultrametric topology. We use for this the
highly regarded 1975 book of this Chilean psychiatrist and pyschoanalyst (born
1908, died 1995). Such an ultrametric model corresponds to hierarchical
clustering in the empirical data, e.g. text. We show how an ultrametric
topology can be used as a mathematical model for the structure of the logic
that reflects or expresses Matte Blanco's symmetric being, and hence of the
reasoning and thought processes involved in conscious reasoning or in reasoning
that is lacking, perhaps entirely, in consciousness or awareness of itself. In
a companion paper we study how symmetric (in the sense of Matte Blanco's)
reasoning can be demarcated in a context of symmetric and asymmetric reasoning
provided by narrative text.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2715</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2715</id><created>2012-01-12</created><updated>2014-11-10</updated><authors><author><keyname>Sauerwald</keyname><forenames>Thomas</forenames></author><author><keyname>Sun</keyname><forenames>He</forenames></author></authors><title>Tight Bounds for Randomized Load Balancing on Arbitrary Network
  Topologies</title><categories>cs.DM cs.DC cs.DS math.PR</categories><comments>74 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of balancing load items (tokens) in networks.
Starting with an arbitrary load distribution, we allow nodes to exchange tokens
with their neighbors in each round. The goal is to achieve a distribution where
all nodes have nearly the same number of tokens.
  For the continuous case where tokens are arbitrarily divisible, most load
balancing schemes correspond to Markov chains, whose convergence is fairly
well-understood in terms of their spectral gap. However, in many applications,
load items cannot be divided arbitrarily, and we need to deal with the discrete
case where the load is composed of indivisible tokens. This discretization
entails a non-linear behavior due to its rounding errors, which makes this
analysis much harder than in the continuous case.
  We investigate several randomized protocols for different communication
models in the discrete case. As our main result, we prove that for any regular
network in the matching model, all nodes have the same load up to an additive
constant in (asymptotically) the same number of rounds as required in the
continuous case. This generalizes and tightens the previous best result, which
only holds for expander graphs, and demonstrates that there is almost no
difference between the discrete and continuous cases. Our results also provide
a positive answer to the question of how well discrete load balancing can be
approximated by (continuous) Markov chains, which has been posed by many
researchers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2719</identifier>
 <datestamp>2012-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2719</id><created>2012-01-12</created><updated>2012-07-16</updated><authors><author><keyname>Murtagh</keyname><forenames>Fionn</forenames></author></authors><title>Ultrametric Model of Mind, II: Application to Text Content Analysis</title><categories>cs.AI cs.CL</categories><comments>21 pages, 6 tables. arXiv admin note: substantial text overlap with
  arXiv:cs/0701181 (V3: minor corrections)</comments><msc-class>68T01</msc-class><acm-class>I.2.0; I.2.3; J.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a companion paper, Murtagh (2012), we discussed how Matte Blanco's work
linked the unrepressed unconscious (in the human) to symmetric logic and
thought processes. We showed how ultrametric topology provides a most useful
representational and computational framework for this. Now we look at the
extent to which we can find ultrametricity in text. We use coherent and
meaningful collections of nearly 1000 texts to show how we can measure inherent
ultrametricity. On the basis of our findings we hypothesize that inherent
ultrametricty is a basis for further exploring unconscious thought processes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2733</identifier>
 <datestamp>2012-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2733</id><created>2012-01-12</created><authors><author><keyname>Mo</keyname><forenames>Qun</forenames></author><author><keyname>Shen</keyname><forenames>Yi</forenames></author></authors><title>A remark on the Restricted Isometry Property in Orthogonal Matching
  Pursuit</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper demonstrates that if the restricted isometry constant
$\delta_{K+1}$ of the measurement matrix $A$ satisfies $$ \delta_{K+1} &lt;
\frac{1}{\sqrt{K}+1}, $$ then a greedy algorithm called Orthogonal Matching
Pursuit (OMP) can recover every $K$--sparse signal $\mathbf{x}$ in $K$
iterations from $A\x$. By contrast, a matrix is also constructed with the
restricted isometry constant $$ \delta_{K+1} = \frac{1}{\sqrt{K}} $$ such that
OMP can not recover some $K$-sparse signal $\mathbf{x}$ in $K$ iterations. This
result positively verifies the conjecture given by Dai and Milenkovic in 2009.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2739</identifier>
 <datestamp>2012-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2739</id><created>2012-01-12</created><authors><author><keyname>Shallue</keyname><forenames>Andrew</forenames></author></authors><title>Division algorithms for the fixed weight subset sum problem</title><categories>math.CO cs.DS</categories><msc-class>11T71</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given positive integers $a_1,..., a_n, t$, the fixed weight subset sum
problem is to find a subset of the $a_i$ that sum to $t$, where the subset has
a prescribed number of elements. It is this problem that underlies the security
of modern knapsack cryptosystems, and solving the problem results directly in a
message attack. We present new exponential algorithms that do not rely on
lattices, and hence will be applicable when lattice basis reduction algorithms
fail. These algorithms rely on a generalization of the notion of splitting
system given by Stinson. In particular, if the problem has length $n$ and
weight $\ell$ then for constant $k$ a power of two less than $n$ we apply a
$k$-set birthday algorithm to the splitting system of the problem. This
randomized algorithm has time and space complexity that satisfies $T \cdot
S^{\log{k}} = O({n \choose \ell})$ (where the constant depends uniformly on
$k$). In addition to using space efficiently, the algorithm is highly
parallelizable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2760</identifier>
 <datestamp>2012-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2760</id><created>2012-01-13</created><authors><author><keyname>Habak</keyname><forenames>Karim</forenames></author><author><keyname>Youssef</keyname><forenames>Moustafa</forenames></author><author><keyname>Harras</keyname><forenames>Khaled A.</forenames></author></authors><title>DBAS: A Deployable Bandwidth Aggregation System</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The explosive increase in data demand coupled with the rapid deployment of
various wireless access technologies have led to the increase of number of
multi-homed or multi-interface enabled devices. Fully exploiting these
interfaces has motivated researchers to propose numerous solutions that
aggregate their available bandwidths to increase overall throughput and satisfy
the end-user's growing data demand. These solutions, however, have faced a
steep deployment barrier that we attempt to overcome in this paper. We propose
a Deployable Bandwidth Aggregation System (DBAS) for multi-interface enabled
devices. Our system does not introduce any intermediate hardware, modify
current operating systems, modify socket implementations, nor require changes
to current applications or legacy servers. The DBAS architecture is designed to
automatically estimate the characteristics of applications and dynamically
schedule various connections or packets to different interfaces. Since our main
focus is deployability, we fully implement DBAS on the Windows operating system
and evaluate various modes of operation. Our implementation and simulation
results show that DBAS achieves throughput gains up to 193% compared to current
operating systems, while operating as an out-of-the-box standard Windows
executable, highlighting its deployability and ease of use.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2766</identifier>
 <datestamp>2012-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2766</id><created>2012-01-13</created><authors><author><keyname>Sioutas</keyname><forenames>Spyros</forenames></author><author><keyname>Triantafillou</keyname><forenames>Peter</forenames></author><author><keyname>Papaloukopoulos</keyname><forenames>George</forenames></author><author><keyname>Sakkopoulos</keyname><forenames>Evangelos</forenames></author><author><keyname>Tsichlas</keyname><forenames>Kostas</forenames></author><author><keyname>Manolopoulos</keyname><forenames>Yannis</forenames></author></authors><title>ART : Sub-Logarithmic Decentralized Range Query Processing with
  Probabilistic Guarantees</title><categories>cs.DB</categories><comments>Submitted to Distributed and Parallel Databases (DAPD) Journal,
  Springer</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We focus on range query processing on large-scale, typically distributed
infrastructures, such as clouds of thousands of nodes of shared-datacenters, of
p2p distributed overlays, etc. In such distributed environments, efficient
range query processing is the key for managing the distributed data sets per
se, and for monitoring the infrastructure's resources. We wish to develop an
architecture that can support range queries in such large-scale decentralized
environments and can scale in terms of the number of nodes as well as in terms
of the data items stored. Of course, in the last few years there have been a
number of solutions (mostly from researchers in the p2p domain) for designing
such large-scale systems. However, these are inadequate for our purposes, since
at the envisaged scales the classic logarithmic complexity (for point queries)
is still too expensive while for range queries it is even more disappointing.
In this paper we go one step further and achieve a sub-logarithmic complexity.
We contribute the ART, which outperforms the most popular decentralized
structures, including Chord (and some of its successors), BATON (and its
successor) and Skip-Graphs. We contribute theoretical analysis, backed up by
detailed experimental results, showing that the communication cost of query and
update operations is $O(\log_{b}^2 \log N)$ hops, where the base $b$ is a
double-exponentially power of two and $N$ is the total number of nodes.
Moreover, ART is a fully dynamic and fault-tolerant structure, which supports
the join/leave node operations in $O(\log \log N)$ expected w.h.p number of
hops. Our experimental performance studies include a detailed performance
comparison which showcases the improved performance, scalability, and
robustness of ART.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2780</identifier>
 <datestamp>2012-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2780</id><created>2012-01-13</created><updated>2012-07-13</updated><authors><author><keyname>Langer</keyname><forenames>Alexander</forenames></author><author><keyname>Reidl</keyname><forenames>Felix</forenames></author><author><keyname>Rossmanith</keyname><forenames>Peter</forenames></author><author><keyname>Sikdar</keyname><forenames>Somnath</forenames></author></authors><title>Linear Kernels on Graphs Excluding Topological Minors</title><categories>cs.DS cs.CC cs.DM</categories><comments>19 pages. A simpler proof of the results of this paper appears in
  http://arxiv.org/abs/1207.0835. This new paper contains additional results</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that problems which have finite integer index and satisfy a
requirement we call treewidth-bounding admit linear kernels on the class of
$H$-topological-minor free graphs, for an arbitrary fixed graph $H$. This
builds on earlier results by Fomin et al.\ on linear kernels for $H$-minor-free
graphs and by Bodlaender et al.\ on graphs of bounded genus. Our framework
encompasses several problems, the prominent ones being Chordal Vertex Deletion,
Feedback Vertex Set and Edge Dominating Set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2788</identifier>
 <datestamp>2012-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2788</id><created>2012-01-13</created><authors><author><keyname>Britton</keyname><forenames>Tom</forenames></author><author><keyname>Trapman</keyname><forenames>Pieter</forenames></author></authors><title>Inferring global network properties from egocentric data with
  applications to epidemics</title><categories>cs.SI math.PR physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Social networks are rarely observed in full detail. In many situations
properties are known for only a sample of the individuals in the network and it
is desirable to induce global properties of the full social network from this
&quot;egocentric&quot; network data. In the current paper we study a few different types
of egocentric data, and show what global network properties are consistent with
those egocentric data. Two global network properties are considered: the size
of the largest connected component in the network (the giant), and secondly,
the possible size of an epidemic outbreak taking place on the network, in which
transmission occurs only between network neighbours, and with probability $p$.
The main conclusion is that in most cases, egocentric data allow for a large
range of possible sizes of the giant and the outbreak. However, there is an
upper bound for the latter. For the case that the network is selected uniformly
among networks with prescribed egocentric data (satisfying some conditions),
the asymptotic size of the giant and the outbreak is characterised.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2823</identifier>
 <datestamp>2012-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2823</id><created>2012-01-13</created><authors><author><keyname>Jiangao</keyname><forenames>Zhang</forenames></author><author><keyname>Weitao</keyname><forenames>Wang</forenames></author></authors><title>Event Space Theory and Its Application</title><categories>cs.SE</categories><comments>10 pages, 1 figure, 1 appendix</comments><acm-class>D.2.1</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In this paper, the basic ideal of the Event Space Theory and Analyzing Events
are expatiated on. Then it is suggested that how to set up event base library
in developing application software. Based above the designing principle of
facing methodology. Finally, in order to explain how to apply the Event Space
Theory in developing economic evaluation software, the software of &quot;sewage
treatment CAD&quot; in a national &quot;8th-Five Year Plan Research Project&quot; of PRC is
used as an example. This software concerns economic effectiveness evaluation
for construction projects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2829</identifier>
 <datestamp>2012-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2829</id><created>2012-01-13</created><updated>2012-04-09</updated><authors><author><keyname>Chatterjee</keyname><forenames>Krishnendu</forenames></author><author><keyname>Velner</keyname><forenames>Yaron</forenames></author></authors><title>Mean-Payoff Pushdown Games</title><categories>cs.LO cs.FL cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Two-player games on graphs is central in many problems in formal verification
and program analysis such as synthesis and verification of open systems. In
this work we consider solving recursive game graphs (or pushdown game graphs)
that can model the control flow of sequential programs with recursion. While
pushdown games have been studied before with qualitative objectives, such as
reachability and $\omega$-regular objectives, in this work we study for the
first time such games with the most well-studied quantitative objective,
namely, mean-payoff objectives. In pushdown games two types of strategies are
relevant: (1) global strategies, that depend on the entire global history; and
(2) modular strategies, that have only local memory and thus does not depend on
the context of invocation, but only on the history of the current invocation of
the module. Our main results are as follows (1) One-player pushdown games with
mean-payoff objectives under global strategies is decidable in polynomial time.
(2) Two-player pushdown games with mean-payoff objectives under global
strategies is undecidable. (3) One-player pushdown games with mean-payoff
objectives under modular strategies is NP-hard. (4) Two-player pushdown games
with mean-payoff objectives under modular strategies can be solved in NP (i.e.,
both one-player and two-player pushdown games with mean-payoff objectives under
modular strategies is NP-complete). We also establish the optimal strategy
complexity showing that global strategies for mean-payoff objectives require
infinite memory even in one-player pushdown games; and memoryless modular
strategies are sufficient in two-player pushdown games. Finally we also show
that all the problems have the same complexity if the stack boundedness
condition is added, where along with the mean-payoff objective the player must
also ensure that the stack height is bounded.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2834</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2834</id><created>2012-01-13</created><updated>2012-06-30</updated><authors><author><keyname>Chatterjee</keyname><forenames>Krishnendu</forenames></author><author><keyname>de Alfaro</keyname><forenames>Luca</forenames></author><author><keyname>Henzinger</keyname><forenames>Thomas A.</forenames></author></authors><title>Strategy Improvement for Concurrent Reachability and Safety Games</title><categories>cs.GT</categories><comments>arXiv admin note: substantial text overlap with arXiv:0804.4530 and
  arXiv:0809.4017</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider concurrent games played on graphs. At every round of a game, each
player simultaneously and independently selects a move; the moves jointly
determine the transition to a successor state. Two basic objectives are the
safety objective to stay forever in a given set of states, and its dual, the
reachability objective to reach a given set of states. First, we present a
simple proof of the fact that in concurrent reachability games, for all
$\epsilon&gt;0$, memoryless $\epsilon$-optimal strategies exist. A memoryless
strategy is independent of the history of plays, and an $\epsilon$-optimal
strategy achieves the objective with probability within $\epsilon$ of the value
of the game. In contrast to previous proofs of this fact, our proof is more
elementary and more combinatorial. Second, we present a strategy-improvement
(a.k.a.\ policy-iteration) algorithm for concurrent games with reachability
objectives. We then present a strategy-improvement algorithm for concurrent
games with safety objectives. Our algorithms yield sequences of player-1
strategies which ensure probabilities of winning that converge monotonically to
the value of the game. Our result is significant because the
strategy-improvement algorithm for safety games provides, for the first time, a
way to approximate the value of a concurrent safety game from below. Previous
methods could approximate the values of these games only from one direction,
and as no rates of convergence are known, they did not provide a practical way
to solve these games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2843</identifier>
 <datestamp>2012-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2843</id><created>2012-01-13</created><authors><author><keyname>Mayiami</keyname><forenames>Mahmoud Ramezani</forenames></author><author><keyname>Seyfe</keyname><forenames>Babak</forenames></author></authors><title>Nonparametric Sparse Representation</title><categories>cs.CV</categories><comments>4 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper suggests a nonparametric scheme to find the sparse solution of the
underdetermined system of linear equations in the presence of unknown impulsive
or non-Gaussian noise. This approach is robust against any variations of the
noise model and its parameters. It is based on minimization of rank pseudo norm
of the residual signal and l_1-norm of the signal of interest, simultaneously.
We use the steepest descent method to find the sparse solution via an iterative
algorithm. Simulation results show that our proposed method outperforms the
existence methods like OMP, BP, Lasso, and BCS whenever the observation vector
is contaminated with measurement or environmental non-Gaussian noise with
unknown parameters. Furthermore, for low SNR condition, the proposed method has
better performance in the presence of Gaussian noise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2845</identifier>
 <datestamp>2012-04-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2845</id><created>2012-01-13</created><updated>2012-04-03</updated><authors><author><keyname>Rutishauser</keyname><forenames>Ueli</forenames></author><author><keyname>Slotine</keyname><forenames>Jean-Jacques</forenames></author><author><keyname>Douglas</keyname><forenames>Rodney J.</forenames></author></authors><title>Competition through selective inhibitory synchrony</title><categories>q-bio.NC cs.NE</categories><comments>in press at Neural computation; 4 figures</comments><journal-ref>Neural computation (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Models of cortical neuronal circuits commonly depend on inhibitory feedback
to control gain, provide signal normalization, and to selectively amplify
signals using winner-take-all (WTA) dynamics. Such models generally assume that
excitatory and inhibitory neurons are able to interact easily, because their
axons and dendrites are co-localized in the same small volume. However,
quantitative neuroanatomical studies of the dimensions of axonal and dendritic
trees of neurons in the neocortex show that this co-localization assumption is
not valid. In this paper we describe a simple modification to the WTA circuit
design that permits the effects of distributed inhibitory neurons to be coupled
through synchronization, and so allows a single WTA to be distributed widely in
cortical space, well beyond the arborization of any single inhibitory neuron,
and even across different cortical areas. We prove by non-linear contraction
analysis, and demonstrate by simulation that distributed WTA sub-systems
combined by such inhibitory synchrony are inherently stable. We show
analytically that synchronization is substantially faster than winner
selection. This circuit mechanism allows networks of independent WTAs to fully
or partially compete with each other.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2859</identifier>
 <datestamp>2012-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2859</id><created>2012-01-13</created><updated>2012-10-31</updated><authors><author><keyname>Dai</keyname><forenames>Bin</forenames></author><author><keyname>Vinck</keyname><forenames>A. J. Han</forenames></author><author><keyname>Zhuang</keyname><forenames>Zhuojun</forenames></author><author><keyname>Luo</keyname><forenames>Yuan</forenames></author></authors><title>Degraded Broadcast Channel with Side Information, Confidential Messages
  and Noiseless Feedback</title><categories>cs.IT math.IT</categories><comments>Part of this paper has been accepted by ISIT2012, and this paper is
  submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, first, we investigate the model of degraded broadcast channel
with side information and confidential messages. This work is from Steinberg's
work on the degraded broadcast channel with causal and noncausal side
information, and Csisz$\acute{a}$r-K\&quot;{o}rner's work on broadcast channel with
confidential messages. Inner and outer bounds on the capacity-equivocation
regions are provided for the noncausal and causal cases. Superposition coding
and double-binning technique are used in the corresponding achievability
proofs.
  Then, we investigate the degraded broadcast channel with side information,
confidential messages and noiseless feedback. The noiseless feedback is from
the non-degraded receiver to the channel encoder. Inner and outer bounds on the
capacity-equivocation region are provided for the noncausal case, and the
capacity-equivocation region is determined for the causal case. Compared with
the model without feedback, we find that the noiseless feedback helps to
enlarge the inner bounds for both causal and noncausal cases. In the
achievability proof of the feedback model, the noiseless feedback is used as a
secret key shared by the non-degraded receiver and the transmitter, and
therefore, the code construction for the feedback model is a combination of
superposition coding, Gel'fand-Pinsker's binning, block Markov coding and
Ahlswede-Cai's secret key on the feedback system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2868</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2868</id><created>2012-01-13</created><authors><author><keyname>Lin</keyname><forenames>Shih-Chun</forenames></author><author><keyname>Lin</keyname><forenames>Pin-Hsun</forenames></author></authors><title>On Ergodic Secrecy Capacity of Multiple Input Wiretap Channel with
  Statistical CSIT</title><categories>cs.IT math.IT</categories><comments>Submitted IEEE Communication letters</comments><doi>10.1109/TIFS.2012.2233735</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the secure transmission in ergodic fast-Rayleigh fading
multiple-input single-output single-antennaeavesdropper (MISOSE) wiretap
channels. We assume that the statistics of both the legitimate and eavesdropper
channels is the only available channel state information at the transmitter
(CSIT). By introducing a new secrecy capacity upper bound, we prove that the
secrecy capacity is achieved by Gaussian input without prefixing. To attain
this, we form another MISOSE channel for upper-bounding, and tighten the bound
by finding the worst correlations between the legitimate and eavesdropper
channel coefficients. The resulting upper bound is tighter than the others in
the literature which are based on modifying the correlation between the noises
at the legitimate receiver and eavesdropper. Next, we fully characterize the
ergodic secrecy capacity by showing that the optimal channel input covariance
matrix is a scaled identity matrix, with the transmit power allocated uniformly
among the antennas. The key to solve such a complicated stochastic optimization
problem is by exploiting the completely monotone property of the ergodic
secrecy capacity to use the stochastic ordering theory. Finally, our simulation
results show that for the considered channel setting, the secrecy capacity is
bounded in both the high signal-to-noise ratio and large number of transmit
antenna regimes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2878</identifier>
 <datestamp>2013-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2878</id><created>2012-01-13</created><authors><author><keyname>Cangiani</keyname><forenames>Andrea</forenames></author><author><keyname>Chapman</keyname><forenames>John</forenames></author><author><keyname>Georgoulis</keyname><forenames>Emmanuil</forenames></author><author><keyname>Jensen</keyname><forenames>Max</forenames></author></authors><title>Implementation of the Continuous-Discontinuous Galerkin Finite Element
  Method</title><categories>math.NA cs.NA</categories><comments>Enumath 2011</comments><doi>10.1007/978-3-642-33134-3_34</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For the stationary advection-diffusion problem the standard continuous
Galerkin method is unstable without some additional control on the mesh or
method. The interior penalty discontinuous Galerkin method is stable but at the
expense of an increased number of degrees of freedom. The hybrid method
proposed in [5] combines the computational complexity of the continuous method
with the stability of the discontinuous method without a significant increase
in degrees of freedom. We discuss the implementation of this method using the
finite element library deal.ii and present some numerical experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2892</identifier>
 <datestamp>2012-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2892</id><created>2012-01-13</created><authors><author><keyname>Ahmadi</keyname><forenames>Amir Ali</forenames></author></authors><title>Algebraic Relaxations and Hardness Results in Polynomial Optimization
  and Lyapunov Analysis</title><categories>math.OC cs.CC cs.DS</categories><comments>PhD Thesis, MIT, September, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This thesis settles a number of questions related to computational complexity
and algebraic, semidefinite programming based relaxations in optimization and
control.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2902</identifier>
 <datestamp>2012-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2902</id><created>2012-01-13</created><authors><author><keyname>George</keyname><forenames>Marian</forenames></author><author><keyname>Youssef</keyname><forenames>Moustafa</forenames></author></authors><title>Acoustical Quality Assessment of the Classroom Environment</title><categories>cs.LG</categories><comments>7 pages, technical report</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Teaching is one of the most important factors affecting any education system.
Many research efforts have been conducted to facilitate the presentation modes
used by instructors in classrooms as well as provide means for students to
review lectures through web browsers. Other studies have been made to provide
acoustical design recommendations for classrooms like room size and
reverberation times. However, using acoustical features of classrooms as a way
to provide education systems with feedback about the learning process was not
thoroughly investigated in any of these studies. We propose a system that
extracts different sound features of students and instructors, and then uses
machine learning techniques to evaluate the acoustical quality of any learning
environment. We infer conclusions about the students' satisfaction with the
quality of lectures. Using classifiers instead of surveys and other subjective
ways of measures can facilitate and speed such experiments which enables us to
perform them continuously. We believe our system enables education systems to
continuously review and improve their teaching strategies and acoustical
quality of classrooms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2905</identifier>
 <datestamp>2012-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2905</id><created>2012-01-13</created><updated>2012-01-15</updated><authors><author><keyname>Qiyang</keyname><forenames>Zhao</forenames></author></authors><title>NegCut: Automatic Image Segmentation based on MRF-MAP</title><categories>cs.CV</categories><comments>Since it's an unlucky failure about length-limit violation, I'd like
  to save it on arXiv as a record. Any suggestions are welcome</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Solving the Maximum a Posteriori on Markov Random Field, MRF-MAP, is a
prevailing method in recent interactive image segmentation tools. Although
mathematically explicit in its computational targets, and impressive for the
segmentation quality, MRF-MAP is hard to accomplish without the interactive
information from users. So it is rarely adopted in the automatic style up to
today. In this paper, we present an automatic image segmentation algorithm,
NegCut, based on the approximation to MRF-MAP. First we prove MRF-MAP is
NP-hard when the probabilistic models are unknown, and then present an
approximation function in the form of minimum cuts on graphs with negative
weights. Finally, the binary segmentation is taken from the largest eigenvector
of the target matrix, with a tuned version of the Lanczos eigensolver. It is
shown competitive at the segmentation quality in our experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2906</identifier>
 <datestamp>2012-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2906</id><created>2012-01-13</created><updated>2012-05-01</updated><authors><author><keyname>Wilde</keyname><forenames>Mark M.</forenames></author><author><keyname>Renes</keyname><forenames>Joseph M.</forenames></author></authors><title>Quantum polar codes for arbitrary channels</title><categories>quant-ph cs.IT math.IT</categories><comments>9 pages, submission to the 2012 International Symposium on
  Information Theory (ISIT 2012), Boston, MA, USA; v2: minor changes and
  accepted for conference</comments><journal-ref>Proceedings of the 2012 IEEE International Symposium on
  Information Theory (ISIT 2012), pages 334-338, Cambridge, MA, USA</journal-ref><doi>10.1109/ISIT.2012.6284203</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We construct a new entanglement-assisted quantum polar coding scheme which
achieves the symmetric coherent information rate by synthesizing &quot;amplitude&quot;
and &quot;phase&quot; channels from a given, arbitrary quantum channel. We first
demonstrate the coding scheme for arbitrary quantum channels with qubit inputs,
and we show that quantum data can be reliably decoded by O(N) rounds of
coherent quantum successive cancellation, followed by N controlled-NOT gates
(where N is the number of channel uses). We also find that the entanglement
consumption rate of the code vanishes for degradable quantum channels. Finally,
we extend the coding scheme to channels with multiple qubit inputs. This gives
a near-explicit method for realizing one of the most striking phenomena in
quantum information theory: the superactivation effect, whereby two quantum
channels which individually have zero quantum capacity can have a non-zero
quantum capacity when used together.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2918</identifier>
 <datestamp>2012-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2918</id><created>2012-01-13</created><updated>2012-11-09</updated><authors><author><keyname>Xu</keyname><forenames>Jie</forenames></author><author><keyname>van der Schaar</keyname><forenames>Mihaela</forenames></author></authors><title>Social Norm Design for Information Exchange Systems with Limited
  Observations</title><categories>cs.GT</categories><comments>24 pages, 9 figures</comments><msc-class>91A80</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Information exchange systems differ in many ways, but all share a common
vulnerability to selfish behavior and free-riding. In this paper, we build
incentives schemes based on social norms. Social norms prescribe a social
strategy for the users in the system to follow and deploy reputation schemes to
reward or penalize users depending on their behaviors. Because users in these
systems often have only limited capability to observe the global system
information, e.g. the reputation distribution of the users participating in the
system, their beliefs about the reputation distribution are heterogeneous and
biased. Such belief heterogeneity causes a positive fraction of users to not
follow the social strategy. In such practical scenarios, the standard
equilibrium analysis deployed in the economics literature is no longer directly
applicable and hence, the system design needs to consider these differences. To
investigate how the system designs need to change when the participating users
have only limited observations, we focus on a simple social norm with binary
reputation labels but allow adjusting the punishment severity through
randomization. First, we model the belief heterogeneity using a suitable
Bayesian belief function. Next, we formalize the users' optimal decision
problems and derive in which scenarios they follow the prescribed social
strategy. With this result, we then study the system dynamics and formally
define equilibrium in the sense that the system is stable when users
strategically optimize their decisions. By rigorously studying two specific
cases where users' belief distribution is constant or is linearly influenced by
the true reputation distribution, we prove that the optimal reputation update
rule is to choose the mildest possible punishment. This result is further
confirmed for higher order beliefs in simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2925</identifier>
 <datestamp>2012-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2925</id><created>2012-01-13</created><updated>2012-03-12</updated><authors><author><keyname>Manjunatha</keyname><forenames>Geetha</forenames></author><author><keyname>Murty</keyname><forenames>M Narasimha</forenames></author><author><keyname>Sitaram</keyname><forenames>Dinkar</forenames></author></authors><title>Combining Heterogeneous Classifiers for Relational Databases</title><categories>cs.LG cs.DB</categories><comments>Withdrawn - as that was a trial upload only. Non public information</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Most enterprise data is distributed in multiple relational databases with
expert-designed schema. Using traditional single-table machine learning
techniques over such data not only incur a computational penalty for converting
to a 'flat' form (mega-join), even the human-specified semantic information
present in the relations is lost. In this paper, we present a practical,
two-phase hierarchical meta-classification algorithm for relational databases
with a semantic divide and conquer approach. We propose a recursive, prediction
aggregation technique over heterogeneous classifiers applied on individual
database tables. The proposed algorithm was evaluated on three diverse
datasets, namely TPCH, PKDD and UCI benchmarks and showed considerable
reduction in classification time without any loss of prediction accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2931</identifier>
 <datestamp>2013-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2931</id><created>2012-01-13</created><updated>2013-11-08</updated><authors><author><keyname>Jurman</keyname><forenames>Giuseppe</forenames></author><author><keyname>Visintainer</keyname><forenames>Roberto</forenames></author><author><keyname>Filosi</keyname><forenames>Michele</forenames></author><author><keyname>Riccadonna</keyname><forenames>Samantha</forenames></author><author><keyname>Furlanello</keyname><forenames>Cesare</forenames></author></authors><title>The HIM glocal metric and kernel for network comparison and
  classification</title><categories>math.CO cs.SI physics.soc-ph</categories><comments>Frontiers of Network Analysis: Methods, Models, and Applications -
  NIPS 2013 Workshop</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to the ever rising importance of the network paradigm across several
areas of science, comparing and classifying graphs represent essential steps in
the networks analysis of complex systems. Both tasks have been recently tackled
via quite different strategies, even tailored ad-hoc for the investigated
problem. Here we deal with both operations by introducing the
Hamming-Ipsen-Mikhailov (HIM) distance, a novel metric to quantitatively
measure the difference between two graphs sharing the same vertices. The new
measure combines the local Hamming distance and the global spectral
Ipsen-Mikhailov distance so to overcome the drawbacks affecting the two
components separately. Building then the HIM kernel function derived from the
HIM distance it is possible to move from network comparison to network
classification via the Support Vector Machine (SVM) algorithm. Applications of
HIM distance and HIM kernel in computational biology and social networks
science demonstrate the effectiveness of the proposed functions as a general
purpose solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2934</identifier>
 <datestamp>2012-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2934</id><created>2012-01-13</created><authors><author><keyname>Li</keyname><forenames>Qiao</forenames></author><author><keyname>Cui</keyname><forenames>Tao</forenames></author><author><keyname>Weng</keyname><forenames>Yang</forenames></author><author><keyname>Negi</keyname><forenames>Rohit</forenames></author><author><keyname>Franchetti</keyname><forenames>Franz</forenames></author><author><keyname>Ilic</keyname><forenames>Marija D.</forenames></author></authors><title>An Information-Theoretic Approach to PMU Placement in Electric Power
  Systems</title><categories>math.OC cs.DS cs.IT math.IT</categories><comments>8 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an information-theoretic approach to address the phasor
measurement unit (PMU) placement problem in electric power systems. Different
from the conventional 'topological observability' based approaches, this paper
advocates a much more refined, information-theoretic criterion, namely the
mutual information (MI) between the PMU measurements and the power system
states. The proposed MI criterion can not only include the full system
observability as a special case, but also can rigorously model the remaining
uncertainties in the power system states with PMU measurements, so as to
generate highly informative PMU configurations. Further, the MI criterion can
facilitate robust PMU placement by explicitly modeling probabilistic PMU
outages. We propose a greedy PMU placement algorithm, and show that it achieves
an approximation ratio of (1-1/e) for any PMU placement budget. We further show
that the performance is the best that one can achieve in practice, in the sense
that it is NP-hard to achieve any approximation ratio beyond (1-1/e). Such
performance guarantee makes the greedy algorithm very attractive in the
practical scenario of multi-stage installations for utilities with limited
budgets. Finally, simulation results demonstrate near-optimal performance of
the proposed PMU placement algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2936</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2936</id><created>2012-01-13</created><authors><author><keyname>Tzeng</keyname><forenames>Stanley</forenames></author><author><keyname>Owens</keyname><forenames>John D.</forenames></author></authors><title>Finding Convex Hulls Using Quickhull on the GPU</title><categories>cs.CG cs.DS cs.GR</categories><comments>11 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a convex hull algorithm that is accelerated on commodity graphics
hardware. We analyze and identify the hurdles of writing a recursive divide and
conquer algorithm on the GPU and divise a framework for representing this class
of problems. Our framework transforms the recursive splitting step into a
permutation step that is well-suited for graphics hardware. Our convex hull
algorithm of choice is Quickhull. Our parallel Quickhull implementation (for
both 2D and 3D cases) achieves an order of magnitude speedup over standard
computational geometry libraries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2937</identifier>
 <datestamp>2012-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2937</id><created>2012-01-13</created><authors><author><keyname>Jaafar</keyname><forenames>Wael</forenames></author><author><keyname>Ajib</keyname><forenames>Wessam</forenames></author><author><keyname>Haccoun</keyname><forenames>David</forenames></author></authors><title>Opportunistic Adaptive Relaying in Cognitive Radio Networks</title><categories>cs.NI</categories><comments>5 pages, 4 figures. Accepted for publication in Proc. IEEE
  International Communications Conference (ICC), Ottawa (ON), Canada, June 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Combining cognitive radio technology with user cooperation could be
advantageous to both primary and secondary transmissions. In this paper, we
propose a first relaying scheme for cognitive radio networks (called &quot;Adaptive
relaying scheme 1&quot;), where one relay node can assist the primary or the
secondary transmission with the objective of improving the outage probability
of the secondary transmission with respect to a primary outage probability
threshold. Upper bound expressions of the secondary outage probability using
the proposed scheme are derived over Rayleigh fading channels. Numerical and
simulation results show that the secondary outage probability using the
proposed scheme is lower than that of other relaying schemes. Then, we extend
the proposed scheme to the case where the relay node has the ability to decode
both the primary and secondary signals and also can assist simultaneously both
transmissions. Simulations show the performance improvement that can be
obtained due to this extension in terms of secondary outage probability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2953</identifier>
 <datestamp>2012-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2953</id><created>2012-01-13</created><updated>2012-06-14</updated><authors><author><keyname>Bradonji&#x107;</keyname><forenames>Milan</forenames></author><author><keyname>Saniee</keyname><forenames>Iraj</forenames></author></authors><title>Bootstrap Percolation on Random Geometric Graphs</title><categories>math.PR cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bootstrap percolation has been used effectively to model phenomena as diverse
as emergence of magnetism in materials, spread of infection, diffusion of
software viruses in computer networks, adoption of new technologies, and
emergence of collective action and cultural fads in human societies. It is
defined on an (arbitrary) network of interacting agents whose state is
determined by the state of their neighbors according to a threshold rule. In a
typical setting, bootstrap percolation starts by random and independent
&quot;activation&quot; of nodes with a fixed probability $p$, followed by a deterministic
process for additional activations based on the density of active nodes in each
neighborhood ($\theta$ activated nodes). Here, we study bootstrap percolation
on random geometric graphs in the regime when the latter are (almost surely)
connected. Random geometric graphs provide an appropriate model in settings
where the neighborhood structure of each node is determined by geographical
distance, as in wireless {\it ad hoc} and sensor networks as well as in
contagion. We derive bounds on the critical thresholds $p_c', p_c&quot;$ such that
for all $p &gt; p&quot;_c(\theta)$ full percolation takes place, whereas for $p &lt;
p'_c(\theta)$ it does not. We conclude with simulations that compare numerical
thresholds with those obtained analytically.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2956</identifier>
 <datestamp>2014-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2956</id><created>2012-01-13</created><updated>2014-05-18</updated><authors><author><keyname>Perrinel</keyname><forenames>Matthieu</forenames></author></authors><title>On paths-based criteria for polynomial time complexity in proof-nets</title><categories>cs.LO</categories><comments>Long version of a conference paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Girard's Light linear logic (LLL) characterized polynomial time in the
proof-as-program paradigm with a bound on cut elimination. This logic relied on
a stratification principle and a &quot;one-door&quot; principle which were generalized
later respectively in the systems L^4 and L^3a. Each system was brought with
its own complex proof of Ptime soundness.
  In this paper we propose a broad sufficient criterion for Ptime soundness for
linear logic subsystems, based on the study of paths inside the proof-nets,
which factorizes proofs of soundness of existing systems and may be used for
future systems. As an additional gain, our bound stands for any reduction
strategy whereas most bounds in the literature only stand for a particular
strategy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2969</identifier>
 <datestamp>2012-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2969</id><created>2012-01-13</created><authors><author><keyname>Al-Naymat</keyname><forenames>Ghazi</forenames></author><author><keyname>Chawla</keyname><forenames>Sanjay</forenames></author><author><keyname>Taheri</keyname><forenames>Javid</forenames></author></authors><title>SparseDTW: A Novel Approach to Speed up Dynamic Time Warping</title><categories>cs.DB cs.DS</categories><comments>17 pages</comments><journal-ref>Al-Naymat, G., S. Chawla, and J. Taheri, &quot;SparseDTW: A Novel
  Approach to Speed up Dynamic Time Warping&quot;, The 2009 Australasian Data
  Mining, vol. 101, Melbourne, Australia, ACM Digital Library, pp. 117-127,
  12/2009</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  We present a new space-efficient approach, (SparseDTW), to compute the
Dynamic Time Warping (DTW) distance between two time series that always yields
the optimal result. This is in contrast to other known approaches which
typically sacrifice optimality to attain space efficiency. The main idea behind
our approach is to dynamically exploit the existence of similarity and/or
correlation between the time series. The more the similarity between the time
series the less space required to compute the DTW between them. To the best of
our knowledge, all other techniques to speedup DTW, impose apriori constraints
and do not exploit similarity characteristics that may be present in the data.
We conduct experiments and demonstrate that SparseDTW outperforms previous
approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2980</identifier>
 <datestamp>2012-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2980</id><created>2012-01-13</created><authors><author><keyname>Guan</keyname><forenames>Xuechong</forenames></author><author><keyname>Li</keyname><forenames>Yongming</forenames></author></authors><title>Information algebra system of soft sets</title><categories>cs.IT math.IT</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Information algebra is algebraic structure for local computation and
inference. Given an initial universe set and a parameter set, we show that a
soft set system over them is an information algebra. Moreover, in a soft set
system, the family of all soft sets with a finite parameter subset can form a
compact information algebra.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2984</identifier>
 <datestamp>2012-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2984</id><created>2012-01-13</created><authors><author><keyname>Xing</keyname><forenames>Chengwen</forenames></author><author><keyname>Ma</keyname><forenames>Shaodan</forenames></author><author><keyname>Fei</keyname><forenames>Zesong</forenames></author><author><keyname>Wu</keyname><forenames>Yik-Chung</forenames></author><author><keyname>Kuang</keyname><forenames>Jingming</forenames></author></authors><title>Joint Robust Weighted LMMSE Transceiver Design for Dual-Hop AF
  Multiple-Antenna Relay Systems</title><categories>cs.IT math.IT</categories><comments>5 Pages, 1 Figure</comments><journal-ref>IEEE Global Communications Conference (GlobeCom'2011), 2011, U.S.A</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, joint transceiver design for dual-hop amplify-and-forward (AF)
MIMO relay systems with Gaussian distributed channel estimation errors in both
two hops is investigated. Due to the fact that various linear transceiver
designs can be transformed to a weighted linear minimum mean-square-error
(LMMSE) transceiver design with specific weighting matrices, weighted mean
square error (MSE) is chosen as the performance metric. Precoder matrix at
source, forwarding matrix at relay and equalizer matrix at destination are
jointly designed with channel estimation errors taken care of by Bayesian
philosophy. Several existing algorithms are found to be special cases of the
proposed solution. The performance advantage of the proposed robust design is
demonstrated by the simulation results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2985</identifier>
 <datestamp>2012-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2985</id><created>2012-01-13</created><authors><author><keyname>Xing</keyname><forenames>Chengwen</forenames></author><author><keyname>Fei</keyname><forenames>Zesong</forenames></author><author><keyname>Wu</keyname><forenames>Yik-Chung</forenames></author><author><keyname>Ma</keyname><forenames>Shaodan</forenames></author><author><keyname>Kuang</keyname><forenames>Jingming</forenames></author></authors><title>Robust Transceiver Design for AF MIMO Relay Systems with Column
  Correlations</title><categories>cs.IT math.IT</categories><comments>6 Pages, 1 Figure</comments><journal-ref>IEEE ICSPCC 2011, Aug. 2011, Xi'An China</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate the robust transceiver design for dual-hop
amplify-and-forward (AF) MIMO relay systems with Gaussian distributed channel
estimation errors. Aiming at maximizing the mutual information under imperfect
channel state information (CSI), source precoder at source and forwarding
matrix at the relay are jointly optimized. Using some elegant attributes of
matrix-monotone functions, the structures of the optimal solutions are derived
first. Then based on the derived structure an iterative waterfilling solution
is proposed. Several existing algorithms are shown to be special cases of the
proposed solution. Finally, the effectiveness of the proposed robust design is
demonstrated by simulation results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2995</identifier>
 <datestamp>2012-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2995</id><created>2012-01-14</created><authors><author><keyname>Rajathilagam</keyname><forenames>B.</forenames></author><author><keyname>Rangarajan</keyname><forenames>Murali</forenames></author><author><keyname>Soman</keyname><forenames>K. P.</forenames></author></authors><title>G-Lets: Signal Processing Using Transformation Groups</title><categories>cs.CV</categories><comments>20 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an algorithm using transformation groups and their irreducible
representations to generate an orthogonal basis for a signal in the vector
space of the signal. It is shown that multiresolution analysis can be done with
amplitudes using a transformation group. G-lets is thus not a single transform,
but a group of linear transformations related by group theory. The algorithm
also specifies that a multiresolution and multiscale analysis for each
resolution is possible in terms of frequencies. Separation of low and high
frequency components of each amplitude resolution is facilitated by G-lets.
Using conjugacy classes of the transformation group, more than one set of basis
may be generated, giving a different perspective of the signal through each
basis. Applications for this algorithm include edge detection, feature
extraction, denoising, face recognition, compression, and more. We analyze this
algorithm using dihedral groups as an example. We demonstrate the results with
an ECG signal and the standard `Lena' image.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.2999</identifier>
 <datestamp>2012-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.2999</id><created>2012-01-14</created><authors><author><keyname>Kudekar</keyname><forenames>Shrinivas</forenames></author><author><keyname>Richardson</keyname><forenames>Tom</forenames></author><author><keyname>Urbanke</keyname><forenames>Ruediger</forenames></author></authors><title>Spatially Coupled Ensembles Universally Achieve Capacity under Belief
  Propagation</title><categories>cs.IT math.IT</categories><comments>50 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate spatially coupled code ensembles. For transmission over the
binary erasure channel, it was recently shown that spatial coupling increases
the belief propagation threshold of the ensemble to essentially the maximum
a-priori threshold of the underlying component ensemble. This explains why
convolutional LDPC ensembles, originally introduced by Felstrom and Zigangirov,
perform so well over this channel. We show that the equivalent result holds
true for transmission over general binary-input memoryless output-symmetric
channels. More precisely, given a desired error probability and a gap to
capacity, we can construct a spatially coupled ensemble which fulfills these
constraints universally on this class of channels under belief propagation
decoding. In fact, most codes in that ensemble have that property. The
quantifier universal refers to the single ensemble/code which is good for all
channels but we assume that the channel is known at the receiver. The key
technical result is a proof that under belief propagation decoding spatially
coupled ensembles achieve essentially the area threshold of the underlying
uncoupled ensemble. We conclude by discussing some interesting open problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3001</identifier>
 <datestamp>2012-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3001</id><created>2012-01-14</created><authors><author><keyname>Srivastava</keyname><forenames>Rachit</forenames></author><author><keyname>Kumar</keyname><forenames>Anurag</forenames></author></authors><title>Performance Analysis of Beacon-Less IEEE 802.15.4 Multi-Hop Networks</title><categories>cs.NI</categories><comments>Appeared in The Fourth International Conference on COMmunication
  Systems and NETworkS (COMSNETS), Bangalore, India, 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop an approximate analytical technique for evaluating the performance
of multi-hop networks based on beacon-less CSMA/CA as standardised in IEEE
802.15.4, a popular standard for wireless sensor networks. The network
comprises sensor nodes, which generate measurement packets, and relay nodes
which only forward packets. We consider a detailed stochastic process at each
node, and analyse this process taking into account the interaction with
neighbouring nodes via certain unknown variables (e.g., channel sensing rates,
collision probabilities, etc.). By coupling these analyses of the various
nodes, we obtain fixed point equations that can be solved numerically to obtain
the unknown variables, thereby yielding approximations of time average
performance measures, such as packet discard probabilities and average queueing
delays. Different analyses arise for networks with no hidden nodes and networks
with hidden nodes. We apply this approach to the performance analysis of tree
networks rooted at a data sink. Finally, we provide a validation of our
analysis technique against simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3011</identifier>
 <datestamp>2012-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3011</id><created>2012-01-14</created><authors><author><keyname>Kobourov</keyname><forenames>Stephen G.</forenames></author></authors><title>Spring Embedders and Force Directed Graph Drawing Algorithms</title><categories>cs.CG cs.DM cs.DS</categories><comments>23 pages, 8 figures</comments><acm-class>F.2.2; G.2.2; H.4.0; I.3.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Force-directed algorithms are among the most flexible methods for calculating
layouts of simple undirected graphs. Also known as spring embedders, such
algorithms calculate the layout of a graph using only information contained
within the structure of the graph itself, rather than relying on
domain-specific knowledge. Graphs drawn with these algorithms tend to be
aesthetically pleasing, exhibit symmetries, and tend to produce crossing-free
layouts for planar graphs. In this survey we consider several classical
algorithms, starting from Tutte's 1963 barycentric method, and including recent
scalable multiscale methods for large and dynamic graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3016</identifier>
 <datestamp>2012-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3016</id><created>2012-01-14</created><authors><author><keyname>Shcherbacov</keyname><forenames>Victor</forenames></author></authors><title>Quasigroup based crypto-algorithms</title><categories>math.GR cs.IT math.IT</categories><msc-class>94A60, 20N05, 20N15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modifications of Markovski quasigroup based crypto-algorithm have been
proposed. Some of these modifications are based on the systems of orthogonal
n-ary groupoids. T-quasigroups based stream ciphers have been constructed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3018</identifier>
 <datestamp>2012-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3018</id><created>2012-01-14</created><authors><author><keyname>Anam</keyname><forenames>Mohammad Ashraful</forenames></author><author><keyname>Andreopoulos</keyname><forenames>Yiannis</forenames></author></authors><title>Throughput Scaling Of Convolution For Error-Tolerant Multimedia
  Applications</title><categories>cs.MM</categories><comments>IEEE Trans. on Multimedia, 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Convolution and cross-correlation are the basis of filtering and pattern or
template matching in multimedia signal processing. We propose two throughput
scaling options for any one-dimensional convolution kernel in programmable
processors by adjusting the imprecision (distortion) of computation. Our
approach is based on scalar quantization, followed by two forms of tight
packing in floating-point (one of which is proposed in this paper) that allow
for concurrent calculation of multiple results. We illustrate how our approach
can operate as an optional pre- and post-processing layer for off-the-shelf
optimized convolution routines. This is useful for multimedia applications that
are tolerant to processing imprecision and for cases where the input signals
are inherently noisy (error tolerant multimedia applications). Indicative
experimental results with a digital music matching system and an MPEG-7 audio
descriptor system demonstrate that the proposed approach offers up to 175%
increase in processing throughput against optimized (full-precision)
convolution with virtually no effect in the accuracy of the results. Based on
marginal statistics of the input data, it is also shown how the throughput and
distortion can be adjusted per input block of samples under constraints on the
signal-to-noise ratio against the full-precision convolution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3019</identifier>
 <datestamp>2015-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3019</id><created>2012-01-14</created><authors><author><keyname>Gracia-Lazaro</keyname><forenames>Carlos</forenames></author><author><keyname>Cuesta</keyname><forenames>Jose A.</forenames></author><author><keyname>Sanchez</keyname><forenames>Angel</forenames></author><author><keyname>Moreno</keyname><forenames>Yamir</forenames></author></authors><title>Human behavior in Prisoner's Dilemma experiments suppresses network
  reciprocity</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><comments>5 Pages including 4 figures. Submitted for publication</comments><journal-ref>Scientific Reports 2, 325 (2012)</journal-ref><doi>10.1038/srep00325</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  During the last few years, much research has been devoted to strategic
interactions on complex networks. In this context, the Prisoner's Dilemma has
become a paradigmatic model, and it has been established that imitative
evolutionary dynamics lead to very different outcomes depending on the details
of the network. We here report that when one takes into account the real
behavior of people observed in the experiments, both at the mean-field level
and on utterly different networks the observed level of cooperation is the
same. We thus show that when human subjects interact in an heterogeneous mix
including cooperators, defectors and moody conditional cooperators, the
structure of the population does not promote or inhibit cooperation with
respect to a well mixed population.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3052</identifier>
 <datestamp>2012-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3052</id><created>2012-01-14</created><updated>2012-06-06</updated><authors><author><keyname>Dybiec</keyname><forenames>Bartlomiej</forenames></author><author><keyname>Mitarai</keyname><forenames>Namiko</forenames></author><author><keyname>Sneppen</keyname><forenames>Kim</forenames></author></authors><title>Information spreading and development of cultural centers</title><categories>physics.soc-ph cs.SI</categories><comments>7 pages, 5 figures</comments><journal-ref>Phys. Rev. E 85, 056116 (2012)</journal-ref><doi>10.1103/PhysRevE.85.056116</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The historical interplay between societies are governed by many factors,
including in particular spreading of languages, religion and other symbolic
traits. Cultural development, in turn, is coupled to emergence and maintenance
of information spreading. Strong centralized cultures exist thanks to attention
from their members, which faithfulness in turn relies on supply of information.
Here, we discuss a culture evolution model on a planar geometry that takes into
account aspects of the feedback between information spreading and its
maintenance. Features of model are highlighted by comparing it to cultural
spreading in ancient and medieval Europe, where it in particular suggests that
long lived centers should be located in geographically remote regions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3056</identifier>
 <datestamp>2012-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3056</id><created>2012-01-14</created><authors><author><keyname>Cao</keyname><forenames>Qian</forenames></author><author><keyname>Zhao</keyname><forenames>H. Vicky</forenames></author><author><keyname>Jing</keyname><forenames>Yindi</forenames></author></authors><title>Power Allocation and Pricing in Multi-User Relay Networks Using
  Stackelberg and Bargaining Games</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers a multi-user single-relay wireless network, where the
relay gets paid for helping the users forward signals, and the users pay to
receive the relay service. We study the relay power allocation and pricing
problems, and model the interaction between the users and the relay as a
two-level Stackelberg game. In this game, the relay, modeled as the service
provider and the leader of the game, sets the relay price to maximize its
revenue; while the users are modeled as customers and the followers who buy
power from the relay for higher transmission rates. We use a bargaining game to
model the negotiation among users to achieve a fair allocation of the relay
power. Based on the proposed fair relay power allocation rule, the optimal
relay power price that maximizes the relay revenue is derived analytically.
Simulation shows that the proposed power allocation scheme achieves higher
network sum-rate and relay revenue than the even power allocation. Furthermore,
compared with the sum-rate-optimal solution, simulation shows that the proposed
scheme achieves better fairness with comparable network sum-rate for a wide
range of network scenarios. The proposed pricing and power allocation solutions
are also shown to be consistent with the laws of supply and demand.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3059</identifier>
 <datestamp>2012-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3059</id><created>2012-01-15</created><authors><author><keyname>Wang</keyname><forenames>Feng</forenames></author><author><keyname>Huang</keyname><forenames>Jianwei</forenames></author><author><keyname>Zhao</keyname><forenames>Yuping</forenames></author></authors><title>Delay Sensitive Communications over Cognitive Radio Networks</title><categories>cs.SY cs.NI</categories><comments>11 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Supporting the quality of service of unlicensed users in cognitive radio
networks is very challenging, mainly due to dynamic resource availability
because of the licensed users' activities. In this paper, we study the optimal
admission control and channel allocation decisions in cognitive overlay
networks in order to support delay sensitive communications of unlicensed
users. We formulate it as a Markov decision process problem, and solve it by
transforming the original formulation into a stochastic shortest path problem.
We then propose a simple heuristic control policy, which includes a
threshold-based admission control scheme and and a largest-delay-first channel
allocation scheme, and prove the optimality of the largest-delay-first channel
allocation scheme. We further propose an improved policy using the rollout
algorithm. By comparing the performance of both proposed policies with the
upper-bound of the maximum revenue, we show that our policies achieve
close-to-optimal performance with low complexities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3060</identifier>
 <datestamp>2014-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3060</id><created>2012-01-15</created><updated>2014-04-28</updated><authors><author><keyname>Ghorbani</keyname><forenames>E.</forenames></author><author><keyname>Mohammadian</keyname><forenames>A.</forenames></author><author><keyname>Tayfeh-Rezaie</keyname><forenames>B.</forenames></author></authors><title>On Order and Rank of Graphs</title><categories>math.CO cs.IT math.IT</categories><comments>Final version, to appear in Combinatorica</comments><msc-class>05C50, 15A03</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The rank of a graph is defined to be the rank of its adjacency matrix. A
graph is called reduced if it has no isolated vertices and no two vertices with
the same set of neighbors. Akbari, Cameron, and Khosrovshahi conjectured that
the number of vertices of every reduced graph of rank r is at most
$m(r)=2^{(r+2)/2}-2$ if r is even and $m(r) = 5\cdot2^{(r-3)/2}-2$ if r is odd.
In this article, we prove that if the conjecture is not true, then there would
be a counterexample of rank at most $46$. We also show that every reduced graph
of rank r has at most $8m(r)+14$ vertices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3066</identifier>
 <datestamp>2012-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3066</id><created>2012-01-15</created><authors><author><keyname>Lim</keyname><forenames>Sungsu</forenames></author><author><keyname>Jung</keyname><forenames>Kyomin</forenames></author><author><keyname>Andrews</keyname><forenames>Matthew</forenames></author></authors><title>Stability of the Max-Weight Protocol in Adversarial Wireless Networks</title><categories>cs.NI</categories><comments>Accepted by IEEE INFOCOM 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider the Max-Weight protocol for routing and scheduling
in wireless networks under an adversarial model. This protocol has received a
significant amount of attention dating back to the papers of Tassiulas and
Ephremides. In particular, this protocol is known to be throughput-optimal
whenever the traffic patterns and propagation conditions are governed by a
stationary stochastic process.
  However, the standard proof of throughput optimality (which is based on the
negative drift of a quadratic potential function) does not hold when the
traffic patterns and the edge capacity changes over time are governed by an
arbitrary adversarial process. Such an environment appears frequently in many
practical wireless scenarios when the assumption that channel conditions are
governed by a stationary stochastic process does not readily apply.
  In this paper we prove that even in the above adversarial setting, the
Max-Weight protocol keeps the queues in the network stable (i.e. keeps the
queue sizes bounded) whenever this is feasible by some routing and scheduling
algorithm. However, the proof is somewhat more complex than the negative
potential drift argument that applied in the stationary case. Our proof holds
for any arbitrary interference relationships among edges. We also prove the
stability of $\ep$-approximate Max-Weight under the adversarial model. We
conclude the paper with a discussion of queue sizes in the adversarial model as
well as a set of simulation results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3068</identifier>
 <datestamp>2012-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3068</id><created>2012-01-15</created><authors><author><keyname>Vanclay</keyname><forenames>Jerome K.</forenames></author><author><keyname>Bornmann</keyname><forenames>Lutz</forenames></author></authors><title>Metrics to evaluate research performance in academic institutions: A
  critique of ERA 2010 as applied in forestry and the indirect H2 index as a
  possible alternative</title><categories>cs.DL</categories><comments>19 pages, 6 figures, 7 tables, appendices</comments><journal-ref>Scientometrics 91(3):751-771 (2012)</journal-ref><doi>10.1007/s11192-012-0618-8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Excellence for Research in Australia (ERA) is an attempt by the Australian
Research Council to rate Australian universities on a 5-point scale within 180
Fields of Research using metrics and peer evaluation by an evaluation
committee. Some of the bibliometric data contributing to this ranking suffer
statistical issues associated with skewed distributions. Other data are
standardised year-by-year, placing undue emphasis on the most recent
publications which may not yet have reliable citation patterns. The
bibliometric data offered to the evaluation committees is extensive, but lacks
effective syntheses such as the h-index and its variants. The indirect H2 index
is objective, can be computed automatically and efficiently, is resistant to
manipulation, and a good indicator of impact to assist the ERA evaluation
committees and to similar evaluations internationally.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3073</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3073</id><created>2012-01-15</created><authors><author><keyname>Martin</keyname><forenames>Sylvain</forenames></author><author><keyname>Chiarello</keyname><forenames>Laurent</forenames></author><author><keyname>Leduc</keyname><forenames>Guy</forenames></author></authors><title>DISco: a Distributed Information Store for network Challenges and their
  Outcome</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present DISco, a storage and communication middleware designed to enable
distributed and task-centric autonomic control of networks.
  DISco is designed to enable multi-agent identification of anomalous
situations -- so-called &quot;challenges&quot; -- and assist coordinated remediation that
maintains degraded -- but acceptable -- service level, while keeping a track of
the challenge evolution in order to enable human-assisted diagnosis of flaws in
the network. We propose to use state-of-art peer-to-peer publish/subscribe and
distributed storage as core building blocks for the DISco service.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3076</identifier>
 <datestamp>2012-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3076</id><created>2012-01-15</created><authors><author><keyname>Vanclay</keyname><forenames>Jerome K.</forenames></author></authors><title>Impact Factor: outdated artefact or stepping-stone to journal
  certification?</title><categories>cs.DL</categories><comments>25 pages, 12 figures, 6 tables</comments><journal-ref>Scientometrics 92(2):211-238 (2012)</journal-ref><doi>10.1007/s11192-011-0561-0</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A review of Garfield's journal impact factor and its specific implementation
as the Thomson Reuters Impact Factor reveals several weaknesses in this
commonly-used indicator of journal standing. Key limitations include the
mismatch between citing and cited documents, the deceptive display of three
decimals that belies the real precision, and the absence of confidence
intervals. These are minor issues that are easily amended and should be
corrected, but more substantive improvements are needed. There are indications
that the scientific community seeks and needs better certification of journal
procedures to improve the quality of published science. Comprehensive
certification of editorial and review procedures could help ensure adequate
procedures to detect duplicate and fraudulent submissions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3077</identifier>
 <datestamp>2012-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3077</id><created>2012-01-15</created><authors><author><keyname>Gil</keyname><forenames>Joseph Yossi</forenames></author><author><keyname>Scott</keyname><forenames>David Allen</forenames></author></authors><title>A Bijective String Sorting Transform</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a string of characters, the Burrows-Wheeler Transform rearranges the
characters in it so as to produce another string of the same length which is
more amenable to compression techniques such as move to front, run-length
encoding, and entropy encoders. We present a variant of the transform which
gives rise to similar or better compression value, but, unlike the original,
the transform we present is bijective, in that the inverse transformation
exists for all strings. Our experiments indicate that using our variant of the
transform gives rise to better compression ratio than the original
Burrows-Wheeler transform. We also show that both the transform and its inverse
can be computed in linear time and consuming linear storage.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3078</identifier>
 <datestamp>2012-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3078</id><created>2012-01-15</created><authors><author><keyname>Gil</keyname><forenames>Joseph</forenames></author><author><keyname>Goldstein</keyname><forenames>Maayan</forenames></author><author><keyname>Moshkovich</keyname><forenames>Dany</forenames></author></authors><title>Empirical Confirmation (and Refutation) of Presumptions on Software</title><categories>cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Code metrics are easy to define, but not so easy to justify. It is hard to
prove that a metric is valid, i.e., that measured numerical values imply
anything on the vaguely defined, yet crucial software properties such as
complexity and maintainability. This paper employs statistical analysis and
tests to check some &quot;believable&quot; presumptions on the behavior of software and
metrics measured for this software. Among those are the reliability presumption
implicit in the application of any code metric, and the presumption that the
magnitude of change in a software artifact is correlated with changes to its
version number.
  Putting a suite of 36 metrics to the trial, we confirm most of the
presumptions. Unexpectedly, we show that a substantial portion of the
reliability of some metrics can be observed even in random changes to
architecture. Another surprising result is that Boolean-valued metrics tend to
flip their values more often in minor software version increments than in major
increments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3082</identifier>
 <datestamp>2012-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3082</id><created>2012-01-15</created><authors><author><keyname>Okubo</keyname><forenames>Fumiya</forenames></author><author><keyname>Kobayashi</keyname><forenames>Satoshi</forenames></author><author><keyname>Yokomori</keyname><forenames>Takashi</forenames></author></authors><title>On the Properties of Language Classes Defined by Bounded Reaction
  Automata</title><categories>cs.FL</categories><comments>23 pages with 3 figures</comments><report-no>EMTR-12-01</report-no><msc-class>68Q45 (Primary) 68Q05 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reaction automata are a formal model that has been introduced to investigate
the computing powers of interactive behaviors of biochemical reactions([14]).
Reaction automata are language acceptors with multiset rewriting mechanism
whose basic frameworks are based on reaction systems introduced in [4]. In this
paper we continue the investigation of reaction automata with a focus on the
formal language theoretic properties of subclasses of reaction automata, called
linearbounded reaction automata (LRAs) and exponentially-bounded reaction
automata (ERAs). Besides LRAs, we newly introduce an extended model (denoted by
lambda-LRAs) by allowing lambda-moves in the accepting process of reaction, and
investigate the closure properties of language classes accepted by both LRAs
and lambda-LRAs. Further, we establish new relationships of language classes
accepted by LRAs and by ERAs with the Chomsky hierarchy. The main results
include the following : (i) the class of languages accepted by lambda-LRAs
forms an AFL with additional closure properties, (ii) any recursively
enumerable language can be expressed as a homomorphic image of a language
accepted by an LRA, (iii) the class of languages accepted by ERAs coincides
with the class of context-sensitive languages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3088</identifier>
 <datestamp>2012-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3088</id><created>2012-01-15</created><authors><author><keyname>Kundu</keyname><forenames>Sudipta</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>An Adaptive Modulation Scheme for Two-user Fading MAC with Quantized
  Fade State Feedback</title><categories>cs.IT math.IT</categories><comments>12 pages; 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With no CSI at the users, transmission over the two-user Gaussian Multiple
Access Channel with fading and finite constellation at the input, is not
efficient because error rates will be high when the channel conditions are
poor. However, perfect CSI at the users is an unrealistic assumption in the
wireless scenario, as it would involve massive feedback overheads. In this
paper we propose a scheme which uses only quantized knowledge of CSI at the
transmitters with the overhead being nominal. The users rotate their
constellation without varying their transmit power to adapt to the existing
channel conditions, in order to meet certain pre-determined minimum Euclidean
distance requirement in the equivalent constellation at the destination. The
optimal modulation scheme has been described for the case when both the users
use symmetric M-PSK constellations at the input, where $ M=2^\lambda $, $
\lambda $ being a positive integer. The strategy has been illustrated by
considering examples where both users use QPSK or 8-PSK signal sets at the
input. It is shown that the proposed scheme has better throughput and error
performance compared to the conventional non-adaptive scheme, at the cost of a
feedback overhead of just $\lceil \log_2(\frac{M^2}{8}-\frac{M}{4}+2)\rceil + 1
$ bits, for the M-PSK case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3091</identifier>
 <datestamp>2012-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3091</id><created>2012-01-15</created><updated>2012-01-17</updated><authors><author><keyname>Ganian</keyname><forenames>Robert</forenames></author></authors><title>Using Neighborhood Diversity to Solve Hard Problems</title><categories>cs.DS cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Parameterized algorithms are a very useful tool for dealing with NP-hard
problems on graphs. Yet, to properly utilize parameterized algorithms it is
necessary to choose the right parameter based on the type of problem and
properties of the target graph class. Tree-width is an example of a very
successful graph parameter, however it cannot be used on dense graph classes
and there also exist problems which are hard even on graphs of bounded
tree-width. Such problems can be tackled by using vertex cover as a parameter,
however this places severe restrictions on admissible graph classes.
  Michael Lampis has recently introduced neighborhood diversity, a new graph
parameter which generalizes vertex cover to dense graphs. Among other results,
he has shown that simple parameterized algorithms exist for a few problems on
graphs of bounded neighborhood diversity. Our article further studies this area
and provides new algorithms parameterized by neighborhood diversity for the
p-Vertex-Disjoint Paths, Graph Motif and Precoloring Extension problems -- the
latter two being hard even on graphs of bounded tree-width.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3095</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3095</id><created>2012-01-15</created><updated>2013-01-08</updated><authors><author><keyname>Gitzenis</keyname><forenames>S.</forenames></author><author><keyname>Paschos</keyname><forenames>G. S.</forenames></author><author><keyname>Tassiulas</keyname><forenames>L.</forenames></author></authors><title>Asymptotic Laws for Joint Content Replication and Delivery in Wireless
  Networks</title><categories>cs.NI</categories><doi>10.1109/TIT.2012.2235905</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate on the scalability of multihop wireless communications, a
major concern in networking, for the case that users access content replicated
across the nodes. In contrast to the standard paradigm of randomly selected
communicating pairs, content replication is efficient for certain regimes of
file popularity, cache and network size. Our study begins with the detailed
joint content replication and delivery problem on a 2D square grid, a hard
combinatorial optimization. This is reduced to a simpler problem based on
replication density, whose performance is of the same order as the original.
Assuming a Zipf popularity law, and letting the size of content and network
both go to infinity, we identify the scaling laws and regimes of the required
link capacity, ranging from O(\sqrt{N}) down to O(1).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3097</identifier>
 <datestamp>2012-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3097</id><created>2012-01-15</created><authors><author><keyname>Florindo</keyname><forenames>Jo&#xe3;o B.</forenames></author><author><keyname>Bruno</keyname><forenames>Odemir M.</forenames></author></authors><title>Closed Contour Fractal Dimension Estimation by the Fourier Transform</title><categories>physics.data-an cs.DM math.DS</categories><journal-ref>Chaos, Solitons and Fractals, Volume 44, Issue 10, October 2011,
  Pages 851--861</journal-ref><doi>10.1016/j.chaos.2011.07.008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work proposes a novel technique for the numerical calculus of the
fractal dimension of fractal objects which can be represented as a closed
contour. The proposed method maps the fractal contour onto a complex signal and
calculates its fractal dimension using the Fourier transform. The Fourier power
spectrum is obtained and an exponential relation is verified between the power
and the frequency. From the parameter (exponent) of the relation, it is
obtained the fractal dimension. The method is compared to other classical
fractal dimension estimation methods in the literature, e. g.,
Bouligand-Minkowski, box-couting and classical Fourier. The comparison is
achieved by the calculus of the fractal dimension of fractal contours whose
dimensions are well-known analytically. The results showed the high precision
and robustness of the proposed technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3107</identifier>
 <datestamp>2012-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3107</id><created>2012-01-15</created><authors><author><keyname>Yang</keyname><forenames>Li</forenames></author><author><keyname>Wang</keyname><forenames>Yuhui</forenames></author></authors><title>Tacit knowledge mining algorithm based on linguistic truth-valued
  concept lattice</title><categories>cs.AI</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper is the continuation of our research work about linguistic
truth-valued concept lattice. In order to provide a mathematical tool for
mining tacit knowledge, we establish a concrete model of 6-ary linguistic
truth-valued concept lattice and introduce a mining algorithm through the
structure consistency. Specifically, we utilize the attributes to depict
knowledge, propose the 6-ary linguistic truth-valued attribute extended context
and congener context to characterize tacit knowledge, and research the
necessary and sufficient conditions of forming tacit knowledge. We respectively
give the algorithms of generating the linguistic truth-valued congener context
and constructing the linguistic truth-valued concept lattice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3108</identifier>
 <datestamp>2014-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3108</id><created>2012-01-15</created><authors><author><keyname>Ceccherini-Silberstein</keyname><forenames>Tullio</forenames></author><author><keyname>Coornaert</keyname><forenames>Michel</forenames></author><author><keyname>Fiorenzi</keyname><forenames>Francesca</forenames></author><author><keyname>Schupp</keyname><forenames>Paul E.</forenames></author></authors><title>Groups, Graphs, Languages, Automata, Games and Second-order Monadic
  Logic</title><categories>math.GR cs.IT math.IT math.LO</categories><msc-class>03D05 (Primary) 20F05, 20F10, 20F65, 20F69, 37B15, 68Q70, 68Q80</msc-class><journal-ref>European J. Combin. 33 (2012) no. 7, 1330-1368</journal-ref><doi>10.1016/j.ejc.2012.03.010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we survey some surprising connections between group theory, the
theory of automata and formal languages, the theory of ends, infinite games of
perfect information, and monadic second-order logic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3109</identifier>
 <datestamp>2012-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3109</id><created>2012-01-15</created><authors><author><keyname>Gon&#xe7;alves</keyname><forenames>Wesley Nunes</forenames></author><author><keyname>Bruno</keyname><forenames>Odemir Martinez</forenames></author></authors><title>Automatic system for counting cells with elliptical shape</title><categories>cs.CV</categories><comments>Learning and NonLinear Models, Volume 9, Issue 1, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a new method for automatic quantification of ellipse-like
cells in images, an important and challenging problem that has been studied by
the computer vision community. The proposed method can be described by two main
steps. Initially, image segmentation based on the k-means algorithm is
performed to separate different types of cells from the background. Then, a
robust and efficient strategy is performed on the blob contour for touching
cells splitting. Due to the contour processing, the method achieves excellent
results of detection compared to manual detection performed by specialists.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3114</identifier>
 <datestamp>2012-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3114</id><created>2012-01-15</created><authors><author><keyname>Marco</keyname><forenames>Anderson Gon&#xe7;alves</forenames></author><author><keyname>Martinez</keyname><forenames>Alexandre Souto</forenames></author><author><keyname>Bruno</keyname><forenames>Odemir Martinez</forenames></author></authors><title>Fast, parallel and secure cryptography algorithm using Lorenz's
  attractor</title><categories>cs.CR math.DS physics.data-an</categories><journal-ref>International Journal of Modern Physics C, Volume: 21, Issue:
  3(2010) pp. 365-382</journal-ref><doi>10.1142/S0129183110015166</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A novel cryptography method based on the Lorenz's attractor chaotic system is
presented. The proposed algorithm is secure and fast, making it practical for
general use. We introduce the chaotic operation mode, which provides an
interaction among the password, message and a chaotic system. It ensures that
the algorithm yields a secure codification, even if the nature of the chaotic
system is known. The algorithm has been implemented in two versions: one
sequential and slow and the other, parallel and fast. Our algorithm assures the
integrity of the ciphertext (we know if it has been altered, which is not
assured by traditional algorithms) and consequently its authenticity. Numerical
experiments are presented, discussed and show the behavior of the method in
terms of security and performance. The fast version of the algorithm has a
performance comparable to AES, a popular cryptography program used commercially
nowadays, but it is more secure, which makes it immediately suitable for
general purpose cryptography applications. An internet page has been set up,
which enables the readers to test the algorithm and also to try to break into
the cipher in.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3116</identifier>
 <datestamp>2012-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3116</id><created>2012-01-15</created><authors><author><keyname>Florindo</keyname><forenames>Jo&#xe3;o Batista</forenames></author><author><keyname>de Castro</keyname><forenames>M&#xe1;rio</forenames></author><author><keyname>Bruno</keyname><forenames>Odemir Martinez</forenames></author></authors><title>Enhancing Volumetric Bouligand-Minkowski Fractal Descriptors by using
  Functional Data Analysis</title><categories>cs.CV physics.data-an</categories><journal-ref>International Journal of Modern Physics C, Volume: 22, Issue:
  9(2011) pp. 929-952</journal-ref><doi>10.1142/S0129183111016701</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work proposes and study the concept of Functional Data Analysis
transform, applying it to the performance improving of volumetric
Bouligand-Minkowski fractal descriptors. The proposed transform consists
essentially in changing the descriptors originally defined in the space of the
calculus of fractal dimension into the space of coefficients used in the
functional data representation of these descriptors. The transformed decriptors
are used here in texture classification problems. The enhancement provided by
the FDA transform is measured by comparing the transformed to the original
descriptors in terms of the correctness rate in the classification of well
known datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3117</identifier>
 <datestamp>2012-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3117</id><created>2012-01-15</created><authors><author><keyname>Guti&#xe9;rrez</keyname><forenames>Jos&#xe9; A. Garc&#xed;a</forenames></author><author><keyname>Cotta</keyname><forenames>Carlos</forenames></author><author><keyname>Fern&#xe1;ndez-Leiva</keyname><forenames>Antonio J.</forenames></author></authors><title>Design of Emergent and Adaptive Virtual Players in a War RTS Game</title><categories>cs.NE cs.AI</categories><comments>IWINAC International Work-conference on the Interplay between Natural
  and Artificial Computation 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Basically, in (one-player) war Real Time Strategy (wRTS) games a human player
controls, in real time, an army consisting of a number of soldiers and her aim
is to destroy the opponent's assets where the opponent is a virtual (i.e.,
non-human player controlled) player that usually consists of a pre-programmed
decision-making script. These scripts have usually associated some well-known
problems (e.g., predictability, non-rationality, repetitive behaviors, and
sensation of artificial stupidity among others). This paper describes a method
for the automatic generation of virtual players that adapt to the player
skills; this is done by building initially a model of the player behavior in
real time during the game, and further evolving the virtual player via this
model in-between two games. The paper also shows preliminary results obtained
on a one player wRTS game constructed specifically for experimentation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3118</identifier>
 <datestamp>2015-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3118</id><created>2012-01-15</created><authors><author><keyname>Backes</keyname><forenames>Andr&#xe9; R.</forenames></author><author><keyname>Florindo</keyname><forenames>Jo&#xe3;o B.</forenames></author><author><keyname>Bruno</keyname><forenames>Odemir M.</forenames></author></authors><title>Shape analysis using fractal dimension: a curvature based approach</title><categories>physics.data-an cs.CV</categories><doi>10.1063/1.4757226</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The present work shows a novel fractal dimension method for shape analysis.
The proposed technique extracts descriptors from the shape by applying a
multiscale approach to the calculus of the fractal dimension of that shape. The
fractal dimension is obtained by the application of the curvature scale-space
technique to the original shape. Through the application of a multiscale
transform to the dimension calculus, it is obtained a set of numbers
(descriptors) capable of describing with a high precision the shape in
analysis. The obtained descriptors are validated in a classification process.
The results demonstrate that the novel technique provides descriptors highly
reliable, confirming the precision of the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3119</identifier>
 <datestamp>2012-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3119</id><created>2012-01-15</created><authors><author><keyname>Adeline</keyname><forenames>Pierrot</forenames></author><author><keyname>Dominique</keyname><forenames>Rossin</forenames></author></authors><title>Simple permutations poset</title><categories>cs.DM</categories><comments>15 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article studies the poset of simple permutations with respect to the
pattern involvement. We specify results on critically indecomposable posets
obtained by Schmerl and Trotter to simple permutations and prove that if
$\sigma, \pi$ are two simple permutations such that $\pi &lt; \sigma$ then there
exists a chain of simple permutations $\sigma^{(0)} = \sigma, \sigma^{(1)},
..., \sigma^{(k)}=\pi$ such that $|\sigma^{(i)}| - |\sigma^{(i+1)}| = 1$ - or 2
when permutations are exceptional- and $\sigma^{(i+1)} &lt; \sigma^{(i)}$. This
characterization induces an algorithm polynomial in the size of the output to
compute the simple permutations in a wreath-closed permutation class.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3120</identifier>
 <datestamp>2013-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3120</id><created>2012-01-15</created><updated>2012-10-01</updated><authors><author><keyname>Benzi</keyname><forenames>Michele</forenames></author><author><keyname>Estrada</keyname><forenames>Ernesto</forenames></author><author><keyname>Klymko</keyname><forenames>Christine</forenames></author></authors><title>Ranking hubs and authorities using matrix functions</title><categories>math.NA cs.NA cs.SI physics.soc-ph</categories><comments>28 pages, 6 figures</comments><msc-class>05C50, 15A16, 65F60, 90B10</msc-class><journal-ref>Linear Algebra and its Applications, 438 (2013), pp. 2447-2474</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The notions of subgraph centrality and communicability, based on the
exponential of the adjacency matrix of the underlying graph, have been
effectively used in the analysis of undirected networks. In this paper we
propose an extension of these measures to directed networks, and we apply them
to the problem of ranking hubs and authorities. The extension is achieved by
bipartization, i.e., the directed network is mapped onto a bipartite undirected
network with twice as many nodes in order to obtain a network with a symmetric
adjacency matrix. We explicitly determine the exponential of this adjacency
matrix in terms of the adjacency matrix of the original, directed network, and
we give an interpretation of centrality and communicability in this new
context, leading to a technique for ranking hubs and authorities. The matrix
exponential method for computing hubs and authorities is compared to the well
known HITS algorithm, both on small artificial examples and on more realistic
real-world networks. A few other ranking algorithms are also discussed and
compared with our technique. The use of Gaussian quadrature rules for
calculating hub and authority scores is discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3123</identifier>
 <datestamp>2015-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3123</id><created>2012-01-15</created><authors><author><keyname>Coon</keyname><forenames>Justin</forenames></author><author><keyname>Dettmann</keyname><forenames>Carl P.</forenames></author><author><keyname>Georgiou</keyname><forenames>Orestis</forenames></author></authors><title>Full Connectivity: Corners, edges and faces</title><categories>cond-mat.dis-nn cs.DM math-ph math.MP math.PR</categories><comments>28 pages, 8 figures</comments><journal-ref>J. Stat. Phys. 147, 758-778 (2012)</journal-ref><doi>10.1007/s10955-012-0493-y</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a cluster expansion for the probability of full connectivity of
high density random networks in confined geometries. In contrast to percolation
phenomena at lower densities, boundary effects, which have previously been
largely neglected, are not only relevant but dominant. We derive general
analytical formulas that show a persistence of universality in a different form
to percolation theory, and provide numerical confirmation. We also demonstrate
the simplicity of our approach in three simple but instructive examples and
discuss the practical benefits of its application to different models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3128</identifier>
 <datestamp>2012-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3128</id><created>2012-01-15</created><authors><author><keyname>Zamani</keyname><forenames>Mahdi</forenames></author><author><keyname>Khandani</keyname><forenames>Amir K.</forenames></author></authors><title>Maximum Throughput in Multiple-Antenna Systems</title><categories>cs.IT math.IT</categories><comments>33 pages; 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The point-to-point multiple-antenna channel is investigated in uncorrelated
block fading environment with Rayleigh distribution. The maximum throughput and
maximum expected-rate of this channel are derived under the assumption that the
transmitter is oblivious to the channel state information (CSI), however, the
receiver has perfect CSI. First, we prove that in multiple-input single-output
(MISO) channels, the optimum transmission strategy maximizing the throughput is
to use all available antennas and perform equal power allocation with
uncorrelated signals. Furthermore, to increase the expected-rate, multi-layer
coding is applied. Analogously, we establish that sending uncorrelated signals
and performing equal power allocation across all available antennas at each
layer is optimum. A closed form expression for the maximum continuous-layer
expected-rate of MISO channels is also obtained. Moreover, we investigate
multiple-input multiple-output (MIMO) channels, and formulate the maximum
throughput in the asymptotically low and high SNR regimes and also
asymptotically large number of transmit or receive antennas by obtaining the
optimum transmit covariance matrix. Finally, a distributed antenna system,
wherein two single-antenna transmitters want to transmit a common message to a
single-antenna receiver, is considered. It is shown that this system has the
same outage probability and hence, throughput and expected-rate, as a
point-to-point $2\times 1$ MISO channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3133</identifier>
 <datestamp>2012-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3133</id><created>2012-01-15</created><updated>2012-02-19</updated><authors><author><keyname>Florindo</keyname><forenames>Jo&#xe3;o Batista</forenames></author><author><keyname>Bruno</keyname><forenames>Odemir Martinez</forenames></author></authors><title>Fractal Descriptors in the Fourier Domain Applied to Color Texture
  Analysis</title><categories>physics.data-an cs.CV math.DS</categories><comments>Chaos, Volume 21, Issue 4, 2011</comments><doi>10.1063/1.3650233</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The present work proposes the development of a novel method to provide
descriptors for colored texture images. The method consists in two steps. In
the first, we apply a linear transform in the color space of the image aiming
at highlighting spatial structuring relations among the color of pixels. In a
second moment, we apply a multiscale approach to the calculus of fractal
dimension based on Fourier transform. From this multiscale operation, we
extract the descriptors used to discriminate the texture represented in digital
images. The accuracy of the method is verified in the classification of two
color texture datasets, by comparing the performance of the proposed technique
to other classical and state-of-the-art methods for color texture analysis. The
results showed an advantage of almost 3% of the proposed technique over the
second best approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3140</identifier>
 <datestamp>2013-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3140</id><created>2012-01-15</created><updated>2013-07-22</updated><authors><author><keyname>Li</keyname><forenames>Yonghui</forenames></author><author><keyname>Rahman</keyname><forenames>Md. Shahriar</forenames></author><author><keyname>Ng</keyname><forenames>Soon Xin</forenames></author><author><keyname>Vucetic</keyname><forenames>Branka</forenames></author></authors><title>Distributed Soft Coding with a Soft Input Soft Output (SISO) Relay
  Encoder in Parallel Relay Channels</title><categories>cs.IT math.IT</categories><comments>to appear on IEEE Transactions on Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a new distributed coding structure with a soft
input soft output (SISO) relay encoder for error-prone parallel relay channels.
We refer to it as the distributed soft coding (DISC). In the proposed scheme,
each relay first uses the received noisy signals to calculate the soft bit
estimate (SBE) of the source symbols. A simple SISO encoder is developed to
encode the SBEs of source symbols based on a constituent code generator matrix.
The SISO encoder outputs at different relays are then forwarded to the
destination and form a distributed codeword. The performance of the proposed
scheme is analyzed. It is shown that its performance is determined by the
generator sequence weight (GSW) of the relay constituent codes, where the GSW
of a constituent code is defined as the number of ones in its generator
sequence. A new coding design criterion for optimally assigning the constituent
codes to all the relays is proposed based on the analysis. Results show that
the proposed DISC can effectively circumvent the error propagation due to the
decoding errors in the conventional detect and forward (DF) with relay
re-encoding and bring considerable coding gains, compared to the conventional
soft information relaying.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3142</identifier>
 <datestamp>2012-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3142</id><created>2012-01-15</created><updated>2012-05-23</updated><authors><author><keyname>Norman</keyname><forenames>Joseph W.</forenames></author></authors><title>A Tutorial Introduction to the Logic of Parametric Probability</title><categories>math.LO cs.LO math.OC math.PR</categories><comments>39 pages including 4 page appendix; new title, additional
  clarifications, correction of bugs introduced into one example in the last
  revision</comments><msc-class>03A05, 68N17, 03B42, 97K50, 90C05, 90C26</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The computational method of parametric probability analysis is introduced. It
is demonstrated how to embed logical formulas from the propositional calculus
into parametric probability networks, thereby enabling sound reasoning about
the probabilities of logical propositions. An alternative direct probability
encoding scheme is presented, which allows statements of implication and
quantification to be modeled directly as constraints on conditional
probabilities. Several example problems are solved, from Johnson-Laird's aces
to Smullyan's zombies. Many apparently challenging problems in logic turn out
to be simple problems in algebra and computer science: systems of polynomial
equations or linear optimization problems. This work extends the mathematical
logic and parametric probability methods invented by George Boole.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3153</identifier>
 <datestamp>2012-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3153</id><created>2012-01-15</created><authors><author><keyname>Backes</keyname><forenames>Andr&#xe9; Ricardo</forenames></author><author><keyname>Bruno</keyname><forenames>Odemir Martinez</forenames></author></authors><title>Fractal and Multi-Scale Fractal Dimension analysis: a comparative study
  of Bouligand-Minkowski method</title><categories>cs.CV</categories><journal-ref>INFOCOMP, v. 7, p. 74-83, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Shape is one of the most important visual attributes to characterize objects,
playing a important role in pattern recognition. There are various approaches
to extract relevant information of a shape. An approach widely used in shape
analysis is the complexity, and Fractal Dimension and Multi-Scale Fractal
Dimension are both well-known methodologies to estimate it. This papers
presents a comparative study between Fractal Dimension and Multi-Scale Fractal
Dimension in a shape analysis context. Through experimental comparison using a
shape database previously classified, both methods are compared. Different
parameters configuration of each method are considered and a discussion about
the results of each method is also presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3160</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3160</id><created>2012-01-16</created><updated>2012-01-22</updated><authors><author><keyname>Bellare</keyname><forenames>Mihir</forenames></author><author><keyname>Tessaro</keyname><forenames>Stefano</forenames></author></authors><title>Polynomial-Time, Semantically-Secure Encryption Achieving the Secrecy
  Capacity</title><categories>cs.IT cs.CR math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the wiretap channel setting, one aims to get information-theoretic privacy
of communicated data based only on the assumption that the channel from sender
to receiver is noisier than the one from sender to adversary. The secrecy
capacity is the optimal (highest possible) rate of a secure scheme, and the
existence of schemes achieving it has been shown. For thirty years the ultimate
and unreached goal has been to achieve this optimal rate with a scheme that is
polynomial-time. (This means both encryption and decryption are proven
polynomial time algorithms.) This paper finally delivers such a scheme. In fact
it does more. Our scheme not only meets the classical notion of security from
the wiretap literature, called MIS-R (mutual information security for random
messages) but achieves the strictly stronger notion of semantic security, thus
delivering more in terms of security without loss of rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3172</identifier>
 <datestamp>2012-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3172</id><created>2012-01-16</created><updated>2012-02-02</updated><authors><author><keyname>Murthy</keyname><forenames>Uma</forenames></author><author><keyname>Boardman</keyname><forenames>David</forenames></author><author><keyname>Garg</keyname><forenames>Chirag</forenames></author></authors><title>Assessing the Value of 3D Reconstruction in Building Construction</title><categories>cs.HC cs.CV</categories><acm-class>I.4.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  3-dimensional (3D) reconstruction is an emerging field in image processing
and computer vision that aims to create 3D visualizations/ models of objects/
scenes from image sets. However, its commercial applications and benefits are
yet to be fully explored. In this paper, we describe ongoing work towards
assessing the value of 3D reconstruction in the building construction domain.
We present preliminary results from a user study, where our objective is to
understand the use of visual information in building construction in order to
determine problems with the use of visual information and identify potential
benefits and scenarios for the use of 3D reconstruction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3179</identifier>
 <datestamp>2012-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3179</id><created>2012-01-16</created><authors><author><keyname>Yordzhev</keyname><forenames>Krasimir</forenames></author><author><keyname>Totina</keyname><forenames>Lilyana</forenames></author></authors><title>Matrix representation of a solution of a combinatorial problem of the
  group theory</title><categories>cs.MS math.CO math.GR</categories><comments>Proceedings of the Fourth International Scientific Conference --
  FMNS2011, 8 -- 11 June 2011</comments><journal-ref>Mathematics and natural science, v. 1, 2011, 144-152</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An equivalence relation in the symmetric group, where is a positive integer
has been considered. An algorithm for calculation of the number of the
equivalence classes by this relation for arbitrary integer has been described.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3181</identifier>
 <datestamp>2012-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3181</id><created>2012-01-16</created><authors><author><keyname>Arvind</keyname><forenames>V.</forenames></author><author><keyname>Mukhopadhyay</keyname><forenames>Partha</forenames></author><author><keyname>Nimbhorkar</keyname><forenames>Prajakta</forenames></author><author><keyname>Vasudev</keyname><forenames>Yadu</forenames></author></authors><title>Near-Optimal Expanding Generating Sets for Solvable Permutation Groups</title><categories>cs.CC cs.DM</categories><comments>15 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $G =&lt;S&gt;$ be a solvable permutation group of the symmetric group $S_n$
given as input by the generating set $S$. We give a deterministic
polynomial-time algorithm that computes an \emph{expanding generating set} of
size $\tilde{O}(n^2)$ for $G$. More precisely, the algorithm computes a subset
$T\subset G$ of size $\tilde{O}(n^2)(1/\lambda)^{O(1)}$ such that the
undirected Cayley graph $Cay(G,T)$ is a $\lambda$-spectral expander (the
$\tilde{O}$ notation suppresses $\log ^{O(1)}n$ factors). As a byproduct of our
proof, we get a new explicit construction of $\varepsilon$-bias spaces of size
$\tilde{O}(n\poly(\log d))(\frac{1}{\varepsilon})^{O(1)}$ for the groups
$\Z_d^n$. The earlier known size bound was $O((d+n/\varepsilon^2))^{11/2}$
given by \cite{AMN98}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3184</identifier>
 <datestamp>2012-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3184</id><created>2012-01-16</created><authors><author><keyname>Zhang</keyname><forenames>Peng</forenames></author></authors><title>Partial Degree Bounded Edge Packing Problem</title><categories>cs.CC cs.DS</categories><comments>9 pages. Being reviewed in FAW 2012. A model of edge packing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In [1], whether a target binary string s can be represented from a boolean
formula with operands chosen from a set of binary strings W was studied. In
this paper, we first examine selecting a maximum subset X from W, so that for
any string t in X, t is not representable by X\{t}. We rephrase this problem as
graph, and surprisingly find it give rise to a broad model of edge packing
problem, which itself falls into the model of forbidden subgraph problem.
Specifically, given a graph G(V;E) and a constant c, the problem asks to choose
as many as edges to form a subgraph G'. So that in G', for each edge, at least
one of its endpoints has degree no more than c. We call such G' partial c
degree bounded. When c = 1, it turns out to be the complement of dominating
set. We present several results about hardness, approximation for the general
graph and efficient exact algorithm on trees. This edge packing problem model
also has a direct interpretation in resource allocation. There are n types of
resources and m jobs. Each job needs two types of resources. A job can be
accomplished if either one of its necessary resources is shared by no more than
c other jobs. The problem then asks to nish as many jobs as possible. We
believe this partial degree bounded graph problem merits more attention.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3194</identifier>
 <datestamp>2012-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3194</id><created>2012-01-16</created><authors><author><keyname>Esparza</keyname><forenames>Javier</forenames></author><author><keyname>Ganty</keyname><forenames>Pierre</forenames></author><author><keyname>Majumdar</keyname><forenames>Rupak</forenames></author></authors><title>A Perfect Model for Bounded Verification</title><categories>cs.FL</categories><comments>14 pages, 6 figures</comments><doi>10.1109/LICS.2012.39</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A class of languages C is perfect if it is closed under Boolean operations
and the emptiness problem is decidable. Perfect language classes are the basis
for the automata-theoretic approach to model checking: a system is correct if
the language generated by the system is disjoint from the language of bad
traces. Regular languages are perfect, but because the disjointness problem for
CFLs is undecidable, no class containing the CFLs can be perfect.
  In practice, verification problems for language classes that are not perfect
are often under-approximated by checking if the property holds for all
behaviors of the system belonging to a fixed subset. A general way to specify a
subset of behaviors is by using bounded languages (languages of the form w1*
... wk* for fixed words w1,...,wk). A class of languages C is perfect modulo
bounded languages if it is closed under Boolean operations relative to every
bounded language, and if the emptiness problem is decidable relative to every
bounded language.
  We consider finding perfect classes of languages modulo bounded languages. We
show that the class of languages accepted by multi-head pushdown automata are
perfect modulo bounded languages, and characterize the complexities of decision
problems. We also show that bounded languages form a maximal class for which
perfection is obtained. We show that computations of several known models of
systems, such as recursive multi-threaded programs, recursive counter machines,
and communicating finite-state machines can be encoded as multi-head pushdown
automata, giving uniform and optimal underapproximation algorithms modulo
bounded languages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3198</identifier>
 <datestamp>2012-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3198</id><created>2012-01-16</created><authors><author><keyname>Oaku</keyname><forenames>Toshinori</forenames></author></authors><title>An algorithm to compute the differential equations for the logarithm of
  a polynomial</title><categories>cs.SC math.CA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an algorithm to compute the annihilator of (i.e., the linear
differential equations for) the logarithm of a polynomial in the ring of
differential operators with polynomial coefficients. The algorithm consists of
differentiation with respect to the parameter s of the annihilator of f^s for a
polynomial f and quotient computation. More generally, the annihilator of
f^s(log f)^m for a complex number s and a positive integer m can be computed,
which constitutes what is called a holonomic system in D-module theory. This
enables us to compute a holonomic system for the integral of a function
involving the logarithm of a polynomial by using integration algorithm for
D-modules.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3204</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3204</id><created>2012-01-16</created><updated>2012-10-24</updated><authors><author><keyname>Kishimoto</keyname><forenames>Akihiro</forenames></author><author><keyname>Fukunaga</keyname><forenames>Alex</forenames></author><author><keyname>Botea</keyname><forenames>Adi</forenames></author></authors><title>Evaluation of a Simple, Scalable, Parallel Best-First Search Strategy</title><categories>cs.AI</categories><comments>in press, to appear in Artificial Intelligence</comments><journal-ref>Artificial Intelligence (2013), vol. 195, pp. 222-248</journal-ref><doi>10.1016/j.artint.2012.10.007</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Large-scale, parallel clusters composed of commodity processors are
increasingly available, enabling the use of vast processing capabilities and
distributed RAM to solve hard search problems. We investigate Hash-Distributed
A* (HDA*), a simple approach to parallel best-first search that asynchronously
distributes and schedules work among processors based on a hash function of the
search state. We use this approach to parallelize the A* algorithm in an
optimal sequential version of the Fast Downward planner, as well as a 24-puzzle
solver. The scaling behavior of HDA* is evaluated experimentally on a shared
memory, multicore machine with 8 cores, a cluster of commodity machines using
up to 64 cores, and large-scale high-performance clusters, using up to 2400
processors. We show that this approach scales well, allowing the effective
utilization of large amounts of distributed memory to optimally solve problems
which require terabytes of RAM. We also compare HDA* to Transposition-table
Driven Scheduling (TDS), a hash-based parallelization of IDA*, and show that,
in planning, HDA* significantly outperforms TDS. A simple hybrid which combines
HDA* and TDS to exploit strengths of both algorithms is proposed and evaluated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3210</identifier>
 <datestamp>2015-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3210</id><created>2012-01-16</created><authors><author><keyname>Rusek</keyname><forenames>Fredrik</forenames></author><author><keyname>Persson</keyname><forenames>Daniel</forenames></author><author><keyname>Lau</keyname><forenames>Buon Kiong</forenames></author><author><keyname>Larsson</keyname><forenames>Erik G.</forenames></author><author><keyname>Marzetta</keyname><forenames>Thomas L.</forenames></author><author><keyname>Edfors</keyname><forenames>Ove</forenames></author><author><keyname>Tufvesson</keyname><forenames>Fredrik</forenames></author></authors><title>Scaling up MIMO: Opportunities and Challenges with Very Large Arrays</title><categories>cs.IT math.IT</categories><comments>Accepted for publication in the IEEE Signal Processing Magazine,
  October 2011</comments><doi>10.1109/MSP.2011.2178495</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper surveys recent advances in the area of very large MIMO systems.
  With very large MIMO, we think of systems that use antenna arrays with an
order of magnitude more elements than in systems being built today, say a
hundred antennas or more. Very large MIMO entails an unprecedented number of
antennas simultaneously serving a much smaller number of terminals. The
disparity in number emerges as a desirable operating condition and a practical
one as well. The number of terminals that can be simultaneously served is
limited, not by the number of antennas, but rather by our inability to acquire
channel-state information for an unlimited number of terminals. Larger numbers
of terminals can always be accommodated by combining very large MIMO technology
with conventional time- and frequency-division multiplexing via OFDM. Very
large MIMO arrays is a new research field both in communication theory,
propagation, and electronics and represents a paradigm shift in the way of
thinking both with regards to theory, systems and implementation. The ultimate
vision of very large MIMO systems is that the antenna array would consist of
small active antenna units, plugged into an (optical) fieldbus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3215</identifier>
 <datestamp>2012-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3215</id><created>2012-01-16</created><authors><author><keyname>Baid</keyname><forenames>Akash</forenames></author><author><keyname>Madan</keyname><forenames>Ritesh</forenames></author><author><keyname>Sampath</keyname><forenames>Ashwin</forenames></author></authors><title>Delay Estimation and Fast Iterative Scheduling Policies for LTE Uplink</title><categories>math.OC cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the allocation of spectral and power resources to the mobiles
(i.e., user equipment (UE)) in a cell every subframe (1 ms) for the Long Term
Evolution (LTE) orthogonal frequency division multiple access (OFDMA) cellular
network. To enable scheduling based on packet delays, we design a novel
mechanism for inferring the packet delays approximately from the buffer status
reports (BSR) transmitted by the UEs; the BSR reports only contain queue length
information. We then consider a constrained optimization problem with a concave
objective function - schedulers such as those based on utility maximization,
maximum weight scheduling, and recent results on iterative scheduling for small
queue/delay follow as special cases. In particular, the construction of the
non-differentiable objective function based on packet delays is novel. We model
constraints on bandwidth, peak transmit power at the UE, and the transmit power
spectral density (PSD) at the UE due to fractional power control. When
frequency diversity doesn't exist or is not exploited at a fast time-scale, we
use subgradient analysis to construct an O(N log L) (per iteration with small
number of iterations) algorithm to compute the optimal resource allocation for
N users and L points of non-differentiability in the objective function. For a
frequency diversity scheduler with M sub-bands, the corre- sponding complexity
per iteration is essentially O(N(M^2+L^2)). Unlike previous iterative policies
based on delay/queue, in our approach the complexity of scheduling can be
reduced when the coherence bandwidth is larger. Through detailed system
simulations (based on NGMN and 3GPP evaluation methodology) which model H-ARQ,
finite resource grants per sub-frame, deployment, realistic traffic, power
limitations, interference, and channel fading, we demonstrate the effectiveness
of our schemes for LTE.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3217</identifier>
 <datestamp>2013-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3217</id><created>2012-01-16</created><updated>2013-03-27</updated><authors><author><keyname>Cavazza</keyname><forenames>Niccol&#xf2;</forenames></author><author><keyname>Ethier</keyname><forenames>Marc</forenames></author><author><keyname>Frosini</keyname><forenames>Patrizio</forenames></author><author><keyname>Kaczynski</keyname><forenames>Tomasz</forenames></author><author><keyname>Landi</keyname><forenames>Claudia</forenames></author></authors><title>Comparison of Persistent Homologies for Vector Functions: from
  continuous to discrete and back</title><categories>cs.CG</categories><comments>This version contains new experiments, described in section 5.3. The
  previous version was presented at: Workshop on Computational Topology,
  November 7-11, 2011, Fields Institute http://amsacta.unibo.it/3205/</comments><msc-class>55-04, 65D18</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The theory of multidimensional persistent homology was initially developed in
the discrete setting, and involved the study of simplicial complexes filtered
through an ordering of the simplices. Later, stability properties of
multidimensional persistence have been proved to hold when topological spaces
are filtered by continuous functions, i.e. for continuous data. This paper aims
to provide a bridge between the continuous setting, where stability properties
hold, and the discrete setting, where actual computations are carried out. More
precisely, a stability preserving method is developed to compare rank
invariants of vector functions obtained from discrete data. These advances
confirm that multidimensional persistent homology is an appropriate tool for
shape comparison in computer vision and computer graphics applications. The
results are supported by numerical tests.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3227</identifier>
 <datestamp>2012-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3227</id><created>2012-01-16</created><authors><author><keyname>Ahmadi</keyname><forenames>Amir Ali</forenames></author><author><keyname>Jungers</keyname><forenames>Raphael M.</forenames></author><author><keyname>Parrilo</keyname><forenames>Pablo A.</forenames></author><author><keyname>Roozbehani</keyname><forenames>Mardavij</forenames></author></authors><title>When is a set of LMIs a sufficient condition for stability?</title><categories>math.OC cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study stability criteria for discrete time switching systems. We
investigate the structure of sets of LMIs that are a sufficient condition for
stability (i.e., such that any switching system which satisfies these LMIs is
stable). We provide an exact characterization of these sets. As a corollary, we
show that it is PSPACE-complete to recognize whether a particular set of LMIs
implies the stability of a switching system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3230</identifier>
 <datestamp>2013-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3230</id><created>2012-01-16</created><updated>2012-04-11</updated><authors><author><keyname>Zawadzki</keyname><forenames>Piotr</forenames></author><author><keyname>Pucha&#x142;a</keyname><forenames>Zbigniew</forenames></author><author><keyname>Miszczak</keyname><forenames>Jaros&#x142;aw Adam</forenames></author></authors><title>Increasing the security of the ping-pong protocol by using many mutually
  unbiased bases</title><categories>quant-ph cs.CR</categories><comments>5 pages, 1 figure</comments><journal-ref>Quantum Inf. Process., Vol. 12, No. 1 (2013), pp. 569-576</journal-ref><doi>10.1007/s11128-012-0403-x</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose an extended version of the ping-pong protocol and
study its security. The proposed protocol incorporates the usage of mutually
unbiased bases in the control mode. We show that, by increasing the number of
bases, it is possible to improve the security of this protocol. We also provide
the upper bounds on eavesdropping average non-detection probability and propose
a control mode modification that increases the attack detection probability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3233</identifier>
 <datestamp>2012-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3233</id><created>2012-01-16</created><updated>2012-01-17</updated><authors><author><keyname>Sparavigna</keyname><forenames>Amelia Carolina</forenames></author></authors><title>Variations of images to increase their visibility</title><categories>cs.CV</categories><comments>Keywords: Image visibility, Fringe visibility, Gimp. Layout after
  revision of misprints</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The calculus of variations applied to the image processing requires some
numerical models able to perform the variations of images and the extremization
of appropriate actions. To produce the variations of images, there are several
possibilities based on the brightness maps. Before a numerical model, I propose
an experimental approach, based on a tool of Gimp, GNU Image Manipulation
Program, in order to visualize how the image variations can be. After the
discussion of this tool, which is able to strongly increase the visibility of
images, the variations and a possible functional for the visibility are
proposed in the framework of a numerical model. The visibility functional is
analogous to the fringe visibility of the optical interference.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3249</identifier>
 <datestamp>2012-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3249</id><created>2012-01-16</created><authors><author><keyname>Howard</keyname><forenames>Gerard</forenames></author><author><keyname>Bull</keyname><forenames>Larry</forenames></author><author><keyname>Lanzi</keyname><forenames>Pier-Luca</forenames></author></authors><title>A Spiking Neural Learning Classifier System</title><categories>cs.NE cs.LG cs.RO</categories><comments>20 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Learning Classifier Systems (LCS) are population-based reinforcement learners
used in a wide variety of applications. This paper presents a LCS where each
traditional rule is represented by a spiking neural network, a type of network
with dynamic internal state. We employ a constructivist model of growth of both
neurons and dendrites that realise flexible learning by evolving structures of
sufficient complexity to solve a well-known problem involving continuous,
real-valued inputs. Additionally, we extend the system to enable temporal state
decomposition. By allowing our LCS to chain together sequences of heterogeneous
actions into macro-actions, it is shown to perform optimally in a problem where
traditional methods can fail to find a solution in a reasonable amount of time.
Our final system is tested on a simulated robotics platform.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3250</identifier>
 <datestamp>2012-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3250</id><created>2012-01-16</created><updated>2012-06-14</updated><authors><author><keyname>Kartzow</keyname><forenames>Alexander</forenames></author><author><keyname>Parys</keyname><forenames>Pawe&#x142;</forenames></author></authors><title>Strictness of the Collapsible Pushdown Hierarchy</title><categories>cs.FL</categories><comments>68 pages, short version in MFCS 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a pumping lemma for each level of the collapsible pushdown graph
hierarchy in analogy to the second author's pumping lemma for higher-order
pushdown graphs (without collapse). Using this lemma, we give the first known
examples that separate the levels of the collapsible pushdown graph hierarchy
and of the collapsible pushdown tree hierarchy, i.e., the hierarchy of trees
generated by higher-order recursion schemes. This confirms the open conjecture
that higher orders allow one to generate more graphs and more trees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3251</identifier>
 <datestamp>2012-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3251</id><created>2012-01-16</created><updated>2012-04-16</updated><authors><author><keyname>Grabmayer</keyname><forenames>Clemens</forenames></author><author><keyname>Endrullis</keyname><forenames>Joerg</forenames></author><author><keyname>Hendriks</keyname><forenames>Dimitri</forenames></author><author><keyname>Klop</keyname><forenames>Jan Willem</forenames></author><author><keyname>Moss</keyname><forenames>Lawrence S.</forenames></author></authors><title>Automatic Sequences and Zip-Specifications</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider infinite sequences of symbols, also known as streams, and the
decidability question for equality of streams defined in a restricted format.
This restricted format consists of prefixing a symbol at the head of a stream,
of the stream function `zip', and recursion variables. Here `zip' interleaves
the elements of two streams in alternating order, starting with the first
stream. For example, the Thue-Morse sequence is obtained by the
`zip-specification' {M = 0 : X, X = 1 : zip(X,Y), Y = 0 : zip(Y,X)}. Our
analysis of such systems employs both term rewriting and coalgebraic
techniques. We establish decidability for these zip-specifications, employing
bisimilarity of observation graphs based on a suitably chosen cobasis. The
importance of zip-specifications resides in their intimate connection with
automatic sequences. We establish a new and simple characterization of
automatic sequences. Thus we obtain for the binary zip that a stream is
2-automatic iff its observation graph using the cobasis (hd,even,odd) is
finite. The generalization to zip-k specifications and their relation to
k-automaticity is straightforward. In fact, zip-specifications can be perceived
as a term rewriting syntax for automatic sequences. Our study of
zip-specifications is placed in an even wider perspective by employing the
observation graphs in a dynamic logic setting, leading to an alternative
characterization of automatic sequences. We further obtain a natural extension
of the class of automatic sequences, obtained by `zip-mix' specifications that
use zips of different arities in one specification. We also show that
equivalence is undecidable for a simple extension of the zip-mix format with
projections like even and odd. However, it remains open whether zip-mix
specifications have a decidable equivalence problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3273</identifier>
 <datestamp>2012-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3273</id><created>2012-01-16</created><updated>2012-11-03</updated><authors><author><keyname>Diwan</keyname><forenames>Ajit</forenames></author><author><keyname>Pal</keyname><forenames>Soumitra</forenames></author><author><keyname>Ranade</keyname><forenames>Abhiram</forenames></author></authors><title>Component Coloring of Proper Interval Graphs and Split Graphs</title><categories>cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a generalization of the well known graph (vertex) coloring
problem, which we call the problem of \emph{component coloring of graphs}.
Given a graph, the problem is to color the vertices using minimum number of
colors so that the size of each connected component of the subgraph induced by
the vertices of the same color does not exceed $C$. We give a linear time
algorithm for the problem on proper interval graphs. We extend this algorithm
to solve two weighted versions of the problem in which vertices have integer
weights. In the \emph{splittable} version the weights of vertices can be split
into differently colored parts, however, the total weight of a monochromatic
component cannot exceed $C$. For this problem on proper interval graphs we give
a polynomial time algorithm. In the \emph{non-splittable} version the vertices
cannot be split. Using the algorithm for the splittable version we give a
2-approximation algorithm for the non-splittable problem on proper interval
graphs which is NP-hard. We also prove that even the unweighted version of the
problem is NP-hard for split graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3278</identifier>
 <datestamp>2012-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3278</id><created>2012-01-16</created><authors><author><keyname>Zaidi</keyname><forenames>Abdellatif</forenames><affiliation>Shitz</affiliation></author><author><keyname>Piantanida</keyname><forenames>Pablo</forenames><affiliation>Shitz</affiliation></author><author><keyname>Shamai</keyname><forenames>Shlomo</forenames><affiliation>Shitz</affiliation></author></authors><title>Capacity Region of Multiple Access Channel with States Known Noncausally
  at One Encoder and Only Strictly Causally at the Other Encoder</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE Transactions on Information Theory, 38 pages, 2
  figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a two-user state-dependent multiaccess channel in which the
states of the channel are known non-causally to one of the encoders and only
strictly causally to the other encoder. Both encoders transmit a common message
and, in addition, the encoder that knows the states non-causally transmits an
individual message. We find explicit characterizations of the capacity region
of this communication model in both discrete memoryless (DM) and memoryless
Gaussian cases. In particular the capacity region analysis demonstrates the
utility of the knowledge of the states only strictly causally at the encoder
that sends only the common message in general. More specifically, in the DM
setting we show that such a knowledge is beneficial and increases the capacity
region in general. In the Gaussian setting, we show that such a knowledge does
not help, and the capacity is same as if the states were completely unknown at
the encoder that sends only the common message. The analysis also reveals
optimal ways of exploiting the knowledge of the state only strictly causally at
the encoder that sends only the common message when such a knowledge is
beneficial. The encoders collaborate to convey to the decoder a lossy version
of the state, in addition to transmitting the information messages through a
generalized Gel'fand-Pinsker binning. Particularly important in this problem
are the questions of 1) optimal ways of performing the state compression and 2)
whether or not the compression indices should be decoded uniquely. We show that
both compression \`a-la noisy network coding, i.e., with no binning and
non-unique decoding, and compression using Wyner-Ziv binning with backward
decoding and non-unique or unique decoding are optimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3292</identifier>
 <datestamp>2012-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3292</id><created>2012-01-16</created><authors><author><keyname>Zhao</keyname><forenames>Kun</forenames></author><author><keyname>Karsai</keyname><forenames>M&#xe1;rton</forenames></author><author><keyname>Bianconi</keyname><forenames>Ginestra</forenames></author></authors><title>Entropy of dynamical social networks</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><journal-ref>PLoS ONE 6(12): e28116 (2011)</journal-ref><doi>10.1371/journal.pone.0028116</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Human dynamical social networks encode information and are highly adaptive.
To characterize the information encoded in the fast dynamics of social
interactions, here we introduce the entropy of dynamical social networks. By
analysing a large dataset of phone-call interactions we show evidence that the
dynamical social network has an entropy that depends on the time of the day in
a typical week-day. Moreover we show evidence for adaptability of human social
behavior showing data on duration of phone-call interactions that significantly
deviates from the statistics of duration of face-to-face interactions. This
adaptability of behavior corresponds to a different information content of the
dynamics of social human interactions. We quantify this information by the use
of the entropy of dynamical networks on realistic models of social
interactions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3298</identifier>
 <datestamp>2013-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3298</id><created>2012-01-16</created><updated>2013-11-02</updated><authors><author><keyname>Curbelo</keyname><forenames>Jezabel</forenames></author><author><keyname>Mancho</keyname><forenames>Ana M.</forenames></author></authors><title>Spectral numerical schemes for time-dependent convection with viscosity
  dependent on temperature</title><categories>physics.comp-ph cs.NA math-ph math.MP</categories><comments>17 pages, 7 figures</comments><msc-class>35-04, 65-04, 65M70, 76R05, 76-04</msc-class><journal-ref>Commun. Nonlinear Sci. Numer. Simul. 19, 538 (2014)</journal-ref><doi>10.1016/j.cnsns.2013.04.005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article proposes spectral numerical methods to solve the time evolution
of convection problems with viscosity strongly depending on temperature at
infinite Prandtl number. Although we verify the proposed techniques just for
viscosities that depend exponentially on temperature, the methods are
extensible to other dependence laws. The set-up is a 2D domain with periodic
boundary conditions along the horizontal coordinate. This introduces a symmetry
in the problem, the O(2) symmetry, which is particularly well described by
spectral methods and motivates the use of these methods in this context. We
examine the scope of our techniques by exploring transitions from stationary
regimes towards time dependent regimes. At a given aspect ratio stable
stationary solutions become unstable through a Hopf bifurcation, after which
the time-dependent regime is solved by the spectral techniques proposed in this
article.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3306</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3306</id><created>2012-01-16</created><authors><author><keyname>Lipton</keyname><forenames>Richard J.</forenames></author><author><keyname>Regan</keyname><forenames>Kenneth W.</forenames></author><author><keyname>Rudra</keyname><forenames>Atri</forenames></author></authors><title>Simulating Special but Natural Quantum Circuits</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We identify a sub-class of BQP that captures certain structural commonalities
among many quantum algorithms including Shor's algorithms. This class does not
contain all of BQP (e.g. Grover's algorithm does not fall into this class). Our
main result is that any algorithm in this class that measures at most O(log n)
qubits can be simulated by classical randomized polynomial time algorithms.
This does not dequantize Shor's algorithm (as the latter measures n qubits) but
our work also highlights a new potentially hard function for cryptographic
applications.
  Our main technical contribution is (to the best of our knowledge) a new exact
characterization of certain sums of Fourier-type coefficients (with
exponentially many summands).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3307</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3307</id><created>2012-01-16</created><authors><author><keyname>Martelot</keyname><forenames>Erwan Le</forenames></author><author><keyname>Hankin</keyname><forenames>Chris</forenames></author></authors><title>Multi-scale Community Detection using Stability Optimisation within
  Greedy Algorithms</title><categories>cs.DS cs.SI physics.soc-ph</categories><comments>This paper is an extension of the paper named &quot;Multi-scale Community
  Detection using Stability as Optimisation Criterion in a Greedy Algorithm&quot; by
  the same authors published in Proc. of the 2011 Int. Conf. on Knowledge
  Discovery and Information Retrieval (KDIR 2011), SciTePress, 2011, 216-225</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many real systems can be represented as networks whose analysis can be very
informative regarding the original system's organisation. In the past decade
community detection received a lot of attention and is now an active field of
research. Recently stability was introduced as a new measure for partition
quality. This work investigates stability as an optimisation criterion that
exploits a Markov process view of networks to enable multi-scale community
detection. Several heuristics and variations of an algorithm optimising
stability are presented as well as an application to overlapping communities.
Experiments show that the method enables accurate multi-scale network analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3310</identifier>
 <datestamp>2015-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3310</id><created>2012-01-16</created><updated>2015-02-24</updated><authors><author><keyname>Park</keyname><forenames>Gahyun</forenames></author></authors><title>A Generalization of Multiple Choice Balls-into-Bins: Tight Bounds</title><categories>cs.DM cs.DC</categories><comments>38 pages</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates a general version of the multiple choice model called
the $(k,d)$-choice process in which $n$ balls are assigned to $n$ bins. In the
process, $k&lt;d$ balls are placed into $k$ least loaded out of $d$ bins chosen
independently and uniformly at random in each of $\frac{n}{k}$ rounds. The
primary goal is to derive tight bounds on the maximum bin load for
$(k,d)$-choice for any $1 \leq k &lt; d \leq n$. Our results enable one to choose
suitable parameters $k$ and $d$ for which the $(k,d)$-choice process achieves
the optimal tradeoff between the maximum bin load and message cost: a constant
maximum load and $2n$ messages. It is also shown that the maximum load for a
heavily loaded case, in which $m&gt;n$ balls are placed into $n$ bins, if $d \geq
2k$. Potential applications are also discussed such as distributed storage as
well as parallel job scheduling in a cluster.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3315</identifier>
 <datestamp>2012-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3315</id><created>2012-01-13</created><authors><author><keyname>G&#xfc;zeltepe</keyname><forenames>Murat</forenames></author></authors><title>Perfect Mannheim, Lipschitz and Hurwitz weight codes</title><categories>cs.IT math.IT</categories><comments>21 pages</comments><msc-class>94B05, 94B15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, upper bounds on codes over Gaussian integers, Lipschitz
integers and Hurwitz integers with respect to Mannheim metric, Lipschitz and
Hurwitz metric are given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3316</identifier>
 <datestamp>2014-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3316</id><created>2012-01-13</created><authors><author><keyname>G&#xfc;zeltepe</keyname><forenames>Murat</forenames></author></authors><title>Codes over Hurwitz integers</title><categories>cs.IT math.IT</categories><comments>11 pages</comments><msc-class>94B05, 94B15, 94B35, 94B60</msc-class><doi>10.1016/j.disc.2012.10.020</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this study, we obtain new classes of linear codes over Hurwitz integers
equipped with a new metric. We refer to the metric as Hurwitz metric. The codes
with respect to Hurwitz metric use in coded modu- lation schemes based on
quadrature amplitude modulation (QAM)-type constellations, for which neither
Hamming metric nor Lee metric. Also, we define decoding algorithms for these
codes when up to two coordinates of a transmitted code vector are effected by
error of arbitrary Hurwitz weight.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3318</identifier>
 <datestamp>2012-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3318</id><created>2012-01-16</created><authors><author><keyname>Kik</keyname><forenames>Marcin</forenames></author></authors><title>Notes on Bit-reversal Broadcast Scheduling</title><categories>cs.DS cs.DC cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This report contains revision and extension of some results about RBO
[arXiv:1108.5095]. RBO is a simple and efficient broadcast scheduling of $n =
2^k$ uniform frames for battery powered radio receivers. Each frame contains a
key from some arbitrary linearly ordered universe. The broadcast cycle -- a
sequence of frames sorted by the keys and permuted by $k$-bit reversal -- is
transmitted in a round robin fashion by the broadcaster. At arbitrary time
during the transmission, the receiver may start a simple protocol that reports
to him all the frames with the keys that are contained in a specified interval
of the key values $[K', K&quot;]$. RBO receives at most $2 k + 1$ other frames' keys
before receiving the first key from $[K', K&quot;]$ or noticing that there are no
such keys in the broadcast cycle. As a simple corollary, $4 k + 2$ is upper
bound the number of keys outside $[K', K&quot;]$ that will ever be received. In
unreliable network the expected number of efforts to receive such frames is
bounded by $(8 k + 4) / p + 2 (1 - p) / p^2$, where $p$ is probability of
successful reception, and the reception rate of the requested frames is $p$ --
the highest possible. The receiver's protocol state consists of the values $k$,
$K'$ and $K&quot;$, one wake-up timer and two other $k$-bit variables. Its only
nontrivial computation -- the computation of the next wake-up time slot -- can
be performed in $O (k)$ simple operations, such as arithmetic/bit-wise
operations on $k$-bit numbers, using only constant number of $k$-bit variables.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3328</identifier>
 <datestamp>2012-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3328</id><created>2012-01-16</created><updated>2012-08-08</updated><authors><author><keyname>Xiao</keyname><forenames>Yuanzhang</forenames></author><author><keyname>van der Schaar</keyname><forenames>Mihaela</forenames></author></authors><title>Dynamic Spectrum Sharing Among Repeatedly Interacting Selfish Users With
  Imperfect Monitoring</title><categories>cs.IT math.IT</categories><comments>37 pages, 8 figures, 4 tables; IEEE Journal on Selected Areas in
  Communications (JSAC) 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a novel design framework for dynamic distributed spectrum sharing
among secondary users (SUs) who adjust their power levels to compete for
spectrum opportunities while satisfying the interference temperature (IT)
constraints imposed by primary users. The considered interaction among the SUs
is characterized by the following three features. First, since the SUs are
decentralized, they are selfish and aim to maximize their own long-term payoffs
from utilizing the network rather than obeying the prescribed allocation of a
centralized controller. Second, the SUs interact with each other repeatedly and
they can coexist in the system for a long time. Third, the SUs have limited and
imperfect monitoring ability: they only observe whether the IT constraints are
violated, and their observation is imperfect due to the erroneous measurements.
To capture these features, we model the interaction of the SUs as a repeated
game with imperfect monitoring. We first characterize the set of Pareto optimal
payoffs that can be achieved by deviation-proof spectrum sharing policies,
which are policies that the selfish users find it in their interest to comply
with. Next, for any given payoff in this set, we show how to construct a
deviation-proof policy to achieve it. The constructed deviation-proof policy is
amenable to distributed implementation, and allows users to transmit in a
time-division multiple-access (TDMA) fashion. In the presence of strong
multi-user interference, our policy outperforms existing spectrum sharing
policies that dictate users to transmit at constant power levels
simultaneously. Moreover, our policy can achieve Pareto optimality even when
the SUs have limited and imperfect monitoring ability, as opposed to existing
solutions based on repeated games, which require perfect monitoring abilities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3332</identifier>
 <datestamp>2012-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3332</id><created>2012-01-16</created><authors><author><keyname>C.</keyname><forenames>Ramya Menon</forenames></author><author><keyname>Pangracious</keyname><forenames>Vinod</forenames></author></authors><title>A Novel Methodology for Thermal Aware Silicon Area Estimation for 2D &amp;
  3D MPSoCs</title><categories>cs.ET cs.AR</categories><journal-ref>VLSICS, International Journal of VLSI Design &amp; Communication
  Systems, Vol 2, Num 4 (2011) 155-165</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a multiprocessor system on chip (MPSoC) IC the processor is one of the
highest heat dissipating devices. The temperature generated in an IC may vary
with floor plan of the chip. This paper proposes an integration and thermal
analysis methodology to extract the peak temperature and temperature
distribution of 2-dimensional and 3-dimensional multiprocessor system-on-chip.
As we know the peak temperature of chip increases in 3-dimensional structures
compared to 2-dimensional ones due to the reduced space in intra-layer and
inter-layer components. In sub-nanometre scale technologies, it is inevitable
to analysis the heat developed in individual chip to extract the temperature
distribution of the entire chip. With the technology scaling in new generation
ICs more and more components are integrated to a smaller area. Along with the
other parameters threshold voltage is also scaled down which results in
exponential increase in leakage current. This has resulted in rise in hotspot
temperature value due to increase in leakage power. In this paper, we have
analysed the temperature developed in an IC with four identical processors at
2.4 GHz in different floorplans. The analysis has been done for both 2D and 3D
arrangements. In the 3D arrangement, a three layered structure has been
considered with two Silicon layers and a thermal interface material (TIM) in
between them. Based on experimental results the paper proposes a methodology to
reduce the peak temperature developed in 2D and 3D integrated circuits .
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3337</identifier>
 <datestamp>2012-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3337</id><created>2012-01-08</created><authors><author><keyname>Alamdar</keyname><forenames>Fatemeh</forenames></author><author><keyname>Keyvanpour</keyname><forenames>MohammadReza</forenames></author></authors><title>A New Color Feature Extraction Method Based on Dynamic Color
  Distribution Entropy of Neighborhoods</title><categories>cs.CV cs.MM</categories><journal-ref>International Journal of Computer Science Issues, Vol. 8, Issue 5,
  No 1 (2011) 42-48</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the important requirements in image retrieval, indexing,
classification, clustering and etc. is extracting efficient features from
images. The color feature is one of the most widely used visual features. Use
of color histogram is the most common way for representing color feature. One
of disadvantage of the color histogram is that it does not take the color
spatial distribution into consideration. In this paper dynamic color
distribution entropy of neighborhoods method based on color distribution
entropy is presented, which effectively describes the spatial information of
colors. The image retrieval results in compare to improved color distribution
entropy show the acceptable efficiency of this approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3353</identifier>
 <datestamp>2012-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3353</id><created>2012-01-16</created><updated>2012-05-16</updated><authors><author><keyname>Garoufalidis</keyname><forenames>Stavros</forenames></author><author><keyname>Koutschan</keyname><forenames>Christoph</forenames></author></authors><title>Twisting q-holonomic sequences by complex roots of unity</title><categories>math.GT cs.SC math.CO</categories><comments>8 pages, 2 figures, 1 table, final version for the ISSAC proceedings;
  Proceedings of ISSAC 2012</comments><acm-class>G.2.1; G.4; I.1.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A sequence $f_n(q)$ is $q$-holonomic if it satisfies a nontrivial linear
recurrence with coefficients polynomials in $q$ and $q^n$. Our main theorems
state that $q$-holonomicity is preserved under twisting, i.e., replacing $q$ by
$\omega q$ where $\omega$ is a complex root of unity, and under the
substitution $q \to q^{\alpha}$ where $\alpha$ is a rational number. Our proofs
are constructive, work in the multivariate setting of $\partial$-finite
sequences and are implemented in the Mathematica package HolonomicFunctions.
Our results are illustrated by twisting natural $q$-holonomic sequences which
appear in quantum topology, namely the colored Jones polynomial of pretzel
knots and twist knots. The recurrence of the twisted colored Jones polynomial
can be used to compute the asymptotics of the Kashaev invariant of a knot at an
arbitrary complex root of unity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3382</identifier>
 <datestamp>2012-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3382</id><created>2012-01-16</created><updated>2012-04-03</updated><authors><author><keyname>Goodfellow</keyname><forenames>Ian J.</forenames></author><author><keyname>Courville</keyname><forenames>Aaron</forenames></author><author><keyname>Bengio</keyname><forenames>Yoshua</forenames></author></authors><title>Spike-and-Slab Sparse Coding for Unsupervised Feature Discovery</title><categories>stat.ML cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of using a factor model we call {\em spike-and-slab
sparse coding} (S3C) to learn features for a classification task. The S3C model
resembles both the spike-and-slab RBM and sparse coding. Since exact inference
in this model is intractable, we derive a structured variational inference
procedure and employ a variational EM training algorithm. Prior work on
approximate inference for this model has not prioritized the ability to exploit
parallel architectures and scale to enormous problem sizes. We present an
inference procedure appropriate for use with GPUs which allows us to
dramatically increase both the training set size and the amount of latent
factors.
  We demonstrate that this approach improves upon the supervised learning
capabilities of both sparse coding and the ssRBM on the CIFAR-10 dataset. We
evaluate our approach's potential for semi-supervised learning on subsets of
CIFAR-10. We demonstrate state-of-the art self-taught learning performance on
the STL-10 dataset and use our method to win the NIPS 2011 Workshop on
Challenges In Learning Hierarchical Models' Transfer Learning Challenge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3401</identifier>
 <datestamp>2012-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3401</id><created>2012-01-16</created><updated>2012-05-03</updated><authors><author><keyname>Adrovic</keyname><forenames>Danko</forenames></author><author><keyname>Verschelde</keyname><forenames>Jan</forenames></author></authors><title>Computing Puiseux Series for Algebraic Surfaces</title><categories>cs.SC math.AG math.NA</categories><comments>accepted for presentation at ISSAC 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we outline an algorithmic approach to compute Puiseux series
expansions for algebraic surfaces. The series expansions originate at the
intersection of the surface with as many coordinate planes as the dimension of
the surface. Our approach starts with a polyhedral method to compute cones of
normal vectors to the Newton polytopes of the given polynomial system that
defines the surface. If as many vectors in the cone as the dimension of the
surface define an initial form system that has isolated solutions, then those
vectors are potential tropisms for the initial term of the Puiseux series
expansion. Our preliminary methods produce exact representations for solution
sets of the cyclic $n$-roots problem, for $n = m^2$, corresponding to a result
of Backelin.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3408</identifier>
 <datestamp>2012-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3408</id><created>2012-01-16</created><authors><author><keyname>Djuric</keyname><forenames>Milos B.</forenames></author><author><keyname>Ilic</keyname><forenames>Velimir M.</forenames></author><author><keyname>Stankovic</keyname><forenames>Miomir S.</forenames></author></authors><title>The computation of first order moments on junction trees</title><categories>cs.AI</categories><comments>9 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We review some existing methods for the computation of first order moments on
junction trees using Shafer-Shenoy algorithm. First, we consider the problem of
first order moments computation as vertices problem in junction trees. In this
way, the problem is solved using the memory space of an order of the junction
tree edge-set cardinality. After that, we consider two algorithms,
Lauritzen-Nilsson algorithm, and Mau\'a et al. algorithm, which computes the
first order moments as the normalization problem in junction tree, using the
memory space of an order of the junction tree leaf-set cardinality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3410</identifier>
 <datestamp>2012-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3410</id><created>2012-01-16</created><authors><author><keyname>Florindo</keyname><forenames>Jo&#xe3;o B.</forenames></author><author><keyname>Sikora</keyname><forenames>Mariana S.</forenames></author><author><keyname>Pereira</keyname><forenames>Ernesto C.</forenames></author><author><keyname>Bruno</keyname><forenames>Odemir M.</forenames></author></authors><title>Multiscale Fractal Descriptors Applied to Nanoscale Images</title><categories>physics.data-an cond-mat.mes-hall cond-mat.mtrl-sci cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work proposes the application of fractal descriptors to the analysis of
nanoscale materials under different experimental conditions. We obtain
descriptors for images from the sample applying a multiscale transform to the
calculation of fractal dimension of a surface map of such image. Particularly,
we have used the}Bouligand-Minkowski fractal dimension. We applied these
descriptors to discriminate between two titanium oxide films prepared under
different experimental conditions. Results demonstrate the discrimination power
of proposed descriptors in such kind of application.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3416</identifier>
 <datestamp>2012-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3416</id><created>2012-01-16</created><authors><author><keyname>Al-Bataineh</keyname><forenames>Omar I.</forenames></author><author><keyname>Reynolds</keyname><forenames>Mark</forenames></author><author><keyname>French</keyname><forenames>Tim</forenames></author><author><keyname>Woodings</keyname><forenames>Terry</forenames></author></authors><title>Verifying Real-time Commit Protocols Using Dense-time Model Checking
  Technology</title><categories>cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The timed-based automata model, introduced by Alur and Dill, provides a
useful formalism for describing real-time systems. Over the last two decades,
several dense-time model checking tools have been developed based on that
model. The paper considers the verification of real-time distributed commit
protocols using dense-time model checking technology. More precisely, we model
and verify the well-known timed two phase commit protocol in three different
state-of-the-art real-time model checkers: UPPAAL, Rabbit, and RED, and compare
the results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3417</identifier>
 <datestamp>2012-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3417</id><created>2012-01-16</created><authors><author><keyname>Baradwaj</keyname><forenames>Brijesh Kumar</forenames></author><author><keyname>Pal</keyname><forenames>Saurabh</forenames></author></authors><title>Mining Educational Data to Analyze Students' Performance</title><categories>cs.IR</categories><comments>7 pages. arXiv admin note: substantial text overlap with
  arXiv:1002.1144 by other authors without attribution</comments><journal-ref>IJACSA Vol. 2, No. 6, 2011, pp 63-69</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The main objective of higher education institutions is to provide quality
education to its students. One way to achieve highest level of quality in
higher education system is by discovering knowledge for prediction regarding
enrolment of students in a particular course, alienation of traditional
classroom teaching model, detection of unfair means used in online examination,
detection of abnormal values in the result sheets of the students, prediction
about students' performance and so on. The knowledge is hidden among the
educational data set and it is extractable through data mining techniques.
Present paper is designed to justify the capabilities of data mining techniques
in context of higher education by offering a data mining model for higher
education system in the university. In this research, the classification task
is used to evaluate student's performance and as there are many approaches that
are used for data classification, the decision tree method is used here. By
this task we extract knowledge that describes students' performance in end
semester examination. It helps earlier in identifying the dropouts and students
who need special attention and allow the teacher to provide appropriate
advising/counseling. Keywords-Educational Data Mining (EDM); Classification;
Knowledge Discovery in Database (KDD); ID3 Algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3418</identifier>
 <datestamp>2012-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3418</id><created>2012-01-16</created><authors><author><keyname>Bhardwaj</keyname><forenames>Brijesh Kumar</forenames></author><author><keyname>Pal</keyname><forenames>Saurabh</forenames></author></authors><title>Data Mining: A prediction for performance improvement using
  classification</title><categories>cs.IR</categories><comments>5 pages. arXiv admin note: substantial text overlap with
  arXiv:1002.1144 by other authors without attribution</comments><journal-ref>(IJCSIS) International Journal of Computer Science and Information
  Security, Vol. 9, No. 4, April 2011, pp 136-140</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Now-a-days the amount of data stored in educational database increasing
rapidly. These databases contain hidden information for improvement of
students' performance. The performance in higher education in India is a
turning point in the academics for all students. This academic performance is
influenced by many factors, therefore it is essential to develop predictive
data mining model for students' performance so as to identify the difference
between high learners and slow learners student. In the present investigation,
an experimental methodology was adopted to generate a database. The raw data
was preprocessed in terms of filling up missing values, transforming values in
one form into another and relevant attribute/ variable selection. As a result,
we had 300 student records, which were used for by Byes classification
prediction model construction. Keywords- Data Mining, Educational Data Mining,
Predictive Model, Classification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3456</identifier>
 <datestamp>2012-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3456</id><created>2012-01-17</created><authors><author><keyname>Espinosa</keyname><forenames>Omar Baqueiro</forenames></author></authors><title>A Genetic Algorithm for the Calibration of a Micro-Simulation Model</title><categories>cs.OH</categories><acm-class>J.4.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes the process followed to calibrate a micro-simulation
model for the Altmark region in Germany and a Derbyshire region in the UK. The
calibration process is performed in three main steps: first, a subset of input
and output variables to use for the calibration process is selected from the
complete parameter space in the model; second, the calibration process is
performed using a genetic algorithm calibration approach; finally, a comparison
between the real data and the data obtained from the best fit model is done to
verify the accuracy of the model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3457</identifier>
 <datestamp>2012-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3457</id><created>2012-01-17</created><authors><author><keyname>Yordzhev</keyname><forenames>Krasimir</forenames></author><author><keyname>Kostadinova</keyname><forenames>Hristina</forenames></author></authors><title>On Some Entertaining Applications of the Concept of Set in Computer
  Science Course</title><categories>cs.OH math.HO</categories><journal-ref>Informational Technologies in Education. - 2011. - No. 10. - P.
  24-29</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Some aspects of programming education are examined in this work. It is
emphasised, based on the entertainment value, the most appropriate examples are
chosen to demonstrate the different language constructions and data structures.
Such an example is the demonstrated algorithm for solving the widespread
nowadays &quot;Sudoku&quot; puzzle. This is made, because of the connection with the term
set and putting it into practice in the programming. Using the so built program
there are solved some combinatorial problems, connected to the Sudoku matrices.
  Key words: Education in programming, programming languages, data structures,
set, Sudoku matrix, Sudoku puzzle.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3458</identifier>
 <datestamp>2012-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3458</id><created>2012-01-17</created><authors><author><keyname>Wu</keyname><forenames>Di</forenames></author><author><keyname>Ke</keyname><forenames>Yiping</forenames></author><author><keyname>Yu</keyname><forenames>Jeffrey Xu</forenames></author><author><keyname>Liu</keyname><forenames>Zheng</forenames></author></authors><title>Detecting Priming News Events</title><categories>cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a problem of detecting priming events based on a time series index
and an evolving document stream. We define a priming event as an event which
triggers abnormal movements of the time series index, i.e., the Iraq war with
respect to the president approval index of President Bush. Existing solutions
either focus on organizing coherent keywords from a document stream into events
or identifying correlated movements between keyword frequency trajectories and
the time series index. In this paper, we tackle the problem in two major steps.
(1) We identify the elements that form a priming event. The element identified
is called influential topic which consists of a set of coherent keywords. And
we extract them by looking at the correlation between keyword trajectories and
the interested time series index at a global level. (2) We extract priming
events by detecting and organizing the bursty influential topics at a micro
level. We evaluate our algorithms on a real-world dataset and the result
confirms that our method is able to discover the priming events effectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3466</identifier>
 <datestamp>2015-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3466</id><created>2012-01-17</created><authors><author><keyname>Yan</keyname><forenames>Bowen</forenames></author><author><keyname>Gregory</keyname><forenames>Steve</forenames></author></authors><title>Detecting community structure in networks using edge prediction methods</title><categories>physics.soc-ph cs.SI</categories><comments>5 pages, 2 figures</comments><doi>10.1088/1742-5468/2012/09/P09008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Community detection and edge prediction are both forms of link mining: they
are concerned with discovering the relations between vertices in networks. Some
of the vertex similarity measures used in edge prediction are closely related
to the concept of community structure. We use this insight to propose a novel
method for improving existing community detection algorithms by using a simple
vertex similarity measure. We show that this new strategy can be more effective
in detecting communities than the basic community detection algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3467</identifier>
 <datestamp>2012-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3467</id><created>2012-01-17</created><authors><author><keyname>Kiani</keyname><forenames>Arman</forenames></author><author><keyname>Annaswamy</keyname><forenames>Anuradha</forenames></author></authors><title>Perturbation Analysis of the Wholesale Energy Market Equilibrium in the
  Presence of Renewables</title><categories>math.OC cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the main challenges in the emerging smart grid is the integration of
renewable energy resources (RER). The latter introduces both intermittency and
uncertainty into the grid, both of which can affect the underlying energy
market. An interesting concept that is being explored for mitigating the
integration cost of RERs is Demand Response. Implemented as a time-varying
electricity price in real-time, Demand Response has a direct impact on the
underlying energy market as well. Beginning with an overall model of the major
market participants together with the constraints of transmission and
generation, we analyze the energy market in this paper and derive conditions
for global maximum using standard KKT criteria. The effect of uncertainties in
the RER on the market equilibrium is then quantified, with and without
real-time pricing. Perturbation analysis methods are used to compare the
equilibria in the nominal and perturbed markets. These markets are also
analyzed using a game-theoretic point of view. Sufficient conditions are
derived for the existence of a unique Pure Nash Equilibrium in the nominal
market. The perturbed market is analyzed using the concept of closeness of two
strategic games and the equilibria of close games. This analysis is used to
quantify the effect of uncertainty of RERs and its possible mitigation using
Demand Response. Finally numerical studies are reported using an IEEE 30-bus to
validate the theoretical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3479</identifier>
 <datestamp>2012-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3479</id><created>2012-01-17</created><authors><author><keyname>Zemanov&#xe1;</keyname><forenames>Alena</forenames></author><author><keyname>Zeman</keyname><forenames>Jan</forenames></author><author><keyname>&#x160;ejnoha</keyname><forenames>Michal</forenames></author></authors><title>Simple Numerical Model of Laminated Glass Beams</title><categories>cs.CE</categories><comments>10 pages, 3 figures</comments><journal-ref>Acta Polytechnica, 48(6), 22-26 (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This contribution presents a simple Finite Element model aimed at efficient
simulation of layered glass units. The adopted approach is based on considering
independent kinematics of each layer, tied together via Lagrange multipliers.
Validation and verification of the resulting model against independent data
demonstrate its accuracy, showing its potential for generalization towards more
complex problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3480</identifier>
 <datestamp>2012-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3480</id><created>2012-01-17</created><authors><author><keyname>Scholtes</keyname><forenames>Ingo</forenames></author><author><keyname>Tessone</keyname><forenames>Claudio Juan</forenames></author></authors><title>Organic Design of Massively Distributed Systems: A Complex Networks
  Perspective</title><categories>cs.NI cond-mat.stat-mech physics.soc-ph</categories><comments>17 pages, 14 figures, preprint of submission to Informatik-Spektrum
  published by Springer</comments><acm-class>C.2.1; C.2.2; C.2.3; C.2.4</acm-class><journal-ref>Informatik-Spektrum, Volume 35, Number 2 (2012), 75-86</journal-ref><doi>10.1007/s00287-012-0597-4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The vision of Organic Computing addresses challenges that arise in the design
of future information systems that are comprised of numerous, heterogeneous,
resource-constrained and error-prone components or devices. Here, the notion
organic particularly highlights the idea that, in order to be manageable, such
systems should exhibit self-organization, self-adaptation and self-healing
characteristics similar to those of biological systems. In recent years, the
principles underlying many of the interesting characteristics of natural
systems have been investigated from the perspective of complex systems science,
particularly using the conceptual framework of statistical physics and
statistical mechanics. In this article, we review some of the interesting
relations between statistical physics and networked systems and discuss
applications in the engineering of organic networked computing systems with
predictable, quantifiable and controllable self-* properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3496</identifier>
 <datestamp>2015-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3496</id><created>2012-01-17</created><authors><author><keyname>Malas</keyname><forenames>Tareq M.</forenames></author><author><keyname>Ahmadia</keyname><forenames>Aron J.</forenames></author><author><keyname>Brown</keyname><forenames>Jed</forenames></author><author><keyname>Gunnels</keyname><forenames>John A.</forenames></author><author><keyname>Keyes</keyname><forenames>David E.</forenames></author></authors><title>Optimizing the Performance of Streaming Numerical Kernels on the IBM
  Blue Gene/P PowerPC 450 Processor</title><categories>cs.PF</categories><doi>10.1177/1094342012444795</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Several emerging petascale architectures use energy-efficient processors with
vectorized computational units and in-order thread processing. On these
architectures the sustained performance of streaming numerical kernels,
ubiquitous in the solution of partial differential equations, represents a
challenge despite the regularity of memory access. Sophisticated optimization
techniques are required to fully utilize the Central Processing Unit (CPU).
  We propose a new method for constructing streaming numerical kernels using a
high-level assembly synthesis and optimization framework. We describe an
implementation of this method in Python targeting the IBM Blue Gene/P
supercomputer's PowerPC 450 core. This paper details the high-level design,
construction, simulation, verification, and analysis of these kernels utilizing
a subset of the CPU's instruction set.
  We demonstrate the effectiveness of our approach by implementing several
three-dimensional stencil kernels over a variety of cached memory scenarios and
analyzing the mechanically scheduled variants, including a 27-point stencil
achieving a 1.7x speedup over the best previously published results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3498</identifier>
 <datestamp>2013-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3498</id><created>2012-01-17</created><updated>2013-01-11</updated><authors><author><keyname>Hansen</keyname><forenames>Thomas Dueholm</forenames></author><author><keyname>Ibsen-Jensen</keyname><forenames>Rasmus</forenames></author><author><keyname>Miltersen</keyname><forenames>Peter Bro</forenames></author></authors><title>A Faster Algorithm for Solving One-Clock Priced Timed Games</title><categories>cs.GT cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One-clock priced timed games is a class of two-player, zero-sum,
continuous-time games that was defined and thoroughly studied in previous
works. We show that one-clock priced timed games can be solved in time m 12^n
n^(O(1)), where n is the number of states and m is the number of actions. The
best previously known time bound for solving one-clock priced timed games was
2^(O(n^2+m)), due to Rutkowski. For our improvement, we introduce and study a
new algorithm for solving one-clock priced timed games, based on the sweep-line
technique from computational geometry and the strategy iteration paradigm from
the algorithmic theory of Markov decision processes. As a corollary, we also
improve the analysis of previous algorithms due to Bouyer, Cassez, Fleury, and
Larsen; and Alur, Bernadsky, and Madhusudan.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3519</identifier>
 <datestamp>2015-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3519</id><created>2012-01-17</created><authors><author><keyname>Avdoshenko</keyname><forenames>Stas M.</forenames></author><author><keyname>da Rocha</keyname><forenames>Claudia Gomes</forenames></author><author><keyname>Cuniberti</keyname><forenames>Gianaurelio</forenames></author></authors><title>Nanoscale ear drum: Graphene based nanoscale sensors</title><categories>cond-mat.mtrl-sci cs.CE physics.chem-ph</categories><doi>10.1039/c2nr30097d</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The difficulty in determining the mass of a sample increases as its size
diminishes. At the nanoscale, there are no direct methods for resolving the
mass of single molecules or nanoparticles and so more sophisticated approaches
based on electromechanical phenomena are required. More importantly, one
demands that such nanoelectromechanical techniques could provide not only
information about the mass of the target molecules but also about their
geometrical properties. In this sense, we report a theoretical study that
illustrates in detail how graphene membranes can operate as
nanoelectromechanical mass-sensor devices. Wide graphene sheets were exposed to
different types and amounts of molecules and molecular dynamic simulations were
employed to treat these doping processes statistically. We demonstrate that the
mass variation effect and information about the graphene-molecule interactions
can be inferred through dynamical response functions. Our results confirm the
potential use of graphene as mass detector devices with remarkable precision in
estimating variations in mass at molecular scale and other physical properties
of the dopants.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3543</identifier>
 <datestamp>2014-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3543</id><created>2012-01-17</created><updated>2014-11-26</updated><authors><author><keyname>Marichal</keyname><forenames>Jean-Luc</forenames></author><author><keyname>Mathonet</keyname><forenames>Pierre</forenames></author></authors><title>Influence and interaction indexes for pseudo-Boolean functions: a
  unified least squares approach</title><categories>math.OC cs.DM</categories><msc-class>91A12, 93E24 (Primary) 39A70, 41A10 (Secondary)</msc-class><journal-ref>Discrete Applied Mathematics 179 (2014) 13-27</journal-ref><doi>10.1016/j.dam.2014.05.039</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Banzhaf power and interaction indexes for a pseudo-Boolean function (or a
cooperative game) appear naturally as leading coefficients in the standard
least squares approximation of the function by a pseudo-Boolean function of a
specified degree. We first observe that this property still holds if we
consider approximations by pseudo-Boolean functions depending only on specified
variables. We then show that the Banzhaf influence index can also be obtained
from the latter approximation problem. Considering certain weighted versions of
this approximation problem, we introduce a class of weighted Banzhaf influence
indexes, analyze their most important properties, and point out similarities
between the weighted Banzhaf influence index and the corresponding weighted
Banzhaf interaction index. We also discuss the issue of reconstructing a
pseudo-Boolean function from prescribed influences and point out very different
behaviors in the weighted and non-weighted cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3545</identifier>
 <datestamp>2012-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3545</id><created>2012-01-16</created><authors><author><keyname>Bull</keyname><forenames>Larry</forenames></author></authors><title>On Natural Genetic Engineering: Structural Dynamism in Random Boolean
  Networks</title><categories>cs.CE q-bio.MN</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This short paper presents an abstract, tunable model of genomic structural
change within the cell lifecycle and explores its use with simulated evolution.
A well-known Boolean model of genetic regulatory networks is extended to
include changes in node connectivity based upon the current cell state, e.g.,
via transposable elements. The underlying behaviour of the resulting dynamical
networks is investigated before their evolvability is explored using a version
of the NK model of fitness landscapes. Structural dynamism is found to be
selected for in non-stationary environments and subsequently shown capable of
providing a mechanism for evolutionary innovation when such reorganizations are
inherited.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3547</identifier>
 <datestamp>2012-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3547</id><created>2012-01-13</created><authors><author><keyname>Ernvall</keyname><forenames>Toni</forenames></author></authors><title>The existence of fractional repetition codes</title><categories>math.CO cs.DM</categories><comments>one page, no figures</comments><msc-class>68R05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Salim El Rouayheb and Kannan Ramchandran introduced the concept of fractional
repetition (FR) code. In their article it remained unsolved when we can find
such codes. Here we give an exact characterization of situations when it is
possible to find an FR code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3584</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3584</id><created>2012-01-17</created><authors><author><keyname>Ermann</keyname><forenames>Leonardo</forenames></author><author><keyname>Shepelyansky</keyname><forenames>Dima L.</forenames></author></authors><title>Ecological analysis of world trade</title><categories>q-fin.GN cond-mat.stat-mech cs.SI physics.soc-ph</categories><comments>5 pages, 6 figures (6 extra figures in Supporting Information)</comments><journal-ref>Phys. Lett. A 377, 250-256 (2013)</journal-ref><doi>10.1016/j.physleta.2012.10.056</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ecological systems have a high level of complexity combined with stability
and rich biodiversity. Recently, the analysis of their properties and evolution
has been pushed forward on a basis of concept of mutualistic networks that
provides a detailed understanding of their features being linked to a high
nestedness of these networks. It was shown that the nestedness architecture of
mutualistic networks of plants and their pollinators minimizes competition and
increases biodiversity. Here, using the United Nations COMTRADE database for
years 1962 - 2009, we show that a similar ecological analysis gives a valuable
description of the world trade. In fact the countries and trade products are
analogous to plants and pollinators, and the whole trade network is
characterized by a low nestedness temperature which is typical for the
ecological networks. This approach provides new mutualistic features of the
world trade highlighting new significance of countries and trade products for
the world trade.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3592</identifier>
 <datestamp>2012-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3592</id><created>2012-01-17</created><updated>2012-05-14</updated><authors><author><keyname>Sayama</keyname><forenames>Hiroki</forenames></author><author><keyname>Akaishi</keyname><forenames>Jin</forenames></author></authors><title>Characterizing Interdisciplinarity of Researchers and Research Topics
  Using Web Search Engines</title><categories>cs.SI cs.DL physics.soc-ph</categories><comments>20 pages, 7 figures. Accepted for publication in PLoS One</comments><journal-ref>PLoS One 7(6): e38747 (2012)</journal-ref><doi>10.1371/journal.pone.0038747</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Researchers' networks have been subject to active modeling and analysis.
Earlier literature mostly focused on citation or co-authorship networks
reconstructed from annotated scientific publication databases, which have
several limitations. Recently, general-purpose web search engines have also
been utilized to collect information about social networks. Here we
reconstructed, using web search engines, a network representing the relatedness
of researchers to their peers as well as to various research topics.
Relatedness between researchers and research topics was characterized by
visibility boost-increase of a researcher's visibility by focusing on a
particular topic. It was observed that researchers who had high visibility
boosts by the same research topic tended to be close to each other in their
network. We calculated correlations between visibility boosts by research
topics and researchers' interdisciplinarity at individual level (diversity of
topics related to the researcher) and at social level (his/her centrality in
the researchers' network). We found that visibility boosts by certain research
topics were positively correlated with researchers' individual-level
interdisciplinarity despite their negative correlations with the general
popularity of researchers. It was also found that visibility boosts by
network-related topics had positive correlations with researchers' social-level
interdisciplinarity. Research topics' correlations with researchers'
individual- and social-level interdisciplinarities were found to be nearly
independent from each other. These findings suggest that the notion of
&quot;interdisciplinarity&quot; of a researcher should be understood as a
multi-dimensional concept that should be evaluated using multiple assessment
means.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3599</identifier>
 <datestamp>2015-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3599</id><created>2012-01-17</created><authors><author><keyname>Schizas</keyname><forenames>Ioannis D.</forenames></author><author><keyname>Giannakis</keyname><forenames>Georgios B.</forenames></author></authors><title>Covariance Eigenvector Sparsity for Compression and Denoising</title><categories>stat.AP cs.IT math.IT</categories><comments>IEEE Transcations on Signal Processing, 2012 (to appear)</comments><doi>10.1109/TSP.2012.2186130</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sparsity in the eigenvectors of signal covariance matrices is exploited in
this paper for compression and denoising. Dimensionality reduction (DR) and
quantization modules present in many practical compression schemes such as
transform codecs, are designed to capitalize on this form of sparsity and
achieve improved reconstruction performance compared to existing
sparsity-agnostic codecs. Using training data that may be noisy a novel
sparsity-aware linear DR scheme is developed to fully exploit sparsity in the
covariance eigenvectors and form noise-resilient estimates of the principal
covariance eigenbasis. Sparsity is effected via norm-one regularization, and
the associated minimization problems are solved using computationally efficient
coordinate descent iterations. The resulting eigenspace estimator is shown
capable of identifying a subset of the unknown support of the eigenspace basis
vectors even when the observation noise covariance matrix is unknown, as long
as the noise power is sufficiently low. It is proved that the sparsity-aware
estimator is asymptotically normal, and the probability to correctly identify
the signal subspace basis support approaches one, as the number of training
data grows large. Simulations using synthetic data and images, corroborate that
the proposed algorithms achieve improved reconstruction quality relative to
alternatives.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3601</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3601</id><created>2012-01-17</created><updated>2012-03-27</updated><authors><author><keyname>Wiedijk</keyname><forenames>Freek</forenames><affiliation>Radboud University Nijmegen</affiliation></author></authors><title>A Synthesis of the Procedural and Declarative Styles of Interactive
  Theorem Proving</title><categories>cs.LO</categories><proxy>LMCS</proxy><acm-class>F.4.1, I.2.3, I.2.4</acm-class><journal-ref>Logical Methods in Computer Science, Volume 8, Issue 1 (March 28,
  2012) lmcs:1046</journal-ref><doi>10.2168/LMCS-8(1:30)2012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a synthesis of the two proof styles of interactive theorem
proving: the procedural style (where proofs are scripts of commands, like in
Coq) and the declarative style (where proofs are texts in a controlled natural
language, like in Isabelle/Isar). Our approach combines the advantages of the
declarative style - the possibility to write formal proofs like normal
mathematical text - and the procedural style - strong automation and help with
shaping the proofs, including determining the statements of intermediate steps.
Our approach is new, and differs significantly from the ways in which the
procedural and declarative proof styles have been combined before in the
Isabelle, Ssreflect and Matita systems. Our approach is generic and can be
implemented on top of any procedural interactive theorem prover, regardless of
its architecture and logical foundations. To show the viability of our proposed
approach, we fully implemented it as a proof interface called miz3, on top of
the HOL Light interactive theorem prover. The declarative language that this
interface uses is a slight variant of the language of the Mizar system, and can
be used for any interactive theorem prover regardless of its logical
foundations. The miz3 interface allows easy access to the full set of tactics
and formal libraries of HOL Light, and as such has &quot;industrial strength&quot;. Our
approach gives a way to automatically convert any procedural proof to a
declarative counterpart, where the converted proof is similar in size to the
original. As all declarative systems have essentially the same proof language,
this gives a straightforward way to port proofs between interactive theorem
provers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3602</identifier>
 <datestamp>2012-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3602</id><created>2012-01-17</created><authors><author><keyname>Barbay</keyname><forenames>J&#xe9;r&#xe9;my</forenames></author><author><keyname>Claude</keyname><forenames>Francisco</forenames></author><author><keyname>Navarro</keyname><forenames>Gonzalo</forenames></author></authors><title>Compact Binary Relation Representations with Rich Functionality</title><categories>cs.DS</categories><comments>32 pages</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Binary relations are an important abstraction arising in many data
representation problems. The data structures proposed so far to represent them
support just a few basic operations required to fit one particular application.
We identify many of those operations arising in applications and generalize
them into a wide set of desirable queries for a binary relation representation.
We also identify reductions among those operations. We then introduce several
novel binary relation representations, some simple and some quite
sophisticated, that not only are space-efficient but also efficiently support a
large subset of the desired queries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3612</identifier>
 <datestamp>2012-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3612</id><created>2012-01-17</created><authors><author><keyname>Gon&#xe7;alves</keyname><forenames>Wesley Nunes</forenames></author><author><keyname>Machado</keyname><forenames>Bruno Brandoli</forenames></author><author><keyname>Bruno</keyname><forenames>Odemir Martinez</forenames></author></authors><title>Spatiotemporal Gabor filters: a new method for dynamic texture
  recognition</title><categories>cs.CV</categories><comments>Workshop on Computer Vision 2011 http://www.wvc2011.ufpr.br</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a new method for dynamic texture recognition based on
spatiotemporal Gabor filters. Dynamic textures have emerged as a new field of
investigation that extends the concept of self-similarity of texture image to
the spatiotemporal domain. To model a dynamic texture, we convolve the sequence
of images to a bank of spatiotemporal Gabor filters. For each response, a
feature vector is built by calculating the energy statistic. As far as the
authors know, this paper is the first to report an effective method for dynamic
texture recognition using spatiotemporal Gabor filters. We evaluate the
proposed method on two challenging databases and the experimental results
indicate that the proposed method is a robust approach for dynamic texture
recognition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3667</identifier>
 <datestamp>2014-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3667</id><created>2012-01-17</created><updated>2014-09-19</updated><authors><author><keyname>Kramer</keyname><forenames>Simon</forenames></author></authors><title>A Logic of Interactive Proofs (Formal Theory of Knowledge Transfer)</title><categories>cs.LO cs.CR cs.DC cs.MA math.LO</categories><comments>related to arXiv:1208.1842, arXiv:1208.5913, and arXiv:1309.1328</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a logic of interactive proofs as the first and main step towards
an intuitionistic foundation for interactive computation to be obtained via an
interactive analog of the Goedel-Kolmogorov-Artemov definition of
intuitionistic logic as embedded into a classical modal logic of proofs, and of
the Curry-Howard isomorphism between intuitionistic proofs and typed programs.
Our interactive proofs effectuate a persistent epistemic impact in their
intended communities of peer reviewers that consists in the induction of the
(propositional) knowledge of their proof goal by means of the (individual)
knowledge of the proof with the interpreting reviewer. That is, interactive
proofs effectuate a transfer of propositional knowledge (knowable facts) via
the transmission of certain individual knowledge (knowable proofs) in
multi-agent distributed systems. In other words, we as a community can have the
formal common knowledge that a proof is that which if known to one of our peer
members would induce the knowledge of its proof goal with that member.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3671</identifier>
 <datestamp>2015-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3671</id><created>2012-01-17</created><authors><author><keyname>Black</keyname><forenames>Don V.</forenames></author><author><keyname>Gopi</keyname><forenames>M.</forenames></author><author><keyname>Wessel</keyname><forenames>F.</forenames></author><author><keyname>Pajarola</keyname><forenames>R.</forenames></author><author><keyname>Kuester</keyname><forenames>F.</forenames></author></authors><title>Visualizing Flat Spacetime: Viewing Optical versus Special Relativistic
  Effects</title><categories>physics.ed-ph cs.CG cs.GR physics.comp-ph</categories><comments>14 pages, 11 color figures, and is accompanied by 6 animated videos.
  The videos can be downloaded from here:
  http://www.hypervisualization.com/videos/black/ The original article appeared
  in American Journal of Physics, June 2007, and can be found here:
  http://ajp.aapt.org/resource/1/ajpias/v75/i6/p540_s1?isAuthorized=no</comments><acm-class>I.3.3; I.3.5; I.3.6; I.4.10; E.2; H.5.2</acm-class><journal-ref>American Journal of Physics, Volume 75, Issue 6, pp. 540-545
  (2007)</journal-ref><doi>10.1119/1.2730838</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A simple visual representation of Minkowski spacetime appropriate for a
student with a background in geometry and algebra is presented. Minkowski
spacetime can be modeled with a Euclidean 4-space to yield accurate
visualizations as predicted by special relativity theory. The contributions of
relativistic aberration as compared to classical pre-relativistic aberration to
the geometry are discussed in the context of its visual representation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3674</identifier>
 <datestamp>2012-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3674</id><created>2012-01-17</created><authors><author><keyname>Singaraju</keyname><forenames>Dheeraj</forenames></author><author><keyname>Elhamifar</keyname><forenames>Ehsan</forenames></author><author><keyname>Tron</keyname><forenames>Roberto</forenames></author><author><keyname>Yang</keyname><forenames>Allen Y.</forenames></author><author><keyname>Sastry</keyname><forenames>S. Shankar</forenames></author></authors><title>On the Lagrangian Biduality of Sparsity Minimization Problems</title><categories>cs.CV cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent results in Compressive Sensing have shown that, under certain
conditions, the solution to an underdetermined system of linear equations with
sparsity-based regularization can be accurately recovered by solving convex
relaxations of the original problem. In this work, we present a novel
primal-dual analysis on a class of sparsity minimization problems. We show that
the Lagrangian bidual (i.e., the Lagrangian dual of the Lagrangian dual) of the
sparsity minimization problems can be used to derive interesting convex
relaxations: the bidual of the $\ell_0$-minimization problem is the
$\ell_1$-minimization problem; and the bidual of the $\ell_{0,1}$-minimization
problem for enforcing group sparsity on structured data is the
$\ell_{1,\infty}$-minimization problem. The analysis provides a means to
compute per-instance non-trivial lower bounds on the (group) sparsity of the
desired solutions. In a real-world application, the bidual relaxation improves
the performance of a sparsity-based classification framework applied to robust
face recognition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3688</identifier>
 <datestamp>2012-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3688</id><created>2012-01-17</created><authors><author><keyname>Lin</keyname><forenames>Fuchun</forenames></author><author><keyname>Oggier</keyname><forenames>Fr&#xe9;d&#xe9;rique</forenames></author></authors><title>A Classification of Unimodular Lattice Wiretap Codes in Small Dimensions</title><categories>math.NT cs.IT math.IT</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Lattice coding over a Gaussian wiretap channel, where an eavesdropper listens
to transmissions between a transmitter and a legitimate receiver, is
considered. A new lattice invariant called the secrecy gain is used as a code
design criterion for wiretap lattice codes since it was shown to characterize
the confusion that a chosen lattice can cause at the eavesdropper: the higher
the secrecy gain of the lattice, the more confusion. In this paper, a formula
for the secrecy gain of unimodular lattices is derived. Secrecy gains of
extremal odd unimodular lattices as well as unimodular lattices in dimension n,
16 \leq n \leq 23 are computed, covering the 4 extremal odd unimodular lattices
and all the 111 nonextremal unimodular lattices (both odd and even) providing
thus a classification of the best wiretap lattice codes coming from unimodular
lattices in dimension n, 8 &lt; n \leq 23. Finally, to permit lattice encoding via
Construction A, the corresponding error correction codes are determined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3697</identifier>
 <datestamp>2012-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3697</id><created>2012-01-18</created><authors><author><keyname>Xu</keyname><forenames>Jie</forenames></author><author><keyname>Qiu</keyname><forenames>Ling</forenames></author><author><keyname>Zhang</keyname><forenames>Shunqing</forenames></author></authors><title>Energy Efficient Iterative Waterfilling for the MIMO Broadcasting
  Channels</title><categories>cs.IT math.IT</categories><comments>6 pages, 4 figures, accepted in IEEE proc. of WCNC 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Optimizing energy efficiency (EE) for the MIMO broadcasting channels (BC) is
considered in this paper, where a practical power model is taken into account.
Although the EE of the MIMO BC is non-concave, we reformulate it as a
quasiconcave function based on the uplink-downlink duality. After that, an
energy efficient iterative waterfilling scheme is proposed based on the
block-coordinate ascent algorithm to obtain the optimal transmission policy
efficiently, and the solution is proved to be convergent. Through simulations,
we validate the efficiency of the proposed scheme and discuss the system
parameters' effect on the EE.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3698</identifier>
 <datestamp>2012-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3698</id><created>2012-01-18</created><authors><author><keyname>Xu</keyname><forenames>Jie</forenames></author><author><keyname>Qiu</keyname><forenames>Ling</forenames></author></authors><title>Energy Efficiency Scaling Law for MIMO Broadcasting Channels</title><categories>cs.IT math.IT</categories><comments>10 pages, submitted to IEEE Wireless Communications Letters</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This letter investigates the energy efficiency (EE) scaling law for the
broadcasting channels (BC) with many users, in which the non-ideal transmit
independent power consumption is taken into account. We first consider the
single antenna case with $K$ users, and derive that the EE scales as
$\frac{{\log_2 \ln K}}{\alpha}$ when $\alpha &gt; 0$ and $\log_2 K$ when $\alpha =
0$, where $\alpha$ is the normalized transmit independent power. After that, we
extend it to the general MIMO BC case with a $M$-antenna transmitter and $K$
users each with $N$ antennas. The scaling law becomes $\frac{{M \log_2 \ln
NK}}{\alpha}$ when $\alpha &gt; 0$ and $ \log_2 NK$ when $\alpha = 0$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3720</identifier>
 <datestamp>2012-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3720</id><created>2012-01-18</created><authors><author><keyname>Khan</keyname><forenames>Aamir</forenames></author><author><keyname>Farhan</keyname><forenames>Muhammad</forenames></author><author><keyname>Khurshid</keyname><forenames>Aasim</forenames></author><author><keyname>Akram</keyname><forenames>Adeel</forenames></author></authors><title>A Multimodal Biometric System Using Linear Discriminant Analysis For
  Improved Performance</title><categories>cs.CV</categories><journal-ref>IJCSI International Journal of Computer Science Issues, Vol. 8,
  Issue 6, No 2, 2011, 122-127</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Essentially a biometric system is a pattern recognition system which
recognizes a user by determining the authenticity of a specific anatomical or
behavioral characteristic possessed by the user. With the ever increasing
integration of computers and Internet into daily life style, it has become
necessary to protect sensitive and personal data. This paper proposes a
multimodal biometric system which incorporates more than one biometric trait to
attain higher security and to handle failure to enroll situations for some
users. This paper is aimed at investigating a multimodal biometric identity
system using Linear Discriminant Analysis as backbone to both facial and speech
recognition and implementing such system in real-time using SignalWAVE.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3722</identifier>
 <datestamp>2012-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3722</id><created>2012-01-18</created><authors><author><keyname>Poormohammadi</keyname><forenames>Hadi</forenames></author><author><keyname>Eslahchi</keyname><forenames>Changiz</forenames></author><author><keyname>Tusserkani</keyname><forenames>Ruzbeh</forenames></author></authors><title>TripNet: A Heuristic Algorithm for Constructing Rooted Phylogenetic
  Networks from Triplets</title><categories>cs.DS q-bio.PE</categories><comments>20 pages, 5 figures, Regular paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of constructing an optimal rooted phylogenetic network from a set
of rooted triplets is an NP-hard problem. In this paper, we present a heuristic
algorithm called TripNet which tries to construct an optimal rooted
phylogenetic network from an arbitrary set of triplets. We prove some theorems
to justify the performance of the algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3723</identifier>
 <datestamp>2012-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3723</id><created>2012-01-18</created><authors><author><keyname>Karumbu</keyname><forenames>Premkumar</forenames></author><author><keyname>Chen</keyname><forenames>Xiaomin</forenames></author><author><keyname>Leith</keyname><forenames>Douglas</forenames></author></authors><title>Proportional Fair Coding for Wireless Mesh Networks</title><categories>cs.NI cs.IT math.IT</categories><comments>Submitted to IEEE/ACM Transactions on Networking (December 2011)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider multi--hop wireless networks carrying unicast flows for multiple
users. Each flow has a specified delay deadline, and the lossy wireless links
are modelled as binary symmetric channels (BSCs). Since transmission time, also
called airtime, on the links is shared amongst flows, increasing the airtime
for one flow comes at the cost of reducing the airtime available to other flows
sharing the same link. We derive the joint allocation of flow airtimes and
coding rates that achieves the proportionally fair throughput allocation. This
utility optimisation problem is non--convex, and one of the technical
contributions of this paper is to show that the proportional fair utility
optimisation can nevertheless be decomposed into a sequence of convex
optimisation problems. The solution to this sequence of convex problems is the
unique solution to the original non--convex optimisation. Surprisingly, this
solution can be written in an explicit form that yields considerable insight
into the nature of the proportional fair joint airtime/coding rate allocation.
To our knowledge, this is the first time that the utility fair joint allocation
of airtime/coding rate has been analysed, and also, one of the first times that
utility fairness with delay deadlines has been considered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3727</identifier>
 <datestamp>2012-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3727</id><created>2012-01-18</created><authors><author><keyname>Cheriyan</keyname><forenames>Joseph</forenames></author><author><keyname>de Gevigney</keyname><forenames>Olivier Durand</forenames></author><author><keyname>Szigeti</keyname><forenames>Zolt&#xe1;n</forenames></author></authors><title>Packing of Rigid Spanning Subgraphs and Spanning Trees</title><categories>cs.DM math.CO</categories><msc-class>05C40</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that every (6k + 2l, 2k)-connected simple graph contains k rigid and
l connected edge-disjoint spanning subgraphs. This implies a theorem of Jackson
and Jord\'an [4] and a theorem of Jord\'an [6] on packing of rigid spanning
subgraphs. Both these results are generalizations of the classical result of
Lov\'asz and Yemini [9] saying that every 6-connected graph is rigid for which
our approach provides a transparent proof. Our result also gives two improved
upper bounds on the connectivity of graphs that have interesting properties:
(1) every 8-connected graph packs a spanning tree and a 2-connected spanning
subgraph; (2) every 14-connected graph has a 2-connected orientation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3731</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3731</id><created>2012-01-18</created><updated>2012-02-15</updated><authors><author><keyname>Mahboubi</keyname><forenames>Assia</forenames><affiliation>INRIA</affiliation></author><author><keyname>Cohen</keyname><forenames>Cyril</forenames><affiliation>INRIA</affiliation></author></authors><title>Formal proofs in real algebraic geometry: from ordered fields to
  quantifier elimination</title><categories>cs.LO</categories><comments>40 pages, 4 figures</comments><proxy>LMCS</proxy><acm-class>F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 8, Issue 1 (February
  16, 2012) lmcs:844</journal-ref><doi>10.2168/LMCS-8(1:2)2012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes a formalization of discrete real closed fields in the
Coq proof assistant. This abstract structure captures for instance the theory
of real algebraic numbers, a decidable subset of real numbers with good
algorithmic properties. The theory of real algebraic numbers and more generally
of semi-algebraic varieties is at the core of a number of effective methods in
real analysis, including decision procedures for non linear arithmetic or
optimization methods for real valued functions. After defining an abstract
structure of discrete real closed field and the elementary theory of real roots
of polynomials, we describe the formalization of an algebraic proof of
quantifier elimination based on pseudo-remainder sequences following the
standard computer algebra literature on the topic. This formalization covers a
large part of the theory which underlies the efficient algorithms implemented
in practice in computer algebra. The success of this work paves the way for
formal certification of these efficient methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3733</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3733</id><created>2012-01-18</created><updated>2012-08-11</updated><authors><author><keyname>Yamagata</keyname><forenames>Yoriyuki</forenames><affiliation>National Institute of Advanced Science and Technology</affiliation></author></authors><title>Bounded Arithmetic in Free Logic</title><categories>math.LO cs.LO</categories><proxy>LMCS</proxy><acm-class>cs.LO</acm-class><journal-ref>Logical Methods in Computer Science, Volume 8, Issue 3 (August 10,
  2012) lmcs:863</journal-ref><doi>10.2168/LMCS-8(3:7)2012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the central open questions in bounded arithmetic is whether Buss'
hierarchy of theories of bounded arithmetic collapses or not. In this paper, we
reformulate Buss' theories using free logic and conjecture that such theories
are easier to handle. To show this, we first prove that Buss' theories prove
consistencies of induction-free fragments of our theories whose formulae have
bounded complexity. Next, we prove that although our theories are based on an
apparently weaker logic, we can interpret theories in Buss' hierarchy by our
theories using a simple translation. Finally, we investigate finitistic G\&quot;odel
sentences in our systems in the hope of proving that a theory in a lower level
of Buss' hierarchy cannot prove consistency of induction-free fragments of our
theories whose formulae have higher complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3740</identifier>
 <datestamp>2014-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3740</id><created>2012-01-18</created><updated>2012-05-30</updated><authors><author><keyname>Feyzmahdavian</keyname><forenames>Hamid Reza</forenames></author><author><keyname>Johansson</keyname><forenames>Mikael</forenames></author><author><keyname>Charalambous</keyname><forenames>Themistoklis</forenames></author></authors><title>Contractive Interference Functions and Rates of Convergence of
  Distributed Power Control Laws</title><categories>cs.IT cs.SY math.IT</categories><comments>20 pages, 1 figures</comments><journal-ref>IEEE Transactions on Wireless Communications, 11 (12), pp.
  4494-4502, December 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The standard interference functions introduced by Yates have been very
influential on the analysis and design of distributed power control laws. While
powerful and versatile, the framework has some drawbacks: the existence of
fixed-points has to be established separately, and no guarantees are given on
the rate of convergence of the iterates. This paper introduces contractive
interference functions, a slight reformulation of the standard interference
functions that guarantees the existence and uniqueness of fixed-points along
with linear convergence of iterates. We show that many power control laws from
the literature are contractive and derive, sometimes for the first time,
analytical convergence rate estimates for these algorithms. We also prove that
contractive interference functions converge when executed totally
asynchronously and, under the assumption that the communication delay is
bounded, derive an explicit bound on the convergence time penalty due to
increased delay. Finally, we demonstrate that although standard interference
functions are, in general, not contractive, they are all para-contractions with
respect to a certain metric. Similar results for two-sided scalable
interference functions are also derived.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3745</identifier>
 <datestamp>2012-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3745</id><created>2012-01-18</created><authors><author><keyname>Soryani</keyname><forenames>Mohammad</forenames></author><author><keyname>Minaei</keyname><forenames>Behrooz</forenames></author></authors><title>Social Networks Research Aspects: A Vast and Fast Survey Focused on the
  Issue of Privacy in Social Network Sites</title><categories>cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The increasing participation of people in online activities in recent years
like content publishing, and having different kinds of relationships and
interactions, along with the emergence of online social networks and people's
extensive tendency toward them, have resulted in generation and availability of
a huge amount of valuable information that has never been available before, and
have introduced some new, attractive, varied, and useful research areas to
researchers. In this paper we try to review some of the accomplished research
on information of SNSs (Social Network Sites), and introduce some of the
attractive applications that analyzing this information has. This will lead to
the introduction of some new research areas to researchers. By reviewing the
research in this area we will present a categorization of research topics about
online social networks. This categorization includes seventeen research
subtopics or subareas that will be introduced along with some of the
accomplished research in these subareas. According to the consequences (slight,
significant, and sometimes catastrophic) that revelation of personal and
private information has, a research area that researchers have vastly
investigated is privacy in online social networks. After an overview on
different research subareas of SNSs, we will get more focused on the subarea of
privacy protection in social networks, and introduce different aspects of it
along with a categorization of these aspects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3771</identifier>
 <datestamp>2013-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3771</id><created>2012-01-18</created><updated>2013-02-28</updated><authors><author><keyname>Zanetti</keyname><forenames>Marcelo Serrano</forenames></author><author><keyname>Schweitzer</keyname><forenames>Frank</forenames></author></authors><title>A Network Perspective on Software Modularity</title><categories>cs.SE cs.SI nlin.AO physics.soc-ph</categories><acm-class>D.2.2; D.2.8</acm-class><journal-ref>ARCS Workshops 2012, pp. 175--186</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modularity is a desirable characteristic for software systems. In this
article we propose to use a quantitative method from complex network sciences
to estimate the coherence between the modularity of the dependency network of
large open source Java projects and their decomposition in terms of Java
packages. The results presented in this article indicate that our methodology
offers a promising and reasonable quantitative approach with potential impact
on software engineering processes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3778</identifier>
 <datestamp>2012-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3778</id><created>2012-01-18</created><updated>2012-06-27</updated><authors><author><keyname>Versaci</keyname><forenames>Francesco</forenames></author><author><keyname>Pingali</keyname><forenames>Keshav</forenames></author></authors><title>Processor Allocation for Optimistic Parallelization of Irregular
  Programs</title><categories>cs.PL cs.DS</categories><comments>12 pages, 3 figures, extended version of SPAA 2011 brief announcement</comments><journal-ref>LNCS 7333/2012</journal-ref><doi>10.1007/978-3-642-31125-3_1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Optimistic parallelization is a promising approach for the parallelization of
irregular algorithms: potentially interfering tasks are launched dynamically,
and the runtime system detects conflicts between concurrent activities,
aborting and rolling back conflicting tasks. However, parallelism in irregular
algorithms is very complex. In a regular algorithm like dense matrix
multiplication, the amount of parallelism can usually be expressed as a
function of the problem size, so it is reasonably straightforward to determine
how many processors should be allocated to execute a regular algorithm of a
certain size (this is called the processor allocation problem). In contrast,
parallelism in irregular algorithms can be a function of input parameters, and
the amount of parallelism can vary dramatically during the execution of the
irregular algorithm. Therefore, the processor allocation problem for irregular
algorithms is very difficult.
  In this paper, we describe the first systematic strategy for addressing this
problem. Our approach is based on a construct called the conflict graph, which
(i) provides insight into the amount of parallelism that can be extracted from
an irregular algorithm, and (ii) can be used to address the processor
allocation problem for irregular algorithms. We show that this problem is
related to a generalization of the unfriendly seating problem and, by extending
Tur\'an's theorem, we obtain a worst-case class of problems for optimistic
parallelization, which we use to derive a lower bound on the exploitable
parallelism. Finally, using some theoretically derived properties and some
experimental facts, we design a quick and stable control strategy for solving
the processor allocation problem heuristically.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3782</identifier>
 <datestamp>2012-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3782</id><created>2012-01-18</created><authors><author><keyname>Ghandar</keyname><forenames>Abeer</forenames></author><author><keyname>Shabaan</keyname><forenames>Eman</forenames></author><author><keyname>Fayed</keyname><forenames>Zaky Taha</forenames></author></authors><title>Performance Analysis of Observation Based Cooperation Enforcement in Ad
  Hoc Networks</title><categories>cs.NI</categories><journal-ref>International Journal of Computer Science Issues (IJCSI), Vol. 8,
  Issue 6, No 2, pp. 79-85, November 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Node misbehavior due to selfish or malicious behavior could significantly
degrade the performance of MANET because most existing routing protocols in
MANET aim to find the most efficient path. Overhearing and reputation based
cooperation schemes have been used to detect and isolate the misbehaving nodes
as well as to force them to cooperate. Performance analysis has been done for
the network traffic using OCEAN over DSR on ns2 while considering the low
energy levels for mobile nodes. Throughput, energy level, routing packets and
normalized routing overhead are analyzed for OCEAN and normal DSR to show the
impact of OCEAN on the overall network performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3783</identifier>
 <datestamp>2012-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3783</id><created>2012-01-18</created><authors><author><keyname>O'Callaghan</keyname><forenames>Derek</forenames></author><author><keyname>Harrigan</keyname><forenames>Martin</forenames></author><author><keyname>Carthy</keyname><forenames>Joe</forenames></author><author><keyname>Cunningham</keyname><forenames>P&#xe1;draig</forenames></author></authors><title>Network Analysis of Recurring YouTube Spam Campaigns</title><categories>cs.SI physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As the popularity of content sharing websites such as YouTube and Flickr has
increased, they have become targets for spam, phishing and the distribution of
malware. On YouTube, the facility for users to post comments can be used by
spam campaigns to direct unsuspecting users to bogus e-commerce websites. In
this paper, we demonstrate how such campaigns can be tracked over time using
network motif profiling, i.e. by tracking counts of indicative network motifs.
By considering all motifs of up to five nodes, we identify discriminating
motifs that reveal two distinctly different spam campaign strategies. One of
these strategies uses a small number of spam user accounts to comment on a
large number of videos, whereas a larger number of accounts is used with the
other. We present an evaluation that uses motif profiling to track two active
campaigns matching these strategies, and identify some of the associated user
accounts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3786</identifier>
 <datestamp>2012-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3786</id><created>2012-01-18</created><updated>2012-05-21</updated><authors><author><keyname>Hendriks</keyname><forenames>Dimitri</forenames></author><author><keyname>Dannenberg</keyname><forenames>Frits G. W.</forenames></author><author><keyname>Endrullis</keyname><forenames>Joerg</forenames></author><author><keyname>Dow</keyname><forenames>Mark</forenames></author><author><keyname>Klop</keyname><forenames>Jan Willem</forenames></author></authors><title>Arithmetic Self-Similarity of Infinite Sequences</title><categories>math.CO cs.LO math.NT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We define the arithmetic self-similarity (AS) of a one-sided infinite
sequence sigma to be the set of arithmetic progressions through sigma which are
a vertical shift of sigma. We study the AS of several famlies of sequences,
viz. completely additive sequences, Toeplitz words and Keane's generalized
Morse sequences. We give a complete characterization of the AS of completely
additive sequences, and classify the set of single-gap Toeplitz patterns that
yield completely additive Toeplitz words. We show that every arithmetic
subsequence of a Toeplitz word generated by a one-gap pattern is again a
Toeplitz word. Finally, we establish that generalized Morse sequences are
specific sum-of-digits sequences, and show that their first difference is a
Toeplitz word.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3793</identifier>
 <datestamp>2012-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3793</id><created>2012-01-18</created><authors><author><keyname>Kim</keyname><forenames>Jeong Han</forenames></author></authors><title>Finding Weighted Graphs by Combinatorial Search</title><categories>math.CO cs.DM</categories><msc-class>05C85</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of finding edges of a hidden weighted graph using a
certain type of queries. Let $G$ be a weighted graph with $n$ vertices. In the
most general setting, the $n$ vertices are known and no other information about
$G$ is given. The problem is finding all edges of $G$ and their weights using
additive queries, where, for an additive query, one chooses a set of vertices
and asks the sum of the weights of edges with both ends in the set. This model
has been extensively used in bioinformatics including genom sequencing.
Extending recent results of Bshouty and Mazzawi, and Choi and Kim, we present a
polynomial time randomized algorithm to find the hidden weighted graph $G$ when
the number of edges in $G$ is known to be at most $m\geq 2$ and the weight
$w(e)$ of each edge $e$ satisfies $\ga \leq |w(e)|\leq \gb$ for fixed constants
$\ga, \gb&gt;0$. The query complexity of the algorithm is $O(\frac{m \log n}{\log
m})$, which is optimal up to a constant factor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3798</identifier>
 <datestamp>2013-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3798</id><created>2012-01-18</created><updated>2013-01-10</updated><authors><author><keyname>Peixoto</keyname><forenames>Tiago P.</forenames></author><author><keyname>Bornholdt</keyname><forenames>Stefan</forenames></author></authors><title>No need for conspiracy: Self-organized cartel formation in a modified
  trust game</title><categories>q-fin.GN cs.GT physics.soc-ph</categories><comments>5 pages, 5 figures [fixes a typo in the text]</comments><journal-ref>Phys. Rev. Lett. 108, 218702 (2012)</journal-ref><doi>10.1103/PhysRevLett.108.218702</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  We investigate the dynamics of a trust game on a mixed population where
individuals with the role of buyers are forced to play against a predetermined
number of sellers, whom they choose dynamically. Agents with the role of
sellers are also allowed to adapt the level of value for money of their
products, based on payoff. The dynamics undergoes a transition at a specific
value of the strategy update rate, above which an emergent cartel organization
is observed, where sellers have similar values of below optimal value for
money. This cartel organization is not due to an explicit collusion among
agents; instead it arises spontaneously from the maximization of the individual
payoffs. This dynamics is marked by large fluctuations and a high degree of
unpredictability for most of the parameter space, and serves as a plausible
qualitative explanation for observed elevated levels and fluctuations of
certain commodity prices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3802</identifier>
 <datestamp>2012-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3802</id><created>2012-01-16</created><authors><author><keyname>Kostadinova</keyname><forenames>Hristina</forenames></author><author><keyname>Yordzhev</keyname><forenames>Krasimir</forenames></author></authors><title>An Entertaining Example for the Usage of Bitwise Operations in
  Programming</title><categories>cs.OH cs.DS</categories><comments>Proceedings of the Fourth International Scientific Conference -
  FMNS2011, 8 - 11 June, 2011</comments><journal-ref>Mathematics and natural science, v. 1, SWU &quot;N. Rilski&quot;, 2011,
  159-168</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The present study is meant to fill in some information gaps occurring in the
most widespread and well-known educational and reference literature about
programming. The stress is laid on a very useful instrument - the bitwise
operations, topic which is, unfortunately, seldom dealt with in most of the
well-known books on programming. In addition, the research is very useful as
regards the topic of overloading operators in any Object-oriented programming
course. Given some appropriate examples, with the emphasis being laid on some
particular and data structures language constructions, the results are quite
interesting. The algorithm of solving the popular Sudoku puzzle is one such
entertaining example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3803</identifier>
 <datestamp>2012-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3803</id><created>2012-01-16</created><authors><author><keyname>Vairalkar</keyname><forenames>Manoj K.</forenames></author><author><keyname>Nimbhorkar</keyname><forenames>Sonali.</forenames></author></authors><title>Image Labeling and Segmentation using Hierarchical Conditional Random
  Field Model</title><categories>cs.CV</categories><comments>08 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The use of hierarchical Conditional Random Field model deal with the problem
of labeling images . At the time of labeling a new image, selection of the
nearest cluster and using the related CRF model to label this image. When one
give input image, one first use the CRF model to get initial pixel labels then
finding the cluster with most similar images. Then at last relabeling the input
image by the CRF model associated with this cluster. This paper presents a
approach to label and segment specific image having correct information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3804</identifier>
 <datestamp>2013-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3804</id><created>2012-01-18</created><authors><author><keyname>Kristensen</keyname><forenames>Mads Ruben Burgdorff</forenames></author><author><keyname>Vinter</keyname><forenames>Brian</forenames></author></authors><title>Managing Communication Latency-Hiding at Runtime for Parallel
  Programming Languages and Libraries</title><categories>cs.DC</categories><comments>PREPRINT</comments><journal-ref>Proceeding HPCC '12 Proceedings of the 2012 IEEE 14th
  International Conference on High Performance Computing and Communication &amp;
  2012 IEEE 9th International Conference on Embedded Software and Systems</journal-ref><doi>10.1109/HPCC.2012.80</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work introduces a runtime model for managing communication with support
for latency-hiding. The model enables non-computer science researchers to
exploit communication latency-hiding techniques seamlessly. For compiled
languages, it is often possible to create efficient schedules for
communication, but this is not the case for interpreted languages. By
maintaining data dependencies between scheduled operations, it is possible to
aggressively initiate communication and lazily evaluate tasks to allow maximal
time for the communication to finish before entering a wait state. We implement
a heuristic of this model in DistNumPy, an auto-parallelizing version of
numerical Python that allows sequential NumPy programs to run on distributed
memory architectures. Furthermore, we present performance comparisons for eight
benchmarks with and without automatic latency-hiding. The results shows that
our model reduces the time spent on waiting for communication as much as 27
times, from a maximum of 54% to only 2% of the total execution time, in a
stencil application.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3821</identifier>
 <datestamp>2012-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3821</id><created>2012-01-18</created><authors><author><keyname>Miravet</keyname><forenames>Carlos</forenames></author><author><keyname>Rodr&#xed;guez</keyname><forenames>Francisco B.</forenames></author></authors><title>A PCA-Based Super-Resolution Algorithm for Short Image Sequences</title><categories>cs.CV</categories><comments>4 pages, 4 figures. A version of this work was submitted to ICIP 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a novel, learning-based, two-step super-resolution
(SR) algorithm well suited to solve the specially demanding problem of
obtaining SR estimates from short image sequences. The first step, devoted to
increase the sampling rate of the incoming images, is performed by fitting
linear combinations of functions generated from principal components (PC) to
reproduce locally the sparse projected image data, and using these models to
estimate image values at nodes of the high-resolution grid. PCs were obtained
from local image patches sampled at sub-pixel level, which were generated in
turn from a database of high-resolution images by application of a physically
realistic observation model. Continuity between local image models is enforced
by minimizing an adequate functional in the space of model coefficients. The
second step, dealing with restoration, is performed by a linear filter with
coefficients learned to restore residual interpolation artifacts in addition to
low-resolution blurring, providing an effective coupling between both steps of
the method. Results on a demanding five-image scanned sequence of graphics and
text are presented, showing the excellent performance of the proposed method
compared to several state-of-the-art two-step and Bayesian Maximum a Posteriori
SR algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3825</identifier>
 <datestamp>2014-06-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3825</id><created>2012-01-18</created><authors><author><keyname>Rosenthal</keyname><forenames>Joachim</forenames></author><author><keyname>Trautmann</keyname><forenames>Anna-Lena</forenames></author></authors><title>A Complete Characterization of Irreducible Cyclic Orbit Codes and their
  Pl\&quot;ucker Embedding</title><categories>cs.IT math.IT</categories><comments>submitted to Designs, Codes and Cryptography</comments><journal-ref>Designs, Codes and Cryptography, volume 66, issue 1-3, pages
  275-289, 2013</journal-ref><doi>10.1007/s10623-012-9691-5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Constant dimension codes are subsets of the finite Grassmann variety. The
study of these codes is a central topic in random linear network coding theory.
Orbit codes represent a subclass of constant dimension codes. They are defined
as orbits of a subgroup of the general linear group on the Grassmannian. This
paper gives a complete characterization of orbit codes that are generated by an
irreducible cyclic group, i.e. a group having one generator that has no
non-trivial invariant subspace. We show how some of the basic properties of
these codes, the cardinality and the minimum distance, can be derived using the
isomorphism of the vector space and the extension field. Furthermore, we
investigate the Pl\&quot;ucker embedding of these codes and show how the orbit
structure is preserved in the embedding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3835</identifier>
 <datestamp>2012-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3835</id><created>2012-01-18</created><authors><author><keyname>Gaur</keyname><forenames>Vibha</forenames></author><author><keyname>Sharma</keyname><forenames>Neeraj Kumar</forenames></author><author><keyname>Bedi</keyname><forenames>Punam</forenames></author></authors><title>A Dynamic Model for Sharing Reputation of Sellers among Buyers for
  Enhancing Trust in Agent Mediated e-market</title><categories>cs.SI cs.HC cs.MA</categories><comments>10 pages; International Journal of Computer Science Issues, Vol. 8,
  Issue 6, Nov. 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reputation systems aim to reduce the risk of loss due to untrustworthy
participants. This loss is aggravated by dishonest advisors trying to pollute
the e-market environment for their self-interest. A major task of a reputation
system is to promote and encourage advisors who repeatedly respond with fair
advice and to apply an opinion filtering or honesty checking mechanism to
detect and resist dishonest advisors. This paper provides a dynamic approach to
compute the aggregated shared reputation component by filtering out unfair
advice and then generating the aggregated shared reputation value. The proposed
approach is dynamic in nature as it is sensitive to the behaviour of advisors,
value of the current transaction and encourages the cooperation among buyers as
advisors. It provides incentive to honest advisors in lieu of repeated sharing
of honest opinion by increasing the weight of their opinion and by making the
increase in the reputation of honest advisors monotonically proportional to the
value of a transaction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3851</identifier>
 <datestamp>2012-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3851</id><created>2012-01-18</created><authors><author><keyname>Hu</keyname><forenames>Jinli</forenames></author></authors><title>Combinatorial Modelling and Learning with Prediction Markets</title><categories>cs.AI cs.GT q-fin.TR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Combining models in appropriate ways to achieve high performance is commonly
seen in machine learning fields today. Although a large amount of combinatorial
models have been created, little attention is drawn to the commons in different
models and their connections. A general modelling technique is thus worth
studying to understand model combination deeply and shed light on creating new
models. Prediction markets show a promise of becoming such a generic, flexible
combinatorial model. By reviewing on several popular combinatorial models and
prediction market models, this paper aims to show how the market models can
generalise different combinatorial stuctures and how they implement these
popular combinatorial models in specific conditions. Besides, we will see among
different market models, Storkey's \emph{Machine Learning Markets} provide more
fundamental, generic modelling mechanisms than the others, and it has a
significant appeal for both theoretical study and application.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3868</identifier>
 <datestamp>2012-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3868</id><created>2012-01-18</created><authors><author><keyname>Cooper</keyname><forenames>Martin C.</forenames></author><author><keyname>Escamocher</keyname><forenames>Guillaume</forenames></author></authors><title>A Dichotomy for 2-Constraint Forbidden CSP Patterns</title><categories>cs.AI cs.CC</categories><comments>19 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although the CSP (constraint satisfaction problem) is NP-complete, even in
the case when all constraints are binary, certain classes of instances are
tractable. We study classes of instances defined by excluding subproblems. This
approach has recently led to the discovery of novel tractable classes. The
complete characterisation of all tractable classes defined by forbidding
patterns (where a pattern is simply a compact representation of a set of
subproblems) is a challenging problem. We demonstrate a dichotomy in the case
of forbidden patterns consisting of either one or two constraints. This has
allowed us to discover new tractable classes including, for example, a novel
generalisation of 2SAT.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3869</identifier>
 <datestamp>2013-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3869</id><created>2012-01-18</created><updated>2013-11-29</updated><authors><author><keyname>Prasad</keyname><forenames>Narayan</forenames></author><author><keyname>Zhang</keyname><forenames>Honghai</forenames></author><author><keyname>Zhu</keyname><forenames>Hao</forenames></author><author><keyname>Rangarajan</keyname><forenames>Sampath</forenames></author></authors><title>Multi-User Scheduling in the 3GPP LTE Cellular Uplink</title><categories>cs.NI</categories><comments>To appear, IEEE Transactions on Mobile Computing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider resource allocation in the 3GPP Long Term
Evolution (LTE) cellular uplink, which will be the most widely deployed next
generation cellular uplink. The key features of the 3GPP LTE uplink (UL) are
that it is based on a modified form of the orthogonal frequency division
multiplexing based multiple access (OFDMA) which enables channel dependent
frequency selective scheduling, and that it allows for multi-user (MU)
scheduling wherein multiple users can be assigned the same time-frequency
resource. In addition to the considerable spectral efficiency improvements that
are possible by exploiting these two features, the LTE UL allows for transmit
antenna selection together with the possibility to employ advanced receivers at
the base-station, which promise further gains. However, several practical
constraints that seek to maintain a low signaling overhead, are also imposed.
In this paper, we show that the resulting resource allocation problem is
APX-hard and then propose a local ratio test (LRT) based constant-factor
polynomial-time approximation algorithm. We then propose two enhancements to
this algorithm as well as a sequential LRT based MU scheduling algorithm that
offers a constant-factor approximation and is another useful choice in the
complexity versus performance tradeoff. Further, user pre-selection, wherein a
smaller pool of good users is pre-selected and a sophisticated scheduling
algorithm is then employed on the selected pool, is also examined. We suggest
several such user pre-selection algorithms, some of which are shown to offer
constant-factor approximations to the pre-selection problem. Detailed
evaluations reveal that the proposed algorithms and their enhancements offer
significant gains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3880</identifier>
 <datestamp>2012-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3880</id><created>2012-01-18</created><authors><author><keyname>Foug&#xe8;res</keyname><forenames>Alain-J&#xe9;r&#xf4;me</forenames></author></authors><title>Modelling and simulation of complex systems: an approach based on
  multi-level agents</title><categories>cs.MA cs.AI cs.HC</categories><comments>10 pages; IJCSI International Journal of Computer Science Issues,
  Vol. 8, Issue 6, No 1, November 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A complex system is made up of many components with many interactions. So the
design of systems such as simulation systems, cooperative systems or assistance
systems includes a very accurate modelling of interactional and communicational
levels. The agent-based approach provides an adapted abstraction level for this
problem. After having studied the organizational context and communicative
capacities of agentbased systems, to simulate the reorganization of a flexible
manufacturing, to regulate an urban transport system, and to simulate an
epidemic detection system, our thoughts on the interactional level were
inspired by human-machine interface models, especially those in &quot;cognitive
engineering&quot;. To provide a general framework for agent-based complex systems
modelling, we then proposed a scale of four behaviours that agents may adopt in
their complex systems (reactive, routine, cognitive, and collective). To
complete the description of multi-level agent models, which is the focus of
this paper, we illustrate our modelling and discuss our ongoing work on each
level.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3881</identifier>
 <datestamp>2012-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3881</id><created>2012-01-18</created><authors><author><keyname>Foug&#xe8;res</keyname><forenames>Alain-J&#xe9;r&#xf4;me</forenames></author></authors><title>Agent-Based {\mu}-Tools Integrated into a Co-Design Platform</title><categories>cs.HC cs.DC cs.MA</categories><comments>10 pages; IJCSI International Journal of Computer Science Issues,
  Vol. 7, Issue 1, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present successively the proposition and the design of: 1)
{\mu}-tools adapted to collaborative activity of design, and 2) a multi-agent
platform adapted to innovative and distributed design of products or services.
This platform called PLACID (innovating and distributed design platform) must
support applications of assistance to actors implies in a design process that
we have called {\mu}-tools. {\mu}-tools are developed with an aim of bringing
assistance to Co-design. The use of the paradigm agent as well relates to the
modeling and the development of various layers of the platform, that those of
the human-computer interfaces. With these objectives, constraints are added to
facilitate the integration of new co-operative tools.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3883</identifier>
 <datestamp>2012-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3883</id><created>2012-01-18</created><authors><author><keyname>Peng</keyname><forenames>Jing</forenames></author><author><keyname>Foug&#xe8;res</keyname><forenames>Alain-J&#xe9;r&#xf4;me</forenames></author><author><keyname>Deniaud</keyname><forenames>Samuel</forenames></author><author><keyname>Ferney</keyname><forenames>Michel</forenames></author></authors><title>Dynamic Shared Context Processing in an E-Collaborative Learning
  Environment</title><categories>cs.HC cs.AI cs.CY</categories><comments>9 pages; IJCSI International Journal of Computer Science Issues, Vol.
  7, Issue 5, September 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a dynamic shared context processing method based on
DSC (Dynamic Shared Context) model, applied in an e-collaborative learning
environment. Firstly, we present the model. This is a way to measure the
relevance between events and roles in collaborative environments. With this
method, we can share the most appropriate event information for each role
instead of sharing all information to all roles in a collaborative work
environment. Then, we apply and verify this method in our project with Google
App supported e-learning collaborative environment. During this experiment, we
compared DSC method measured relevance of events and roles to manual measured
relevance. And we describe the favorable points from this comparison and our
finding. Finally, we discuss our future research of a hybrid DSC method to make
dynamical information shared more effective in a collaborative work
environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3898</identifier>
 <datestamp>2012-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3898</id><created>2012-01-18</created><updated>2012-05-02</updated><authors><author><keyname>Awodey</keyname><forenames>Steve</forenames></author><author><keyname>Gambino</keyname><forenames>Nicola</forenames></author><author><keyname>Sojakova</keyname><forenames>Kristina</forenames></author></authors><title>Inductive types in homotopy type theory</title><categories>math.LO cs.LO</categories><comments>19 pages; v2: added references and acknowledgements, removed appendix
  with Coq README file, updated URL for Coq files. To appear in the proceedings
  of LICS 2012</comments><msc-class>03B15, 03B70, 03F50</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Homotopy type theory is an interpretation of Martin-L\&quot;of's constructive type
theory into abstract homotopy theory. There results a link between constructive
mathematics and algebraic topology, providing topological semantics for
intensional systems of type theory as well as a computational approach to
algebraic topology via type theory-based proof assistants such as Coq.
  The present work investigates inductive types in this setting. Modified rules
for inductive types, including types of well-founded trees, or W-types, are
presented, and the basic homotopical semantics of such types are determined.
Proofs of all results have been formally verified by the Coq proof assistant,
and the proof scripts for this verification form an essential component of this
research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3900</identifier>
 <datestamp>2012-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3900</id><created>2012-01-18</created><authors><author><keyname>Mas</keyname><forenames>Massimiliano Dal</forenames></author></authors><title>Elasticity on Ontology Matching of Folksodriven Structure Network</title><categories>cs.DL cs.IR</categories><comments>*** This paper has been accepted to the 4th Asian Conference on
  Intelligent Information and Database Systems (ACIIDS 2012) - Kaohsiung Taiwan
  R.O.C., 19-21 March 2012 *** 9 pages, 4 figures; for details see:
  http://www.maxdalmas.com</comments><msc-class>03B65, 03G10, 68P05, 68Q55, 68T30, 74C99, 74D10</msc-class><acm-class>G.2.2; H.3.1; I.2.3; I.2.4; I.2.7</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nowadays folksonomy tags are used not just for personal organization, but for
communication and sharing between people sharing their own local interests. In
this paper is considered the new concept structure called &quot;Folksodriven&quot; to
represent folksonomies. The Folksodriven Structure Network (FSN) was thought as
folksonomy tags suggestions for the user on a dataset built on chosen websites
- based on Natural Language Processing (NLP). Morphological changes, such as
changes in folksonomy tags chose have direct impact on network connectivity
(structural plasticity) of the folksonomy tags considered. The goal of this
paper is on defining a base for a FSN plasticity theory to analyze. To perform
such goal it is necessary a systematic mathematical analysis on deformation and
fracture for the ontology matching on the FSN. The advantages of that approach
could be used on a new interesting method to be employed by a knowledge
management system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3901</identifier>
 <datestamp>2014-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3901</id><created>2012-01-18</created><updated>2013-11-12</updated><authors><author><keyname>Tan</keyname><forenames>Vincent Y. F.</forenames></author><author><keyname>Kosut</keyname><forenames>Oliver</forenames></author></authors><title>On the Dispersions of Three Network Information Theory Problems</title><categories>cs.IT math.IT</categories><comments>Accepted to the IEEE Transactions on Information Theory</comments><doi>10.1109/TIT.2013.2291231</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze the dispersions of distributed lossless source coding (the
Slepian-Wolf problem), the multiple-access channel and the asymmetric broadcast
channel. For the two-encoder Slepian-Wolf problem, we introduce a quantity
known as the entropy dispersion matrix, which is analogous to the scalar
dispersions that have gained interest recently. We prove a global dispersion
result that can be expressed in terms of this entropy dispersion matrix and
provides intuition on the approximate rate losses at a given blocklength and
error probability. To gain better intuition about the rate at which the
non-asymptotic rate region converges to the Slepian-Wolf boundary, we define
and characterize two operational dispersions: the local dispersion and the
weighted sum-rate dispersion. The former represents the rate of convergence to
a point on the Slepian-Wolf boundary while the latter represents the fastest
rate for which a weighted sum of the two rates converges to its asymptotic
fundamental limit. Interestingly, when we approach either of the two corner
points, the local dispersion is characterized not by a univariate Gaussian but
a bivariate one as well as a subset of off-diagonal elements of the
aforementioned entropy dispersion matrix. Finally, we demonstrate the
versatility of our achievability proof technique by providing inner bounds for
the multiple-access channel and the asymmetric broadcast channel in terms of
dispersion matrices. All our proofs are unified a so-called vector rate
redundancy theorem which is proved using the multidimensional Berry-Esseen
theorem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3907</identifier>
 <datestamp>2012-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3907</id><created>2012-01-18</created><authors><author><keyname>Chang</keyname><forenames>Stephen</forenames></author><author><keyname>Felleisen</keyname><forenames>Matthias</forenames></author></authors><title>The Call-by-need Lambda Calculus, Revisited</title><categories>cs.PL</categories><comments>ESOP 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The existing call-by-need lambda calculi describe lazy evaluation via
equational logics. A programmer can use these logics to safely ascertain
whether one term is behaviorally equivalent to another or to determine the
value of a lazy program. However, neither of the existing calculi models
evaluation in a way that matches lazy implementations.
  Both calculi suffer from the same two problems. First, the calculi never
discard function calls, even after they are completely resolved. Second, the
calculi include re-association axioms even though these axioms are merely
administrative steps with no counterpart in any implementation.
  In this paper, we present an alternative axiomatization of lazy evaluation
using a single axiom. It eliminates both the function call retention problem
and the extraneous re-association axioms. Our axiom uses a grammar of contexts
to describe the exact notion of a needed computation. Like its predecessors,
our new calculus satisfies consistency and standardization properties and is
thus suitable for reasoning about behavioral equivalence. In addition, we
establish a correspondence between our semantics and Launchbury's natural
semantics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3914</identifier>
 <datestamp>2012-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3914</id><created>2012-01-18</created><authors><author><keyname>Kornerup</keyname><forenames>Peter</forenames></author><author><keyname>Muller</keyname><forenames>Jean-Michel</forenames></author><author><keyname>Panhaleux</keyname><forenames>Adrien</forenames></author></authors><title>Floating-Point Arithmetic on Round-to-Nearest Representations</title><categories>cs.NA</categories><comments>IMADA-preprint</comments><acm-class>G.1.0; B.2.4; B.7.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently we introduced a class of number representations denoted
RN-representations, allowing an un-biased rounding-to-nearest to take place by
a simple truncation. In this paper we briefly review the binary fixed-point
representation in an encoding which is essentially an ordinary 2's complement
representation with an appended round-bit. Not only is this rounding a constant
time operation, so is also sign inversion, both of which are at best log-time
operations on ordinary 2's complement representations. Addition, multiplication
and division is defined in such a way that rounding information can be carried
along in a meaningful way, at minimal cost. Based on the fixed-point encoding
we here define a floating point representation, and describe to some detail a
possible implementation of a floating point arithmetic unit employing this
representation, including also the directed roundings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3915</identifier>
 <datestamp>2012-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3915</id><created>2012-01-18</created><updated>2012-05-14</updated><authors><author><keyname>Kang</keyname><forenames>Jaewook</forenames></author><author><keyname>Lee</keyname><forenames>Heung-No</forenames></author><author><keyname>Kim</keyname><forenames>Kiseon</forenames></author></authors><title>On Detection-Directed Estimation Approach for Noisy Compressive Sensing</title><categories>cs.IT math.IT</categories><comments>22 pages, 7 figures, 1 table, 1 algorithm table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate a Bayesian sparse reconstruction algorithm
called compressive sensing via Bayesian support detection (CS-BSD). This
algorithm is quite robust against measurement noise and achieves the
performance of a minimum mean square error (MMSE) estimator that has support
knowledge beyond a certain SNR threshold. The key idea behind CS-BSD is that
reconstruction takes a detection-directed estimation structure consisting of
two parts: support detection and signal value estimation. Belief propagation
(BP) and a Bayesian hypothesis test perform support detection, and an MMSE
estimator finds the signal values belonging to the support set. CS-BSD
converges faster than other BP-based algorithms, and it can be converted to a
parallel architecture to become much faster. Numerical results are provided to
verify the superiority of CS-BSD compared to recent algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3929</identifier>
 <datestamp>2012-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3929</id><created>2012-01-18</created><authors><author><keyname>Bergstra</keyname><forenames>J. A.</forenames></author></authors><title>About Instruction Sequence Testing</title><categories>cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Software testing is presented as a so-called theme within which different
authors and groups have defined different subjects each of these subjects
having a different focus on testing. A uniform concept of software testing is
non-existent and the space of possible coherent perspectives on software
testing, each fitting within the theme, is viewed as being spanned by five
dimensions, each dimension representing two opposite views with a variety of
intermediate views in between.
  Instruction sequences are used as a simple theoretical conceptualization of
computer programs. A theory of instruction sequence testing may serve as a
model for a theory of software testing. Instruction sequences testing is
considered a new topic for which definitions may be freely contemplated without
being restricted by existing views on software testing.
  The problem of developing a theory of instruction sequence testing is posed.
A survey is given of motivations and scenarios for developing a theory of
instruction sequence testing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3950</identifier>
 <datestamp>2012-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3950</id><created>2012-01-18</created><authors><author><keyname>Koulali</keyname><forenames>Mohammed-Amine</forenames></author><author><keyname>Koutbi</keyname><forenames>Mohammed El</forenames></author><author><keyname>Kobbane</keyname><forenames>Abdellatif</forenames></author><author><keyname>Azizi</keyname><forenames>Mostafa</forenames></author></authors><title>QGRP: A Novel QoS-Geographic Routing Protocol for Multimedia Wireless
  Sensor Networks</title><categories>cs.NI</categories><comments>ISSN (Online): 1694-0814</comments><journal-ref>IJCSI International Journal of Computer Science Issues, Vol. 8,
  Issue 6, No 2, pages 55-61, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Thanks to the potential they hold and the variety of their application
domains, Multimedia Wireless Sensor Networks (MWSN) are forecast to become
highly integrated into our daily activities. Due to the carried content nature,
mainly composed of images and/or video streams with high throughput and delay
constraints, Quality of Service in the context of MWSN is a crucial issue. In
this paper, we propose a QoS and energy aware geographic routing protocol for
MWSN: QGRP. The proposed protocol addresses bandwidth, delay and energy
constraints associated with MWSN. QGRP adopts an analytical model of IEEE
802.11 Distributed Coordination Function (DCF) to estimate available bandwidth
and generates loop-free routing paths.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3955</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3955</id><created>2012-01-18</created><updated>2013-07-05</updated><authors><author><keyname>Mathieu</keyname><forenames>Claire</forenames></author><author><keyname>Wilson</keyname><forenames>David B.</forenames></author></authors><title>The min mean-weight cycle in a random network</title><categories>math.PR cs.DS</categories><comments>21 pages, 1 figure</comments><msc-class>05C80, 68Q87</msc-class><journal-ref>Combinatorics, Probability &amp; Computing 22(5):763-782, 2013</journal-ref><doi>10.1017/S0963548313000229</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The mean weight of a cycle in an edge-weighted graph is the sum of the
cycle's edge weights divided by the cycle's length. We study the minimum
mean-weight cycle on the complete graph on n vertices, with random i.i.d. edge
weights drawn from an exponential distribution with mean 1. We show that the
probability of the min mean weight being at most c/n tends to a limiting
function of c which is analytic for c&lt;=1/e, discontinuous at c=1/e, and equal
to 1 for c&gt;1/e. We further show that if the min mean weight is &lt;=1/(en), then
the length of the relevant cycle is Theta_p(1) (i.e., it has a limiting
probability distribution which does not scale with n), but that if the min mean
weight is &gt;1/(en), then the relevant cycle almost always has mean weight
(1+o(1))/(en) and length at least (2/pi^2-o(1)) log^2 n log log n.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3960</identifier>
 <datestamp>2012-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3960</id><created>2012-01-18</created><authors><author><keyname>Ryu</keyname><forenames>Jung</forenames></author></authors><title>Congestion Control and Routing over Challenged Networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This dissertation is a study on the design and analysis of novel, optimal
routing and rate control algorithms in wireless, mobile communication networks.
Congestion control and routing algorithms upto now have been designed and
optimized for wired or wireless mesh networks. In those networks, optimal
algorithms (optimal in the sense that either the throughput is maximized or
delay is minimized, or the network operation cost is minimized) can be
engineered based on the classic time scale decomposition assumption that the
dynamics of the network are either fast enough so that these algorithms
essentially see the average or slow enough that any changes can be tracked to
allow the algorithms to adapt over time. However, as technological advancements
enable integration of ever more mobile nodes into communication networks, any
rate control or routing algorithms based, for example, on averaging out the
capacity of the wireless mobile link or tracking the instantaneous capacity
will perform poorly. The common element in our solution to engineering
efficient routing and rate control algorithms for mobile wireless networks is
to make the wireless mobile links seem as if they are wired or wireless links
to all but few nodes that directly see the mobile links (either the mobiles or
nodes that can transmit to or receive from the mobiles) through an appropriate
use of queuing structures at these selected nodes. This approach allows us to
design end-to-end rate control or routing algorithms for wireless mobile
networks so that neither averaging nor instantaneous tracking is necessary.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3972</identifier>
 <datestamp>2014-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3972</id><created>2012-01-18</created><authors><author><keyname>Gupta</keyname><forenames>Kapil Kumar</forenames></author><author><keyname>Beg</keyname><forenames>Rizwan</forenames></author><author><keyname>Niranjan</keyname><forenames>Jitendra Kumar</forenames></author></authors><title>A Novel Approach to Fast Image Filtering Algorithm of Infrared Images
  based on Intro Sort Algorithm</title><categories>cs.CV</categories><comments>7 pages. arXiv admin note: substantial text with articles by
  Chih-Lung Lin et al.</comments><journal-ref>IJCSI International Journal of Computer Science Issues, Vol. 8,
  Issue 6, No 1, November 2011, 235-241</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this study we investigate the fast image filtering algorithm based on
Intro sort algorithm and fast noise reduction of infrared images. Main feature
of the proposed approach is that no prior knowledge of noise required. It is
developed based on Stefan- Boltzmann law and the Fourier law. We also
investigate the fast noise reduction approach that has advantage of less
computation load. In addition, it can retain edges, details, text information
even if the size of the window increases. Intro sort algorithm begins with
Quick sort and switches to heap sort when the recursion depth exceeds a level
based on the number of elements being sorted. This approach has the advantage
of fast noise reduction by reducing the comparison time. It also significantly
speed up the noise reduction process and can apply to real-time image
processing. This approach will extend the Infrared images applications for
medicine and video conferencing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3976</identifier>
 <datestamp>2012-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3976</id><created>2012-01-19</created><authors><author><keyname>Sengupta</keyname><forenames>Souvik</forenames></author><author><keyname>Sahu</keyname><forenames>Sandipan</forenames></author><author><keyname>Dasgupta</keyname><forenames>Ranjan</forenames></author></authors><title>Construction of Learning Path Using Ant Colony Optimization from a
  Frequent Pattern Graph</title><categories>cs.OH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In an e-Learning system a learner may come across multiple unknown terms,
which are generally hyperlinked, while reading a text definition or theory on
any topic. It becomes even harder when one tries to understand those unknown
terms through further such links and they again find some new terms that have
new links. As a consequence they get confused where to initiate from and what
are the prerequisites. So it is very obvious for the learner to make a choice
of what should be learnt before what. In this paper we have taken the data
mining based frequent pattern graph model to define the association and
sequencing between the words and then adopted the Ant Colony Optimization, an
artificial intelligence approach, to derive a searching technique to obtain an
efficient and optimized learning path to reach to a unknown term.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3978</identifier>
 <datestamp>2012-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3978</id><created>2012-01-19</created><authors><author><keyname>Sengupta</keyname><forenames>Souvik</forenames></author><author><keyname>Chaki</keyname><forenames>Nabendu</forenames></author><author><keyname>Dasgupta</keyname><forenames>Ranjan</forenames></author></authors><title>Learners' Quanta based Design of a Learning Management System</title><categories>cs.OH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper IEEE Learning Technology System Architecture (LTSA) for LMS
software has been analyzed. It has been observed that LTSA is too abstract to
be adapted in a uniform way by LMS developers. A Learners' Quanta based high
level design that satisfies the IEEE LTSA standard has been proposed for future
development of efficient LMS software. A hybrid model of learning fitting into
LTSA model has also been proposed while designing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3979</identifier>
 <datestamp>2013-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3979</id><created>2012-01-19</created><updated>2012-03-05</updated><authors><author><keyname>Xi</keyname><forenames>Zhengjun</forenames></author><author><keyname>Fan</keyname><forenames>Heng</forenames></author><author><keyname>Li</keyname><forenames>Yongming</forenames></author></authors><title>The one-way unlocalizable quantum discord</title><categories>quant-ph cs.IT math.IT</categories><comments>6 pages, 3 figures. Minor corrections, references added</comments><doi>10.1103/PhysRevA.85.052102</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present the concept of the one-way unlocalizable quantum
discord and investigate its properties. We provide a polygamy inequality for it
in tripartite pure quantum system of arbitrary dimension. Several tradeoff
relations between the one-way unlocalizable quantum discord and other
correlations are given. If the von Neumann measurement is on a part of the
system, we give two expressions of the one-way unlocalizable quantum discord in
terms of partial distillable entanglement and quantum disturbance. Finally, we
also provide a lower bound for bipartite shareability of quantum correlation
beyond entanglement in a tripartite system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3981</identifier>
 <datestamp>2012-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3981</id><created>2012-01-19</created><authors><author><keyname>Sengupta</keyname><forenames>Souvik</forenames></author><author><keyname>Pal</keyname><forenames>Saurabh</forenames></author><author><keyname>Banerjee</keyname><forenames>Nilanjan</forenames></author></authors><title>A comparison algorithm to check LTSA Layer 1 and SCORM compliance in
  e-Learning sites</title><categories>cs.OH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The success of e-Learning is largely dependent on the impact of its
multimedia aided learning content on the learner over the hyper media. The
e-Learning portals with different proportion of multimedia elements have
different impact on the learner, as there is lack of standardization. The
Learning Technology System Architecture (LTSA) Layer 1 deals with the effect of
environment on the learner. From an information technology perspective it
specifies learner interaction from the environment to the learner via
multimedia content. Sharable Content Object Reference Model (SCROM) is a
collection of standards and specifications for content of web-based e-learning
and specifies how JavaScript API can be used to integrate content development.
In this paper an examination is made on the design features of interactive
multimedia components of the learning packages by creating an algorithm which
will give a comparative study of multimedia component used by different
learning packages. The resultant graph as output helps us to analysis to what
extent any LMS compliance LTSA layer 1 and SCORM specification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3982</identifier>
 <datestamp>2012-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3982</id><created>2012-01-19</created><authors><author><keyname>Mehri</keyname><forenames>Hassan</forenames></author></authors><title>Min-Sum algorithm for lattices constructed by Construction D</title><categories>cs.CR cs.IT math.CO math.IT</categories><comments>10 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The so-called min-sum algorithm has been applied for decoding lattices
constructed by Construction D'. We generalize this iterative decoding algorithm
to decode lattices constructed by Construction D. An upper bound on the
decoding complexity per iteration, in terms of coding gain, label group sizes
of the lattice and other factors is derived. We show that iterative decoding of
LDGM lattices has a reasonably low complexity such that lattices with
dimensions of a few thousands can be easily decoded.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3984</identifier>
 <datestamp>2012-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3984</id><created>2012-01-19</created><updated>2012-02-13</updated><authors><author><keyname>Rhodes</keyname><forenames>John</forenames></author><author><keyname>Silva</keyname><forenames>Pedro V.</forenames></author></authors><title>A new notion of vertex independence and rank for finite graphs</title><categories>math.CO cs.DM math.RT</categories><comments>47 pages</comments><msc-class>05C25, 05C50, 16Y60, 05B35</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new notion of vertex independence and rank for a finite graph G is
introduced. The independence of vertices is based on the boolean independence
of columns of a natural boolean matrix associated to G. Rank is the cardinality
of the largest set of independent columns. Some basic properties and some more
advanced theorems are proved. Geometric properties of the graph are related to
its rank and independent sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.3985</identifier>
 <datestamp>2012-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.3985</id><created>2012-01-19</created><authors><author><keyname>Askarunisa</keyname><forenames>A.</forenames></author><author><keyname>Manju</keyname><forenames>T.</forenames></author><author><keyname>Babu</keyname><forenames>B. Giri</forenames></author></authors><title>Fault Localization for Java Programs using Probabilistic Program
  Dependence Graph</title><categories>cs.SE</categories><comments>9 Pages, 8 figures 4 tables; International Journal of Computer
  Science Issues, December 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fault localization is a process to find the location of faults. It determines
the root cause of the failure. It identifies the causes of abnormal behaviour
of a faulty program. It identifies exactly where the bugs are. Existing fault
localization techniques are Slice based technique, Program- Spectrum based
Technique, Statistics Based Technique, Program State Based Technique, Machine
learning based Technique and Similarity Based Technique. In the proposed method
Model Based Fault Localization Technique is used, which is called Probabilistic
Program Dependence Graph . Probabilistic Program Dependence Graph (PPDG) is an
innovative model that scans the internal behaviour of the project. PPDG
construction is enhanced by Program Dependence Graph (PDG). PDG is achieved by
the Control Flow Graph (CFG). The PPDG construction augments the structural
dependences represented by a program dependence graph with estimates of
statistical dependences between node states, which are computed from the test
set. The PPDG is based on the established framework of probabilistic graphical
models. This work presents algorithms for constructing PPDGs and applying fault
localization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4002</identifier>
 <datestamp>2012-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4002</id><created>2012-01-19</created><authors><author><keyname>Burnetas</keyname><forenames>Apostolos</forenames></author><author><keyname>Kanavetas</keyname><forenames>Odysseas</forenames></author></authors><title>Adaptive Policies for Sequential Sampling under Incomplete Information
  and a Cost Constraint</title><categories>stat.ML cs.LG math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of sequential sampling from a finite number of
independent statistical populations to maximize the expected infinite horizon
average outcome per period, under a constraint that the expected average
sampling cost does not exceed an upper bound. The outcome distributions are not
known. We construct a class of consistent adaptive policies, under which the
average outcome converges with probability 1 to the true value under complete
information for all distributions with finite means. We also compare the rate
of convergence for various policies in this class using simulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4013</identifier>
 <datestamp>2012-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4013</id><created>2012-01-19</created><authors><author><keyname>Coon</keyname><forenames>Justin P.</forenames></author><author><keyname>Dettmann</keyname><forenames>Carl P.</forenames></author><author><keyname>Georgiou</keyname><forenames>Orestis</forenames></author></authors><title>Connectivity of Confined Dense Networks: Boundary Effects and Scaling
  Laws</title><categories>cs.NI cs.IT math.IT</categories><comments>21 pages, 6 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the probability that a dense network confined within
a given geometry is fully connected. We employ a cluster expansion approach
often used in statistical physics to analyze the effects that the boundaries of
the geometry have on connectivity. To maximize practicality and applicability,
we adopt four important point-to-point link models based on outage probability
in our analysis: single-input single-output (SISO), single-input
multiple-output (SIMO), multiple-input single-output (MISO), and multiple-input
multiple-output (MIMO). Furthermore, we derive diversity and power scaling laws
that dictate how boundary effects can be mitigated (to leading order) in
confined dense networks for each of these models. Finally, in order to
demonstrate the versatility of our theory, we analyze boundary effects for
dense networks comprising MIMO point-to-point links confined within a right
prism, a polyhedron that accurately models many geometries that can be found in
practice. We provide numerical results for this example, which verify our
analytical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4044</identifier>
 <datestamp>2012-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4044</id><created>2012-01-19</created><authors><author><keyname>Bauke</keyname><forenames>Heiko</forenames></author><author><keyname>Moore</keyname><forenames>Cristopher</forenames></author><author><keyname>Rouquier</keyname><forenames>Jean-Baptiste</forenames></author><author><keyname>Sherrington</keyname><forenames>David</forenames></author></authors><title>Topological phase transition in a network model with preferential
  attachment and node removal</title><categories>cond-mat.stat-mech cs.SI physics.soc-ph</categories><comments>The final publication is available at http://www.epj.org</comments><journal-ref>European Physical Journal B, 83(4), 519-524. (2011)</journal-ref><doi>10.1140/epjb/e2011-20346-0</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Preferential attachment is a popular model of growing networks. We consider a
generalized model with random node removal, and a combination of preferential
and random attachment. Using a high-degree expansion of the master equation, we
identify a topological phase transition depending on the rate of node removal
and the relative strength of preferential vs. random attachment, where the
degree distribution goes from a power law to one with an exponential tail.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4049</identifier>
 <datestamp>2013-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4049</id><created>2012-01-19</created><authors><author><keyname>Rosi&#x107;</keyname><forenames>Bojana V.</forenames></author><author><keyname>Ku&#x10d;erov&#xe1;</keyname><forenames>Anna</forenames></author><author><keyname>S&#xfd;kora</keyname><forenames>Jan</forenames></author><author><keyname>Pajonk</keyname><forenames>Oliver</forenames></author><author><keyname>Litvinenko</keyname><forenames>Alexander</forenames></author><author><keyname>Matthies</keyname><forenames>Hermann G.</forenames></author></authors><title>Parameter Identification in a Probabilistic Setting</title><categories>cs.NA cs.CE</categories><comments>29 pages, 16 figures</comments><journal-ref>Engineering Structures, 50, 179-196, 2013</journal-ref><doi>10.1016/j.engstruct.2012.12.029</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Parameter identification problems are formulated in a probabilistic language,
where the randomness reflects the uncertainty about the knowledge of the true
values. This setting allows conceptually easily to incorporate new information,
e.g. through a measurement, by connecting it to Bayes's theorem. The unknown
quantity is modelled as a (may be high-dimensional) random variable. Such a
description has two constituents, the measurable function and the measure. One
group of methods is identified as updating the measure, the other group changes
the measurable function. We connect both groups with the relatively recent
methods of functional approximation of stochastic problems, and introduce
especially in combination with the second group of methods a new procedure
which does not need any sampling, hence works completely deterministically. It
also seems to be the fastest and more reliable when compared with other
methods. We show by example that it also works for highly nonlinear non-smooth
problems with non-Gaussian measures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4050</identifier>
 <datestamp>2015-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4050</id><created>2012-01-19</created><updated>2012-05-29</updated><authors><author><keyname>Alc&#xe1;zar</keyname><forenames>J. G.</forenames></author><author><keyname>D&#xed;az-Toca</keyname><forenames>G. M.</forenames></author></authors><title>On the Shape of Curves that are Rational in Polar Coordinates</title><categories>cs.SC cs.CG cs.MS</categories><doi>10.1016/j.cagd.2012.09.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we provide a computational approach to the shape of curves
which are rational in polar coordinates, i.e. which are defined by means of a
parametrization (r(t),\theta(t)) where both r(t),\theta(t) are rational
functions. Our study includes theoretical aspects on the shape of these curves,
and algorithmic results which eventually lead to an algorithm for plotting the
&quot;interesting parts&quot; of the curve, i.e. the parts showing the main geometrical
features of it. On the theoretical side, we prove that these curves, with the
exceptions of lines and circles, cannot be algebraic (in cartesian
coordinates), we characterize the existence of infinitely many
self-intersections, and we connect this with certain phenomena which are not
possible in the algebraic world, namely the existence of limit circles, limit
points, or spiral branches. On the practical side, we provide an algorithm
which has been implemented in the computer algebra system Maple to visualize
this kind of curves. Our implementation makes use (and improves some aspects
of) the command polarplot currently available in Maple for plotting curves in
polar form.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4054</identifier>
 <datestamp>2012-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4054</id><created>2012-01-19</created><authors><author><keyname>Cohen</keyname><forenames>Asaf</forenames></author><author><keyname>Dolav</keyname><forenames>Shlomi</forenames></author><author><keyname>Leshem</keyname><forenames>Guy</forenames></author></authors><title>Sensor Networks: from Dependence Analysis Via Matroid Bases to Online
  Synthesis</title><categories>cs.IT cs.DS math.IT</categories><comments>27 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider the two related problems of sensor selection and sensor fusion. In
the first, given a set of sensors, one wishes to identify a subset of the
sensors, which while small in size, captures the essence of the data gathered
by the sensors. In the second, one wishes to construct a fused sensor, which
utilizes the data from the sensors (possibly after discarding dependent ones)
in order to create a single sensor which is more reliable than each of the
individual ones. In this work, we rigorously define the dependence among
sensors in terms of joint empirical measures and incremental parsing. We show
that these measures adhere to a polymatroid structure, which in turn
facilitates the application of efficient algorithms for sensor selection. We
suggest both a random and a greedy algorithm for sensor selection. Given an
independent set, we then turn to the fusion problem, and suggest a novel
variant of the exponential weighting algorithm. In the suggested algorithm, one
competes against an augmented set of sensors, which allows it to converge to
the best fused sensor in a family of sensors, without having any prior data on
the sensors' performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4080</identifier>
 <datestamp>2012-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4080</id><created>2012-01-19</created><authors><author><keyname>Steiner</keyname><forenames>Ingmar</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Ouni</keyname><forenames>Slim</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>Progress in animation of an EMA-controlled tongue model for
  acoustic-visual speech synthesis</title><categories>cs.AI</categories><proxy>ccsd</proxy><journal-ref>Elektronische Sprachsignalverarbeitung 2011 TUDpress (Ed.) (2011)
  245-252</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a technique for the animation of a 3D kinematic tongue model, one
component of the talking head of an acoustic-visual (AV) speech synthesizer.
The skeletal animation approach is adapted to make use of a deformable rig
controlled by tongue motion capture data obtained with electromagnetic
articulography (EMA), while the tongue surface is extracted from volumetric
magnetic resonance imaging (MRI) data. Initial results are shown and future
work outlined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4089</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4089</id><created>2012-01-19</created><updated>2013-06-03</updated><authors><author><keyname>Kr&#xf6;tzsch</keyname><forenames>Markus</forenames></author><author><keyname>Simancik</keyname><forenames>Frantisek</forenames></author><author><keyname>Horrocks</keyname><forenames>Ian</forenames></author></authors><title>A Description Logic Primer</title><categories>cs.AI cs.LO</categories><acm-class>I.2.4; F.4.1</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper provides a self-contained first introduction to description logics
(DLs). The main concepts and features are explained with examples before syntax
and semantics of the DL SROIQ are defined in detail. Additional sections review
light-weight DL languages, discuss the relationship to the Web Ontology
Language OWL and give pointers to further reading.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4106</identifier>
 <datestamp>2015-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4106</id><created>2012-01-19</created><authors><author><keyname>Smith</keyname><forenames>Benjamin P.</forenames></author><author><keyname>Farhood</keyname><forenames>Arash</forenames></author><author><keyname>Hunt</keyname><forenames>Andrew</forenames></author><author><keyname>Kschischang</keyname><forenames>Frank R.</forenames></author><author><keyname>Lodge</keyname><forenames>John</forenames></author></authors><title>Staircase Codes: FEC for 100 Gb/s OTN</title><categories>cs.IT math.IT</categories><comments>To appear in IEEE/OSA J. of Lightwave Technology</comments><doi>10.1109/JLT.2011.2175479</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Staircase codes, a new class of forward-error-correction (FEC) codes suitable
for high-speed optical communications, are introduced. An ITU-T
G.709-compatible staircase code with rate R=239/255 is proposed, and FPGA-based
simulation results are presented, exhibiting a net coding gain (NCG) of 9.41 dB
at an output error rate of 1E-15, an improvement of 0.42 dB relative to the
best code from the ITU-T G.975.1 recommendation. An error floor analysis
technique is presented, and the proposed code is shown to have an error floor
at 4.0E-21.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4108</identifier>
 <datestamp>2015-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4108</id><created>2012-01-19</created><authors><author><keyname>Smith</keyname><forenames>Benjamin P.</forenames></author><author><keyname>Kschischang</keyname><forenames>Frank R.</forenames></author></authors><title>A Pragmatic Coded Modulation Scheme for High-Spectral-Efficiency
  Fiber-Optic Communications</title><categories>cs.IT math.IT</categories><comments>To appear in IEEE/OSA J. of Lightwave Technology</comments><doi>10.1109/JLT.2012.2185683</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A pragmatic coded modulation system is presented that incorporates signal
shaping and exploits the excellent performance and efficient high-speed
decoding architecture of staircase codes. Reliable communication within 0.62
bits/s/Hz of the estimated capacity (per polarization) of a system with L=2000
km is provided by the proposed system, with an error floor below 1E-20. Also,
it is shown that digital backpropagation increases the achievable spectral
efficiencies---relative to linear equalization---by 0.55 to 0.75 bits/s/Hz per
polarization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4109</identifier>
 <datestamp>2012-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4109</id><created>2012-01-19</created><authors><author><keyname>&#x15e;en</keyname><forenames>Nevroz</forenames></author><author><keyname>Alajaji</keyname><forenames>Fady</forenames></author><author><keyname>Y&#xfc;ksel</keyname><forenames>Serdar</forenames></author><author><keyname>Como</keyname><forenames>Giacomo</forenames></author></authors><title>On the Multiple Access Channel with Asymmetric Noisy State Information
  at the Encoders</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of reliable communication over multiple-access
channels (MAC) where the channel is driven by an independent and identically
distributed state process and the encoders and the decoder are provided with
various degrees of asymmetric noisy channel state information (CSI). For the
case where the encoders observe causal, asymmetric noisy CSI and the decoder
observes complete CSI, we provide inner and outer bounds to the capacity
region, which are tight for the sum-rate capacity. We then observe that, under
a Markov assumption, similar capacity results also hold in the case where the
receiver observes noisy CSI. Furthermore, we provide a single letter
characterization for the capacity region when the CSI at the encoders are
asymmetric deterministic functions of the CSI at the decoder and the encoders
have non-causal noisy CSI (its causal version is recently solved in
\cite{como-yuksel}). When the encoders observe asymmetric noisy CSI with
asymmetric delays and the decoder observes complete CSI, we provide a single
letter characterization for the capacity region. Finally, we consider a
cooperative scenario with common and private messages, with asymmetric noisy
CSI at the encoders and complete CSI at the decoder. We provide a single letter
expression for the capacity region for such channels. For the cooperative
scenario, we also note that as soon as the common message encoder does not have
access to CSI, then in any noisy setup, covering the cases where no CSI or
noisy CSI at the decoder, it is possible to obtain a single letter
characterization for the capacity region. The main component in these results
is a generalization of a converse coding approach, recently introduced in [1]
for the MAC with asymmetric quantized CSI at the encoders and herein
considerably extended and adapted for the noisy CSI setup.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4116</identifier>
 <datestamp>2012-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4116</id><created>2012-01-19</created><authors><author><keyname>Siomina</keyname><forenames>Iana</forenames></author><author><keyname>Yuan</keyname><forenames>Di</forenames></author></authors><title>Analysis of Cell Load Coupling for LTE Network Planning and Optimization</title><categories>cs.IT cs.NI math.IT</categories><comments>The paper contains 22 pages with 9 figures. The paper is submitted to
  IEEE Transactions on Wireless Communications. This is the version in Jan 2012
  after one revision</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  System-centric modeling and analysis are of key significance in planning and
optimizing cellular networks. In this paper, we provide a mathematical analysis
of performance modeling for LTE networks. The system model characterizes the
coupling relation between the cell load factors, taking into account
non-uniform traffic demand and interference between the cells with arbitrary
network topology. Solving the model enables a network-wide performance
evaluation in resource consumption. We develop and prove both sufficient and
necessary conditions for the feasibility of the load-coupling system, and
provide results related to computational aspects for numerically approaching
the solution. The theoretical findings are accompanied with experimental
results to instructively illustrate the application in optimizing LTE network
configuration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4118</identifier>
 <datestamp>2012-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4118</id><created>2012-01-19</created><authors><author><keyname>Coppersmith</keyname><forenames>Glen A.</forenames></author><author><keyname>Priebe</keyname><forenames>Carey E.</forenames></author></authors><title>Vertex Nomination via Content and Context</title><categories>stat.AP cs.SI physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  If I know of a few persons of interest, how can a combination of human
language technology and graph theory help me find other people similarly
interesting? If I know of a few people committing a crime, how can I determine
their co-conspirators? Given a set of actors deemed interesting, we seek other
actors who are similarly interesting. We use a collection of communications
encoded as an attributed graph, where vertices represents actors and edges
connect pairs of actors that communicate. Attached to each edge is the set of
documents wherein that pair of actors communicate, providing content in context
- the communication topic in the context of who communicates with whom. In
these documents, our identified interesting actors communicate amongst each
other and with other actors whose interestingness is unknown. Our objective is
to nominate the most likely interesting vertex from all vertices with unknown
interestingness. As an illustrative example, the Enron email corpus consists of
communications between actors, some of which are allegedly committing fraud.
Some of their fraudulent activity is captured in emails, along with many
innocuous emails (both between the fraudsters and between the other employees
of Enron); we are given the identities of a few fraudster vertices and asked to
nominate other vertices in the graph as likely representing other actors
committing fraud. Foundational theory and initial experimental results indicate
that approaching this task with a joint model of content and context improves
the performance (as measured by standard information retrieval measures) over
either content or context alone.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4139</identifier>
 <datestamp>2012-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4139</id><created>2012-01-19</created><authors><author><keyname>Machado</keyname><forenames>Bruno Brandoli</forenames></author><author><keyname>Gon&#xe7;alves</keyname><forenames>Wesley Nunes</forenames></author><author><keyname>Bruno</keyname><forenames>Odemir Martinez</forenames></author></authors><title>Image decomposition with anisotropic diffusion applied to leaf-texture
  analysis</title><categories>cs.CV</categories><comments>Annals of Workshop of Computer Vision 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Texture analysis is an important field of investigation that has received a
great deal of interest from computer vision community. In this paper, we
propose a novel approach for texture modeling based on partial differential
equation (PDE). Each image $f$ is decomposed into a family of derived
sub-images. $f$ is split into the $u$ component, obtained with anisotropic
diffusion, and the $v$ component which is calculated by the difference between
the original image and the $u$ component. After enhancing the texture attribute
$v$ of the image, Gabor features are computed as descriptors. We validate the
proposed approach on two texture datasets with high variability. We also
evaluate our approach on an important real-world application: leaf-texture
analysis. Experimental results indicate that our approach can be used to
produce higher classification rates and can be successfully employed for
different texture applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4142</identifier>
 <datestamp>2012-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4142</id><created>2012-01-19</created><authors><author><keyname>Amrit</keyname><forenames>Chintan</forenames></author><author><keyname>van Hillegersberg</keyname><forenames>Jos</forenames></author><author><keyname>Kumar</keyname><forenames>Kuldeep</forenames></author></authors><title>Identifying Coordination Problems in Software Development: Finding
  Mismatches between Software and Project Team Structures</title><categories>cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Today's dynamic and iterative development environment brings significant
challenges for software project management. In distributed project settings,
&quot;management by walking around&quot; is no longer an option and project managers may
miss out on key project insights. The TESNA (TEchnical Social Network Analysis)
method and tool aims to provide project managers both a method and a tool for
gaining insights and taking corrective action. TESNA achieves this by analysing
a project's evolving social and technical network structures using data from
multiple sources, including CVS, email and chat repositories. Using pattern
theory, TESNA helps to identify areas where the current state of the project's
social and technical networks conflicts with what patterns suggest. We refer to
such a conflict as a Socio-Technical Structure Clash (STSC). In this paper we
report on our experience of using TESNA to identify STSCs in a corporate
environment through the mining of software repositories. We find multiple
instances of three STSCs (Conway's Law, Code Ownership and Project
Coordination) in many of the on-going development projects, thereby validating
the method and tool that we have developed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4145</identifier>
 <datestamp>2012-02-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4145</id><created>2012-01-19</created><updated>2012-02-27</updated><authors><author><keyname>Bakshy</keyname><forenames>Eytan</forenames></author><author><keyname>Rosenn</keyname><forenames>Itamar</forenames></author><author><keyname>Marlow</keyname><forenames>Cameron</forenames></author><author><keyname>Adamic</keyname><forenames>Lada</forenames></author></authors><title>The Role of Social Networks in Information Diffusion</title><categories>cs.SI physics.soc-ph</categories><comments>10 pages, 7 figures. In the Proceedings of ACM WWW 2012, April 16-20,
  2012, Lyon, France</comments><acm-class>J.4; H.1.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Online social networking technologies enable individuals to simultaneously
share information with any number of peers. Quantifying the causal effect of
these technologies on the dissemination of information requires not only
identification of who influences whom, but also of whether individuals would
still propagate information in the absence of social signals about that
information. We examine the role of social networks in online information
diffusion with a large-scale field experiment that randomizes exposure to
signals about friends' information sharing among 253 million subjects in situ.
Those who are exposed are significantly more likely to spread information, and
do so sooner than those who are not exposed. We further examine the relative
role of strong and weak ties in information propagation. We show that, although
stronger ties are individually more influential, it is the more abundant weak
ties who are responsible for the propagation of novel information. This
suggests that weak ties may play a more dominant role in the dissemination of
information online than currently believed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4150</identifier>
 <datestamp>2012-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4150</id><created>2012-01-19</created><authors><author><keyname>Avrachenkov</keyname><forenames>Konstantin</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Dudin</keyname><forenames>Alexander</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Klimenok</keyname><forenames>Valentina</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Nain</keyname><forenames>Philippe</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Semenova</keyname><forenames>Olga</forenames></author></authors><title>Optimal Threshold Control by the Robots of Web Search Engines with
  Obsolescence of Documents</title><categories>cs.NI</categories><proxy>ccsd</proxy><journal-ref>Computer Networks 55, 8 (2011) 1880-1893</journal-ref><doi>10.1016/j.comnet.2011.01.013</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A typical web search engine consists of three principal parts: crawling
engine, indexing engine, and searching engine. The present work aims to
optimize the performance of the crawling engine. The crawling engine finds new
web pages and updates web pages existing in the database of the web search
engine. The crawling engine has several robots collecting information from the
Internet. We first calculate various performance measures of the system (e.g.,
probability of arbitrary page loss due to the buffer overflow, probability of
starvation of the system, the average time waiting in the buffer). Intuitively,
we would like to avoid system starvation and at the same time to minimize the
information loss. We formulate the problem as a multi-criteria optimization
problem and attributing a weight to each criterion. We solve it in the class of
threshold policies. We consider a very general web page arrival process modeled
by Batch Marked Markov Arrival Process and a very general service time modeled
by Phase-type distribution. The model has been applied to the performance
evaluation and optimization of the crawler designed by INRIA Maestro team in
the framework of the RIAM INRIA-Canon research project.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4153</identifier>
 <datestamp>2012-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4153</id><created>2012-01-19</created><authors><author><keyname>Faber</keyname><forenames>Vance</forenames></author></authors><title>Global sum on symmetric networks</title><categories>math.CO cs.DC</categories><comments>5 pages</comments><msc-class>05E15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We are interested in the following problem we call global sum. Each processor
starts with a single real value. At each time step, every directed edge in the
graph can simultaneously be used to transmit a single (bounded) number between
the processors (vertices). How many time steps s are required to ensure that
every processor acquires the global sum? We know that s is bounded below by the
diameter and above by two times the diameter. We conjecture that for vertex
symmetric graphs, s is equal to the diameter. We show this is true if the
diameter is 2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4179</identifier>
 <datestamp>2012-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4179</id><created>2012-01-19</created><authors><author><keyname>Telgarsky</keyname><forenames>Rastislav</forenames></author></authors><title>Applications of topology in computer algorithms</title><categories>math.NA cs.CY math.GT</categories><comments>This paper is based on the invited lecture at International
  Conference on Topology and Applications held in August 23--27, 1999, at
  Kanagawa University in Yokohama, Japan</comments><msc-class>00A71, 65D17, 65D18, 68U10</msc-class><acm-class>G.1.10; G.2.3</acm-class><journal-ref>Matematyka Stosowana, 13 (54), 2011, 35-46</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of this paper is to discuss some applications of general topology in
computer algorithms including modeling and simulation, and also in computer
graphics and image processing. While the progress in these areas heavily
depends on advances in computing hardware, the major intellectual achievements
are the algorithms. The applications of general topology in other branches of
mathematics are not discussed, since they are not applications of mathematics
outside of mathematics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4183</identifier>
 <datestamp>2012-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4183</id><created>2012-01-19</created><updated>2012-02-02</updated><authors><author><keyname>Vaidya</keyname><forenames>Nitin</forenames></author><author><keyname>Tseng</keyname><forenames>Lewis</forenames></author><author><keyname>Liang</keyname><forenames>Guanfeng</forenames></author></authors><title>Iterative Approximate Byzantine Consensus in Arbitrary Directed Graphs</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we explore the problem of iterative approximate Byzantine
consensus in arbitrary directed graphs. In particular, we prove a necessary and
sufficient condition for the existence of iterative byzantine consensus
algorithms. Additionally, we use our sufficient condition to examine whether
such algorithms exist for some specific graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4197</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4197</id><created>2012-01-19</created><updated>2013-09-28</updated><authors><author><keyname>Sen</keyname><forenames>Soumya</forenames></author><author><keyname>Joe-Wong</keyname><forenames>Carlee</forenames></author><author><keyname>Ha</keyname><forenames>Sangtae</forenames></author><author><keyname>Chiang</keyname><forenames>Mung</forenames></author></authors><title>A Survey of Smart Data Pricing: Past Proposals, Current Plans, and
  Future Trends</title><categories>cs.NI cs.CY</categories><journal-ref>ACM Computing Surveys, Vol. 146, No. 2, June 2014</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditionally, network operators have used simple flat-rate broadband data
plans for both wired and wireless network access. But today, with the
popularity of mobile devices and exponential growth of apps, videos, and
clouds, service providers are gradually moving towards more sophisticated
pricing schemes. This decade will therefore likely witness a major change in
the ways in which network resources are managed, and the role of economics in
allocating these resources. This survey reviews some of the well-known past
broadband pricing proposals (both static and dynamic), including their current
realizations in various consumer data plans around the world, and discusses
several research problems and open questions. By exploring the benefits and
challenges of pricing data, this paper attempts to facilitate both the
industrial and the academic communities' efforts in understanding the existing
literature, recognizing new trends, and shaping an appropriate and timely
research agenda.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4206</identifier>
 <datestamp>2012-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4206</id><created>2012-01-20</created><authors><author><keyname>Jaiswal</keyname><forenames>Ragesh</forenames></author><author><keyname>Kumar</keyname><forenames>Amit</forenames></author><author><keyname>Sen</keyname><forenames>Sandeep</forenames></author></authors><title>A simple D^2-sampling based PTAS for k-means and other Clustering
  Problems</title><categories>cs.DS</categories><acm-class>I.5.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a set of points $P \subset \mathbb{R}^d$, the $k$-means clustering
problem is to find a set of $k$ {\em centers} $C = \{c_1,...,c_k\}, c_i \in
\mathbb{R}^d,$ such that the objective function $\sum_{x \in P} d(x,C)^2$,
where $d(x,C)$ denotes the distance between $x$ and the closest center in $C$,
is minimized. This is one of the most prominent objective functions that have
been studied with respect to clustering.
  $D^2$-sampling \cite{ArthurV07} is a simple non-uniform sampling technique
for choosing points from a set of points. It works as follows: given a set of
points $P \subseteq \mathbb{R}^d$, the first point is chosen uniformly at
random from $P$. Subsequently, a point from $P$ is chosen as the next sample
with probability proportional to the square of the distance of this point to
the nearest previously sampled points.
  $D^2$-sampling has been shown to have nice properties with respect to the
$k$-means clustering problem. Arthur and Vassilvitskii \cite{ArthurV07} show
that $k$ points chosen as centers from $P$ using $D^2$-sampling gives an
$O(\log{k})$ approximation in expectation. Ailon et. al. \cite{AJMonteleoni09}
and Aggarwal et. al. \cite{AggarwalDK09} extended results of \cite{ArthurV07}
to show that $O(k)$ points chosen as centers using $D^2$-sampling give $O(1)$
approximation to the $k$-means objective function with high probability. In
this paper, we further demonstrate the power of $D^2$-sampling by giving a
simple randomized $(1 + \epsilon)$-approximation algorithm that uses the
$D^2$-sampling in its core.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4210</identifier>
 <datestamp>2012-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4210</id><created>2012-01-20</created><authors><author><keyname>Mehta</keyname><forenames>Harita</forenames></author><author><keyname>Bhatia</keyname><forenames>Shveta Kundra</forenames></author><author><keyname>Bedi</keyname><forenames>Punam</forenames></author><author><keyname>Dixit</keyname><forenames>V. S.</forenames></author></authors><title>Collaborative Personalized Web Recommender System using Entropy based
  Similarity Measure</title><categories>cs.IR cs.AI</categories><comments>10 pages</comments><journal-ref>IJCSI, Vol 8, Issue 6, No 3, Nov 2011</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  On the internet, web surfers, in the search of information, always strive for
recommendations. The solutions for generating recommendations become more
difficult because of exponential increase in information domain day by day. In
this paper, we have calculated entropy based similarity between users to
achieve solution for scalability problem. Using this concept, we have
implemented an online user based collaborative web recommender system. In this
model based collaborative system, the user session is divided into two levels.
Entropy is calculated at both the levels. It is shown that from the set of
valuable recommenders obtained at level I; only those recommenders having lower
entropy at level II than entropy at level I, served as trustworthy
recommenders. Finally, top N recommendations are generated from such
trustworthy recommenders for an online user.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4214</identifier>
 <datestamp>2012-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4214</id><created>2012-01-20</created><authors><author><keyname>Zhang</keyname><forenames>Zhou</forenames></author><author><keyname>Jiang</keyname><forenames>Hai</forenames></author><author><keyname>Tan</keyname><forenames>Peng</forenames></author><author><keyname>Slevinsky</keyname><forenames>Jim</forenames></author></authors><title>Channel Exploration and Exploitation with Imperfect Spectrum Sensing in
  Cognitive Radio Networks</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the problem of opportunistic channel sensing and access in
cognitive radio networks when the sensing is imperfect and a secondary user has
limited traffic to send at a time is investigated. Primary users' statistical
information is assumed to be unknown, and therefore, a secondary user needs to
learn the information online during channel sensing and access process, which
means learning loss, also referred to as regret, is inevitable. In this
research, the case when all potential channels can be sensed simultaneously is
investigated first. The channel access process is modeled as a multi-armed
bandit problem with side observation. And channel access rules are derived and
theoretically proved to have asymptotically finite regret. Then the case when
the secondary user can sense only a limited number of channels at a time is
investigated. The channel sensing and access process is modeled as a bi-level
multi-armed bandit problem. It is shown that any adaptive rule has at least
logarithmic regret. Then we derive channel sensing and access rules and
theoretically prove they have logarithmic regret asymptotically and with finite
time. The effectiveness of the derived rules is validated by computer
simulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4219</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4219</id><created>2012-01-20</created><updated>2012-09-25</updated><authors><author><keyname>Yang</keyname><forenames>Zhengfeng</forenames></author><author><keyname>Wu</keyname><forenames>Min</forenames></author><author><keyname>Lin</keyname><forenames>Wang</forenames></author></authors><title>Exact Safety Verification of Hybrid Systems Based on Bilinear SOS
  Representation</title><categories>cs.SE cs.SC</categories><comments>arXiv admin note: substantial text overlap with arXiv:1112.2328</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we address the problem of safety verification of nonlinear
hybrid systems. A hybrid symbolic-numeric method is presented to compute exact
inequality invariants of hybrid systems efficiently. Some numerical invariants
of a hybrid system can be obtained by solving a bilinear SOS programming via
PENBMI solver or iterative method, then the modified Newton refinement and
rational vector recovery techniques are applied to obtain exact polynomial
invariants with rational coefficients, which {\it exactly} satisfy the
conditions of invariants. Experiments on some benchmarks are given to
illustrate the efficiency of our algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4239</identifier>
 <datestamp>2013-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4239</id><created>2012-01-20</created><updated>2013-06-28</updated><authors><author><keyname>Martinelli</keyname><forenames>Gabriele</forenames></author><author><keyname>Eidsvik</keyname><forenames>Jo</forenames></author><author><keyname>Hauge</keyname><forenames>Ragnar</forenames></author></authors><title>Dynamic Decision Making for Graphical Models Applied to Oil Exploration</title><categories>stat.AP cs.AI stat.CO</categories><comments>This paper has been withdrawn by the authors. 22 pages, 7 figures,
  submitted</comments><report-no>Technical Report in Statistics N. 12/2011, Dept. of Mathematical
  Sciences, NTNU</report-no><doi>10.1016/j.ejor.2013.04.057</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn by the authors. We present a framework for
sequential decision making in problems described by graphical models. The
setting is given by dependent discrete random variables with associated costs
or revenues. In our examples, the dependent variables are the potential
outcomes (oil, gas or dry) when drilling a petroleum well. The goal is to
develop an optimal selection strategy that incorporates a chosen utility
function within an approximated dynamic programming scheme. We propose and
compare different approximations, from simple heuristics to more complex
iterative schemes, and we discuss their computational properties. We apply our
strategies to oil exploration over multiple prospects modeled by a directed
acyclic graph, and to a reservoir drilling decision problem modeled by a Markov
random field. The results show that the suggested strategies clearly improve
the simpler intuitive constructions, and this is useful when selecting
exploration policies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4243</identifier>
 <datestamp>2012-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4243</id><created>2012-01-20</created><updated>2012-07-10</updated><authors><author><keyname>Gerard</keyname><forenames>Maze</forenames></author></authors><title>Analysis of a Key Distribution Scheme in Secure Multicasting</title><categories>cs.CR cs.DM cs.IT math.IT</categories><msc-class>11T55, 94A60, 68P30</msc-class><journal-ref>Journal of Mathematical Cryptology, Vol. 6, 1 (2012), pp. 69--80</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article presents an analysis of the secure key broadcasting scheme
proposed by Wu, Ruan, Lai and Tseng. The study of the parameters of the system
is based on a connection with a special type of symmetric equations over finite
fields. We present two different attacks against the system, whose efficiency
depends on the choice of the parameters. In particular, a time-memory tradeoff
attack is described, effective when a parameter of the scheme is chosen without
care. In such a situation, more than one third of the cases can be broken with
a time and space complexity in the range of the square root of the complexity
of the best attack suggested by Wu et al. against their system. This leads to a
feasible attack in a realistic scenario.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4262</identifier>
 <datestamp>2012-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4262</id><created>2012-01-20</created><authors><author><keyname>Yang</keyname><forenames>Fan</forenames></author><author><keyname>Hankin</keyname><forenames>Chris</forenames></author><author><keyname>Nielson</keyname><forenames>Flemming</forenames></author><author><keyname>Nielson</keyname><forenames>Hanne Riis</forenames></author></authors><title>Secondary use of data in EHR systems</title><categories>cs.PL cs.DC</categories><comments>40 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show how to use aspect-oriented programming to separate security and trust
issues from the logical design of mobile, distributed systems. The main
challenge is how to enforce various types of security policies, in particular
predictive access control policies - policies based on the future behavior of a
program. A novel feature of our approach is that advice is able to analyze the
future use of data. We consider a number of different security policies,
concerning both primary and secondary use of data, some of which can only be
enforced by analysis of process continuations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4279</identifier>
 <datestamp>2012-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4279</id><created>2012-01-20</created><authors><author><keyname>Joubert</keyname><forenames>Alain</forenames><affiliation>LIRMM</affiliation></author><author><keyname>Lafourcade</keyname><forenames>Mathieu</forenames><affiliation>LIRMM</affiliation></author><author><keyname>Schwab</keyname><forenames>Didier</forenames><affiliation>LIG Laboratoire d'Informatique de Grenoble</affiliation></author><author><keyname>Zock</keyname><forenames>Michael</forenames><affiliation>LIF</affiliation></author></authors><title>\'Evaluation et consolidation d'un r\'eseau lexical via un outil pour
  retrouver le mot sur le bout de la langue</title><categories>cs.HC</categories><proxy>ccsd</proxy><journal-ref>TALN, Montpellier : France (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Since September 2007, a large scale lexical network for French is under
construction through methods based on some kind of popular consensus by means
of games (JeuxDeMots project). Human intervention can be considered as
marginal. It is limited to corrections, adjustments and validation of the
senses of terms, which amounts to less than 0,5 % of the relations in the
network. To appreciate the quality of this resource built by non-expert users
(players of the game), we use a similar approach to its construction. The
resource must be validated by laymen, persistent in time, on open class
vocabulary. We suggest to check whether our tool is able to solve the Tip of
the Tongue (TOT) problem. Just like JeuxDeMots, our tool can be considered as
an on-line game. Like the former, it allows the acquisition of new relations,
enriching thus the (existing) network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4285</identifier>
 <datestamp>2012-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4285</id><created>2012-01-20</created><updated>2012-07-16</updated><authors><author><keyname>Vachery</keyname><forenames>Jithin</forenames></author><author><keyname>Dukkipati</keyname><forenames>Ambedkar</forenames></author></authors><title>On Shore and Johnson properties for a Special Case of Csisz\'ar
  f-divergences</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The importance of power-law distributions is attributed to the fact that most
of the naturally occurring phenomenon exhibit this distribution. While
exponential distributions can be derived by minimizing KL-divergence w.r.t some
moment constraints, some power law distributions can be derived by minimizing
some generalizations of KL-divergence (more specifically some special cases of
Csisz\'ar f-divergences). Divergence minimization is very well studied in
information theoretical approaches to statistics. In this work we study
properties of minimization of Tsallis divergence, which is a special case of
Csisz\'ar f-divergence. In line with the work by Shore and Johnson (IEEE Trans.
IT, 1981), we examine the properties exhibited by these minimization methods
including the Pythagorean property.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4291</identifier>
 <datestamp>2012-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4291</id><created>2012-01-20</created><authors><author><keyname>Saniee</keyname><forenames>Iraj</forenames></author><author><keyname>Tucci</keyname><forenames>Gabriel H.</forenames></author></authors><title>Scaling of Congestion in Small World Networks</title><categories>math.MG cond-mat.stat-mech cs.SI physics.soc-ph</categories><comments>8 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this report we show that in a planar exponentially growing network
consisting of $N$ nodes, congestion scales as $O(N^2/\log(N))$ independently of
how flows may be routed. This is in contrast to the $O(N^{3/2})$ scaling of
congestion in a flat polynomially growing network. We also show that without
the planarity condition, congestion in a small world network could scale as low
as $O(N^{1+\epsilon})$, for arbitrarily small $\epsilon$. These extreme results
demonstrate that the small world property by itself cannot provide guidance on
the level of congestion in a network and other characteristics are needed for
better resolution. Finally, we investigate scaling of congestion under the
geodesic flow, that is, when flows are routed on shortest paths based on a link
metric. Here we prove that if the link weights are scaled by arbitrarily small
or large multipliers then considerable changes in congestion may occur.
However, if we constrain the link-weight multipliers to be bounded away from
both zero and infinity, then variations in congestion due to such remetrization
are negligible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4292</identifier>
 <datestamp>2012-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4292</id><created>2012-01-20</created><updated>2012-02-18</updated><authors><author><keyname>Whitbeck</keyname><forenames>John</forenames></author><author><keyname>Lopez</keyname><forenames>Yoann</forenames></author><author><keyname>Leguay</keyname><forenames>Jeremie</forenames></author><author><keyname>Conan</keyname><forenames>Vania</forenames></author><author><keyname>de Amorim</keyname><forenames>Marcelo Dias</forenames></author></authors><title>Push-and-Track: Saving Infrastructure Bandwidth Through Opportunistic
  Forwarding</title><categories>cs.NI</categories><comments>Accepted for publication in the Pervasive and Mobile Computing
  journal</comments><doi>10.1016/j.pmcj.2012.02.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Major wireless operators are nowadays facing network capacity issues in
striving to meet the growing demands of mobile users. At the same time,
3G-enabled devices increasingly benefit from ad hoc radio connectivity (e.g.,
Wi-Fi). In this context of hybrid connectivity, we propose Push-and-track, a
content dissemina- tion framework that harnesses ad hoc communication
opportunities to minimize the load on the wireless infrastructure while
guaranteeing tight delivery delays. It achieves this through a control loop
that collects user-sent acknowledgements to determine if new copies need to be
reinjected into the network through the 3G interface. Push-and-Track is
flexible and can be applied to a variety of scenarios, including periodic
message flooding and floating data. For the former, this paper examines
multiple strategies to determine how many copies of the content should be
injected, when, and to whom; for the latter, it examines the achievable offload
ratio depending on the freshness constraints. The short delay-tolerance of
common content, such as news or road traffic updates, make them suitable for
such a system. Use cases with a long delay-tolerance, such as software updates,
are an even better fit. Based on a realistic large-scale vehicular dataset from
the city of Bologna composed of more than 10,000 vehicles, we demonstrate that
Push-and-Track consistently meets its delivery objectives while reducing the
use of the 3G network by about 90%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4301</identifier>
 <datestamp>2012-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4301</id><created>2012-01-20</created><authors><author><keyname>N.</keyname><forenames>Chitra Kiran</forenames></author><author><keyname>Kumar</keyname><forenames>G. Narendra</forenames></author></authors><title>A Robust Client Verification in cloud enabled m-Commerce using Gaining
  Protocol</title><categories>cs.NI</categories><journal-ref>IJCSI International Journal of Computer Science Issues, Vol. 8,
  Issue 6, No 2, November 2011 ISSN (Online): 1694-0814</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The proposed system highlights a novel approach of exclusive verification
process using gain protocol for ensuring security among both the parties
(client-service provider) in m-commerce application with cloud enabled service.
The proposed system is based on the potential to verify the clients with
trusted hand held device depending on the set of frequent events and actions to
be carried out. The framework of the proposed work is design after collecting a
real time data sets from an android enabled hand set, which when subjected to
gain protocol, will result in detection of malicious behavior of illegal
clients in the network. The real time experiment is performed with applicable
datasets gather, which show the best result for identifying threats from last 2
months data collected.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4304</identifier>
 <datestamp>2012-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4304</id><created>2012-01-20</created><authors><author><keyname>Zabihi</keyname><forenames>Mohammad</forenames></author><author><keyname>Shaghaghi</keyname><forenames>Ramin</forenames></author><author><keyname>kalantari</keyname><forenames>Mohammad Esmail</forenames></author></authors><title>Improving Security Levels of IEEE 802.16e Authentication By
  Diffie-Hellman Method</title><categories>cs.CR</categories><comments>6 pages,7 figuers,3 tabels</comments><msc-class>97</msc-class><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  In this paper, we proposed an authentication method according to
Diffie-Hellman. First, we introduce different methods for authentication in
IEEE.802.16 then we proposed an authentication method according to
Diffie-Hellman and in the last we compare different methods for authentication
to improve security in IEEE802.16e. CPN is a useful for simulation and compare
protocol together so we use CPN tools in this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4307</identifier>
 <datestamp>2012-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4307</id><created>2012-01-20</created><updated>2012-11-19</updated><authors><author><keyname>Brunel</keyname><forenames>Alo&#xef;s</forenames></author></authors><title>Quantitative classical realizability</title><categories>cs.LO</categories><comments>Revised version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Introduced by Dal Lago and Hofmann, quantitative realizability is a technique
used to define models for logics based on Multiplicative Linear Logic. A
particularity is that functions are interpreted as bounded time computable
functions. It has been used to give new and uniform proofs of soundness of
several type systems with respect to certain time complexity classes. We
propose a reformulation of their ideas in the setting of Krivine's classical
realizability. The framework obtained generalizes Dal Lago and Hofmann's
realizability, and reveals deep connections between quantitative realizability
and a linear variant of Cohen's forcing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4329</identifier>
 <datestamp>2012-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4329</id><created>2012-01-20</created><authors><author><keyname>Naskar</keyname><forenames>Souvik</forenames></author><author><keyname>Ghosh</keyname><forenames>Avishek</forenames></author><author><keyname>Choudhury</keyname><forenames>Pabitra Pal</forenames></author></authors><title>Application of Integral Value Transformation (IVT) in a Specialized
  Computer Network Design</title><categories>cs.DM</categories><comments>7 pages,2 figures (Presented in Indian Science Congress 2012)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Integral Value Transformation (IVT) is a family of transformations from N0kto
N0. An algebraic result has been established in p-adic IVT systems and an
application of the result is described in this paper. The result in this paper
provides the rule to find the pth pre image of a natural number for the Collatz
like bijective functions in p-adic IVT systems. Using this result a routing
algorithm is proposed. This proposed routing algorithm reduces number of
address calculation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4334</identifier>
 <datestamp>2012-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4334</id><created>2012-01-20</created><authors><author><keyname>Bouyuklieva</keyname><forenames>Stefka</forenames></author><author><keyname>Yankov</keyname><forenames>Nikolay</forenames></author><author><keyname>Kim</keyname><forenames>Jon-Lark</forenames></author></authors><title>Classification of Binary Self-Dual [48,24,10] Codes with an Automorphism
  of Odd Prime Order</title><categories>cs.IT math.CO math.IT</categories><comments>11 pages, 4 tables</comments><msc-class>94B05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The purpose of this paper is to complete the classification of binary
self-dual [48,24,10] codes with an automorphism of odd prime order. We prove
that if there is a self-dual [48, 24, 10] code with an automorphism of type
p-(c,f) with p being an odd prime, then p=3, c=16, f=0. By considering only an
automorphism of type 3-(16,0), we prove that there are exactly 264 inequivalent
self-dual [48, 24, 10] codes with an automorphism of odd prime order,
equivalently, there are exactly 264 inequivalent cubic self-dual [48, 24, 10]
codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4342</identifier>
 <datestamp>2014-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4342</id><created>2012-01-20</created><updated>2013-04-22</updated><authors><author><keyname>Buer</keyname><forenames>Tobias</forenames></author><author><keyname>Kopfer</keyname><forenames>Herbert</forenames></author></authors><title>A Pareto-metaheuristic for a bi-objective winner determination problem
  in a combinatorial reverse auction</title><categories>cs.GT cs.AI math.OC</categories><comments>Accepted for publication in Computers &amp; Operations Research,
  available online, Computers &amp; Operations Research, 2013</comments><msc-class>90B50, 90C59, 68T20 (Primary), 90B06 (Secondary)</msc-class><acm-class>I.2.8; G.1.6; G.2.3</acm-class><journal-ref>Computers &amp; Operations Research 41 (2014), 208-220</journal-ref><doi>10.1016/j.cor.2013.04.004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The bi-objective winner determination problem (2WDP-SC) of a combinatorial
procurement auction for transport contracts is characterized by a set B of
bundle bids, with each bundle bid b in B consisting of a bidding carrier c_b, a
bid price p_b, and a set tau_b transport contracts which is a subset of the set
T of tendered transport contracts. Additionally, the transport quality
q_{t,c_b} is given which is expected to be realized when a transport contract t
is executed by a carrier c_b. The task of the auctioneer is to find a set X of
winning bids (X subset B), such that each transport contract is part of at
least one winning bid, the total procurement costs are minimized, and the total
transport quality is maximized. This article presents a metaheuristic approach
for the 2WDP-SC which integrates the greedy randomized adaptive search
procedure with a two-stage candidate component selection procedure, large
neighborhood search, and self-adaptive parameter setting in order to find a
competitive set of non-dominated solutions. The heuristic outperforms all
existing approaches. For seven small benchmark instances, the heuristic is the
sole approach that finds all Pareto-optimal solutions. For 28 out of 30 large
instances, none of the existing approaches is able to compute a solution that
dominates a solution found by the proposed heuristic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4344</identifier>
 <datestamp>2012-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4344</id><created>2012-01-20</created><updated>2012-04-25</updated><authors><author><keyname>Heintz</keyname><forenames>Joos</forenames></author><author><keyname>Kuijpers</keyname><forenames>Bart</forenames></author><author><keyname>Paredes</keyname><forenames>Andres Rojas</forenames></author></authors><title>On the intrinsic complexity of elimination problems in effective
  Algebraic Geometry</title><categories>cs.CC</categories><comments>37 pages. arXiv admin note: substantial text overlap with
  arXiv:1110.3030</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The representation of polynomials by arithmetic circuits evaluating them is
an alternative data structure which allowed considerable progress in polynomial
equation solving in the last fifteen years. We present a circuit based
computation model which captures all known symbolic elimination algorithms in
effective algebraic geometry and show the intrinsically exponential complexity
character of elimination in this complexity model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4354</identifier>
 <datestamp>2012-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4354</id><created>2012-01-20</created><authors><author><keyname>&#xc1;lvarez</keyname><forenames>V&#xed;ctor</forenames></author><author><keyname>Armario</keyname><forenames>Jos&#xe9;-Andr&#xe9;s</forenames></author><author><keyname>Frau</keyname><forenames>Mar&#xed;a-Dolores</forenames></author><author><keyname>Gudiel</keyname><forenames>F&#xe9;lix</forenames></author><author><keyname>G&#xfc;emes</keyname><forenames>Mar&#xed;a-Bel&#xe9;n</forenames></author><author><keyname>Mart&#xed;n</keyname><forenames>Elena</forenames></author><author><keyname>Osuna</keyname><forenames>Amparo</forenames></author></authors><title>GA based robust blind digital watermarking</title><categories>math.CO cs.CR math.OC</categories><comments>12 pages, 91 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A genetic algorithm based robust blind digital watermarking scheme is
presented. Starting from a binary image (the original watermark), a genetic
algorithm is performed searching for a permutation of this image which is as
uncorrelated as possible to the original watermark. The output of the GA is
used as our final watermark, so that both security and robustness in the
watermarking process is improved. Now, the original cover image is partitioned
into non-overlapped square blocks (depending on the size of the watermark
image). Then a (possibly extended) Hadamard transform is applied to these
blocks, so that one bit information from the watermark image is embedded in
each block by modifying the relationship of two coefficients in the transformed
matrices. The watermarked image is finally obtained by simply performing the
inverse (extended) Hadamard transform on the modified matrices. The
experimental results show that our scheme keeps invisibility, security and
robustness more likely than other proposals in the literature, thanks to the GA
pretreatment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4357</identifier>
 <datestamp>2012-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4357</id><created>2012-01-20</created><updated>2012-07-09</updated><authors><author><keyname>Manjunath</keyname><forenames>Madhusudan</forenames></author><author><keyname>Sturmfels</keyname><forenames>Bernd</forenames></author></authors><title>Monomials, Binomials, and Riemann-Roch</title><categories>math.AC cs.DM math.CO</categories><comments>18 pages, 2 figures, Minor revisions</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Riemann-Roch theorem on a graph G is related to Alexander duality in
combinatorial commutive algebra. We study the lattice ideal given by chip
firing on G and the initial ideal whose standard monomials are the G-parking
functions. When G is a saturated graph, these ideals are generic and the Scarf
complex is a minimal free resolution. Otherwise, syzygies are obtained by
degeneration. We also develop a self-contained Riemann-Roch theory for artinian
monomial ideals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4363</identifier>
 <datestamp>2014-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4363</id><created>2012-01-20</created><updated>2013-01-02</updated><authors><author><keyname>Elder</keyname><forenames>Murray</forenames></author><author><keyname>Elston</keyname><forenames>Gillian</forenames></author><author><keyname>Ostheimer</keyname><forenames>Gretchen</forenames></author></authors><title>On groups that have normal forms computable in logspace</title><categories>math.GR cs.CC</categories><comments>24 pages, 1 figure. Minor corrections from previous version</comments><msc-class>20F65, 68Q15</msc-class><doi>10.1016/j.jalgebra.2013.01.036</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the class of finitely generated groups which have a normal form
computable in logspace. We prove that the class of such groups is closed under
finite extensions, finite index subgroups, direct products, wreath products,
and also certain free products, and includes the solvable Baumslag-Solitar
groups, as well as non-residually finite (and hence non-linear) examples. We
define a group to be logspace embeddable if it embeds in a group with normal
forms computable in logspace. We prove that finitely generated nilpotent groups
are logspace embeddable. It follows that all groups of polynomial growth are
logspace embeddable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4369</identifier>
 <datestamp>2012-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4369</id><created>2012-01-20</created><updated>2012-04-27</updated><authors><author><keyname>Allard</keyname><forenames>Antoine</forenames></author><author><keyname>H&#xe9;bert-Dufresne</keyname><forenames>Laurent</forenames></author><author><keyname>No&#xeb;l</keyname><forenames>Pierre-Andr&#xe9;</forenames></author><author><keyname>Marceau</keyname><forenames>Vincent</forenames></author><author><keyname>Dub&#xe9;</keyname><forenames>Louis J.</forenames></author></authors><title>Exact solution of bond percolation on small arbitrary graphs</title><categories>cond-mat.stat-mech cs.SI physics.soc-ph</categories><comments>5 pages and 3 figures</comments><journal-ref>Europhysics Letters 98, 16001 (2012)</journal-ref><doi>10.1209/0295-5075/98/16001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a set of iterative equations that exactly solves the size
distribution of components on small arbitrary graphs after the random removal
of edges. We also demonstrate how these equations can be used to predict the
distribution of the node partitions (i.e., the constrained distribution of the
size of each component) in undirected graphs. Besides opening the way to the
theoretical prediction of percolation on arbitrary graphs of large but finite
size, we show how our results find application in graph theory, epidemiology,
percolation and fragmentation theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4376</identifier>
 <datestamp>2013-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4376</id><created>2012-01-20</created><updated>2013-02-07</updated><authors><author><keyname>De Cristofaro</keyname><forenames>Emiliano</forenames></author><author><keyname>Soriente</keyname><forenames>Claudio</forenames></author></authors><title>Participatory Privacy: Enabling Privacy in Participatory Sensing</title><categories>cs.CR cs.NI</categories><comments>To appear in IEEE Network. Vol. 27, No. 1. January 2013. Submitted
  March 2011, Accepted January 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Participatory Sensing is an emerging computing paradigm that enables the
distributed collection of data by self-selected participants. It allows the
increasing number of mobile phone users to share local knowledge acquired by
their sensor-equipped devices, e.g., to monitor temperature, pollution level or
consumer pricing information. While research initiatives and prototypes
proliferate, their real-world impact is often bounded to comprehensive user
participation. If users have no incentive, or feel that their privacy might be
endangered, it is likely that they will not participate. In this article, we
focus on privacy protection in Participatory Sensing and introduce a suitable
privacy-enhanced infrastructure. First, we provide a set of definitions of
privacy requirements for both data producers (i.e., users providing sensed
information) and consumers (i.e., applications accessing the data). Then, we
propose an efficient solution designed for mobile phone users, which incurs
very low overhead. Finally, we discuss a number of open problems and possible
research directions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4428</identifier>
 <datestamp>2012-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4428</id><created>2012-01-20</created><authors><author><keyname>Tajima</keyname><forenames>Masato</forenames></author><author><keyname>Okino</keyname><forenames>Koji</forenames></author></authors><title>Error-Trellis Construction for Tailbiting Convolutional Codes</title><categories>cs.IT math.IT</categories><comments>5 pages, submitted to the 2012 IEEE International Symposium on
  Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present an error-trellis construction for tailbiting
convolutional codes. A tailbiting error-trellis is characterized by the
condition that the syndrome former starts and ends in the same state. We
clarify the correspondence between code subtrellises in the tailbiting
code-trellis and error subtrellises in the tailbiting error-trellis. Also, we
present a construction of tailbiting backward error-trellises. Moreover, we
obtain the scalar parity-check matrix for a tailbiting convolutional code. The
proposed construction is based on the adjoint-obvious realization of a syndrome
former and its behavior is fully used in the discussion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4442</identifier>
 <datestamp>2012-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4442</id><created>2012-01-21</created><authors><author><keyname>Bisu</keyname><forenames>Claudiu-Florinel</forenames><affiliation>MPS</affiliation></author><author><keyname>G&#xe9;rard</keyname><forenames>Alain</forenames><affiliation>I2M</affiliation></author><author><keyname>Zapciu</keyname><forenames>Miron</forenames><affiliation>MPS</affiliation></author><author><keyname>Cahuc</keyname><forenames>Olivier</forenames><affiliation>I2M</affiliation></author></authors><title>The milling process monitoring using 3D envelope method</title><categories>cs.OH</categories><proxy>ccsd</proxy><journal-ref>Journal of Advanced Materials Research 423 (2012) 77-88</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a method to vibration analysis in order to on-line
monitoring of milling process quality. Adapting envelope analysis to
characterize the milling tool materials is an important contribution to the
qualitative and quantitative characterization of milling capacity and a step by
modeling the three-dimensional cutting process. An experimental protocol was
designed and developed for the acquisition, processing and analyzing
three-dimensional signal. The vibration envelope analysis is proposed to detect
the cutting capacity of the tool with the optimization application of cutting
parameters. The research is focused on Hilbert transform optimization to
evaluate the dynamic behavior of the machine/ tool/workpiece.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4443</identifier>
 <datestamp>2012-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4443</id><created>2012-01-21</created><authors><author><keyname>Bisu</keyname><forenames>Claudiu-Florinel</forenames><affiliation>MPS</affiliation></author><author><keyname>Cherif</keyname><forenames>Medhi</forenames><affiliation>I2M</affiliation></author><author><keyname>G&#xe9;rard</keyname><forenames>Alain</forenames><affiliation>I2M</affiliation></author><author><keyname>K'Nevez</keyname><forenames>Jean-Yves</forenames><affiliation>I2M</affiliation></author></authors><title>Dynamic behavior analysis for a six axis industrial machining robot</title><categories>cs.RO</categories><proxy>ccsd</proxy><journal-ref>Journal of Advanced Materials Research 423 (2012) 65-76</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The six axis robots are widely used in automotive industry for their good
repeatability (as defined in the ISO92983) (painting, welding, mastic
deposition, handling etc.). In the aerospace industry, robot starts to be used
for complex applications such as drilling, riveting, fiber placement, NDT, etc.
Given the positioning performance of serial robots, precision applications
require usually external measurement device with complexes calibration
procedure in order to reach the precision needed. New applications in the
machining field of composite material (aerospace, naval, or wind turbine for
example) intend to use off line programming of serial robot without the use of
calibration or external measurement device. For those applications, the
position, orientation and path trajectory precision of the tool center point of
the robot are needed to generate the machining operation. This article presents
the different conditions that currently limit the development of robots in
robotic machining applications. We analyze the dynamical behavior of a robot
KUKA KR240-2 (located at the University of Bordeaux 1) equipped with a HSM
Spindle (42000 rpm, 18kW). This analysis is done in three stages. The first
step is determining the self-excited frequencies of the robot structure for
three different configurations of work. The second phase aims to analyze the
dynamical vibration of the structure as the spindle is activated without
cutting. The third stage consists of vibration analysis during a milling
operation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4445</identifier>
 <datestamp>2012-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4445</id><created>2012-01-21</created><authors><author><keyname>K'Nevez</keyname><forenames>Jean-Yves</forenames><affiliation>I2M</affiliation></author><author><keyname>Cherif</keyname><forenames>Mehdi</forenames><affiliation>I2M</affiliation></author><author><keyname>Zapciu</keyname><forenames>Miron</forenames><affiliation>MPS</affiliation></author><author><keyname>G&#xe9;rard</keyname><forenames>Alain</forenames><affiliation>I2M</affiliation></author></authors><title>Experimental Characterization of Robot Arm Rigidity in Order to Be Used
  in Machining Operation</title><categories>cs.RO</categories><proxy>ccsd</proxy><journal-ref>19 th International Conference on Manufacturing System - ICMaS
  2010, Bucarest : Romania (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Attempts to install a rotating tool at the end of a robot arm
poly-articulated date back twenty years, but these robots were not designed for
that. Indeed, two essential features are necessary for machining: high rigidity
and precision in a given workspace. The experimental results presented are the
dynamic identification of a poly-articulated robot equipped with an integrated
spindle. This study aims to highlight the influence of the geometric
configuration of the robot arm on the overall stiffness of the system. The
spindle is taken into account as an additional weight on board but also as a
dynamical excitation for the robot KUKA KR_240_2. Study of the robotic
machining vibrations shows the suitable directions of movement in milling
process
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4446</identifier>
 <datestamp>2012-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4446</id><created>2012-01-21</created><authors><author><keyname>Bisu</keyname><forenames>Claudiu-Florinel</forenames><affiliation>MPS</affiliation></author><author><keyname>Zapciu</keyname><forenames>Miron</forenames><affiliation>MPS</affiliation></author><author><keyname>G&#xe9;rard</keyname><forenames>Alain</forenames><affiliation>I2M</affiliation></author><author><keyname>Vijelea</keyname><forenames>V.</forenames><affiliation>DC</affiliation></author><author><keyname>Anica</keyname><forenames>Marin</forenames></author></authors><title>New Approach of Envelope Dynamic Analysis for Milling Process</title><categories>cs.OH</categories><proxy>ccsd</proxy><journal-ref>8 th Internationalm Conference on High Speed Machining, Metz :
  France (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a method to vibration analysis in order to on-line
monitoring of milling process quality. Adapting envelope analysis to
characterize the milling tool materials is an important contribution to the
qualitative and quantitative characterization of milling capacity and a step by
modeling the three-dimensional cutting process. An experimental protocol was
designed and developed for the acquisition, processing and analyzing
three-dimensional signal. The vibration envelope analysis is proposed to detect
the cutting capacity of the tool with the optimization application of cutting
parameters. The research is focused on FFT Fourier transform optimization of
vibration analysis and vibration envelope to evaluate the dynamic behavior of
the machine/ tool/workpiece
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4449</identifier>
 <datestamp>2012-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4449</id><created>2012-01-21</created><updated>2012-06-21</updated><authors><author><keyname>Chatterjee</keyname><forenames>Krishnendu</forenames></author><author><keyname>Chaubal</keyname><forenames>Siddhesh</forenames></author><author><keyname>Kamath</keyname><forenames>Pritish</forenames></author></authors><title>Faster Algorithms for Alternating Refinement Relations</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One central issue in the formal design and analysis of reactive systems is
the notion of refinement that asks whether all behaviors of the implementation
is allowed by the specification. The local interpretation of behavior leads to
the notion of simulation. Alternating transition systems (ATSs) provide a
general model for composite reactive systems, and the simulation relation for
ATSs is known as alternating simulation. The simulation relation for fair
transition systems is called fair simulation. In this work our main
contributions are as follows: (1) We present an improved algorithm for fair
simulation with B\&quot;uchi fairness constraints; our algorithm requires $O(n^3
\cdot m)$ time as compared to the previous known $O(n^6)$-time algorithm, where
$n$ is the number of states and $m$ is the number of transitions. (2) We
present a game based algorithm for alternating simulation that requires
$O(m^2)$-time as compared to the previous known $O((n \cdot m)^2)$-time
algorithm, where $n$ is the number of states and $m$ is the size of transition
relation. (3) We present an iterative algorithm for alternating simulation that
matches the time complexity of the game based algorithm, but is more space
efficient than the game based algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4459</identifier>
 <datestamp>2012-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4459</id><created>2012-01-21</created><authors><author><keyname>Keshavarz-Kohjerdi</keyname><forenames>Fatemeh</forenames></author><author><keyname>Bagheri</keyname><forenames>Alireza</forenames></author></authors><title>An efficient parallel algorithm for the longest path problem in meshes</title><categories>cs.DS</categories><comments>23page, 16 figures</comments><msc-class>05C45, 05C85, 05C38</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, first we give a sequential linear-time algorithm for the
longest path problem in meshes. This algorithm can be considered as an
improvement of [13]. Then based on this sequential algorithm, we present a
constant-time parallel algorithm for the problem which can be run on every
parallel machine.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4462</identifier>
 <datestamp>2012-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4462</id><created>2012-01-21</created><authors><author><keyname>Ghica</keyname><forenames>Dan R.</forenames></author><author><keyname>Tzevelekos</keyname><forenames>Nikos</forenames></author></authors><title>A System-Level Semantics</title><categories>cs.LO</categories><acm-class>F.3.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Game semantics is a trace-like denotational semantics for programming
languages where the notion of legal observable behaviour of a term is defined
combinatorially, by means of rules of a game between the term (the &quot;Proponent&quot;)
and its context (the &quot;Opponent&quot;). In general, the richer the computational
features a language has, the less constrained the rules of the semantic game.
In this paper we consider the consequences of taking this relaxation of rules
to the limit, by granting the Opponent omnipotence, that is, permission to play
any move without combinatorial restrictions. However, we impose an epistemic
restriction by not granting Opponent omniscience, so that Proponent can have
undisclosed secret moves. We introduce a basic C-like programming language and
we define such a semantic model for it. We argue that the resulting semantics
is an appealingly simple combination of operational and game semantics and we
show how certain traces explain system-level attacks, i.e. plausible attacks
that are realizable outside of the programming language itself. We also show
how allowing Proponent to have secrets ensures that some desirable equivalences
in the programming language are preserved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4468</identifier>
 <datestamp>2012-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4468</id><created>2012-01-21</created><authors><author><keyname>Matom&#xe4;ki</keyname><forenames>Kaisa</forenames></author><author><keyname>Saari</keyname><forenames>Kalle</forenames></author></authors><title>A new geometric approach to Sturmian words</title><categories>cs.DM math.CO</categories><comments>12 pages, 7 figures. A preprint of a paper to appear in Theoretical
  Computer Science</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new geometric approach to Sturmian words by means of a mapping
that associates certain lines in the n x n -grid and sets of finite Sturmian
words of length n. Using this mapping, we give new proofs of the formulas
enumerating the finite Sturmian words and the palindromic finite Sturmian words
of a given length. We also give a new proof for the well-known result that a
factor of a Sturmian word has precisely two return words.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4469</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4469</id><created>2012-01-21</created><updated>2012-09-15</updated><authors><author><keyname>Karlsson</keyname><forenames>Johan</forenames></author><author><keyname>Georgiou</keyname><forenames>Tryphon T.</forenames></author></authors><title>Uncertainty Bounds for Spectral Estimation</title><categories>cs.SY math.OC math.ST stat.TH</categories><comments>8 figures</comments><msc-class>62G07, 93E10</msc-class><acm-class>G.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The purpose of this paper is to study metrics suitable for assessing
uncertainty of power spectra when these are based on finite second-order
statistics. The family of power spectra which is consistent with a given range
of values for the estimated statistics represents the uncertainty set about the
&quot;true&quot; power spectrum. Our aim is to quantify the size of this uncertainty set
using suitable notions of distance, and in particular, to compute the diameter
of the set since this represents an upper bound on the distance between any
choice of a nominal element in the set and the &quot;true&quot; power spectrum. Since the
uncertainty set may contain power spectra with lines and discontinuities, it is
natural to quantify distances in the weak topology---the topology defined by
continuity of moments. We provide examples of such weakly-continuous metrics
and focus on particular metrics for which we can explicitly quantify spectral
uncertainty. We then consider certain high resolution techniques which utilize
filter-banks for pre-processing, and compute worst-case a priori uncertainty
bounds solely on the basis of the filter dynamics. This allows the a priori
tuning of the filter-banks for improved resolution over selected frequency
bands.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4472</identifier>
 <datestamp>2013-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4472</id><created>2012-01-21</created><updated>2012-07-24</updated><authors><author><keyname>Mkrtchyan</keyname><forenames>Vahan V.</forenames></author></authors><title>A remark on Petersen coloring conjecture of Jaeger</title><categories>cs.DM math.CO</categories><comments>6 pages, 2 figures, + the comments of the referees are taken into
  account+ Sylvester coloring conjecture is introduced+ a result related with
  this conjectures is proved</comments><journal-ref>Australasian Journal of Combinatorics 56, (2013), 145-151</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  If $G$ and $H$ are two cubic graphs, then we write $H\prec G$, if $G$ admits
a proper edge-coloring $f$ with edges of $H$, such that for each vertex $x$ of
$G$, there is a vertex $y$ of $H$ with $f(\partial_G(x))=\partial_H(y)$. Let
$P$ and $S$ be the Petersen graph and the Sylvester graph, respectively. In
this paper, we introduce the Sylvester coloring conjecture. Moreover, we show
that if $G$ is a connected bridgeless cubic graph with $G\prec P$, then $G=P$.
Finally, if $G$ is a connected cubic graph with $G\prec S$, then $G=S$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4477</identifier>
 <datestamp>2012-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4477</id><created>2012-01-21</created><updated>2012-03-14</updated><authors><author><keyname>Muralidharan</keyname><forenames>Vijayvaradharaj T.</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>Wireless Network Coding for MIMO Two-way Relaying using Latin Rectangles</title><categories>cs.IT math.IT</categories><comments>17 pages, 17 figures, 1 table; some mistakes corrected</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The design of modulation schemes for the physical layer network-coded two-way
MIMO relaying scenario is considered, with $n_R$ antennas at the relay R, $n_A$
and $n_B$ antennas respectively at the end nodes A and B. We consider the
denoise-and-forward (DNF) protocol which employs two phases: Multiple access
(MA) phase and Broadcast (BC) phase. It is known for the network-coded SISO
two-way relaying that adaptively changing the networking coding map used at the
relay, also known as the denoising map, according to the channel conditions
greatly reduces the impact of multiple access interference which occurs at the
relay during the MA phase and all these network coding maps should satisfy a
requirement called the {\it exclusive law}. The network coding maps which
satisfy exclusive law can be viewed equivalently as Latin Rectangles. In this
paper, it is shown that for MIMO two-way relaying, deep fade occurs at the
relay when the row space of the channel fade coefficient matrix is a subspace
of a finite number of vector subspaces of $\mathbb{C}^{n_A+n_B}$ which are
referred to as the singular fade subspaces. It is shown that proper choice of
network coding map can remove most of the singular fade subspaces, referred to
as the removable singular fade subspaces. For $2^{\lambda}$-PSK signal set, it
is shown that the number of non-removable singular fade subspaces is a small
fraction of the total number of singular fade subspaces. The Latin Rectangles
for the case when the end nodes use different number of antennas are shown to
be obtainable from the Latin Squares for the case when they use the same number
of antennas. Also, the network coding maps which remove all the removable
singular singular fade subspaces are shown to be obtainable from a small set of
Latin Squares.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4479</identifier>
 <datestamp>2012-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4479</id><created>2012-01-21</created><authors><author><keyname>Jafarizadeh</keyname><forenames>Saber</forenames></author><author><keyname>Jamalipour</keyname><forenames>Abbas</forenames></author></authors><title>Distributed Data Storage in Large-Scale Sensor Networks Based on LT
  Codes</title><categories>cs.IT cs.DB math.IT</categories><comments>9 pages, 4 figures, 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes an algorithm for increasing data persistency in
large-scale sensor networks. In the scenario considered here, k out of n nodes
sense the phenomenon and produced ? information packets. Due to usually
hazardous environment and limited resources, e.g. energy, sensors in the
network are vulnerable. Also due to the large size of the network, gathering
information from a few central hopes is not feasible. Flooding is not a desired
option either due to limited memory of each node. Therefore the best approach
to increase data persistency is propagating data throughout the network by
random walks. The algorithm proposed here is based on distributed LT (Luby
Transform) codes and it benefits from the low complexity of encoding and
decoding of LT codes. In previous algorithms the essential global information
(e.g., n and k) are estimated based on graph statistics, which requires
excessive transmissions. In our proposed algorithm, these values are obtained
without additional transmissions. Also the mixing time of random walk is
enhanced by proposing a new scheme for generating the probabilistic forwarding
table of random walk. The proposed method uses only local information and it is
scalable to any network topology. By simulations the improved performance of
developed algorithm compared to previous ones has been verified.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4480</identifier>
 <datestamp>2012-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4480</id><created>2012-01-21</created><authors><author><keyname>Jafarizadeh</keyname><forenames>Saber</forenames></author><author><keyname>Jamalipour</keyname><forenames>Abbas</forenames></author></authors><title>A Solution to Fastest Distributed Consensus Problem for Generic Star &amp;
  K-cored Star Networks</title><categories>cs.IT cs.DC math.IT</categories><comments>8 pages, 5 figures, 3 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distributed average consensus is the main mechanism in algorithms for
decentralized computation. In distributed average consensus algorithm each node
has an initial state, and the goal is to compute the average of these initial
states in every node. To accomplish this task, each node updates its state by a
weighted average of its own and neighbors' states, by using local communication
between neighboring nodes. In the networks with fixed topology, convergence
rate of distributed average consensus algorithm depends on the choice of
weights. This paper studies the weight optimization problem in distributed
average consensus algorithm. The network topology considered here is a star
network where the branches have different lengths. Closed-form formulas of
optimal weights and convergence rate of algorithm are determined in terms of
the network's topological parameters. Furthermore generic K-cored star topology
has been introduced as an alternative to star topology. The introduced topology
benefits from faster convergence rate compared to star topology. By simulation
better performance of optimal weights compared to other common weighting
methods has been proved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4499</identifier>
 <datestamp>2012-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4499</id><created>2012-01-21</created><authors><author><keyname>Garcia</keyname><forenames>Alvaro Juan Ojeda</forenames></author></authors><title>Mathematical and computational modeling for describing the basic
  behavior of free radicals and antioxidants within epithelial cells</title><categories>cs.CE q-bio.QM</categories><comments>4 pages, 5 figures. Treball de Recerca, gener de 2012</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The traditional methods of the biology, based on illustrative descriptions
and linear logic explanations, are discussed. This work aims to improve this
approach by introducing alternative tools to describe and represent complex
biological systems. Two models were developed, one mathematical and another
computational, both were made in order to study the biological process between
free radicals and antioxidants. Each model was used to study the same process
but in different scenarios. The mathematical model was used to study the
biological process in an epithelial cells culture; this model was validated
with the experimental data of Anne Hanneken's research group from the
Department of Molecular and Experimental Medicine, published by the journal
Investigative Ophthalmology and Visual Science in July 2006. The computational
model was used to study the same process in an individual. The model was made
using C++ programming language, supported by the network theory of aging.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4500</identifier>
 <datestamp>2012-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4500</id><created>2012-01-21</created><authors><author><keyname>Qureshi</keyname><forenames>M. Rizwan Jameel</forenames></author></authors><title>Requirements and the baseline plan</title><categories>cs.SE</categories><comments>4 pages, 1 figure, ISSN: 1013-5316, CODEN: SINTE 8; Science
  International-Lahore, Vol. 17/4, Dec. 2005</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For each software project a plan is developed, according to a documented
procedure, that covers the software activities and commitments. The
requirements allocated to software form the basis for the software development
plan. Estimates for critical computer resources are documented, reviewed, and
agreed to. All affected groups and individuals understand the estimates and
plans and commit to support them. Senior management reviews the estimates and
plans before external commitments are made. Software risks associated with the
cost, resources, schedule, and technical aspects of the project are identified
and evaluated, and contingencies are documented. Planning and estimation data
are collected for use in planning subsequent projects and for input in
management oversight review meetings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4504</identifier>
 <datestamp>2012-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4504</id><created>2012-01-21</created><updated>2012-04-02</updated><authors><author><keyname>Szudzik</keyname><forenames>Matthew P.</forenames><affiliation>Carnegie Mellon</affiliation></author></authors><title>Is Turing's Thesis the Consequence of a More General Physical Principle?</title><categories>math.LO cs.CC cs.LO math-ph math.MP</categories><comments>10 pages, 0 figures; section 1 revised, other minor changes</comments><msc-class>03A10 (Primary) 03D80, 03D78 (Secondary)</msc-class><journal-ref>Lecture Notes in Computer Science, vol. 7318, Springer, 2012, pp.
  714-722</journal-ref><doi>10.1007/978-3-642-30870-3_72</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss historical attempts to formulate a physical hypothesis from which
Turing's thesis may be derived, and also discuss some related attempts to
establish the computability of mathematical models in physics. We show that
these attempts are all related to a single, unified hypothesis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4512</identifier>
 <datestamp>2013-12-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4512</id><created>2012-01-21</created><updated>2013-12-20</updated><authors><author><keyname>Kelmans</keyname><forenames>Alexander</forenames></author><author><keyname>Rubinov</keyname><forenames>Anatoliy</forenames></author></authors><title>On Convex Polytopes in the d-dimensional Space Containing and Avoiding
  Zero</title><categories>math.CO cs.DM</categories><comments>8 pages, some typos corrected</comments><journal-ref>European Journal of Combinatorics 34 (2013) 764-769</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The goal of this paper is to establish certain inequalities between the
numbers of convex polytopes in the d-dimensional space &quot;containing&quot; and
&quot;avoiding&quot; zero provided that their vertex sets are subsets of a given finite
set of points in the space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4522</identifier>
 <datestamp>2012-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4522</id><created>2012-01-21</created><authors><author><keyname>Buyya</keyname><forenames>Rajkumar</forenames></author><author><keyname>Garg</keyname><forenames>Saurabh Kumar</forenames></author><author><keyname>Calheiros</keyname><forenames>Rodrigo N.</forenames></author></authors><title>SLA-Oriented Resource Provisioning for Cloud Computing: Challenges,
  Architecture, and Solutions</title><categories>cs.DC cs.NI</categories><comments>10 pages, 7 figures, Conference Keynote Paper: 2011 IEEE
  International Conference on Cloud and Service Computing (CSC 2011, IEEE
  Press, USA), Hong Kong, China, December 12-14, 2011</comments><acm-class>C.1.4</acm-class><journal-ref>Proceedings of the 2011 IEEE International Conference on Cloud and
  Service Computing (CSC 2011, IEEE Press, USA), Hong Kong, China, December
  12-14, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cloud computing systems promise to offer subscription-oriented,
enterprise-quality computing services to users worldwide. With the increased
demand for delivering services to a large number of users, they need to offer
differentiated services to users and meet their quality expectations. Existing
resource management systems in data centers are yet to support Service Level
Agreement (SLA)-oriented resource allocation, and thus need to be enhanced to
realize cloud computing and utility computing. In addition, no work has been
done to collectively incorporate customer-driven service management,
computational risk management, and autonomic resource management into a
market-based resource management system to target the rapidly changing
enterprise requirements of Cloud computing. This paper presents vision,
challenges, and architectural elements of SLA-oriented resource management. The
proposed architecture supports integration of marketbased provisioning policies
and virtualisation technologies for flexible allocation of resources to
applications. The performance results obtained from our working prototype
system shows the feasibility and effectiveness of SLA-based resource
provisioning in Clouds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4524</identifier>
 <datestamp>2012-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4524</id><created>2012-01-21</created><authors><author><keyname>Faber</keyname><forenames>Vance</forenames></author></authors><title>Livelock free routing schemes</title><categories>cs.NI</categories><comments>5 pages</comments><msc-class>68M10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a livelock free routing algorithm for any allowed network. Unlike
some other solutions to this problem:
  1) packets entering the network have an absolute upper bound on the time to
reach their destination; 2) under light loads, packets are delivered to their
destinations in nearly optimal time; 3) packets with desired paths far away
from congested areas will have routing times far shorter than packets wanting
to access congested areas; 4) if the network becomes congested and later
clears, the network operates just as it would have when it was initially under
a light load.
  The main ideas of this note appear in a different form in my 1994 patent
5,369,745. This note adds to those results and makes them more mathematical.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4532</identifier>
 <datestamp>2012-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4532</id><created>2012-01-22</created><updated>2012-04-30</updated><authors><author><keyname>Sen</keyname><forenames>Jaydip</forenames></author><author><keyname>Maitra</keyname><forenames>Subhamoy</forenames></author></authors><title>An Attack on Privacy Preserving Data Aggregation Protocol for Wireless
  Sensor Networks</title><categories>cs.CR cs.NI</categories><comments>The paper is withdrawn</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In-network data aggregation in Wireless Sensor Networks (WSNs) provides
efficient bandwidth utilization and energy-efficient computing.Supporting
efficient in-network data aggregation while preserving the privacy of the data
of individual sensor nodes has emerged as an important requirement in numerous
WSN applications. For privacy-preserving data aggregation in WSNs, He et al.
(INFOCOM 2007) have proposed a Cluster-based Private Data Aggregation (CPDA)
that uses a clustering protocol and a well-known key distribution scheme for
computing an additive aggregation function in a privacy-preserving manner. In
spite of the wide popularity of CPDA, it has been observed that the protocol is
not secure and it is also possible to enhance its efficiency. In this paper, we
first identify a security vulnerability in the existing CPDA scheme, wherein we
show how a malicious participant node can launch an attack on the privacy
protocol so as to get access to the private data of its neighboring sensor
nodes. Next it is shown how the existing CPDA scheme can be made more efficient
by suitable modification of the protocol. Further, suitable modifications in
the existing protocol have been proposed so as to plug the vulnerability of the
protocol.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4536</identifier>
 <datestamp>2012-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4536</id><created>2012-01-22</created><authors><author><keyname>Sen</keyname><forenames>Jaydip</forenames></author></authors><title>A Multi-Path Certification Protocol for Mobile Ad Hoc Networks</title><categories>cs.CR cs.NI</categories><comments>4 pages, 6 figures, 4 pages. In Proceedings of the 4th International
  Conference on Computers &amp; Devices for Communications (CODEC), December 14 --
  16, 2009, Kolkata, India</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A mobile ad hoc network (MANET) is a collection of autonomous nodes that
communicate with each other by forming a multi-hop radio network and
maintaining connections in a decentralized manner. Security remains a major
challenge for these networks due to their features of open medium, dynamically
changing topologies, reliance on cooperative algorithms, absence of centralized
monitoring points, and lack of clear lines of defense. Most of the routing
protocols for MANETs are thus vulnerable to various types of attacks. For
security, these protocols are highly dependent on cryptographic key exchange
operations. This paper presents a multi-path certification protocol for
efficient and reliable key exchange among the nodes in a MANET. Simulation
results have shown the effectiveness and efficiency of the protocol.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4553</identifier>
 <datestamp>2012-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4553</id><created>2012-01-22</created><authors><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author></authors><title>The Knowledge-Based Economy and the Triple Helix Model</title><categories>cs.OH physics.soc-ph</categories><comments>Annual Review of Information Science and Technology 44 (2010)
  367-417; preprint version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  1. Introduction - the metaphor of a &quot;knowledge-based economy&quot;; 2. The Triple
Helix as a model of the knowledge-based economy; 3. Knowledge as a social
coordination mechanism; 4. Neo-evolutionary dynamics in a Triple Helix of
coordination mechanism; 5. The operation of the knowledge base; 6. The
restructuring of knowledge production in a KBE; 7. The KBE and the
systems-of-innovation approach; 8. The KBE and neo-evolutionary theories of
innovation; 8.1 The construction of the evolving unit; 8.2 User-producer
relations in systems of innovation; 8.3 'Mode-2' and the production of
scientific knowledge; 8.4 A Triple Helix model of innovations; 9. Empirical
studies and simulations using the TH model; 10. The KBE and the measurement;
10.1 The communication of meaning and information; 10.2 The expectation of
social structure; 10.3 Configurations in a knowledge-based economy
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4555</identifier>
 <datestamp>2012-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4555</id><created>2012-01-22</created><authors><author><keyname>Kaur</keyname><forenames>Harleen</forenames></author><author><keyname>E.</keyname><forenames>Omid MahdiEbadati</forenames></author><author><keyname>Alm</keyname><forenames>M. Afshar</forenames></author></authors><title>Implementation of Portion Approach in Distributed Firewall Application
  for Network Security Framework</title><categories>cs.NI cs.CR</categories><comments>11 pages, 8 figurs, 4 tables, IJCSI; ISSN (Online): 1694-0814</comments><journal-ref>IJCSI International Journal of Computer Science Issues, Vol. 8,
  Issue 6, No 2, November 2011 IJCSI, International Journal of Computer Science
  Issues, Vol. 8, Issue 6, No 2, November 2011, 207-217</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The stimulate of this research seeks collaboration of firewalls which, could
reach to the capability of distributed points of security policy; the front-end
entity may much interact by the invaders so the separation between this entity
and back-end entity to make the secure domain protection is necessary;
collaborative security entity has the various task in the organization and
there is a certain security policy to apply in; the entities like DPFF have to
be protected from outsiders. Firewalls are utilized typically to be the main
layer of security in the network framework. The research is presented the
particular segment of the proposed framework that DPFF based on the developed
iptable firewall to be the layers of defense, which is protected front and
backend of the framework with a dynamic security and policy update to control
the framework's safeguard through proposed portion approach algorithm that
utilize to reduce the traffic and efficiency in detection and policy update
mechanism. The policy update mechanism for DPFF is given the way of its
employment. The complete framework signifies a distributed firewall, where the
administrator configures the policy rules set, which could be separately or
else from administration nodes' side.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4564</identifier>
 <datestamp>2012-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4564</id><created>2012-01-22</created><updated>2012-04-07</updated><authors><author><keyname>Bramoull&#xe9;</keyname><forenames>Yann</forenames></author><author><keyname>Currarini</keyname><forenames>Sergio</forenames></author><author><keyname>Jackson</keyname><forenames>Matthew O.</forenames></author><author><keyname>Pin</keyname><forenames>Paolo</forenames></author><author><keyname>Rogers</keyname><forenames>Brian W.</forenames></author></authors><title>Homophily and Long-Run Integration in Social Networks</title><categories>physics.soc-ph cs.SI</categories><comments>39 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We model network formation when heterogeneous nodes enter sequentially and
form connections through both random meetings and network-based search, but
with type-dependent biases. We show that there is &quot;long-run integration,&quot;
whereby the composition of types in sufficiently old nodes' neighborhoods
approaches the global type distribution, provided that the network-based search
is unbiased. However, younger nodes' connections still reflect the biased
meetings process. We derive the type-based degree distributions and group-level
homophily patterns when there are two types and location-based biases. Finally,
we illustrate aspects of the model with an empirical application to data on
citations in physics journals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4565</identifier>
 <datestamp>2012-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4565</id><created>2012-01-22</created><authors><author><keyname>Martins</keyname><forenames>Andr&#xe9; C. R.</forenames></author></authors><title>Discrete Opinion models as a limit case of the CODA model</title><categories>physics.soc-ph cs.MA cs.SI nlin.AO</categories><comments>10 pages, 3 figures. arXiv admin note: substantial text overlap with
  arXiv:0811.0113</comments><journal-ref>AIP Conf. Proc. 1490, 212 (2012)</journal-ref><doi>10.1063/1.4759605</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Opinion Dynamics models can be, for most of them, divided between discrete
and continuous. They are used in different circumstances and the relationship
between them is not clear. Here we will explore the relationship between a
model where choices are discrete but opinions are a continuous function (the
Continuous Opinions and Discrete Actions, CODA, model) and traditional discrete
models. I will show that, when CODA is altered to include reasoning about the
influence one agent can have on its own neighbors, agreement and disagreement
no longer have the same importance. The limit when an agent considers itself to
be more and more influential will be studied and we will see that one recovers
discrete dynamics, like those of the Voter model in that limit
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4567</identifier>
 <datestamp>2012-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4567</id><created>2012-01-22</created><updated>2012-01-27</updated><authors><author><keyname>Danner</keyname><forenames>Norman</forenames></author><author><keyname>Royer</keyname><forenames>James S.</forenames></author></authors><title>Ramified Structural Recursion and Corecursion</title><categories>cs.LO cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate feasible computation over a fairly general notion of data and
codata. Specifically, we present a direct Bellantoni-Cook-style normal/safe
typed programming formalism, RS1, that expresses feasible structural recursions
and corecursions over data and codata specified by polynomial functors. (Lists,
streams, finite trees, infinite trees, etc. are all directly definable.) A
novel aspect of RS1 is that it embraces structure-sharing as in standard
functional-programming implementations. As our data representations use
sharing, our implementation of structural recursions are memoized to avoid the
possibly exponentially-many repeated subcomputations a naive implementation
might perform. We introduce notions of size for representations of data
(accounting for sharing) and codata (using ideas from type-2 computational
complexity) and establish that type-level 1 RS1-functions have
polynomial-bounded runtimes and satisfy a polynomial-time completeness
condition. Also, restricting RS1 terms to particular types produces
characterizations of some standard complexity classes (e.g., omega-regular
languages, linear-space functions) and some less-standard classes (e.g.,
log-space streams).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4574</identifier>
 <datestamp>2012-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4574</id><created>2012-01-22</created><updated>2012-02-06</updated><authors><author><keyname>Kembellec</keyname><forenames>G&#xe9;rald</forenames></author></authors><title>Technologie et pratiques bibliographiques associ\'ees \`a l'\'ecriture
  scientifique en milieu universitaire</title><categories>cs.DL</categories><comments>25 pages</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Observe and understand users of the Scientific and Technical Information, is
preparing to offer them appropriate services. This exploratory study provides
answers about the uses in the humanities, social sciences as well as technical
sciences. We also observe those who assist teachers in their scientific
research: librarians. Then we outline considerations and recommendations to
specify functionalities of an efficient e-Linrary.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4597</identifier>
 <datestamp>2012-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4597</id><created>2012-01-22</created><authors><author><keyname>Florindo</keyname><forenames>Jo&#xe3;o Batista</forenames></author><author><keyname>Bruno</keyname><forenames>Odemir Martinez</forenames></author></authors><title>Fractal Descriptors Based on Fourier Spectrum Applied to Texture
  Analysis</title><categories>physics.data-an cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work proposes the development and study of a novel technique for the
generation of fractal descriptors used in texture analysis. The novel
descriptors are obtained from a multiscale transform applied to the Fourier
technique of fractal dimension calculus. The power spectrum of the Fourier
transform of the image is plotted against the frequency in a log- log scale and
a multiscale transform is applied to this curve. The obtained values are taken
as the fractal descriptors of the image. The validation of the propose is
performed by the use of the descriptors for the classification of a dataset of
texture images whose real classes are previously known. The classification
precision is compared to other fractal descriptors known in the literature. The
results confirm the efficiency of the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4602</identifier>
 <datestamp>2015-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4602</id><created>2012-01-22</created><updated>2012-09-03</updated><authors><author><keyname>Allard</keyname><forenames>Antoine</forenames></author><author><keyname>H&#xe9;bert-Dufresne</keyname><forenames>Laurent</forenames></author><author><keyname>No&#xeb;l</keyname><forenames>Pierre-Andr&#xe9;</forenames></author><author><keyname>Marceau</keyname><forenames>Vincent</forenames></author><author><keyname>Dub&#xe9;</keyname><forenames>Louis J.</forenames></author></authors><title>Bond percolation on a class of correlated and clustered random graphs</title><categories>cond-mat.stat-mech cs.SI physics.soc-ph q-bio.PE</categories><comments>16 pages and 4 figures</comments><doi>10.1088/1751-8113/45/40/405005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a formalism for computing bond percolation properties of a class
of correlated and clustered random graphs. This class of graphs is a
generalization of the Configuration Model where nodes of different types are
connected via different types of hyperedges, edges that can link more than 2
nodes. We argue that the multitype approach coupled with the use of clustered
hyperedges can reproduce a wide spectrum of complex patterns, and thus enhances
our capability to model real complex networks. As an illustration of this
claim, we use our formalism to highlight unusual behaviors of the size and
composition of the components (small and giant) in a synthetic, albeit
realistic, social network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4603</identifier>
 <datestamp>2012-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4603</id><created>2012-01-22</created><updated>2012-10-02</updated><authors><author><keyname>Frieze</keyname><forenames>Alan</forenames></author><author><keyname>Tsourakakis</keyname><forenames>Charalampos E.</forenames></author></authors><title>Rainbow Connectivity of Sparse Random Graphs</title><categories>math.CO cs.DM cs.DS</categories><comments>17 pages, 4 figures Accepted at APPROX-RANDOM'12</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An edge colored graph $G$ is rainbow edge connected if any two vertices are
connected by a path whose edges have distinct colors. The rainbow connectivity
of a connected graph $G$, denoted by $rc(G)$, is the smallest number of colors
that are needed in order to make $G$ rainbow connected.
  In this work we study the rainbow connectivity of binomial random graphs at
the connectivity threshold $p=\frac{\log n+\om}{n}$ where $\om=\om(n)\to\infty$
and ${\om}=o(\log{n})$ and of random $r$-regular graphs where $r \geq 3$ is a
fixed integer. Specifically, we prove that the rainbow connectivity $rc(G)$ of
$G=G(n,p)$ satisfies $rc(G) \sim \max\set{Z_1,diameter(G)}$ with high
probability (\whp). Here $Z_1$ is the number of vertices in $G$ whose degree
equals 1 and the diameter of $G$ is asymptotically equal to $\diam$ \whp.
Finally, we prove that the rainbow connectivity $rc(G)$ of the random
$r$-regular graph $G=G(n,r)$ satisfies $rc(G) =O(\log^2{n})$ \whp.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4615</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4615</id><created>2012-01-22</created><updated>2013-03-13</updated><authors><author><keyname>Lai</keyname><forenames>Ming-Jun</forenames></author><author><keyname>Yin</keyname><forenames>Wotao</forenames></author></authors><title>Augmented L1 and Nuclear-Norm Models with a Globally Linearly Convergent
  Algorithm</title><categories>cs.IT math.IT math.OC</categories><comments>arXiv admin note: text overlap with arXiv:1207.5326 by other authors</comments><journal-ref>SIAM Journal on Imaging Sciences 6(2), 1059-1091, 2013</journal-ref><doi>10.1137/120863290</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the long-existing idea of adding a nice smooth function to
&quot;smooth&quot; a non-differentiable objective function in the context of sparse
optimization, in particular, the minimization of
$||x||_1+1/(2\alpha)||x||_2^2$, where $x$ is a vector, as well as the
minimization of $||X||_*+1/(2\alpha)||X||_F^2$, where $X$ is a matrix and
$||X||_*$ and $||X||_F$ are the nuclear and Frobenius norms of $X$,
respectively. We show that they can efficiently recover sparse vectors and
low-rank matrices. In particular, they enjoy exact and stable recovery
guarantees similar to those known for minimizing $||x||_1$ and $||X||_*$ under
the conditions on the sensing operator such as its null-space property,
restricted isometry property, spherical section property, or RIPless property.
To recover a (nearly) sparse vector $x^0$, minimizing
$||x||_1+1/(2\alpha)||x||_2^2$ returns (nearly) the same solution as minimizing
$||x||_1$ almost whenever $\alpha\ge 10||x^0||_\infty$. The same relation also
holds between minimizing $||X||_*+1/(2\alpha)||X||_F^2$ and minimizing
$||X||_*$ for recovering a (nearly) low-rank matrix $X^0$, if $\alpha\ge
10||X^0||_2$. Furthermore, we show that the linearized Bregman algorithm for
minimizing $||x||_1+1/(2\alpha)||x||_2^2$ subject to $Ax=b$ enjoys global
linear convergence as long as a nonzero solution exists, and we give an
explicit rate of convergence. The convergence property does not require a
solution solution or any properties on $A$. To our knowledge, this is the best
known global convergence result for first-order sparse optimization algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4618</identifier>
 <datestamp>2012-10-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4618</id><created>2012-01-22</created><authors><author><keyname>Tsourakakis</keyname><forenames>Charalampos E.</forenames></author></authors><title>Perfect Reconstruction of Oncogenetic Trees</title><categories>q-bio.QM cs.DM math.CO q-bio.PE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this note we provide the necessary and sufficient conditions to uniquely
reconstruct an oncogenetic tree.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4638</identifier>
 <datestamp>2012-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4638</id><created>2012-01-23</created><updated>2012-02-04</updated><authors><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author></authors><title>Alternatives to the Journal Impact Factor: I3 and the Top-10% (or
  Top-25%?) of the Most-Highly Cited Papers</title><categories>cs.DL</categories><comments>Scientometrics, in press</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Journal Impact Factors (IFs) can be considered historically as the first
attempt to normalize citation distributions by using averages over two years.
However, it has been recognized that citation distributions vary among fields
of science and that one needs to normalize for this. Furthermore, the mean-or
any central-tendency statistics-is not a good representation of the citation
distribution because these distributions are skewed. Important steps have been
taken to solve these two problems during the last few years. First, one can
normalize at the article level using the citing audience as the reference set.
Second, one can use non-parametric statistics for testing the significance of
differences among ratings. A proportion of most-highly cited papers (the
top-10% or top-quartile) on the basis of fractional counting of the citations
may provide an alternative to the current IF. This indicator is intuitively
simple, allows for statistical testing, and accords with the state of the art.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4639</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4639</id><created>2012-01-23</created><updated>2012-07-18</updated><authors><author><keyname>Guerrero-Bote</keyname><forenames>Vicente P.</forenames></author><author><keyname>Moya-Anegon</keyname><forenames>Felix</forenames></author></authors><title>A further step forward in measuring journals' scientific prestige: The
  SJR2 indicator</title><categories>cs.DL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new size-independent indicator of scientific journal prestige, the SJR2
indicator, is proposed. This indicator takes into account not only the prestige
of the citing scientific journal but also its closeness to the cited journal
using the cosine of the angle between the vectors of the two journals'
cocitation profiles. To eliminate the size effect, the accumulated prestige is
divided by the fraction of the journal's citable documents, thus eliminating
the decreasing tendency of this type of indicator and giving meaning to the
scores. Its method of computation is described, and the results of its
implementation on the Scopus 2008 dataset is compared with those of an ad hoc
Journal Impact Factor, JIF(3y), and SNIP, the comparison being made both
overall and within specific scientific areas. All three, the SJR2 indicator,
the SNIP indicator and the JIF distributions, were found to fit well to a
logarithmic law. Although the three metrics were strongly correlated, there
were major changes in rank. In addition, the SJR2 was distributed more
equalized than the JIF by Subject Area and almost as equalized as the SNIP, and
better than both at the lower level of Specific Subject Areas. The
incorporation of the cosine increased the values of the flows of prestige
between thematically close journals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4642</identifier>
 <datestamp>2012-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4642</id><created>2012-01-23</created><authors><author><keyname>Perry</keyname><forenames>Nicolas</forenames><affiliation>LGM2B</affiliation></author><author><keyname>Candlot</keyname><forenames>Alexandre</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Corne</keyname><forenames>Schutte</forenames><affiliation>GCC</affiliation></author></authors><title>Collaborative knowledge networks emergence for innovation: Factors of
  success analysis and comparison</title><categories>cs.CY</categories><proxy>ccsd</proxy><journal-ref>Journal of Decision Systems 19, 1 (2010) 75-91</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  New product development needs new engineering approaches. Knowledge is a key
resource that impacts traditional, organisational, economic and innovative
models. Through NICT (New Information and Communication Technologies),
globalisation encourages the emergence of networks that overcome traditional
organisation boundaries. International enterprises, European-Community Networks
of Excellence or Clusters (competitiveness poles) indicate the need to define a
new way of thinking. This new way moves towards an agile, continuous innovative
use of knowledge. Based on an epistemic study of knowledge management best
practices, four examples show the barriers that can be encountered today. This
paper aims defining the key elements that enhance collaborative networks. The
analysis of best practices from collaborative environments enables the design
of high standard information systems and initiate knowledge ecosystems. A
balance between formalism required to share knowledge and fuzziness of social
networks triggers new initiatives. This ensures the validity of information
exchange through virtual collaboration. It helps to maintain group coherence
despite exceeding the natural maximum number of collaborators. Finally the main
success or failure factors are highlights and commented to ease the transition
from economic-driven to expertise-driven models is then facilitated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4650</identifier>
 <datestamp>2014-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4650</id><created>2012-01-23</created><authors><author><keyname>Antonopoulos</keyname><forenames>Angelos</forenames></author><author><keyname>Verikoukis</keyname><forenames>Christos</forenames></author></authors><title>Network Coding-Based Cooperative ARQ Scheme</title><categories>cs.NI</categories><comments>5 pages, Conference</comments><journal-ref>IEEE International Conference on Communications (ICC 2011),
  pp.1-5, 5-9 June 2011, Kyoto, Japan</journal-ref><doi>10.1109/icc.2011.5963256</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we introduce a novel Automatic Repeat reQuest (ARQ) scheme for
cooperative wireless networks. Our scheme adopts network coding techniques in
order to enhance the total bandwidth of the network by minimizing the total
number of transmissions. The performance of the proposed approach is evaluated
by means of computer simulations and compared to other cooperative schemes,
while an analytical solution is provided to validate the results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4655</identifier>
 <datestamp>2012-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4655</id><created>2012-01-23</created><authors><author><keyname>Sowmiyanarayanan</keyname><forenames>Sridhar</forenames></author></authors><title>Reengineering multi tiered enterprise business applications for
  performance enhancement and reciprocal or rectangular hyperbolic relation of
  variation of data transportation time with row pre-fetch size of relational
  database drivers</title><categories>cs.PF cs.SE</categories><comments>i) A general approach for Re engineering a N tier Java EE
  applications for performance improvements, A Case study of performance
  enhancement iii) Elaborates on rectangular hyperbolic relationship between
  total elapsed time to transport a set of records from database server to
  application server vs the pre fetch size configurable for database drivers;
  http://www.IJCSI.org ISSN (Online): 1694-0814</comments><journal-ref>IJCSI International Journal of Computer Science Issues, Vol. 8,
  Issue 6, No 3, November 2011, 393-412</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reengineering multi tiered enterprise business applications for performance
enhancement and reciprocal or rectangular hyperbolic relation of variation of
data transportation time with row pre-fetch size of relational database drivers
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4672</identifier>
 <datestamp>2015-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4672</id><created>2012-01-23</created><authors><author><keyname>Yao</keyname><forenames>Jianfeng</forenames><affiliation>LTCI</affiliation></author><author><keyname>Kammoun</keyname><forenames>Abla</forenames><affiliation>LTCI</affiliation></author><author><keyname>Najim</keyname><forenames>Jamal</forenames><affiliation>LTCI</affiliation></author></authors><title>Estimation of the Covariance Matrix of Large Dimensional Data</title><categories>cs.IT math.IT</categories><proxy>ccsd</proxy><doi>10.1109/TSP.2012.2212016</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with the problem of estimating the covariance matrix of a
series of independent multivariate observations, in the case where the
dimension of each observation is of the same order as the number of
observations. Although such a regime is of interest for many current
statistical signal processing and wireless communication issues, traditional
methods fail to produce consistent estimators and only recently results relying
on large random matrix theory have been unveiled. In this paper, we develop the
parametric framework proposed by Mestre, and consider a model where the
covariance matrix to be estimated has a (known) finite number of eigenvalues,
each of it with an unknown multiplicity. The main contributions of this work
are essentially threefold with respect to existing results, and in particular
to Mestre's work: To relax the (restrictive) separability assumption, to
provide joint consistent estimates for the eigenvalues and their
multiplicities, and to study the variance error by means of a Central Limit
theorem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4714</identifier>
 <datestamp>2012-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4714</id><created>2012-01-23</created><authors><author><keyname>Do</keyname><forenames>Huyen</forenames></author><author><keyname>Kalousis</keyname><forenames>Alexandros</forenames></author><author><keyname>Wang</keyname><forenames>Jun</forenames></author><author><keyname>Woznica</keyname><forenames>Adam</forenames></author></authors><title>A metric learning perspective of SVM: on the relation of SVM and LMNN</title><categories>cs.LG stat.ML</categories><comments>To appear in AISTATS 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Support Vector Machines, SVMs, and the Large Margin Nearest Neighbor
algorithm, LMNN, are two very popular learning algorithms with quite different
learning biases. In this paper we bring them into a unified view and show that
they have a much stronger relation than what is commonly thought. We analyze
SVMs from a metric learning perspective and cast them as a metric learning
problem, a view which helps us uncover the relations of the two algorithms. We
show that LMNN can be seen as learning a set of local SVM-like models in a
quadratic space. Along the way and inspired by the metric-based interpretation
of SVM s we derive a novel variant of SVMs, epsilon-SVM, to which LMNN is even
more similar. We give a unified view of LMNN and the different SVM variants.
Finally we provide some preliminary experiments on a number of benchmark
datasets in which show that epsilon-SVM compares favorably both with respect to
LMNN and SVM.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4715</identifier>
 <datestamp>2013-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4715</id><created>2012-01-23</created><updated>2013-09-17</updated><authors><author><keyname>Slab&#xfd;</keyname><forenames>Ji&#x159;&#xed;</forenames></author><author><keyname>Strej&#x10d;ek</keyname><forenames>Jan</forenames></author><author><keyname>Trt&#xed;k</keyname><forenames>Marek</forenames></author></authors><title>Compact Symbolic Execution</title><categories>cs.PL</categories><comments>This is a full version of the paper accepted to ATVA 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a generalisation of King's symbolic execution technique called
compact symbolic execution. It proceeds in two steps. First, we analyse cyclic
paths in the control flow graph of a given program, independently from the rest
of the program. Our goal is to compute a so called template for each such a
cyclic path. A template is a declarative parametric description of all possible
program states, which may leave the analysed cyclic path after any number of
iterations along it. In the second step, we execute the program symbolically
with the templates in hand. The result is a compact symbolic execution tree. A
compact tree always carry the same information in all its leaves as the
corresponding classic symbolic execution tree. Nevertheless, a compact tree is
typically substantially smaller than the corresponding classic tree. There are
even programs for which compact symbolic execution trees are finite while
classic symbolic execution trees are infinite.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4719</identifier>
 <datestamp>2012-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4719</id><created>2012-01-23</created><authors><author><keyname>Slab&#xfd;</keyname><forenames>Ji&#x159;&#xed;</forenames></author><author><keyname>Strej&#x10d;ek</keyname><forenames>Jan</forenames></author><author><keyname>Trt&#xed;k</keyname><forenames>Marek</forenames></author></authors><title>On Synergy of Metal, Slicing, and Symbolic Execution</title><categories>cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a novel technique for finding real errors in programs. The
technique is based on a synergy of three well-known methods: metacompilation,
slicing, and symbolic execution. More precisely, we instrument a given program
with a code that tracks runs of state machines representing various kinds of
errors. Next we slice the program to reduce its size without affecting runs of
state machines. And then we symbolically execute the sliced program. Depending
on the kind of symbolic execution, the technique can be applied as a
stand-alone bug finding technique, or to weed out some false positives from an
output of another bug-finding tool. We provide several examples demonstrating
the practical applicability of our technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4725</identifier>
 <datestamp>2012-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4725</id><created>2012-01-23</created><authors><author><keyname>Wagner</keyname><forenames>Urs</forenames></author></authors><title>Solving the LPN problem in cube-root time</title><categories>cs.CR</categories><msc-class>94A60</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper it is shown that given a sufficient number of (noisy) random
binary linear equations, the Learning from Parity with Noise (LPN) problem can
be solved in essentially cube root time in the number of unknowns. The
techniques used to recover the solution are known from fast correlation attacks
on stream ciphers. As in fast correlation attacks, the performance of the
algorithm depends on the number of equations given. It is shown that if this
number exceeds a certain bound, and the bias of the noisy equations is
polynomial in number of unknowns, the running time of the algorithm is reduced
to almost cube root time compared to the brute force checking of all possible
solutions. The mentioned bound is explicitly given and it is further shown that
when this bound is exceeded, the complexity of the approach can even be further
reduced.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4733</identifier>
 <datestamp>2012-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4733</id><created>2012-01-20</created><authors><author><keyname>Zock</keyname><forenames>Michael</forenames><affiliation>LIF</affiliation></author><author><keyname>Lapalme</keyname><forenames>Guy</forenames><affiliation>DIRO</affiliation></author></authors><title>Du TAL au TIL</title><categories>cs.CL cs.HC</categories><comments>TALN, Montr\'eal : Canada (2010)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Historically two types of NLP have been investigated: fully automated
processing of language by machines (NLP) and autonomous processing of natural
language by people, i.e. the human brain (psycholinguistics). We believe that
there is room and need for another kind, INLP: interactive natural language
processing. This intermediate approach starts from peoples' needs, trying to
bridge the gap between their actual knowledge and a given goal. Given the fact
that peoples' knowledge is variable and often incomplete, the aim is to build
bridges linking a given knowledge state to a given goal. We present some
examples, trying to show that this goal is worth pursuing, achievable and at a
reasonable cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4737</identifier>
 <datestamp>2012-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4737</id><created>2012-01-20</created><authors><author><keyname>Bull</keyname><forenames>Larry</forenames></author></authors><title>Production System Rules as Protein Complexes from Genetic Regulatory
  Networks</title><categories>cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This short paper introduces a new way by which to design production system
rules. An indirect encoding scheme is presented which views such rules as
protein complexes produced by the temporal behaviour of an artificial genetic
regulatory network. This initial study begins by using a simple Boolean
regulatory network to produce traditional ternary-encoded rules before moving
to a fuzzy variant to produce real-valued rules. Competitive performance is
shown with related genetic regulatory networks and rule-based systems on
benchmark problems.
</abstract></arXiv>
</metadata>
</record>
<resumptionToken cursor="27000" completeListSize="102538">1122234|28001</resumptionToken>
</ListRecords>
</OAI-PMH>
