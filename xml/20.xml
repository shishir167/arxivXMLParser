<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2016-03-09T00:48:38Z</responseDate>
<request verb="ListRecords" resumptionToken="1122234|19001">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1122</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1122</id><created>2011-02-05</created><updated>2011-02-28</updated><authors><author><keyname>Ghasemiesfeh</keyname><forenames>Golnaz</forenames></author><author><keyname>Daneshgar</keyname><forenames>Amir</forenames></author></authors><title>New Definition for Fuzzy Constraint Satisfaction Problem and its
  Applications</title><categories>cs.CC cs.DM math.CT</categories><comments>This article has been withdrawn</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article has been withdrawn.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1123</identifier>
 <datestamp>2011-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1123</id><created>2011-02-05</created><updated>2011-03-02</updated><authors><author><keyname>Ghasemiesfeh</keyname><forenames>Golnaz</forenames></author></authors><title>Algorithms for Silver Coloring of Generalized Petersen Graphs</title><categories>math.CO cs.DM cs.DS</categories><comments>This paper has been withdrawn</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1124</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1124</id><created>2011-02-05</created><updated>2011-02-28</updated><authors><author><keyname>Ghasemiesfeh</keyname><forenames>Golnaz</forenames></author><author><keyname>Mirzaei</keyname><forenames>Hanieh</forenames></author><author><keyname>Tabesh</keyname><forenames>Yahya</forenames></author></authors><title>A Polynomial Time Algorithm for a Special Case of Linear Integer
  Programming</title><categories>cs.DS</categories><comments>This article has been withdrawn</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article has been withdrawn.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1138</identifier>
 <datestamp>2011-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1138</id><created>2011-02-06</created><updated>2011-02-09</updated><authors><author><keyname>Levit</keyname><forenames>Vadim E.</forenames></author><author><keyname>Mandrescu</keyname><forenames>Eugen</forenames></author></authors><title>Critical Sets in Bipartite Graphs</title><categories>cs.DM math.CO</categories><comments>13 pages, 8 figures</comments><msc-class>05C69, 05C70 (Primary) 05A20(Secondary)</msc-class><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let G=(V,E) be a graph. A set S is independent if no two vertices from S are
adjacent, alpha(G) is the size of a maximum independent set, and core(G) is the
intersection of all maximum independent sets. The number d(X)=|X|-|N(X)| is the
difference of the set X, and d_{c}(G)=max{d(I):I is an independent set} is
called the critical difference of G. A set X is critical if d(X)=d_{c}(G). For
a graph G we define ker(G) as the intersection of all critical independent
sets, while diadem(G) is the union of all critical independent sets. For a
bipartite graph G=(A,B,E), with bipartition {A,B}, Ore defined delta(X)=d(X)
for every subset X of A, while delta_0(A)=max{delta(X):X is a subset of A}.
Similarly is defined delta_0(B). In this paper we prove that for every
bipartite graph G=(A,B,E) the following assertions hold:
d_{c}(G)=delta_0(A)+delta_0(B); ker(G)=core(G);
|ker(G)|+|diadem(G)|=2*alpha(G).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1139</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1139</id><created>2011-02-06</created><authors><author><keyname>Esik</keyname><forenames>Zoltan</forenames></author></authors><title>Residuated Park Theories</title><categories>cs.LO math.LO</categories><msc-class>68Q55, 68Q70</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When $L$ is a complete lattice, the collection $\Mon_L$ of all monotone
functions $L^p \to L^n$, $n,p \geq 0$, forms a Lawvere theory. We enrich this
Lawvere theory with the binary supremum operation $\vee$, an operation of
(left) residuation $\res$ and the parameterized least fixed point operation
$^\dagger$. We exhibit a system of \emph{equational} axioms which is sound and
proves all valid equations of the theories $\Mon_L$ involving only the theory
operations, $\vee$ and $^\dagger$, i.e., all valid equations not involving
residuation. We also present an alternative axiomatization, where $^\dagger$ is
replaced by a star operation, and provide an application to regular tree
languages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1140</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1140</id><created>2011-02-06</created><updated>2012-09-03</updated><authors><author><keyname>Doerr</keyname><forenames>Benjamin</forenames></author><author><keyname>Winzen</keyname><forenames>Carola</forenames></author></authors><title>Ranking-Based Black-Box Complexity</title><categories>cs.NE cs.CC cs.DS</categories><comments>This is an extended version of our CSR 2011 paper. 31 pages. The
  journal version is to appear in Algorithmica, DOI: 10.1007/s00453-012-9684-9</comments><doi>10.1007/s00453-012-9684-9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Randomized search heuristics such as evolutionary algorithms, simulated
annealing, and ant colony optimization are a broadly used class of
general-purpose algorithms. Analyzing them via classical methods of theoretical
computer science is a growing field. While several strong runtime analysis
results have appeared in the last 20 years, a powerful complexity theory for
such algorithms is yet to be developed. We enrich the existing notions of
black-box complexity by the additional restriction that not the actual
objective values, but only the relative quality of the previously evaluated
solutions may be taken into account by the black-box algorithm. Many randomized
search heuristics belong to this class of algorithms.
  We show that the new ranking-based model gives more realistic complexity
estimates for some problems. For example, the class of all binary-value
functions has a black-box complexity of $O(\log n)$ in the previous black-box
models, but has a ranking-based complexity of $\Theta(n)$.
  For the class of all OneMax functions, we present a ranking-based black-box
algorithm that has a runtime of $\Theta(n / \log n)$, which shows that the
OneMax problem does not become harder with the additional ranking-basedness
restriction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1141</identifier>
 <datestamp>2011-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1141</id><created>2011-02-06</created><authors><author><keyname>Levit</keyname><forenames>Vadim E.</forenames></author><author><keyname>Mandrescu</keyname><forenames>Eugen</forenames></author></authors><title>An Algorithm Computing the Core of a Konig-Egervary Graph</title><categories>cs.DM math.CO</categories><comments>8 pages, 5 figures</comments><msc-class>05C69 (Primary) 05C70(Secondary)</msc-class><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A set S of vertices is independent in a graph G if no two vertices from S are
adjacent, and alpha(G) is the cardinality of a maximum independent set of G.
  G is called a Konig-Egervary graph if its order equals alpha(G)+mu(G), where
mu(G) denotes the size of a maximum matching. By core(G) we mean the
intersection of all maximum independent sets of G.
  To decide whether core(G) is empty is known to be NP-hard.
  In this paper, we present some polynomial time algorithms finding core(G) of
a Konig-Egervary graph G.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1142</identifier>
 <datestamp>2011-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1142</id><created>2011-02-06</created><authors><author><keyname>Levit</keyname><forenames>Vadim E.</forenames></author><author><keyname>Mandrescu</keyname><forenames>Eugen</forenames></author></authors><title>Local Maximum Stable Sets Greedoids Stemmed from Very Well-Covered
  Graphs</title><categories>cs.DM math.CO</categories><comments>12 pages, 12 figures</comments><msc-class>05C69, 05B35 (Primary), 51D10, 05C70 (Secondary)</msc-class><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A maximum stable set in a graph G is a stable set of maximum cardinality. S
is called a local maximum stable set of G if S is a maximum stable set of the
subgraph induced by the closed neighborhood of S. A greedoid (V,F) is called a
local maximum stable set greedoid if there exists a graph G=(V,E) such that its
family of local maximum stable sets coinsides with (V,F). It has been shown
that the family local maximum stable sets of a forest T forms a greedoid on its
vertex set. In this paper we demonstrate that if G is a very well-covered
graph, then its family of local maximum stable sets is a greedoid if and only
if G has a unique perfect matching.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1152</identifier>
 <datestamp>2011-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1152</id><created>2011-02-06</created><authors><author><keyname>Ni</keyname><forenames>Hongbo</forenames></author><author><keyname>Abdulrazak</keyname><forenames>Bessam</forenames></author><author><keyname>Zhang</keyname><forenames>Daqing</forenames></author><author><keyname>Wu</keyname><forenames>Shu</forenames></author></authors><title>CDTOM: A Context-driven Task-oriented Middleware for Pervasive Homecare
  Environment</title><categories>cs.HC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the growing number of the elderly, we see a greater demand for home
care, and the vision of pervasive computing is also floating into the domain of
the household that aims to build a smart home which can assist inhabitants
(users) to live more conveniently and harmoniously. Such health-care pervasive
applications in smart home should focus on the inhabitant's goal or task in
diverse situations, rather than the various complex devices and services. The
core challenge for homecare design is to perceive the environment and assess
occurring situations, thus allowing systems to behave intelligently according
to the user's intent. Due to the dynamic and heterogeneous nature of pervasive
computing environment, it is difficult for an average user to obtain right
information and service and in right place at right time. This paper proposes a
context-driven task-oriented middleware (CDTOM) to meet the challenge. The most
important component is its task model that provides an adequate high-level
description of user-oriented tasks and their related contexts. Leveraging the
model multiple entities can easily exchange, share and reuse their knowledge.
Based on the hierarchy of task ontology, a novel task recognition approach
using CBR (case-based reasoning) is presented and the performance of task
recognition is evaluated by task number, context size and time costing.
Moreover, a dynamic mechanism for mapping the recognized task and services is
also discussed. Finally, we present the design and implementation of our task
supporting system (TSS) to aid an inhabitant's tasks in light of his lifestyle
and environment conditions in pervasive homecare environment, and the results
of the prototype system show that our middleware approach achieves good
efficiency of context management and good accuracy of user's activity
inference, and can improve efficiently quality of user's life.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1161</identifier>
 <datestamp>2011-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1161</id><created>2011-02-06</created><authors><author><keyname>Magniez</keyname><forenames>Frederic</forenames></author><author><keyname>de Rougemont</keyname><forenames>Michel</forenames></author><author><keyname>Santha</keyname><forenames>Miklos</forenames></author><author><keyname>Zeitoun</keyname><forenames>Xavier</forenames></author></authors><title>The complexity of approximate Nash equilibrium in congestion games with
  negative delays</title><categories>cs.GT cs.CC cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We extend the study of the complexity of finding an $\eps$-approximate Nash
equilibrium in congestion games from the case of positive delay functions to
delays of arbitrary sign. We first prove that in symmetric games with
$\alpha$-bounded jump the $\eps$-Nash dynamic converges in polynomial time when
all delay functions are negative, similarly to the case of positive delays. We
then establish a hardness result for symmetric games with $\alpha$-bounded jump
and with arbitrary delay functions: in that case finding an $\eps$-Nash
equilibrium becomes $\PLS$-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1165</identifier>
 <datestamp>2011-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1165</id><created>2011-02-06</created><authors><author><keyname>Zamanighomi</keyname><forenames>Mahdi</forenames></author><author><keyname>Emadi</keyname><forenames>Mohammad Javad</forenames></author><author><keyname>Chaharsooghi</keyname><forenames>Farhad Shirani</forenames></author><author><keyname>Aref</keyname><forenames>Mohammad Reza</forenames></author></authors><title>Achievable Rate Region for Multiple Access Channel with Correlated
  Channel States and Cooperating Encoders</title><categories>cs.IT math.IT</categories><comments>7 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a two-user discrete memoryless multiple-access channel
(DM-MAC) with correlated channel states, each known at one of the encoders is
considered, in which each encoder transmits independent messages and tries to
cooperate with the other one. To consider cooperating encoders, it is assumed
that each encoder strictly-causally receives and learns the other encoder's
transmitted symbols and tries to cooperate with the other encoder by
transmitting its message. Next, we study this channel in a special case; we
assume that the common part of both states is known at both, hence encoders use
this opportunity to get better rate region. For these scenarios, an achievable
rate region is derived based on a combination of block-Markov encoding and
Gel'fand-Pinsker coding techniques. Furthermore, the achievable rate region is
established for the Gaussian channel, and it is shown that the capacity region
is achieved in certain circumstances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1167</identifier>
 <datestamp>2012-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1167</id><created>2011-02-06</created><authors><author><keyname>Barabesi</keyname><forenames>Alberto Baccini And Lucio</forenames></author></authors><title>Seats at the table: the network of the editorial boards in information
  and library science</title><categories>cs.DL cs.SI physics.soc-ph</categories><comments>12 pages, 3 figures, 3 tables Accepted for publication. Journal of
  Informetrics</comments><journal-ref>Journal of Informetrics 5 2011 382-391</journal-ref><doi>10.1016/j.joi.2011.01.012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The structural properties of the network generated by the editorial
activities of the members of the boards of &quot;Information Science &amp; Library
Science&quot; journals are explored through network analysis techniques. The crossed
presence of scholars on editorial boards, the phenomenon called interlocking
editorship, is considered a proxy of the similarity of editorial policies. The
evidences support the idea that this group of journals is better described as a
set of only relatively connected subfields. In particular two main subfield are
identified, consisting of research oriented journals devoted respectively to
LIS and MIS. The links between these two subsets are weak. Around these two
subsets there are a lot of (relatively) isolated professional journals or
journals characterized more by their subject-matter content than by their focus
on information flows. It is possible to suggest that this configuration of the
network may be the consequence of the youthfulness of Information Science &amp;
Library Science, which has not permitted yet to reach a general consensus
through scholars on research aims, methods and instruments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1168</identifier>
 <datestamp>2011-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1168</id><created>2011-02-06</created><authors><author><keyname>Baccini</keyname><forenames>Alberto</forenames></author><author><keyname>Barabesi</keyname><forenames>Lucio</forenames></author></authors><title>Interlocking editorship. A network analysis of the links between
  economic journals</title><categories>cs.DL cs.SI physics.soc-ph</categories><report-no>Quaderni del Dipartimento di Economia Politica Universita' di Siena
  532/2008</report-no><journal-ref>Scientometrics, 2010 Volume 82, Number 2, 365-389</journal-ref><doi>10.1007/s11192-009-0053-7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The exploratory analysis developed in this paper relies on the hypothesis
that each editor possesses some power in the definition of the editorial policy
of her journal. Consequently if the same scholar sits on the board of editors
of two journals, those journals could have some common elements in their
editorial policies. The proximity of the editorial policies of two scientific
journals can be assessed by the number of common editors sitting on their
boards. A database of all editors of ECONLIT journals is used. The structure of
the network generated by interlocking editorship is explored by applying the
instruments of network analysis. Evidences have been found of a compact network
containing different components. This is interpreted as the result of a
plurality of perspectives about the appropriate methods for the investigation
of problems and the construction of theories within the domain of economics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1173</identifier>
 <datestamp>2011-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1173</id><created>2011-02-06</created><updated>2011-03-25</updated><authors><author><keyname>Ito</keyname><forenames>Kazufumi</forenames></author><author><keyname>Jin</keyname><forenames>Bangti</forenames></author><author><keyname>Takeuchi</keyname><forenames>Tomoya</forenames></author></authors><title>Multi-Parameter Tikhonov Regularization</title><categories>math.NA cs.SY math.OC</categories><comments>15 pages, 5 figures, accepted for publication in Methods and
  Applications of Analysis, with a few typos corrected</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study multi-parameter Tikhonov regularization, i.e., with multiple
penalties. Such models are useful when the sought-for solution exhibits several
distinct features simultaneously. Two choice rules, i.e., discrepancy principle
and balancing principle, are studied for choosing an appropriate
(vector-valued) regularization parameter, and some theoretical results are
presented. In particular, the consistency of the discrepancy principle as well
as convergence rate are established, and an a posteriori error estimate for the
balancing principle is established. Also two fixed point algorithms are
proposed for computing the regularization parameter by the latter rule.
Numerical results for several nonsmooth multi-parameter models are presented,
which show clearly their superior performance over their single-parameter
counterparts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1178</identifier>
 <datestamp>2011-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1178</id><created>2011-02-06</created><authors><author><keyname>Tarau</keyname><forenames>Paul</forenames></author></authors><title>The BinProlog Experience: Architecture and Implementation Choices for
  Continuation Passing Prolog and First-Class Logic Engines</title><categories>cs.PL</categories><comments>To appear in Theory and Practice of Logic Programming (TPLP);
  Keywords: Prolog, logic programming system, continuation passing style
  compilation, implementation of Prolog, first-class logic engines,
  data-representations for Prolog run-time systems</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe the BinProlog system's compilation technology, runtime system and
its extensions supporting first-class Logic Engines while providing a short
history of its development, details of some of its newer re-implementations as
well as an overview of the most important architectural choices involved in
their design.
  With focus on its differences with conventional WAM implementations, we
explain key details of BinProlog's compilation technique, which replaces the
WAM with a simplified continuation passing runtime system (the &quot;BinWAM&quot;), based
on a mapping of full Prolog to binary logic programs. This is followed by a
description of a term compression technique using a &quot;tag-on-data&quot;
representation.
  Later derivatives, the Java-based Jinni Prolog compiler and the recently
developed Lean Prolog system refine the BinProlog architecture with first-class
Logic Engines, made generic through the use of an Interactor interface. An
overview of their applications with focus on the ability to express at source
level a wide variety of Prolog built-ins and extensions, covers these newer
developments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1182</identifier>
 <datestamp>2011-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1182</id><created>2011-02-06</created><authors><author><keyname>Decelle</keyname><forenames>Aurelien</forenames></author><author><keyname>Krzakala</keyname><forenames>Florent</forenames></author><author><keyname>Moore</keyname><forenames>Cristopher</forenames></author><author><keyname>Zdeborov&#xe1;</keyname><forenames>Lenka</forenames></author></authors><title>Phase transition in the detection of modules in sparse networks</title><categories>cond-mat.stat-mech cs.LG cs.SI physics.soc-ph</categories><comments>4 pages, 4 figures</comments><journal-ref>Phys. Rev. Lett. 107, 065701 (2011)</journal-ref><doi>10.1103/PhysRevLett.107.065701</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an asymptotically exact analysis of the problem of detecting
communities in sparse random networks. Our results are also applicable to
detection of functional modules, partitions, and colorings in noisy planted
models. Using a cavity method analysis, we unveil a phase transition from a
region where the original group assignment is undetectable to one where
detection is possible. In some cases, the detectable region splits into an
algorithmically hard region and an easy one. Our approach naturally translates
into a practical algorithm for detecting modules in sparse networks, and
learning the parameters of the underlying model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1189</identifier>
 <datestamp>2011-05-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1189</id><created>2011-02-06</created><updated>2011-05-10</updated><authors><author><keyname>Jeandel</keyname><forenames>Emmanuel</forenames><affiliation>LIF</affiliation></author><author><keyname>Vanier</keyname><forenames>Pascal</forenames><affiliation>LIF</affiliation></author></authors><title>Pi01 sets and tilings</title><categories>cs.DM</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we prove that given any \Pi^0_1 subset $P$ of $\{0,1\}^\NN$
there is a tileset $\tau$ with a set of configurations $C$ such that
$P\times\ZZ^2$ is recursively homeomorphic to $C\setminus U$ where $U$ is a
computable set of configurations. As a consequence, if $P$ is countable, this
tileset has the exact same set of Turing degrees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1199</identifier>
 <datestamp>2014-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1199</id><created>2011-02-06</created><updated>2011-08-16</updated><authors><author><keyname>Say</keyname><forenames>A. C. Cem</forenames></author><author><keyname>Yakaryilmaz</keyname><forenames>Abuzer</forenames></author></authors><title>Computation with narrow CTCs</title><categories>cs.CC quant-ph</categories><comments>16 pages. A few typo was corrected</comments><doi>10.1007/978-3-642-21341-0_23</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We examine some variants of computation with closed timelike curves (CTCs),
where various restrictions are imposed on the memory of the computer, and the
information carrying capacity and range of the CTC. We give full
characterizations of the classes of languages recognized by polynomial time
probabilistic and quantum computers that can send a single classical bit to
their own past. Such narrow CTCs are demonstrated to add the power of limited
nondeterminism to deterministic computers, and lead to exponential speedup in
constant-space probabilistic and quantum computation. We show that, given a
time machine with constant negative delay, one can implement CTC-based
computations without the need to know about the runtime beforehand.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1208</identifier>
 <datestamp>2011-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1208</id><created>2011-02-06</created><authors><author><keyname>So&#x142;tys</keyname><forenames>Karolina</forenames></author></authors><title>The hardness of Median in the synchronized bit communication model</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The synchronized bit communication model, defined recently by Impagliazzo and
Williams in \emph{Communication complexity with synchronized clocks}, CCC '10,
is a communication model which allows the participants to share a common clock.
The main open problem posed in this paper was the following: does the
synchronized bit model allow a logarithmic speed-up for all functions over the
standard deterministic model of communication? We resolve this question in the
negative by showing that the Median function, whose communication complexity is
$O(\log n)$, does not admit polytime synchronized bit protocol with
communication complexity $O\left(\log^{1-\epsilon} n\right)$ for any $\epsilon
&gt; 0$. Our results follow by a new round-communication trade-off for the Median
function in the standard model, which easily translates to its hardness in the
synchronized bit model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1226</identifier>
 <datestamp>2011-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1226</id><created>2011-02-06</created><authors><author><keyname>Sen</keyname><forenames>Jaydip</forenames></author></authors><title>Secure Routing in Wireless Mesh Networks</title><categories>cs.CR cs.NI</categories><comments>44 pages, 17 figures, 5 tables</comments><journal-ref>Book Chapter: Jaydip Sen (2011). Secure Routing in Wireless Mesh
  Networks, Wireless Mesh Networks, Nobuo Funabiki (Ed.), InTech. Available
  from:
  http://www.intechopen.com/articles/show/title/secure-routing-in-wireless-mesh-networks</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless mesh networks (WMNs) have emerged as a promising concept to meet the
challenges in next-generation networks such as providing flexible, adaptive,
and reconfigurable architecture while offering cost-effective solutions to the
service providers. Unlike traditional Wi-Fi networks, with each access point
(AP) connected to the wired network, in WMNs only a subset of the APs are
required to be connected to the wired network. The APs that are connected to
the wired network are called the Internet gateways (IGWs), while the APs that
do not have wired connections are called the mesh routers (MRs). The MRs are
connected to the IGWs using multi-hop communication. The IGWs provide access to
conventional clients and interconnect ad hoc, sensor, cellular, and other
networks to the Internet. However, most of the existing routing protocols for
WMNs are extensions of protocols originally designed for mobile ad hoc networks
(MANETs) and thus they perform sub-optimally. Moreover, most routing protocols
for WMNs are designed without security issues in mind, where the nodes are all
assumed to be honest. In practical deployment scenarios, this assumption does
not hold. This chapter provides a comprehensive overview of security issues in
WMNs and then particularly focuses on secure routing in these networks. First,
it identifies security vulnerabilities in the medium access control (MAC) and
the network layers. Various possibilities of compromising data confidentiality,
data integrity, replay attacks and offline cryptanalysis are also discussed.
Then various types of attacks in the MAC and the network layers are discussed.
After enumerating the various types of attacks on the MAC and the network
layer, the chapter briefly discusses on some of the preventive mechanisms for
these attacks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1227</identifier>
 <datestamp>2011-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1227</id><created>2011-02-06</created><updated>2011-11-23</updated><authors><author><keyname>Nguyen</keyname><forenames>Nam H.</forenames></author><author><keyname>Tran</keyname><forenames>Trac. D.</forenames></author></authors><title>Exact recoverability from dense corrupted observations via $L_1$
  minimization</title><categories>cs.IT math.IT math.ST stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper confirms a surprising phenomenon first observed by Wright
\textit{et al.} \cite{WYGSM_Face_2009_J} \cite{WM_denseError_2010_J} under
different setting: given $m$ highly corrupted measurements $y = A_{\Omega
\bullet} x^{\star} + e^{\star}$, where $A_{\Omega \bullet}$ is a submatrix
whose rows are selected uniformly at random from rows of an orthogonal matrix
$A$ and $e^{\star}$ is an unknown sparse error vector whose nonzero entries may
be unbounded, we show that with high probability $\ell_1$-minimization can
recover the sparse signal of interest $x^{\star}$ exactly from only $m = C
\mu^2 k (\log n)^2$ where $k$ is the number of nonzero components of
$x^{\star}$ and $\mu = n \max_{ij} A_{ij}^2$, even if nearly 100% of the
measurements are corrupted. We further guarantee that stable recovery is
possible when measurements are polluted by both gross sparse and small dense
errors: $y = A_{\Omega \bullet} x^{\star} + e^{\star}+ \nu$ where $\nu$ is the
small dense noise with bounded energy. Numerous simulation results under
various settings are also presented to verify the validity of the theory as
well as to illustrate the promising potential of the proposed framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1231</identifier>
 <datestamp>2011-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1231</id><created>2011-02-06</created><authors><author><keyname>Li</keyname><forenames>Yen-Huan</forenames></author><author><keyname>Su</keyname><forenames>Borching</forenames></author><author><keyname>Yeh</keyname><forenames>Ping-Cheng</forenames></author></authors><title>Cramer-Rao Bound for Blind Channel Estimators in Redundant Block
  Transmission Systems</title><categories>cs.IT math.IT</categories><comments>10 pages, 6 figures, submitted to IEEE Trans. Signal Process</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we derive the Cramer-Rao bound (CRB) for blind channel
estimation in redundant block transmission systems, a lower bound for the mean
squared error of any blind channel estimators. The derived CRB is valid for any
full-rank linear redundant precoder, including both zero-padded (ZP) and
cyclic-prefixed (CP) precoders. A simple form of CRBs for multiple complex
parameters is also derived and presented which facilitates the CRB derivation
of the problem of interest. A comparison is made between the derived CRBs and
performances of existing subspace-based blind channel estimators for both CP
and ZP systems. Numerical results show that there is still some room for
performance improvement of blind channel estimators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1232</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1232</id><created>2011-02-06</created><updated>2013-02-20</updated><authors><author><keyname>Govindasamy</keyname><forenames>Siddhartan</forenames></author><author><keyname>Bliss</keyname><forenames>Daniel W.</forenames></author><author><keyname>Staelin</keyname><forenames>David H.</forenames></author></authors><title>Asymptotic Spectral Efficiency of the Uplink in Spatially Distributed
  Wireless Networks With Multi-Antenna Base Stations</title><categories>cs.IT math.IT</categories><comments>Accepted to IEEE Transactions on Communications</comments><journal-ref>Communications, IEEE Transactions on , vol.61, no.7, pp.100,112,
  July 2013</journal-ref><doi>10.1109/TCOMM.2013.053013.110784</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The spectral efficiency of a representative uplink of a given length, in
interference-limited, spatially-distributed wireless networks with hexagonal
cells, simple power control, and multiantenna linear Minimum-Mean-Square-Error
receivers is found to approach an asymptote as the numbers of base-station
antennas N and wireless nodes go to infinity. An approximation for the
area-averaged spectral efficiency of a representative link (averaged over the
spatial base-station and mobile distributions), for Poisson distributed base
stations, is also provided. For large N, in the interference-limited regime,
the area-averaged spectral efficiency is primarily a function of the ratio of
the product of N and the ratio of base-station to wireless-node densities,
indicating that it is possible to scale such networks by linearly increasing
the product of the number of base-station antennas and the relative density of
base stations to wireless nodes, with wireless-node density. The results are
useful for designers of wireless systems with high inter-cell interference
because it provides simple expressions for spectral efficiency as a function of
tangible system parameters like base-station and wireless-node densities, and
number of antennas. These results were derived combining infinite random matrix
theory and stochastic geometry.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1235</identifier>
 <datestamp>2011-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1235</id><created>2011-02-07</created><authors><author><keyname>Diwan</keyname><forenames>Ajit Arvind</forenames></author><author><keyname>Ghosh</keyname><forenames>Subir Kumar</forenames></author><author><keyname>Goswami</keyname><forenames>Partha Pratim</forenames></author><author><keyname>Lingas</keyname><forenames>Andrzej</forenames></author></authors><title>On joint triangulations of two sets of points in the plane</title><categories>cs.DM cs.CG</categories><comments>The extended abstrat of this paper appeared in the Proceedings of
  India-Taiwan Conference on Discrete Mathematics, Taipei, pp. 34-43, 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we establish two necessary conditions for a joint
triangulation of two sets of $n$ points in the plane and conjecture that they
are sufficient. We show that these necessary conditions can be tested in
$O(n^3)$ time. For the problem of a joint triangulation of two simple polygons
of $n$ vertices, we propose an $O(n^3)$ time algorithm for constructing a joint
triangulation using dynamic programming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1237</identifier>
 <datestamp>2011-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1237</id><created>2011-02-07</created><authors><author><keyname>Zaliva</keyname><forenames>Vadim</forenames></author></authors><title>Applying static code analysis to firewall policies for the purpose of
  anomaly detection</title><categories>cs.PL cs.CR cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Treating modern firewall policy languages as imperative, special purpose
programming languages, in this article we will try to apply static code
analysis techniques for the purpose of anomaly detection.
  We will first abstract a policy in common firewall policy language into an
intermediate language, and then we will try to apply anomaly detection
algorithms to it.
  The contributions made by this work are:
  1. An analysis of various control flow instructions in popular firewall
policy languages 2. Introduction of an intermediate firewall policy language,
with emphasis on control flow constructs. 3. Application of \textit{Static Code
Analysis} to detect anomalies in firewall policy, expressed in intermediate
firewall policy language. 4. Sample implementation of \textit{Static Code
Analysis} of firewall policies, expressed in our abstract language using
Datalog language.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1247</identifier>
 <datestamp>2014-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1247</id><created>2011-02-07</created><updated>2014-11-11</updated><authors><author><keyname>Abbe</keyname><forenames>Emmanuel</forenames></author></authors><title>Randomness and dependencies extraction via polarization, with
  applications to Slepian-Wolf coding and secrecy</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The polarization phenomenon for a single source is extended to a framework
with multiple correlated sources. It is shown in addition to extracting the
randomness of the source, the polar transforms takes the original arbitrary
dependencies to extremal dependencies. Polar coding schemes for the
Slepian-Wolf problem and for secret key generations are then proposed based on
this phenomenon. In particular, constructions of secret keys achieving the
secrecy capacity and compression schemes achieving the Slepian-Wolf capacity
region are obtained with a complexity of $O(n \log (n))$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1249</identifier>
 <datestamp>2012-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1249</id><created>2011-02-07</created><updated>2012-04-25</updated><authors><author><keyname>Gribonval</keyname><forenames>R&#xe9;mi</forenames><affiliation>INRIA - IRISA</affiliation></author><author><keyname>Cevher</keyname><forenames>Volkan</forenames><affiliation>EPFL</affiliation></author><author><keyname>Davies</keyname><forenames>Mike E.</forenames></author></authors><title>Compressible Distributions for High-dimensional Statistics</title><categories>math.ST cs.IT math.IT stat.TH</categories><comments>Was previously entitled &quot;Compressible priors for high-dimensional
  statistics&quot;; IEEE Transactions on Information Theory (2012)</comments><proxy>ccsd</proxy><doi>10.1109/TIT.2012.2197174</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a principled way of identifying probability distributions whose
independent and identically distributed (iid) realizations are compressible,
i.e., can be well-approximated as sparse. We focus on Gaussian random
underdetermined linear regression (GULR) problems, where compressibility is
known to ensure the success of estimators exploiting sparse regularization. We
prove that many distributions revolving around maximum a posteriori (MAP)
interpretation of sparse regularized estimators are in fact incompressible, in
the limit of large problem sizes. A highlight is the Laplace distribution and
$\ell^{1}$ regularized estimators such as the Lasso and Basis Pursuit
denoising. To establish this result, we identify non-trivial undersampling
regions in GULR where the simple least squares solution almost surely
outperforms an oracle sparse solution, when the data is generated from the
Laplace distribution. We provide simple rules of thumb to characterize classes
of compressible (respectively incompressible) distributions based on their
second and fourth moments. Generalized Gaussians and generalized Pareto
distributions serve as running examples for concreteness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1256</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1256</id><created>2011-02-07</created><authors><author><keyname>Asri</keyname><forenames>Brahim El</forenames></author></authors><title>Stochastic Optimal Multi-Modes Switching with a Viscosity Solution
  Approach</title><categories>math.OC cs.SY math.PR</categories><comments>2 figures</comments><msc-class>Real options, Backward stochastic differential equations, Snell
  envelope, Stopping times, Switching, Viscosity solution of PDEs, Variational
  inequalities</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of optimal multi-modes switching in finite horizon,
when the state of the system, including the switching cost functions are
arbitrary ($g_{ij}(t,x)\geq 0$). We show existence of the optimal strategy, and
give when the optimal strategy is finite via a verification theorem. Finally,
when the state of the system is a markov process, we show that the vector of
value functions of the optimal problem is the unique viscosity solution to the
system of $m$ variational partial differential inequalities with
inter-connected obstacles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1261</identifier>
 <datestamp>2011-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1261</id><created>2011-02-07</created><updated>2011-08-18</updated><authors><author><keyname>Sikora</keyname><forenames>W.</forenames></author><author><keyname>Malinowski</keyname><forenames>J.</forenames></author></authors><title>Symmetry in behavior of complex social systems - discussion of models of
  crowd evacuation organized in agreement with symmetry conditions</title><categories>cs.MA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The evacuation of football stadium scenarios are discussed as model realizing
ordered states, described as movements of individuals according to fields of
displacements, calculated correspondingly to given scenario. The symmetry of
the evacuation space is taken into account in calculation of displacements
field - the displacements related to every point of this space are presented in
the coordinate frame in the best way adapted to given symmetry space group,
which the set of basic vectors of irreducible representation of given group is.
The speeds of individuals at every point in the presented model have the same
quantity. As the results the times of evacuation and average forces acting on
individuals during the evacuation are given. Both parameters are compared with
the same parameters got without symmetry considerations. They are calculated in
the simulation procedure. The new program (using modified Helbing model) has
been elaborated and presented in this work for realization the simulation tasks
the.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1265</identifier>
 <datestamp>2011-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1265</id><created>2011-02-07</created><authors><author><keyname>Jalden</keyname><forenames>Joakim</forenames></author><author><keyname>Elia</keyname><forenames>Petros</forenames></author></authors><title>Sphere decoding complexity exponent for decoding full rate codes over
  the quasi-static MIMO channel</title><categories>cs.IT math.IT</categories><comments>19 Pages, 4 figures. Submitted to the IEEE Transactions on
  Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the setting of quasi-static multiple-input multiple-output (MIMO)
channels, we consider the high signal-to-noise ratio (SNR) asymptotic
complexity required by the sphere decoding (SD) algorithm for decoding a large
class of full rate linear space-time codes. With SD complexity having random
fluctuations induced by the random channel, noise and codeword realizations,
the introduced SD complexity exponent manages to concisely describe the
computational reserves required by the SD algorithm to achieve arbitrarily
close to optimal decoding performance. Bounds and exact expressions for the SD
complexity exponent are obtained for the decoding of large families of codes
with arbitrary performance characteristics. For the particular example of
decoding the recently introduced threaded cyclic division algebra (CDA) based
codes -- the only currently known explicit designs that are uniformly optimal
with respect to the diversity multiplexing tradeoff (DMT) -- the SD complexity
exponent is shown to take a particularly concise form as a non-monotonic
function of the multiplexing gain. To date, the SD complexity exponent also
describes the minimum known complexity of any decoder that can provably achieve
a gap to maximum likelihood (ML) performance which vanishes in the high SNR
limit.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1273</identifier>
 <datestamp>2011-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1273</id><created>2011-02-07</created><authors><author><keyname>Je&#x17c;</keyname><forenames>&#x141;ukasz</forenames></author></authors><title>One to Rule Them All: a General Randomized Algorithm for Buffer
  Management with Bounded Delay</title><categories>cs.DS</categories><comments>14 pages</comments><msc-class>68Q25, 68Q87</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a memoryless scale-invariant randomized algorithm for the Buffer
Management with Bounded Delay problem that is e/(e-1)-competitive against an
adaptive adversary, together with better performance guarantees for many
restricted variants, including the s-bounded instances. In particular, our
algorithm attains the optimum competitive ratio of 4/3 on 2-bounded instances.
  Both the algorithm and its analysis are applicable to a more general problem,
called Collecting Items, in which only the relative order between packets'
deadlines is known. Our algorithm is the optimal randomized memoryless
algorithm against adaptive adversary for that problem in a strong sense.
  While some of provided upper bounds were already known, in general, they were
attained by several different algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1292</identifier>
 <datestamp>2011-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1292</id><created>2011-02-07</created><authors><author><keyname>Ghanem</keyname><forenames>Bernard</forenames></author><author><keyname>Ahuja</keyname><forenames>Narendra</forenames></author></authors><title>Modeling Dynamic Swarms</title><categories>cs.CV</categories><comments>11 pages, 17 figures, conference paper, computer vision</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes the problem of modeling video sequences of dynamic swarms
(DS). We define DS as a large layout of stochastically repetitive spatial
configurations of dynamic objects (swarm elements) whose motions exhibit local
spatiotemporal interdependency and stationarity, i.e., the motions are similar
in any small spatiotemporal neighborhood. Examples of DS abound in nature,
e.g., herds of animals and flocks of birds. To capture the local spatiotemporal
properties of the DS, we present a probabilistic model that learns both the
spatial layout of swarm elements and their joint dynamics that are modeled as
linear transformations. To this end, a spatiotemporal neighborhood is
associated with each swarm element, in which local stationarity is enforced
both spatially and temporally. We assume that the prior on the swarm dynamics
is distributed according to an MRF in both space and time. Embedding this model
in a MAP framework, we iterate between learning the spatial layout of the swarm
and its dynamics. We learn the swarm transformations using ICM, which iterates
between estimating these transformations and updating their distribution in the
spatiotemporal neighborhoods. We demonstrate the validity of our method by
conducting experiments on real video sequences. Real sequences of birds, geese,
robot swarms, and pedestrians evaluate the applicability of our model to real
world data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1313</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1313</id><created>2011-02-07</created><authors><author><keyname>Abramsky</keyname><forenames>Samson</forenames></author><author><keyname>Tzevelekos</keyname><forenames>Nikos</forenames></author></authors><title>Introduction to Categories and Categorical Logic</title><categories>math.CT cs.LO</categories><comments>96 pages</comments><journal-ref>In New Structures for Physics, B. Coecke (ed). Lecture Notes in
  Physics Vol. 813, pages 3--94, Springer-Verlag 2011</journal-ref><doi>10.1007/978-3-642-12821-9_1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of these notes is to provide a succinct, accessible introduction to
some of the basic ideas of category theory and categorical logic. The notes are
based on a lecture course given at Oxford over the past few years. They contain
numerous exercises, and hopefully will prove useful for self-study by those
seeking a first introduction to the subject, with fairly minimal prerequisites.
The coverage is by no means comprehensive, but should provide a good basis for
further study; a guide to further reading is included. The main prerequisite is
a basic familiarity with the elements of discrete mathematics: sets, relations
and functions. An Appendix contains a summary of what we will need, and it may
be useful to review this first. In addition, some prior exposure to abstract
algebra - vector spaces and linear maps, or groups and group homomorphisms -
would be helpful.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1323</identifier>
 <datestamp>2011-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1323</id><created>2011-02-07</created><authors><author><keyname>Spitters</keyname><forenames>Bas</forenames></author><author><keyname>van der Weegen</keyname><forenames>Eelis</forenames></author></authors><title>Type Classes for Mathematics in Type Theory</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The introduction of first-class type classes in the Coq system calls for
re-examination of the basic interfaces used for mathematical formalization in
type theory. We present a new set of type classes for mathematics and take full
advantage of their unique features to make practical a particularly flexible
approach formerly thought infeasible. Thus, we address both traditional proof
engineering challenges as well as new ones resulting from our ambition to build
upon this development a library of constructive analysis in which abstraction
penalties inhibiting efficient computation are reduced to a minimum.
  The base of our development consists of type classes representing a standard
algebraic hierarchy, as well as portions of category theory and universal
algebra. On this foundation we build a set of mathematically sound abstract
interfaces for different kinds of numbers, succinctly expressed using
categorical language and universal algebra constructions. Strategic use of type
classes lets us support these high-level theory-friendly definitions while
still enabling efficient implementations unhindered by gratuitous indirection,
conversion or projection.
  Algebra thrives on the interplay between syntax and semantics. The
Prolog-like abilities of type class instance resolution allow us to
conveniently define a quote function, thus facilitating the use of reflective
techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1324</identifier>
 <datestamp>2011-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1324</id><created>2011-02-07</created><authors><author><keyname>Xu</keyname><forenames>Yuesheng</forenames></author><author><keyname>Zhang</keyname><forenames>Haizhang</forenames></author><author><keyname>Zhang</keyname><forenames>Qinghui</forenames></author></authors><title>Refinement of Operator-valued Reproducing Kernels</title><categories>cs.LG math.FA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the construction of a refinement kernel for a given
operator-valued reproducing kernel such that the vector-valued reproducing
kernel Hilbert space of the refinement kernel contains that of the given one as
a subspace. The study is motivated from the need of updating the current
operator-valued reproducing kernel in multi-task learning when underfitting or
overfitting occurs. Numerical simulations confirm that the established
refinement kernel method is able to meet this need. Various characterizations
are provided based on feature maps and vector-valued integral representations
of operator-valued reproducing kernels. Concrete examples of refining
translation invariant and finite Hilbert-Schmidt operator-valued reproducing
kernels are provided. Other examples include refinement of Hessian of
scalar-valued translation-invariant kernels and transformation kernels.
Existence and properties of operator-valued reproducing kernels preserved
during the refinement process are also investigated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1340</identifier>
 <datestamp>2011-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1340</id><created>2011-02-07</created><authors><author><keyname>Faigle</keyname><forenames>Ulrich</forenames></author><author><keyname>Grabisch</keyname><forenames>Michel</forenames></author></authors><title>A Discrete Choquet Integral for Ordered Systems</title><categories>cs.DM math.PR</categories><doi>10.1016/j.fss.2010.10.003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A model for a Choquet integral for arbitrary finite set systems is presented.
The model includes in particular the classical model on the system of all
subsets of a finite set. The general model associates canonical non-negative
and positively homogeneous superadditive functionals with generalized belief
functions relative to an ordered system, which are then extended to arbitrary
valuations on the set system. It is shown that the general Choquet integral can
be computed by a simple Monge-type algorithm for so-called intersection
systems, which include as a special case weakly union-closed families.
Generalizing Lov\'asz' classical characterization, we give a characterization
of the superadditivity of the Choquet integral relative to a capacity on a
union-closed system in terms of an appropriate model of supermodularity of such
capacities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1341</identifier>
 <datestamp>2011-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1341</id><created>2011-02-07</created><authors><author><keyname>Grabisch</keyname><forenames>Michel</forenames></author></authors><title>Ensuring the boundedness of the core of games with restricted
  cooperation</title><categories>cs.GT cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The core of a cooperative game on a set of players $N$ is one of the most
popular concept of solution. When cooperation is restricted (feasible
coalitions form a subcollection $\cF$ of $2^N$), the core may become unbounded,
which makes it usage questionable in practice. Our proposal is to make the core
bounded by turning some of the inequalities defining the core into equalities
(additional efficiency constraints). We address the following mathematical
problem: can we find a minimal set of inequalities in the core such that, if
turned into equalities, the core becomes bounded? The new core obtained is
called the restricted core. We completely solve the question when $\cF$ is a
distributive lattice, introducing also the notion of restricted Weber set. We
show that the case of regular set systems amounts more or less to the case of
distributive lattices. We also study the case of weakly union-closed systems
and give some results for the general case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1342</identifier>
 <datestamp>2011-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1342</id><created>2011-02-07</created><authors><author><keyname>Grabisch</keyname><forenames>Michel</forenames></author><author><keyname>li</keyname><forenames>Tong</forenames></author></authors><title>On the set of imputations induced by the k-additive core</title><categories>cs.GT cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An extension to the classical notion of core is the notion of $k$-additive
core, that is, the set of $k$-additive games which dominate a given game, where
a $k$-additive game has its M\&quot;obius transform (or Harsanyi dividends)
vanishing for subsets of more than $k$ elements. Therefore, the 1-additive core
coincides with the classical core. The advantages of the $k$-additive core is
that it is never empty once $k\geq 2$, and that it preserves the idea of
coalitional rationality. However, it produces $k$-imputations, that is,
imputations on individuals and coalitions of at most $k$ inidividuals, instead
of a classical imputation. Therefore one needs to derive a classical imputation
from a $k$-order imputation by a so-called sharing rule. The paper investigates
what set of imputations the $k$-additive core can produce from a given sharing
rule.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1345</identifier>
 <datestamp>2011-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1345</id><created>2011-02-07</created><authors><author><keyname>Mukhopadhyay</keyname><forenames>Debajyoti</forenames></author><author><keyname>Sinha</keyname><forenames>Sukanta</forenames></author></authors><title>Introducing a New Mechanism for Construction of an Efficient Search
  Model</title><categories>cs.IR</categories><comments>7 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Search engine has become an inevitable tool for retrieving information from
the WWW. Web researchers introduce lots of algorithms to modify search engine
based on different features. Sometimes those algorithms are domain related,
sometimes they are Web page ranking related, and sometimes they are efficiency
related and so on. We are introducing such a type of algorithm which is
multiple domains as well as efficiency related. In this paper, we are providing
multilevel indexing on top of Index Based Acyclic Graph (IBAG) which support
multiple Ontologies as well as reduce search time. IBAG contains only domains
related pages and are constructed from Relevant Page Graph (RPaG). We have also
provided a comparative study of time complexity for the various models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1379</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1379</id><created>2011-02-07</created><updated>2011-05-23</updated><authors><author><keyname>Egu&#xed;luz</keyname><forenames>V&#xed;ctor M.</forenames><affiliation>IFISC</affiliation></author><author><keyname>P&#xe9;rez</keyname><forenames>Toni</forenames><affiliation>IFISC</affiliation><affiliation>Lehigh University, USA</affiliation></author><author><keyname>Borge-Holtoefer</keyname><forenames>Javier</forenames><affiliation>Universitat Rovira i Virgili, Spain</affiliation></author><author><keyname>Arenas</keyname><forenames>Alex</forenames><affiliation>Universitat Rovira i Virgili, Spain</affiliation></author></authors><title>Structural and functional networks in complex systems with delay</title><categories>cond-mat.dis-nn cs.SI physics.soc-ph</categories><comments>5 pages, 3 figures</comments><journal-ref>Physical Review E 83, 056113 (2011)</journal-ref><doi>10.1103/PhysRevE.83.056113</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Functional networks of complex systems are obtained from the analysis of the
temporal activity of their components, and are often used to infer their
unknown underlying connectivity. We obtain the equations relating topology and
function in a system of diffusively delay-coupled elements in complex networks.
We solve exactly the resulting equations in motifs (directed structures of
three nodes), and in directed networks. The mean-field solution for directed
uncorrelated networks shows that the clusterization of the activity is
dominated by the in-degree of the nodes, and that the locking frequency
decreases with increasing average degree. We find that the exponent of a power
law degree distribution of the structural topology, b, is related to the
exponent of the associated functional network as a =1/(2-b), for b &lt; 2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1388</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1388</id><created>2011-02-07</created><authors><author><keyname>Abramsky</keyname><forenames>Samson</forenames></author><author><keyname>Vaananen</keyname><forenames>Jouko</forenames></author></authors><title>From IF to BI: a tale of dependence and separation</title><categories>math.LO cs.LO</categories><comments>28 pages, journal version</comments><journal-ref>Synthese, 167:2, pages 207--230, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We take a fresh look at the logics of informational dependence and
independence of Hintikka and Sandu and Vaananen, and their compositional
semantics due to Hodges. We show how Hodges' semantics can be seen as a special
case of a general construction, which provides a context for a useful
completeness theorem with respect to a wider class of models. We shed some new
light on each aspect of the logic. We show that the natural propositional logic
carried by the semantics is the logic of Bunched Implications due to Pym and
O'Hearn, which combines intuitionistic and multiplicative connectives. This
introduces several new connectives not previously considered in logics of
informational dependence, but which we show play a very natural role, most
notably intuitionistic implication. As regards the quantifiers, we show that
their interpretation in the Hodges semantics is forced, in that they are the
image under the general construction of the usual Tarski semantics; this
implies that they are adjoints to substitution, and hence uniquely determined.
As for the dependence predicate, we show that this is definable from a simpler
predicate, of constancy or dependence on nothing. This makes essential use of
the intuitionistic implication. The Armstrong axioms for functional dependence
are then recovered as a standard set of axioms for intuitionistic implication.
We also prove a full abstraction result in the style of Hodges, in which the
intuitionistic implication plays a very natural r\^ole.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1398</identifier>
 <datestamp>2011-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1398</id><created>2011-02-07</created><authors><author><keyname>Kanoria</keyname><forenames>Yashodhan</forenames></author><author><keyname>Tamuz</keyname><forenames>Omer</forenames></author></authors><title>Efficient Bayesian Social Learning on Trees</title><categories>cs.SI cs.GT cs.MA</categories><comments>11 pages, 1 figure, submitted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a set of agents who are attempting to iteratively learn the
'state of the world' from their neighbors in a social network. Each agent
initially receives a noisy observation of the true state of the world. The
agents then repeatedly 'vote' and observe the votes of some of their peers,
from which they gain more information. The agents' calculations are Bayesian
and aim to myopically maximize the expected utility at each iteration.
  This model, introduced by Gale and Kariv (2003), is a natural approach to
learning on networks. However, it has been criticized, chiefly because the
agents' decision rule appears to become computationally intractable as the
number of iterations advances. For instance, a dynamic programming approach
(part of this work) has running time that is exponentially large in \min(n,
(d-1)^t), where n is the number of agents.
  We provide a new algorithm to perform the agents' computations on locally
tree-like graphs. Our algorithm uses the dynamic cavity method to drastically
reduce computational effort. Let d be the maximum degree and t be the iteration
number. The computational effort needed per agent is exponential only in O(td)
(note that the number of possible information sets of a neighbor at time t is
itself exponential in td).
  Under appropriate assumptions on the rate of convergence, we deduce that each
agent is only required to spend polylogarithmic (in 1/\eps) computational
effort to approximately learn the true state of the world with error
probability \eps, on regular trees of degree at least five. We provide
numerical and other evidence to justify our assumption on convergence rate.
  We extend our results in various directions, including loopy graphs. Our
results indicate efficiency of iterative Bayesian social learning in a wide
range of situations, contrary to widely held beliefs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1402</identifier>
 <datestamp>2011-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1402</id><created>2011-02-07</created><authors><author><keyname>Asur</keyname><forenames>Sitaram</forenames></author><author><keyname>Huberman</keyname><forenames>Bernardo A.</forenames></author><author><keyname>Szabo</keyname><forenames>Gabor</forenames></author><author><keyname>Wang</keyname><forenames>Chunyan</forenames></author></authors><title>Trends in Social Media : Persistence and Decay</title><categories>cs.CY physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Social media generates a prodigious wealth of real-time content at an
incessant rate. From all the content that people create and share, only a few
topics manage to attract enough attention to rise to the top and become
temporal trends which are displayed to users. The question of what factors
cause the formation and persistence of trends is an important one that has not
been answered yet. In this paper, we conduct an intensive study of trending
topics on Twitter and provide a theoretical basis for the formation,
persistence and decay of trends. We also demonstrate empirically how factors
such as user activity and number of followers do not contribute strongly to
trend creation and its propagation. In fact, we find that the resonance of the
content with the users of the social network plays a major role in causing
trends.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1407</identifier>
 <datestamp>2011-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1407</id><created>2011-02-07</created><updated>2011-05-17</updated><authors><author><keyname>Ravuri</keyname><forenames>Muralidhar</forenames></author></authors><title>Stable Parallel Looped Systems -- A New Theoretical Framework for the
  Evolution of Order</title><categories>cs.NE nlin.AO</categories><comments>21 pages, 9 figures; simplified text and figures for clarity</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The objective of the paper is to identify laws and mechanisms that allow the
creation of more order from disorder using natural means i.e., without the help
of conscious beings. While this is not possible for the collection of all
dynamical systems as it violates the second law of thermodynamics, I show that
this is possible within a special subset called stable parallel looped (SPL)
dynamical systems. I identify a new infinite family of physical and chemical
dynamical SPL systems, which are (a) easy to create naturally and (b) easy to
merge, link and combine to create dynamical systems of any specified
complexity. Within SPL systems, I propose a special collection of designs
called active material-energy looped systems using which it is possible to
generate large-scale ordered chemical networks, like the metabolic networks, in
a reliable, repeatable, iterative and natural manner. The resulting SPL systems
provide a new theoretical framework for the problem of origin of life.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1408</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1408</id><created>2011-02-07</created><updated>2011-09-07</updated><authors><author><keyname>Zhang</keyname><forenames>Zhenghao</forenames></author><author><keyname>Gong</keyname><forenames>Shuping</forenames></author><author><keyname>Li</keyname><forenames>Husheng</forenames></author><author><keyname>Pei</keyname><forenames>Changxing</forenames></author></authors><title>Time Stamp Attack on Wide Area Monitoring System in Smart Grid</title><categories>cs.CR</categories><comments>This paper has been withdrawn by the author due to a crucial sign
  error in derivation</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Security becomes an extremely important issue in smart grid. To maintain the
steady operation for smart power grid, massive measurement devices must be
allocated widely among the power grid. Previous studies are focused on false
data injection attack to the smart grid system. In practice, false data
injection attack is not easy to implement, since it is not easy to hack the
power grid data communication system. In this paper, we demonstrate that a
novel time stamp attack is a practical and dangerous attack scheme for smart
grid. Since most of measurement devices are equipped with global positioning
system (GPS) to provide the time information of measurements, it is highly
probable to attack the measurement system by spoofing the GPS. By employing the
real measurement data in North American Power Grid, simulation results
demonstrate the effectiveness of the time stamp attack on smart grid.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1440</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1440</id><created>2011-02-07</created><updated>2013-06-09</updated><authors><author><keyname>Istrate</keyname><forenames>Gabriel</forenames></author></authors><title>Reachability and recurrence in a modular generalization of annihilating
  random walks (and lights-out games) on hypergraphs</title><categories>math.CO cond-mat.dis-nn cs.DM math.PR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a dynamical system motivated by our earlier work on the statistical
physics of social balance on graphs that can be viewed as a generalization of
annihilating walks along two directions: first, the interaction topology is a
hypergraph; second, the ``number of particles`` at a vertex of the hypergraph
is an element of a finite field ${\bf Z}_{p}$ of integers modulo $p$, $p\geq
3$. Equivalently, particles move on a hypergraph, with a moving particle at a
vertex being replaced by one indistinguishable copy at each neighbor in a given
hyperedge; particles at a vertex collectively annihilate when their number
reaches $p$. The system we study can also be regarded as a natural
generalization of certain lights-out games to finite fields and hypergraph
topologies. Our result shows that under a liberal sufficient condition on the
nature of the interaction hypergraph there exists a polynomial time algorithm
(based on linear algebra over ${\bf Z}_{p}$) for deciding reachability and
recurrence of this dynamical system. Interestingly, we provide a counterexample
that shows that this connection does not extend to all graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1441</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1441</id><created>2011-02-07</created><authors><author><keyname>Lee</keyname><forenames>David</forenames></author><author><keyname>Bruck</keyname><forenames>Jehoshua</forenames></author></authors><title>Generating Probability Distributions using Multivalued Stochastic Relay
  Circuits</title><categories>cs.IT cs.DM math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of random number generation dates back to von Neumann's work in
1951. Since then, many algorithms have been developed for generating unbiased
bits from complex correlated sources as well as for generating arbitrary
distributions from unbiased bits. An equally interesting, but less studied
aspect is the structural component of random number generation as opposed to
the algorithmic aspect. That is, given a network structure imposed by nature or
physical devices, how can we build networks that generate arbitrary probability
distributions in an optimal way? In this paper, we study the generation of
arbitrary probability distributions in multivalued relay circuits, a
generalization in which relays can take on any of N states and the logical
'and' and 'or' are replaced with 'min' and 'max' respectively. Previous work
was done on two-state relays. We generalize these results, describing a duality
property and networks that generate arbitrary rational probability
distributions. We prove that these networks are robust to errors and design a
universal probability generator which takes input bits and outputs arbitrary
binary probability distributions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1443</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1443</id><created>2011-02-07</created><updated>2012-07-09</updated><authors><author><keyname>Comi</keyname><forenames>Marco</forenames></author><author><keyname>DasGupta</keyname><forenames>Bhaskar</forenames></author><author><keyname>Schapira</keyname><forenames>Michael</forenames></author><author><keyname>Srinivasan</keyname><forenames>Venkatakumar</forenames></author></authors><title>On Communication Protocols that Compute Almost Privately</title><categories>cs.CR cs.GT</categories><comments>to appear in Theoretical Computer Science (series A)</comments><msc-class>91B26, 91A99, 68Q99</msc-class><acm-class>F.0</acm-class><journal-ref>Theoretical Computer Science, 457, 45-58, 2012</journal-ref><doi>10.1016/j.tcs.2012.07.008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A traditionally desired goal when designing auction mechanisms is incentive
compatibility, i.e., ensuring that bidders fare best by truthfully reporting
their preferences. A complementary goal, which has, thus far, received
significantly less attention, is to preserve privacy, i.e., to ensure that
bidders reveal no more information than necessary. We further investigate and
generalize the approximate privacy model for two-party communication recently
introduced by Feigenbaum et al.[8]. We explore the privacy properties of a
natural class of communication protocols that we refer to as &quot;dissection
protocols&quot;. Dissection protocols include, among others, the bisection auction
in [9,10] and the bisection protocol for the millionaires problem in [8].
Informally, in a dissection protocol the communicating parties are restricted
to answering simple questions of the form &quot;Is your input between the values
\alpha and \beta (under a predefined order over the possible inputs)?&quot;.
  We prove that for a large class of functions, called tiling functions, which
include the 2nd-price Vickrey auction, there always exists a dissection
protocol that provides a constant average-case privacy approximation ratio for
uniform or &quot;almost uniform&quot; probability distributions over inputs. To establish
this result we present an interesting connection between the approximate
privacy framework and basic concepts in computational geometry. We show that
such a good privacy approximation ratio for tiling functions does not, in
general, exist in the worst case. We also discuss extensions of the basic setup
to more than two parties and to non-tiling functions, and provide calculations
of privacy approximation ratios for two functions of interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1456</identifier>
 <datestamp>2011-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1456</id><created>2011-02-07</created><authors><author><keyname>Arora</keyname><forenames>Sanjeev</forenames></author><author><keyname>Lee</keyname><forenames>James</forenames></author><author><keyname>Sachdeva</keyname><forenames>Sushant</forenames></author></authors><title>A Reformulation of the Arora-Rao-Vazirani Structure Theorem</title><categories>cs.DM</categories><comments>4 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a well-known paper[ARV], Arora, Rao and Vazirani obtained an O(sqrt(log
n)) approximation to the Balanced Separator problem and Uniform Sparsest Cut.
At the heart of their result is a geometric statement about sets of points that
satisfy triangle inequalities, which also underlies subsequent work on
approximation algorithms and geometric embeddings.
  In this note, we give an equivalent formulation of the Structure theorem in
[ARV] in terms of the expansion of large sets in geometric graphs on sets of
points satisfying triangle inequalities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1462</identifier>
 <datestamp>2012-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1462</id><created>2011-02-07</created><updated>2012-10-08</updated><authors><author><keyname>Mehana</keyname><forenames>Ahmed Hesham</forenames></author><author><keyname>Nosratinia</keyname><forenames>Aria</forenames></author></authors><title>Diversity of MMSE MIMO Receivers</title><categories>cs.IT math.IT</categories><comments>To appear in IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In most MIMO systems, the family of waterfall error curves, calculated at
different spectral efficiencies, are asymptotically parallel at high SNR. In
other words, most MIMO systems exhibit a single diversity value for all fixed
rates. The MIMO MMSE receiver does not follow this pattern and exhibits a
varying diversity in its family of error curves. This work analyzes this
interesting behavior of the MMSE MIMO receiver and produces the MMSE MIMO
diversity at all rates. The diversity of the quasi-static flat-fading MIMO
channel consisting of any arbitrary number of transmit and receive antennas is
fully characterized, showing that full spatial diversity is possible if and
only if the rate is within a certain bound which is a function of the number of
antennas. For other rates, the available diversity is fully characterized. At
sufficiently low rates, the MMSE receiver has a diversity similar to the
maximum likelihood receiver (maximal diversity), while at high rates it
performs similarly to the zero-forcing receiver (minimal diversity). Linear
receivers are also studied in the context of the MIMO multiple access channel
(MAC). Then, the quasi-static frequency selective MIMO channel is analyzed
under zero-padding (ZP) and cyclic-prefix (CP) block transmissions and MMSE
reception, and lower and upper bounds on diversity are derived. For the special
case of SIMO under CP, it is shown that the above-mentioned bounds are tight.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1465</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1465</id><created>2011-02-07</created><updated>2012-07-09</updated><authors><author><keyname>Barbu</keyname><forenames>Adrian</forenames></author><author><keyname>Lay</keyname><forenames>Nathan</forenames></author></authors><title>An Introduction to Artificial Prediction Markets for Classification</title><categories>stat.ML cs.LG math.ST stat.TH</categories><comments>29 pages, 8 figures</comments><journal-ref>Journal of Machine Learning Research, 13, 2177-2204, 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Prediction markets are used in real life to predict outcomes of interest such
as presidential elections. This paper presents a mathematical theory of
artificial prediction markets for supervised learning of conditional
probability estimators. The artificial prediction market is a novel method for
fusing the prediction information of features or trained classifiers, where the
fusion result is the contract price on the possible outcomes. The market can be
trained online by updating the participants' budgets using training examples.
Inspired by the real prediction markets, the equations that govern the market
are derived from simple and reasonable assumptions. Efficient numerical
algorithms are presented for solving these equations. The obtained artificial
prediction market is shown to be a maximum likelihood estimator. It generalizes
linear aggregation, existent in boosting and random forest, as well as logistic
regression and some kernel methods. Furthermore, the market mechanism allows
the aggregation of specialized classifiers that participate only on specific
instances. Experimental comparisons show that the artificial prediction markets
often outperform random forest and implicit online learning on synthetic data
and real UCI datasets. Moreover, an extensive evaluation for pelvic and
abdominal lymph node detection in CT data shows that the prediction market
improves adaboost's detection rate from 79.6% to 81.2% at 3 false
positives/volume.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1466</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1466</id><created>2011-02-07</created><authors><author><keyname>Li</keyname><forenames>Qiao</forenames></author><author><keyname>Negi</keyname><forenames>Rohit</forenames></author></authors><title>Distributed Throughput-optimal Scheduling in Ad Hoc Wireless Networks</title><categories>cs.IT math.IT</categories><comments>6 pages, 3 figures. A shorter version will appear in the proceedings
  of IEEE ICC 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a distributed throughput-optimal ad hoc wireless
network scheduling algorithm, which is motivated by the celebrated simplex
algorithm for solving linear programming (LP) problems. The scheduler stores a
sparse set of basic schedules, and chooses the max-weight basic schedule for
transmission in each time slot. At the same time, the scheduler tries to update
the set of basic schedules by searching for a new basic schedule in a
throughput increasing direction. We show that both of the above procedures can
be achieved in a distributed manner. Specifically, we propose an average
consensus based link contending algorithm to implement the distributed max
weight scheduling. Further, we show that the basic schedule update can be
implemented using CSMA mechanisms, which is similar to the one proposed by
Jiang et al. Compared to the optimal distributed scheduler in Jiang's paper,
where schedules change in a random walk fashion, our algorithm has a better
delay performance by achieving faster schedule transitions in the steady state.
The performance of the algorithm is finally confirmed by simulation results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1472</identifier>
 <datestamp>2011-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1472</id><created>2011-02-07</created><authors><author><keyname>Chandrasekaran</keyname><forenames>Karthekeyan</forenames></author><author><keyname>Karp</keyname><forenames>Richard</forenames></author><author><keyname>Moreno-Centeno</keyname><forenames>Erick</forenames></author><author><keyname>Vempala</keyname><forenames>Santosh</forenames></author></authors><title>Algorithms for Implicit Hitting Set Problems</title><categories>cs.DS</categories><acm-class>F.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A hitting set for a collection of sets is a set that has a non-empty
intersection with each set in the collection; the hitting set problem is to
find a hitting set of minimum cardinality. Motivated by instances of the
hitting set problem where the number of sets to be hit is large, we introduce
the notion of implicit hitting set problems. In an implicit hitting set problem
the collection of sets to be hit is typically too large to list explicitly;
instead, an oracle is provided which, given a set H, either determines that H
is a hitting set or returns a set that H does not hit. We show a number of
examples of classic implicit hitting set problems, and give a generic algorithm
for solving such problems optimally. The main contribution of this paper is to
show that this framework is valuable in developing approximation algorithms. We
illustrate this methodology by presenting a simple on-line algorithm for the
minimum feedback vertex set problem on random graphs. In particular our
algorithm gives a feedback vertex set of size n-(1/p)\log{np}(1-o(1)) with
probability at least 3/4 for the random graph G_{n,p} (the smallest feedback
vertex set is of size n-(2/p)\log{np}(1+o(1))). We also consider a planted
model for the feedback vertex set in directed random graphs. Here we show that
a hitting set for a polynomial-sized subset of cycles is a hitting set for the
planted random graph and this allows us to exactly recover the planted feedback
vertex set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1475</identifier>
 <datestamp>2011-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1475</id><created>2011-02-07</created><authors><author><keyname>Ly</keyname><forenames>Hung D.</forenames></author><author><keyname>Liu</keyname><forenames>Tie</forenames></author><author><keyname>Blankenship</keyname><forenames>Yufei</forenames></author></authors><title>Security Embedding Codes</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE Transactions on Information Forensics and
  Security</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the problem of simultaneously communicating two
messages, a high-security message and a low-security message, to a legitimate
receiver, referred to as the security embedding problem. An
information-theoretic formulation of the problem is presented. A coding scheme
that combines rate splitting, superposition coding, nested binning and channel
prefixing is considered and is shown to achieve the secrecy capacity region of
the channel in several scenarios. Specifying these results to both scalar and
independent parallel Gaussian channels (under an average individual
per-subchannel power constraint), it is shown that the high-security message
can be embedded into the low-security message at full rate (as if the
low-security message does not exist) without incurring any loss on the overall
rate of communication (as if both messages are low-security messages).
Extensions to the wiretap channel II setting of Ozarow and Wyner are also
considered, where it is shown that &quot;perfect&quot; security embedding can be achieved
by an encoder that uses a two-level coset code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1480</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1480</id><created>2011-02-07</created><updated>2011-07-27</updated><authors><author><keyname>Kim</keyname><forenames>Byung-Hak</forenames></author><author><keyname>Pfister</keyname><forenames>Henry D.</forenames></author></authors><title>Joint Decoding of LDPC Codes and Finite-State Channels via
  Linear-Programming</title><categories>cs.IT math.IT</categories><comments>Accepted to IEEE Journal of Selected Topics in Signal Processing
  (Special Issue on Soft Detection for Wireless Transmission)</comments><doi>10.1109/JSTSP.2011.2165525</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the joint-decoding (JD) problem for finite-state
channels (FSCs) and low-density parity-check (LDPC) codes. In the first part,
the linear-programming (LP) decoder for binary linear codes is extended to JD
of binary-input FSCs. In particular, we provide a rigorous definition of LP
joint-decoding pseudo-codewords (JD-PCWs) that enables evaluation of the
pairwise error probability between codewords and JD-PCWs in AWGN. This leads
naturally to a provable upper bound on decoder failure probability. If the
channel is a finite-state intersymbol interference channel, then the joint LP
decoder also has the maximum-likelihood (ML) certificate property and all
integer-valued solutions are codewords. In this case, the performance loss
relative to ML decoding can be explained completely by fractional-valued
JD-PCWs. After deriving these results, we discovered some elements were
equivalent to earlier work by Flanagan on LP receivers.
  In the second part, we develop an efficient iterative solver for the joint LP
decoder discussed in the first part. In particular, we extend the approach of
iterative approximate LP decoding, proposed by Vontobel and Koetter and
analyzed by Burshtein, to this problem. By taking advantage of the dual-domain
structure of the JD-LP, we obtain a convergent iterative algorithm for joint LP
decoding whose structure is similar to BCJR-based turbo equalization (TE). The
result is a joint iterative decoder whose per-iteration complexity is similar
to that of TE but whose performance is similar to that of joint LP decoding.
The main advantage of this decoder is that it appears to provide the
predictability of joint LP decoding and superior performance with the
computational complexity of TE. One expected application is coding for magnetic
storage where the required block-error rate is extremely low and system
performance is difficult to verify by simulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1487</identifier>
 <datestamp>2013-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1487</id><created>2011-02-07</created><updated>2013-02-28</updated><authors><author><keyname>Zhang</keyname><forenames>Yichao</forenames></author><author><keyname>Zhou</keyname><forenames>Shi</forenames></author><author><keyname>Guan</keyname><forenames>Jihong</forenames></author><author><keyname>Zhou</keyname><forenames>Shuigeng</forenames></author></authors><title>Rumor Evolution in Social Networks</title><categories>physics.soc-ph cs.SI</categories><comments>a regular paper with 6 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Social network is a main tunnel of rumor spreading. Previous studies are
concentrated on a static rumor spreading. The content of the rumor is
invariable during the whole spreading process. Indeed, the rumor evolves
constantly in its spreading process, which grows shorter, more concise, more
easily grasped and told. In an early psychological experiment, researchers
found about 70% of details in a rumor were lost in the first 6 mouth-to-mouth
transmissions \cite{TPR}. Based on the facts, we investigate rumor spreading on
social networks, where the content of the rumor is modified by the individuals
with a certain probability. In the scenario, they have two choices, to forward
or to modify. As a forwarder, an individual disseminates the rumor directly to
its neighbors. As a modifier, conversely, an individual revises the rumor
before spreading it out. When the rumor spreads on the social networks, for
instance, scale-free networks and small-world networks, the majority of
individuals actually are infected by the multi-revised version of the rumor, if
the modifiers dominate the networks. Our observation indicates that the
original rumor may lose its influence in the spreading process. Similarly, a
true information may turn to be a rumor as well. Our result suggests the rumor
evolution should not be a negligible question, which may provide a better
understanding of the generation and destruction of a rumor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1497</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1497</id><created>2011-02-07</created><updated>2011-03-10</updated><authors><author><keyname>Mimura</keyname><forenames>Kazushi</forenames></author><author><keyname>Cousseau</keyname><forenames>Florent</forenames></author><author><keyname>Okada</keyname><forenames>Masato</forenames></author></authors><title>Belief Propagation for Error Correcting Codes and Lossy Compression
  Using Multilayer Perceptrons</title><categories>cs.IT math.IT physics.data-an</categories><comments>18 pages, 18 figures</comments><journal-ref>J. Phys. Soc. Jpn., 80, 3, 034802 (2011)</journal-ref><doi>10.1143/JPSJ.80.034802</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The belief propagation (BP) based algorithm is investigated as a potential
decoder for both of error correcting codes and lossy compression, which are
based on non-monotonic tree-like multilayer perceptron encoders. We discuss
that whether the BP can give practical algorithms or not in these schemes. The
BP implementations in those kind of fully connected networks unfortunately
shows strong limitation, while the theoretical results seems a bit promising.
Instead, it reveals it might have a rich and complex structure of the solution
space via the BP-based algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1498</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1498</id><created>2011-02-07</created><authors><author><keyname>Tadrous</keyname><forenames>John</forenames></author><author><keyname>Nafie</keyname><forenames>Mohammed</forenames></author></authors><title>On Rate-Splitting by a Secondary Link in Multiple Access Primary Network</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An achievable rate region is obtained for a primary multiple access network
coexisting with a secondary link of one transmitter and a corresponding
receiver. The rate region depicts the sum primary rate versus the secondary
rate and is established assuming that the secondary link performs
rate-splitting. The achievable rate region is the union of two types of
achievable rate regions. The first type is a rate region established assuming
that the secondary receiver cannot decode any primary signal, whereas the
second is established assuming that the secondary receiver can decode the
signal of one primary receiver. The achievable rate region is determined first
assuming discrete memoryless channel (DMC) then the results are applied to a
Gaussian channel. In the Gaussian channel, the performance of rate-splitting is
characterized for the two types of rate regions. Moreover, a necessary and
sufficient condition to determine which primary signal that the secondary
receiver can decode without degrading the range of primary achievable sum rates
is provided. When this condition is satisfied by a certain primary user, the
secondary receiver can decode its signal and achieve larger rates without
reducing the primary achievable sum rates from the case in which it does not
decode any primary signal. It is also shown that, the probability of having at
least one primary user satisfying this condition grows with the primary signal
to noise ratio.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1502</identifier>
 <datestamp>2011-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1502</id><created>2011-02-07</created><authors><author><keyname>Gariel</keyname><forenames>Maxime</forenames></author><author><keyname>Spieser</keyname><forenames>Kevin</forenames></author><author><keyname>Frazzoli</keyname><forenames>Emilio</forenames></author></authors><title>On the Statistics and Predictability of Go-Arounds</title><categories>cs.SY</categories><comments>10 pages, 14 figures, Submitted to USA/Europe ATM Seminar 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper takes an empirical approach to identify operational factors at
busy airports that may predate go-around maneuvers. Using four years of data
from San Francisco International Airport, we begin our investigation with a
statistical approach to investigate which features of airborne, ground
operations (e.g., number of inbound aircraft, number of aircraft taxiing from
gate, etc.) or weather are most likely to fluctuate, relative to nominal
operations, in the minutes immediately preceding a missed approach. We analyze
these findings both in terms of their implication on current airport operations
and discuss how the antecedent factors may affect NextGen. Finally, as a means
to assist air traffic controllers, we draw upon techniques from the machine
learning community to develop a preliminary alert system for go-around
prediction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1503</identifier>
 <datestamp>2011-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1503</id><created>2011-02-07</created><authors><author><keyname>Zhang</keyname><forenames>Yu</forenames></author><author><keyname>van der Schaar</keyname><forenames>Mihaela</forenames></author></authors><title>Peer-to-Peer Multimedia Sharing based on Social Norms</title><categories>cs.MM cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Empirical data shows that in the absence of incentives, a peer participating
in a Peer-to-Peer (P2P) network wishes to free-riding. Most solutions for
providing incentives in P2P networks are based on direct reciprocity, which are
not appropriate for most P2P multimedia sharing networks due to the unique
features exhibited by such networks: large populations of anonymous agents
interacting infrequently, asymmetric interests of peers, network errors, and
multiple concurrent transactions. In this paper, we design and rigorously
analyze a new family of incentive protocols that utilizes indirect reciprocity
which is based on the design of efficient social norms. In the proposed P2P
protocols, the social norms consist of a social strategy, which represents the
rule prescribing to the peers when they should or should not provide content to
other peers, and a reputation scheme, which rewards or punishes peers depending
on whether they comply or not with the social strategy. We first define the
concept of a sustainable social norm, under which no peer has an incentive to
deviate. We then formulate the problem of designing optimal social norms, which
selects the social norm that maximizes the network performance among all
sustainable social norms. Hence, we prove that it becomes in the self-interest
of peers to contribute their content to the network rather than to free-ride.
We also investigate the impact of various punishment schemes on the social
welfare as well as how should the optimal social norms be designed if
altruistic and malicious peers are active in the network. Our results show that
optimal social norms are capable of providing significant improvements in the
sharing efficiency of multimedia P2P networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1507</identifier>
 <datestamp>2011-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1507</id><created>2011-02-07</created><authors><author><keyname>Williams</keyname><forenames>Paul L.</forenames></author><author><keyname>Beer</keyname><forenames>Randall D.</forenames></author></authors><title>Generalized Measures of Information Transfer</title><categories>physics.data-an cs.IT math.DS math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Transfer entropy provides a general tool for analyzing the magnitudes and
directions---but not the \emph{kinds}---of information transfer in a system. We
extend transfer entropy in two complementary ways. First, we distinguish
state-dependent from state-independent transfer, based on whether a source's
influence depends on the state of the target. Second, for multiple sources, we
distinguish between unique, redundant, and synergistic transfer. The new
measures are demonstrated on several systems that extend examples from previous
literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1523</identifier>
 <datestamp>2011-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1523</id><created>2011-02-08</created><authors><author><keyname>Van Der Walt</keyname><forenames>Stefan</forenames><affiliation>Parietal</affiliation></author><author><keyname>Colbert</keyname><forenames>S. Chris</forenames><affiliation>Parietal</affiliation></author><author><keyname>Varoquaux</keyname><forenames>Ga&#xeb;l</forenames><affiliation>Parietal</affiliation></author></authors><title>The NumPy array: a structure for efficient numerical computation</title><categories>cs.MS</categories><proxy>ccsd</proxy><journal-ref>Computing in Science and Engineering 13, 2 (2011) 22-30</journal-ref><doi>10.1109/MCSE.2011.37</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the Python world, NumPy arrays are the standard representation for
numerical data. Here, we show how these arrays enable efficient implementation
of numerical computations in a high-level language. Overall, three techniques
are applied to improve performance: vectorizing calculations, avoiding copying
data in memory, and minimizing operation counts. We first present the NumPy
array structure, then show how to use it for efficient computation, and finally
how to share array data with other libraries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1534</identifier>
 <datestamp>2011-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1534</id><created>2011-02-08</created><authors><author><keyname>Luo</keyname><forenames>Xu-Ren</forenames></author><author><keyname>Lin</keyname><forenames>Chen-Hui Jerry</forenames></author><author><keyname>Yin</keyname><forenames>Te-Lung</forenames></author></authors><title>Reversible Data Hiding Based on Two-level HDWT Coefficient Histograms</title><categories>cs.CR</categories><comments>16 pages, 8 figures</comments><journal-ref>Advanced Computing: An International Journal(ACIJ), January 2011,
  Volume 2, Number 1</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, reversible data hiding has attracted much more attention
than before. Reversibility signifies that the original media can be recovered
without any loss from the marked media after extracting the embedded message.
This paper presents a new method that adopts two-level wavelet transform and
exploits the feature of large wavelet coefficient variance to achieve the goal
of high capacity with imperceptibility. Our method differs from those of
previous ones in which the wavelet coefficients histogram not gray-level
histogram is manipulated. Besides, clever shifting rules are introduced into
histogram to avoid the decimal problem in pixel values after recovery to
achieve reversibility. With small alteration of the wavelet coefficients in the
embedding process, and therefore low visual distortion is obtained in the
marked image. In addition, an important feature of our design is that the use
of threshold is much different from previous studies. The results indicate that
our design is superior to many other state-of-the-art reversible data hiding
schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1536</identifier>
 <datestamp>2011-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1536</id><created>2011-02-08</created><authors><author><keyname>Belgasmi</keyname><forenames>Nabil</forenames><affiliation>SOIE</affiliation></author><author><keyname>Said</keyname><forenames>Lamjed Ben</forenames><affiliation>SOIE</affiliation></author><author><keyname>Gh&#xe9;dira</keyname><forenames>Khaled</forenames><affiliation>SOIE</affiliation></author></authors><title>Evolutionary multiobjective optimization of the multi-location
  transshipment problem</title><categories>cs.AI math.OC</categories><proxy>ccsd</proxy><journal-ref>Operational Research 8, 2 (2008) 167-183</journal-ref><doi>10.1007/s12351-008-0015-5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a multi-location inventory system where inventory choices at each
location are centrally coordinated. Lateral transshipments are allowed as
recourse actions within the same echelon in the inventory system to reduce
costs and improve service level. However, this transshipment process usually
causes undesirable lead times. In this paper, we propose a multiobjective model
of the multi-location transshipment problem which addresses optimizing three
conflicting objectives: (1) minimizing the aggregate expected cost, (2)
maximizing the expected fill rate, and (3) minimizing the expected
transshipment lead times. We apply an evolutionary multiobjective optimization
approach using the strength Pareto evolutionary algorithm (SPEA2), to
approximate the optimal Pareto front. Simulation with a wide choice of model
parameters shows the different trades-off between the conflicting objectives.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1544</identifier>
 <datestamp>2011-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1544</id><created>2011-02-08</created><authors><author><keyname>Adiga</keyname><forenames>Abhijin</forenames></author><author><keyname>Babu</keyname><forenames>Jasine</forenames></author><author><keyname>Chandran</keyname><forenames>L. Sunil</forenames></author></authors><title>A Constant Factor Approximation Algorithm for Boxicity of Circular Arc
  Graphs</title><categories>cs.DS cs.DM math.CO</categories><comments>23 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Boxicity of a graph $G(V,E)$ is the minimum integer $k$ such that $G$ can be
represented as the intersection graph of $k$-dimensional axis parallel
rectangles in $\mathbf{R}^k$. Equivalently, it is the minimum number of
interval graphs on the vertex set $V$ such that the intersection of their edge
sets is $E$. It is known that boxicity cannot be approximated even for graph
classes like bipartite, co-bipartite and split graphs below $O(n^{0.5 -
\epsilon})$-factor, for any $\epsilon &gt;0$ in polynomial time unless $NP=ZPP$.
Till date, there is no well known graph class of unbounded boxicity for which
even an $n^\epsilon$-factor approximation algorithm for computing boxicity is
known, for any $\epsilon &lt;1$. In this paper, we study the boxicity problem on
Circular Arc graphs - intersection graphs of arcs of a circle. We give a
$(2+\frac{1}{k})$-factor polynomial time approximation algorithm for computing
the boxicity of any circular arc graph along with a corresponding box
representation, where $k \ge 1$ is its boxicity. For Normal Circular Arc(NCA)
graphs, with an NCA model given, this can be improved to an additive 2-factor
approximation algorithm. The time complexity of the algorithms to approximately
compute the boxicity is $O(mn+n^2)$ in both these cases and in $O(mn+kn^2)=
O(n^3)$ time we also get their corresponding box representations, where $n$ is
the number of vertices of the graph and $m$ is its number of edges. The
additive 2-factor algorithm directly works for any Proper Circular Arc graph,
since computing an NCA model for it can be done in polynomial time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1547</identifier>
 <datestamp>2012-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1547</id><created>2011-02-08</created><updated>2012-07-14</updated><authors><author><keyname>Triantafyllou</keyname><forenames>Nikolaos</forenames></author><author><keyname>Frangos</keyname><forenames>Petros Stefaneas amd Panayiotis</forenames></author></authors><title>Redesigning the Open Mobile Alliance License Choice Algorithm</title><categories>cs.CR</categories><comments>10 pages, 2 tables, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We claim that the Open Mobile Alliance (OMA) License Choice Algorithm,
implemented in mobile DRM agents as specified by OMA suffers from a bug. More
precisely there exist some cases that the user, may end up losing some rights
without even to exercise them. We redesign this algorithm and claim that our
approach eliminates this bug.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1552</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1552</id><created>2011-02-08</created><authors><author><keyname>Rajanna</keyname><forenames>Amogh</forenames></author><author><keyname>Jindal</keyname><forenames>Nihar</forenames></author></authors><title>Multiuser Diversity in Downlink Channels: When does the Feedback Cost
  Outweigh the Spectral Efficiency Gain?</title><categories>cs.IT math.IT</categories><comments>25 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we perform a cost-benefit analysis of multiuser diversity in
single antenna broadcast channels. It is well known that multiuser diversity
can be beneficial but there is a significant cost associated with acquiring
instantaneous CSI. We perform a cost-benefit analysis of multiuser diversity
for 2 types of CSI feedback methods, dedicated feedback and SNR dependent
feedback, quantifying how many users should feedback CSI from a net throughput
perspective. Dedicated feedback, in which orthogonal resources are allocated to
each user, has significant feedback cost and this limits the amount of
available multiuser diversity that can be used. SNR dependent feedback method,
in which only users with SNR above a threshold attempt to feedback, has
relatively much smaller feedback cost and this allows for all of the available
multiuser diversity to be used. Next, we study the effect of single user
multiantenna techniques, which reduce the SNR variation, on the number of
feedback users neccessary. It is seen that a broadcast channel using single
user multiantenna techniques should reduce the number of feedback users with
the spatial dimension.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1580</identifier>
 <datestamp>2011-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1580</id><created>2011-02-08</created><authors><author><keyname>Auger</keyname><forenames>David</forenames><affiliation>LRI, INRIA Saclay - Ile de France</affiliation></author></authors><title>Multiple Tree for Partially Observable Monte-Carlo Tree Search</title><categories>cs.GT</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an algorithm for computing approximate Nash equilibria of
partially observable games using Monte-Carlo tree search based on recent bandit
methods. We obtain experimental results for the game of phantom tic-tac-toe,
showing that strong strategies can be efficiently computed by our algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1600</identifier>
 <datestamp>2013-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1600</id><created>2011-02-08</created><authors><author><keyname>Masood</keyname><forenames>Farhat</forenames><affiliation>National University of Sciences and Technology, Pakistan</affiliation></author></authors><title>A Study on Digital Video Broadcasting to a Handheld Device (DVB-H),
  Operating in UHF Band</title><categories>cs.NI cs.MM</categories><journal-ref>Computing Research Repository - CORR, vol. abs/1102.1, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we will understand that the development of the Digital Video
Broadcasting to a Handheld (DVB-H) standard makes it possible to deliver live
broadcast television to a mobile handheld device. Building upon the strengths
of the Digital Video Broadcasting - Terrestrial (DVB-T) standard in use in
millions of homes, DVB-H recognizes the trend towards the personal consumption
of media.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1609</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1609</id><created>2011-02-08</created><updated>2011-05-31</updated><authors><author><keyname>Shum</keyname><forenames>Kenneth W.</forenames></author><author><keyname>Hu</keyname><forenames>Yuchong</forenames></author></authors><title>Exact Minimum-Repair-Bandwidth Cooperative Regenerating Codes for
  Distributed Storage Systems</title><categories>cs.IT cs.DC math.IT</categories><comments>5 pages, 4 figures, presented at IEEE ISIT 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In order to provide high data reliability, distributed storage systems
disperse data with redundancy to multiple storage nodes. Regenerating codes is
a new class of erasure codes to introduce redundancy for the purpose of
improving the data repair performance in distributed storage. Most of the
studies on regenerating codes focus on the single-failure recovery, but it is
not uncommon to see two or more node failures at the same time in large storage
networks. To exploit the opportunity of repairing multiple failed nodes
simultaneously, a cooperative repair mechanism, in the sense that the nodes to
be repaired can exchange data among themselves, is investigated. A lower bound
on the repair-bandwidth for cooperative repair is derived and a construction of
a family of exact cooperative regenerating codes matching this lower bound is
presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1612</identifier>
 <datestamp>2011-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1612</id><created>2011-02-08</created><authors><author><keyname>Arrighi</keyname><forenames>Pablo</forenames></author><author><keyname>Dowek</keyname><forenames>Gilles</forenames></author></authors><title>The physical Church-Turing thesis and the principles of quantum theory</title><categories>quant-ph cs.DM cs.FL math-ph math.MP</categories><comments>14 pages, LaTeX</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Notoriously, quantum computation shatters complexity theory, but is innocuous
to computability theory. Yet several works have shown how quantum theory as it
stands could breach the physical Church-Turing thesis. We draw a clear line as
to when this is the case, in a way that is inspired by Gandy. Gandy formulates
postulates about physics, such as homogeneity of space and time, bounded
density and velocity of information --- and proves that the physical
Church-Turing thesis is a consequence of these postulates. We provide a quantum
version of the theorem. Thus this approach exhibits a formal non-trivial
interplay between theoretical physics symmetries and computability assumptions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1621</identifier>
 <datestamp>2011-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1621</id><created>2011-02-08</created><updated>2011-12-07</updated><authors><author><keyname>Studer</keyname><forenames>Christoph</forenames></author><author><keyname>Kuppinger</keyname><forenames>Patrick</forenames></author><author><keyname>Pope</keyname><forenames>Graeme</forenames></author><author><keyname>B&#xf6;lcskei</keyname><forenames>Helmut</forenames></author></authors><title>Recovery of Sparsely Corrupted Signals</title><categories>cs.IT math.IT</categories><comments>Accepted for publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the recovery of signals exhibiting a sparse representation in
a general (i.e., possibly redundant or incomplete) dictionary that are
corrupted by additive noise admitting a sparse representation in another
general dictionary. This setup covers a wide range of applications, such as
image inpainting, super-resolution, signal separation, and recovery of signals
that are impaired by, e.g., clipping, impulse noise, or narrowband
interference. We present deterministic recovery guarantees based on a novel
uncertainty relation for pairs of general dictionaries and we provide
corresponding practicable recovery algorithms. The recovery guarantees we find
depend on the signal and noise sparsity levels, on the coherence parameters of
the involved dictionaries, and on the amount of prior knowledge about the
signal and noise support sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1636</identifier>
 <datestamp>2011-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1636</id><created>2011-02-08</created><updated>2011-03-14</updated><authors><author><keyname>Saha</keyname><forenames>Arpan</forenames></author><author><keyname>Karthik</keyname><forenames>C S</forenames></author></authors><title>A Few Equivalences of Wall-Sun-Sun Prime Conjecture</title><categories>math.NT cs.DM</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we prove a few lemmas concerning Fibonacci numbers modulo
primes and provide a few statements that are equivalent to Wall-Sun-Sun Prime
Conjecture. Further, we investigate the conjecture through heuristic arguments
and propose a few additional conjectures for future research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1660</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1660</id><created>2011-02-07</created><authors><author><keyname>Popescu</keyname><forenames>Vlad</forenames></author><author><keyname>Clarke</keyname><forenames>John-Paul B.</forenames></author><author><keyname>Feigh</keyname><forenames>Karen M.</forenames></author><author><keyname>Feron</keyname><forenames>Eric</forenames></author></authors><title>ATC Taskload Inherent to the Geometry of Stochastic 4-D Trajectory Flows
  with Flight Technical Errors</title><categories>cs.SY</categories><comments>Submitted to the 9th USA/Europe ATM R&amp;D Seminar - Berlin 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A method to quantify the probabilistic controller taskload inherent to
maintaining aircraft adherence to 4-D trajectories within flow corridors is
presented. An Ornstein-Uhlenbeck model of the aircraft motion and a Poisson
model of the flow scheduling are introduced along with reasonable numerical
values of the model parameters. Analytic expressions are derived for the
taskload probability density functions for basic functional elements of the
flow structure. Monte Carlo simulations are performed for these basic
functional elements and the controller taskload probabilities are exhibited.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1691</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1691</id><created>2011-02-08</created><updated>2011-02-09</updated><authors><author><keyname>Marques-Pita</keyname><forenames>Manuel</forenames></author><author><keyname>Rocha</keyname><forenames>Luis M.</forenames></author></authors><title>Schema Redescription in Cellular Automata: Revisiting Emergence in
  Complex Systems</title><categories>nlin.CG cs.AI cs.FL cs.NE q-bio.QM</categories><comments>paper submitted to the 2011 IEEE Symposium on Artificial Life</comments><journal-ref>The 2011 IEEE Symposium on Artificial Life, at the IEEE Symposium
  Series on Computational Intelligence 2011. April 11 - 15, 201, Paris, France,
  pp: 233-240</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a method to eliminate redundancy in the transition tables of
Boolean automata: schema redescription with two symbols. One symbol is used to
capture redundancy of individual input variables, and another to capture
permutability in sets of input variables: fully characterizing the canalization
present in Boolean functions. Two-symbol schemata explain aspects of the
behaviour of automata networks that the characterization of their emergent
patterns does not capture. We use our method to compare two well-known cellular
automata for the density classification task: the human engineered CA GKL, and
another obtained via genetic programming (GP). We show that despite having very
different collective behaviour, these rules are very similar. Indeed, GKL is a
special case of GP. Therefore, we demonstrate that it is more feasible to
compare cellular automata via schema redescriptions of their rules, than by
looking at their emergent behaviour, leading us to question the tendency in
complexity research to pay much more attention to emergent patterns than to
local interactions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1745</identifier>
 <datestamp>2011-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1745</id><created>2011-02-08</created><authors><author><keyname>Levin</keyname><forenames>Mark Sh.</forenames></author></authors><title>Restructuring in Combinatorial Optimization</title><categories>cs.DS cs.AI math.CO math.OC</categories><comments>11 pages, 12 figures</comments><msc-class>90Bxx</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper addresses a new class of combinatorial problems which consist in
restructuring of solutions (as structures) in combinatorial optimization. Two
main features of the restructuring process are examined: (i) a cost of the
restructuring, (ii) a closeness to a goal solution. This problem corresponds to
redesign (improvement, upgrade) of modular systems or solutions. The
restructuring approach is described and illustrated for the following
combinatorial optimization problems: knapsack problem, multiple choice problem,
assignment problem, spanning tree problems. Examples illustrate the
restructuring processes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1746</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1746</id><created>2011-02-08</created><authors><author><keyname>Burcsi</keyname><forenames>P&#xe9;ter</forenames></author><author><keyname>Cicalese</keyname><forenames>Ferdinando</forenames></author><author><keyname>Fici</keyname><forenames>Gabriele</forenames></author><author><keyname>Lipt&#xe1;k</keyname><forenames>Zsuzsanna</forenames></author></authors><title>Algorithms for Jumbled Pattern Matching in Strings</title><categories>cs.DS</categories><comments>18 pages, 9 figures; article accepted for publication in the
  International Journal of Foundations of Computer Science</comments><acm-class>F.2.2; J.3</acm-class><journal-ref>Int. J. Found. Comput. Sci. 23(2): 357-374 (2012)</journal-ref><doi>10.1142/S0129054112400175</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Parikh vector p(s) of a string s is defined as the vector of
multiplicities of the characters. Parikh vector q occurs in s if s has a
substring t with p(t)=q. We present two novel algorithms for searching for a
query q in a text s. One solves the decision problem over a binary text in
constant time, using a linear size index of the text. The second algorithm, for
a general finite alphabet, finds all occurrences of a given Parikh vector q and
has sub-linear expected time complexity; we present two variants, which both
use a linear size index of the text.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1747</identifier>
 <datestamp>2011-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1747</id><created>2011-02-08</created><authors><author><keyname>Voice</keyname><forenames>Thomas D.</forenames></author><author><keyname>Polukarov</keyname><forenames>Maria</forenames></author><author><keyname>Jennings</keyname><forenames>Nicholas R.</forenames></author></authors><title>Graph Coalition Structure Generation</title><categories>cs.DS cs.AI cs.CC cs.GT cs.MA</categories><comments>22 pages, 10 figures</comments><msc-class>68Q25, 68R10, 05C10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give the first analysis of the computational complexity of {\it coalition
structure generation over graphs}. Given an undirected graph $G=(N,E)$ and a
valuation function $v:2^N\rightarrow\RR$ over the subsets of nodes, the problem
is to find a partition of $N$ into connected subsets, that maximises the sum of
the components' values. This problem is generally NP--complete; in particular,
it is hard for a defined class of valuation functions which are {\it
independent of disconnected members}---that is, two nodes have no effect on
each other's marginal contribution to their vertex separator. Nonetheless, for
all such functions we provide bounds on the complexity of coalition structure
generation over general and minor free graphs. Our proof is constructive and
yields algorithms for solving corresponding instances of the problem.
Furthermore, we derive polynomial time bounds for acyclic, $K_{2,3}$ and $K_4$
minor free graphs. However, as we show, the problem remains NP--complete for
planar graphs, and hence, for any $K_k$ minor free graphs where $k\geq 5$.
Moreover, our hardness result holds for a particular subclass of valuation
functions, termed {\it edge sum}, where the value of each subset of nodes is
simply determined by the sum of given weights of the edges in the induced
subgraph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1753</identifier>
 <datestamp>2011-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1753</id><created>2011-02-08</created><updated>2011-02-11</updated><authors><author><keyname>Raeder</keyname><forenames>Troy</forenames></author><author><keyname>Lizardo</keyname><forenames>Omar</forenames></author><author><keyname>Hachen</keyname><forenames>David</forenames></author><author><keyname>Chawla</keyname><forenames>Nitesh V.</forenames></author></authors><title>Predictors of short-term decay of cell phone contacts in a large scale
  communication network</title><categories>cs.SI physics.soc-ph stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Under what conditions is an edge present in a social network at time t likely
to decay or persist by some future time t + Delta(t)? Previous research
addressing this issue suggests that the network range of the people involved in
the edge, the extent to which the edge is embedded in a surrounding structure,
and the age of the edge all play a role in edge decay. This paper uses weighted
data from a large-scale social network built from cell-phone calls in an 8-week
period to determine the importance of edge weight for the decay/persistence
process. In particular, we study the relative predictive power of directed
weight, embeddedness, newness, and range (measured as outdegree) with respect
to edge decay and assess the effectiveness with which a simple decision tree
and logistic regression classifier can accurately predict whether an edge that
was active in one time period continues to be so in a future time period. We
find that directed edge weight, weighted reciprocity and time-dependent
measures of edge longevity are highly predictive of whether we classify an edge
as persistent or decayed, relative to the other types of factors at the dyad
and neighborhood level.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1754</identifier>
 <datestamp>2011-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1754</id><created>2011-02-08</created><authors><author><keyname>Rohini</keyname><forenames>S.</forenames></author><author><keyname>Indumathi</keyname><forenames>K.</forenames></author></authors><title>Probability Based Adaptive Invoked Clustering Algorithm in MANETs</title><categories>cs.DC</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A mobile ad hoc network (MANET), is a self-configuring network of mobile
devices connected by wireless links. In order to achieve stable clusters, the
cluster-heads maintaining the cluster should be stable with minimum overhead of
cluster re-elections. In this paper we propose a Probability Based Adaptive
Invoked Weighted Clustering Algorithm (PAIWCA) which can enhance the stability
of the clusters by taking battery power of the nodes into considerations for
the clustering formation and electing stable cluster-heads using cluster head
probability of a node. In this simulation study a comparison was conducted to
measure the performance of our algorithm with maximal weighted independent set
(MWIS) in terms of the number of clusters formed, the connectivity of the
network, dominant set updates,throughput of the overall network and packet
delivery ratio. The result shows that our algorithm performs better than
existing one and is also tunable to different kinds of network conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1760</identifier>
 <datestamp>2011-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1760</id><created>2011-02-08</created><authors><author><keyname>Ding</keyname><forenames>Ying</forenames></author></authors><title>Applying weighted PageRank to author citation networks</title><categories>cs.DL</categories><comments>19 pages, 4 figures, 5 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper aims to identify whether different weighted PageRank algorithms
can be applied to author citation networks to measure the popularity and
prestige of a scholar from a citation perspective. Information Retrieval (IR)
was selected as a test field and data from 1956-2008 were collected from Web of
Science (WOS). Weighted PageRank with citation and publication as weighted
vectors were calculated on author citation networks. The results indicate that
both popularity rank and prestige rank were highly correlated with the weighted
PageRank. Principal Component Analysis (PCA) was conducted to detect
relationships among these different measures. For capturing prize winners
within the IR field, prestige rank outperformed all the other measures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1770</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1770</id><created>2011-02-08</created><authors><author><keyname>Tang</keyname><forenames>Ming</forenames></author><author><keyname>Zhou</keyname><forenames>Tao</forenames></author></authors><title>Efficient routing strategies in scale-free networks with limited
  bandwidth</title><categories>physics.data-an cs.NI</categories><comments>5 pages, 4 figures</comments><journal-ref>Physical Review E 84 (2011) 026116</journal-ref><doi>10.1103/PhysRevE.84.026116</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the traffic dynamics in complex networks where each link is assigned
a limited and identical bandwidth. Although the first-in-first-out (FIFO)
queuing rule is widely applied in the routing protocol of information packets,
here we argue that if we drop this rule, the overall throughput of the network
can be remarkably enhanced. We proposed some efficient routing strategies that
do not strictly obey the FIFO rule. Comparing with the routine shortest path
strategy, the throughput for both Barab\'asi-Albert (BA) networks and the real
Internet, the throughput can be improved more than five times. We calculate the
theoretical limitation of the throughput. In BA networks, our proposed strategy
can achieve 88% of the theoretical optimum, yet for the real Internet, it is
about 12%, implying that we have a huge space to further improve the routing
strategy for the real Internet. Finally we discuss possibly promising ways to
design more efficient routing strategies for the Internet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1779</identifier>
 <datestamp>2014-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1779</id><created>2011-02-08</created><updated>2014-01-07</updated><authors><author><keyname>Adam</keyname><forenames>Jared</forenames></author><author><keyname>Freden</keyname><forenames>Eric</forenames></author><author><keyname>Mishna</keyname><forenames>Marni</forenames></author></authors><title>From indexed grammars to generating functions</title><categories>math.CO cs.DM</categories><comments>23 pages, 3 figures</comments><msc-class>68Q70, 05A15</msc-class><journal-ref>RAIRO - Theor. Inf. and Applic. 47(4): 325-350 (2013)</journal-ref><doi>10.1051/ita/2013041</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We extend the Chomsky/Sch\&quot;utzenberger method of computing the growth series
of an unambiguous context-free language to the larger class of indexed
languages. We illustrate the technique with numerous examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1782</identifier>
 <datestamp>2013-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1782</id><created>2011-02-09</created><updated>2013-07-06</updated><authors><author><keyname>Prasad</keyname><forenames>K.</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>On network coding for acyclic networks with delays</title><categories>cs.IT math.IT</categories><comments>Minor updates</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Problems related to network coding for acyclic, instantaneous networks (where
the edges of the acyclic graph representing the network are assumed to have
zero-delay) have been extensively dealt with in the recent past. The most
prominent of these problems include (a) the existence of network codes that
achieve maximum rate of transmission, (b) efficient network code constructions,
and (c) field size issues. In practice, however, networks have transmission
delays. In network coding theory, such networks with transmission delays are
generally abstracted by assuming that their edges have integer delays. Note
that using enough memory at the nodes of an acyclic network with integer delays
can effectively simulate instantaneous behavior, which is probably why only
acyclic instantaneous networks have been primarily focused on thus far. In this
work, we elaborate on issues ((a), (b) and (c) above) related to network coding
for acyclic networks with integer delays, which have till now mostly been
overlooked. We show that the delays associated with the edges of the network
cannot be ignored, and in fact turn out to be advantageous, disadvantageous or
immaterial, depending on the topology of the network and the problem considered
i.e., (a), (b) or (c). In the process, we also show that for a single source
multicast problem in acyclic networks (instantaneous and with delays), the
network coding operations at each node can simply be limited to storing old
symbols and coding them over a binary field. Therefore, operations over
elements of larger fields are unnecessary in the network, the trade-off being
that enough memory exists at the nodes and at the sinks, and that the sinks
have more processing power.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1783</identifier>
 <datestamp>2011-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1783</id><created>2011-02-09</created><updated>2011-03-27</updated><authors><author><keyname>Patrascu</keyname><forenames>Mihai</forenames></author><author><keyname>Thorup</keyname><forenames>Mikkel</forenames></author></authors><title>Don't Rush into a Union: Take Time to Find Your Roots</title><categories>cs.DS cs.CC</categories><comments>To appear in STOC'11</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new threshold phenomenon in data structure lower bounds where
slightly reduced update times lead to exploding query times. Consider
incremental connectivity, letting t_u be the time to insert an edge and t_q be
the query time. For t_u = Omega(t_q), the problem is equivalent to the
well-understood union-find problem: InsertEdge(s,t) can be implemented by
Union(Find(s), Find(t)). This gives worst-case time t_u = t_q = O(lg n / lglg
n) and amortized t_u = t_q = O(alpha(n)).
  By contrast, we show that if t_u = o(lg n / lglg n), the query time explodes
to t_q &gt;= n^{1-o(1)}. In other words, if the data structure doesn't have time
to find the roots of each disjoint set (tree) during edge insertion, there is
no effective way to organize the information!
  For amortized complexity, we demonstrate a new inverse-Ackermann type
trade-off in the regime t_u = o(t_q).
  A similar lower bound is given for fully dynamic connectivity, where an
update time of o(\lg n) forces the query time to be n^{1-o(1)}. This lower
bound allows for amortization and Las Vegas randomization, and comes close to
the known O(lg n * poly(lglg n)) upper bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1789</identifier>
 <datestamp>2011-05-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1789</id><created>2011-02-09</created><authors><author><keyname>Kishore</keyname><forenames>Vimal</forenames></author><author><keyname>Santhanam</keyname><forenames>M. S.</forenames></author><author><keyname>Amritkar</keyname><forenames>R. E.</forenames></author></authors><title>Extreme events on complex networks</title><categories>cond-mat.stat-mech cs.SI physics.soc-ph</categories><comments>5 pages, 4 figures</comments><journal-ref>Phys. Rev. Lett. 106, 188701 (2011)</journal-ref><doi>10.1103/PhysRevLett.106.188701</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the extreme events taking place on complex networks. The transport
on networks is modelled using random walks and we compute the probability for
the occurance and recurrence of extreme events on the network. We show that the
nodes with smaller number of links are more prone to extreme events than the
ones with larger number of links. We obtain analytical estimates and verify
them with numerical simulations. They are shown to be robust even when random
walkers follow shortest path on the network. The results suggest a revision of
design principles and can be used as an input for designing the nodes of a
network so as to smoothly handle an extreme event.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1803</identifier>
 <datestamp>2011-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1803</id><created>2011-02-09</created><authors><author><keyname>Ahmed</keyname><forenames>Zeeshan</forenames></author></authors><title>Proposing LT based Search in PDM Systems for Better Information
  Retrieval</title><categories>cs.IR cs.AI</categories><comments>15 pages, 31 figures</comments><journal-ref>International Journal of Computer Science &amp; Emerging Technologies
  (E-ISSN: 2044-6004), Volume 1, Issue 4, P86-100, December 2010</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  PDM Systems contain and manage heavy amount of data but the search mechanism
of most of the systems is not intelligent which can process user&quot;s natural
language based queries to extract desired information. Currently available
search mechanisms in almost all of the PDM systems are not very efficient and
based on old ways of searching information by entering the relevant information
to the respective fields of search forms to find out some specific information
from attached repositories. Targeting this issue, a thorough research was
conducted in fields of PDM Systems and Language Technology. Concerning the PDM
System, conducted research provides the information about PDM and PDM Systems
in detail. Concerning the field of Language Technology, helps in implementing a
search mechanism for PDM Systems to search user&quot;s needed information by
analyzing user&quot;s natural language based requests. The accomplished goal of this
research was to support the field of PDM with a new proposition of a conceptual
model for the implementation of natural language based search. The proposed
conceptual model is successfully designed and partially implementation in the
form of a prototype. Describing the proposition in detail the main concept,
implementation designs and developed prototype of proposed approach is
discussed in this paper. Implemented prototype is compared with respective
functions of existing PDM systems .i.e., Windchill and CIM to evaluate its
effectiveness against targeted challenges.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1808</identifier>
 <datestamp>2011-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1808</id><created>2011-02-09</created><updated>2011-02-11</updated><authors><author><keyname>Bottou</keyname><forenames>Leon</forenames></author></authors><title>From Machine Learning to Machine Reasoning</title><categories>cs.AI cs.LG</categories><comments>15 pages - fix broken pagination in v2</comments><report-no>tr-2011-02-08</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A plausible definition of &quot;reasoning&quot; could be &quot;algebraically manipulating
previously acquired knowledge in order to answer a new question&quot;. This
definition covers first-order logical inference or probabilistic inference. It
also includes much simpler manipulations commonly used to build large learning
systems. For instance, we can build an optical character recognition system by
first training a character segmenter, an isolated character recognizer, and a
language model, using appropriate labeled training sets. Adequately
concatenating these modules and fine tuning the resulting system can be viewed
as an algebraic operation in a space of models. The resulting model answers a
new question, that is, converting the image of a text page into a computer
readable text.
  This observation suggests a conceptual continuity between algebraically rich
inference systems, such as logical or probabilistic inference, and simple
manipulations, such as the mere concatenation of trainable learning systems.
Therefore, instead of trying to bridge the gap between machine learning systems
and sophisticated &quot;all-purpose&quot; inference mechanisms, we can instead
algebraically enrich the set of manipulations applicable to training systems,
and build reasoning capabilities from the ground up.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1809</identifier>
 <datestamp>2011-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1809</id><created>2011-02-09</created><authors><author><keyname>Boito</keyname><forenames>Paola</forenames></author><author><keyname>Ruatta</keyname><forenames>Olivier</forenames></author></authors><title>Generalized companion matrix for approximate GCD</title><categories>cs.SC</categories><comments>Submitted to MEGA 2011</comments><msc-class>14Q20, 13P05, 68W25, 68W30</msc-class><acm-class>G.0; G.1.2; G.1.3; I.1.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a variant of the univariate approximate GCD problem, where the coe?-
cients of one polynomial f(x)are known exactly, whereas the coe?cients of the
second polynomial g(x)may be perturbed. Our approach relies on the properties
of the matrix which describes the operator of multiplication by gin the
quotient ring C[x]=(f). In particular, the structure of the null space of the
multiplication matrix contains all the essential information about GCD(f; g).
Moreover, the multiplication matrix exhibits a displacement structure that
allows us to design a fast algorithm for approximate GCD computation with
quadratic complexity w.r.t. polynomial degrees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1820</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1820</id><created>2011-02-09</created><updated>2011-02-11</updated><authors><author><keyname>Salaris</keyname><forenames>Paolo</forenames></author><author><keyname>Pallottino</keyname><forenames>Lucia</forenames></author><author><keyname>Bicchi</keyname><forenames>Antonio</forenames></author></authors><title>Optimal Synthesis for Nonholonomic Vehicles With Constrained Side
  Sensors</title><categories>cs.RO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a complete characterization of shortest paths to a goal position
for a vehicle with unicycle kinematics and a limited range sensor, constantly
keeping a given landmark in sight. Previous work on this subject studied the
optimal paths in case of a frontal, symmetrically limited Field--Of--View
(FOV). In this paper we provide a generalization to the case of arbitrary FOVs,
including the case that the direction of motion is not an axis of symmetry for
the FOV, and even that it is not contained in the FOV. The provided solution is
of particular relevance to applications using side-scanning, such as e.g. in
underwater sonar-based surveying and navigation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1859</identifier>
 <datestamp>2011-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1859</id><created>2011-02-09</created><authors><author><keyname>Levit</keyname><forenames>Vadim E.</forenames></author><author><keyname>Mandrescu</keyname><forenames>Eugen</forenames></author></authors><title>On the Structure of the Minimum Critical Independent Set of a Graph</title><categories>cs.DM math.CO</categories><comments>8 pages, 3 figures</comments><msc-class>05C69, 05C70 (Primary) 05A20(Secondary)</msc-class><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let G=(V,E). A set S is independent if no two vertices from S are adjacent.
The number d(X)= |X|-|N(X)| is the difference of X, and an independent set A is
critical if d(A) = max{d(I):I is an independent set}. Let us recall that ker(G)
is the intersection of all critical independent sets, and core(G) is the
intersection of all maximum independent sets. Recently, it was established that
ker(G) is a subset of core(G) is true for every graph, while the corresponding
equality holds for bipartite graphs. In this paper we present various
structural properties of ker(G). The main finding claims that ker(G) is equal
to the union of all inclusion minimal independent sets with positive
difference.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1889</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1889</id><created>2011-02-09</created><updated>2011-08-07</updated><authors><author><keyname>Spivak</keyname><forenames>David I.</forenames></author><author><keyname>Kent</keyname><forenames>Robert E.</forenames></author></authors><title>Ologs: a categorical framework for knowledge representation</title><categories>cs.LO cs.AI math.CT</categories><comments>38 pages</comments><msc-class>00-01, 18-01, 68P20, 68T30</msc-class><acm-class>H.2.1; H.5.2</acm-class><doi>10.1371/journal.pone.0024274</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In this paper we introduce the olog, or ontology log, a category-theoretic
model for knowledge representation (KR). Grounded in formal mathematics, ologs
can be rigorously formulated and cross-compared in ways that other KR models
(such as semantic networks) cannot. An olog is similar to a relational database
schema; in fact an olog can serve as a data repository if desired. Unlike
database schemas, which are generally difficult to create or modify, ologs are
designed to be user-friendly enough that authoring or reconfiguring an olog is
a matter of course rather than a difficult chore. It is hoped that learning to
author ologs is much simpler than learning a database definition language,
despite their similarity. We describe ologs carefully and illustrate with many
examples. As an application we show that any primitive recursive function can
be described by an olog. We also show that ologs can be aligned or connected
together into a larger network using functors. The various methods of
information flow and institutions can then be used to integrate local and
global world-views. We finish by providing several different avenues for future
research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1929</identifier>
 <datestamp>2011-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1929</id><created>2011-02-09</created><updated>2011-12-18</updated><authors><author><keyname>Schneider</keyname><forenames>Christian M.</forenames></author><author><keyname>Mihaljev</keyname><forenames>Tamara</forenames></author><author><keyname>Havlin</keyname><forenames>Shlomo</forenames></author><author><keyname>Herrmann</keyname><forenames>Hans J.</forenames></author></authors><title>Suppressing Epidemics with a Limited Amount of Immunization Units</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><comments>7 pages, 6 figures</comments><journal-ref>Phys. Rev. E 84, 061911 (2011)</journal-ref><doi>10.1103/PhysRevE.84.061911</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The way diseases spread through schools, epidemics through countries, and
viruses through the Internet is crucial in determining their risk. Although
each of these threats has its own characteristics, its underlying network
determines the spreading. To restrain the spreading, a widely used approach is
the fragmentation of these networks through immunization, so that epidemics
cannot spread. Here we develop an immunization approach based on optimizing the
susceptible size, which outperforms the best known strategy based on immunizing
the highest-betweenness links or nodes. We find that the network's
vulnerability can be significantly reduced, demonstrating this on three
different real networks: the global flight network, a school friendship
network, and the internet. In all cases, we find that not only is the average
infection probability significantly suppressed, but also for the most relevant
case of a small and limited number of immunization units the infection
probability can be reduced by up to 55%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1934</identifier>
 <datestamp>2011-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1934</id><created>2011-02-09</created><updated>2011-07-20</updated><authors><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author><author><keyname>Hammarfelt</keyname><forenames>Bj&#xf6;rn</forenames></author><author><keyname>Salah</keyname><forenames>Alkim Almila Akdag</forenames></author></authors><title>The structure of the Arts &amp; Humanities Citation Index: A mapping on the
  basis of aggregated citations among 1,157 journals</title><categories>cs.DL physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using the Arts &amp; Humanities Citation Index (A&amp;HCI) 2008, we apply mapping
techniques previously developed for mapping journal structures in the Science
and Social Science Citation Indices. Citation relations among the 110,718
records were aggregated at the level of 1,157 journals specific to the A&amp;HCI,
and the journal structures are questioned on whether a cognitive structure can
be reconstructed and visualized. Both cosine-normalization (bottom up) and
factor analysis (top down) suggest a division into approximately twelve
subsets. The relations among these subsets are explored using various
visualization techniques. However, we were not able to retrieve this structure
using the ISI Subject Categories, including the 25 categories which are
specific to the A&amp;HCI. We discuss options for validation such as against the
categories of the Humanities Indicators of the American Academy of Arts and
Sciences, the panel structure of the European Reference Index for the
Humanities (ERIH), and compare our results with the curriculum organization of
the Humanities Section of the College of Letters and Sciences of UCLA as an
example of institutional organization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1935</identifier>
 <datestamp>2011-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1935</id><created>2011-02-09</created><authors><author><keyname>Majkic</keyname><forenames>Zoran</forenames></author></authors><title>On Paraconsistent Weakening of Intuitionistic Negation</title><categories>cs.LO</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In [1], systems of weakening of intuitionistic negation logic called Z_n and
CZ_n were developed in the spirit of da Costa's approach(c.f. [2]) by
preserving, differently from da Costa, its fundamental properties:
antitonicity, inversion and additivity for distributive lattices. However,
according to [3], those systems turned out to be not paraconsistent but
extensions of intuitionistic logic. Taking into account of this result, we
shall here make some observations on the modified systems of Z_n and CZ_n, that
are paraconsistent as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1959</identifier>
 <datestamp>2011-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1959</id><created>2011-02-09</created><updated>2011-02-10</updated><authors><author><keyname>Hong</keyname><forenames>Mingyi</forenames></author><author><keyname>Garcia</keyname><forenames>Alfredo</forenames></author><author><keyname>Wilson</keyname><forenames>Stephen</forenames></author></authors><title>Distributed Uplink Resource Allocation in Cognitive Radio Networks --
  Part I: Equilibria and Algorithms for Power Allocation</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Signal Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spectrum management has been identified as a crucial step towards enabling
the technology of a cognitive radio network (CRN). Most of the current works
dealing with spectrum management in the CRN focus on a single task of the
problem, e.g., spectrum sensing, spectrum decision, spectrum sharing or
spectrum mobility. In this two-part paper, we argue that for certain network
configurations, jointly performing several tasks of the spectrum management
improves the spectrum efficiency. Specifically, our aim is to study the uplink
resource management problem in a CRN where there exist multiple cognitive users
(CUs) and access points (APs). The CUs, in order to maximize their uplink
transmission rates, have to associate to a suitable AP (spectrum decision), and
to share the channels used by this AP with other CUs (spectrum sharing). These
tasks are clearly interdependent, and the problem of how they should be carried
out efficiently and in a distributed manner is still open in the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1960</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1960</id><created>2011-02-09</created><authors><author><keyname>Hong</keyname><forenames>Mingyi</forenames></author><author><keyname>Garcia</keyname><forenames>Alfredo</forenames></author></authors><title>Averaged Iterative Water-Filling Algorithm: Robustness and Convergence</title><categories>cs.IT math.IT</categories><doi>10.1109/TSP.2011.2113341</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The convergence properties of the Iterative water-filling (IWF) based
algorithms have been derived in the ideal situation where the transmitters in
the network are able to obtain the exact value of the interference plus noise
(IPN) experienced at the corresponding receivers in each iteration of the
algorithm. However, these algorithms are not robust because they diverge when
there is it time-varying estimation error of the IPN, a situation that arises
in real communication system. In this correspondence, we propose an algorithm
that possesses convergence guarantees in the presence of various forms of such
time-varying error. Moreover, we also show by simulation that in scenarios
where the interference is strong, the conventional IWF diverges while our
proposed algorithm still converges.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1963</identifier>
 <datestamp>2011-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1963</id><created>2011-02-09</created><authors><author><keyname>Guha</keyname><forenames>Saikat</forenames></author><author><keyname>Dutton</keyname><forenames>Zachary</forenames></author><author><keyname>Shapiro</keyname><forenames>Jeffrey H.</forenames></author></authors><title>On quantum limit of optical communications: concatenated codes and
  joint-detection receivers</title><categories>quant-ph cs.IT math.IT</categories><comments>5 pages, 7 figures, submitted to IEEE International Symposium on
  Information Theory (ISIT), 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When classical information is sent over a channel with quantum-state
modulation alphabet, such as the free-space optical (FSO) channel, attaining
the ultimate (Holevo) limit to channel capacity requires the receiver to make
joint measurements over long codeword blocks. In recent work, we showed a
receiver for a pure-state channel that can attain the ultimate capacity by
applying a single-shot optical (unitary) transformation on the received
codeword state followed by simultaneous (but separable) projective measurements
on the single-modulation-symbol state spaces. In this paper, we study the
ultimate tradeoff between photon efficiency and spectral efficiency for the FSO
channel. Based on our general results for the pure-state quantum channel, we
show some of the first concrete examples of codes and laboratory-realizable
joint-detection optical receivers that can achieve fundamentally higher
(superadditive) channel capacity than receivers that physically detect each
modulation symbol one at a time, as is done by all conventional (coherent or
direct-detection) optical receivers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1965</identifier>
 <datestamp>2011-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1965</id><created>2011-02-09</created><updated>2011-02-10</updated><authors><author><keyname>Hong</keyname><forenames>Mingyi</forenames></author><author><keyname>Garcia</keyname><forenames>Alfredo</forenames></author><author><keyname>Barrera</keyname><forenames>Jorge</forenames></author></authors><title>Distributed Uplink Resource Allocation in Cognitive Radio Networks --
  Part II: Equilibria and Algorithms for Joint Access Point Selection and Power
  Allocation</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Signal Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the first part of this paper, we have studied solely the spectrum sharing
aspect of the above problem, and proposed algorithms for the CUs in the single
AP network to efficiently share the spectrum. In this second part of the paper,
we build upon our previous understanding of the single AP network, and
formulate the joint spectrum decision and spectrum sharing problem in a
multiple AP network into a non-cooperative game, in which the feasible strategy
of a player contains a discrete variable (the AP/spectrum decision) and a
continuous vector (the power allocation among multiple channels). The structure
of the game is hence very different from most non-cooperative spectrum
management game proposed in the literature. We provide characterization of the
Nash Equilibrium (NE) of this game, and present a set of novel algorithms that
allow the CUs to distributively and efficiently select the suitable AP and
share the channels with other CUs. Finally, we study the properties of the
proposed algorithms as well as their performance via extensive simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1985</identifier>
 <datestamp>2011-04-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1985</id><created>2011-02-09</created><updated>2011-04-01</updated><authors><author><keyname>Steeg</keyname><forenames>Greg Ver</forenames></author><author><keyname>Ghosh</keyname><forenames>Rumi</forenames></author><author><keyname>Lerman</keyname><forenames>Kristina</forenames></author></authors><title>What Stops Social Epidemics?</title><categories>cs.SI physics.soc-ph</categories><comments>8 pages, 10 figures, accepted in ICWSM11</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Theoretical progress in understanding the dynamics of spreading processes on
graphs suggests the existence of an epidemic threshold below which no epidemics
form and above which epidemics spread to a significant fraction of the graph.
We have observed information cascades on the social media site Digg that spread
fast enough for one initial spreader to infect hundreds of people, yet end up
affecting only 0.1% of the entire network. We find that two effects, previously
studied in isolation, combine cooperatively to drastically limit the final size
of cascades on Digg. First, because of the highly clustered structure of the
Digg network, most people who are aware of a story have been exposed to it via
multiple friends. This structure lowers the epidemic threshold while moderately
slowing the overall growth of cascades. In addition, we find that the mechanism
for social contagion on Digg points to a fundamental difference between
information spread and other contagion processes: despite multiple
opportunities for infection within a social group, people are less likely to
become spreaders of information with repeated exposure. The consequences of
this mechanism become more pronounced for more clustered graphs. Ultimately,
this effect severely curtails the size of social epidemics on Digg.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2003</identifier>
 <datestamp>2011-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2003</id><created>2011-02-09</created><updated>2011-02-11</updated><authors><author><keyname>Stansifer</keyname><forenames>Paul</forenames></author><author><keyname>Wand</keyname><forenames>Mitchell</forenames></author></authors><title>Parsing Reflective Grammars</title><categories>cs.PL</categories><comments>A shorter version appears in LDTA 2011</comments><acm-class>D.3.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Existing technology can parse arbitrary context-free grammars, but only a
single, static grammar per input. In order to support more powerful
syntax-extension systems, we propose reflective grammars, which can modify
their own syntax during parsing. We demonstrate and prove the correctness of an
algorithm for parsing reflective grammars. The algorithm is based on Earley's
algorithm, and we prove that it performs asymptotically no worse than Earley's
algorithm on ordinary context-free grammars.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2008</identifier>
 <datestamp>2012-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2008</id><created>2011-02-09</created><updated>2012-12-22</updated><authors><author><keyname>Ezra</keyname><forenames>Esther</forenames></author><author><keyname>Mulzer</keyname><forenames>Wolfgang</forenames></author></authors><title>Convex Hull of Points Lying on Lines in o(n log n) Time after
  Preprocessing</title><categories>cs.CG</categories><comments>26 pages, 5 figures, 1 appendix; a preliminary version appeared at
  SoCG 2011</comments><acm-class>F.2.2</acm-class><journal-ref>Computational Geometry: Theory and Applications (CGTA), 46(4),
  2013, pp. 417-434</journal-ref><doi>10.1016/j.comgeo.2012.03.004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by the desire to cope with data imprecision, we study methods for
taking advantage of preliminary information about point sets in order to speed
up the computation of certain structures associated with them.
  In particular, we study the following problem: given a set L of n lines in
the plane, we wish to preprocess L such that later, upon receiving a set P of n
points, each of which lies on a distinct line of L, we can construct the convex
hull of P efficiently. We show that in quadratic time and space it is possible
to construct a data structure on L that enables us to compute the convex hull
of any such point set P in O(n alpha(n) log* n) expected time. If we further
assume that the points are &quot;oblivious&quot; with respect to the data structure, the
running time improves to O(n alpha(n)). The analysis applies almost verbatim
when L is a set of line-segments, and yields similar asymptotic bounds. We
present several extensions, including a trade-off between space and query time
and an output-sensitive algorithm. We also study the &quot;dual problem&quot; where we
show how to efficiently compute the (&lt;= k)-level of n lines in the plane, each
of which lies on a distinct point (given in advance).
  We complement our results by Omega(n log n) lower bounds under the algebraic
computation tree model for several related problems, including sorting a set of
points (according to, say, their x-order), each of which lies on a given line
known in advance. Therefore, the convex hull problem under our setting is
easier than sorting, contrary to the &quot;standard&quot; convex hull and sorting
problems, in which the two problems require Theta(n log n) steps in the worst
case (under the algebraic computation tree model).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2017</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2017</id><created>2011-02-09</created><updated>2011-06-17</updated><authors><author><keyname>Penunuri</keyname><forenames>F.</forenames></author><author><keyname>Peon-Escalante</keyname><forenames>R.</forenames></author><author><keyname>Villanueva</keyname><forenames>C.</forenames></author><author><keyname>Pech-Oy</keyname><forenames>D.</forenames></author></authors><title>Synthesis of Mechanism for single- and hybrid-tasks using Differential
  Evolution</title><categories>cs.CE</categories><comments>Final version accepted in Mechanism and Machine Theory</comments><journal-ref>Mechanism and Machine Theory 46 (2011) 1335--1349</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The optimal dimensional synthesis for planar mechanisms using differential
evolution (DE) is demonstrated. Four examples are included: in the first case,
the synthesis of a mechanism for hybrid-tasks, considering path generation,
function generation, and motion generation, is carried out. The second and
third cases pertain to path generation, with and without prescribed timing.
Finally, the synthesis of an Ackerman mechanism is reported. Order defect
problem is solved by manipulating individuals instead of penalizing or
discretizing the search space for the parameters. A technique that consists in
applying a transformation in order to satisfy the Grashof and crank conditions
to generate an initial elitist population is introduced. As a result, the
evolutionary algorithm increases its efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2035</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2035</id><created>2011-02-10</created><authors><author><keyname>Schwartz</keyname><forenames>Moshe</forenames></author></authors><title>Quasi-Cross Lattice Tilings with Applications to Flash Memory</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider lattice tilings of $\R^n$ by a shape we call a
$(\kp,\km,n)$-quasi-cross. Such lattices form perfect error-correcting codes
which correct a single limited-magnitude error with prescribed
maximal-magnitudes of positive error and negative error (the ratio of which is
called the balance ratio). These codes can be used to correct both disturb and
retention errors in flash memories, which are characterized by having limited
magnitudes and different signs.
  We construct infinite families of perfect codes for any rational balance
ratio, and provide a specific construction for $(2,1,n)$-quasi-cross lattice
tiling. The constructions are related to group splitting and modular $B_1$
sequences. We also study bounds on the parameters of lattice-tilings by
quasi-crosses, connecting the arm lengths of the quasi-crosses and the
dimension. We also prove constraints on group splitting, a specific case of
which shows that the parameters of the lattice tiling of
$(2,1,n)$-quasi-crosses is the only ones possible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2041</identifier>
 <datestamp>2011-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2041</id><created>2011-02-10</created><updated>2011-10-11</updated><authors><author><keyname>Antos</keyname><forenames>Andr&#xe1;s</forenames></author><author><keyname>Bart&#xf3;k</keyname><forenames>G&#xe1;bor</forenames></author><author><keyname>P&#xe1;l</keyname><forenames>D&#xe1;vid</forenames></author><author><keyname>Szepesv&#xe1;ri</keyname><forenames>Csaba</forenames></author></authors><title>Toward a Classification of Finite Partial-Monitoring Games</title><categories>cs.GT stat.ML</categories><comments>Submitted for review to Theoretical Computer Science (Special Issue
  of the conference Algorithmic Learning Theory 2010)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Partial-monitoring games constitute a mathematical framework for sequential
decision making problems with imperfect feedback: The learner repeatedly
chooses an action, opponent responds with an outcome, and then the learner
suffers a loss and receives a feedback signal, both of which are fixed
functions of the action and the outcome. The goal of the learner is to minimize
his total cumulative loss. We make progress towards the classification of these
games based on their minimax expected regret. Namely, we classify almost all
games with two outcomes and finite number of actions: We show that their
minimax expected regret is either zero, $\widetilde{\Theta}(\sqrt{T})$,
$\Theta(T^{2/3})$, or $\Theta(T)$ and we give a simple and efficiently
computable classification of these four classes of games. Our hope is that the
result can serve as a stepping stone toward classifying all finite
partial-monitoring games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2075</identifier>
 <datestamp>2011-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2075</id><created>2011-02-10</created><authors><author><keyname>Maier</keyname><forenames>Markus</forenames></author><author><keyname>von Luxburg</keyname><forenames>Ulrike</forenames></author><author><keyname>Hein</keyname><forenames>Matthias</forenames></author></authors><title>How the result of graph clustering methods depends on the construction
  of the graph</title><categories>stat.ML cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the scenario of graph-based clustering algorithms such as spectral
clustering. Given a set of data points, one first has to construct a graph on
the data points and then apply a graph clustering algorithm to find a suitable
partition of the graph. Our main question is if and how the construction of the
graph (choice of the graph, choice of parameters, choice of weights) influences
the outcome of the final clustering result. To this end we study the
convergence of cluster quality measures such as the normalized cut or the
Cheeger cut on various kinds of random geometric graphs as the sample size
tends to infinity. It turns out that the limit values of the same objective
function are systematically different on different types of graphs. This
implies that clustering results systematically depend on the graph and can be
very different for different types of graph. We provide examples to illustrate
the implications on spectral clustering.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2079</identifier>
 <datestamp>2011-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2079</id><created>2011-02-10</created><authors><author><keyname>Jansen</keyname><forenames>David N.</forenames><affiliation>Radboud Universiteit Nijmegen, The Netherlands</affiliation></author></authors><title>Erratum to: Model-checking continuous-time Markov chains by Aziz et al</title><categories>cs.LO</categories><msc-class>03B44</msc-class><acm-class>F.3.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This note corrects a discrepancy between the semantics and the algorithm of
the multiple until operator of CSL, like in Pr_{&gt; 0.0025} (a until[1,2] b
until[3,4] c), of the article: Model-checking continuous-time Markov chains by
Aziz, Sanwal, Singhal and Brayton, TOCL 1(1), July 2000, pp. 162-170.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2091</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2091</id><created>2011-02-10</created><authors><author><keyname>Klimek</keyname><forenames>Peter</forenames></author><author><keyname>Bayer</keyname><forenames>Werner</forenames></author><author><keyname>Thurner</keyname><forenames>Stefan</forenames></author></authors><title>The blogosphere as an excitable social medium: Richter's and Omori's Law
  in media coverage</title><categories>physics.soc-ph cs.SI</categories><comments>4 pages, 4 figures</comments><doi>10.1016/j.physa.2011.05.033</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the dynamics of public media attention by monitoring the content of
online blogs. Social and media events can be traced by the propagation of word
frequencies of related keywords. Media events are classified as exogenous -
where blogging activity is triggered by an external news item - or endogenous
where word frequencies build up within a blogging community without external
influences. We show that word occurrences show statistical similarities to
earthquakes. The size distribution of media events follows a Gutenberg-Richter
law, the dynamics of media attention before and after the media event follows
Omori's law. We present further empirical evidence that for media events of
endogenous origin the overall public reception of the event is correlated with
the behavior of word frequencies at the beginning of the event, and is to a
certain degree predictable. These results may imply that the process of opinion
formation in a human society might be related to effects known from excitable
media.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2094</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2094</id><created>2011-02-10</created><authors><author><keyname>Nelis</keyname><forenames>Vincent</forenames><affiliation>CISTER Research unit Polytechnic Institute of Porto</affiliation></author><author><keyname>Yomsi</keyname><forenames>Patrick Meumeu</forenames><affiliation>LORIA</affiliation></author><author><keyname>Andersson</keyname><forenames>Bj&#xf6;rn</forenames><affiliation>CISTER Research unit Polytechnic Institute of Porto</affiliation></author><author><keyname>Goossens</keyname><forenames>Jo&#xeb;l</forenames><affiliation>U.L.B</affiliation></author></authors><title>Global Scheduling of Multi-Mode Real-Time Applications upon
  Multiprocessor Platforms</title><categories>cs.OS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-mode real-time systems are those which support applications with
different modes of operation, where each mode is characterized by a specific
set of tasks. At run-time, such systems can, at any time, be requested to
switch from its current operating mode to another mode (called &quot;new mode&quot;) by
replacing the current set of tasks with that of the new-mode. Thereby, ensuring
that all the timing requirements are met not only requires that a
schedulability test is performed on the tasks of each mode but also that (i) a
protocol for transitioning from one mode to another is specified and (ii) a
schedulability test for each transition is performed. We propose two distinct
protocols that manage the mode transitions upon uniform and identical
multiprocessor platforms at run-time, each specific to distinct task
requirements. For each protocol, we formally establish schedulability analyses
that indicate beforehand whether all the timing requirements will be met during
any mode transition of the system. This is performed assuming both
Fixed-Task-Priority and Fixed-Job-Priority schedulers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2095</identifier>
 <datestamp>2012-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2095</id><created>2011-02-10</created><updated>2012-01-31</updated><authors><author><keyname>Gu</keyname><forenames>Xiaoyang</forenames></author><author><keyname>Lutz</keyname><forenames>Jack H.</forenames></author><author><keyname>Nandakumar</keyname><forenames>Satyadev</forenames></author><author><keyname>Royer</keyname><forenames>James S.</forenames></author></authors><title>Axiomatizing Resource Bounds for Measure</title><categories>cs.CC cs.LO</categories><comments>Changed one reference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Resource-bounded measure is a generalization of classical Lebesgue measure
that is useful in computational complexity. The central parameter of
resource-bounded measure is the {\it resource bound} $\Delta$, which is a class
of functions. When $\Delta$ is unrestricted, i.e., contains all functions with
the specified domains and codomains, resource-bounded measure coincides with
classical Lebesgue measure. On the other hand, when $\Delta$ contains functions
satisfying some complexity constraint, resource-bounded measure imposes
internal measure structure on a corresponding complexity class.
  Most applications of resource-bounded measure use only the
&quot;measure-zero/measure-one fragment&quot; of the theory. For this fragment, $\Delta$
can be taken to be a class of type-one functions (e.g., from strings to
rationals). However, in the full theory of resource-bounded measurability and
measure, the resource bound $\Delta$ also contains type-two functionals. To
date, both the full theory and its zero-one fragment have been developed in
terms of a list of example resource bounds chosen for their apparent utility.
  This paper replaces this list-of-examples approach with a careful
investigation of the conditions that suffice for a class $\Delta$ to be a
resource bound. Our main theorem says that every class $\Delta$ that has the
closure properties of Mehlhorn's basic feasible functionals is a resource bound
for measure.
  We also prove that the type-2 versions of the time and space hierarchies that
have been extensively used in resource-bounded measure have these closure
properties. In the course of doing this, we prove theorems establishing that
these time and space resource bounds are all robust.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2114</identifier>
 <datestamp>2011-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2114</id><created>2011-02-10</created><updated>2011-02-17</updated><authors><author><keyname>Jain</keyname><forenames>Pooja</forenames></author><author><keyname>Dahiya</keyname><forenames>Deepak</forenames></author></authors><title>Knowledge Management System Design using Extended Gaia</title><categories>cs.MA</categories><comments>This paper has been withdrawn by the authors</comments><journal-ref>International Journal of Computer Networks &amp; Communications
  (IJCNC), Vol. 3, No. 1, January 2011</journal-ref><doi>10.5121/ijcnc.2011.3109</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An efficient Learning resource centre can be achieved with the help of a
network of collaborating, coordinating and communicating software agents.
Agent-oriented techniques represent an exciting new means of analysing,
designing and building complex software systems. The designing of the
interacting agents is done with the help of Gaia, extended for the multiagent
systems. Gaia is a methodology for agent-oriented analysis and design proposed
by M. Wooldridge [9].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2122</identifier>
 <datestamp>2011-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2122</id><created>2011-02-10</created><authors><author><keyname>Leducq</keyname><forenames>Elodie</forenames></author></authors><title>On the covering radius of first order generalized Reed-Muller codes</title><categories>math.NT cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We generalize to any q a theorem about covering radius of linear codes proved
by Helleseth, Klove and Mykkelvit. Then we determine the covering radius of
first order generalized Reed-Muller codes in second order generalized
Reed-Muller codes. Using these results, we are able to give bounds for the
covering radius of first order generalized Reed-Muller codes. Finaly, using
Magma, we get some improvements for q=3.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2125</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2125</id><created>2011-02-10</created><authors><author><keyname>Balduccini</keyname><forenames>Marcello</forenames></author></authors><title>Improving DPLL Solver Performance with Domain-Specific Heuristics: the
  ASP Case</title><categories>cs.AI cs.LO</categories><comments>Presented at the ASPOCP10 workshop of ICLP10</comments><msc-class>68N17</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In spite of the recent improvements in the performance of the solvers based
on the DPLL procedure, it is still possible for the search algorithm to focus
on the wrong areas of the search space, preventing the solver from returning a
solution in an acceptable amount of time. This prospect is a real concern e.g.
in an industrial setting, where users typically expect consistent performance.
To overcome this problem, we propose a framework that allows learning and using
domain-specific heuristics in solvers based on the DPLL procedure. The learning
is done off-line, on representative instances from the target domain, and the
learned heuristics are then used for choice-point selection. In this paper we
focus on Answer Set Programming (ASP) solvers. In our experiments, the
introduction of domain-specific heuristics improved performance on hard
instances by up to 3 orders of magnitude (and 2 on average), nearly completely
eliminating the cases in which the solver had to be terminated because the wait
for an answer had become unacceptable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2131</identifier>
 <datestamp>2011-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2131</id><created>2011-02-10</created><updated>2011-02-17</updated><authors><author><keyname>Batra</keyname><forenames>Usha</forenames></author><author><keyname>Dahiya</keyname><forenames>Deepak</forenames></author><author><keyname>Bhardwaj</keyname><forenames>Sachin</forenames></author></authors><title>Analytical Study of Object Components for Distributed and Ubiquitous
  Computing Environment</title><categories>cs.DC</categories><comments>This paper has been withdrawn by the authors</comments><journal-ref>WSEAS TRANSACTIONS on INFORMATION SCIENCE &amp; APPLICATIONS, Issue 6,
  Volume 5, June 2008, ISSN: 1790-0832</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Distributed object computing is a paradigm that allows objects to be
distributed across a heterogeneous network, and allows each of the components
to interoperate as a unified whole. A new generation of distributed
applications, such as telemedicine and e-commerce applications, are being
deployed in heterogeneous and ubiquitous computing environments. The objective
of this paper is to explore an applicability of a component based services in
ubiquitous computational environment. While the fundamental structure of
various distributed object components is similar, there are differences that
can profoundly impact an application developer or the administrator of a
distributed simulation exercise and to implement in Ubiquitous Computing
Environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2134</identifier>
 <datestamp>2014-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2134</id><created>2011-02-10</created><updated>2014-07-08</updated><authors><author><keyname>Kant&#xe9;</keyname><forenames>Mamadou Moustapha</forenames></author></authors><title>Well-Quasi-Ordering of Matrices under Schur Complement and Applications
  to Directed Graphs</title><categories>math.CO cs.DM</categories><comments>35 pages. Revised version with a section for directed graphs</comments><msc-class>68R05, 68R10, 05C22, 05C50, 05C75</msc-class><acm-class>F.0; G.2.1; G.2.2</acm-class><journal-ref>European Journal of Combinatorics 33(8):1820--1841(2012)</journal-ref><doi>10.1016/j.ejc.2012.03.034</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In [Rank-Width and Well-Quasi-Ordering of Skew-Symmetric or Symmetric
Matrices, arXiv:1007.3807v1] Oum proved that, for a fixed finite field
$\mathbf{F}$, any infinite sequence $M_1,M_2,...$ of (skew) symmetric matrices
over $\mathbf{F}$ of bounded $\mathbf{F}$-rank-width has a pair $i&lt; j$, such
that $M_i$ is isomorphic to a principal submatrix of a principal pivot
transform of $M_j$. We generalise this result to $\sigma$-symmetric matrices
introduced by Rao and myself in [The Rank-Width of Edge-Coloured Graphs,
arXiv:0709.1433v4]. (Skew) symmetric matrices are special cases of
$\sigma$-symmetric matrices. As a by-product, we obtain that for every infinite
sequence $G_1,G_2,...$ of directed graphs of bounded rank-width there exist a
pair $i&lt;j$ such that $G_i$ is a pivot-minor of $G_j$. Another consequence is
that non-singular principal submatrices of a $\sigma$-symmetric matrix form a
delta-matroid. We extend in this way the notion of representability of
delta-matroids by Bouchet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2166</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2166</id><created>2011-02-10</created><authors><author><keyname>Traud</keyname><forenames>Amanda L.</forenames></author><author><keyname>Mucha</keyname><forenames>Peter J.</forenames></author><author><keyname>Porter</keyname><forenames>Mason A.</forenames></author></authors><title>Social Structure of Facebook Networks</title><categories>cs.SI nlin.AO physics.soc-ph</categories><comments>82 pages (including many pages of tables), 8 multi-part figures,
  &quot;Facebook100&quot; data used in this paper is publicly available at
  http://people.maths.ox.ac.uk/~porterm/data/facebook100.zip</comments><doi>10.1016/j.physa.2011.12.021</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the social structure of Facebook &quot;friendship&quot; networks at one
hundred American colleges and universities at a single point in time, and we
examine the roles of user attributes - gender, class year, major, high school,
and residence - at these institutions. We investigate the influence of common
attributes at the dyad level in terms of assortativity coefficients and
regression models. We then examine larger-scale groupings by detecting
communities algorithmically and comparing them to network partitions based on
the user characteristics. We thereby compare the relative importances of
different characteristics at different institutions, finding for example that
common high school is more important to the social organization of large
institutions and that the importance of common major varies significantly
between institutions. Our calculations illustrate how microscopic and
macroscopic perspectives give complementary insights on the social organization
at universities and suggest future studies to investigate such phenomena
further.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2174</identifier>
 <datestamp>2011-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2174</id><created>2011-02-10</created><updated>2011-04-19</updated><authors><author><keyname>Aravantinos</keyname><forenames>Vincent</forenames></author><author><keyname>Caferra</keyname><forenames>Ricardo</forenames></author><author><keyname>Peltier</keyname><forenames>Nicolas</forenames></author></authors><title>Linear Temporal Logic and Propositional Schemata, Back and Forth
  (extended version)</title><categories>cs.LO cs.AI</categories><comments>Extended version of a paper submitted at TIME 2011: contains proofs,
  additional examples &amp; figures, additional comparison between classical
  LTL/schemata algorithms up to the provided translations, and an example of
  how to do model checking with schemata; 36 pages, 8 figures</comments><msc-class>03B35, 68T15, 68T27</msc-class><acm-class>I.2.3; F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper relates the well-known Linear Temporal Logic with the logic of
propositional schemata introduced by the authors. We prove that LTL is
equivalent to a class of schemata in the sense that polynomial-time reductions
exist from one logic to the other. Some consequences about complexity are
given. We report about first experiments and the consequences about possible
improvements in existing implementations are analyzed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2176</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2176</id><created>2011-02-10</created><authors><author><keyname>Hong</keyname><forenames>Mingyi</forenames></author><author><keyname>Garcia</keyname><forenames>Alfredo</forenames></author><author><keyname>Alviar</keyname><forenames>Jorge</forenames></author></authors><title>Joint Distributed Access Point Selection and Power Allocation in
  Cognitive Radio Networks</title><categories>cs.IT math.IT</categories><comments>Accepted by Infocom 2011; Infocom 2011, The 30th IEEE International
  Conference on Computer Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spectrum management has been identified as a crucial step towards enabling
the technology of the cognitive radio network (CRN). Most of the current works
dealing with spectrum management in the CRN focus on a single task of the
problem, e.g., spectrum sensing, spectrum decision, spectrum sharing or
spectrum mobility. In this work, we argue that for certain network
configurations, jointly performing several tasks of the spectrum management
improves the spectrum efficiency. Specifically, we study the uplink resource
management problem in a CRN where there exist multiple cognitive users (CUs)
and access points (APs), with each AP operates on a set of non-overlapping
channels. The CUs, in order to maximize their uplink transmission rates, have
to associate to a suitable AP (spectrum decision), and to share the channels
belong to this AP with other CUs (spectrum sharing). These tasks are clearly
interdependent, and the problem of how they should be carried out efficiently
and distributedly is still open in the literature.
  In this work we formulate this joint spectrum decision and spectrum sharing
problem into a non-cooperative game, in which the feasible strategy of a player
contains a discrete variable and a continuous vector. The structure of the game
is hence very different from most non-cooperative spectrum management game
proposed in the literature. We provide characterization of the Nash Equilibrium
(NE) of this game, and present a set of novel algorithms that allow the CUs to
distributively and efficiently select the suitable AP and share the channels
with other CUs. Finally, we study the properties of the proposed algorithms as
well as their performance via extensive simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2180</identifier>
 <datestamp>2011-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2180</id><created>2011-02-10</created><updated>2011-02-13</updated><authors><author><keyname>Serva</keyname><forenames>M.</forenames></author><author><keyname>Petroni</keyname><forenames>F.</forenames></author><author><keyname>Volchenkov</keyname><forenames>D.</forenames></author><author><keyname>Wichmann</keyname><forenames>S.</forenames></author></authors><title>Malagasy Dialects and the Peopling of Madagascar</title><categories>cs.CL physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The origin of Malagasy DNA is half African and half Indonesian, nevertheless
the Malagasy language, spoken by the entire population, belongs to the
Austronesian family. The language most closely related to Malagasy is Maanyan
(Greater Barito East group of the Austronesian family), but related languages
are also in Sulawesi, Malaysia and Sumatra. For this reason, and because
Maanyan is spoken by a population which lives along the Barito river in
Kalimantan and which does not possess the necessary skill for long maritime
navigation, the ethnic composition of the Indonesian colonizers is still
unclear.
  There is a general consensus that Indonesian sailors reached Madagascar by a
maritime trek, but the time, the path and the landing area of the first
colonization are all disputed. In this research we try to answer these problems
together with other ones, such as the historical configuration of Malagasy
dialects, by types of analysis related to lexicostatistics and glottochronology
which draw upon the automated method recently proposed by the authors
\cite{Serva:2008, Holman:2008, Petroni:2008, Bakker:2009}. The data were
collected by the first author at the beginning of 2010 with the invaluable help
of Joselin\`a Soafara N\'er\'e and consist of Swadesh lists of 200 items for 23
dialects covering all areas of the Island.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2203</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2203</id><created>2011-02-10</created><authors><author><keyname>Abrunheiro</keyname><forenames>L.</forenames></author><author><keyname>Camarinha</keyname><forenames>M.</forenames></author><author><keyname>Cari&#xf1;ena</keyname><forenames>J. F.</forenames></author><author><keyname>Clemente-Gallardo</keyname><forenames>J.</forenames></author><author><keyname>Mart&#xed;nez</keyname><forenames>E.</forenames></author><author><keyname>Santos</keyname><forenames>P.</forenames></author></authors><title>Some applications of quasi-velocities in optimal control</title><categories>math.OC cs.SY math-ph math.MP</categories><comments>Revtex 4.1, 20 pages. To appear in Int. J. Geom. Meth. Modern Physics</comments><journal-ref>International Journal of Geometric Methods in Modern Physics 8(4)
  835-851, 2011</journal-ref><doi>10.1142/S0219887811005427</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study optimal control problems for nonholonomic systems
defined on Lie algebroids by using quasi-velocities. We consider both
kinematic, i.e. systems whose cost functional depends only on position and
velocities, and dynamic optimal control problems, i.e. systems whose cost
functional depends also on accelerations. The formulation of the problem
directly at the level of Lie algebroids turns out to be the correct framework
to explain in detail similar results appeared recently (Maruskin and Bloch,
2007). We also provide several examples to illustrate our construction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2207</identifier>
 <datestamp>2011-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2207</id><created>2011-02-10</created><authors><author><keyname>Charalambous</keyname><forenames>Charalambos D.</forenames></author><author><keyname>Charalambous</keyname><forenames>Themistoklis</forenames></author><author><keyname>Rezaei</keyname><forenames>Farzad</forenames></author></authors><title>Lossless Coding with Generalised Criteria</title><categories>cs.IT math.IT</categories><comments>6 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents prefix codes which minimize various criteria constructed
as a convex combination of maximum codeword length and average codeword length
or maximum redundancy and average redundancy, including a convex combination of
the average of an exponential function of the codeword length and the average
redundancy. This framework encompasses as a special case several criteria
previously investigated in the literature, while relations to universal coding
is discussed. The coding algorithm derived is parametric resulting in
re-adjusting the initial source probabilities via a weighted probability vector
according to a merging rule. The level of desirable merging has implication in
applications where the maximum codeword length is bounded.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2214</identifier>
 <datestamp>2011-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2214</id><created>2011-02-10</created><authors><author><keyname>Dantala</keyname><forenames>Pradeep Kumar</forenames></author></authors><title>A new protocol implementing authentication transformations for
  multi-located parties</title><categories>cs.CR</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper discusses a new protocol implementing authentication in a
multi-located environment that avoids man-in-the-middle (MIM) attack, replay
attack and provides privacy, integrity of a message for multi-located parties.
The protocol uses the concept that each party is associated with a subsidiary
agent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2216</identifier>
 <datestamp>2011-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2216</id><created>2011-02-10</created><updated>2011-02-27</updated><authors><author><keyname>Duman</keyname><forenames>Tolga M</forenames></author></authors><title>On the Capacity of Memoryless Channels with Synchronization Errors</title><categories>cs.IT math.IT</categories><comments>The paper is withdrawn from Arxiv due to a gap in the proof of Lemma
  2. If a fix can be found, the paper will be resubmitted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Memoryless channels with synchronization errors as defined by a stochastic
channel matrix allowing for symbol insertions and deletions in addition to
random errors are considered. Such channels are information stable, hence their
Shannon capacity exists. However, computation of the channel capacity is
formidable, and only some upper and lower bounds on the capacity (for some
special cases) exist. In this short paper, using a simple methodology, we prove
that the channel capacity is a convex function of the stochastic channel
matrix. Since the more widely studied model of an independent identically
distributed (i.i.d.) deletion channel is a particular case, as an immediate
corollary to this result we also argue that the i.i.d. deletion channel
capacity is a convex function of the deletion probability. We further use this
result to improve the existing capacity upper bounds on the deletion channel by
a proper &quot;convexification&quot; argument. In particular, we prove that the capacity
of the deletion channel, as the deletion probability d --&gt; 1, is upper bounded
by $0.4143(1-d)$ (which was also observed by a different (weaker) recent
result).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2223</identifier>
 <datestamp>2011-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2223</id><created>2011-02-10</created><authors><author><keyname>Ryu</keyname><forenames>Jonghoon</forenames></author><author><keyname>Takeshita</keyname><forenames>Oscar Y.</forenames></author></authors><title>On Inverses for Quadratic Permutation Polynomials over Integer Rings</title><categories>cs.IT math.IT</categories><comments>21 pages, one column, Matlab files attached</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quadratic permutation polynomial interleavers over integer rings have
recently received attention in practical turbo coding systems from deep space
applications to mobile communications. In this correspondence, a necessary and
sufficient condition that determines the least degree inverse of a quadratic
permutation polynomial is proven. Moreover, an algorithm is provided to
explicitly compute the inverse polynomials.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2224</identifier>
 <datestamp>2011-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2224</id><created>2011-02-10</created><authors><author><keyname>Collins</keyname><forenames>Michael J.</forenames></author></authors><title>Cost Sharing in the Aspnes Inoculation Model</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the use of cost sharing in the Aspnes model of network
inoculation, showing that this can improve the cost of the optimal equilibrium
by a factor of $O(\sqrt{n})$ in a network of $n$ nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2232</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2232</id><created>2011-02-10</created><updated>2011-05-04</updated><authors><author><keyname>Bes</keyname><forenames>Alexis</forenames><affiliation>University of Paris-Est Cr&#xe9;teil</affiliation></author><author><keyname>Rabinovich</keyname><forenames>Alexander</forenames><affiliation>Tel-Aviv University, The Blavatnik School of Computer Science</affiliation></author></authors><title>Decidable Expansions of Labelled Linear Orderings</title><categories>cs.LO math.LO</categories><comments>18 pages</comments><proxy>LMCS</proxy><acm-class>math.LO</acm-class><journal-ref>Logical Methods in Computer Science, Volume 7, Issue 2 (May 7,
  2011) lmcs:746</journal-ref><doi>10.2168/LMCS-7(2:5)2011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider a linear ordering equipped with a finite sequence of monadic
predicates. If the ordering contains an interval of order type \omega or
-\omega, and the monadic second-order theory of the combined structure is
decidable, there exists a non-trivial expansion by a further monadic predicate
that is still decidable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2250</identifier>
 <datestamp>2013-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2250</id><created>2011-02-10</created><authors><author><keyname>Yagan</keyname><forenames>Osman</forenames></author><author><keyname>Makowski</keyname><forenames>Armand M.</forenames></author></authors><title>Modeling the pairwise key distribution scheme in the presence of
  unreliable links</title><categories>cs.IT math.CO math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory, October 2010</comments><journal-ref>IEEE Transactions on Information Theory, Volume: 59, Issue: 3,
  Pages: 1740-1760, March 2013</journal-ref><doi>10.1109/TIT.2012.2219578</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the secure connectivity of wireless sensor networks under the
pairwise key distribution scheme of Chan et al.. Unlike recent work which was
carried out under the assumption of full visibility, here we assume a
(simplified) communication model where unreliable wireless links are
represented as on/off channels. We present conditions on how to scale the model
parameters so that the network i) has no secure node which is isolated and ii)
is securely connected, both with high probability when the number of sensor
nodes becomes large. The results are given in the form of zero-one laws, and
exhibit significant differences with corresponding results in the full
visibility case. Through simulations these zero-one laws are shown to be valid
also under a more realistic communication model, i.e., the disk model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2254</identifier>
 <datestamp>2011-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2254</id><created>2011-02-10</created><authors><author><keyname>Chen</keyname><forenames>Yudong</forenames></author><author><keyname>Xu</keyname><forenames>Huan</forenames></author><author><keyname>Caramanis</keyname><forenames>Constantine</forenames></author><author><keyname>Sanghavi</keyname><forenames>Sujay</forenames></author></authors><title>Robust Matrix Completion with Corrupted Columns</title><categories>stat.ML cs.IT math.IT</categories><comments>32 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the problem of matrix completion, when some number of
the columns are arbitrarily corrupted, potentially by a malicious adversary. It
is well-known that standard algorithms for matrix completion can return
arbitrarily poor results, if even a single column is corrupted. What can be
done if a large number, or even a constant fraction of columns are corrupted?
In this paper, we study this very problem, and develop an efficient algorithm
for its solution. Our results show that with a vanishing fraction of observed
entries, it is nevertheless possible to succeed in performing matrix
completion, even when the number of corrupted columns grows. When the number of
corruptions is as high as a constant fraction of the total number of columns,
we show that again exact matrix completion is possible, but in this case our
algorithm requires many more -- a constant fraction -- of observations. One
direct application comes from robust collaborative filtering. Here, some number
of users are so-called manipulators, and try to skew the predictions of the
algorithm. Significantly, our results hold without any assumptions on the
number, locations or values of the observed entries of the manipulated columns.
In particular, this means that manipulators can act in a completely adversarial
manner.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2256</identifier>
 <datestamp>2011-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2256</id><created>2011-02-10</created><authors><author><keyname>Kish</keyname><forenames>Laszlo B.</forenames></author><author><keyname>Khatri</keyname><forenames>Sunil</forenames></author><author><keyname>Bezrukov</keyname><forenames>Sergey</forenames></author><author><keyname>Peper</keyname><forenames>Ferdinand</forenames></author><author><keyname>Gingl</keyname><forenames>Zoltan</forenames></author><author><keyname>Horvath</keyname><forenames>Tamas</forenames></author></authors><title>Noise-based information processing: Noise-based logic and computing:
  what do we have so far?</title><categories>cs.ET</categories><comments>Invited talk at the 21st International Conference on Noise and
  Fluctuations, Toronto, Canada, June 12-16, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We briefly introduce noise-based logic. After describing the main motivations
we outline classical, instantaneous (squeezed and non-squeezed), continuum,
spike and random-telegraph-signal based schemes with applications such as
circuits that emulate the brain functioning and string verification via a slow
communication channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2262</identifier>
 <datestamp>2011-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2262</id><created>2011-02-10</created><authors><author><keyname>Karus</keyname><forenames>Siim</forenames></author><author><keyname>Gall</keyname><forenames>Harald</forenames></author></authors><title>A Study of Language Usage Evolution in Open Source Software</title><categories>cs.PL</categories><comments>working paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The use of programming languages such as Java and C in Open Source Software
(OSS) has been well studied. However, many other popular languages such as XSL
or XML have received minor attention. In this paper, we discuss some trends in
OSS development that we observed when considering multiple programming language
evolution of OSS. Based on the revision data of 22 OSS projects, we tracked the
evolution of language usage and other artefacts such as documentation files,
binaries and graphics files. In these systems several different languages and
artefact types including C/C++, Java, XML, XSL, Makefile, Groovy, HTML, Shell
scripts, CSS, Graphics files, JavaScript, JSP, Ruby, Phyton, XQuery,
OpenDocument files, PHP, etc. have been used. We found that the amount of code
written in different languages differs substantially. Some of our findings can
be summarized as follows: (1) JavaScript and CSS files most often co-evolve
with XSL; (2) Most Java developers but only every second C/C++ developer work
with XML; (3) and more generally, we observed a significant increase of usage
of XML and XSL during recent years and found that Java or C are hardly ever the
only language used by a developer. In fact, a developer works with more than 5
different artefact types (or 4 different languages) in a project on average.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2268</identifier>
 <datestamp>2011-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2268</id><created>2011-02-10</created><authors><author><keyname>Echahed</keyname><forenames>Rachid</forenames></author></authors><title>Proceedings 6th International Workshop on Computing with Terms and
  Graphs</title><categories>cs.LO cs.PL cs.SE</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 48, 2011</journal-ref><doi>10.4204/EPTCS.48</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This volume contains the proceedings of the Sixth International Workshop on
Computing with Terms and Graphs (TERMGRAPH 2011). The workshop took place in
Saarbruecken, Germany, on April 2nd, 2011, as part of the fourteenth edition of
the European Joint Conferences on Theory and Practice of Software (ETAPS 2011).
Research in term and graph rewriting ranges from theoretical questions to
practical issues. Computing with graphs handles the sharing of common
subexpressions in a natural and seamless way, and improves the efficiency of
computations in space and time. Sharing is ubiquitous in several research
areas, for instance : the modelling of first- and higher-order term rewriting
by (acyclic or cyclic) graph rewriting, the modelling of biological or chemical
abstract machines, the implementation techniques of programming languages. Term
graphs are also used in automated theorem proving and symbolic computation
systems working on shared structures. The aim of this workshop is to bring
together researchers working in different domains on term and graph
transformation and to foster their interaction, to provide a forum for
presenting new ideas and work in progress, and to enable newcomers to learn
about current activities in term graph rewriting. These proceedings contain six
accepted papers and the abstracts of three invited talks. All submissions were
subject to careful refereeing. The topics of accepted papers range over a wide
spectrum, including theoretical aspects of term graph rewriting, proof methods,
semantics as well as application issues of term graph transformation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2280</identifier>
 <datestamp>2011-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2280</id><created>2011-02-10</created><authors><author><keyname>Daskalakis</keyname><forenames>Constantinos</forenames></author><author><keyname>Papadimitriou</keyname><forenames>Christos H.</forenames></author></authors><title>On Oblivious PTAS's for Nash Equilibrium</title><categories>cs.GT stat.CO</categories><comments>extended version of paper of the same title that appeared in STOC
  2009</comments><acm-class>F.2.0</acm-class><journal-ref>STOC 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  If a game has a Nash equilibrium with probability values that are either zero
or Omega(1) then this equilibrium can be found exhaustively in polynomial time.
Somewhat surprisingly, we show that there is a PTAS for the games whose
equilibria are guaranteed to have small-O(1/n)-values, and therefore
large-Omega(n)-supports. We also point out that there is a PTAS for games with
sparse payoff matrices, which are known to be PPAD-complete to solve exactly.
Both algorithms are of a special kind that we call oblivious: The algorithm
just samples a fixed distribution on pairs of mixed strategies, and the game is
only used to determine whether the sampled strategies comprise an eps-Nash
equilibrium; the answer is yes with inverse polynomial probability. These
results bring about the question: Is there an oblivious PTAS for Nash
equilibrium in general games? We answer this question in the negative; our
lower bound comes close to the quasi-polynomial upper bound of [Lipton,
Markakis, Mehta 2003].
  Another recent PTAS for anonymous games is also oblivious in a weaker sense
appropriate for this class of games (it samples from a fixed distribution on
unordered collections of mixed strategies), but its runtime is exponential in
1/eps. We prove that any oblivious PTAS for anonymous games with two strategies
and three player types must have 1/eps^c in the exponent of the running time
for some c&gt;1/3, rendering the algorithm in [Daskalakis 2008] essentially
optimal within oblivious algorithms. In contrast, we devise a poly(n)
(1/eps)^O(log^2(1/eps)) non-oblivious PTAS for anonymous games with 2
strategies and any bounded number of player types.
  Our algorithm is based on the construction of a sparse (and efficiently
computable) eps-cover of the set of all possible sums of n independent
indicators, under the total variation distance. The size of the cover is
poly(n) (1/ eps^{O(log^2 (1/eps))}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2284</identifier>
 <datestamp>2011-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2284</id><created>2011-02-11</created><updated>2011-04-06</updated><authors><author><keyname>Vaze</keyname><forenames>Rahul</forenames></author></authors><title>Competitive Use of Multiple Antennas</title><categories>cs.IT math.IT</categories><comments>This paper has been withdrawn. Authorship conflict</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A game theoretic framework is presented to analyze the problem of finding the
optimal number of data streams to transmit in a multi-user MIMO scenario, where
both the transmitters and receivers are equipped with multiple antennas.
Without channel state information (CSI) at any transmitter, and using outage
capacity as the utility function with zero-forcing receiver, each user is shown
to transmit a single data stream at Nash equilibrium in the presence of
sufficient number of users. Transmitting a single data stream is also shown to
be optimal in terms of maximizing the sum of the outage capacities in the
presence of sufficient number of users. With CSI available at each transmitter,
and using the number of successful bits per Joule of energy as the utility
function, at Nash equilibrium, each user is shown to transmit a single data
stream on the best eigen-mode that requires the least transmit power to achieve
a fixed signal-to-interference ratio. Using the concept of locally gross
direction preserving maps, existence of Nash equilibrium is shown when the
number of successful bits per Joule of energy is used as the utility function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2291</identifier>
 <datestamp>2011-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2291</id><created>2011-02-11</created><authors><author><keyname>Gonzalez-Horta</keyname><forenames>Francisco A.</forenames></author><author><keyname>Enriquez-Caldera</keyname><forenames>Rogerio A.</forenames></author><author><keyname>Ramirez-Cortes</keyname><forenames>Juan M.</forenames></author><author><keyname>Martinez-Carballido</keyname><forenames>Jorge</forenames></author><author><keyname>Buenfil-Alpuche</keyname><forenames>Eldamira</forenames></author></authors><title>Towards a Cognitive Handoff for the Future Internet: Model-driven
  Methodology and Taxonomy of Scenarios</title><categories>cs.NI</categories><comments>9 pages (pp. 11-19), 5 figures, 2 tables, published on conference
  proceedings of The Second International Conference on Advanced Cognitive
  Technologies and Applications (COGNITIVE 2010), ISBN: 978-1-61208-001-7,
  Lisbon, Portugal, Nov. 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A cognitive handoff is a multipurpose handoff that achieves many desirable
features simultaneously; e.g., seamlessness, autonomy, security, correctness,
adaptability, etc. But, the development of cognitive handoffs is a challenging
task that has not been properly addressed in the literature. In this paper, we
discuss the difficulties of developing cognitive handoffs and propose a new
model-driven methodology for their systematic development. The theoretical
framework of this methodology is the holistic approach, the functional
decomposition method, the model-based design paradigm, and the theory of design
as scientific problem-solving. We applied the proposed methodology and obtained
the following results: (i) a correspondence between handoff purposes and
quantitative environment information, (ii) a novel taxonomy of handoff mobility
scenarios, and (iii) an original state-based model representing the functional
behavior of the handoff process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2293</identifier>
 <datestamp>2011-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2293</id><created>2011-02-11</created><authors><author><keyname>Gonzalez-Horta</keyname><forenames>Francisco A.</forenames></author><author><keyname>Enriquez-Caldera</keyname><forenames>Rogerio A.</forenames></author><author><keyname>Ramirez-Cortes</keyname><forenames>Juan M.</forenames></author><author><keyname>Martinez-Carballido</keyname><forenames>Jorge</forenames></author><author><keyname>Buenfil-Alpuche</keyname><forenames>Eldamira</forenames></author></authors><title>Towards a Cognitive Handoff for the Future Internet: A Holistic Vision</title><categories>cs.NI</categories><comments>8 pages (pp. 44-51), 4 figures, 2 tables, published on conference
  proceedings of The Second International Conference on Advanced Cognitive
  Technologies and Applications (COGNITIVE 2010), ISBN: 978-1-61208-001-7,
  Lisbon, Portugal, Nov. 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Current handoffs are not designed to achieve multiple desirable features
simultaneously. This weakness has resulted in handoff schemes that are seamless
but not adaptive, or adaptive but not secure, or secure but not autonomous, or
autonomous but not correct, etc. To face this limitation, we initiated a
research project to develop a new kind of handoff system which attains multiple
purposes simultaneously by using context information from the external and
internal handoff environment. We envision a cognitive handoff as a
multipurpose, multi-criteria, environment-aware, and policy-based handoff that
trades-off multiple objectives to reach its intended goals. This paper presents
a conceptual (soft) model of cognitive handoffs using a holistic approach. We
applied the proposed model to identify cognitive handoff performance parameters
and tradeoffs between conflicting objectives. We argue that cognitive handoffs
are the archetype of handoffs for the future Internet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2300</identifier>
 <datestamp>2011-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2300</id><created>2011-02-11</created><authors><author><keyname>Kolla</keyname><forenames>Alexandra</forenames></author></authors><title>Spectral Algorithms for Unique Games</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a new algorithm for Unique Games which is based on purely {\em
spectral} techniques, in contrast to previous work in the area, which relies
heavily on semidefinite programming (SDP). Given a highly satisfiable instance
of Unique Games, our algorithm is able to recover a good assignment. The
approximation guarantee depends only on the completeness of the game, and not
on the alphabet size, while the running time depends on spectral properties of
the {\em Label-Extended} graph associated with the instance of Unique Games.
  We further show that on input the integrality gap instance of Khot and
Vishnoi, our algorithm runs in quasi-polynomial time and decides that the
instance if highly unsatisfiable. Notably, when run on this instance, the
standard SDP relaxation of Unique Games {\em fails}. As a special case, we also
re-derive a polynomial time algorithm for Unique Games on expander constraint
graphs.
  The main ingredient of our algorithm is a technique to effectively use the
full spectrum of the underlying graph instead of just the second eigenvalue,
which is of independent interest. The question of how to take advantage of the
full spectrum of a graph in the design of algorithms has been often studied,
but no significant progress was made prior to this work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2315</identifier>
 <datestamp>2011-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2315</id><created>2011-02-11</created><authors><author><keyname>Debled-Rennesson</keyname><forenames>Isabelle</forenames></author><author><keyname>Margenstern</keyname><forenames>Maurice</forenames></author></authors><title>Cellular Automata and Discrete Geometry</title><categories>cs.CG nlin.CG</categories><comments>44 pages, 28 figures</comments><msc-class>68Q80, 52C00</msc-class><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we look at the possibility to implement the algorithm to
construct a discrete line devised by the first author in cellular automata. It
turns out that such an implementation is feasible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2330</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2330</id><created>2011-02-11</created><authors><author><keyname>Donaldson</keyname><forenames>Alastair</forenames></author><author><keyname>Kaiser</keyname><forenames>Alexander</forenames></author><author><keyname>Kroening</keyname><forenames>Daniel</forenames></author><author><keyname>Wahl</keyname><forenames>Thomas</forenames></author></authors><title>Symmetry-Aware Predicate Abstraction for Shared-Variable Concurrent
  Programs (Extended Technical Report)</title><categories>cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Predicate abstraction is a key enabling technology for applying finite-state
model checkers to programs written in mainstream languages. It has been used
very successfully for debugging sequential system-level C code. Although model
checking was originally designed for analyzing concurrent systems, there is
little evidence of fruitful applications of predicate abstraction to
shared-variable concurrent software. The goal of this paper is to close this
gap. We have developed a symmetry-aware predicate abstraction strategy: it
takes into account the replicated structure of C programs that consist of many
threads executing the same procedure, and generates a Boolean program template
whose multi-threaded execution soundly overapproximates the concurrent C
program. State explosion during model checking parallel instantiations of this
template can now be absorbed by exploiting symmetry. We have implemented our
method in the SATABS predicate abstraction framework, and demonstrate its
superior performance over alternative approaches on a large range of
synchronization programs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2332</identifier>
 <datestamp>2011-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2332</id><created>2011-02-11</created><authors><author><keyname>Mani</keyname><forenames>Ashish</forenames></author><author><keyname>Patvardhan</keyname><forenames>C</forenames></author></authors><title>A Fast Measurement based fixed-point Quantum Search Algorithm</title><categories>cs.DB quant-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Generic quantum search algorithm searches for target entity in an unsorted
database by repeatedly applying canonical Grover's quantum rotation transform
to reach near the vicinity of the target entity represented by a basis state in
the Hilbert space associated with the qubits. Thus, when qubits are measured,
there is a high probability of finding the target entity. However, the number
of times quantum rotation transform is to be applied for reaching near the
vicinity of the target is a function of the number of target entities present
in the unsorted database, which is generally unknown. A wrong estimate of the
number of target entities can lead to overshooting or undershooting the
targets, thus reducing the success probability. Some proposals have been made
to overcome this limitation. These proposals either employ quantum counting to
estimate the number of solutions or fixed point schemes. This paper proposes a
new scheme for stopping the application of quantum rotation transformation on
reaching near the targets by measurement and subsequent processing to estimate
the distance of the state vector from the target states. It ensures a success
probability, which is at least greater than half for all the ratios of the
number of target entities to the total number of entities in a database, which
are less than half. The search problem is trivial for remaining possible
ratios. The proposed scheme is simpler than quantum counting and more efficient
than the known fixed-point schemes. It has same order of computational
complexity as canonical Grover's search algorithm but is slow by a factor of
two and requires an additional ancilla qubit.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2334</identifier>
 <datestamp>2016-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2334</id><created>2011-02-11</created><updated>2012-04-11</updated><authors><author><keyname>Davini</keyname><forenames>Andrea</forenames></author><author><keyname>Zavidovique</keyname><forenames>Maxime</forenames></author></authors><title>Weak KAM theoretic aspects for nonregular commuting Hamiltonians</title><categories>math.AP cs.SY math.OC</categories><comments>37 pages. Third version. Presentation of the commutation property
  changed. Proof of the main theorem made clearer</comments><report-no>Roma01.Math.AP</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider the notion of commutation for a pair of continuous
and convex Hamiltonians, given in terms of commutation of their Lax- Oleinik
semigroups. This is equivalent to the solvability of an associated multi- time
Hamilton-Jacobi equation. We examine the weak KAM theoretic aspects of the
commutation property and show that the two Hamiltonians have the same weak KAM
solutions and the same Aubry set, thus generalizing a result recently obtained
by the second author for Tonelli Hamiltonians. We make a further step by
proving that the Hamiltonians admit a common critical subsolution, strict
outside their Aubry set. This subsolution can be taken of class C^{1,1} in the
Tonelli case. To prove our main results in full generality, it is crucial to
establish suitable differentiability properties of the critical subsolutions on
the Aubry set. These latter results are new in the purely continuous case and
of independent interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2336</identifier>
 <datestamp>2011-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2336</id><created>2011-02-11</created><authors><author><keyname>Quattrociocchi</keyname><forenames>Walter</forenames></author><author><keyname>Conte</keyname><forenames>Rosaria</forenames></author><author><keyname>Lodi</keyname><forenames>Elena</forenames></author></authors><title>Opinions within Media, Power and Gossip</title><categories>cs.SI cs.AI physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite the increasing diffusion of the Internet technology, TV remains the
principal medium of communication. People's perceptions, knowledge, beliefs and
opinions about matter of facts get (in)formed through the information reported
on by the mass-media. However, a single source of information (and consensus)
could be a potential cause of anomalies in the structure and evolution of a
society. Hence, as the information available (and the way it is reported) is
fundamental for our perceptions and opinions, the definition of conditions
allowing for a good information to be disseminated is a pressing challenge. In
this paper starting from a report on the last Italian political campaign in
2008, we derive a socio-cognitive computational model of opinion dynamics where
agents get informed by different sources of information. Then, a what-if
analysis, performed trough simulations on the model's parameters space, is
shown. In particular, the scenario implemented includes three main streams of
information acquisition, differing in both the contents and the perceived
reliability of the messages spread. Agents' internal opinion is updated either
by accessing one of the information sources, namely media and experts, or by
exchanging information with one another. They are also endowed with cognitive
mechanisms to accept, reject or partially consider the acquired information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2339</identifier>
 <datestamp>2011-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2339</id><created>2011-02-11</created><authors><author><keyname>Amadio</keyname><forenames>Roberto</forenames><affiliation>PPS</affiliation></author></authors><title>A decompilation of the pi-calculus and its application to termination</title><categories>cs.PL</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the correspondence between a concurrent lambda-calculus in
administrative, continuation passing style and a pi-calculus and we derive a
termination result for the latter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2346</identifier>
 <datestamp>2011-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2346</id><created>2011-02-11</created><authors><author><keyname>Pivanti</keyname><forenames>Marcello</forenames></author><author><keyname>Schifano</keyname><forenames>Sebastiano Fabio</forenames></author><author><keyname>Simma</keyname><forenames>Hubert</forenames></author></authors><title>An FPGA-based Torus Communication Network</title><categories>hep-lat cs.DC</categories><comments>7 pages, 3 figures, proceedings of the XXVIII International Symposium
  on Lattice Field Theory, Lattice2010, June 14-19, 2010, Villasimius,
  Sardinia, Italy</comments><report-no>DESY 11-011</report-no><journal-ref>PoS LATTICE2010:038,2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe the design and FPGA implementation of a 3D torus network (TNW) to
provide nearest-neighbor communications between commodity multi-core
processors. The aim of this project is to build up tightly interconnected and
scalable parallel systems for scientific computing. The design includes the
VHDL code to implement on latest FPGA devices a network processor, which can be
accessed by the CPU through a PCIe interface and which controls the external
PHYs of the physical links. Moreover, a Linux driver and a library implementing
custom communication APIs are provided. The TNW has been successfully
integrated in two recent parallel machine projects, QPACE and AuroraScience. We
describe some details of the porting of the TNW for the AuroraScience system
and report performance results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2350</identifier>
 <datestamp>2011-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2350</id><created>2011-02-11</created><authors><author><keyname>Kl&#xf8;ve</keyname><forenames>Torleiv</forenames></author><author><keyname>Luo</keyname><forenames>Jinquan</forenames></author></authors><title>The best possible upper bound on the probability of undetected error for
  linear codes of full support</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There is a known best possible upper bound on the probability of undetected
error for linear codes. The $[n,k;q]$ codes with probability of undetected
error meeting the bound have support of size $k$ only. In this note, linear
codes of full support ($=n$) are studied. A best possible upper bound on the
probability of undetected error for such codes is given, and the codes with
probability of undetected error meeting this bound are characterized.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2358</identifier>
 <datestamp>2011-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2358</id><created>2011-02-11</created><authors><author><keyname>Blackburn</keyname><forenames>Simon R.</forenames></author><author><keyname>Cid</keyname><forenames>Carlos</forenames></author><author><keyname>Mullan</keyname><forenames>Ciaran</forenames></author></authors><title>Cryptanalysis of three matrix-based key establishment protocols</title><categories>math.GR cs.CR</categories><comments>9 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We cryptanalyse a matrix-based key transport protocol due to Baumslag, Camps,
Fine, Rosenberger and Xu from 2006. We also cryptanalyse two recently proposed
matrix-based key agreement protocols, due to Habeeb, Kahrobaei and Shpilrain,
and due to Romanczuk and Ustimenko.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2361</identifier>
 <datestamp>2013-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2361</id><created>2011-02-11</created><updated>2013-04-26</updated><authors><author><keyname>Hendrickx</keyname><forenames>Julien M.</forenames></author><author><keyname>Tsitsiklis</keyname><forenames>John N.</forenames></author></authors><title>Convergence of type-symmetric and cut-balanced consensus seeking systems
  (extended version)</title><categories>cs.SY cs.MA math.OC</categories><comments>update of the file following publication of journal version,
  including a minor correction in the proof of theorem 1(b). 12 pages, 12 tex
  files, no figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider continuous-time consensus seeking systems whose time-dependent
interactions are cut-balanced, in the following sense: if a group of agents
influences the remaining ones, the former group is also influenced by the
remaining ones by at least a proportional amount. Models involving symmetric
interconnections and models in which a weighted average of the agent values is
conserved are special cases. We prove that such systems always converge. We
give a sufficient condition on the evolving interaction topology for the limit
values of two agents to be the same. Conversely, we show that if our condition
is not satisfied, then these limits are generically different. These results
allow treating systems where the agent interactions are a priori unknown, e.g.,
random or determined endogenously by the agent values. We also derive
corresponding results for discrete-time systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2366</identifier>
 <datestamp>2011-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2366</id><created>2011-02-11</created><authors><author><keyname>Cranen</keyname><forenames>Sjoerd</forenames></author><author><keyname>Keiren</keyname><forenames>Jeroen J. A.</forenames></author><author><keyname>Willemse</keyname><forenames>Tim A. C.</forenames></author></authors><title>Stuttering Equivalence for Parity Games</title><categories>cs.LO</categories><comments>Version to appear in NFM 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the process theoretic notion of stuttering equivalence in the
setting of parity games. We demonstrate that stuttering equivalent vertices
have the same winner in the parity game. This means that solving a parity game
can be accelerated by minimising the game graph with respect to stuttering
equivalence. While, at the outset, it might not be clear that this strategy
should pay off, our experiments using typical verification problems illustrate
that stuttering equivalence speeds up solving parity games in many cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2368</identifier>
 <datestamp>2012-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2368</id><created>2011-02-11</created><authors><author><keyname>Coecke</keyname><forenames>Bob</forenames></author><author><keyname>Spekkens</keyname><forenames>Robert W.</forenames></author></authors><title>Picturing classical and quantum Bayesian inference</title><categories>quant-ph cs.LO math.CT math.PR</categories><comments>38 pages, lots of pictures</comments><journal-ref>Synthese 186, 651 (2012)</journal-ref><doi>10.1007/s11229-011-9917-5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a graphical framework for Bayesian inference that is
sufficiently general to accommodate not just the standard case but also recent
proposals for a theory of quantum Bayesian inference wherein one considers
density operators rather than probability distributions as representative of
degrees of belief. The diagrammatic framework is stated in the graphical
language of symmetric monoidal categories and of compact structures and
Frobenius structures therein, in which Bayesian inversion boils down to
transposition with respect to an appropriate compact structure. We characterize
classical Bayesian inference in terms of a graphical property and demonstrate
that our approach eliminates some purely conventional elements that appear in
common representations thereof, such as whether degrees of belief are
represented by probabilities or entropic quantities. We also introduce a
quantum-like calculus wherein the Frobenius structure is noncommutative and
show that it can accommodate Leifer's calculus of `conditional density
operators'. The notion of conditional independence is also generalized to our
graphical setting and we make some preliminary connections to the theory of
Bayesian networks. Finally, we demonstrate how to construct a graphical
Bayesian calculus within any dagger compact category.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2382</identifier>
 <datestamp>2011-03-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2382</id><created>2011-02-09</created><updated>2011-03-10</updated><authors><author><keyname>Egger</keyname><forenames>Jan</forenames></author><author><keyname>Zuki&#x107;</keyname><forenames>D&#x17e;enan</forenames></author><author><keyname>Bauer</keyname><forenames>Miriam H. A.</forenames></author><author><keyname>Kuhnt</keyname><forenames>Daniela</forenames></author><author><keyname>Carl</keyname><forenames>Barbara</forenames></author><author><keyname>Freisleben</keyname><forenames>Bernd</forenames></author><author><keyname>Kolb</keyname><forenames>Andreas</forenames></author><author><keyname>Nimsky</keyname><forenames>Christopher</forenames></author></authors><title>A Comparison of Two Human Brain Tumor Segmentation Methods for MRI Data</title><categories>cs.CV physics.med-ph</categories><comments>4 pages, 5 figures, Proc. of the 6th Russian-Bavarian Conference on
  Bio-Medical Engineering</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The most common primary brain tumors are gliomas, evolving from the cerebral
supportive cells. For clinical follow-up, the evaluation of the preoperative
tumor volume is essential. Volumetric assessment of tumor volume with manual
segmentation of its outlines is a time-consuming process that can be overcome
with the help of computerized segmentation methods. In this contribution, two
methods for World Health Organization (WHO) grade IV glioma segmentation in the
human brain are compared using magnetic resonance imaging (MRI) patient data
from the clinical routine. One method uses balloon inflation forces, and relies
on detection of high intensity tumor boundaries that are coupled with the use
of contrast agent gadolinium. The other method sets up a directed and weighted
graph and performs a min-cut for optimal segmentation results. The ground truth
of the tumor boundaries - for evaluating the methods on 27 cases - is manually
extracted by neurosurgeons with several years of experience in the resection of
gliomas. A comparison is performed using the Dice Similarity Coefficient (DSC),
a measure for the spatial overlap of different segmentation results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2395</identifier>
 <datestamp>2011-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2395</id><created>2011-02-11</created><authors><author><keyname>Majkic</keyname><forenames>Zoran</forenames></author></authors><title>Matching, Merging and Structural Properties of Data Base Category</title><categories>cs.DB cs.LO math.CT</categories><comments>27 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Main contribution of this paper is an investigation of expressive power of
the database category DB. An object in this category is a database-instance
(set of n-ary relations). Morphisms are not functions but have complex tree
structures based on a set of complex query computations. They express the
semantics of view-based mappings between databases. The higher (logical) level
scheme mappings between databases, usually written in some high expressive
logical language, may be functorially translated into this base &quot;computation&quot;
DB category . The behavioral point of view for databases is assumed, with
behavioural equivalence of databases corresponding to isomorphism of objects in
DB category. The introduced observations, which are view-based computations
without side-effects, are based (from Universal algebra) on monad endofunctor
T, which is the closure operator for objects and for morphisms also. It was
shown that DB is symmetric (with a bijection between arrows and objects)
2-category, equal to its dual, complete and cocomplete. In this paper we
demonstrate that DB is concrete, locally small and finitely presentable.
Moreover, it is enriched over itself monoidal symmetric category with a tensor
products for matching, and has a parameterized merging database operation. We
show that it is an algebraic lattice and we define a database metric space and
a subobject classifier: thus, DB category is a monoidal elementary topos.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2398</identifier>
 <datestamp>2011-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2398</id><created>2011-02-11</created><authors><author><keyname>Giovannetti</keyname><forenames>Vittorio</forenames></author><author><keyname>Severini</keyname><forenames>Simone</forenames></author></authors><title>The Kirchhoff's Matrix-Tree Theorem revisited: counting spanning trees
  with the quantum relative entropy</title><categories>quant-ph cs.IT math.CO math.IT</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  By revisiting the Kirchhoff's Matrix-Tree Theorem, we give an exact formula
for the number of spanning trees of a graph in terms of the quantum relative
entropy between the maximally mixed state and another state specifically
obtained from the graph. We use properties of the quantum relative entropy to
prove tight bounds for the number of spanning trees in terms of basic
parameters like degrees and number of vertices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2405</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2405</id><created>2011-02-11</created><updated>2011-05-04</updated><authors><author><keyname>Abel</keyname><forenames>Andreas</forenames><affiliation>Ludwig-Maximilians-Universit&#xe4;t M&#xfc;nchen</affiliation></author><author><keyname>Coquand</keyname><forenames>Thierry</forenames><affiliation>G&#xf6;teborg University</affiliation></author><author><keyname>Pagano</keyname><forenames>Miguel</forenames><affiliation>Universidad Nacional de C&#xf3;rdoba</affiliation></author></authors><title>A Modular Type-checking algorithm for Type Theory with Singleton Types
  and Proof Irrelevance</title><categories>cs.LO</categories><proxy>LMCS</proxy><acm-class>F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 7, Issue 2 (May 7,
  2011) lmcs:1069</journal-ref><doi>10.2168/LMCS-7(2:4)2011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We define a logical framework with singleton types and one universe of small
types. We give the semantics using a PER model; it is used for constructing a
normalisation-by-evaluation algorithm. We prove completeness and soundness of
the algorithm; and get as a corollary the injectivity of type constructors.
Then we give the definition of a correct and complete type-checking algorithm
for terms in normal form. We extend the results to proof-irrelevant
propositions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2413</identifier>
 <datestamp>2013-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2413</id><created>2011-02-11</created><updated>2013-01-06</updated><authors><author><keyname>Bassino</keyname><forenames>Fr&#xe9;d&#xe9;rique</forenames></author><author><keyname>Cl&#xe9;ment</keyname><forenames>Julien</forenames></author><author><keyname>Seroussi</keyname><forenames>Gadiel</forenames></author><author><keyname>Viola</keyname><forenames>Alfredo</forenames></author></authors><title>Optimal prefix codes for pairs of geometrically-distributed random
  variables</title><categories>cs.IT math.IT</categories><comments>To appear in IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Optimal prefix codes are studied for pairs of independent, integer-valued
symbols emitted by a source with a geometric probability distribution of
parameter $q$, $0{&lt;}q{&lt;}1$. By encoding pairs of symbols, it is possible to
reduce the redundancy penalty of symbol-by-symbol encoding, while preserving
the simplicity of the encoding and decoding procedures typical of Golomb codes
and their variants. It is shown that optimal codes for these so-called
two-dimensional geometric distributions are \emph{singular}, in the sense that
a prefix code that is optimal for one value of the parameter $q$ cannot be
optimal for any other value of $q$. This is in sharp contrast to the
one-dimensional case, where codes are optimal for positive-length intervals of
the parameter $q$. Thus, in the two-dimensional case, it is infeasible to give
a compact characterization of optimal codes for all values of the parameter
$q$, as was done in the one-dimensional case. Instead, optimal codes are
characterized for a discrete sequence of values of $q$ that provide good
coverage of the unit interval. Specifically, optimal prefix codes are described
for $q=2^{-1/k}$ ($k\ge 1$), covering the range $q\ge 1/2$, and $q=2^{-k}$
($k&gt;1$), covering the range $q&lt;1/2$. The described codes produce the expected
reduction in redundancy with respect to the one-dimensional case, while
maintaining low complexity coding operations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2422</identifier>
 <datestamp>2014-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2422</id><created>2011-02-11</created><updated>2011-03-02</updated><authors><author><keyname>Scurlock</keyname><forenames>Bob</forenames></author></authors><title>Use of root in vehicular accident reconstruction</title><categories>physics.pop-ph cs.OH</categories><journal-ref>Accident Reconstruction Journal, Vol. 21, No. 3, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The purpose of this article is to introduce the reader to the ROOT data
analysis software package, and demonstrate how it may be used to complement
one's accident reconstruction analyses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2423</identifier>
 <datestamp>2011-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2423</id><created>2011-02-11</created><updated>2011-05-17</updated><authors><author><keyname>Zhao</keyname><forenames>Kun</forenames></author><author><keyname>Stehle</keyname><forenames>Juliette</forenames></author><author><keyname>Bianconi</keyname><forenames>Ginestra</forenames></author><author><keyname>Barrat</keyname><forenames>Alain</forenames></author></authors><title>Social network dynamics of face-to-face interactions</title><categories>physics.soc-ph cond-mat.dis-nn cond-mat.stat-mech cs.SI</categories><comments>20 pages, 25 figures</comments><journal-ref>Phys. Rev. E 83, 056109 (2011)</journal-ref><doi>10.1103/PhysRevE.83.056109</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The recent availability of data describing social networks is changing our
understanding of the &quot;microscopic structure&quot; of a social tie. A social tie
indeed is an aggregated outcome of many social interactions such as
face-to-face conversations or phone-calls. Analysis of data on face-to-face
interactions shows that such events, as many other human activities, are
bursty, with very heterogeneous durations. In this paper we present a model for
social interactions at short time scales, aimed at describing contexts such as
conference venues in which individuals interact in small groups. We present a
detailed anayltical and numerical study of the model's dynamical properties,
and show that it reproduces important features of empirical data. The model
allows for many generalizations toward an increasingly realistic description of
social interactions. In particular in this paper we investigate the case where
the agents have intrinsic heterogeneities in their social behavior, or where
dynamic variations of the local number of individuals are included. Finally we
propose this model as a very flexible framework to investigate how dynamical
processes unfold in social networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2445</identifier>
 <datestamp>2011-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2445</id><created>2011-02-11</created><authors><author><keyname>Dietz</keyname><forenames>Michael</forenames></author><author><keyname>Shekhar</keyname><forenames>Shashi</forenames></author><author><keyname>Pisetsky</keyname><forenames>Yuliy</forenames></author><author><keyname>Shu</keyname><forenames>Anhei</forenames></author><author><keyname>Wallach</keyname><forenames>Dan S.</forenames></author></authors><title>Quire: Lightweight Provenance for Smart Phone Operating Systems</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Smartphone apps often run with full privileges to access the network and
sensitive local resources, making it difficult for remote systems to have any
trust in the provenance of network connections they receive. Even within the
phone, different apps with different privileges can communicate with one
another, allowing one app to trick another into improperly exercising its
privileges (a Confused Deputy attack). In Quire, we engineered two new security
mechanisms into Android to address these issues. First, we track the call chain
of IPCs, allowing an app the choice of operating with the diminished privileges
of its callers or to act explicitly on its own behalf. Second, a lightweight
signature scheme allows any app to create a signed statement that can be
verified anywhere inside the phone. Both of these mechanisms are reflected in
network RPCs, allowing remote systems visibility into the state of the phone
when an RPC is made. We demonstrate the usefulness of Quire with two example
applications. We built an advertising service, running distinctly from the app
which wants to display ads, which can validate clicks passed to it from its
host. We also built a payment service, allowing an app to issue a request which
the payment service validates with the user. An app cannot not forge a payment
request by directly connecting to the remote server, nor can the local payment
service tamper with the request.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2453</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2453</id><created>2011-02-11</created><updated>2011-03-07</updated><authors><author><keyname>Zhang</keyname><forenames>Wenji</forenames></author><author><keyname>Li</keyname><forenames>Lianlin</forenames></author><author><keyname>Li</keyname><forenames>Fang</forenames></author></authors><title>Reducing the Number of Elements in Linear and Planar Antenna Arrays with
  Sparse Constraint Optimization</title><categories>cs.IT math.IT</categories><comments>This paper has been withdrawn by the authors. I will do the major
  revision</comments><doi>10.1109/TAP.2011.2158943</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn by the authors. I will do the major revision.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2467</identifier>
 <datestamp>2012-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2467</id><created>2011-02-11</created><authors><author><keyname>Hutter</keyname><forenames>Marcus</forenames></author></authors><title>Universal Learning Theory</title><categories>cs.LG cs.IT math.IT</categories><comments>12 LaTeX pages</comments><journal-ref>Encyclopedia of Machine Learning (2011) pages 1001-1008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This encyclopedic article gives a mini-introduction into the theory of
universal learning, founded by Ray Solomonoff in the 1960s and significantly
developed and extended in the last decade. It explains the spirit of universal
learning, but necessarily glosses over technical subtleties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2468</identifier>
 <datestamp>2012-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2468</id><created>2011-02-11</created><authors><author><keyname>Hutter</keyname><forenames>Marcus</forenames></author></authors><title>Algorithmic Randomness as Foundation of Inductive Reasoning and
  Artificial Intelligence</title><categories>cs.IT cs.AI cs.CC math.IT</categories><comments>9 LaTeX pages</comments><journal-ref>Chapter 12 in Randomness through Computation: Some Answers, More
  Questions (2011) pages 159-169</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article is a brief personal account of the past, present, and future of
algorithmic randomness, emphasizing its role in inductive inference and
artificial intelligence. It is written for a general audience interested in
science and philosophy. Intuitively, randomness is a lack of order or
predictability. If randomness is the opposite of determinism, then algorithmic
randomness is the opposite of computability. Besides many other things, these
concepts have been used to quantify Ockham's razor, solve the induction
problem, and define intelligence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2479</identifier>
 <datestamp>2011-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2479</id><created>2011-02-11</created><authors><author><keyname>Garg</keyname><forenames>Rachit Mohan</forenames></author><author><keyname>Sood</keyname><forenames>Yamini</forenames></author><author><keyname>Kottana</keyname><forenames>Balaji</forenames></author><author><keyname>Totlani</keyname><forenames>Pallavi</forenames></author></authors><title>A Framework Based Approach for the Development of Web Based Applications</title><categories>cs.CY</categories><comments>4 pages</comments><journal-ref>World of Computer Science and Information Technology Journal
  (WCSIT),ISSN: 2221-0741,Vol. 1, No. 1, 1-4, Feb. 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The sole goal of E-Governance is to allow interaction of government with
their citizens in a comfortable &amp; transparent manner. Uniqueness of J2EE makes
it a perfect technology for development of any online portal. These involve
constancy, easy to replant, construct speedily etc. In this paper we present a
procedural approach to develop a web application using the J2EE Struts
Framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2489</identifier>
 <datestamp>2011-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2489</id><created>2011-02-12</created><authors><author><keyname>Asaeedi</keyname><forenames>Saeed</forenames></author><author><keyname>Didehvar</keyname><forenames>Farzad</forenames></author></authors><title>Co-ordering and Type 2 co-ordering</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In [arXiv:1006.4939] the enumeration order reducibility is defined on natural
numbers. For a c.e. set A, [A] denoted the class of all subsets of natural
numbers which are co-order with A. In definition 5 we redefine co-ordering for
rational numbers. One of the main questions there, was: &quot;For a specific c.e.
set A, consider set of all enumerations of it which is generated by some Turing
machine {TM_A} what are the associated order types in [A]?&quot; Here, we propose
the same question for rational numbers, and we try to investigate the varieties
of c.e. sets on Q. The theories here are hold for R_c and we could repeat the
same theories in this domain, in a parallel way.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2490</identifier>
 <datestamp>2013-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2490</id><created>2011-02-12</created><updated>2013-08-29</updated><authors><author><keyname>Garivier</keyname><forenames>Aur&#xe9;lien</forenames></author><author><keyname>Capp&#xe9;</keyname><forenames>Olivier</forenames></author></authors><title>The KL-UCB Algorithm for Bounded Stochastic Bandits and Beyond</title><categories>math.ST cs.LG cs.SY math.OC stat.TH</categories><comments>18 pages, 3 figures; Conf. Comput. Learning Theory (COLT) 2011 in
  Budapest, Hungary</comments><msc-class>93E35</msc-class><journal-ref>Conference On Learning Theory n{\deg}24 Jul. 2011 pp.359-376</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a finite-time analysis of the KL-UCB algorithm, an
online, horizon-free index policy for stochastic bandit problems. We prove two
distinct results: first, for arbitrary bounded rewards, the KL-UCB algorithm
satisfies a uniformly better regret bound than UCB or UCB2; second, in the
special case of Bernoulli rewards, it reaches the lower bound of Lai and
Robbins. Furthermore, we show that simple adaptations of the KL-UCB algorithm
are also optimal for specific classes of (possibly unbounded) rewards,
including those generated from exponential families of distributions. A
large-scale numerical study comparing KL-UCB with its main competitors (UCB,
UCB2, UCB-Tuned, UCB-V, DMED) shows that KL-UCB is remarkably efficient and
stable, including for short time horizons. KL-UCB is also the only method that
always performs better than the basic UCB policy. Our regret bounds rely on
deviations results of independent interest which are stated and proved in the
Appendix. As a by-product, we also obtain an improved regret bound for the
standard UCB algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2498</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2498</id><created>2011-02-12</created><updated>2012-08-08</updated><authors><author><keyname>Shomorony</keyname><forenames>Ilan</forenames></author><author><keyname>Avestimehr</keyname><forenames>A. Salman</forenames></author></authors><title>Two-Unicast Wireless Networks: Characterizing the Degrees-of-Freedom</title><categories>cs.IT math.IT</categories><comments>To appear on IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider two-source two-destination (i.e., two-unicast) multi-hop wireless
networks that have a layered structure with arbitrary connectivity. We show
that, if the channel gains are chosen independently according to continuous
distributions, then, with probability 1, two-unicast layered Gaussian networks
can only have 1, 3/2 or 2 sum degrees-of-freedom (unless both
source-destination pairs are disconnected, in which case no degrees-of-freedom
can be achieved). We provide sufficient and necessary conditions for each case
based on network connectivity and a new notion of source-destination paths with
manageable interference. Our achievability scheme is based on forwarding the
received signals at all nodes, except for a small fraction of them in at most
two key layers. Hence, we effectively create a &quot;condensed network&quot; that has at
most four layers (including the sources layer and the destinations layer). We
design the transmission strategies based on the structure of this condensed
network. The converse results are obtained by developing information-theoretic
inequalities that capture the structures of the network connectivity. Finally,
we extend this result and characterize the full degrees-of-freedom region of
two-unicast layered wireless networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2504</identifier>
 <datestamp>2011-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2504</id><created>2011-02-12</created><authors><author><keyname>Maham</keyname><forenames>Behrouz</forenames></author><author><keyname>Popovski</keyname><forenames>Petar</forenames></author><author><keyname>Zhou</keyname><forenames>Xiangyun</forenames></author><author><keyname>Hj&#xf8;rungnes</keyname><forenames>Are</forenames></author></authors><title>Cognitive Multiple Access Network with Outage Margin in the Primary
  System</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the problem of spectrally efficient operation of a
multiuser uplink cognitive radio system in the presence of a single primary
link. The secondary system applies opportunistic interference cancelation (OIC)
and decode the primary signal when such an opportunity is created. We derive
the achievable rate in the secondary system when OIC is used. This scheme has a
practical significance, since it enables rate adaptation without requiring any
action from the primary system. The \emph{exact} expressions for outage
probability of the primary user are derived, when the primary system is exposed
to interference from secondary users. Moreover, approximated formulas and tight
lower and upper bounds for the ergodic sum-rate capacity of the secondary
network are found. Next, the power allocation is investigated in the secondary
system for maximizing the sum-rate under an outage constraint at the primary
system. We formulate the power optimization problem in various scenarios
depending on the availability of channel state information and the type of
power constraints, and propose a set of simple solutions. Finally, the
analytical results are confirmed by simulations, indicating both the accuracy
of the analysis, and the fact that the spectral-efficient, low-complexity,
flexible, and high-performing cognitive radio can be designed based on the
proposed schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2506</identifier>
 <datestamp>2011-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2506</id><created>2011-02-12</created><authors><author><keyname>Maham</keyname><forenames>Behrouz</forenames></author><author><keyname>Hj&#xf8;rungnes</keyname><forenames>Are</forenames></author></authors><title>Opportunistic Relaying for Space-Time Coded Cooperation with Multiple
  Antenna Terminals</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a wireless relay network with multiple antenna terminals over
Rayleigh fading channels, and apply distributed space-time coding (DSTC) in
amplify-and-forward (A&amp;F) mode. The A&amp;F scheme is used in a way that each relay
transmits a scaled version of the linear combination of the received symbols.
It turns out that, combined with power allocation in the relays, A&amp;F DSTC
results in an opportunistic relaying scheme, in which only the best relay is
selected to retransmit the source's space-time coded signal. Furthermore,
assuming the knowledge of source-relay CSI at the source node, we design an
efficient power allocation which outperforms uniform power allocation across
the source antennas. Next, assuming M-PSK or M-QAM modulations, we analyze the
performance of the proposed cooperative diversity transmission schemes in a
wireless relay networks with the multiple-antenna source and destination. We
derive the probability density function (PDF) of the received SNR at the
destination. Then, the PDF is used to determine the symbol error rate (SER) in
Rayleigh fading channels. We derived closed-form approximations of the average
SER in the high SNR scenario, from which we find the diversity order of system
RminfNs;Ndg, where R, Ns, and Nd are the number of the relays, source antennas,
and destination antennas, respectively. Simulation results show that the
proposed system obtain more than 6 dB gain in SNR over A&amp;F MIMO DSTC for BER
10^{-4}, when R = 2, Ns = 2, and Nd = 1.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2516</identifier>
 <datestamp>2011-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2516</id><created>2011-02-12</created><authors><author><keyname>Paolini</keyname><forenames>Enrico</forenames></author><author><keyname>Liva</keyname><forenames>Gianluigi</forenames></author><author><keyname>Chiani</keyname><forenames>Marco</forenames></author></authors><title>High Throughput Random Access via Codes on Graphs: Coded Slotted ALOHA</title><categories>cs.IT math.IT</categories><comments>6 pages, 2 figures. To be presented at IEEE ICC 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, coded slotted ALOHA (CSA) is introduced as a powerful random
access scheme to the MAC frame. In CSA, the burst a generic user wishes to
transmit in the MAC frame is first split into segments, and these segments are
then encoded through a local a packet-oriented code prior to transmission. On
the receiver side, iterative interference cancellation combined with decoding
of the local code is performed to recover from collisions. The new scheme
generalizes the previously proposed irregular repetition slotted ALOHA (IRSA)
technique, based on a simple repetition of the users' bursts. An interpretation
of the CSA interference cancellation process as an iterative erasure decoding
process over a sparse bipartite graph is identified, and the corresponding
density evolution equations derived. Based on these equations, asymptotically
optimal CSA schemes are designed for several rates and their performance for a
finite number of users investigated through simulation and compared to IRSA
competitors. Throughputs as high as 0.8 are demonstrated. The new scheme turns
out to be a good candidate in contexts where power efficiency is required.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2521</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2521</id><created>2011-02-12</created><updated>2011-05-07</updated><authors><author><keyname>Garg</keyname><forenames>Deepak</forenames></author><author><keyname>Jia</keyname><forenames>Limin</forenames></author><author><keyname>Datta</keyname><forenames>Anupam</forenames></author></authors><title>A Logical Method for Policy Enforcement over Evolving Audit Logs</title><categories>cs.LO cs.CR</categories><comments>Carnegie Mellon University CyLab Technical Report. 51 pages</comments><report-no>CMU-CyLab-11-002</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an iterative algorithm for enforcing policies represented in a
first-order logic, which can, in particular, express all transmission-related
clauses in the HIPAA Privacy Rule. The logic has three features that raise
challenges for enforcement --- uninterpreted predicates (used to model
subjective concepts in privacy policies), real-time temporal properties, and
quantification over infinite domains (such as the set of messages containing
personal information). The algorithm operates over audit logs that are
inherently incomplete and evolve over time. In each iteration, the algorithm
provably checks as much of the policy as possible over the current log and
outputs a residual policy that can only be checked when the log is extended
with additional information. We prove correctness and termination properties of
the algorithm. While these results are developed in a general form, accounting
for many different sources of incompleteness in audit logs, we also prove that
for the special case of logs that maintain a complete record of all relevant
actions, the algorithm effectively enforces all safety and co-safety
properties. The algorithm can significantly help automate enforcement of
policies derived from the HIPAA Privacy Rule.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2524</identifier>
 <datestamp>2011-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2524</id><created>2011-02-12</created><authors><author><keyname>Levin</keyname><forenames>Mark Sh.</forenames></author><author><keyname>Nuriakhmetov</keyname><forenames>Rustem I.</forenames></author></authors><title>Multicriteria Steiner Tree Problem for Communication Network</title><categories>cs.DS cs.AI cs.NI math.OC</categories><comments>11 pages, 7 figures</comments><journal-ref>Information Processes 9(3) (2009) 199-209</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses combinatorial optimization scheme for solving the
multicriteria Steiner tree problem for communication network topology design
(e.g., wireless mesh network). The solving scheme is based on several models:
multicriteria ranking, clustering, minimum spanning tree, and minimum Steiner
tree problem. An illustrative numerical example corresponds to designing a
covering long-distance Wi-Fi network (static Ad-Hoc network). The set of
criteria (i.e., objective functions) involves the following: total cost, total
edge length, overall throughput (capacity), and estimate of QoS. Obtained
computing results show the suggested solving scheme provides good network
topologies which can be compared with minimum spanning trees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2529</identifier>
 <datestamp>2011-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2529</id><created>2011-02-12</created><authors><author><keyname>Brazdil</keyname><forenames>Tomas</forenames></author><author><keyname>Kiefer</keyname><forenames>Stefan</forenames></author><author><keyname>Kucera</keyname><forenames>Antonin</forenames></author></authors><title>Efficient Analysis of Probabilistic Programs with an Unbounded Counter</title><categories>cs.FL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that a subclass of infinite-state probabilistic programs that can be
modeled by probabilistic one-counter automata (pOC) admits an efficient
quantitative analysis. In particular, we show that the expected termination
time can be approximated up to an arbitrarily small relative error with
polynomially many arithmetic operations, and the same holds for the probability
of all runs that satisfy a given omega-regular property. Further, our results
establish a powerful link between pOC and martingale theory, which leads to
fundamental observations about quantitative properties of runs in pOC. In
particular, we provide a &quot;divergence gap theorem&quot;, which bounds a positive
non-termination probability in pOC away from zero.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2536</identifier>
 <datestamp>2011-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2536</id><created>2011-02-12</created><authors><author><keyname>Harremo&#xeb;s</keyname><forenames>Peter</forenames></author><author><keyname>Vignat</keyname><forenames>Christophe</forenames></author></authors><title>Lower bounds on Information Divergence</title><categories>cs.IT math.IT math.PR</categories><comments>Submitted for the conference ISIT 2011</comments><msc-class>94A15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we establish lower bounds on information divergence from a
distribution to certain important classes of distributions as Gaussian,
exponential, Gamma, Poisson, geometric, and binomial. These lower bounds are
tight and for several convergence theorems where a rate of convergence can be
computed, this rate is determined by the lower bounds proved in this paper.
General techniques for getting lower bounds in terms of moments are developed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2541</identifier>
 <datestamp>2012-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2541</id><created>2011-02-12</created><updated>2012-11-02</updated><authors><author><keyname>Broutin</keyname><forenames>Nicolas</forenames></author><author><keyname>Holmgren</keyname><forenames>Cecilia</forenames></author></authors><title>The total path length of split trees</title><categories>math.PR cs.DS math.CO</categories><comments>Published in at http://dx.doi.org/10.1214/11-AAP812 the Annals of
  Applied Probability (http://www.imstat.org/aap/) by the Institute of
  Mathematical Statistics (http://www.imstat.org)</comments><proxy>vtex</proxy><report-no>IMS-AAP-AAP812</report-no><journal-ref>Annals of Applied Probability 2012, Vol. 22, No. 5, 1745-1777</journal-ref><doi>10.1214/11-AAP812</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the model of random trees introduced by Devroye [SIAM J. Comput.
28 (1999) 409-432]. The model encompasses many important randomized algorithms
and data structures. The pieces of data (items) are stored in a randomized
fashion in the nodes of a tree. The total path length (sum of depths of the
items) is a natural measure of the efficiency of the algorithm/data structure.
Using renewal theory, we prove convergence in distribution of the total path
length toward a distribution characterized uniquely by a fixed point equation.
Our result covers, using a unified approach, many data structures such as
binary search trees, m-ary search trees, quad trees, median-of-(2k+1) trees,
and simplex trees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2551</identifier>
 <datestamp>2012-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2551</id><created>2011-02-12</created><updated>2012-09-21</updated><authors><author><keyname>Balseiro</keyname><forenames>Santiago</forenames></author><author><keyname>Feldman</keyname><forenames>Jon</forenames></author><author><keyname>Mirrokni</keyname><forenames>Vahab</forenames></author><author><keyname>Muthukrishnan</keyname><forenames>S.</forenames></author></authors><title>Yield Optimization of Display Advertising with Ad Exchange</title><categories>math.OC cs.DS cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In light of the growing market of Ad Exchanges for the real-time sale of
advertising slots, publishers face new challenges in choosing between the
allocation of contract-based reservation ads and spot market ads. In this
setting, the publisher should take into account the tradeoff between short-term
revenue from an Ad Exchange and quality of allocating reservation ads. In this
paper, we formalize this combined optimization problem as a stochastic control
problem and derive an efficient policy for online ad allocation in settings
with general joint distribution over placement quality and exchange bids. We
prove asymptotic optimality of this policy in terms of any trade-off between
quality of delivered reservation ads and revenue from the exchange, and provide
a rigorous bound for its convergence rate to the optimal policy. We also give
experimental results on data derived from real publisher inventory, showing
that our policy can achieve any pareto-optimal point on the quality vs. revenue
curve. Finally, we study a parametric training-based algorithm in which instead
of learning the dual variables from a sample data (as is done in non-parametric
training-based algorithms), we learn the parameters of the distribution and
construct those dual variables from the learned parameter values. We compare
parametric and non-parametric ways to estimate from data both analytically and
experimentally in the special case without the ad exchange, and show that
though both methods converge to the optimal policy as the sample size grows,
our parametric method converges faster, and thus performs better on smaller
samples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2553</identifier>
 <datestamp>2011-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2553</id><created>2011-02-12</created><authors><author><keyname>Hou</keyname><forenames>I-Hong</forenames></author><author><keyname>Gupta</keyname><forenames>Piyush</forenames></author></authors><title>Distributed Resource Allocation for Proportional Fairness in Multi-Band
  Wireless Systems</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A challenging problem in multi-band multi-cell self-organized wireless
systems, such as multi-channel Wi-Fi networks, femto/pico cells in 3G/4G
cellular networks, and more recent wireless networks over TV white spaces, is
of distributed resource allocation. This involves four components: channel
selection, client association, channel access, and client scheduling. In this
paper, we present a unified framework for jointly addressing the four
components with the global system objective of maximizing the clients
throughput in a proportionally fair manner. Our formulation allows a natural
dissociation of the problem into two sub-parts. We show that the first part,
involving channel access and client scheduling, is convex and derive a
distributed adaptation procedure for achieving Pareto-optimal solution. For the
second part, involving channel selection and client association, we develop a
Gibbs-sampler based approach for local adaptation to achieve the global
objective, as well as derive fast greedy algorithms from it that achieve good
solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2558</identifier>
 <datestamp>2011-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2558</id><created>2011-02-12</created><authors><author><keyname>Mani</keyname><forenames>A.</forenames></author></authors><title>Dialectics of Counting and Measures of Rough Theories</title><categories>math.LO cs.LO</categories><comments>17 Pages; NCETSC'2011 held during 2-3 Feb'2011 at NW College and
  organised by Indian Society for Rough Sets, Univ of Pune and Nowrosjee Wadia
  college</comments><msc-class>03E70, 03A99, 03E99, 03G25, 94D99</msc-class><journal-ref>IEEE Proceedings of NCETSC'2011 held during 2-3 Feb'2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  New concepts of rough natural number systems, recently introduced by the
present author, are used to improve most rough set-theoretical measures in
general Rough Set theory (\textsf{RST}) and measures of mutual consistency of
multiple models of knowledge. In this research paper, the explicit dependence
on the axiomatic theory of granules of \cite{AM99} is reduced and more results
on the measures and representation of the numbers are proved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2559</identifier>
 <datestamp>2011-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2559</id><created>2011-02-13</created><authors><author><keyname>Stimpson</keyname><forenames>Mike</forenames></author></authors><title>Toward Measuring the Scaling of Genetic Programming</title><categories>cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Several genetic programming systems are created, each solving a different
problem. In these systems, the median number of generations G needed to evolve
a working program is measured. The behavior of G is observed as the difficulty
of the problem is increased. In these systems, the density D of working
programs in the universe of all possible programs is measured. The relationship
G ~ 1/sqrt(D) is observed to approximately hold for two program-like systems.
For parallel systems (systems that look like several independent programs
evolving in parallel), the relationship G ~ 1/(n ln n) is observed to
approximately hold. Finally, systems that are anti-parallel are considered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2566</identifier>
 <datestamp>2011-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2566</id><created>2011-02-13</created><updated>2011-11-15</updated><authors><author><keyname>Barbier</keyname><forenames>Morgan</forenames><affiliation>INRIA Saclay - Ile de France</affiliation></author><author><keyname>Paulo</keyname><forenames>Barreto S. L. M.</forenames><affiliation>IME/USP</affiliation></author></authors><title>Key Reduction of McEliece's Cryptosystem Using List Decoding</title><categories>cs.CR cs.IT math.IT</categories><proxy>ccsd</proxy><journal-ref>International Symposium of Information Theory (ISIT) (2011)
  2657-2661</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Different variants of the code-based McEliece cryptosystem were pro- posed to
reduce the size of the public key. All these variants use very structured
codes, which open the door to new attacks exploiting the underlying structure.
In this paper, we show that the dyadic variant can be designed to resist all
known attacks. In light of a new study on list decoding algorithms for binary
Goppa codes, we explain how to increase the security level for given public
keysizes. Using the state-of-the-art list decoding algorithm instead of unique
decoding, we exhibit a keysize gain of about 4% for the standard McEliece
cryptosystem and up to 21% for the adjusted dyadic variant.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2567</identifier>
 <datestamp>2015-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2567</id><created>2011-02-13</created><updated>2015-06-01</updated><authors><author><keyname>Rousseau</keyname><forenames>Ronald</forenames></author><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author></authors><title>Simple arithmetic versus intuitive understanding: The case of the impact
  factor</title><categories>cs.DL physics.soc-ph</categories><comments>ISSI Newsletter 7(1) (2011) 10-14</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that as a consequence of basic properties of elementary arithmetic
journal impact factors show a counterintuitive behaviour with respect to adding
non-cited articles. Synchronous as well as diachronous journal impact factors
are affected. Our findings provide a rationale for not taking uncitable
publications into account in impact factor calculations, at least if these
items are truly uncitable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2568</identifier>
 <datestamp>2011-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2568</id><created>2011-02-13</created><authors><author><keyname>Wang</keyname><forenames>Xinhua</forenames></author></authors><title>Frequency characteristics based on describing function method for
  differentiators</title><categories>cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, describing function method is used to analyze the
characteristics and parameters selection of differentiators. Nonlinear
differentiator is an effective compensation to linear differentiator, and
hybrid differentiator consisting of linear and nonlinear parts is the
combination of both advantages of linear and nonlinear differentiators. The
merits of the hybrid differentiator include its simplicity, rapid convergence
at all times, and restraining noises effectively. The methods are confirmed by
some examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2569</identifier>
 <datestamp>2011-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2569</id><created>2011-02-13</created><updated>2011-02-14</updated><authors><author><keyname>Opthof</keyname><forenames>Tobias</forenames></author><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author></authors><title>Citation analysis cannot legitimate the strategic selection of
  excellence</title><categories>cs.DL physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In reaction to a previous critique(Opthof &amp; Leydesdorff, 2010), the Center
for Science and Technology Studies (CWTS) in Leiden proposed to change their
old &quot;crown&quot; indicator in citation analysis into a new one. Waltman et al.
(2011)argue that this change does not affect rankings at various aggregated
levels. However, CWTS data is not publicly available for testing and criticism.
In this correspondence, we use previously published data of Van Raan (2006) to
address the pivotal issue of how the results of citation analysis correlate
with the results of peer review. A quality parameter based on peer review was
neither significantly correlated with the two parameters developed by the CWTS
in the past (CPP/JCSm or CPP/FCSm) nor with the more recently proposed h-index
(Hirsch, 2005). Given the high correlations between the old and new &quot;crown&quot;
indicators, one can expect that the lack of correlation with the peer-review
based quality indicator applies equally to the newly developed ones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2593</identifier>
 <datestamp>2012-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2593</id><created>2011-02-13</created><updated>2012-08-16</updated><authors><author><keyname>Etzion</keyname><forenames>Tuvi</forenames></author><author><keyname>Silberstein</keyname><forenames>Natalia</forenames></author></authors><title>Codes and Designs Related to Lifted MRD Codes</title><categories>cs.IT cs.DM math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory. The material in
  this paper was presented in part in the 2011 IEEE International Symposium on
  Information Theory, Saint Petersburg, Russia, August 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Lifted maximum rank distance (MRD) codes, which are constant dimension codes,
are considered. It is shown that a lifted MRD code can be represented in such a
way that it forms a block design known as a transversal design. A slightly
different representation of this design makes it similar to a $q-$analog of a
transversal design. The structure of these designs is used to obtain upper
bounds on the sizes of constant dimension codes which contain a lifted MRD
code. Codes which attain these bounds are constructed. These codes are the
largest known codes for the given parameters. These transversal designs can be
also used to derive a new family of linear codes in the Hamming space. Bounds
on the minimum distance and the dimension of such codes are given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2598</identifier>
 <datestamp>2011-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2598</id><created>2011-02-13</created><authors><author><keyname>Ingber</keyname><forenames>Amir</forenames></author><author><keyname>Kochman</keyname><forenames>Yuval</forenames></author></authors><title>The Dispersion of Lossy Source Coding</title><categories>cs.IT math.IT</categories><comments>2011 Data Compression Conference, to appear (submitted Nov. 2010)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we investigate the behavior of the minimal rate needed in order
to guarantee a given probability that the distortion exceeds a prescribed
threshold, at some fixed finite quantization block length. We show that the
excess coding rate above the rate-distortion function is inversely proportional
(to the first order) to the square root of the block length. We give an
explicit expression for the proportion constant, which is given by the inverse
Q-function of the allowed excess distortion probability, times the square root
of a constant, termed the excess distortion dispersion. This result is the dual
of a corresponding channel coding result, where the dispersion above is the
dual of the channel dispersion. The work treats discrete memoryless sources, as
well as the quadratic-Gaussian case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2599</identifier>
 <datestamp>2015-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2599</id><created>2011-02-13</created><updated>2015-05-05</updated><authors><author><keyname>Wang</keyname><forenames>Xinhua</forenames></author><author><keyname>Shirinzadeh</keyname><forenames>Bijan</forenames></author></authors><title>Rapid-convergent nonlinear differentiator</title><categories>cs.SY</categories><comments>26 pages, 15 figures</comments><journal-ref>Mechanical Systems and Signal Processing, vol. 28, 2012, 414-431</journal-ref><doi>10.1016/j.ymssp.2011.09.026</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A nonlinear differentiator being fit for rapid convergence is presented,
which is based on singular perturbation technique. The differentiator design
can not only sufficiently reduce the chattering phenomenon of derivative
estimation by introducing a continuous power function, but the dynamical
performances are also improved by adding linear correction terms to the
nonlinear ones. Moreover, strong robustness ability is obtained by integrating
nonlinear items and the linear filter. The merits of the rapid-convergent
differentiator include the excellent dynamical performances, restraining noises
sufficiently, avoiding the chattering phenomenon and being not based on system
model. The theoretical results are confirmed by computer simulations and an
experiment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2600</identifier>
 <datestamp>2011-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2600</id><created>2011-02-13</created><authors><author><keyname>Wang</keyname><forenames>Xinhua</forenames></author></authors><title>High-order integral-chain differentiator and application to acceleration
  feedback</title><categories>cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The equivalence between integral-chain differentiator and usual high-gain
differentiator is given under suitable coordinate transformation.
Integral-chain differentiator can restrain noises more thoroughly than usual
high-gain linear differentiator. In integral-chain differentiator, disturbances
only exist in the last differential equation and can be restrained through each
layer of integrator. Moreover, a nonlinear integral-chain differentiator is
designed which is the expansion of linear integral-chain differentiator.
Finally, a 3-order differentiator is applied to the estimation of acceleration
for a second-order uncertain system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2602</identifier>
 <datestamp>2011-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2602</id><created>2011-02-13</created><authors><author><keyname>Chaharsooghi</keyname><forenames>Farhad Shirani</forenames></author><author><keyname>Emadi</keyname><forenames>Mohammad Javad</forenames></author><author><keyname>Zamanighomi</keyname><forenames>Mahdi</forenames></author><author><keyname>Aref</keyname><forenames>Mohammad Reza</forenames></author></authors><title>A New Method for Variable Elimination in Systems of Inequations</title><categories>cs.IT cs.DS math.IT</categories><comments>5 Pages, 0 Figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a new method for variable elimination in systems of
inequations which is much faster than the Fourier-Motzkin Elimination (FME)
method. In our method, a linear Diophantine problem is introduced which is dual
to our original problem. The new Diophantine system is then solved, and the
final result is calculated by finding the dual inequations system. Our new
method uses the algorithm Normaliz to find the Hilbert basis of the solution
space of the given Diophantine problem. We introduce a problem in the
interference channel with multiple nodes and solve it with our new method.
Next, we generalize our method to all problems involving FME and in the end we
compare our method with the previous method. We show that our method has many
advantages in comparison to the previous method. It does not produce many of
the redundant answers of the FME method. It also solves the whole problem in
one step whereas the previous method uses a step by step approach in
eliminating each auxiliary variable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2604</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2604</id><created>2011-02-13</created><updated>2012-08-17</updated><authors><author><keyname>Talebi</keyname><forenames>Mohammad Sadegh</forenames></author><author><keyname>Khonsari</keyname><forenames>Ahmad</forenames></author><author><keyname>Hajiesmaili</keyname><forenames>Mohammad Hassan</forenames></author><author><keyname>Jafarpour</keyname><forenames>Sina</forenames></author></authors><title>Quasi-Optimal Network Utility Maximization for Scalable Video Streaming</title><categories>cs.MM cs.NI</categories><comments>This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses rate control for transmission of scalable video streams
via Network Utility Maximization (NUM) formulation. Due to stringent QoS
requirements of video streams and specific characterization of utility
experienced by end-users, one has to solve nonconvex and even nonsmooth NUM
formulation for such streams, where dual methods often prove incompetent.
Convexification plays an important role in this work as it permits the use of
existing dual methods to solve an approximate to the NUM problem iteratively
and distributively. Hence, to tackle the nonsmoothness and nonconvexity, we aim
at reformulating the NUM problem through approximation and transformation of
the ideal discretely adaptive utility function for scalable video streams. The
reformulated problem is shown to be a D.C. (Difference of Convex) problem. We
leveraged Sequential Convex Programming (SCP) approach to replace the nonconvex
D.C. problem by a sequence of convex problems that aim to approximate the
original D.C. problem. We then solve each convex problem produced by SCP
approach using existing dual methods. This procedure is the essence of two
distributed iterative rate control algorithms proposed in this paper, for which
one can show the convergence to a locally optimal point of the nonconvex D.C.
problem and equivalently to a locally optimal point of an approximate to the
original nonconvex problem. Our experimental results show that the proposed
rate control algorithms converge with tractable convergence behavior.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2608</identifier>
 <datestamp>2011-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2608</id><created>2011-02-13</created><authors><author><keyname>Chimakurthi</keyname><forenames>Lskrao</forenames></author><author><keyname>D</keyname><forenames>Madhu Kumar S</forenames></author></authors><title>Power Efficient Resource Allocation for Clouds Using Ant Colony
  Framework</title><categories>cs.DC</categories><comments>6 pages, 1 figure, 6 algorithms</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cloud computing is one of the rapidly improving technologies. It provides
scalable resources needed for the ap- plications hosted on it. As cloud-based
services become more dynamic, resource provisioning becomes more challenging.
The QoS constrained resource allocation problem is considered in this paper, in
which customers are willing to host their applications on the provider's cloud
with a given SLA requirements for performance such as throughput and response
time. Since, the data centers hosting the applications consume huge amounts of
energy and cause huge operational costs, solutions that reduce energy
consumption as well as operational costs are gaining importance. In this work,
we propose an energy efficient mechanism that allocates the cloud resources to
the applications without violating the given service level agreements(SLA)
using Ant colony framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2615</identifier>
 <datestamp>2011-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2615</id><created>2011-02-13</created><updated>2011-02-20</updated><authors><author><keyname>Balcan</keyname><forenames>Doru C.</forenames></author><author><keyname>Srinivasa</keyname><forenames>Gowri</forenames></author><author><keyname>Fickus</keyname><forenames>Matthew</forenames></author><author><keyname>Kovacevic</keyname><forenames>Jelena</forenames></author></authors><title>Guaranteeing Convergence of Iterative Skewed Voting Algorithms for Image
  Segmentation</title><categories>math.FA cs.CV nlin.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we provide rigorous proof for the convergence of an iterative
voting-based image segmentation algorithm called Active Masks. Active Masks
(AM) was proposed to solve the challenging task of delineating punctate
patterns of cells from fluorescence microscope images. Each iteration of AM
consists of a linear convolution composed with a nonlinear thresholding; what
makes this process special in our case is the presence of additive terms whose
role is to &quot;skew&quot; the voting when prior information is available. In real-world
implementation, the AM algorithm always converges to a fixed point. We study
the behavior of AM rigorously and present a proof of this convergence. The key
idea is to formulate AM as a generalized (parallel) majority cellular
automaton, adapting proof techniques from discrete dynamical systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2616</identifier>
 <datestamp>2011-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2616</id><created>2011-02-13</created><authors><author><keyname>Bansal</keyname><forenames>Sanjay</forenames></author><author><keyname>Sharma</keyname><forenames>Sanjeev</forenames></author></authors><title>An Improved Multiple Faults Reassignment based Recovery in Cluster
  Computing</title><categories>cs.DC</categories><comments>Online at http://journalofcomputing.org</comments><journal-ref>Journal of Computing, Volume 2, Issue 11, November 2010, eISSN
  2151-9617</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In case of multiple node failures performance becomes very low as compare to
single node failure. Failures of nodes in cluster computing can be tolerated by
multiple fault tolerant computing. Existing recovery schemes are efficient for
single fault but not with multiple faults. Recovery scheme proposed in this
paper having two phases; sequentially phase, concurrent phase. In sequentially
phase, loads of all working nodes are uniformly and evenly distributed by
proposed dynamic rank based and load distribution algorithm. In concurrent
phase, loads of all failure nodes as well as new job arrival are assigned
equally to all available nodes by just finding the least loaded node among the
several nodes by failure nodes job allocation algorithm. Sequential and
concurrent executions of algorithms improve the performance as well better
resource utilization. Dynamic rank based algorithm for load redistribution
works as a sequential restoration algorithm and reassignment algorithm for
distribution of failure nodes to least loaded computing nodes works as a
concurrent recovery reassignment algorithm. Since load is evenly and uniformly
distributed among all available working nodes with less number of iterations,
low iterative time and communication overheads hence performance is improved.
Dynamic ranking algorithm is low overhead, high convergence algorithm for
reassignment of tasks uniformly among all available nodes. Reassignments of
failure nodes are done by a low overhead efficient failure job allocation
algorithm. Test results to show effectiveness of the proposed scheme are
presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2620</identifier>
 <datestamp>2011-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2620</id><created>2011-02-13</created><authors><author><keyname>Harmon</keyname><forenames>Dion</forenames></author><author><keyname>de Aguiar</keyname><forenames>Marcus A. M.</forenames></author><author><keyname>Chinellato</keyname><forenames>David D.</forenames></author><author><keyname>Braha</keyname><forenames>Dan</forenames></author><author><keyname>Epstein</keyname><forenames>Irving R.</forenames></author><author><keyname>Bar-Yam</keyname><forenames>Yaneer</forenames></author></authors><title>Predicting economic market crises using measures of collective panic</title><categories>q-fin.ST cs.SI physics.soc-ph</categories><comments>17 pages, 4 figures</comments><report-no>NECSI Report 2010-08-01</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Predicting panic is of critical importance in many areas of human and animal
behavior, notably in the context of economics. The recent financial crisis is a
case in point. Panic may be due to a specific external threat, or
self-generated nervousness. Here we show that the recent economic crisis and
earlier large single-day panics were preceded by extended periods of high
levels of market mimicry --- direct evidence of uncertainty and nervousness,
and of the comparatively weak influence of external news. High levels of
mimicry can be a quite general indicator of the potential for self-organized
crises.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2623</identifier>
 <datestamp>2011-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2623</id><created>2011-02-13</created><updated>2011-02-19</updated><authors><author><keyname>Friggeri</keyname><forenames>Adrien</forenames><affiliation>ENS / LIP Laboratoire de l'Informatique du Parall&#xe9;lisme / INRIA Grenoble Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Chelius</keyname><forenames>Guillaume</forenames><affiliation>ENS / LIP Laboratoire de l'Informatique du Parall&#xe9;lisme / INRIA Grenoble Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Fleury</keyname><forenames>Eric</forenames><affiliation>ENS / LIP Laboratoire de l'Informatique du Parall&#xe9;lisme / INRIA Grenoble Rh&#xf4;ne-Alpes, IXXI</affiliation></author></authors><title>Egomunities, Exploring Socially Cohesive Person-based Communities</title><categories>cs.SI cs.NI physics.soc-ph</categories><proxy>ccsd</proxy><report-no>RR-7535</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the last few years, there has been a great interest in detecting
overlapping communities in complex networks, which is understood as dense
groups of nodes featuring a low outbound density. To date, most methods used to
compute such communities stem from the field of disjoint community detection by
either extending the concept of modularity to an overlapping context or by
attempting to decompose the whole set of nodes into several possibly
overlapping subsets. In this report we take an orthogonal approach by
introducing a metric, the cohesion, rooted in sociological considerations. The
cohesion quantifies the community-ness of one given set of nodes, based on the
notions of triangles - triplets of connected nodes - and weak ties, instead of
the classical view using only edge density. A set of nodes has a high cohesion
if it features a high density of triangles and intersects few triangles with
the rest of the network. As such, we introduce a numerical characterization of
communities: sets of nodes featuring a high cohesion. We then present a new
approach to the problem of overlapping communities by introducing the concept
of ego-munities, which are subjective communities centered around a given node,
specifically inside its neighborhood. We build upon the cohesion to construct a
heuristic algorithm which outputs a node's ego-munities by attempting to
maximize their cohesion. We illustrate the pertinence of our method with a
detailed description of one person's ego-munities among Facebook friends. We
finally conclude by describing promising applications of ego-munities such as
information inference and interest recommendations, and present a possible
extension to cohesion in the case of weighted networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2624</identifier>
 <datestamp>2012-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2624</id><created>2011-02-13</created><updated>2012-02-14</updated><authors><author><keyname>Fawzi</keyname><forenames>Omar</forenames></author><author><keyname>Hayden</keyname><forenames>Patrick</forenames></author><author><keyname>Savov</keyname><forenames>Ivan</forenames></author><author><keyname>Sen</keyname><forenames>Pranab</forenames></author><author><keyname>Wilde</keyname><forenames>Mark M.</forenames></author></authors><title>Classical communication over a quantum interference channel</title><categories>quant-ph cs.IT math.IT</categories><comments>21 pages, 6 figures, v5: Accepted for publication in the IEEE
  Transactions on Information Theory</comments><journal-ref>IEEE Transactions on Information Theory, vol. 58, no. 6, pp.
  3670-3691 (June 2012)</journal-ref><doi>10.1109/TIT.2012.2188620</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Calculating the capacity of interference channels is a notorious open problem
in classical information theory. Such channels have two senders and two
receivers, and each sender would like to communicate with a partner receiver.
The capacity of such channels is known exactly in the settings of &quot;very strong&quot;
and &quot;strong&quot; interference, while the Han-Kobayashi coding strategy gives the
best known achievable rate region in the general case. Here, we introduce and
study the quantum interference channel, a natural generalization of the
interference channel to the setting of quantum information theory. We restrict
ourselves for the most part to channels with two classical inputs and two
quantum outputs in order to simplify the presentation of our results (though
generalizations of our results to channels with quantum inputs are
straightforward). We are able to determine the exact classical capacity of this
channel in the settings of &quot;very strong&quot; and &quot;strong&quot; interference, by
exploiting Winter's successive decoding strategy and a novel two-sender quantum
simultaneous decoder, respectively. We provide a proof that a Han-Kobayashi
strategy is achievable with Holevo information rates, up to a conjecture
regarding the existence of a three-sender quantum simultaneous decoder. This
conjecture holds for a special class of quantum multiple access channels with
average output states that commute, and we discuss some other variations of the
conjecture that hold. Finally, we detail a connection between the quantum
interference channel and prior work on the capacity of bipartite unitary gates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2627</identifier>
 <datestamp>2011-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2627</id><created>2011-02-13</created><updated>2011-05-20</updated><authors><author><keyname>Guha</keyname><forenames>Saikat</forenames></author><author><keyname>Savov</keyname><forenames>Ivan</forenames></author><author><keyname>Wilde</keyname><forenames>Mark M.</forenames></author></authors><title>The free space optical interference channel</title><categories>quant-ph cs.IT math.IT</categories><comments>5 pages, 3 figures, Accepted for ISIT 2011, Saint-Petersburg, Russia,
  v2 has minor changes</comments><journal-ref>Proceedings of the International Symposium on Information Theory
  2011 (ISIT 2011), pp. 114--118, St. Petersburg, Russia</journal-ref><doi>10.1109/ISIT.2011.6033712</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Semiclassical models for multiple-user optical communication cannot assess
the ultimate limits on reliable communication as permitted by the laws of
physics. In all optical communications settings that have been analyzed within
a quantum framework so far, the gaps between the quantum limit to the capacity
and the Shannon limit for structured receivers become most significant in the
low photon-number regime. Here, we present a quantum treatment of a
multiple-transmitter multiple-receiver multi-spatial-mode free-space
interference channel with diffraction-limited loss and a thermal background. We
consider the performance of a laser-light (coherent state) encoding in
conjunction with various detection strategies such as homodyne, heterodyne, and
joint detection. Joint detection outperforms both homodyne and heterodyne
detection whenever the channel exhibits &quot;very strong&quot; interference. We
determine the capacity region for homodyne or heterodyne detection when the
channel has &quot;strong&quot; interference, and we conjecture the existence of a joint
detection strategy that outperforms the former two strategies in this case.
Finally, we determine the Han-Kobayashi achievable rate regions for both
homodyne and heterodyne detection and compare them to a region achievable by a
conjectured joint detection strategy. In these latter cases, we determine
achievable rate regions if the receivers employ a recently discovered
min-entropy quantum simultaneous decoder.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2641</identifier>
 <datestamp>2011-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2641</id><created>2011-02-13</created><updated>2011-05-01</updated><authors><author><keyname>Baer</keyname><forenames>Michael B.</forenames></author></authors><title>Improved Redundancy Bounds for Exponential Objectives</title><categories>cs.IT math.IT</categories><comments>5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present new lower and upper bounds for the compression rate of binary
prefix codes optimized over memoryless sources according to two related
exponential codeword length objectives. The objectives explored here are
exponential-average length and exponential-average redundancy. The first of
these relates to various problems involving queueing, uncertainty, and lossless
communications, and it can be reduced to the second, which has properties more
amenable to analysis. These bounds, some of which are tight, are in terms of a
form of entropy and/or the probability of an input symbol, improving on
recently discovered bounds of similar form. We also observe properties of
optimal codes over the exponential-average redundancy utility.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2645</identifier>
 <datestamp>2011-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2645</id><created>2011-02-13</created><updated>2011-04-15</updated><authors><author><keyname>Santos</keyname><forenames>Francisco</forenames></author></authors><title>Embedding a pair of graphs in a surface, and the width of 4-dimensional
  prismatoids</title><categories>math.CO cs.CG</categories><comments>This paper and arXiv:1101.3050 have been merged, forming now the
  paper arXiv:1104.2630</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A prismatoid is a polytope with all its vertices contained in two parallel
facets, called its bases. Its width is the number of steps needed to go from
one base to the other in the dual graph. The author recently showed in
arXiv:1006.2814 that the existence of counter-examples to the Hirsch conjecture
is equivalent to that of $d$-prismatoids of width larger than $d$, and
constructed such prismatoids in dimension five. Here we show that the same is
impossible in dimension four. This is proved by looking at the pair of graph
embeddings on a 2-sphere that arise from the normal fans of the two bases of
$Q$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2651</identifier>
 <datestamp>2011-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2651</id><created>2011-02-13</created><authors><author><keyname>Corradini</keyname><forenames>Andrea</forenames><affiliation>Dipartimento di Informatica, Pisa, Italy</affiliation></author><author><keyname>Drewes</keyname><forenames>Frank</forenames><affiliation>Department of Computing Science, Ume&#xe5;, Sweden</affiliation></author></authors><title>Term Graph Rewriting and Parallel Term Rewriting</title><categories>cs.LO</categories><comments>In Proceedings TERMGRAPH 2011, arXiv:1102.2268</comments><proxy>EPTCS</proxy><acm-class>F.4.2</acm-class><journal-ref>EPTCS 48, 2011, pp. 3-18</journal-ref><doi>10.4204/EPTCS.48.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The relationship between Term Graph Rewriting and Term Rewriting is well
understood: a single term graph reduction may correspond to several term
reductions, due to sharing. It is also known that if term graphs are allowed to
contain cycles, then one term graph reduction may correspond to infinitely many
term reductions. We stress that this fact can be interpreted in two ways.
According to the &quot;sequential interpretation&quot;, a term graph reduction
corresponds to an infinite sequence of term reductions, as formalized by
Kennaway et.al. using strongly converging derivations over the complete metric
space of infinite terms. Instead according to the &quot;parallel interpretation&quot; a
term graph reduction corresponds to the parallel reduction of an infinite set
of redexes in a rational term. We formalize the latter notion by exploiting the
complete partial order of infinite and possibly partial terms, and we stress
that this interpretation allows to explain the result of reducing circular
redexes in several approaches to term graph rewriting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2652</identifier>
 <datestamp>2011-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2652</id><created>2011-02-13</created><authors><author><keyname>Bellet</keyname><forenames>Thomas</forenames><affiliation>University of Poitiers</affiliation></author><author><keyname>Arnould</keyname><forenames>Agn&#xe8;s</forenames><affiliation>University of Poitiers</affiliation></author><author><keyname>Gall</keyname><forenames>Pascale Le</forenames><affiliation>Ecole Centrale Paris</affiliation></author></authors><title>Rule-based transformations for geometric modelling</title><categories>cs.GR cs.DM</categories><comments>In Proceedings TERMGRAPH 2011, arXiv:1102.2268</comments><proxy>EPTCS</proxy><acm-class>I.3.5; G.2.2</acm-class><journal-ref>EPTCS 48, 2011, pp. 20-37</journal-ref><doi>10.4204/EPTCS.48.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The context of this paper is the use of formal methods for topology-based
geometric modelling. Topology-based geometric modelling deals with objects of
various dimensions and shapes. Usually, objects are defined by a graph-based
topological data structure and by an embedding that associates each topological
element (vertex, edge, face, etc.) with relevant data as their geometric shape
(position, curve, surface, etc.) or application dedicated data (e.g. molecule
concentration level in a biological context). We propose to define
topology-based geometric objects as labelled graphs. The arc labelling defines
the topological structure of the object whose topological consistency is then
ensured by labelling constraints. Nodes have as many labels as there are
different data kinds in the embedding. Labelling constraints ensure then that
the embedding is consistent with the topological structure. Thus,
topology-based geometric objects constitute a particular subclass of a category
of labelled graphs in which nodes have multiple labels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2653</identifier>
 <datestamp>2011-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2653</id><created>2011-02-13</created><authors><author><keyname>Kahl</keyname><forenames>Wolfram</forenames><affiliation>McMaster University</affiliation></author></authors><title>Dependently-Typed Formalisation of Typed Term Graphs</title><categories>cs.LO cs.PL</categories><comments>In Proceedings TERMGRAPH 2011, arXiv:1102.2268</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 48, 2011, pp. 38-53</journal-ref><doi>10.4204/EPTCS.48.6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We employ the dependently-typed programming language Agda2 to explore
formalisation of untyped and typed term graphs directly as set-based graph
structures, via the gs-monoidal categories of Corradini and Gadducci, and as
nested let-expressions using Pouillard and Pottier's NotSoFresh library of
variable-binding abstractions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2654</identifier>
 <datestamp>2011-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2654</id><created>2011-02-13</created><authors><author><keyname>Andrei</keyname><forenames>Oana</forenames><affiliation>School of Computing Science, University of Glasgow</affiliation></author><author><keyname>Fern&#xe1;ndez</keyname><forenames>Maribel</forenames><affiliation>King's College London</affiliation></author><author><keyname>Kirchner</keyname><forenames>H&#xe9;l&#xe8;ne</forenames><affiliation>INRIA Bordeaux Sud-Ouest</affiliation></author><author><keyname>Melan&#xe7;on</keyname><forenames>Guy</forenames><affiliation>INRIA Bordeaux Sud-Ouest</affiliation></author><author><keyname>Namet</keyname><forenames>Olivier</forenames><affiliation>King's College London</affiliation></author><author><keyname>Pinaud</keyname><forenames>Bruno</forenames><affiliation>INRIA Bordeaux Sud-Ouest</affiliation></author></authors><title>PORGY: Strategy-Driven Interactive Transformation of Graphs</title><categories>cs.CE cs.SE</categories><comments>In Proceedings TERMGRAPH 2011, arXiv:1102.2268</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 48, 2011, pp. 54-68</journal-ref><doi>10.4204/EPTCS.48.7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the use of graph rewriting systems as a modelling
tool, and advocates the embedding of such systems in an interactive
environment. One important application domain is the modelling of biochemical
systems, where states are represented by port graphs and the dynamics is driven
by rules and strategies. A graph rewriting tool's capability to interactively
explore the features of the rewriting system provides useful insights into
possible behaviours of the model and its properties. We describe PORGY, a
visual and interactive tool we have developed to model complex systems using
port graphs and port graph rewrite rules guided by strategies, and to navigate
in the derivation history. We demonstrate via examples some functionalities
provided by PORGY.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2655</identifier>
 <datestamp>2011-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2655</id><created>2011-02-13</created><authors><author><keyname>Alves</keyname><forenames>Sandra</forenames><affiliation>University of Porto</affiliation></author><author><keyname>Fern&#xe1;ndez</keyname><forenames>Maribel</forenames><affiliation>King's College London</affiliation></author><author><keyname>Mackie</keyname><forenames>Ian</forenames><affiliation>Ecole Polytechnique</affiliation></author></authors><title>A new graphical calculus of proofs</title><categories>cs.LO</categories><comments>In Proceedings TERMGRAPH 2011, arXiv:1102.2268</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 48, 2011, pp. 69-84</journal-ref><doi>10.4204/EPTCS.48.8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We offer a simple graphical representation for proofs of intuitionistic
logic, which is inspired by proof nets and interaction nets (two formalisms
originating in linear logic). This graphical calculus of proofs inherits good
features from each, but is not constrained by them. By the Curry-Howard
isomorphism, the representation applies equally to the lambda calculus,
offering an alternative diagrammatic representation of functional computations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2656</identifier>
 <datestamp>2011-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2656</id><created>2011-02-13</created><authors><author><keyname>Rochel</keyname><forenames>Jan</forenames><affiliation>Utrecht University, The Netherlands</affiliation></author><author><keyname>Grabmayer</keyname><forenames>Clemens</forenames><affiliation>Utrecht University, The Netherlands</affiliation></author></authors><title>Repetitive Reduction Patterns in Lambda Calculus with letrec (Work in
  Progress)</title><categories>cs.PL</categories><comments>In Proceedings TERMGRAPH 2011, arXiv:1102.2268</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 48, 2011, pp. 85-100</journal-ref><doi>10.4204/EPTCS.48.9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For the lambda-calculus with letrec we develop an optimisation, which is
based on the contraction of a certain class of 'future' (also: virtual)
redexes.
  In the implementation of functional programming languages it is common
practice to perform beta-reductions at compile time whenever possible in order
to produce code that requires fewer reductions at run time. This is, however,
in principle limited to redexes and created redexes that are 'visible' (in the
sense that they can be contracted without the need for unsharing), and cannot
generally be extended to redexes that are concealed by sharing constructs such
as letrec. In the case of recursion, concealed redexes become visible only
after unwindings during evaluation, and then have to be contracted time and
again.
  We observe that in some cases such redexes exhibit a certain form of
repetitive behaviour at run time. We describe an analysis for identifying
binders that give rise to such repetitive reduction patterns, and eliminate
them by a sort of predictive contraction. Thereby these binders are lifted out
of recursive positions or eliminated altogether, as a result alleviating the
amount of beta-reductions required for each recursive iteration.
  Both our analysis and simplification are suitable to be integrated into
existing compilers for functional programming languages as an additional
optimisation phase. With this work we hope to contribute to increasing the
efficiency of executing programs written in such languages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2670</identifier>
 <datestamp>2011-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2670</id><created>2011-02-13</created><authors><author><keyname>Abbasi-Yadkori</keyname><forenames>Yasin</forenames></author><author><keyname>Pal</keyname><forenames>David</forenames></author><author><keyname>Szepesvari</keyname><forenames>Csaba</forenames></author></authors><title>Online Least Squares Estimation with Self-Normalized Processes: An
  Application to Bandit Problems</title><categories>cs.AI</categories><comments>Submitted to the 24th Annual Conference on Learning Theory (COLT
  2011)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The analysis of online least squares estimation is at the heart of many
stochastic sequential decision making problems. We employ tools from the
self-normalized processes to provide a simple and self-contained proof of a
tail bound of a vector-valued martingale. We use the bound to construct a new
tighter confidence sets for the least squares estimate.
  We apply the confidence sets to several online decision problems, such as the
multi-armed and the linearly parametrized bandit problems. The confidence sets
are potentially applicable to other problems such as sleeping bandits,
generalized linear bandits, and other linear control problems.
  We improve the regret bound of the Upper Confidence Bound (UCB) algorithm of
Auer et al. (2002) and show that its regret is with high-probability a problem
dependent constant. In the case of linear bandits (Dani et al., 2008), we
improve the problem dependent bound in the dimension and number of time steps.
Furthermore, as opposed to the previous result, we prove that our bound holds
for small sample sizes, and at the same time the worst case bound is improved
by a logarithmic factor and the constant is improved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2673</identifier>
 <datestamp>2011-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2673</id><created>2011-02-13</created><authors><author><keyname>Burgain</keyname><forenames>Pierrick</forenames></author><author><keyname>Feron</keyname><forenames>Eric</forenames></author></authors><title>Environmental benefits of enhanced surveillance technology on airport
  departure operations</title><categories>cs.SY</categories><comments>25 pages, submitted to US/EUrope 2011 ATM seminar</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Airport departure operations constitute an important source of airline delays
and passenger frustration. Excessive surface traffic is the cause of increased
controller and pilot workload; It is also the source of increased emissions; It
worsens traffic safety and often does not yield improved runway throughput.
Acknowledging this fact, this paper explores some of the feedback mechanisms by
which airport traffic can be optimized in real time according to its current
degree of congestion. In particular, it examines the environmnetal benefits
that improved surveillance technologies can bring in the context of gate- or
spot-release aircraft strategies. It is shown that improvements can lead yield
4% to 6% emission reductions for busy airports like New-York La Guardia or
Seattle Tacoma. These benefits come on top of the benefits already obtained by
adopting threshold strategies currently under evaluation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2677</identifier>
 <datestamp>2013-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2677</id><created>2011-02-14</created><updated>2013-03-27</updated><authors><author><keyname>Duarte</keyname><forenames>Marco F.</forenames></author><author><keyname>Wakin</keyname><forenames>Michael B.</forenames></author><author><keyname>Baron</keyname><forenames>Dror</forenames></author><author><keyname>Sarvotham</keyname><forenames>Shriram</forenames></author><author><keyname>Baraniuk</keyname><forenames>Richard G.</forenames></author></authors><title>Measurement Bounds for Sparse Signal Ensembles via Graphical Models</title><categories>cs.IT math.IT</categories><comments>11 pages, 2 figures</comments><journal-ref>IEEE Transactions on Information Theory, 2013</journal-ref><doi>10.1109/TIT.2013.2252051</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In compressive sensing, a small collection of linear projections of a sparse
signal contains enough information to permit signal recovery. Distributed
compressive sensing (DCS) extends this framework by defining ensemble sparsity
models, allowing a correlated ensemble of sparse signals to be jointly
recovered from a collection of separately acquired compressive measurements. In
this paper, we introduce a framework for modeling sparse signal ensembles that
quantifies the intra- and inter-signal dependencies within and among the
signals. This framework is based on a novel bipartite graph representation that
links the sparse signal coefficients with the measurements obtained for each
signal. Using our framework, we provide fundamental bounds on the number of
noiseless measurements that each sensor must collect to ensure that the signals
are jointly recoverable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2678</identifier>
 <datestamp>2011-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2678</id><created>2011-02-14</created><updated>2011-05-01</updated><authors><author><keyname>Baer</keyname><forenames>Michael B.</forenames></author><author><keyname>Rezaei</keyname><forenames>Farzad</forenames></author><author><keyname>Charalambous</keyname><forenames>Charalambos D.</forenames></author></authors><title>Minimum Redundancy Coding for Uncertain Sources</title><categories>cs.IT math.IT</categories><comments>5 pages</comments><acm-class>E.4; H.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider the set of source distributions within a fixed maximum relative
entropy with respect to a given nominal distribution. Lossless source coding
over this relative entropy ball can be approached in more than one way. A
problem previously considered is finding a minimax average length source code.
The minimizing players are the codeword lengths --- real numbers for arithmetic
codes, integers for prefix codes --- while the maximizing players are the
uncertain source distributions. Another traditional minimizing objective is the
first one considered here, maximum (average) redundancy. This problem reduces
to an extension of an exponential Huffman objective treated in the literature
but heretofore without direct practical application. In addition to these, this
paper examines the related problem of maximal minimax pointwise redundancy and
the problem considered by Gawrychowski and Gagie, which, for a sufficiently
small relative entropy ball, is equivalent to minimax redundancy. One can
consider both Shannon-like coding based on optimal real number (&quot;ideal&quot;)
codeword lengths and a Huffman-like optimal prefix coding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2684</identifier>
 <datestamp>2011-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2684</id><created>2011-02-14</created><authors><author><keyname>Nielsen</keyname><forenames>Frank</forenames></author></authors><title>Chernoff information of exponential families</title><categories>cs.IT cs.CV cs.IR math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Chernoff information upper bounds the probability of error of the optimal
Bayesian decision rule for $2$-class classification problems. However, it turns
out that in practice the Chernoff bound is hard to calculate or even
approximate. In statistics, many usual distributions, such as Gaussians,
Poissons or frequency histograms called multinomials, can be handled in the
unified framework of exponential families. In this note, we prove that the
Chernoff information for members of the same exponential family can be either
derived analytically in closed form, or efficiently approximated using a simple
geodesic bisection optimization technique based on an exact geometric
characterization of the &quot;Chernoff point&quot; on the underlying statistical
manifold.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2700</identifier>
 <datestamp>2011-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2700</id><created>2011-02-14</created><updated>2011-02-15</updated><authors><author><keyname>Wachter</keyname><forenames>Antonia</forenames></author><author><keyname>Sidorenko</keyname><forenames>Vladimir</forenames></author><author><keyname>Bossert</keyname><forenames>Martin</forenames></author><author><keyname>Zyablov</keyname><forenames>Victor</forenames></author></authors><title>On (Partial) Unit Memory Codes Based on Gabidulin Codes</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  (Partial) Unit Memory ((P)UM) codes provide a powerful possibility to
construct convolutional codes based on block codes in order to achieve a high
decoding performance. In this contribution, a construction based on Gabidulin
codes is considered. This construction requires a modified rank metric, the
so-called sum rank metric. For the sum rank metric, the free rank distance, the
extended row rank distance and its slope are defined analogous to the extended
row distance in Hamming metric. Upper bounds for the free rank distance and the
slope of (P)UM codes in the sum rank metric are derived and an explicit
construction of (P)UM codes based on Gabidulin codes is given, achieving the
upper bound for the free rank distance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2701</identifier>
 <datestamp>2014-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2701</id><created>2011-02-14</created><authors><author><keyname>Pratelli</keyname><forenames>Luca</forenames></author><author><keyname>Baccini</keyname><forenames>Alberto</forenames></author><author><keyname>Barabesi</keyname><forenames>Lucio</forenames></author><author><keyname>Marcheselli</keyname><forenames>Marzia</forenames></author></authors><title>Statistical analysis of the Hirsch Index</title><categories>math.ST cs.DL physics.soc-ph stat.TH</categories><msc-class>62G05, 62G20, 62G32</msc-class><journal-ref>Scandinavian Journal of Statistics Volume 39, Issue 4, pages
  681-694, December 2012</journal-ref><doi>10.1111/j.1467-9469.2011.00782.x</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Hirsch index (commonly referred to as h-index) is a bibliometric
indicator which is widely recognized as effective for measuring the scientific
production of a scholar since it summarizes size and impact of the research
output. In a formal setting, the h-index is actually an empirical functional of
the distribution of the citation counts received by the scholar. Under this
approach, the asymptotic theory for the empirical h-index has been recently
exploited when the citation counts follow a continuous distribution and, in
particular, variance estimation has been considered for the Pareto-type and the
Weibull-type distribution families. However, in bibliometric applications,
citation counts display a distribution supported by the integers. Thus, we
provide general properties for the empirical h-index under the small- and
large-sample settings. In addition, we also introduce consistent nonparametric
variance estimation, which allows for the implemention of large-sample set
estimation for the theoretical h-index.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2702</identifier>
 <datestamp>2011-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2702</id><created>2011-02-14</created><updated>2011-09-19</updated><authors><author><keyname>Tamo</keyname><forenames>Itzhak</forenames></author><author><keyname>Schwartz</keyname><forenames>Moshe</forenames></author></authors><title>On the Labeling Problem of Permutation Group Codes under the Infinity
  Metric</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Codes over permutations under the infinity norm have been recently suggested
as a coding scheme for correcting limited-magnitude errors in the rank
modulation scheme. Given such a code, we show that a simple relabeling
operation, which produces an isomorphic code, may drastically change the
minimal distance of the code. Thus, we may choose a code structure for
efficient encoding/decoding procedures, and then optimize the code's minimal
distance via relabeling.
  We formally define the relabeling problem, and show that all codes may be
relabeled to get a minimal distance at most 2. The decision problem of whether
a code may be relabeled to distance 1 is shown to be NP-complete, and
calculating the best achievable minimal distance after relabeling is proved
hard to approximate.
  Finally, we consider general bounds on the relabeling problem. We
specifically show the optimal relabeling distance of cyclic groups. A specific
case of a general probabilistic argument is used to show $\agl(p)$ may be
relabeled to a minimal distance of $p-O(\sqrt{p\ln p})$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2706</identifier>
 <datestamp>2011-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2706</id><created>2011-02-14</created><authors><author><keyname>Florian</keyname><forenames>E.</forenames></author><author><keyname>Chevreuil</keyname><forenames>A.</forenames></author><author><keyname>Loubaton</keyname><forenames>P.</forenames></author></authors><title>Blind source separation of convolutive mixtures of non circular linearly
  modulated signals with unknown baud rates</title><categories>cs.IT math.IT</categories><comments>15 pages, 5 figures, 1 table, based on conference article &quot;Blind
  source separation of convolutive mixtures of non circular linearly modulated
  signals with unknown baud rates&quot; - E.Florian, A.Chevreuil, Ph.Loubaton -
  EUSIPCO 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the problem of blind separation of convolutive mixtures
of BPSK and circular linearly modulated signals with unknown (and possibly
different) baud rates and carrier frequencies. In previous works, we
established that the Constant Modulus Algorithm (CMA) is able to extract a
source from a convolutive mixture of circular linearly modulated signals. We
extend the analysis of the extraction capabilities of the CMA when the mixing
also contains BPSK signals. We prove that if the various source signals do not
share any non zero cyclic frequency nor any non conjugate cyclic frequencies,
the local minima of the constant modulus cost function are separating filters.
Unfortunately, the minimization of the Godard cost function generally fails
when considering BPSK signals that have the same rates and the same carrier
frequencies. This failure is due to the existence of non-separating local
minima of the Godard cost function. In order to achieve the separation, we
propose a simple modification of the Godard cost function which only requires
knowledge of the BPSK sources frequency offsets at the receiver side. We
provide various simulations of realistic digital communications scenarios that
support our theoretical statements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2719</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2719</id><created>2011-02-14</created><updated>2014-08-17</updated><authors><author><keyname>Say</keyname><forenames>Cem</forenames><affiliation>Bogazici University</affiliation></author><author><keyname>Yakaryilmaz</keyname><forenames>Abuzer</forenames><affiliation>University of Latvia</affiliation></author></authors><title>Finite state verifiers with constant randomness</title><categories>cs.CC cs.LO</categories><comments>17 pages. An improved version</comments><proxy>LMCS</proxy><journal-ref>Logical Methods in Computer Science, Volume 10, Issue 3 (August
  19, 2014) lmcs:724</journal-ref><doi>10.2168/LMCS-10(3:6)2014</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a new characterization of $\mathsf{NL}$ as the class of languages
whose members have certificates that can be verified with small error in
polynomial time by finite state machines that use a constant number of random
bits, as opposed to its conventional description in terms of deterministic
logarithmic-space verifiers. It turns out that allowing two-way interaction
with the prover does not change the class of verifiable languages, and that no
polynomially bounded amount of randomness is useful for constant-memory
computers when used as language recognizers, or public-coin verifiers. A
corollary of our main result is that the class of outcome problems
corresponding to O(log n)-space bounded games of incomplete information where
the universal player is allowed a constant number of moves equals NL.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2730</identifier>
 <datestamp>2011-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2730</id><created>2011-02-14</created><authors><author><keyname>Lazzarotto</keyname><forenames>Francesco</forenames></author><author><keyname>Fabiani</keyname><forenames>Sergio</forenames></author><author><keyname>Costa</keyname><forenames>Enrico</forenames></author><author><keyname>Del Monte</keyname><forenames>Ettore</forenames></author><author><keyname>Di Persio</keyname><forenames>Giuseppe</forenames></author><author><keyname>Donnarumma</keyname><forenames>Immacolata</forenames></author><author><keyname>Evangelista</keyname><forenames>Yuri</forenames></author><author><keyname>Feroci</keyname><forenames>Marco</forenames></author><author><keyname>Pacciani</keyname><forenames>Luigi</forenames></author><author><keyname>Rubini</keyname><forenames>Alda</forenames></author><author><keyname>Soffitta</keyname><forenames>Paolo</forenames></author></authors><title>A method to develop mission critical data processing systems for
  satellite based instruments. The spinning mode case</title><categories>astro-ph.IM cs.SE</categories><comments>proceedings of the COSPAR 2010 assembly, Bremen, Germany</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modern satellite based experiments are often very complex real-time systems,
composed by flight and ground segments, that have challenging resource related
constraints, in terms of size, weight, power, requirements for real-time
response, fault tolerance, and specialized input/output hardware-software, and
they must be certified to high levels of assurance. Hardware-software data
processing systems have to be responsive to system degradation and to changes
in the data acquisition modes, and actions have to be taken to change the
organization of the mission operations. A big research &amp; develop effort in a
team composed by scientists and technologists can lead to produce software
systems able to optimize the hardware to reach very high levels of performance
or to pull degraded hardware to maintain satisfactory features. We'll show
real-life examples describing a system, processing the data of a X-Ray detector
on satellite-based mission in spinning mode.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2731</identifier>
 <datestamp>2011-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2731</id><created>2011-02-14</created><updated>2011-02-18</updated><authors><author><keyname>Lou</keyname><forenames>Hongwei</forenames></author></authors><title>Necessary and Sufficient Conditions for Distinguishability of Linear
  Control Systems</title><categories>math.OC cs.SY</categories><comments>13 pages</comments><msc-class>34H05, 93B99</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distinguishability takes a crucial rule in studying observability of hybrid
system such as switched system. Recently, for two linear systems, Lou and Si
gave a condition not only necessary but also sufficient to the
distinguishability of linear systems. However, the condition is not easy enough
to verify. This paper will give a new equivalent condition which is relatively
easy to verify.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2734</identifier>
 <datestamp>2011-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2734</id><created>2011-02-14</created><updated>2011-03-25</updated><authors><author><keyname>Kashyap</keyname><forenames>Navin</forenames></author><author><keyname>Thangaraj</keyname><forenames>Andrew</forenames></author></authors><title>The Treewidth of MDS and Reed-Muller Codes</title><categories>cs.IT cs.DM math.IT</categories><comments>This constitutes a major upgrade of previous versions; submitted to
  IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The constraint complexity of a graphical realization of a linear code is the
maximum dimension of the local constraint codes in the realization. The
treewidth of a linear code is the least constraint complexity of any of its
cycle-free graphical realizations. This notion provides a useful
parametrization of the maximum-likelihood decoding complexity for linear codes.
In this paper, we prove the surprising fact that for maximum distance separable
codes and Reed-Muller codes, treewidth equals trelliswidth, which, for a code,
is defined to be the least constraint complexity (or branch complexity) of any
of its trellis realizations. From this, we obtain exact expressions for the
treewidth of these codes, which constitute the only known explicit expressions
for the treewidth of algebraic codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2738</identifier>
 <datestamp>2011-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2738</id><created>2011-02-14</created><authors><author><keyname>Yukalov</keyname><forenames>V. I.</forenames></author><author><keyname>Sornette</keyname><forenames>D.</forenames></author></authors><title>Decision Theory with Prospect Interference and Entanglement</title><categories>math-ph cs.AI math.MP physics.soc-ph quant-ph</categories><comments>Latex file, 42 pages</comments><journal-ref>Theor. Dec. 70 (2011) 283-328</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel variant of decision making based on the mathematical
theory of separable Hilbert spaces. This mathematical structure captures the
effect of superposition of composite prospects, including many incorporated
intentions, which allows us to describe a variety of interesting fallacies and
anomalies that have been reported to particularize the decision making of real
human beings. The theory characterizes entangled decision making,
non-commutativity of subsequent decisions, and intention interference. We
demonstrate how the violation of the Savage's sure-thing principle, known as
the disjunction effect, can be explained quantitatively as a result of the
interference of intentions, when making decisions under uncertainty. The
disjunction effects, observed in experiments, are accurately predicted using a
theorem on interference alternation that we derive, which connects
aversion-to-uncertainty to the appearance of negative interference terms
suppressing the probability of actions. The conjunction fallacy is also
explained by the presence of the interference terms. A series of experiments
are analysed and shown to be in excellent agreement with a priori evaluation of
interference effects. The conjunction fallacy is also shown to be a sufficient
condition for the disjunction effect and novel experiments testing the combined
interplay between the two effects are suggested.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2739</identifier>
 <datestamp>2011-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2739</id><created>2011-02-14</created><authors><author><keyname>Tarasenko</keyname><forenames>Sergey S.</forenames></author></authors><title>A General Framework for Development of the Cortex-like Visual Object
  Recognition System: Waves of Spikes, Predictive Coding and Universal
  Dictionary of Features</title><categories>cs.CV cs.AI cs.LG cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This study is focused on the development of the cortex-like visual object
recognition system. We propose a general framework, which consists of three
hierarchical levels (modules). These modules functionally correspond to the V1,
V4 and IT areas. Both bottom-up and top-down connections between the
hierarchical levels V4 and IT are employed. The higher the degree of matching
between the input and the preferred stimulus, the shorter the response time of
the neuron. Therefore information about a single stimulus is distributed in
time and is transmitted by the waves of spikes. The reciprocal connections and
waves of spikes implement predictive coding: an initial hypothesis is generated
on the basis of information delivered by the first wave of spikes and is tested
with the information carried by the consecutive waves. The development is
considered as extraction and accumulation of features in V4 and objects in IT.
Once stored a feature can be disposed, if rarely activated. This cause update
of feature repository. Consequently, objects in IT are also updated. This
illustrates the growing process and dynamical change of topological structures
of V4, IT and connections between these areas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2743</identifier>
 <datestamp>2011-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2743</id><created>2011-02-14</created><updated>2011-05-06</updated><authors><author><keyname>Liang</keyname><forenames>Yixiong</forenames></author><author><keyname>Wang</keyname><forenames>Lei</forenames></author><author><keyname>Liao</keyname><forenames>Shenghui</forenames></author><author><keyname>Zou</keyname><forenames>Beiji</forenames></author></authors><title>Feature selection via simultaneous sparse approximation for person
  specific face verification</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There is an increasing use of some imperceivable and redundant local features
for face recognition. While only a relatively small fraction of them is
relevant to the final recognition task, the feature selection is a crucial and
necessary step to select the most discriminant ones to obtain a compact face
representation. In this paper, we investigate the sparsity-enforced
regularization-based feature selection methods and propose a multi-task feature
selection method for building person specific models for face verification. We
assume that the person specific models share a common subset of features and
novelly reformulated the common subset selection problem as a simultaneous
sparse approximation problem. To the best of our knowledge, it is the first
time to apply the sparsity-enforced regularization methods for person specific
face verification. The effectiveness of the proposed methods is verified with
the challenging LFW face databases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2748</identifier>
 <datestamp>2011-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2748</id><created>2011-02-14</created><authors><author><keyname>Liang</keyname><forenames>Yixiong</forenames></author><author><keyname>Wang</keyname><forenames>Lei</forenames></author><author><keyname>Xiang</keyname><forenames>Yao</forenames></author><author><keyname>Zou</keyname><forenames>Beiji</forenames></author></authors><title>Feature Selection via Sparse Approximation for Face Recognition</title><categories>cs.CV cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inspired by biological vision systems, the over-complete local features with
huge cardinality are increasingly used for face recognition during the last
decades. Accordingly, feature selection has become more and more important and
plays a critical role for face data description and recognition. In this paper,
we propose a trainable feature selection algorithm based on the regularized
frame for face recognition. By enforcing a sparsity penalty term on the minimum
squared error (MSE) criterion, we cast the feature selection problem into a
combinatorial sparse approximation problem, which can be solved by greedy
methods or convex relaxation methods. Moreover, based on the same frame, we
propose a sparse Ho-Kashyap (HK) procedure to obtain simultaneously the optimal
sparse solution and the corresponding margin vector of the MSE criterion. The
proposed methods are used for selecting the most informative Gabor features of
face images for recognition and the experimental results on benchmark face
databases demonstrate the effectiveness of the proposed methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2749</identifier>
 <datestamp>2011-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2749</id><created>2011-02-14</created><updated>2011-05-06</updated><authors><author><keyname>Liang</keyname><forenames>Yixiong</forenames></author><author><keyname>Liu</keyname><forenames>Lingbo</forenames></author><author><keyname>Xu</keyname><forenames>Ying</forenames></author><author><keyname>Xiang</keyname><forenames>Yao</forenames></author><author><keyname>Zou</keyname><forenames>Beiji</forenames></author></authors><title>Multi-task GLOH feature selection for human age estimation</title><categories>cs.CV cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a novel age estimation method based on GLOH feature
descriptor and multi-task learning (MTL). The GLOH feature descriptor, one of
the state-of-the-art feature descriptor, is used to capture the age-related
local and spatial information of face image. As the exacted GLOH features are
often redundant, MTL is designed to select the most informative feature bins
for age estimation problem, while the corresponding weights are determined by
ridge regression. This approach largely reduces the dimensions of feature,
which can not only improve performance but also decrease the computational
burden. Experiments on the public available FG-NET database show that the
proposed method can achieve comparable performance over previous approaches
while using much fewer features.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2761</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2761</id><created>2011-02-14</created><updated>2011-04-27</updated><authors><author><keyname>Schenk</keyname><forenames>Andreas</forenames></author><author><keyname>Fischer</keyname><forenames>Robert F. H.</forenames></author></authors><title>Capacity of BICM Using (Bi-)Orthogonal Signal Constellations in
  Impulse-Radio Ultra-Wideband Systems</title><categories>cs.IT math.IT</categories><comments>Draft-version of a manuscript submitted to ICUWB'11</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bit-interleaved coded modulation (BICM) using (bi-)orthogonal signals is
especially well suited for the application in impulse-radio ultra-wideband
transmission systems, which typically operate in the power-limited regime and
require a very low-complexity transmitter and receiver design. In this paper we
analyze the capacity of BICM using (bi-)orthogonal signals with coherent and
noncoherent detection and put particular focus on the power-limited or wideband
regime. We give analytical expressions for the ratio energy per bit vs. noise
power spectral density in the limit of infinite bandwidth and the respective
wideband slope, and thus, are able to quantify the loss incurred by the
restriction to BICM in contrast to coded modulation. The gained theoretical
insights allow to derive design rules for impulse-radio ultra-wideband
transmission systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2768</identifier>
 <datestamp>2011-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2768</id><created>2011-02-14</created><authors><author><keyname>Chandrasekaran</keyname><forenames>Suresh</forenames></author><author><keyname>Mohammed</keyname><forenames>Saif K.</forenames></author><author><keyname>Chockalingam</keyname><forenames>A.</forenames></author></authors><title>Achievable Rate Region of Quantized Broadcast and MAC Channels</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the achievable rate region of Gaussian multiuser
channels with the messages transmitted being from finite input alphabets and
the outputs being {\em quantized at the receiver}. In particular, we focus on
the achievable rate region of $i)$ Gaussian broadcast channel (GBC) and $ii)$
Gaussian multiple access channel (GMAC). First, we study the achievable rate
region of two-user GBC when the messages to be transmitted to both the users
take values from finite signal sets and the received signal is quantized at
both the users. We refer to this channel as {\em quantized broadcast channel
(QBC)}. We observe that the capacity region defined for a GBC does not carry
over as such to QBC. We show that the optimal decoding scheme for GBC (i.e.,
high SNR user doing successive decoding and low SNR user decoding its message
alone) is not optimal for QBC. We then propose an achievable rate region for
QBC based on two different schemes. We present achievable rate region results
for the case of uniform quantization at the receivers. Next, we investigate the
achievable rate region of two-user GMAC with finite input alphabet and
quantized receiver output. We refer to this channel as {\em quantized multiple
access channel (QMAC)}. We derive expressions for the achievable rate region of
a two-user QMAC. We show that, with finite input alphabet, the achievable rate
region with the commonly used uniform receiver quantizer has a significant loss
compared to the achievable rate region without receiver quantization. We
propose a {\em non-uniform quantizer} which has a significantly larger rate
region compared to what is achieved with a uniform quantizer in QMAC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2782</identifier>
 <datestamp>2011-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2782</id><created>2011-02-14</created><authors><author><keyname>Lohrey</keyname><forenames>Markus</forenames></author><author><keyname>Mathissen</keyname><forenames>Christian</forenames></author></authors><title>Isomorphism of regular trees and words</title><categories>cs.FL cs.CC</categories><msc-class>68Q45, 68Q17</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The computational complexity of the isomorphism problem for regular trees,
regular linear orders, and regular words is analyzed. A tree is regular if it
is isomorphic to the prefix order on a regular language. In case regular
languages are represented by NFAs (DFAs), the isomorphism problem for regular
trees turns out to be EXPTIME-complete (resp. P-complete). In case the input
automata are acyclic NFAs (acyclic DFAs), the corresponding trees are
(succinctly represented) finite trees, and the isomorphism problem turns out to
be PSPACE-complete (resp. P-complete). A linear order is regular if it is
isomorphic to the lexicographic order on a regular language. A polynomial time
algorithm for the isomorphism problem for regular linear orders (and even
regular words, which generalize the latter) given by DFAs is presented. This
solves an open problem by Esik and Bloom.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2785</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2785</id><created>2011-02-14</created><updated>2012-06-29</updated><authors><author><keyname>Korman</keyname><forenames>Matias</forenames></author></authors><title>Minimizing interference in ad-hoc networks with bounded communication
  radius</title><categories>cs.CG cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a topology control problem in which we are given a set of $n$
sensors in the plane and we would like to assign a communication radius to each
of them. The radii assignment must generate a strongly connected network and
have low receiver-based interference (i.e., we minimize the largest in-degree
of the network). We give an algorithm that generates a network with $O(\log
\Delta)$ interference, where $\Delta$ is the interference of a uniform-radius
ad-hoc network. We then adapt the construction to the case in which no sensor
can have a communication radius larger than $R_{\min}$, the minimum value
needed to obtain connectivity. We also show that $\log \Delta$ interference is
needed for some instances, making our algorithms asymptotically optimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2787</identifier>
 <datestamp>2011-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2787</id><created>2011-02-14</created><authors><author><keyname>Chaaban</keyname><forenames>Anas</forenames></author><author><keyname>Sezgin</keyname><forenames>Aydin</forenames></author><author><keyname>Avestimehr</keyname><forenames>Salman</forenames></author></authors><title>On the Sum Capacity of the Y-Channel</title><categories>cs.IT math.IT</categories><comments>12 pages, 8 figures, submitted to ISIT 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A network where three users communicate with each other via a relay is
considered. Users do not receive other users' signals via a direct link, and
thus the relay is essential for their communication. Each user is assumed to
have an individual message to be delivered to each other user. Thus, each user
wants to send two messages and to decode two messages. In general, the transmit
signals of different nodes can be dependent since they can depend on previously
received symbols. We call this case the general case. The sum-capacity is
studied, and upper bounds and lower bounds are given. If all nodes have the
same power, the sum-capacity is characterized to within a gap of 5/2 bits or a
factor of 3 for all values of channel coefficients. This gap is also shown to
approach 3/2 bits as the transmit power increases. Moreover, for the symmetric
case with equal channel coefficients, the gap is shown to be less than 1 bit.
The restricted case is also considered where the transmit signal does not
depend on previously received symbols. In this case, the sum-capacity is
characterized to within a gap of 2 bits or a factor of 3 for all values of
channel coefficients, and approaches 1 bit as the transmit power increases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2789</identifier>
 <datestamp>2011-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2789</id><created>2011-02-14</created><authors><author><keyname>Beecken</keyname><forenames>Malte</forenames></author><author><keyname>Mittmann</keyname><forenames>Johannes</forenames></author><author><keyname>Saxena</keyname><forenames>Nitin</forenames></author></authors><title>Algebraic Independence and Blackbox Identity Testing</title><categories>cs.CC math.AC</categories><comments>32 pages, preliminary version</comments><msc-class>13P25</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Algebraic independence is an advanced notion in commutative algebra that
generalizes independence of linear polynomials to higher degree. Polynomials
{f_1, ..., f_m} \subset \F[x_1, ..., x_n] are called algebraically independent
if there is no non-zero polynomial F such that F(f_1, ..., f_m) = 0. The
transcendence degree, trdeg{f_1, ..., f_m}, is the maximal number r of
algebraically independent polynomials in the set. In this paper we design
blackbox and efficient linear maps \phi that reduce the number of variables
from n to r but maintain trdeg{\phi(f_i)}_i = r, assuming f_i's sparse and
small r. We apply these fundamental maps to solve several cases of blackbox
identity testing:
  (1) Given a polynomial-degree circuit C and sparse polynomials f_1, ..., f_m
with trdeg r, we can test blackbox D := C(f_1, ..., f_m) for zeroness in
poly(size(D))^r time.
  (2) Define a spsp_\delta(k,s,n) circuit C to be of the form \sum_{i=1}^k
\prod_{j=1}^s f_{i,j}, where f_{i,j} are sparse n-variate polynomials of degree
at most \delta. For k = 2 we give a poly(sn\delta)^{\delta^2} time blackbox
identity test.
  (3) For a general depth-4 circuit we define a notion of rank. Assuming there
is a rank bound R for minimal simple spsp_\delta(k,s,n) identities, we give a
poly(snR\delta)^{Rk\delta^2} time blackbox identity test for spsp_\delta(k,s,n)
circuits. This partially generalizes the state of the art of depth-3 to depth-4
circuits.
  The notion of trdeg works best with large or zero characteristic, but we also
give versions of our results for arbitrary fields.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2791</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2791</id><created>2011-02-14</created><updated>2011-08-02</updated><authors><author><keyname>Aghasi</keyname><forenames>Hamidreza</forenames></author><author><keyname>Amindavar</keyname><forenames>Hamidreza</forenames></author><author><keyname>Aghasi</keyname><forenames>Alireza</forenames></author></authors><title>A Hybrid Global Minimization Scheme for Accurate Source Localization in
  Sensor Networks</title><categories>cs.NI</categories><doi>10.1186/1687-6180-2011-81</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the localization problem of multiple wideband sources in a
multi-path environment by coherently taking into account the attenuation
characteristics and the time delays in the reception of the signal. Our
proposed method leaves the space for unavailability of an accurate signal
attenuation model in the environment by considering the model as an unknown
function with reasonable prior assumptions about its functional space. Such
approach is capable of enhancing the localization performance compared to only
utilizing the signal attenuation information or the time delays. In this paper,
the localization problem is modeled as a cost function in terms of the source
locations, attenuation model parameters and the multi-path parameters. To
globally perform the minimization, we propose a hybrid algorithm combining the
differential evolution algorithm with the Levenberg-Marquardt algorithm.
Besides the proposed combination of optimization schemes, supporting the
technical details such as closed forms of cost function sensitivity matrices
are provided. Finally, the validity of the proposed method is examined in
several localization scenarios, taking into account the noise in the
environment, the multi-path phenomenon and considering the sensors not being
synchronized.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2794</identifier>
 <datestamp>2011-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2794</id><created>2011-02-14</created><authors><author><keyname>Wang</keyname><forenames>Xinhua</forenames></author></authors><title>Universal approximation using differentiators and application to
  feedback control</title><categories>cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the problems of approximating uncertainties and
feedback control for a class of nonlinear systems without full-known states,
and two approximation methods are proposed: universal approximation using
integral-chain differentiator or extended observer. Comparing to the
approximations by fuzzy system and radial-based-function (RBF) neural networks,
the presented two methods can not only approximate universally the
uncertainties, but also estimate the unknown states. Moreover, the
integral-chain differentiator can restrain noises thoroughly. The theoretical
results are confirmed by computer simulations for feedback control.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2797</identifier>
 <datestamp>2011-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2797</id><created>2011-02-14</created><authors><author><keyname>Dau</keyname><forenames>Son Hoang</forenames></author><author><keyname>Skachek</keyname><forenames>Vitaly</forenames></author><author><keyname>Chee</keyname><forenames>Yeow Meng</forenames></author></authors><title>On the Security of Index Coding with Side Information</title><categories>cs.IT math.IT</categories><comments>14 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Security aspects of the Index Coding with Side Information (ICSI) problem are
investigated. Building on the results of Bar-Yossef et al. (2006), the
properties of linear index codes are further explored. The notion of weak
security, considered by Bhattad and Narayanan (2005) in the context of network
coding, is generalized to block security. It is shown that the linear index
code based on a matrix $L$, whose column space code $C(L)$ has length $n$,
minimum distance $d$ and dual distance $d^\perp$, is $(d-1-t)$-block secure
(and hence also weakly secure) if the adversary knows in advance $t \leq d-2$
messages, and is completely insecure if the adversary knows in advance more
than $n - d$ messages. Strong security is examined under the conditions that
the adversary: (i) possesses $t$ messages in advance; (ii) eavesdrops at most
$\mu$ transmissions; (iii) corrupts at most $\delta$ transmissions. We prove
that for sufficiently large $q$, an optimal linear index code which is strongly
secure against such an adversary has length $\kappa_q+\mu+2\delta$. Here
$\kappa_q$ is a generalization of the min-rank over $F_q$ of the side
information graph for the ICSI problem in its original formulation in the work
of Bar- Yossef et al.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2799</identifier>
 <datestamp>2011-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2799</id><created>2011-02-14</created><updated>2011-02-14</updated><authors><author><keyname>Shieh</keyname><forenames>Min-Zheng</forenames></author><author><keyname>Tsai</keyname><forenames>Shi-Chun</forenames></author></authors><title>Computing the Ball Size of Frequency Permutations under Chebyshev
  Distance</title><categories>cs.IT cs.DM math.IT</categories><comments>Submitted to ISIT 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $S_n^\lambda$ be the set of all permutations over the multiset
$\{\overbrace{1,...,1}^{\lambda},...,\overbrace{m,...,m}^\lambda\}$ where
$n=m\lambda$. A frequency permutation array (FPA) of minimum distance $d$ is a
subset of $S_n^\lambda$ in which every two elements have distance at least $d$.
FPAs have many applications related to error correcting codes. In coding
theory, the Gilbert-Varshamov bound and the sphere-packing bound are derived
from the size of balls of certain radii. We propose two efficient algorithms
that compute the ball size of frequency permutations under Chebyshev distance.
Both methods extend previous known results. The first one runs in $O({2d\lambda
\choose d\lambda}^{2.376}\log n)$ time and $O({2d\lambda \choose
d\lambda}^{2})$ space. The second one runs in $O({2d\lambda \choose
d\lambda}{d\lambda+\lambda\choose \lambda}\frac{n}{\lambda})$ time and
$O({2d\lambda \choose d\lambda})$ space. For small constants $\lambda$ and $d$,
both are efficient in time and use constant storage space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2806</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2806</id><created>2011-02-14</created><updated>2011-03-13</updated><authors><author><keyname>Pritychenko</keyname><forenames>B.</forenames></author><author><keyname>Betak</keyname><forenames>E.</forenames></author><author><keyname>Kellett</keyname><forenames>M. A.</forenames></author><author><keyname>Singh</keyname><forenames>B.</forenames></author><author><keyname>Totans</keyname><forenames>J.</forenames></author></authors><title>The Nuclear Science References (NSR) Database and Web Retrieval System</title><categories>physics.data-an cs.DL</categories><comments>16 pages, 5 figures</comments><report-no>Brookhaven National Laboratory Report BNL-94690-2011-JA</report-no><journal-ref>Nucl. Instr. Meth. A 640, 213 (2011)</journal-ref><doi>10.1016/j.nima.2011.03.018</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Nuclear Science References (NSR) database together with its associated
Web interface, is the world's only comprehensive source of easily accessible
low- and intermediate-energy nuclear physics bibliographic information for more
than 200,000 articles since the beginning of nuclear science. The
weekly-updated NSR database provides essential support for nuclear data
evaluation, compilation and research activities. The principles of the database
and Web application development and maintenance are described. Examples of
nuclear structure, reaction and decay applications are specifically included.
The complete NSR database is freely available at the websites of the National
Nuclear Data Center http://www.nndc.bnl.gov/nsr and the International Atomic
Energy Agency http://www-nds.iaea.org/nsr.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2808</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2808</id><created>2011-02-14</created><updated>2012-09-02</updated><authors><author><keyname>Seah</keyname><forenames>Chun-Wei</forenames></author><author><keyname>Tsang</keyname><forenames>Ivor W.</forenames></author><author><keyname>Ong</keyname><forenames>Yew-Soon</forenames></author></authors><title>Transductive Ordinal Regression</title><categories>cs.LG</categories><journal-ref>IEEE Transactions on Neural Networks and Learning Systems,
  23(7):1074 - 1086, 2012</journal-ref><doi>10.1109/TNNLS.2012.2198240</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ordinal regression is commonly formulated as a multi-class problem with
ordinal constraints. The challenge of designing accurate classifiers for
ordinal regression generally increases with the number of classes involved, due
to the large number of labeled patterns that are needed. The availability of
ordinal class labels, however, is often costly to calibrate or difficult to
obtain. Unlabeled patterns, on the other hand, often exist in much greater
abundance and are freely available. To take benefits from the abundance of
unlabeled patterns, we present a novel transductive learning paradigm for
ordinal regression in this paper, namely Transductive Ordinal Regression (TOR).
The key challenge of the present study lies in the precise estimation of both
the ordinal class label of the unlabeled data and the decision functions of the
ordinal classes, simultaneously. The core elements of the proposed TOR include
an objective function that caters to several commonly used loss functions
casted in transductive settings, for general ordinal regression. A label
swapping scheme that facilitates a strictly monotonic decrease in the objective
function value is also introduced. Extensive numerical studies on commonly used
benchmark datasets including the real world sentiment prediction problem are
then presented to showcase the characteristics and efficacies of the proposed
transductive ordinal regression. Further, comparisons to recent
state-of-the-art ordinal regression methods demonstrate the introduced
transductive learning paradigm for ordinal regression led to the robust and
improved performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2816</identifier>
 <datestamp>2013-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2816</id><created>2011-02-14</created><updated>2011-07-14</updated><authors><author><keyname>Kent</keyname><forenames>Adrian</forenames><affiliation>Centre for Quantum Information and Foundations, DAMTP, University of Cambridge and Perimeter Institute for Theoretical Physics</affiliation></author></authors><title>Location-Oblivious Data Transfer with Flying Entangled Qudits</title><categories>quant-ph cs.CR cs.IT math.IT</categories><comments>References updated. Published version</comments><journal-ref>Phys. Rev. A 84, 012328 (2011)</journal-ref><doi>10.1103/PhysRevA.84.012328</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a simple and practical quantum protocol involving two mistrustful
agencies in Minkowski space, which allows Alice to transfer data to Bob at a
spacetime location that neither can predict in advance. The location depends on
both Alice's and Bob's actions. The protocol guarantees unconditionally to
Alice that Bob learns the data at a randomly determined location; it guarantees
to Bob that Alice will not learn the transfer location even after the protocol
is complete.
  The task implemented, transferring data at a space-time location that remains
hidden from the transferrer, has no precise analogue in non-relativistic
quantum cryptography. It illustrates further the scope for novel cryptographic
applications of relativistic quantum theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2819</identifier>
 <datestamp>2011-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2819</id><created>2011-02-14</created><authors><author><keyname>Andreychenko</keyname><forenames>Aleksandr</forenames></author><author><keyname>Mikeev</keyname><forenames>Linar</forenames></author><author><keyname>Spieler</keyname><forenames>David</forenames></author><author><keyname>Wolf</keyname><forenames>Verena</forenames></author></authors><title>Parameter Identification for Markov Models of Biochemical Reactions</title><categories>q-bio.QM cs.CE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a numerical technique for parameter inference in Markov models of
biological processes. Based on time-series data of a process we estimate the
kinetic rate constants by maximizing the likelihood of the data. The
computation of the likelihood relies on a dynamic abstraction of the discrete
state space of the Markov model which successfully mitigates the problem of
state space largeness. We compare two variants of our method to
state-of-the-art, recently published methods and demonstrate their usefulness
and efficiency on several case studies from systems biology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2825</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2825</id><created>2011-02-14</created><updated>2011-12-28</updated><authors><author><keyname>Baghaie</keyname><forenames>Marjan</forenames></author><author><keyname>Krishnamachari</keyname><forenames>Bhaskar</forenames></author><author><keyname>Molisch</keyname><forenames>Andreas F.</forenames></author></authors><title>Algorithmic Aspects of Energy-Delay Tradeoff in Multihop Cooperative
  Wireless Networks</title><categories>math.OC cs.DS cs.IT math.IT</categories><comments>12 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of energy-efficient transmission in delay constrained
cooperative multihop wireless networks. The combinatorial nature of cooperative
multihop schemes makes it difficult to design efficient polynomial-time
algorithms for deciding which nodes should take part in cooperation, and when
and with what power they should transmit. In this work, we tackle this problem
in memoryless networks with or without delay constraints, i.e., quality of
service guarantee. We analyze a wide class of setups, including unicast,
multicast, and broadcast, and two main cooperative approaches, namely: energy
accumulation (EA) and mutual information accumulation (MIA). We provide a
generalized algorithmic formulation of the problem that encompasses all those
cases. We investigate the similarities and differences of EA and MIA in our
generalized formulation. We prove that the broadcast and multicast problems
are, in general, not only NP hard but also o(log(n)) inapproximable. We break
these problems into three parts: ordering, scheduling and power control, and
propose a novel algorithm that, given an ordering, can optimally solve the
joint power allocation and scheduling problems simultaneously in polynomial
time. We further show empirically that this algorithm used in conjunction with
an ordering derived heuristically using the Dijkstra's shortest path algorithm
yields near-optimal performance in typical settings. For the unicast case, we
prove that although the problem remains NP hard with MIA, it can be solved
optimally and in polynomial time when EA is used. We further use our algorithm
to study numerically the trade-off between delay and power-efficiency in
cooperative broadcast and compare the performance of EA vs MIA as well as the
performance of our cooperative algorithm with a smart noncooperative algorithm
in a broadcast setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2828</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2828</id><created>2011-02-14</created><updated>2011-05-14</updated><authors><author><keyname>Bezhanishvili</keyname><forenames>Nick</forenames><affiliation>Imperial College London</affiliation></author><author><keyname>Gehrke</keyname><forenames>Mai</forenames><affiliation>Radboud Universiteit, Nijmegen</affiliation></author></authors><title>Finitely generated free Heyting algebras via Birkhoff duality and
  coalgebra</title><categories>cs.LO math.LO</categories><proxy>LMCS</proxy><acm-class>F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 7, Issue 2 (May 17,
  2011) lmcs:702</journal-ref><doi>10.2168/LMCS-7(2:9)2011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Algebras axiomatized entirely by rank 1 axioms are algebras for a functor and
thus the free algebras can be obtained by a direct limit process. Dually, the
final coalgebras can be obtained by an inverse limit process. In order to
explore the limits of this method we look at Heyting algebras which have mixed
rank 0-1 axiomatizations. We will see that Heyting algebras are special in that
they are almost rank 1 axiomatized and can be handled by a slight variant of
the rank 1 coalgebraic methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2831</identifier>
 <datestamp>2011-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2831</id><created>2011-02-14</created><updated>2011-02-14</updated><authors><author><keyname>Krishna</keyname><forenames>Madhav</forenames></author><author><keyname>Hassan</keyname><forenames>Ahmed</forenames></author><author><keyname>Liu</keyname><forenames>Yang</forenames></author><author><keyname>Radev</keyname><forenames>Dragomir</forenames></author></authors><title>The effect of linguistic constraints on the large scale organization of
  language</title><categories>cs.CL cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the effect of linguistic constraints on the large scale
organization of language. It describes the properties of linguistic networks
built using texts of written language with the words randomized. These
properties are compared to those obtained for a network built over the text in
natural order. It is observed that the &quot;random&quot; networks too exhibit
small-world and scale-free characteristics. They also show a high degree of
clustering. This is indeed a surprising result - one that has not been
addressed adequately in the literature. We hypothesize that many of the network
statistics reported here studied are in fact functions of the distribution of
the underlying data from which the network is built and may not be indicative
of the nature of the concerned network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2836</identifier>
 <datestamp>2013-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2836</id><created>2011-02-14</created><updated>2013-02-05</updated><authors><author><keyname>Dar</keyname><forenames>Ronen</forenames></author><author><keyname>feder</keyname><forenames>Meir</forenames></author></authors><title>Finite-Memory Prediction as Well as the Empirical Mean</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of universally predicting an individual continuous sequence using
a deterministic finite-state machine (FSM) is considered. The empirical mean is
used as a reference as it is the constant that fits a given sequence within a
minimal square error. With this reference, a reasonable prediction performance
is the regret, namely the excess square-error over the reference loss, the
empirical variance. The paper analyzes the tradeoff between the number of
states of the universal FSM and the attainable regret. It first studies the
case of a small number of states. A class of machines, denoted Degenerated
Tracking Memory (DTM), is defined and the optimal machine in this class is
shown to be the optimal among all machines for small enough number of states.
Unfortunately, DTM machines become suboptimal as the number of available states
increases. Next, the Exponential Decaying Memory (EDM) machine, previously used
for predicting binary sequences, is considered. While this machine has poorer
performance for small number of states, it achieves a vanishing regret for
large number of states. Following that, an asymptotic lower bound of
O(k^{-2/3}) on the achievable regret of any k-state machine is derived. This
bound is attained asymptotically by the EDM machine. Furthermore, a new
machine, denoted the Enhanced Exponential Decaying Memory machine, is shown to
outperform the EDM machine for any number of states.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2837</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2837</id><created>2011-02-14</created><updated>2011-05-12</updated><authors><author><keyname>Pluchino</keyname><forenames>Alessandro</forenames></author><author><keyname>Rapisarda</keyname><forenames>Andrea</forenames></author><author><keyname>Garofalo</keyname><forenames>Cesare</forenames></author></authors><title>Efficient Promotion Strategies in Hierarchical Organizations</title><categories>physics.soc-ph cs.SI</categories><comments>27 pages, 12 figures, 2 tables; Improved version with new Fig.4,5,6;
  Accepted for publication on Physica A</comments><journal-ref>Physica A 390 (2011) 3496-3511</journal-ref><doi>10.1016/j.physa.2011.05.021</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Peter principle has been recently investigated by means of an agent-based
simulation and its validity has been numerically corroborated. It has been
confirmed that, within certain conditions, it can really influence in a
negative way the efficiency of a pyramidal organization adopting meritocratic
promotions. It was also found that, in order to bypass these effects,
alternative promotion strategies should be adopted, as for example a random
selection choice. In this paper, within the same line of research, we study
promotion strategies in a more realistic hierarchical and modular organization
and we show the robustness of our previous results, extending their validity to
a more general context. We discuss also why the adoption of these strategies
could be useful for real organizations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2840</identifier>
 <datestamp>2011-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2840</id><created>2011-02-14</created><updated>2011-02-18</updated><authors><author><keyname>Zhang</keyname><forenames>Peng</forenames></author><author><keyname>Qiu</keyname><forenames>Robert</forenames></author></authors><title>Spectrum Sensing Based on Blindly Learned Signal Feature</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spectrum sensing is the major challenge in the cognitive radio (CR). We
propose to learn local feature and use it as the prior knowledge to improve the
detection performance. We define the local feature as the leading eigenvector
derived from the received signal samples. A feature learning algorithm (FLA) is
proposed to learn the feature blindly. Then, with local feature as the prior
knowledge, we propose the feature template matching algorithm (FTM) for
spectrum sensing. We use the discrete Karhunen--Lo{\`e}ve transform (DKLT) to
show that such a feature is robust against noise and has maximum effective
signal-to-noise ratio (SNR). Captured real-world data shows that the learned
feature is very stable over time. It is almost unchanged in 25 seconds. Then,
we test the detection performance of the FTM in very low SNR. Simulation
results show that the FTM is about 2 dB better than the blind algorithms, and
the FTM does not have the noise uncertainty problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2853</identifier>
 <datestamp>2011-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2853</id><created>2011-02-14</created><updated>2011-03-12</updated><authors><author><keyname>Pegden</keyname><forenames>Wesley</forenames></author></authors><title>An extension of the Moser-Tardos algorithmic local lemma</title><categories>math.CO cs.DS</categories><comments>8 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A recent theorem of Bissacot, et al. proved using results about the cluster
expansion in statistical mechanics extends the Lov\'asz Local Lemma by
weakening the conditions under which its conclusions holds. In this note, we
prove an algorithmic analog of this result, extending Moser and Tardos's recent
algorithmic Local Lemma, and providing an alternative proof of the theorem of
Bissacot, et al. applicable in the Moser-Tardos algorithmic framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2856</identifier>
 <datestamp>2011-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2856</id><created>2011-02-14</created><authors><author><keyname>Kudekar</keyname><forenames>Shrinivas</forenames></author><author><keyname>Kasai</keyname><forenames>Kenta</forenames></author></authors><title>Spatially Coupled Codes over the Multiple Access Channel</title><categories>cs.IT math.IT</categories><report-no>ISIT 2011</report-no><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  We consider spatially coupled code ensembles over a multiple access channel.
Convolutional LDPC ensembles are one instance of spatially coupled codes. It
was shown recently that, for transmission over the binary erasure channel, this
coupling of individual code ensembles has the effect of increasing the belief
propagation threshold of the coupled ensembles to the maximum a-posteriori
threshold of the underlying ensemble. In this sense, spatially coupled codes
were shown to be capacity achieving. It was observed, empirically, that these
codes are universal in the sense that they achieve performance close to the
Shannon threshold for any general binary-input memoryless symmetric channels.
  In this work we provide further evidence of the threshold saturation
phenomena when transmitting over a class of multiple access channel. We show,
by density evolution analysis and EXIT curves, that the belief propagation
threshold of the coupled ensembles is very close to the ultimate Shannon limit.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2868</identifier>
 <datestamp>2011-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2868</id><created>2011-02-14</created><authors><author><keyname>Baccelli</keyname><forenames>Francois</forenames></author><author><keyname>Gamal</keyname><forenames>Abbas El</forenames></author><author><keyname>Tse</keyname><forenames>David</forenames></author></authors><title>Interference Networks with Point-to-Point Codes</title><categories>cs.IT math.IT math.PR</categories><msc-class>94A15, 60D05</msc-class><acm-class>E.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper establishes the capacity region of the Gaussian interference
channel with many transmitter-receiver pairs constrained to use point-to-point
codes. The capacity region is shown to be strictly larger in general than the
achievable rate regions when treating interference as noise, using successive
interference cancellation decoding, and using joint decoding. The gains in
coverage and achievable rate using the optimal decoder are analyzed in terms of
ensemble averages using stochastic geometry. In a spatial network where the
nodes are distributed according to a Poisson point process and the channel path
loss exponent is $\beta &gt; 2$, it is shown that the density of users that can be
supported by treating interference as noise can scale no faster than
$B^{2/\beta}$ as the bandwidth $B$ grows, while the density of users can scale
linearly with $B$ under optimal decoding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2878</identifier>
 <datestamp>2011-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2878</id><created>2011-02-14</created><authors><author><keyname>Lee</keyname><forenames>Dongryeol</forenames></author><author><keyname>Gray</keyname><forenames>Alexander G.</forenames></author><author><keyname>Moore</keyname><forenames>Andrew W.</forenames></author></authors><title>Dual-Tree Fast Gauss Transforms</title><categories>stat.CO cs.DS stat.ML</categories><comments>Extended version of a conference paper. Submitted to a journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Kernel density estimation (KDE) is a popular statistical technique for
estimating the underlying density distribution with minimal assumptions.
Although they can be shown to achieve asymptotic estimation optimality for any
input distribution, cross-validating for an optimal parameter requires
significant computation dominated by kernel summations. In this paper we
present an improvement to the dual-tree algorithm, the first practical kernel
summation algorithm for general dimension. Our extension is based on the
series-expansion for the Gaussian kernel used by fast Gauss transform. First,
we derive two additional analytical machinery for extending the original
algorithm to utilize a hierarchical data structure, demonstrating the first
truly hierarchical fast Gauss transform. Second, we show how to integrate the
series-expansion approximation within the dual-tree approach to compute kernel
summations with a user-controllable relative error bound. We evaluate our
algorithm on real-world datasets in the context of optimal bandwidth selection
in kernel density estimation. Our results demonstrate that our new algorithm is
the only one that guarantees a hard relative error bound and offers fast
performance across a wide range of bandwidths evaluated in cross validation
procedures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2880</identifier>
 <datestamp>2011-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2880</id><created>2011-02-14</created><updated>2011-04-28</updated><authors><author><keyname>Jonsson</keyname><forenames>Peter</forenames></author><author><keyname>Kuivinen</keyname><forenames>Fredrik</forenames></author><author><keyname>Thapper</keyname><forenames>Johan</forenames></author></authors><title>Min CSP on Four Elements: Moving Beyond Submodularity</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We report new results on the complexity of the valued constraint satisfaction
problem (VCSP). Under the unique games conjecture, the approximability of
finite-valued VCSP is fairly well-understood. However, there is yet no
characterisation of VCSPs that can be solved exactly in polynomial time. This
is unsatisfactory, since such results are interesting from a combinatorial
optimisation perspective; there are deep connections with, for instance,
submodular and bisubmodular minimisation. We consider the Min and Max CSP
problems (i.e. where the cost functions only attain values in {0,1}) over
four-element domains and identify all tractable fragments. Similar
classifications were previously known for two- and three-element domains. In
the process, we introduce a new class of tractable VCSPs based on a
generalisation of submodularity. We also extend and modify a graph-based
technique by Kolmogorov and Zivny (originally introduced by Takhanov) for
efficiently obtaining hardness results in our setting. This allow us to prove
the result without relying on computer-assisted case analyses (which otherwise
are fairly common when studying the complexity and approximability of VCSPs.)
The hardness results are further simplified by the introduction of powerful
reduction techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2881</identifier>
 <datestamp>2011-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2881</id><created>2011-02-14</created><authors><author><keyname>Zhang</keyname><forenames>Peng</forenames></author><author><keyname>Qiu</keyname><forenames>Robert</forenames></author></authors><title>Modified Orthogonal Matching Pursuit Algorithm for Cognitive Radio
  Wideband Spectrum Sensing</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sampling rate is the bottleneck for spectrum sensing over multi-GHz
bandwidth. Recent progress in compressed sensing (CS) initialized several
sub-Nyquist rate approaches to overcome the problem. However, efforts to design
CS reconstruction algorithms for wideband spectrum sensing are very limited. It
is possible to further reduce the sampling rate requirement and improve
reconstruction performance via algorithms considering prior knowledge of
cognitive radio spectrum usages. In this paper, we group the usages of
cognitive radio spectrum into three categories and propose a modified
orthogonal matching pursuit (OMP) algorithm for wideband spectrum sensing.
Simulation results show that this modified OMP algorithm outperforms two
modified basis pursuit de-noising (BPDN) algorithms in terms of reconstruction
performance and computation time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2890</identifier>
 <datestamp>2015-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2890</id><created>2011-02-14</created><updated>2015-03-24</updated><authors><author><keyname>Vlasov</keyname><forenames>Alexander Yu.</forenames></author></authors><title>Some Notes on Quantum Information Theory and Emerging Computing
  Technologies</title><categories>cs.IT math.IT quant-ph</categories><comments>v2: LaTeX 9 pages, 3 figures, spelling and grammar corrected, class
  changed, v3: 12 pages, 4 figures, references and appendix added</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is considered an interdependence of the theory of quantum computing and
some perspective information technologies. A couple of illustrative and useful
examples are discussed. The reversible computing from very beginning had the
serious impact on the design of quantum computers and it is revisited first.
Some applications of ternary circuits are also quite instructive and it may be
useful in the quantum information theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2891</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2891</id><created>2011-02-14</created><authors><author><keyname>Kurtz</keyname><forenames>Michael J.</forenames></author><author><keyname>Bollen</keyname><forenames>Johan</forenames></author></authors><title>Usage Bibliometrics</title><categories>cs.DL astro-ph.IM cs.IR physics.soc-ph</categories><comments>Publisher's PDF (by permission). Publisher web site:
  books.infotoday.com/asist/arist44.shtml</comments><journal-ref>Annual Review of Information Science and Technology, vol 44, p.
  3-64 (2010)</journal-ref><doi>10.1002/aris.2010.1440440108</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Scholarly usage data provides unique opportunities to address the known
shortcomings of citation analysis. However, the collection, processing and
analysis of usage data remains an area of active research. This article
provides a review of the state-of-the-art in usage-based informetric, i.e. the
use of usage data to study the scholarly process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2904</identifier>
 <datestamp>2011-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2904</id><created>2011-02-14</created><authors><author><keyname>de Kerret</keyname><forenames>P.</forenames></author><author><keyname>Gesbert</keyname><forenames>D.</forenames></author></authors><title>The Asymptotic Limits of Interference in Multicell Networks with Channel
  Aware Scheduling</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interference is emerging as a fundamental bottleneck in many important
wireless communication scenarios, including dense cellular networks and
cognitive networks with spectrum sharing by multiple service providers.
Although multipleantenna (MIMO) signal processing is known to offer useful
degrees of freedom to cancel interference, extreme-value theoretic analysis
recently showed that, even in the absence of MIMO processing, the scaling law
of the capacity in the number of users for a multi-cell network with and
without inter-cell interference was asymptotically identical provided a simple
signal to noise and interference ratio (SINR) maximizing scheduler is
exploited. This suggests that scheduling can help reduce inter-cell
interference substantially, thus possibly limiting the need for
multiple-antenna processing. However, the convergence limits of interference
after scheduling in a multi-cell setting are not yet identified. In this paper1
we analyze such limits theoretically. We consider channel statistics under
Rayleigh fading with equal path loss for all users or with unequal path loss.
We uncover two surprisingly different behaviors for such systems. For the equal
path loss case, we show that scheduling alone can cause the residual
interference to converge to zero for large number of users. With unequal path
loss however, the interference are shown to converge in average to a nonzero
constant. Simulations back our findings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2906</identifier>
 <datestamp>2011-10-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2906</id><created>2011-02-14</created><updated>2011-10-15</updated><authors><author><keyname>Nanongkai</keyname><forenames>Danupon</forenames></author><author><keyname>Sarma</keyname><forenames>Atish Das</forenames></author><author><keyname>Pandurangan</keyname><forenames>Gopal</forenames></author></authors><title>A Tight Lower Bound on Distributed Random Walk Computation</title><categories>cs.DC cs.DS</categories><comments>PODC 2011</comments><acm-class>F.2.2; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of performing a random walk in a distributed network.
Given bandwidth constraints, the goal of the problem is to minimize the number
of rounds required to obtain a random walk sample. Das Sarma et al. [PODC'10]
show that a random walk of length $\ell$ on a network of diameter $D$ can be
performed in $\tilde O(\sqrt{\ell D}+D)$ time. A major question left open is
whether there exists a faster algorithm, especially whether the multiplication
of $\sqrt{\ell}$ and $\sqrt{D}$ is necessary.
  In this paper, we show a tight unconditional lower bound on the time
complexity of distributed random walk computation. Specifically, we show that
for any $n$, $D$, and $D\leq \ell \leq (n/(D^3\log n))^{1/4}$, performing a
random walk of length $\Theta(\ell)$ on an $n$-node network of diameter $D$
requires $\Omega(\sqrt{\ell D}+D)$ time. This bound is {\em unconditional},
i.e., it holds for any (possibly randomized) algorithm. To the best of our
knowledge, this is the first lower bound that the diameter plays a role of
multiplicative factor. Our bound shows that the algorithm of Das Sarma et al.
is time optimal.
  Our proof technique introduces a new connection between {\em bounded-round}
communication complexity and distributed algorithm lower bounds with $D$ as a
trade-off parameter, strengthening the previous study by Das Sarma et al.
[STOC'11]. In particular, we make use of the bounded-round communication
complexity of the pointer chasing problem. Our technique can be of independent
interest and may be useful in showing non-trivial lower bounds on the
complexity of other fundamental distributed computing problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2915</identifier>
 <datestamp>2011-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2915</id><created>2011-02-14</created><authors><author><keyname>Utro</keyname><forenames>Filippo</forenames></author></authors><title>Algorithms for Internal Validation Clustering Measures in the Post
  Genomic Era</title><categories>cs.DS q-bio.QM</categories><journal-ref>PhD Thesis, University of Palermo, Italy, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inferring cluster structure in microarray datasets is a fundamental task for
the -omic sciences. A fundamental question in Statistics, Data Analysis and
Classification, is the prediction of the number of clusters in a dataset,
usually established via internal validation measures. Despite the wealth of
internal measures available in the literature, new ones have been recently
proposed, some of them specifically for microarray data. In this dissertation,
a study of internal validation measures is given, paying particular attention
to the stability based ones. Indeed, this class of measures is particularly
prominent and promising in order to have a reliable estimate the number of
clusters in a dataset. For those measures, a new general algorithmic paradigm
is proposed here that highlights the richness of measures in this class and
accounts for the ones already available in the literature. Moreover, some of
the most representative validation measures are also considered. Experiments on
12 benchmark datasets are performed in order to assess both the intrinsic
ability of a measure to predict the correct number of clusters in a dataset and
its merit relative to the other measures. The main result is a hierarchy of
internal validation measures in terms of precision and speed, highlighting some
of their merits and limitations not reported before in the literature. This
hierarchy shows that the faster the measure, the less accurate it is. In order
to reduce the time performance gap between the fastest and the most precise
measures, the technique of designing fast approximation algorithms is
systematically applied. The end result is a speed-up of many of the measures
studied here that brings the gap between the fastest and the most precise
within one order of magnitude in time, with no degradation in their prediction
power. Prior to this work, the time gap was at least two orders of magnitude.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2928</identifier>
 <datestamp>2011-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2928</id><created>2011-02-14</created><updated>2011-06-01</updated><authors><author><keyname>Eftekhari</keyname><forenames>Yaser</forenames></author><author><keyname>Heidarzadeh</keyname><forenames>Anoosheh</forenames></author><author><keyname>Banihashemi</keyname><forenames>Amir H.</forenames></author><author><keyname>Lambadaris</keyname><forenames>Ioannis</forenames></author></authors><title>Density Evolution Analysis of Node-Based Verification-Based Algorithms
  in Compressed Sensing</title><categories>cs.IT math.IT</categories><comments>5 Pages, 2 Figures, Proc. ISIT 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a new approach for the analysis of iterative
node-based verification-based (NB-VB) recovery algorithms in the context of
compressive sensing. These algorithms are particularly interesting due to their
low complexity (linear in the signal dimension $n$). The asymptotic analysis
predicts the fraction of unverified signal elements at each iteration $\ell$ in
the asymptotic regime where $n \rightarrow \infty$. The analysis is similar in
nature to the well-known density evolution technique commonly used to analyze
iterative decoding algorithms. To perform the analysis, a message-passing
interpretation of NB-VB algorithms is provided. This interpretation lacks the
extrinsic nature of standard message-passing algorithms to which density
evolution is usually applied. This requires a number of non-trivial
modifications in the analysis. The analysis tracks the average performance of
the recovery algorithms over the ensembles of input signals and sensing
matrices as a function of $\ell$. Concentration results are devised to
demonstrate that the performance of the recovery algorithms applied to any
choice of the input signal over any realization of the sensing matrix follows
the deterministic results of the analysis closely. Simulation results are also
provided which demonstrate that the proposed asymptotic analysis matches the
performance of recovery algorithms for large but finite values of $n$. Compared
to the existing technique for the analysis of NB-VB algorithms, which is based
on numerically solving a large system of coupled differential equations, the
proposed method is much simpler and more accurate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2932</identifier>
 <datestamp>2011-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2932</id><created>2011-02-14</created><updated>2011-11-19</updated><authors><author><keyname>Li</keyname><forenames>Yang D.</forenames></author></authors><title>Applications of Monotone Rank to Complexity Theory</title><categories>cs.CC quant-ph</categories><comments>A bug was fixed. Submitted to IEEE complexity 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Raz's recent result \cite{Raz2010} has rekindled people's interest in the
study of \emph{tensor rank}, the generalization of matrix rank to high
dimensions, by showing its connections to arithmetic formulas. In this paper,
we follow Raz's work and show that \emph{monotone rank}, the monotone variant
of tensor rank and matrix rank, has applications in algebraic complexity,
quantum computing and communication complexity. This paper differs from Raz's
paper in that it leverages existing results to show unconditional bounds while
Raz's result relies on some assumptions.
  We show a super-exponential separation between monotone and non-monotone
computation in the non-commutative model, and thus provide a strong solution to
Nisan's question \cite{Nis1991} in algebraic complexity. More specifically, we
exhibit that there exists a homogeneous algebraic function $f$ of degree $d$
($d$ even) on $n$ variables with the monotone algebraic branching program (ABP)
complexity $\Omega(d^2\log n)$ and the non-monotone ABP complexity $O(d^2)$.
  In Bell's theorem\cite{Bel1964, CHSH1969}, a basic assumption is that players
have free will, and under such an assumption, local hidden variable theory
still cannot predict the correlations produced by quantum mechanics. Using
tools from monotone rank, we show that even if we disallow the players to have
free will, local hidden variable theory still cannot predict the correlations
produced by quantum mechanics.
  We generalize the log-rank conjecture \cite{LS1988} in communication
complexity to the multiparty case, and prove that for super-polynomial parties,
there is a super-polynomial separation between the deterministic communication
complexity and the logarithm of the rank of the communication tensor. This
means that the log-rank conjecture does not hold in high dimensions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2933</identifier>
 <datestamp>2011-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2933</id><created>2011-02-14</created><updated>2011-03-31</updated><authors><author><keyname>Mortensen</keyname><forenames>Mikael</forenames></author><author><keyname>Langtangen</keyname><forenames>Hans Petter</forenames></author><author><keyname>Wells</keyname><forenames>Garth N.</forenames></author></authors><title>A FEniCS-Based Programming Framework for Modeling Turbulent Flow by the
  Reynolds-Averaged Navier-Stokes Equations</title><categories>cs.CE physics.comp-ph physics.flu-dyn</categories><comments>To appear in Advances in Water Resources</comments><doi>10.1016/j.advwatres.2011.02.013</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Finding an appropriate turbulence model for a given flow case usually calls
for extensive experimentation with both models and numerical solution methods.
This work presents the design and implementation of a flexible, programmable
software framework for assisting with numerical experiments in computational
turbulence. The framework targets Reynolds-averaged Navier-Stokes models,
discretized by finite element methods. The novel implementation makes use of
Python and the FEniCS package, the combination of which leads to compact and
reusable code, where model- and solver-specific code resemble closely the
mathematical formulation of equations and algorithms. The presented ideas and
programming techniques are also applicable to other fields that involve systems
of nonlinear partial differential equations. We demonstrate the framework in
two applications and investigate the impact of various linearizations on the
convergence properties of nonlinear solvers for a Reynolds-averaged
Navier-Stokes model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2935</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2935</id><created>2011-02-14</created><updated>2013-05-14</updated><authors><author><keyname>Yona</keyname><forenames>Yair</forenames></author><author><keyname>Feder</keyname><forenames>Meir</forenames></author></authors><title>Fundamental Limits of Infinite Constellations in MIMO Fading Channels</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The fundamental and natural connection between the infinite constellation
(IC) dimension and the best diversity order it can achieve is investigated in
this paper. In the first part of this work we develop an upper bound on the
diversity order of IC's for any dimension and any number of transmit and
receive antennas. By choosing the right dimensions, we prove in the second part
of this work that IC's in general and lattices in particular can achieve the
optimal diversity-multiplexing tradeoff of finite constellations. This work
gives a framework for designing lattices for multiple-antenna channels using
lattice decoding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2936</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2936</id><created>2011-02-14</created><updated>2012-12-28</updated><authors><author><keyname>Luzzi</keyname><forenames>Laura</forenames></author><author><keyname>Stehle</keyname><forenames>Damien</forenames></author><author><keyname>Ling</keyname><forenames>Cong</forenames></author></authors><title>Decoding by Embedding: Correct Decoding Radius and DMT Optimality</title><categories>cs.IT math.IT</categories><comments>To appear in IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The closest vector problem (CVP) and shortest (nonzero) vector problem (SVP)
are the core algorithmic problems on Euclidean lattices. They are central to
the applications of lattices in many problems of communications and
cryptography. Kannan's \emph{embedding technique} is a powerful technique for
solving the approximate CVP, yet its remarkable practical performance is not
well understood. In this paper, the embedding technique is analyzed from a
\emph{bounded distance decoding} (BDD) viewpoint. We present two complementary
analyses of the embedding technique: We establish a reduction from BDD to
Hermite SVP (via unique SVP), which can be used along with any Hermite SVP
solver (including, among others, the Lenstra, Lenstra and Lov\'asz (LLL)
algorithm), and show that, in the special case of LLL, it performs at least as
well as Babai's nearest plane algorithm (LLL-aided SIC). The former analysis
helps to explain the folklore practical observation that unique SVP is easier
than standard approximate SVP. It is proven that when the LLL algorithm is
employed, the embedding technique can solve the CVP provided that the noise
norm is smaller than a decoding radius $\lambda_1/(2\gamma)$, where $\lambda_1$
is the minimum distance of the lattice, and $\gamma \approx O(2^{n/4})$. This
substantially improves the previously best known correct decoding bound $\gamma
\approx {O}(2^{n})$. Focusing on the applications of BDD to decoding of
multiple-input multiple-output (MIMO) systems, we also prove that BDD of the
regularized lattice is optimal in terms of the diversity-multiplexing gain
tradeoff (DMT), and propose practical variants of embedding decoding which
require no knowledge of the minimum distance of the lattice and/or further
improve the error performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2939</identifier>
 <datestamp>2011-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2939</id><created>2011-02-14</created><updated>2011-05-27</updated><authors><author><keyname>Schipani</keyname><forenames>Davide</forenames></author><author><keyname>Elia</keyname><forenames>Michele</forenames></author><author><keyname>Rosenthal</keyname><forenames>Joachim</forenames></author></authors><title>On the Decoding Complexity of Cyclic Codes Up to the BCH Bound</title><categories>cs.IT math.IT</categories><comments>accepted for publication in Proceedings ISIT 2011. IEEE copyright</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The standard algebraic decoding algorithm of cyclic codes $[n,k,d]$ up to the
BCH bound $t$ is very efficient and practical for relatively small $n$ while it
becomes unpractical for large $n$ as its computational complexity is $O(nt)$.
Aim of this paper is to show how to make this algebraic decoding
computationally more efficient: in the case of binary codes, for example, the
complexity of the syndrome computation drops from $O(nt)$ to $O(t\sqrt n)$, and
that of the error location from $O(nt)$ to at most $\max \{O(t\sqrt n),
O(t^2\log(t)\log(n))\}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2946</identifier>
 <datestamp>2011-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2946</id><created>2011-02-14</created><authors><author><keyname>Murayama</keyname><forenames>Tatsuto</forenames></author><author><keyname>Davis</keyname><forenames>Peter</forenames></author></authors><title>A Large Deviations Result for Aggregation of Independent Noisy
  Observations</title><categories>cs.IT math.IT</categories><comments>5 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sensing and aggregation of noisy observations should not be considered as
separate issues. The quality of collective estimation involves a difficult
tradeoff between sensing quality which increases by increasing the number of
sensors, and aggregation quality which typically decreases if the number of
sensors is too large. We examine a strategy for optimal aggregation for an
ensemble of independent sensors with constrained system capacity. We show that
in the large capacity limit larger scale aggregation always outperforms smaller
scale aggregation at higher noise levels, while below a critical value of
noise, there exist moderate scale aggregation levels at which optimal
estimation is realized.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2950</identifier>
 <datestamp>2011-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2950</id><created>2011-02-14</created><authors><author><keyname>Dorfler</keyname><forenames>Florian</forenames></author><author><keyname>Bullo</keyname><forenames>Francesco</forenames></author></authors><title>Kron Reduction of Graphs with Applications to Electrical Networks</title><categories>math.CO cs.DM cs.SY math-ph math.MP math.OC</categories><msc-class>05C50, 94C15, 68R10, 05C76</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider a weighted and undirected graph, possibly with self-loops, and its
corresponding Laplacian matrix, possibly augmented with additional diagonal
elements corresponding to the self-loops. The Kron reduction of this graph is
again a graph whose Laplacian matrix is obtained by the Schur complement of the
original Laplacian matrix with respect to a subset of nodes. The Kron reduction
process is ubiquitous in classic circuit theory and in related disciplines such
as electrical impedance tomography, smart grid monitoring, transient stability
assessment in power networks, or analysis and simulation of induction motors
and power electronics. More general applications of Kron reduction occur in
sparse matrix algorithms, multi-grid solvers, finite--element analysis, and
Markov chains. The Schur complement of a Laplacian matrix and related concepts
have also been studied under different names and as purely theoretic problems
in the literature on linear algebra. In this paper we propose a general
graph-theoretic framework for Kron reduction that leads to novel and deep
insights both on the mathematical and the physical side. We show the
applicability of our framework to various practical problem setups arising in
engineering applications and computation. Furthermore, we provide a
comprehensive and detailed graph-theoretic analysis of the Kron reduction
process encompassing topological, algebraic, spectral, resistive, and
sensitivity analyses. Throughout our theoretic elaborations we especially
emphasize the practical applicability of our results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2955</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2955</id><created>2011-02-14</created><updated>2011-07-28</updated><authors><author><keyname>Savov</keyname><forenames>Ivan</forenames></author><author><keyname>Fawzi</keyname><forenames>Omar</forenames></author><author><keyname>Wilde</keyname><forenames>Mark M.</forenames></author><author><keyname>Sen</keyname><forenames>Pranab</forenames></author><author><keyname>Hayden</keyname><forenames>Patrick</forenames></author></authors><title>Quantum interference channels</title><categories>quant-ph cs.IT math.IT</categories><comments>10 pages, 2 figures, submitted to the 2011 Allerton Conference on
  Communication, Control, and Computing; v3 has a proof for a two-sender
  quantum simultaneous decoder and as a result, we get the capacity for
  channels with strong interference</comments><journal-ref>Proceedings of the 49th Annual Allerton Conference on
  Communication, Control, and Computing, pages 609-616 (2011)</journal-ref><doi>10.1109/Allerton.2011.6120224</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The discrete memoryless interference channel is modelled as a conditional
probability distribution with two outputs depending on two inputs and has
widespread applications in practical communication scenarios. In this paper, we
introduce and study the quantum interference channel, a generalization of a
two-input, two-output memoryless channel to the setting of quantum Shannon
theory. We discuss three different coding strategies and obtain corresponding
achievable rate regions for quantum interference channels. We calculate the
capacity regions in the special cases of &quot;very strong&quot; and &quot;strong&quot;
interference. The achievability proof in the case of &quot;strong&quot; interference
exploits a novel quantum simultaneous decoder for two-sender quantum multiple
access channels. We formulate a conjecture regarding the existence of a quantum
simultaneous decoder in the three-sender case and use it to state the rates
achievable by a quantum Han-Kobayashi strategy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2960</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2960</id><created>2011-02-14</created><updated>2011-06-13</updated><authors><author><keyname>Cai</keyname><forenames>Yang</forenames></author><author><keyname>Zhang</keyname><forenames>Ting</forenames></author></authors><title>Tight Upper Bounds for Streett and Parity Complementation</title><categories>cs.LO cs.FL</categories><comments>Corrected typos. 23 pages, 3 figures. To appear in the 20th
  Conference on Computer Science Logic (CSL 2011)</comments><acm-class>F.4.3; F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Complementation of finite automata on infinite words is not only a
fundamental problem in automata theory, but also serves as a cornerstone for
solving numerous decision problems in mathematical logic, model-checking,
program analysis and verification. For Streett complementation, a significant
gap exists between the current lower bound $2^{\Omega(n\lg nk)}$ and upper
bound $2^{O(nk\lg nk)}$, where $n$ is the state size, $k$ is the number of
Streett pairs, and $k$ can be as large as $2^{n}$. Determining the complexity
of Streett complementation has been an open question since the late '80s. In
this paper show a complementation construction with upper bound $2^{O(n \lg
n+nk \lg k)}$ for $k = O(n)$ and $2^{O(n^{2} \lg n)}$ for $k = \omega(n)$,
which matches well the lower bound obtained in \cite{CZ11a}. We also obtain a
tight upper bound $2^{O(n \lg n)}$ for parity complementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2963</identifier>
 <datestamp>2011-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2963</id><created>2011-02-15</created><updated>2011-09-18</updated><authors><author><keyname>Cai</keyname><forenames>Yang</forenames></author><author><keyname>Zhang</keyname><forenames>Ting</forenames></author></authors><title>A Tight Lower Bound for Streett Complementation</title><categories>cs.LO cs.FL</categories><comments>Typo correction and section reorganization. To appear in the
  proceeding of the 31st Foundations of Software Technology and Theoretical
  Computer Science conference (FSTTCS 2011)</comments><acm-class>F.4.3; F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Finite automata on infinite words ($\omega$-automata) proved to be a powerful
weapon for modeling and reasoning infinite behaviors of reactive systems.
Complementation of $\omega$-automata is crucial in many of these applications.
But the problem is non-trivial; even after extensive study during the past four
decades, we still have an important type of $\omega$-automata, namely Streett
automata, for which the gap between the current best lower bound $2^{\Omega(n
\lg nk)}$ and upper bound $2^{\Omega(nk \lg nk)}$ is substantial, for the
Streett index size $k$ can be exponential in the number of states $n$. In
arXiv:1102.2960 we showed a construction for complementing Streett automata
with the upper bound $2^{O(n \lg n+nk \lg k)}$ for $k = O(n)$ and $2^{O(n^{2}
\lg n)}$ for $k=\omega(n)$. In this paper we establish a matching lower bound
$2^{\Omega(n \lg n+nk \lg k)}$ for $k = O(n)$ and $2^{\Omega(n^{2} \lg n)}$ for
$k = \omega(n)$, and therefore showing that the construction is asymptotically
optimal with respect to the $2^{\Theta(\cdot)}$ notation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2969</identifier>
 <datestamp>2011-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2969</id><created>2011-02-15</created><authors><author><keyname>Roh</keyname><forenames>Gook-Pil</forenames></author><author><keyname>Hwang</keyname><forenames>Seung-won</forenames></author><author><keyname>Yi</keyname><forenames>Byoung-Kee</forenames></author></authors><title>Efficient and scalable geometric hashing method for searching protein 3D
  structures</title><categories>cs.DB q-bio.QM</categories><comments>9 pages, 1 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As the structural databases continue to expand, efficient methods are
required to search similar structures of the query structure from the database.
There are many previous works about comparing protein 3D structures and
scanning the database with a query structure. However, they generally have
limitations on practical use because of large computational and storage
requirements.
  We propose two new types of queries for searching similar sub-structures on
the structural database: LSPM (Local Spatial Pattern Matching) and RLSPM
(Reverse LSPM). Between two types of queries, we focus on RLSPM problem,
because it is more practical and general than LSPM. As a naive algorithm, we
adopt geometric hashing techniques to RLSPM problem and then propose our
proposed algorithm which improves the baseline algorithm to deal with
large-scale data and provide an efficient matching algorithm. We employ the
sub-sampling and Z-ordering to reduce the storage requirement and execution
time, respectively. We conduct our experiments to show the correctness and
reliability of the proposed method. Our experiment shows that the true positive
rate is at least 0.8 using the reliability measure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2975</identifier>
 <datestamp>2011-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2975</id><created>2011-02-15</created><authors><author><keyname>Liu</keyname><forenames>Haoyang</forenames></author><author><keyname>Liu</keyname><forenames>Keqin</forenames></author><author><keyname>Zhao</keyname><forenames>Qing</forenames></author></authors><title>Decentralized Restless Bandit with Multiple Players and Unknown Dynamics</title><categories>math.OC cs.LG cs.SY math.PR</categories><comments>7 pages, 2 figures, in Proc. of Information Theory and Applications
  Workshop (ITA), January, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider decentralized restless multi-armed bandit problems with unknown
dynamics and multiple players. The reward state of each arm transits according
to an unknown Markovian rule when it is played and evolves according to an
arbitrary unknown random process when it is passive. Players activating the
same arm at the same time collide and suffer from reward loss. The objective is
to maximize the long-term reward by designing a decentralized arm selection
policy to address unknown reward models and collisions among players. A
decentralized policy is constructed that achieves a regret with logarithmic
order when an arbitrary nontrivial bound on certain system parameters is known.
When no knowledge about the system is available, we extend the policy to
achieve a regret arbitrarily close to the logarithmic order. The result finds
applications in communication networks, financial investment, and industrial
engineering.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2984</identifier>
 <datestamp>2011-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2984</id><created>2011-02-15</created><authors><author><keyname>Hajlaoui</keyname><forenames>Rjab</forenames></author><author><keyname>Gzara</keyname><forenames>Mariem</forenames></author><author><keyname>Dammak</keyname><forenames>Abdelaziz</forenames></author></authors><title>Hybrid Model for Solving Multi-Objective Problems Using Evolutionary
  Algorithm and Tabu Search</title><categories>cs.AI</categories><comments>5 pages</comments><journal-ref>World of Computer Science and Information Technology Journal
  (WCSIT),ISSN: 2221-0741,Vol. 1, No. 1, 5-9, Feb. 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a new multi-objective hybrid model that makes cooperation
between the strength of research of neighborhood methods presented by the tabu
search (TS) and the important exploration capacity of evolutionary algorithm.
This model was implemented and tested in benchmark functions (ZDT1, ZDT2, and
ZDT3), using a network of computers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.2986</identifier>
 <datestamp>2011-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.2986</id><created>2011-02-15</created><authors><author><keyname>Etzion</keyname><forenames>Tuvi</forenames></author></authors><title>Sidon Sequences and Doubly Periodic Two-Dimensional Synchronization
  Patterns</title><categories>cs.IT math.IT</categories><comments>submitted to International Symposium on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sidon sequences and their generalizations have found during the years and
especially recently various applications in coding theory. One of the most
important applications of these sequences is in the connection of
synchronization patterns. A few constructions of two-dimensional
synchronization patterns are based on these sequences. In this paper we present
sufficient conditions that a two-dimensional synchronization pattern can be
transformed into a Sidon sequence. We also present a new construction for Sidon
sequences over an alphabet of size q(q-1), where q is a power of a prime.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3002</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3002</id><created>2011-02-15</created><updated>2011-06-05</updated><authors><author><keyname>Matsumoto</keyname><forenames>Ryutaroh</forenames></author><author><keyname>Hayashi</keyname><forenames>Masahito</forenames></author></authors><title>Secure Multiplex Network Coding</title><categories>cs.IT cs.CR math.IT</categories><comments>IEEEtran.sty, 7 pages, no figure, Version 2 will appear in Proc.
  NetCod 2011, Beijing, China. Version 3 adds an appendix proving that the
  mutual information can be made exactly zero</comments><doi>10.1109/ISNETCOD.2011.5979076</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the secure network coding for multicasting, there is loss of information
rate due to inclusion of random bits at the source node. We show a method to
eliminate that loss of information rate by using multiple statistically
independent messages to be kept secret from an eavesdropper. The proposed
scheme is an adaptation of Yamamoto et al.'s secure multiplex coding to the
secure network coding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3013</identifier>
 <datestamp>2011-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3013</id><created>2011-02-15</created><authors><author><keyname>La</keyname><forenames>Chi-Anh</forenames></author><author><keyname>Michiardi</keyname><forenames>Pietro</forenames></author><author><keyname>Casetti</keyname><forenames>Claudio</forenames></author><author><keyname>Chiasserini</keyname><forenames>Carla-Fabiana</forenames></author><author><keyname>Fiore</keyname><forenames>Marco</forenames></author></authors><title>Content replication and placement in mobile networks</title><categories>cs.NI</categories><comments>14 pages, 34 figures</comments><msc-class>68M10</msc-class><acm-class>C.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Performance and reliability of content access in mobile networks is
conditioned by the number and location of content replicas deployed at the
network nodes. Location theory has been the traditional, centralized approach
to study content replication: computing the number and placement of replicas in
a static network can be cast as a facility location problem. The endeavor of
this work is to design a practical solution to the above joint optimization
problem that is suitable for mobile wireless environments. We thus seek a
replication algorithm that is lightweight, distributed, and reactive to network
dynamics. We devise a solution that lets nodes (i) share the burden of storing
and providing content, so as to achieve load balancing, and (ii) autonomously
decide whether to replicate or drop the information, so as to adapt the content
availability to dynamic demands and time-varying network topologies. We
evaluate our mechanism through simulation, by exploring a wide range of
settings, including different node mobility models, content characteristics and
system scales. Furthermore, we compare our mechanism to state-of-the-art
approaches to content delivery in static and mobile networks. Results show that
our mechanism, which uses local measurements only, is: (i) extremely precise in
approximating an optimal solution to content placement and replication; (ii)
robust against network mobility; (iii) flexible in accommodating various
content access patterns. Moreover, our scheme outperforms alternative
approaches to content dissemination both in terms of content access delay and
access congestion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3025</identifier>
 <datestamp>2011-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3025</id><created>2011-02-15</created><authors><author><keyname>Fleischer</keyname><forenames>Rudolf</forenames></author><author><keyname>Woeginger</keyname><forenames>Gerhard J.</forenames></author></authors><title>An Algorithmic Analysis of the Honey-Bee Game</title><categories>cs.GT</categories><comments>20 pages, 9 figures</comments><acm-class>F.2.2; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Honey-Bee game is a two-player board game that is played on a connected
hexagonal colored grid or (in a generalized setting) on a connected graph with
colored nodes. In a single move, a player calls a color and thereby conquers
all the nodes of that color that are adjacent to his own current territory.
Both players want to conquer the majority of the nodes. We show that winning
the game is PSPACE-hard in general, NP-hard on series-parallel graphs, but easy
on outerplanar graphs.
  In the solitaire version, the goal of the single player is to conquer the
entire graph with the minimum number of moves. The solitaire version is NP-hard
on trees and split graphs, but can be solved in polynomial time on
co-comparability graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3029</identifier>
 <datestamp>2011-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3029</id><created>2011-02-15</created><authors><author><keyname>Eggermont</keyname><forenames>Christian</forenames></author><author><keyname>Schrijver</keyname><forenames>Alexander</forenames></author><author><keyname>Woeginger</keyname><forenames>Gerhard J.</forenames></author></authors><title>Analysis of multi-stage open shop processing systems</title><categories>cs.DS cs.SY math.OC</categories><comments>19 pages, no figures</comments><msc-class>90C27</msc-class><acm-class>F.2.2; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study algorithmic problems in multi-stage open shop processing systems
that are centered around reachability and deadlock detection questions. We
characterize safe and unsafe system states. We show that it is easy to
recognize system states that can be reached from the initial state (where the
system is empty), but that in general it is hard to decide whether one given
system state is reachable from another given system state. We show that the
problem of identifying reachable deadlock states is hard in general open shop
systems, but is easy in the special case where no job needs processing on more
than two machines (by linear programming and matching theory), and in the
special case where all machines have capacity one (by graph-theoretic
arguments).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3044</identifier>
 <datestamp>2011-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3044</id><created>2011-02-15</created><updated>2011-07-19</updated><authors><author><keyname>de Kerret</keyname><forenames>P.</forenames></author><author><keyname>Gesbert</keyname><forenames>D.</forenames></author></authors><title>The Multiplexing Gain of a Two-cell MIMO Channel with Unequal CSI</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, the joint precoding across two distant transmitters (TXs),
sharing the knowledge of the data symbols to be transmitted, to two receivers
(RXs), each equipped with one antenna, is discussed. We consider a distributed
channel state information (CSI) configuration where each TX has its own local
estimate of the channel and no communication is possible between the TXs. Based
on the distributed CSI configuration, we introduce a concept of distributed
MIMO precoding. We focus on the high signal-to-noise ratio (SNR) regime such
that the two TXs aim at designing a precoding matrix to cancel the
interference. Building on the study of the multiple antenna broadcast channel,
we obtain the following key results: We derive the multiplexing gain (MG) as a
function of the scaling in the SNR of the number of bits quantizing at each TX
the channel to a given RX. Particularly, we show that the conventional Zero
Forcing precoder is not MG maximizing, and we provide a precoding scheme
optimal in terms of MG. Beyond the established MG optimality, simulations show
that the proposed precoding schemes achieve better performances at intermediate
SNR than known linear precoders.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3047</identifier>
 <datestamp>2011-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3047</id><created>2011-02-15</created><authors><author><keyname>Shelton</keyname><forenames>Robert D.</forenames></author><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author></authors><title>Publish or Patent: Bibliometric evidence for empirical trade-offs in
  national funding strategies</title><categories>cs.DL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multivariate linear regression models suggest a trade-off in allocations of
national R&amp;D investments. Government funding, and spending in the higher
education sector, seem to encourage publications, whereas other components such
as industrial funding, and spending in the business sector, encourage
patenting. Our results help explain why the US trails the EU in publications,
because of its focus on industrial funding - some 70% of its total R&amp;D
investment. Conversely, it also helps explain why the EU trails the US in
patenting. Government funding is indicated as a negative incentive to
high-quality patenting. The models here can also be used to predict an output
indicator for a country, once the appropriate input indicator is known. This
usually is done within a dataset for a single year, but the process can be
extended to predict outputs a few years into the future, if reasonable
forecasts can be made of the input indicators. We provide new forecasts about
the further relationships of the US, the EU-27, and the PRC in the case of
publishing. Models for individual countries may be more successful, however,
than regression models whose parameters are averaged over a set of countries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3056</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3056</id><created>2011-02-15</created><updated>2011-11-10</updated><authors><author><keyname>Takeuchi</keyname><forenames>Keigo</forenames></author><author><keyname>Tanaka</keyname><forenames>Toshiyuki</forenames></author><author><keyname>Kawabata</keyname><forenames>Tsutomu</forenames></author></authors><title>A Phenomenological Study on Threshold Improvement via Spatial Coupling</title><categories>cs.IT math.IT</categories><comments>re-submitted to IEICE Trans. Fundamentals</comments><doi>10.1587/transfun.E95.A.974</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Kudekar et al. proved an interesting result in low-density parity-check
(LDPC) convolutional codes: The belief-propagation (BP) threshold is boosted to
the maximum-a-posteriori (MAP) threshold by spatial coupling. Furthermore, the
authors showed that the BP threshold for code-division multiple-access (CDMA)
systems is improved up to the optimal one via spatial coupling. In this letter,
a phenomenological model for elucidating the essence of these phenomenon,
called threshold improvement, is proposed. The main result implies that
threshold improvement occurs for spatially-coupled general graphical models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3058</identifier>
 <datestamp>2011-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3058</id><created>2011-02-15</created><authors><author><keyname>Mazzucco</keyname><forenames>Michele</forenames></author><author><keyname>Dyachuk</keyname><forenames>Dmytro</forenames></author><author><keyname>Deters</keyname><forenames>Ralph</forenames></author></authors><title>Maximizing Cloud Providers Revenues via Energy Aware Allocation Policies</title><categories>cs.DC cs.PF</categories><comments>8 pages</comments><journal-ref>2010 IEEE 3rd International Conference on Cloud Computing, 2010 --
  pp 131-138</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Cloud providers, like Amazon, offer their data centers' computational and
storage capacities for lease to paying customers. High electricity consumption,
associated with running a data center, not only reflects on its carbon
footprint, but also increases the costs of running the data center itself. This
paper addresses the problem of maximizing the revenues of Cloud providers by
trimming down their electricity costs. As a solution allocation policies which
are based on the dynamic powering servers on and off are introduced and
evaluated. The policies aim at satisfying the conflicting goals of maximizing
the users' experience while minimizing the amount of consumed electricity. The
results of numerical experiments and simulations are described, showing that
the proposed scheme performs well under different traffic conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3059</identifier>
 <datestamp>2011-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3059</id><created>2011-02-15</created><authors><author><keyname>Mazzucco</keyname><forenames>Michele</forenames></author><author><keyname>Dyachuk</keyname><forenames>Dmytro</forenames></author><author><keyname>Dikaiakos</keyname><forenames>Marios</forenames></author></authors><title>Profit-Aware Server Allocation for Green Internet Services</title><categories>cs.PF cs.DC</categories><comments>8 pages</comments><journal-ref>18th Annual IEEE/ACM International Symposium on Modeling, Analysis
  and Simulation of Computer and Telecommunication Systems, 2010, pp 277-284</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  A server farm is examined, where a number of servers are used to offer a
service to impatient customers. Every completed request generates a certain
amount of profit, running servers consume electricity for power and cooling,
while waiting customers might leave the system before receiving service if they
experience excessive delays. A dynamic allocation policy aiming at satisfying
the conflicting goals of maximizing the quality of users' experience while
minimizing the cost for the provider is introduced and evaluated. The results
of several experiments are described, showing that the proposed scheme performs
well under different traffic conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3061</identifier>
 <datestamp>2011-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3061</id><created>2011-02-15</created><updated>2011-04-20</updated><authors><author><keyname>Takeuchi</keyname><forenames>Keigo</forenames></author><author><keyname>Tanaka</keyname><forenames>Toshiyuki</forenames></author><author><keyname>Kawabata</keyname><forenames>Tsutomu</forenames></author></authors><title>Improvement of BP-Based CDMA Multiuser Detection by Spatial Coupling</title><categories>cs.IT math.IT</categories><comments>accepted for presentation at ISIT2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Kudekar et al. proved that the belief-propagation (BP) threshold for
low-density parity-check codes can be boosted up to the maximum-a-posteriori
(MAP) threshold by spatial coupling. In this paper, spatial coupling is applied
to randomly-spread code-division multiple-access (CDMA) systems in order to
improve the performance of BP-based multiuser detection (MUD).
Spatially-coupled CDMA systems can be regarded as multi-code CDMA systems with
two transmission phases. The large-system analysis shows that spatial coupling
can improve the BP performance, while there is a gap between the BP performance
and the individually-optimal (IO) performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3063</identifier>
 <datestamp>2011-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3063</id><created>2011-02-15</created><authors><author><keyname>Boscain</keyname><forenames>Ugo</forenames><affiliation>CMAP</affiliation></author><author><keyname>Chittaro</keyname><forenames>Francesca</forenames><affiliation>IECN, INRIA Lorraine / IECN / MMAS</affiliation></author><author><keyname>Mason</keyname><forenames>Paolo</forenames><affiliation>IECN, INRIA Lorraine / IECN / MMAS</affiliation></author><author><keyname>Sigalotti</keyname><forenames>Mario</forenames><affiliation>IECN, INRIA Lorraine / IECN / MMAS</affiliation></author></authors><title>Adiabatic control of the Schr\&quot;odinger equation via conical
  intersections of the eigenvalues</title><categories>math.OC cs.SY</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a constructive method to control the bilinear
Schr\&quot;odinger equation via two controls. The method is based on adiabatic
techniques and works if the spectrum of the Hamiltonian admits eigenvalue
intersections, and if the latter are conical (as it happens generically). We
provide sharp estimates of the relation between the error and the
controllability time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3067</identifier>
 <datestamp>2012-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3067</id><created>2011-02-15</created><authors><author><keyname>Donges</keyname><forenames>Jonathan F.</forenames></author><author><keyname>Schultz</keyname><forenames>Hanna C. H.</forenames></author><author><keyname>Marwan</keyname><forenames>Norbert</forenames></author><author><keyname>Zou</keyname><forenames>Yong</forenames></author><author><keyname>Kurths</keyname><forenames>Juergen</forenames></author></authors><title>Investigating the topology of interacting networks - Theory and
  application to coupled climate subnetworks</title><categories>physics.data-an cs.SI physics.ao-ph physics.soc-ph</categories><journal-ref>European Physical Journal B 84(4), 635-652 (2011)</journal-ref><doi>10.1140/epjb/e2011-10795-8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Network theory provides various tools for investigating the structural or
functional topology of many complex systems found in nature, technology and
society. Nevertheless, it has recently been realised that a considerable number
of systems of interest should be treated, more appropriately, as interacting
networks or networks of networks. Here we introduce a novel graph-theoretical
framework for studying the interaction structure between subnetworks embedded
within a complex network of networks. This framework allows us to quantify the
structural role of single vertices or whole subnetworks with respect to the
interaction of a pair of subnetworks on local, mesoscopic and global
topological scales.
  Climate networks have recently been shown to be a powerful tool for the
analysis of climatological data. Applying the general framework for studying
interacting networks, we introduce coupled climate subnetworks to represent and
investigate the topology of statistical relationships between the fields of
distinct climatological variables. Using coupled climate subnetworks to
investigate the terrestrial atmosphere's three-dimensional geopotential height
field uncovers known as well as interesting novel features of the atmosphere's
vertical stratification and general circulation. Specifically, the new measure
&quot;cross-betweenness&quot; identifies regions which are particularly important for
mediating vertical wind field interactions. The promising results obtained by
following the coupled climate subnetwork approach present a first step towards
an improved understanding of the Earth system and its complex interacting
components from a network perspective.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3079</identifier>
 <datestamp>2011-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3079</id><created>2011-02-15</created><authors><author><keyname>Dombek</keyname><forenames>Daniel</forenames></author><author><keyname>Mas&#xe1;kov&#xe1;</keyname><forenames>Zuzana</forenames></author><author><keyname>Pelantov&#xe1;</keyname><forenames>Edita</forenames></author></authors><title>Number representation using generalized $(-\beta)$-transformation</title><categories>cs.DM math.NT</categories><comments>22 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study non-standard number systems with negative base $-\beta$. Instead of
the Ito-Sadahiro definition, based on the transformation $T_{-\beta}$ of the
interval $\big[-\frac{\beta}{\beta+1},\frac{1}{\beta+1}\big)$ into itself, we
suggest a generalization using an interval $[l,l+1)$ with $l\in(-1,0]$. Such
generalization may eliminate certain disadvantages of the Ito-Sadahiro system.
We focus on the description of admissible digit strings and their periodicity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3080</identifier>
 <datestamp>2011-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3080</id><created>2011-02-15</created><authors><author><keyname>Lapidoth</keyname><forenames>Amos</forenames></author><author><keyname>Mal&#xe4;r</keyname><forenames>Andreas</forenames></author><author><keyname>Wang</keyname><forenames>Ligong</forenames></author></authors><title>Covering Point Patterns</title><categories>cs.IT math.IT</categories><comments>5 pages. Submitted to ISIT 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An encoder observes a point pattern---a finite number of points in the
interval $[0,T]$---which is to be described to a reconstructor using bits.
Based on these bits, the reconstructor wishes to select a subset of $[0,T]$
that contains all the points in the pattern. It is shown that, if the point
pattern is produced by a homogeneous Poisson process of intensity $\lambda$,
and if the reconstructor is restricted to select a subset of average Lebesgue
measure not exceeding $DT$, then, as $T$ tends to infinity, the minimum number
of bits per second needed by the encoder is $-\lambda\log D$. It is also shown
that, as $T$ tends to infinity, any point pattern on $[0,T]$ containing no more
than $\lambda T$ points can be successfully described using $-\lambda \log D$
bits per second in this sense. Finally, a Wyner-Ziv version of this problem is
considered where some of the points in the pattern are known to the
reconstructor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3082</identifier>
 <datestamp>2011-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3082</id><created>2011-02-15</created><updated>2011-02-16</updated><authors><author><keyname>Yilmaz</keyname><forenames>Erhan</forenames></author><author><keyname>Knopp</keyname><forenames>Raymond</forenames></author></authors><title>Hash-and-Forward Relaying for Two-Way Relay Channel</title><categories>cs.IT math.IT</categories><comments>5 pages, 2 figures, submitted to the IEEE ISIT'11 conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers a communication network comprised of two nodes, which
have no mutual direct communication links, communicating two-way with the aid
of a common relay node (RN), also known as separated two-way relay (TWR)
channel.
  We first recall a cut-set outer bound for the set of rates in the context of
this network topology assuming full-duplex transmission capabilities. Then, we
derive a new achievable rate region based on hash-and-forward (HF) relaying
where the RN does not attempt to decode but instead hashes its received signal,
and show that under certain channel conditions it coincides with Shannon's
inner-bound for the two-way channel [1]. Moreover, for binary adder TWR channel
with additive noise at the nodes and the RN we provide a detailed capacity
achieving coding scheme based on structure codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3093</identifier>
 <datestamp>2011-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3093</id><created>2011-02-15</created><updated>2011-05-09</updated><authors><author><keyname>Yakaryilmaz</keyname><forenames>Abuzer</forenames></author></authors><title>Superiority of one-way and realtime quantum machines and new directions</title><categories>cs.CC quant-ph</categories><comments>A revised edition with some corrections</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In automata theory, the quantum computation has been widely examined for
finite state machines, known as quantum finite automata (QFAs), and less
attention has been given to the QFAs augmented with counters or stacks.
Moreover, to our knowledge, there is no result related to QFAs having more than
one input head. In this paper, we focus on such generalizations of QFAs whose
input head(s) operate(s) in one-way or realtime mode and present many
superiority of them to their classical counterparts. Furthermore, we propose
some open problems and conjectures in order to investigate the power of
quantumness better. We also give some new results on classical computation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3106</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3106</id><created>2011-02-15</created><updated>2011-04-11</updated><authors><author><keyname>Esik</keyname><forenames>Zoltan</forenames></author></authors><title>Multi-linear iterative K-Sigma-semialgebras</title><categories>cs.DM cs.FL</categories><msc-class>68Q70, 08A70</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider $K$-semialgebras for a commutative semiring $K$ that are at the
same time $\Sigma$-algebras and satisfy certain linearity conditions. When each
finite system of guarded polynomial fixed point equations has a unique solution
over such an algebra, then we call it an iterative multi-linear
$K$-$\Sigma$-semialgebra. Examples of such algebras include the algebras of
$\Sigma$-tree series over an alphabet $A$ with coefficients in $K$, and the
algebra of all rational tree series. We show that for many commutative
semirings $K$, the rational $\Sigma$-tree series over $A$ with coefficients in
$K$ form the free multi-linear iterative $K$-$\Sigma$-semialgebra on $A$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3112</identifier>
 <datestamp>2011-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3112</id><created>2011-02-13</created><authors><author><keyname>Hassani</keyname><forenames>Abdessalem</forenames><affiliation>LGM</affiliation></author><author><keyname>Aifaoui</keyname><forenames>Nizar</forenames><affiliation>LGM</affiliation></author><author><keyname>Benamara</keyname><forenames>Abdelmajid</forenames><affiliation>LGM</affiliation></author><author><keyname>Samper</keyname><forenames>Serge</forenames><affiliation>SYMME</affiliation></author></authors><title>Computer Aided Tolerancing Based on Analysis and Synthetizes of
  Tolerances Method</title><categories>cs.OH</categories><proxy>ccsd</proxy><journal-ref>ICAMEM 2008, Sousse : Tunisia (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The tolerancing step has a great importance in the design process. It
characterises the relationship between the different sectors of the product
life cycle: Design, Manufacturing and Control. We can distinguish several
methods to assist the tolerancing process in the design. Based on arithmetic
and statistical method, this paper presents a new approach of analysis and
verification of tolerances. The chosen approach is based on the Worst Case
Method as an arithmetic method and Monte Carlo method as a statistical method.
In this paper, we compare these methods and we present our main approach, which
is validated using an example of 1 D tolerancing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3114</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3114</id><created>2011-02-15</created><authors><author><keyname>Skipsey</keyname><forenames>Samuel C</forenames><affiliation>University of Glasgow</affiliation></author><author><keyname>Bhimji</keyname><forenames>Wahid</forenames><affiliation>University of Edinburgh</affiliation></author><author><keyname>Kenyon</keyname><forenames>Mike</forenames><affiliation>IT Department, CERN</affiliation></author></authors><title>Establishing Applicability of SSDs to LHC Tier-2 Hardware Configuration</title><categories>cs.DC</categories><comments>6 pages, 1 figure, 4 tables. Conference proceedings for CHEP2010</comments><doi>10.1088/1742-6596/331/5/052019</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Solid State Disk technologies are increasingly replacing high-speed hard
disks as the storage technology in high-random-I/O environments. There are
several potentially I/O bound services within the typical LHC Tier-2 - in the
back-end, with the trend towards many-core architectures continuing, worker
nodes running many single-threaded jobs and storage nodes delivering many
simultaneous files can both exhibit I/O limited efficiency. We estimate the
effectiveness of affordable SSDs in the context of worker nodes, on a large
Tier-2 production setup using both low level tools and real LHC I/O intensive
data analysis jobs comparing and contrasting with high performance spinning
disk based solutions. We consider the applicability of each solution in the
context of its price/performance metrics, with an eye on the pragmatic issues
facing Tier-2 provision and upgrades
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3120</identifier>
 <datestamp>2011-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3120</id><created>2011-02-15</created><authors><author><keyname>Yilmaz</keyname><forenames>Erhan</forenames></author><author><keyname>Knopp</keyname><forenames>Raymond</forenames></author><author><keyname>Gesbert</keyname><forenames>David</forenames></author></authors><title>Interference Two-Way Relay Channel with Three End-nodes</title><categories>cs.IT math.IT</categories><comments>7 pages, 2 figures, submitted to the IEEE ISIT'11 conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study a communication system consisting of three end-nodes,
e.g. a single transceiver base station (BS), one transmitting and one receiving
user equipments (UEs), and a common two-way relay node (RN) wherein the
full-duplex BS transmits to the receiving UE in downlink direction and receives
from the transmitting UE in uplink direction with the help of the intermediate
full-duplex RN. We call this system model as interference two-way relay channel
(ITWRC) with three end-nodes. Information theoretic bounds corresponding this
system model are derived and analyzed so as to better understand the potentials
of exploiting RN in future communication systems. Specifically, achievable rate
regions corresponding to decode-and-forward (DF) relaying with and without rate
splitting, and partial-DF and compress-and-forward (pDF+CF) relaying strategies
are derived.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3126</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3126</id><created>2011-02-15</created><updated>2011-05-19</updated><authors><author><keyname>Kurzweil</keyname><forenames>Hans</forenames></author><author><keyname>Seidl</keyname><forenames>Mathis</forenames></author><author><keyname>Huber</keyname><forenames>Johannes B.</forenames></author></authors><title>Reduced-Complexity Collaborative Decoding of Interleaved Reed-Solomon
  and Gabidulin Codes</title><categories>cs.IT math.IT</categories><comments>Accepted for IEEE International Symposium on Information Theory
  (ISIT) 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An alternative method for collaborative decoding of interleaved Reed-Solomon
codes as well as Gabidulin codes for the case of high interleaving degree is
proposed. As an example of application, simulation results are presented for a
concatenated coding scheme using polar codes as inner codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3127</identifier>
 <datestamp>2011-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3127</id><created>2011-02-15</created><authors><author><keyname>Chu</keyname><forenames>Hsuan-Yi</forenames></author><author><keyname>Su</keyname><forenames>Hsuan-Jung</forenames></author></authors><title>On the Cognitive Interference Channel with Unidirectional Destination
  Cooperation</title><categories>cs.IT math.IT</categories><comments>18 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The cognitive interference channel with unidirectional destination
cooperation (CIFC-UDC) is a cognitive interference channel (CIFC) where the
cognitive (secondary) destination not only decodes the information sent from
its sending dual but also helps enhance the communication of the primary user.
This channel model is an extension of the original CIFC to achieve a win-win
solution under the coexistence condition. From an information-theoretic
perspective, the CIFC-UDC comprises a broadcast channel (BC), a relay channel
(RC) and a partially cooperative relay broadcast channel (PCRBC), and can be
degraded to any one of them. Our main result is the establishment of a new
unified achieva-ble rate region for the CIFC-UDC which is the largest known to
date and can be explicitly shown to include the previous result proposed by Chu
and the largest known rate regions for the BC, the RC and the PCRBC. In
addition, an interesting viewpoint on the unidirectional destination
cooperation in the CIFC-UDC is discussed: to enable the decoder of the primary
user to perform interference mitigation can be considered as a complementary
idea to the interference mitigation via Gel'fand-Pinsker precod-ing in the CIFC
proposed by Devroye et al. Henceforth, by com-bing these two ideas, the
interferences caused at both the desti-nations can be alleviated. Lastly, an
outer bound is presented and proved to be tight for a class of the CIFC-UDC,
resulting in the characterization of the capacity region for this class.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3129</identifier>
 <datestamp>2011-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3129</id><created>2011-02-15</created><updated>2011-06-01</updated><authors><author><keyname>Hirokawa</keyname><forenames>Nao</forenames></author><author><keyname>Moser</keyname><forenames>Georg</forenames></author></authors><title>Automated Complexity Analysis Based on the Dependency Pair Method</title><categories>cs.LO cs.AI cs.CC cs.PL</categories><comments>37 pages, submitted to Information &amp; Computation</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This article is concerned with automated complexity analysis of term rewrite
systems. Since these systems underlie much of declarative programming, time
complexity of functions defined by rewrite systems is of particular interest.
Among other results, we present a variant of the dependency pair method for
analysing runtime complexities of term rewrite systems automatically. The
established results significantly extent previously known techniques: we give
examples of rewrite systems subject to our methods that could previously not
been analysed automatically. Furthermore, the techniques have been implemented
in the Tyrolean Complexity Tool. We provide ample numerical data for assessing
the viability of the method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3132</identifier>
 <datestamp>2011-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3132</id><created>2011-02-15</created><updated>2011-02-18</updated><authors><author><keyname>Mori</keyname><forenames>Ryuhei</forenames></author></authors><title>Connection between Annealed Free Energy and Belief Propagation on Random
  Factor Graph Ensembles</title><categories>cs.IT math.IT</categories><comments>10 pages, 1 figure, submitted to ISIT2011; The saddle point equation
  in Lemma 7 is fixed</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, Vontobel showed the relationship between Bethe free energy and
annealed free energy for protograph factor graph ensembles. In this paper,
annealed free energy of any random regular, irregular and Poisson factor graph
ensembles are connected to Bethe free energy. The annealed free energy is
expressed as the solution of maximization problem whose stationary condition
equations coincide with equations of belief propagation since the contribution
to partition function of particular type of variable and factor nodes has
similar form of minus Bethe free energy. It gives simple derivation of replica
symmetric solution. As consequence, it is shown that on replica symmetric
ansatz, replica symmetric solution and annealed free energy are equal for
regular ensemble.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3140</identifier>
 <datestamp>2011-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3140</id><created>2011-02-15</created><authors><author><keyname>Abhinav</keyname><forenames>G.</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>Capacity Region of $K$-User Discrete Memoryless Interference Channels
  with a Mixed Strong-Very Strong Interference</title><categories>cs.IT math.IT</categories><comments>6 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The capacity region of the 3-user Gaussian Interference Channel (GIC) with
mixed strong-very strong interference was established in \cite{ChS}. The mixed
strong-very strong interference conditions considered in \cite{ChS} correspond
to the case where, at each receiver, one of the interfering signals is strong
and the other is very strong. In this paper, we derive the capacity region of
$K$-user $(K\geq 3)$ Discrete Memoryless Interference Channels (DMICs) with a
mixed strong-very strong interference. This corresponds to the case where, at
each receiver one of the interfering signals is strong and the other $(K-2)$
interfering signals are very strong. This includes, as a special case, the
3-user DMIC with mixed strong-very strong interference. The proof is
specialized to the 3-user GIC case and hence an alternative simpler derivation
for the capacity region of the 3-user GIC with mixed strong-very strong
interference is provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3145</identifier>
 <datestamp>2011-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3145</id><created>2011-02-15</created><authors><author><keyname>Coja-Oghlan</keyname><forenames>Amin</forenames></author><author><keyname>Pachon-Pinzon</keyname><forenames>Angelica Y.</forenames></author></authors><title>The decimation process in random k-SAT</title><categories>math.CO cs.DM math.PR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let F be a uniformly distributed random k-SAT formula with n variables and m
clauses. Non-rigorous statistical mechanics ideas have inspired a message
passing algorithm called Belief Propagation Guided Decimation for finding
satisfying assignments of F. This algorithm can be viewed as an attempt at
implementing a certain thought experiment that we call the Decimation Process.
In this paper we identify a variety of phase transitions in the decimation
process and link these phase transitions to the performance of the algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3151</identifier>
 <datestamp>2015-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3151</id><created>2011-02-15</created><updated>2015-12-30</updated><authors><author><keyname>Pauly</keyname><forenames>Arno</forenames></author></authors><title>Many-one reductions and the category of multivalued functions</title><categories>cs.CC math.CT</categories><comments>an earlier version was titled &quot;Many-one reductions between search
  problems&quot;. in Mathematical Structures in Computer Science, 2015</comments><msc-class>03D30, 03D65, 68Q15, 18D99</msc-class><acm-class>F.1.3; F.1.1</acm-class><doi>10.1017/S0960129515000262</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-valued functions are common in computable analysis (built upon the Type
2 Theory of Effectivity), and have made an appearance in complexity theory
under the moniker search problems leading to complexity classes such as PPAD
and PLS being studied. However, a systematic investigation of the resulting
degree structures has only been initiated in the former situation so far (the
Weihrauch-degrees).
  A more general understanding is possible, if the category-theoretic
properties of multi-valued functions are taken into account. In the present
paper, the category-theoretic framework is established, and it is demonstrated
that many-one degrees of multi-valued functions form a distributive lattice
under very general conditions, regardless of the actual reducibility notions
used (e.g. Cook, Karp, Weihrauch).
  Beyond this, an abundance of open questions arises. Some classic results for
reductions between functions carry over to multi-valued functions, but others
do not. The basic theme here again depends on category-theoretic differences
between functions and multi-valued functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3162</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3162</id><created>2011-02-15</created><updated>2011-10-02</updated><authors><author><keyname>Langberg</keyname><forenames>Michael</forenames></author><author><keyname>Effros</keyname><forenames>Michelle</forenames></author></authors><title>Network Coding: Is zero error always possible?</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we study zero vs. epsilon-error capacity in network coding
instances. For multicast network coding it is well known that all rates that
can be delivered with arbitrarily small error probability can also be delivered
with zero error probability; that is, the epsilon-error multicast capacity
region and zero-error multicast capacity region are identical. For general
network coding instances in which all sources originate at the same source
node, Chan and Grant recently showed [ISIT 2010] that, again, epsilon-error
communication has no rate advantage over zero-error communication.
  We start by revisiting the setting of co-located sources, where we present an
alternative proof to that given by Chan and Grant. While the new proof is based
on similar core ideas, our constructive strategy complements the previous
argument.We then extend our results to the setting of index coding, which is a
special and representative form of network coding that encapsulates the &quot;source
coding with side information&quot; problem. Finally, we consider the &quot;edge removal&quot;
problem (recently studied by Jalali, Effros, and Ho in [Allerton 2010] and [ITA
2011]) that aims to quantify the loss in capacity associated with removing a
single edge from a given network. Using our proof for co-located sources, we
tie the &quot;zero vs. epsilon-error&quot; problem in general network coding instances
with the &quot;edge removal&quot; problem. Loosely speaking, we show that the two problem
are equivalent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3165</identifier>
 <datestamp>2011-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3165</id><created>2011-02-15</created><authors><author><keyname>Aleksandrov</keyname><forenames>Lyudmil</forenames></author><author><keyname>Djidjev</keyname><forenames>Hristo</forenames></author><author><keyname>Maheshwari</keyname><forenames>Anil</forenames></author><author><keyname>Sack</keyname><forenames>Joerg-Rudiger</forenames></author></authors><title>An Approximation Algorithm for Computing Shortest Paths in Weighted 3-d
  Domains</title><categories>cs.CG cs.DS cs.GR cs.RO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the first polynomial time approximation algorithm for computing
shortest paths in weighted three-dimensional domains. Given a polyhedral domain
$\D$, consisting of $n$ tetrahedra with positive weights, and a real number
$\eps\in(0,1)$, our algorithm constructs paths in $\D$ from a fixed source
vertex to all vertices of $\D$, whose costs are at most $1+\eps$ times the
costs of (weighted) shortest paths, in
$O(\C(\D)\frac{n}{\eps^{2.5}}\log\frac{n}{\eps}\log^3\frac{1}{\eps})$ time,
where $\C(\D)$ is a geometric parameter related to the aspect ratios of
tetrahedra. The efficiency of the proposed algorithm is based on an in-depth
study of the local behavior of geodesic paths and additive Voronoi diagrams in
weighted three-dimensional domains, which are of independent interest. The
paper extends the results of Aleksandrov, Maheshwari and Sack [JACM 2005] to
three dimensions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3167</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3167</id><created>2011-02-15</created><updated>2011-08-26</updated><authors><author><keyname>Trautmann</keyname><forenames>Anna-Lena</forenames></author><author><keyname>Rosenthal</keyname><forenames>Joachim</forenames></author></authors><title>A Complete Characterization of Irreducible Cyclic Orbit Codes</title><categories>cs.IT math.IT</categories><comments>in Proceedings of The Seventh International Workshop on Coding and
  Cryptography 2011 April 11-15 2011, Paris, France</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a complete list of orbit codes that are generated by an irreducible
cyclic group, i.e. an irreducible group having one generator. We derive some of
the basic properties of these codes such as the cardinality and the minimum
distance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3173</identifier>
 <datestamp>2015-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3173</id><created>2011-02-15</created><authors><author><keyname>Harrison</keyname><forenames>W. K.</forenames></author><author><keyname>Almeida</keyname><forenames>J.</forenames></author><author><keyname>McLaughlin</keyname><forenames>S. W.</forenames></author><author><keyname>Barros</keyname><forenames>J.</forenames></author></authors><title>Coding for Cryptographic Security Enhancement using Stopping Sets</title><categories>cs.CR</categories><comments>13 pages, 8 figures</comments><doi>10.1109/TIFS.2011.2145371</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we discuss the ability of channel codes to enhance
cryptographic secrecy. Toward that end, we present the secrecy metric of
degrees of freedom in an attacker's knowledge of the cryptogram, which is
similar to equivocation. Using this notion of secrecy, we show how a specific
practical channel coding system can be used to hide information about the
ciphertext, thus increasing the difficulty of cryptographic attacks. The system
setup is the wiretap channel model where transmitted data traverse through
independent packet erasure channels with public feedback for authenticated ARQ
(Automatic Repeat reQuest). The code design relies on puncturing nonsystematic
low-density parity-check codes with the intent of inflicting an eavesdropper
with stopping sets in the decoder. Furthermore, the design amplifies errors
when stopping sets occur such that a receiver must guess all the channel-erased
bits correctly to avoid an expected error rate of one half in the ciphertext.
We extend previous results on the coding scheme by giving design criteria that
reduces the effectiveness of a maximum-likelihood attack to that of a
message-passing attack. We further extend security analysis to models with
multiple receivers and collaborative attackers. Cryptographic security is
enhanced in all these cases by exploiting properties of the physical-layer. The
enhancement is accurately presented as a function of the degrees of freedom in
the eavesdropper's knowledge of the ciphertext, and is even shown to be present
when eavesdroppers have better channel quality than legitimate receivers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3174</identifier>
 <datestamp>2011-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3174</id><created>2011-02-15</created><updated>2011-02-16</updated><authors><author><keyname>Kurz</keyname><forenames>Alexander</forenames></author><author><keyname>Suzuki</keyname><forenames>Tomoyuki</forenames></author><author><keyname>Tuosto</keyname><forenames>Emilio</forenames></author></authors><title>Towards Nominal Formal Languages</title><categories>cs.FL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce formal languages over infinite alphabets where words may contain
binders. We define the notions of nominal language, nominal monoid, and nominal
regular expressions. Moreover, we extend history-dependent automata
(HD-automata) by adding stack, and study the recognisability of nominal
languages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3176</identifier>
 <datestamp>2013-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3176</id><created>2011-02-15</created><updated>2011-06-08</updated><authors><author><keyname>Frank</keyname><forenames>Mario</forenames></author><author><keyname>Buhmann</keyname><forenames>Joachim M.</forenames></author></authors><title>Selecting the rank of truncated SVD by Maximum Approximation Capacity</title><categories>cs.IT cs.LG math.IT stat.ML</categories><comments>7 pages, 5 figures; Will be presented at the IEEE International
  Symposium on Information Theory (ISIT) 2011. The conference version has only
  5 pages. This version has an extended appendix</comments><journal-ref>Information Theory Proceedings (ISIT), 2011 IEEE International
  Symposium on, 2011, pages 1036-1040</journal-ref><doi>10.1109/ISIT.2011.6033687</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Truncated Singular Value Decomposition (SVD) calculates the closest rank-$k$
approximation of a given input matrix. Selecting the appropriate rank $k$
defines a critical model order choice in most applications of SVD. To obtain a
principled cut-off criterion for the spectrum, we convert the underlying
optimization problem into a noisy channel coding problem. The optimal
approximation capacity of this channel controls the appropriate strength of
regularization to suppress noise. In simulation experiments, this information
theoretic method to determine the optimal rank competes with state-of-the art
model selection techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3181</identifier>
 <datestamp>2011-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3181</id><created>2011-02-15</created><authors><author><keyname>Hagiwara</keyname><forenames>Manabu</forenames></author><author><keyname>Kasai</keyname><forenames>Kenta</forenames></author><author><keyname>Imai</keyname><forenames>Hideki</forenames></author><author><keyname>Sakaniwa</keyname><forenames>Kohichi</forenames></author></authors><title>Spatially Coupled Quasi-Cyclic Quantum LDPC Codes</title><categories>cs.IT math.IT quant-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We face the following dilemma for designing low-density parity-check codes
(LDPC) for quantum error correction. 1) The row weights of parity-check should
be large: The minimum distances are bounded above by the minimum row weights of
parity-check matrices of constituent classical codes. Small minimum distance
tends to result in poor decoding performance at the error-floor region. 2) The
row weights of parity-check matrices should not be large: The sum-product
decoding performance at the water-fall region is degraded as the row weight
increases. Recently, Kudekar et al. showed spatially-coupled (SC) LDPC codes
exhibit capacity-achieving performance for classical channels. SC LDPC codes
have both large row weight and capacity-achieving error-floor and water-fall
performance. In this paper, we design SC LDPC-CSS (Calderbank, Shor and Steane)
codes for quantum error correction over the depolarizing channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3195</identifier>
 <datestamp>2012-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3195</id><created>2011-02-15</created><updated>2012-07-25</updated><authors><author><keyname>Abhishek</keyname><forenames>Vineet</forenames></author><author><keyname>Hajek</keyname><forenames>Bruce</forenames></author><author><keyname>Williams</keyname><forenames>Steven R.</forenames></author></authors><title>Auctions with a Profit Sharing Contract</title><categories>cs.GT</categories><comments>36 pages, 2 figure. This is a work in progress</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of selling a resource through an auction mechanism. The
winning buyer in turn develops this resource to generate profit. Two forms of
payment are considered: charging the winning buyer a one-time payment, or an
initial payment plus a profit sharing contract (PSC). We consider a symmetric
interdependent values model with risk averse or risk neutral buyers and a risk
neutral seller. For the second price auction and the English auction, we show
that the seller's expected total revenue from the auction where he also takes a
fraction of the positive profit is higher than the expected revenue from the
auction with only a one-time payment. Moreover, the seller can generate an even
higher expected total revenue if, in addition to taking a fraction of the
positive profit, he also takes the same fraction of any loss incurred from
developing the resource. Moving beyond simple PSCs, we show that the auction
with a PSC from a very general class generates higher expected total revenue
than the auction with only a one-time payment. Finally, we show that suitable
PSCs provide higher expected total revenue than a one-time payment even when
the incentives of the winning buyer to develop the resource must be addressed
by the seller.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3204</identifier>
 <datestamp>2011-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3204</id><created>2011-02-15</created><authors><author><keyname>Haeupler</keyname><forenames>Bernhard</forenames></author><author><keyname>M&#xe9;dard</keyname><forenames>Muriel</forenames></author></authors><title>One Packet Suffices - Highly Efficient Packetized Network Coding With
  Finite Memory</title><categories>cs.IT cs.DS math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Random Linear Network Coding (RLNC) has emerged as a powerful tool for robust
high-throughput multicast. Projection analysis - a recently introduced
technique - shows that the distributed packetized RLNC protocol achieves
(order) optimal and perfectly pipelined information dissemination in many
settings. In the original approach to RNLC intermediate nodes code together all
available information. This requires intermediate nodes to keep considerable
data available for coding. Moreover, it results in a coding complexity that
grows linearly with the size of this data. While this has been identified as a
problem, approaches that combine queuing theory and network coding have
heretofore not provided a succinct representation of the memory needs of
network coding at intermediates nodes.
  This paper shows the surprising result that, in all settings with a
continuous stream of data, network coding continues to perform optimally even
if only one packet per node is kept in active memory and used for computations.
This leads to an extremely simple RLNC protocol variant with drastically
reduced requirements on computational and memory resources. By extending the
projection analysis, we show that in all settings in which the RLNC protocol
was proven to be optimal its finite memory variant performs equally well. In
the same way as the original projection analysis, our technique applies in a
wide variety of network models, including highly dynamic topologies that can
change completely at any time in an adversarial fashion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3214</identifier>
 <datestamp>2011-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3214</id><created>2011-02-15</created><authors><author><keyname>Ardestanizadeh</keyname><forenames>Ehsan</forenames></author><author><keyname>Minero</keyname><forenames>Paolo</forenames></author><author><keyname>Franceschetti</keyname><forenames>Massimo</forenames></author></authors><title>LQG Control Approach to Gaussian Broadcast Channels with Feedback</title><categories>cs.IT math.IT math.OC</categories><comments>Submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A code for communication over the k-receiver additive white Gaussian noise
broadcast channel with feedback is presented and analyzed using tools from the
theory of linear quadratic Gaussian optimal control. It is shown that the
performance of this code depends on the noise correlation at the receivers and
it is related to the solution of a discrete algebraic Riccati equation. For the
case of independent noises, the sum rate achieved by the proposed code,
satisfying average power constraint P, is characterized as 1/2 log (1+P*phi),
where the coefficient &quot;phi&quot; in the interval [1,k] quantifies the power gain due
to the presence of feedback. When specialized to the case of two receivers,
this includes a previous result by Elia and strictly improves upon the code of
Ozarow and Leung. When the noises are correlated, the pre-log of the
sum-capacity of the broadcast channel with feedback can be strictly greater
than one. It is established that for all noise covariance matrices of rank r
the pre-log of the sum capacity is at most k-r+1 and, conversely, there exists
a noise covariance matrix of rank r for which the proposed code achieves this
upper bound. This generalizes a previous result by Gastpar and Wigger for the
two-receiver broadcast channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3216</identifier>
 <datestamp>2011-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3216</id><created>2011-02-15</created><authors><author><keyname>Jafarian</keyname><forenames>Amin</forenames></author><author><keyname>Vishwanath</keyname><forenames>Sriram</forenames></author></authors><title>The Two-User Gaussian Fading Broadcast Channel</title><categories>cs.IT math.IT</categories><comments>Also submitted to ISIT 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents outerbounds for the two-user Gaussian fading broadcast
channel. These outerbounds are based on Costa's entropy power inequality
(Costa-EPI) and are formulated mathematically as a feasibility problem. For
classes of the two-user Gaussian fading broadcast channel where the outerbound
is found to have a feasible solution, we find conditions under which a suitable
inner and outer bound meet. For all such cases, this paper provides a partial
characterization of the capacity region of the Gaussian two-user fading
broadcast channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3219</identifier>
 <datestamp>2011-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3219</id><created>2011-02-15</created><authors><author><keyname>Yong-Xiang</keyname><forenames>Zhao</forenames></author><author><keyname>Chang-Jia</keyname><forenames>Chen</forenames></author></authors><title>On the Capacity of p2p Multipoint Video Conference</title><categories>cs.NI cs.MM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, The structure of video conference is formulated and the
peer-assisted distribution scheme is constructed to achieve optimal video
delivery rate in each sub-conference. The capacity of conference is proposed to
referee the video rate that can be supported in every possible scenario. We
have proved that, in case of one user watching only one video, 5/6 is a lower
bound of the capacity which is much larger than 1/2, the achievable rate of
chained approach in [2]. Almost all proofs in this paper are constructive. They
can be applied into real implementation directly with a few modifications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3220</identifier>
 <datestamp>2011-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3220</id><created>2011-02-15</created><authors><author><keyname>Kabashima</keyname><forenames>Yoshiyuki</forenames></author><author><keyname>Wadayama</keyname><forenames>Tadashi</forenames></author></authors><title>A signal recovery algorithm for sparse matrix based compressed sensing</title><categories>cs.IT cond-mat.dis-nn math.IT</categories><comments>Submitted to ISIT2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We have developed an approximate signal recovery algorithm with low
computational cost for compressed sensing on the basis of randomly constructed
sparse measurement matrices. The law of large numbers and the central limit
theorem suggest that the developed algorithm saturates the Donoho-Tanner weak
threshold for the perfect recovery when the matrix becomes as dense as the
signal size $N$ and the number of measurements $M$ tends to infinity keep
$\alpha=M/N \sim O(1)$, which is supported by extensive numerical experiments.
Even when the numbers of non-zero entries per column/row in the measurement
matrices are limited to $O(1)$, numerical experiments indicate that the
algorithm can still typically recover the original signal perfectly with an
$O(N)$ computational cost per update as well if the density $\rho$ of non-zero
entries of the signal is lower than a certain critical value $\rho_{\rm
th}(\alpha)$ as $N,M \to \infty$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3225</identifier>
 <datestamp>2011-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3225</id><created>2011-02-15</created><authors><author><keyname>Rini</keyname><forenames>Stefano</forenames></author><author><keyname>Tuninetti</keyname><forenames>Daniela</forenames></author><author><keyname>Devroye</keyname><forenames>Natasha</forenames></author></authors><title>Capacity to within 3 bits for a class of Gaussian Interference Channels
  with a Cognitive Relay</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The InterFerence Channel with a Cognitive Relay (IFC-CR) consists of a
classical two-user interference channel in which the two independent messages
are also non-causally known at a cognitive relay node. In this work a special
class of IFC-CRs in which the sources do not create interference at the
non-intended destinations is analyzed. This special model results in a channel
with two non-interfering point-to-point channels whose transmission is aided by
an in-band cognitive relay, which is thus referred to as the Parallel Channel
with a Cognitive Relay (PC-CR). We determine the capacity of the PC-CR channel
to within 3 bits/s/Hz for all channel parameters. In particular, we present
several new outer bounds which we achieve to within a constant gap by proper
selection of Gaussian input distributions in a simple rate-splitting and
superposition coding-based inner bound. The inner and outer bounds are
numerically evaluated to show that the actual gap can be far less than 3
bits/s/Hz.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3226</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3226</id><created>2011-02-15</created><authors><author><keyname>Rini</keyname><forenames>Stefano</forenames></author><author><keyname>Tuninetti</keyname><forenames>Daniela</forenames></author><author><keyname>Devroye</keyname><forenames>Natasha</forenames></author></authors><title>A New Capacity Result for the Z-Gaussian Cognitive Interference Channel</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work proposes a novel outer bound for the Gaussian cognitive
interference channel in strong interference at the primary receiver based on
the capacity of a multi-antenna broadcast channel with degraded message set. It
then shows that for the Z-channel, i.e., when the secondary receiver
experiences no interference and the primary receiver experiences strong
interference, the proposed outer bound not only is the tightest among known
bounds but is actually achievable for sufficiently strong interference. The
latter is a novel capacity result that from numerical evaluations appears to be
generalizable to a larger (i.e., non-Z) class of Gaussian channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3227</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3227</id><created>2011-02-15</created><authors><author><keyname>Riniy</keyname><forenames>Stefano</forenames></author><author><keyname>Tuninetti</keyname><forenames>Daniela</forenames></author><author><keyname>Devroye</keyname><forenames>Natasha</forenames></author><author><keyname>Goldsmith</keyname><forenames>Andrea</forenames></author></authors><title>The Capacity of the Interference Channel with a Cognitive Relay in Very
  Strong Interference</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The interference channel with a cognitive relay consists of a classical
interference channel with two sourcedestination pairs and with an additional
cognitive relay that has a priori knowledge of the sources' messages and aids
in the sources' transmission. We derive a new outer bound for this channel
using an argument originally devised for the &quot;more capable&quot; broadcast channel,
and show the achievability of the proposed outer bound in the &quot;very strong
interference&quot; regime, a class of channels where there is no loss in optimality
if both destinations decode both messages. This result is analogous to the
&quot;very strong interference&quot; capacity result for the classical interference
channel and for the cognitive interference channel, and is the first capacity
known capacity result for the general interference channel with a cognitive
relay.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3232</identifier>
 <datestamp>2011-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3232</id><created>2011-02-15</created><updated>2011-04-24</updated><authors><author><keyname>Zhang</keyname><forenames>Lianming</forenames></author><author><keyname>Yu</keyname><forenames>Jianping</forenames></author><author><keyname>Deng</keyname><forenames>Xiaoheng</forenames></author></authors><title>Modelling on the Guaranteed QoS for Wireless Sensor Networks: A Network
  Calculus Approach</title><categories>cs.NI cs.PF</categories><comments>14 pages, 10 figures</comments><journal-ref>EURASIP Journal on Wireless Communications and Networking 2011,
  2011:82</journal-ref><doi>10.1186/1687-1499-2011-82</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless sensor networks (WSNs) became one of the high technology domains
during the last ten years. Real-time applications for them make it necessary to
provide the guaranteed Quality of Service (QoS). The main contributions of this
paper are a system skeleton and a guaranteed QoS model that are suitable for
the WSNs. To do it, we develop a sensor node model based on virtual buffer
sharing and present a two-layer scheduling model using the network calculus.
With the system skeleton, we develop a guaranteed QoS model, such as the upper
bounds on buffer queue length/delay/effective bandwidth, and single-hop/
multi-hops delay/jitter/effective bandwidth. Numerical results show the system
skeleton and the guaranteed QoS model are scalable for different types of
flows, including the self-similar traffic flows, and the parameters of flow
regulators and service curves of sensor nodes affect them. Our proposal leads
to buffer dimensioning, guaranteed QoS support and control in the WSNs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3235</identifier>
 <datestamp>2011-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3235</id><created>2011-02-15</created><authors><author><keyname>Tuninetti</keyname><forenames>Daniela</forenames></author></authors><title>K-user Interference Channels: General Outer Bound and Sum-capacity for
  Certain Gaussian Channels</title><categories>cs.IT math.IT</categories><comments>Submitted to the 2011 IEEE International Symposium on Information
  Theory (ISIT 2011)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper derives an outer bound on the capacity region of a general
memoryless interference channel with an arbitrary number of users. The
derivation follows from a generalization of the techniques developed by Kramer
and by Etkin et al for the Gaussian two-user channel. The derived bound is the
first known outer bound valid for any memoryless channel. In Gaussian noise,
classes of channels for which the proposed bound gives the sum-rate capacity
are identified, including degraded channels and a class of Z-channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3241</identifier>
 <datestamp>2011-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3241</id><created>2011-02-16</created><authors><author><keyname>Takahashi</keyname><forenames>Hayato</forenames></author></authors><title>Some limits to nonparametric estimation for ergodic processes</title><categories>cs.IT math.IT</categories><comments>submitted to ISIT2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new negative result for nonparametric distribution estimation of binary
ergodic processes is shown. The problem of estimation of distribution with any
degree of accuracy is studied. Then it is shown that for any countable class of
estimators there is a zero-entropy binary ergodic process that is inconsistent
with the class of estimators. Our result is different from other negative
results for universal forecasting scheme of ergodic processes. We also
introduce a related result by B. Weiss.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3242</identifier>
 <datestamp>2011-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3242</id><created>2011-02-16</created><authors><author><keyname>Takahashi</keyname><forenames>Hayato</forenames></author></authors><title>Weak randomness and Kamae's theorem on normal numbers</title><categories>cs.IT math.IT</categories><comments>submitted to ISIT2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A function from sequences to their subsequences is called selection function.
A selection function is called admissible (with respect to normal numbers) if
for all normal numbers, their subsequences obtained by the selection function
are normal numbers.
  In Kamae (1973) selection functions that are not depend on sequences (depend
only on coordinates) are studied, and their necessary and sufficient condition
for admissibility is given. In this paper we introduce a notion of weak
randomness and study an algorithmic analogy to the Kamae's theorem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3243</identifier>
 <datestamp>2011-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3243</id><created>2011-02-16</created><authors><author><keyname>Sahebi</keyname><forenames>Aria Ghasemian</forenames></author><author><keyname>Pradhan</keyname><forenames>S. Sandeep</forenames></author></authors><title>On the Capacity of Abelian Group Codes Over Discrete Memoryless Channels</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For most discrete memoryless channels, there does not exist a linear code for
the channel which uses all of the channel's input symbols. Therefore, linearity
of the code for such channels is a very restrictive condition and there should
be a loosening of the algebraic structure of the code to a degree that the code
can admit any channel input alphabet. For any channel input alphabet size,
there always exists an Abelian group structure defined on the alphabet. We
investigate the capacity of Abelian group codes over discrete memoryless
channels and provide lower and upper bounds on the capacity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3245</identifier>
 <datestamp>2011-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3245</id><created>2011-02-16</created><updated>2011-10-05</updated><authors><author><keyname>Roy</keyname><forenames>Swapnoneel</forenames></author></authors><title>On Sorting by Bounded Block Interchanges</title><categories>cs.CC cs.DS</categories><comments>This paper has been withdrawn by the author due to a bug in the
  reduction. Would be available again after it is fixed</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we consider a restricted case of the well studied Sorting by
Block Interchanges problem. We put an upper bound k on the length of the blocks
(substrings) to be interchanged at each step. We call the problem Sorting by
k-Block Interchanges. We show the problem to be NP-Hard for k=1. The problem is
easy for k=n-1, where n is the length of the permutation (the unbounded case).
Sorting by Block Interchanges is a very important and widely studied problem
with applications in comparative genomics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3260</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3260</id><created>2011-02-16</created><authors><author><keyname>Cocco</keyname><forenames>Simona</forenames><affiliation>LPS</affiliation></author><author><keyname>Monasson</keyname><forenames>R&#xe9;mi</forenames><affiliation>LPTENS</affiliation></author></authors><title>Adaptive Cluster Expansion for Inferring Boltzmann Machines with Noisy
  Data</title><categories>physics.data-an cond-mat.stat-mech cs.LG q-bio.NC q-bio.QM</categories><comments>Accepted for publication in Physical Review Letters (2011)</comments><proxy>ccsd</proxy><doi>10.1103/PhysRevLett.106.090601</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a procedure to infer the interactions among a set of binary
variables, based on their sampled frequencies and pairwise correlations. The
algorithm builds the clusters of variables contributing most to the entropy of
the inferred Ising model, and rejects the small contributions due to the
sampling noise. Our procedure successfully recovers benchmark Ising models even
at criticality and in the low temperature phase, and is applied to
neurobiological data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3268</identifier>
 <datestamp>2011-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3268</id><created>2011-02-16</created><authors><author><keyname>Haak</keyname><forenames>Bernhard Hermann</forenames><affiliation>IMB</affiliation></author><author><keyname>Ouhabaz</keyname><forenames>El-Maati</forenames><affiliation>IMB</affiliation></author></authors><title>Exact observability, square functions and spectral theory</title><categories>math.FA cs.SY math.OC</categories><comments>17 pages</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the first part of this article we introduce the notion of a
backward-forward conditioning (BFC) system that generalises the notion of
zero-class admissibiliy introduced in [Xu,Liu,Yung]. We can show that unless
the spectum contains a halfplane, the BFC property occurs only in siutations
where the underlying semigroup extends to a group. In a second part we present
a sufficient condition for exact observability in Banach spaces that is
designed for infinite-dimensional output spaces and general strongly continuous
semigroups. To obtain this we make use of certain weighted square function
estimates. Specialising to the Hilbert space situation we obtain a result for
contraction semigroups without an analyticity condition on the semigroup.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3270</identifier>
 <datestamp>2012-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3270</id><created>2011-02-16</created><updated>2012-11-21</updated><authors><author><keyname>Diana</keyname><forenames>R&#xe9;mi</forenames></author><author><keyname>Lochin</keyname><forenames>Emmanuel</forenames></author></authors><title>Analytical Model of TCP Relentless Congestion Control</title><categories>cs.NI</categories><comments>Extended version of the one presented at 6th International Workshop
  on Verification and Evaluation of Computer and Communication Systems (Vecos
  2012)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a model of the Relentless Congestion Control proposed by Matt
Mathis. Relentless Congestion Control (RCC) is a modification of the AIMD
(Additive Increase Multiplicative Decrease) congestion control which consists
in decreasing the TCP congestion window by the number of lost segments instead
of halving it. Despite some on-going discussions at the ICCRG IRTF-group, this
congestion control has, to the best of our knowledge, never been modeled. In
this paper, we provide an analytical model of this novel congestion control and
propose an implementation of RCC for the commonly-used network simulator ns-2.
We also improve RCC with the addition of a loss retransmission detection scheme
(based on SACK+) to prevent RTO caused by a loss of a retransmission and called
this new version RCC+. The proposed models describe both the original RCC
algorithm and RCC+ improvement and would allow to better assess the impact of
this new congestion control scheme over the network traffic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3272</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3272</id><created>2011-02-16</created><authors><author><keyname>Dyachuk</keyname><forenames>Dmytro</forenames></author><author><keyname>Mazzucco</keyname><forenames>Michele</forenames></author></authors><title>On Allocation Policies for Power and Performance</title><categories>cs.DC cs.PF</categories><comments>8 pages, 11 figures, 2010 11th IEEE/ACM International Conference on
  Grid Computing (GRID), pp 313 - 320 (E2GC2-2010 workshop)</comments><journal-ref>2010 11th IEEE/ACM International Conference on Grid Computing
  (GRID), pp 313 - 320</journal-ref><doi>10.1109/GRID.2010.5697986</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  With the increasing popularity of Internet-based services and applications,
power efficiency is becoming a major concern for data center operators, as high
electricity consumption not only increases greenhouse gas emissions, but also
increases the cost of running the server farm itself. In this paper we address
the problem of maximizing the revenue of a service provider by means of dynamic
allocation policies that run the minimum amount of servers necessary to meet
user's requirements in terms of performance. The results of several experiments
executed using Wikipedia traces are described, showing that the proposed
schemes work well, even if the workload is non-stationary. Since any resource
allocation policy requires the use of forecasting mechanisms, various schemes
allowing compensating errors in the load forecasts are presented and evaluated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3285</identifier>
 <datestamp>2011-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3285</id><created>2011-02-16</created><updated>2011-04-26</updated><authors><author><keyname>Clemente</keyname><forenames>Lorenzo</forenames></author></authors><title>B\&quot;uchi Automata can have Smaller Quotients</title><categories>cs.FL</categories><comments>technical report of a ICALP 2011 paper</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We study novel simulation-like preorders for quotienting nondeterministic
B\&quot;uchi automata. We define fixed-word delayed simulation, a new preorder
coarser than delayed simulation. We argue that fixed-word simulation is the
coarsest forward simulation-like preorder which can be used for quotienting
B\&quot;uchi automata, thus improving our understanding of the limits of
quotienting. Also, we show that computing fixed-word simulation is
PSPACE-complete. On the practical side, we introduce proxy simulations, which
are novel polynomial-time computable preorders sound for quotienting. In
particular, delayed proxy simulation induce quotients that can be smaller by an
arbitrarily large factor than direct backward simulation. We derive proxy
simulations as the product of a theory of refinement transformers: A refinement
transformer maps preorders non-decreasingly, preserving certain properties. We
study under which general conditions refinement transformers are sound for
quotienting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3288</identifier>
 <datestamp>2011-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3288</id><created>2011-02-16</created><updated>2011-05-31</updated><authors><author><keyname>Kim</keyname><forenames>Jong Min</forenames></author><author><keyname>Lee</keyname><forenames>Ok Kyun</forenames></author><author><keyname>Ye</keyname><forenames>Jong Chul</forenames></author></authors><title>Compressive MUSIC with optimized partial support for joint sparse
  recovery</title><categories>cs.IT math.IT</categories><comments>9 pages, 2 figures</comments><msc-class>94A20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multiple measurement vector (MMV) problem addresses the identification of
unknown input vectors that share common sparse support. The MMV problems had
been traditionally addressed either by sensor array signal processing or
compressive sensing. However, recent breakthrough in this area such as
compressive MUSIC (CS-MUSIC) or subspace-augumented MUSIC (SA-MUSIC) optimally
combines the compressive sensing (CS) and array signal processing such that
$k-r$ supports are first found by CS and the remaining $r$ supports are
determined by generalized MUSIC criterion, where $k$ and $r$ denote the
sparsity and the independent snapshots, respectively. Even though such hybrid
approach significantly outperforms the conventional algorithms, its performance
heavily depends on the correct identification of $k-r$ partial support by
compressive sensing step, which often deteriorate the overall performance. The
main contribution of this paper is, therefore, to show that as long as $k-r+1$
correct supports are included in any $k$-sparse CS solution, the optimal $k-r$
partial support can be found using a subspace fitting criterion, significantly
improving the overall performance of CS-MUSIC. Furthermore, unlike the single
measurement CS counterpart that requires infinite SNR for a perfect support
recovery, we can derive an information theoretic sufficient condition for the
perfect recovery using CS-MUSIC under a {\em finite} SNR scenario.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3289</identifier>
 <datestamp>2011-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3289</id><created>2011-02-16</created><authors><author><keyname>Kim</keyname><forenames>Jongmin</forenames></author><author><keyname>Chang</keyname><forenames>Woohyuk</forenames></author><author><keyname>Jung</keyname><forenames>Bangchul</forenames></author><author><keyname>Baron</keyname><forenames>Dror</forenames></author><author><keyname>Ye</keyname><forenames>Jong Chul</forenames></author></authors><title>Belief propagation for joint sparse recovery</title><categories>cs.IT math.IT</categories><comments>8 pages, 2 figures</comments><msc-class>94A20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compressed sensing (CS) demonstrates that sparse signals can be recovered
from underdetermined linear measurements. We focus on the joint sparse recovery
problem where multiple signals share the same common sparse support sets, and
they are measured through the same sensing matrix. Leveraging a recent
information theoretic characterization of single signal CS, we formulate the
optimal minimum mean square error (MMSE) estimation problem, and derive a
belief propagation algorithm, its relaxed version, for the joint sparse
recovery problem and an approximate message passing algorithm. In addition,
using density evolution, we provide a sufficient condition for exact recovery.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3294</identifier>
 <datestamp>2011-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3294</id><created>2011-02-16</created><authors><author><keyname>Charalambous</keyname><forenames>Charalambos D.</forenames></author><author><keyname>Stavrou</keyname><forenames>Photios A.</forenames></author><author><keyname>Kourtellaris</keyname><forenames>Christos K.</forenames></author></authors><title>Causal Rate Distortion Function on Abstract Alphabets and Optimal
  Reconstruction Kernel</title><categories>cs.IT math.IT</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  A Causal rate distortion function with a general fidelity criterion is
formulated on abstract alphabets and the optimal reconstruction kernel is
derived, which consists of a product of causal kernels. In the process, general
abstract spaces are introduced to show existence of the minimizing kernel using
weak*-convergence. Certain properties of the causal rate distortion function
are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3295</identifier>
 <datestamp>2011-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3295</id><created>2011-02-16</created><updated>2011-02-16</updated><authors><author><keyname>Qingxin</keyname><forenames>Meng</forenames></author></authors><title>General Linear Quadratic Optimal Stochastic Control Problem Driven by a
  Brownian Motion and a Poisson Random Martingale Measure with Random
  Coefficients</title><categories>math.OC cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The main purpose of this paper is to discuss detailed the stochastic LQ
control problem with random coefficients where the linear system is a
multidimensional stochastic differential equation driven by a multidimensional
Brownian motion and a Poisson random martingale measure. In the paper, we will
establish the connections of the multidimensional Backward stochastic Riccati
equation with jumps (BSRDEJ in short form) to the stochastic LQ problem and to
the associated Hamilton systems. By the connections, we show the optimal
control have the state feedback representation. Moreover, we will show the
existence and uniqueness result of the multidimensional BSRDEJ for the case
where the generator is bounded linear dependence with respect to the unknowns
martingale term.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3298</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3298</id><created>2011-02-16</created><authors><author><keyname>Luzzi</keyname><forenames>Laura</forenames></author><author><keyname>Oggier</keyname><forenames>Fr&#xe9;d&#xe9;rique</forenames></author></authors><title>A family of fast-decodable MIDO codes from crossed-product algebras over
  Q</title><categories>cs.IT math.IT math.RA</categories><comments>5 pages, 1 figure, conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multiple Input Double Output (MIDO) asymmetric space-time codes for 4
transmit antennas and 2 receive antennas can be employed in the downlink from
base stations to portable devices. Previous MIDO code constructions with low
Maximum Likelihood (ML) decoding complexity, full diversity and the
non-vanishing determinant (NVD) property are mostly based on cyclic division
algebras. In this paper, a new family of MIDO codes with the NVD property based
on crossed-product algebras over Q is introduced. Fast decodability follows
naturally from the structure of the codewords which consist of four generalized
Alamouti blocks. The associated ML complexity order is the lowest known for
full-rate MIDO codes (O(M^{10}) instead of O(M^{16}) with respect to the real
constellation size M). Numerical simulations show that these codes have a
performance from comparable up to 1dB gain compared to the best known MIDO code
with the same complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3306</identifier>
 <datestamp>2011-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3306</id><created>2011-02-16</created><authors><author><keyname>Jung</keyname><forenames>Christian</forenames></author><author><keyname>Karch</keyname><forenames>Daniel</forenames></author><author><keyname>Knopp</keyname><forenames>Sebastian</forenames></author><author><keyname>Luxen</keyname><forenames>Dennis</forenames></author><author><keyname>Sanders</keyname><forenames>Peter</forenames></author></authors><title>Efficient Error-Correcting Geocoding</title><categories>cs.IR cs.DS</categories><acm-class>H.3.3; E.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of resolving a perhaps misspelled address of a location
into geographic coordinates of latitude and longitude. Our data structure
solves this problem within a few milliseconds even for misspelled and
fragmentary queries. Compared to major geographic search engines such as Google
or Bing we achieve results of significantly better quality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3310</identifier>
 <datestamp>2011-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3310</id><created>2011-02-16</created><updated>2011-07-21</updated><authors><author><keyname>Machta</keyname><forenames>Jon</forenames></author><author><keyname>DeDeo</keyname><forenames>Simon</forenames></author><author><keyname>Mertens</keyname><forenames>Stephan</forenames></author><author><keyname>Moore</keyname><forenames>Cristopher</forenames></author></authors><title>Parallel Complexity of Random Boolean Circuits</title><categories>cond-mat.dis-nn cond-mat.stat-mech cs.CC nlin.CD</categories><comments>16 pages, 10 figures, matches published version</comments><report-no>SFI Working Paper #11-06-020</report-no><journal-ref>J. Stat. Mech. (2011) P04015</journal-ref><doi>10.1088/1742-5468/2011/04/P04015</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Random instances of feedforward Boolean circuits are studied both
analytically and numerically. Evaluating these circuits is known to be a
P-complete problem and thus, in the worst case, believed to be impossible to
perform, even given a massively parallel computer, in time much less than the
depth of the circuit. Nonetheless, it is found that for some ensembles of
random circuits, saturation to a fixed truth value occurs rapidly so that
evaluation of the circuit can be accomplished in much less parallel time than
the depth of the circuit. For other ensembles saturation does not occur and
circuit evaluation is apparently hard. In particular, for some random circuits
composed of connectives with five or more inputs, the number of true outputs at
each level is a chaotic sequence. Finally, while the average case complexity
depends on the choice of ensemble, it is shown that for all ensembles it is
possible to simultaneously construct a typical circuit together with its
solution in polylogarithmic parallel time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3325</identifier>
 <datestamp>2011-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3325</id><created>2011-02-16</created><authors><author><keyname>Mirza-Babaei</keyname><forenames>Pejman</forenames></author></authors><title>Using physiological measures in conjunction with other UX approaches for
  better understanding of the player's gameplay experiences</title><categories>cs.HC</categories><comments>15 Pages. This paper has been presented at Games Research Methods
  Seminar,8-9 April 2010,University of Tampere, Finland</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The goal of video games is to challenge and entertain the players. Successful
video games deliver experience that impact players on a level of arousal.
Therefore undertaking a user experience (UX) study is crucial to ensure that a
game achieves both critical and financial success. However, traditional
usability methods (observation, subjective reporting, questionnaire, and
interview) have a number of limitations on game user research. In this study we
capture player's physiological measures during a gameplay session, to indicate
micro-events that have caused changes in their body signals. At the
post-gameplay interviews we ask participants to comment and describe their
feelings on the selected events. The aim of this study is not to over-interpret
physiological measures, but on using blips in measures to help identify key
points in a game, which we then use to investigate further with the
participant. This approach provides a method that can identify not only the
negative user experience and usability issues but also the events which have a
positive impact on player's experience.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3328</identifier>
 <datestamp>2011-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3328</id><created>2011-02-16</created><authors><author><keyname>Dong</keyname><forenames>Xuan</forenames><affiliation>Gene</affiliation></author><author><keyname>Jiangtao</keyname><affiliation>Gene</affiliation></author><author><keyname>Wen</keyname><affiliation>Amy</affiliation></author><author><keyname>Li</keyname><forenames>Weixin</forenames><affiliation>Amy</affiliation></author><author><keyname>Yi</keyname><affiliation>Amy</affiliation></author><author><keyname>Pang</keyname></author><author><keyname>Wang</keyname><forenames>Guan</forenames></author><author><keyname>Lu</keyname><forenames>Yao</forenames></author><author><keyname>Meng</keyname><forenames>Wei</forenames></author></authors><title>An Efficient and Integrated Algorithm for Video Enhancement in
  Challenging Lighting Conditions</title><categories>cs.GR cs.CV</categories><comments>10 pages, 23 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a novel integrated algorithm for real-time enhancement of video
acquired under challenging lighting conditions. Such conditions include low
lighting, haze, and high dynamic range situations. The algorithm automatically
detects the dominate source of impairment, then depending on whether it is low
lighting, haze or others, a corresponding pre-processing is applied to the
input video, followed by the core enhancement algorithm. Temporal and spatial
redundancies in the video input are utilized to facilitate real-time processing
and to improve temporal and spatial consistency of the output. The proposed
algorithm can be used as an independent module, or be integrated in either a
video encoder or a video decoder for further optimizations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3340</identifier>
 <datestamp>2011-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3340</id><created>2011-02-12</created><authors><author><keyname>Gajewar</keyname><forenames>Amita</forenames></author><author><keyname>Sarma</keyname><forenames>Atish Das</forenames></author></authors><title>Multi-skill Collaborative Teams based on Densest Subgraphs</title><categories>cs.SI cs.DS physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of identifying a team of skilled individuals for
collaboration, in the presence of a social network. Each node in the social
network may be an expert in one or more skills. Edge weights specify affinity
or collaborative compatibility between respective nodes. Given a project that
requires a set of specified number of skilled individuals in each area of
expertise, the goal is to identify a team that maximizes the collaborative
compatibility. For example, the requirement may be to form a team that has at
least three databases experts and at least two theory experts. We explore team
formation where the collaborative compatibility objective is measured as the
density of the induced subgraph on selected nodes. The problem of maximizing
density is NP-hard even when the team requires individuals of only one skill.
We present a 3-approximation algorithm that improves upon a naive extension of
the previously known algorithm for densest at least $k$ subgraph problem. We
further show how the same approximation can be extended to a special case of
multiple skills. Our problem generalizes the formulation studied by Lappas et
al. [KDD '09] who measure team compatibility in terms of diameter or spanning
tree costs. Experiments are performed on a crawl of the DBLP graph where
individuals can be skilled in at most four areas - theory, databases, data
mining, and artificial intelligence. In addition to our main algorithm, we also
present heuristic extensions to trade off between the size of the solution and
its induced density. These density-based algorithms outperform the
diameter-based objective on several metrics for assessing the collaborative
compatibility of teams. The solutions suggested are also intuitively meaningful
and scale well with the increase in the number of skilled individuals required.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3341</identifier>
 <datestamp>2011-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3341</id><created>2011-02-16</created><authors><author><keyname>Troquard</keyname><forenames>Nicolas</forenames></author><author><keyname>van der Hoek</keyname><forenames>Wiebe</forenames></author><author><keyname>Wooldridge</keyname><forenames>Michael</forenames></author></authors><title>Reasoning about Social Choice Functions</title><categories>cs.MA</categories><doi>10.1007/s10992-011-9189-z</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a logic specifically designed to support reasoning about social
choice functions. The logic includes operators to capture strategic ability,
and operators to capture agent preferences. We establish a correspondence
between formulae in the logic and properties of social choice functions, and
show that the logic is expressively complete with respect to social choice
functions, i.e., that every social choice function can be characterised as a
formula of the logic. We prove that the logic is decidable, and give a complete
axiomatization. To demonstrate the value of the logic, we show in particular
how it can be applied to the problem of determining whether a social choice
function is strategy-proof.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3350</identifier>
 <datestamp>2014-06-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3350</id><created>2011-02-16</created><updated>2011-07-27</updated><authors><author><keyname>Manganiello</keyname><forenames>Felice</forenames></author><author><keyname>Trautmann</keyname><forenames>Anna-Lena</forenames></author><author><keyname>Rosenthal</keyname><forenames>Joachim</forenames></author></authors><title>On conjugacy classes of subgroups of the general linear group and cyclic
  orbit codes</title><categories>cs.IT math.IT</categories><comments>5 pages; Submitted to IEEE International Symposium on Information
  Theory (ISIT) 2011</comments><doi>10.1109/ISIT.2011.6033885</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Orbit codes are a family of codes employable for communications on a random
linear network coding channel. The paper focuses on the classification of these
codes. We start by classifying the conjugacy classes of cyclic subgroups of the
general linear group. As a result, we are able to focus the study of cyclic
orbit codes to a restricted family of them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3389</identifier>
 <datestamp>2011-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3389</id><created>2011-02-16</created><authors><author><keyname>Bendich</keyname><forenames>Paul</forenames></author><author><keyname>Edelsbrunner</keyname><forenames>Herbert</forenames></author><author><keyname>Morozov</keyname><forenames>Dmitriy</forenames></author><author><keyname>Patel</keyname><forenames>Amit</forenames></author></authors><title>Homology and Robustness of Level and Interlevel Sets</title><categories>cs.CG math.AT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a function $f: \Xspace \to \Rspace$ on a topological space, we consider
the preimages of intervals and their homology groups and show how to read the
ranks of these groups from the extended persistence diagram of $f$. In
addition, we quantify the robustness of the homology classes under
perturbations of $f$ using well groups, and we show how to read the ranks of
these groups from the same extended persistence diagram. The special case
$\Xspace = \Rspace^3$ has ramifications in the fields of medical imaging and
scientific visualization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3390</identifier>
 <datestamp>2011-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3390</id><created>2011-02-16</created><authors><author><keyname>Punekar</keyname><forenames>Mayur</forenames></author><author><keyname>Flanagan</keyname><forenames>Mark F.</forenames></author></authors><title>Trellis-Based Check Node Processing for Low-Complexity Nonbinary LP
  Decoding</title><categories>cs.IT math.IT</categories><comments>Submitted to 2011 IEEE International Symposium on Information Theory
  (ISIT 2011)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Linear Programming (LP) decoding is emerging as an attractive alternative to
decode Low-Density Parity-Check (LDPC) codes. However, the earliest LP decoders
proposed for binary and nonbinary LDPC codes are not suitable for use at
moderate and large code lengths. To overcome this problem, Vontobel et al.
developed an iterative Low-Complexity LP (LCLP) decoding algorithm for binary
LDPC codes. The variable and check node calculations of binary LCLP decoding
algorithm are related to those of binary Belief Propagation (BP). The present
authors generalized this work to derive an iterative LCLP decoding algorithm
for nonbinary linear codes. Contrary to binary LCLP, the variable and check
node calculations of this algorithm are in general different from that of
nonbinary BP. The overall complexity of nonbinary LCLP decoding is linear in
block length; however the complexity of its check node calculations is
exponential in the check node degree. In this paper, we propose a modified BCJR
algorithm for efficient check node processing in the nonbinary LCLP decoding
algorithm. The proposed algorithm has complexity linear in the check node
degree. We also introduce an alternative state metric to improve the run time
of the proposed algorithm. Simulation results are presented for $(504, 252)$
and $(1008, 504)$ nonbinary LDPC codes over $\mathbb{Z}_4$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3392</identifier>
 <datestamp>2011-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3392</id><created>2011-02-16</created><authors><author><keyname>Lee</keyname><forenames>Junghoon</forenames></author><author><keyname>Tepedelenlioglu</keyname><forenames>Cihan</forenames></author></authors><title>Space-Time Coding over Fading Channels with Stable Noise</title><categories>cs.IT math.IT</categories><comments>22 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the performance of space-time coding over fading
channels with impulsive noise which is known to accurately capture network
interference. We use the symmetric alpha stable noise distribution and adopt
two models which assume dependent and independent noise components across
receive antennas. We derive pairwise error probability (PEP) of orthogonal
space-time block codes (STBC) with a benchmark genie-aided receiver (GAR), or
the minimum distance receiver (MDR) which is optimal in the Gaussian case. For
general space-time codes we propose a maximum-likelihood (ML) receiver, and its
approximation at high signal-to-noise ratio (SNR). The resulting asymptotically
optimal receiver (AOR) does not depend on noise parameters and is
computationally simple. Monte-Carlo simulations are used to supplement our
analytical results and compare the performance of the receivers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3393</identifier>
 <datestamp>2011-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3393</id><created>2011-02-16</created><authors><author><keyname>Chrobak</keyname><forenames>Marek</forenames></author><author><keyname>Je&#x17c;</keyname><forenames>&#x141;ukasz</forenames></author><author><keyname>Sgall</keyname><forenames>Ji&#x159;&#xed;</forenames></author></authors><title>Better Bounds for Incremental Frequency Allocation in Bipartite Graphs</title><categories>cs.DS</categories><comments>12 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study frequency allocation in wireless networks. A wireless network is
modeled by an undirected graph, with vertices corresponding to cells. In each
vertex we have a certain number of requests, and each of those requests must be
assigned a different frequency. Edges represent conflicts between cells,
meaning that frequencies in adjacent vertices must be different as well. The
objective is to minimize the total number of used frequencies.
  The offline version of the problem is known to be NP-hard. In the incremental
version, requests for frequencies arrive over time and the algorithm is
required to assign a frequency to a request as soon as it arrives. Competitive
incremental algorithms have been studied for several classes of graphs. For
paths, the optimal (asymptotic) ratio is known to be 4/3, while for
hexagonal-cell graphs it is between 1.5 and 1.9126. For k-colorable graphs, the
ratio of (k+1)/2 can be achieved.
  In this paper, we prove nearly tight bounds on the asymptotic competitive
ratio for bipartite graphs, showing that it is between 1.428 and 1.433. This
improves the previous lower bound of 4/3 and upper bound of 1.5. Our proofs are
based on reducing the incremental problem to a purely combinatorial
(equivalent) problem of constructing set families with certain intersection
properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3396</identifier>
 <datestamp>2011-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3396</id><created>2011-02-16</created><authors><author><keyname>Liao</keyname><forenames>Chenda</forenames></author><author><keyname>Chenji</keyname><forenames>Harshavardhan</forenames></author><author><keyname>Barooah</keyname><forenames>Prabir</forenames></author><author><keyname>Stoleru</keyname><forenames>Radu</forenames></author><author><keyname>Kalm&#xe1;r-Nagy</keyname><forenames>Tam&#xe1;s</forenames></author></authors><title>Detecting Separation in Robotic and Sensor Networks</title><categories>cs.RO cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider the problem of monitoring detecting separation of
agents from a base station in robotic and sensor networks. Such separation can
be caused by mobility and/or failure of the agents. While separation/cut
detection may be performed by passing messages between a node and the base in
static networks, such a solution is impractical for networks with high
mobility, since routes are constantly changing. We propose a distributed
algorithm to detect separation from the base station. The algorithm consists of
an averaging scheme in which every node updates a scalar state by communicating
with its current neighbors. We prove that if a node is permanently disconnected
from the base station, its state converges to $0$. If a node is connected to
the base station in an average sense, even if not connected in any instant,
then we show that the expected value of its state converges to a positive
number. Therefore, a node can detect if it has been separated from the base
station by monitoring its state. The effectiveness of the proposed algorithm is
demonstrated through simulations, a real system implementation and experiments
involving both static as well as mobile networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3410</identifier>
 <datestamp>2013-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3410</id><created>2011-02-16</created><updated>2011-05-17</updated><authors><author><keyname>Farsani</keyname><forenames>Reza K.</forenames></author><author><keyname>Marvasti</keyname><forenames>Farokh</forenames></author></authors><title>Capacity Bounds for Multiuser Channels with Non-Causal Channel State
  Information at the Transmitters</title><categories>cs.IT math.IT</categories><comments>12 pages, It is also shown that our derived achievable rate region
  for the two-user BC with CSI strictly contains those of [11, Sec. V] and [12,
  p. 7-53]</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, capacity inner and outer bounds are established for the
multiuser channels with Channel State Information (CSI) known non-causally at
the transmitters: The Multiple Access Channel (MAC), the Broadcast Channel (BC)
with common information, and the Relay Channel (RC). For each channel, the
actual capacity region is also derived in some special cases. Specifically, it
is shown that for some deterministic models with non-causal CSI at the
transmitters, similar to Costa's Gaussian channel, the availability of CSI at
the deterministic receivers does not affect the capacity region.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3413</identifier>
 <datestamp>2013-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3413</id><created>2011-02-16</created><authors><author><keyname>Haghi</keyname><forenames>Ali</forenames></author><author><keyname>Farsani</keyname><forenames>Reza K.</forenames></author><author><keyname>Aref</keyname><forenames>Mohammad Reza</forenames></author><author><keyname>Marvasti</keyname><forenames>Farokh</forenames></author></authors><title>The Capacity Region of p-Transmitter/q-Receiver Multiple-Access Channels
  with Common Information</title><categories>cs.IT math.IT</categories><comments>29 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the capacity problem for some multiple-access
scenarios with cooperative transmitters. First, a general Multiple-Access
Channel (MAC) with common information, i.e., a scenario where p transmitters
send private messages and also a common message to q receivers and each
receiver decodes all of the messages, is considered. The capacity region of the
discrete memoryless channel is characterized. Then, the general Gaussian fading
MAC with common information wherein partial Channel State Information (CSI) is
available at the transmitters (CSIT) and perfect CSI is available at the
receivers (CSIR) is investigated. A coding theorem is proved for this model
that yields an exact characterization of the throughput capacity region.
Finally, a two-transmitter/one-receiver Gaussian fading MAC with conferencing
encoders with partial CSIT and perfect CSIR is studied and its capacity region
is determined. For the Gaussian fading models with CSIR only (transmitters have
no access to CSIT), some numerical examples and simulation results are provided
for Rayleigh fading.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3420</identifier>
 <datestamp>2011-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3420</id><created>2011-02-16</created><authors><author><keyname>Kuijper</keyname><forenames>Wouter</forenames></author><author><keyname>Weber</keyname><forenames>Michael</forenames></author></authors><title>Generic Programming of Reusable, High Performance Container Types using
  Automatic Type Hierarchy Inference and Bidirectional Antichain Typing</title><categories>cs.PL cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new compile-time notion of type subsumption based on type
simulation. We show how to apply this static subsumption relation to support a
more intuitive, object oriented approach to generic programming of reusable,
high performance container types. As a first step towards an efficient
implementation of the resulting type system in a compiler we present a novel
algorithm for bidirectional type inference over arbitrary syntax graphs. The
algorithm uses the new static type subsumption relation to compress the data
that has to be stored for each node in the typeflow graph. During typeflow
analysis this means that the set of types for a given node can be symbolically
represented using antichains instead of using bitvectors or some other explicit
set representation. This results in a typing algorithm that is both flexible
and precise and shows good performance on representative instances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3426</identifier>
 <datestamp>2012-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3426</id><created>2011-02-16</created><updated>2012-06-21</updated><authors><author><keyname>Mertzios</keyname><forenames>George B.</forenames></author><author><keyname>Nikoletseas</keyname><forenames>Sotiris</forenames></author><author><keyname>Raptopoulos</keyname><forenames>Christoforos</forenames></author><author><keyname>Spirakis</keyname><forenames>Paul G.</forenames></author></authors><title>Natural Models for Evolution on Networks</title><categories>cs.DM q-bio.PE</categories><comments>21 pages, 3 figures</comments><msc-class>92D15, 60J10, 05C81</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Evolutionary dynamics have been traditionally studied in the context of
homogeneous populations, mainly described my the Moran process. Recently, this
approach has been generalized in \cite{LHN} by arranging individuals on the
nodes of a network. Undirected networks seem to have a smoother behavior than
directed ones, and thus it is more challenging to find suppressors/amplifiers
of selection. In this paper we present the first class of undirected graphs
which act as suppressors of selection, by achieving a fixation probability that
is at most one half of that of the complete graph, as the number of vertices
increases. Moreover, we provide some generic upper and lower bounds for the
fixation probability of general undirected graphs. As our main contribution, we
introduce the natural alternative of the model proposed in \cite{LHN}, where
all individuals interact simultaneously and the result is a compromise between
aggressive and non-aggressive individuals. That is, the behavior of the
individuals in our new model and in the model of \cite{LHN} can be interpreted
as an &quot;aggregation&quot; vs. an &quot;all-or-nothing&quot; strategy, respectively. We prove
that our new model of mutual influences admits a \emph{potential function},
which guarantees the convergence of the system for any graph topology and any
initial fitness vector of the individuals. Furthermore, we prove fast
convergence to the stable state for the case of the complete graph, as well as
we provide almost tight bounds on the limit fitness of the individuals. Apart
from being important on its own, this new evolutionary model appears to be
useful also in the abstract modeling of control mechanisms over invading
populations in networks. We demonstrate this by introducing and analyzing two
alternative control approaches, for which we bound the time needed to stabilize
to the &quot;healthy&quot; state of the system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3440</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3440</id><created>2011-02-16</created><updated>2011-04-06</updated><authors><author><keyname>Wimmer</keyname><forenames>M.</forenames></author></authors><title>Efficient numerical computation of the Pfaffian for dense and banded
  skew-symmetric matrices</title><categories>cond-mat.mes-hall cs.MS math.NA physics.comp-ph</categories><comments>New algorithm (Parlett-Reid), overall speed-ups, now also Matlab
  implementation. Program code available as ancillary files, or from
  http://www.ilorentz.org/~wimmer/downloads.html</comments><journal-ref>ACM Trans. Math. Software 38, 30 (2012)</journal-ref><doi>10.1145/2331130.2331138</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computing the Pfaffian of a skew-symmetric matrix is a problem that arises in
various fields of physics. Both computing the Pfaffian and a related problem,
computing the canonical form of a skew-symmetric matrix under unitary
congruence, can be solved easily once the skew-symmetric matrix has been
reduced to skew-symmetric tridiagonal form. We develop efficient numerical
methods for computing this tridiagonal form based on Gauss transformations,
using a skew-symmetric, blocked form of the Parlett-Reid algorithm, or based on
unitary transformations, using block Householder transformations and Givens
rotations, that are applicable to dense and banded matrices, respectively. We
also give a complete and fully optimized implementation of these algorithms in
Fortran, and also provide Python, Matlab and Mathematica implementations for
convenience. Finally, we apply these methods to compute the topological charge
of a class D nanowire, and show numerically the equivalence of definitions
based on the Hamiltonian and the scattering matrix.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3463</identifier>
 <datestamp>2011-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3463</id><created>2011-02-16</created><authors><author><keyname>Martin</keyname><forenames>Barnaby</forenames></author></authors><title>Low-level dichotomy for Quantified Constraint Satisfaction Problems</title><categories>cs.CC cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Building on a result of Larose and Tesson for constraint satisfaction
problems (CSP s), we uncover a dichotomy for the quantified constraint
satisfaction problem QCSP(B), where B is a finite structure that is a core.
Specifically, such problems are either in ALogtime or are L-hard. This involves
demonstrating that if CSP(B) is first-order expressible, and B is a core, then
QCSP(B) is in ALogtime.
  We show that the class of B such that CSP(B) is first-order expressible
(indeed, trivially true) is a microcosm for all QCSPs. Specifically, for any B
there exists a C such that CSP(C) is trivially true, yet QCSP(B) and QCSP(C)
are equivalent under logspace reductions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3465</identifier>
 <datestamp>2011-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3465</id><created>2011-02-16</created><authors><author><keyname>Bonelli</keyname><forenames>Eduardo</forenames><affiliation>Universidad Nacional de Quilmes</affiliation></author></authors><title>Proceedings 5th International Workshop on Higher-Order Rewriting</title><categories>cs.LO cs.PL</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 49, 2011</journal-ref><doi>10.4204/EPTCS.49</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  HOR 2010 is a forum to present work concerning all aspects of higher-order
rewriting. The aim is to provide an informal and friendly setting to discuss
recent work and work in progress. Previous editions of HOR were held in
Copenhagen - Denmark (HOR 2002), Aachen - Germany (HOR 2004), Seattle - USA
(HOR 2006) and Paris - France (HOR 2007).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3491</identifier>
 <datestamp>2011-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3491</id><created>2011-02-16</created><authors><author><keyname>Soto</keyname><forenames>Jos&#xe9; A.</forenames></author></authors><title>A simple PTAS for Weighted Matroid Matching on Strongly Base Orderable
  Matroids</title><categories>cs.DS</categories><comments>8 pages, 3 figures. To appear in LAGOS 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a simple polynomial time approximation scheme for the weighted
matroid matching problem on strongly base orderable matroids. We also show that
even the unweighted version of this problem is NP-complete and not in
oracle-coNP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3493</identifier>
 <datestamp>2012-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3493</id><created>2011-02-16</created><updated>2011-09-29</updated><authors><author><keyname>Koo</keyname><forenames>Joseph C.</forenames></author><author><keyname>Gill</keyname><forenames>John</forenames></author></authors><title>Scalable constructions of fractional repetition codes in distributed
  storage systems</title><categories>cs.IT cs.DC math.IT</categories><comments>8 pages, 6 figures, presented at 49th Allerton Conference on
  Communication Control and Computing, 2011</comments><msc-class>94C30 (Primary), 51E10 (Secondary), 51E15</msc-class><acm-class>G.2.3; H.2.7</acm-class><doi>10.1109/Allerton.2011.6120326</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In distributed storage systems built using commodity hardware, it is
necessary to have data redundancy in order to ensure system reliability. In
such systems, it is also often desirable to be able to quickly repair storage
nodes that fail. We consider a scheme--introduced by El Rouayheb and
Ramchandran--which uses combinatorial block design in order to design storage
systems that enable efficient (and exact) node repair. In this work, we
investigate systems where node sizes may be much larger than replication
degrees, and explicitly provide algorithms for constructing these storage
designs. Our designs, which are related to projective geometries, are based on
the construction of bipartite cage graphs (with girth 6) and the concept of
mutually-orthogonal Latin squares. Via these constructions, we can guarantee
that the resulting designs require the fewest number of storage nodes for the
given parameters, and can further show that these systems can be easily
expanded without need for frequent reconfiguration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3495</identifier>
 <datestamp>2012-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3495</id><created>2011-02-16</created><updated>2012-03-27</updated><authors><author><keyname>Song</keyname><forenames>Xiaoshi</forenames></author><author><keyname>Yin</keyname><forenames>Changchuan</forenames></author><author><keyname>Liu</keyname><forenames>Danpu</forenames></author></authors><title>Diversity and Multiplexing Tradeoff in the Uplink of Cellular Systems
  with Linear MMSE Receiver</title><categories>cs.IT math.IT</categories><comments>Published in WCSP 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we extend the diversity and multiplexing tradeoff (DMT)
analysis from point-to-point channels to cellular systems to evaluate the
impact of inter-cell interference on the system reliability and efficiency.
Fundamental tradeoff among diversity order, multiplexing gain and inter-cell
interference intensity is characterized to reveal the capability of multiple
antennas in cellular systems. And the detrimental effects of the inter-cell
interference on the system performance of diversity and multiplexing is
presented and analyzed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3499</identifier>
 <datestamp>2011-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3499</id><created>2011-02-17</created><authors><author><keyname>Adler</keyname><forenames>Ilan</forenames></author><author><keyname>Hochbaum</keyname><forenames>Dorit S.</forenames></author></authors><title>Benchmark Problems for Totally Unimodular Set System Auction</title><categories>cs.GT cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a generalization of the $k$-flow set system auction where the set
to be procured by a customer corresponds to a feasible solution to a linear
programming problem where the coefficient matrix and right-hand-side together
constitute a totally unimodular matrix. Our results generalize and strengthen
bounds identified for several benchmarks, which form a crucial component in the
study of frugality ratios of truthful auction mechanisms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3500</identifier>
 <datestamp>2011-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3500</id><created>2011-02-17</created><authors><author><keyname>Marina</keyname><forenames>Ninoslav</forenames></author><author><keyname>Yagi</keyname><forenames>Hideki</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Improved Rate-Equivocation Regions for Secure Cooperative Communication</title><categories>cs.IT math.IT</categories><comments>18 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A simple four node network in which cooperation improves the
information-theoretic secrecy is studied. The channel consists of two senders,
a receiver, and an eavesdropper. One or both senders transmit confidential
messages to the receiver, while the eavesdropper tries to decode the
transmitted message. The main result is the derivation of a newly achievable
rate-equivocation region that is shown to be larger than a rate-equivocation
region derived by Lai and El Gamal for the relay-eavesdropper channel. When the
rate of the helping interferer is zero, the new rate-equivocation region
reduces to the capacity-equivocation region over the wire-tap channel, hence,
the new achievability scheme can be seen as a generalization of a coding scheme
proposed by Csiszar and Korner. This result can naturally be combined with a
rate-equivocation region given by Tang et al. (for the interference assisted
secret communication), yielding an even larger achievable rate-equivocation
region.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3503</identifier>
 <datestamp>2011-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3503</id><created>2011-02-17</created><updated>2011-02-27</updated><authors><author><keyname>Okubo</keyname><forenames>Fumiya</forenames></author><author><keyname>Yokomori</keyname><forenames>Takashi</forenames></author></authors><title>On the Hairpin Incompletion</title><categories>cs.FL</categories><comments>17 pages, 2 figures</comments><report-no>EMTR-11-01</report-no><journal-ref>Fundamenta Informaticae 110 (2011) 255--269</journal-ref><doi>10.3233/FI-2011-542</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hairpin completion and its variant called bounded hairpin completion are
operations on formal languages, inspired by a hairpin formation in molecular
biology. Another variant called hairpin lengthening has been recently
introduced and studied on the closure properties and algorithmic problems
concerning several families of languages. In this paper, we introduce a new
operation of this kind, called hairpin incompletion which is not only an
extension of bounded hairpin completion, but also a restricted (bounded)
variant of hairpin lengthening. Further, the hairpin incompletion operation
provides a formal language theoretic framework that models a bio-molecular
technique nowadays known as Whiplash PCR. We study the closure properties of
language families under both the operation and its iterated version. We show
that a family of languages closed under intersection with regular sets,
concatenation with regular sets, and finite union is closed under one-sided
iterated hairpin incompletion, and that a family of languages containing all
linear languages and closed under circular permutation, left derivative and
substitution is also closed under iterated hairpin incompletion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3504</identifier>
 <datestamp>2011-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3504</id><created>2011-02-17</created><updated>2011-09-15</updated><authors><author><keyname>Le</keyname><forenames>Anh</forenames></author><author><keyname>Markopoulou</keyname><forenames>Athina</forenames></author></authors><title>Cooperative Defense against Pollution Attacks in Network Coding Using
  SpaceMac</title><categories>cs.CR cs.NI</categories><comments>This is an extended version of a short version to appear in IEEE JSAC
  on Cooperative Networking - Challenges and Applications 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Intra-session network coding is known to be vulnerable to pollution attacks.
In this work, first, we introduce a novel homomorphic MAC scheme called
SpaceMac, which allows an intermediate node to verify if its received packets
belong to a specific subspace, even if the subspace is expanding over time.
Then, we use SpaceMac as a building block to design a cooperative scheme that
provides complete defense against pollution attacks: (i) it can detect polluted
packets early at intermediate nodes and (ii) it can identify the exact location
of all, even colluding, attackers, thus making it possible to eliminate them.
Our scheme is cooperative: parents and children of any node cooperate to detect
any corrupted packets sent by the node, and nodes in the network cooperate with
a central controller to identify the exact location of all attackers. We
implement SpaceMac in both C/C++ and Java as a library, and we make the library
available online. Our evaluation on both a PC and an Android device shows that
(i) SpaceMac's algorithms can be computed quickly and efficiently, and (ii) our
cooperative defense scheme has low computation and significantly lower
communication overhead than other comparable state-of-the-art schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3508</identifier>
 <datestamp>2015-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3508</id><created>2011-02-17</created><authors><author><keyname>Tekin</keyname><forenames>Cem</forenames></author><author><keyname>Liu</keyname><forenames>Mingyan</forenames></author></authors><title>Online Learning of Rested and Restless Bandits</title><categories>math.OC cs.LG</categories><journal-ref>Information Theory, IEEE Transactions on , vol.58, no.8,
  pp.5588,5611, Aug. 2012</journal-ref><doi>10.1109/TIT.2012.2198613</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study the online learning problem involving rested and
restless multiarmed bandits with multiple plays. The system consists of a
single player/user and a set of K finite-state discrete-time Markov chains
(arms) with unknown state spaces and statistics. At each time step the player
can play M arms. The objective of the user is to decide for each step which M
of the K arms to play over a sequence of trials so as to maximize its long term
reward. The restless multiarmed bandit is particularly relevant to the
application of opportunistic spectrum access (OSA), where a (secondary) user
has access to a set of K channels, each of time-varying condition as a result
of random fading and/or certain primary users' activities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3513</identifier>
 <datestamp>2011-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3513</id><created>2011-02-17</created><authors><author><keyname>Suzuki</keyname><forenames>Riki</forenames></author><author><keyname>Wadayama</keyname><forenames>Tadashi</forenames></author></authors><title>Layered Index-less Indexed Flash Codes for Improving Average Performance</title><categories>cs.IT math.IT</categories><comments>5 pages, submitted to ISIT 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the present paper, a modification of the Index-less Indexed Flash Codes
(ILIFC) for flash memory storage system is presented. Although the ILIFC
proposed by Mahdavifar et al. has excellent worst case performance, the ILIFC
can be further improved in terms of the average case performance. The proposed
scheme, referred to as the {\em layered ILIFC}, is based on the ILIFC. However,
the primary focus of the present study is the average case performance. The
main feature of the proposed scheme is the use of the layer-based index coding
to represent indices of information bits. The layer index coding promotes the
uniform use of cell levels, which leads to better average case performance.
Based on experiments, the proposed scheme achieves a larger average number of
rewritings than the original ILIFC without loss of worst case performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3515</identifier>
 <datestamp>2011-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3515</id><created>2011-02-17</created><authors><author><keyname>Matou\vsek</keyname><forenames>Ji\vr&#xed;</forenames></author><author><keyname>Wagner</keyname><forenames>Uli</forenames></author></authors><title>On Gromov's Method of Selecting Heavily Covered Points</title><categories>math.CO cs.CG</categories><msc-class>52C35, 52C45, 05C10, 53C23, 55U10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A result of Boros and F\&quot;uredi ($d=2$) and of B\'ar\'any (arbitrary $d$)
asserts that for every $d$ there exists $c_d&gt;0$ such that for every $n$-point
set $P\subset \R^d$, some point of $\R^d$ is covered by at least $c_d{n\choose
d+1}$ of the $d$-simplices spanned by the points of $P$. The largest possible
value of $c_d$ has been the subject of ongoing research. Recently Gromov
improved the existing lower bounds considerably by introducing a new,
topological proof method. We provide an exposition of the combinatorial
component of Gromov's approach, in terms accessible to combinatorialists and
discrete geometers, and we investigate the limits of his method. In particular,
we give tighter bounds on the \emph{cofilling profiles} for the
$(n-1)$-simplex. These bounds yield a minor improvement over Gromov's lower
bounds on $c_d$ for large $d$, but they also show that the room for further
improvement through the {\cofilling} profiles alone is quite small. We also
prove a slightly better lower bound for $c_3$ by an approach using an
additional structure besides the {\cofilling} profiles. We formulate a
combinatorial extremal problem whose solution might perhaps lead to a tight
lower bound for $c_d$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3520</identifier>
 <datestamp>2011-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3520</id><created>2011-02-17</created><updated>2011-05-25</updated><authors><author><keyname>Grigoryan</keyname><forenames>Naira</forenames></author><author><keyname>Harutyunyan</keyname><forenames>Ashot</forenames></author><author><keyname>Voloshynovskiy</keyname><forenames>Svyatoslav</forenames></author><author><keyname>Koval</keyname><forenames>Oleksiy</forenames></author></authors><title>On Multiple Hypothesis Testing with Rejection Option</title><categories>cs.IT math.IT</categories><comments>5 pages, 3 figures, submitted to IEEE Information Theory Workshop
  2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of multiple hypothesis testing (HT) in view of a
rejection option. That model of HT has many different applications. Errors in
testing of M hypotheses regarding the source distribution with an option of
rejecting all those hypotheses are considered. The source is discrete and
arbitrarily varying (AVS). The tradeoffs among error probability
exponents/reliabilities associated with false acceptance of rejection decision
and false rejection of true distribution are investigated and the optimal
decision strategies are outlined. The main result is specialized for discrete
memoryless sources (DMS) and studied further. An interesting insight that the
analysis implies is the phenomenon (comprehensible in terms of
supervised/unsupervised learning) that in optimal discrimination within M
hypothetical distributions one permits always lower error than in deciding to
decline the set of hypotheses. Geometric interpretations of the optimal
decision schemes are given for the current and known bounds in multi-HT for
AVS's.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3522</identifier>
 <datestamp>2011-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3522</id><created>2011-02-17</created><authors><author><keyname>Goles</keyname><forenames>Eric</forenames></author><author><keyname>Guillon</keyname><forenames>Pierre</forenames></author><author><keyname>Rapaport</keyname><forenames>Ivan</forenames></author></authors><title>Traced communication complexity of cellular automata</title><categories>cs.FL math.DS</categories><comments>submitted to TCS</comments><msc-class>94A-XX, 68Q-XX, 37B-XX</msc-class><acm-class>F.1.1; F.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study cellular automata with respect to a new communication complexity
problem: each of two players know half of some finite word, and must be able to
tell whether the state of the central cell will follow a given evolution, by
communicating as little as possible between each other. We present some links
with classical dynamical concepts, especially equicontinuity, expansiveness,
entropy and give the asymptotic communication complexity of most elementary
cellular automata.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3523</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3523</id><created>2011-02-17</created><authors><author><keyname>Dittrich</keyname><forenames>Jens</forenames></author></authors><title>PaperBricks: An Alternative to Complete-Story Peer Reviewing</title><categories>cs.DL</categories><comments>refined proposal of my CIDR 2011 Gong Show presentation</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The peer review system as used in several computer science communities has
several flaws including long review times, overloaded reviewers, as well as
fostering of niche topics. These flaws decrease quality, lower impact, slowdown
the innovation process, and lead to frustration of authors, readers, and
reviewers. In order to fix this, we propose a new peer review system termed
paper bricks. Paper bricks has several advantages over the existing system
including shorter publications, better competition for new ideas, as well as an
accelerated innovation process. Furthermore, paper bricks may be implemented
with minimal change to the existing peer review systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3526</identifier>
 <datestamp>2011-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3526</id><created>2011-02-17</created><updated>2011-05-31</updated><authors><author><keyname>Sukhavasi</keyname><forenames>Ravi Teja</forenames></author><author><keyname>Hassibi</keyname><forenames>Babak</forenames></author></authors><title>Linear Error Correcting Codes with Anytime Reliability</title><categories>cs.IT cs.SY math.IT math.OC</categories><comments>accepted at ISIT 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider rate R = k/n causal linear codes that map a sequence of
k-dimensional binary vectors {b_t} to a sequence of n-dimensional binary
vectors {c_t}, such that each c_t is a function of {b_1,b_2,...,b_t}. Such a
code is called anytime reliable, for a particular binary-input memoryless
channel, if at each time, probability of making an error about a source bit
that was sent d time instants ago decays exponentially in d. Anytime reliable
codes are useful in interactive communication problems and, in particular, can
be used to stabilize unstable plants across noisy channels. Schulman proved the
existence of such codes which, due to their structure, he called tree codes;
however, to date, no explicit constructions and tractable decoding algorithms
have been devised. In this paper, we show the existence of anytime reliable
&quot;linear&quot; codes with &quot;high probability&quot;, i.e., suitably chosen random linear
causal codes are anytime reliable with high probability. The key is to consider
time-invariant codes (i.e., ones with Toeplitz generator and parity check
matrices) which obviates the need to union bound over all times. For the binary
erasure channel we give a simple ML decoding algorithm whose average complexity
is constant per time iteration and for which the probability that complexity at
a given time t exceeds KC^3 decays exponentially in C. We show the efficacy of
the method by simulating the stabilization of an unstable plant across a BEC,
and remark on the tradeoffs between the utilization of the communication
resources and the control performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3527</identifier>
 <datestamp>2011-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3527</id><created>2011-02-17</created><updated>2011-05-24</updated><authors><author><keyname>Kwan</keyname><forenames>Ho Yuet</forenames></author><author><keyname>Shum</keyname><forenames>Kenneth W.</forenames></author><author><keyname>Sung</keyname><forenames>Chi Wan</forenames></author></authors><title>Generation of Innovative and Sparse Encoding Vectors for Broadcast
  Systems with Feedback</title><categories>cs.IT cs.CC math.IT</categories><comments>5 pages, 4 figures, accepted for publication in the Proc. of IEEE
  ISIT 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the application of linear network coding to wireless broadcasting with
feedback, we prove that the problem of determining the existence of an
innovative encoding vector is NP-complete when the finite field size is two.
When the finite field size is larger than or equal to the number of users, it
is shown that we can always find an encoding vector which is both innovative
and sparse. The sparsity can be utilized in speeding up the decoding process.
An efficient algorithm to generate innovative and sparse encoding vectors is
developed. Simulations show that the delay performance of our scheme with
binary finite field outperforms a number of existing schemes in terms of
average and worst-case delay.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3529</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3529</id><created>2011-02-17</created><authors><author><keyname>Blech</keyname><forenames>Jan Olaf</forenames></author></authors><title>A Tool for the Certification of PLCs based on a Coq Semantics for
  Sequential Function Charts</title><categories>cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this report we describe a tool framework for certifying properties of
PLCs: CERTPLC. CERTPLC can handle PLC descriptions provided in the Sequential
Function Chart (SFC) language of the IEC 61131-3 standard. It provides routines
to certify properties of systems by delivering an independently checkable
formal system description and proof (called certificate) for the desired
properties. We focus on properties that can be described as inductive
invariants. System descriptions and certificates are generated and handled
using the COQ proof assistant. Our tool framework is used to provide supporting
evidence for the safety of embedded systems in the industrial automation domain
to third-party authorities. In this document we describe the tool framework:
usage scenarios, the archi-tecture, semantics of PLCs and their realization in
COQ, proof generation and the construction of certificates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3533</identifier>
 <datestamp>2011-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3533</id><created>2011-02-17</created><authors><author><keyname>Sultanov</keyname><forenames>Timur</forenames></author><author><keyname>Veselovskiy</keyname><forenames>Pavel</forenames></author></authors><title>Packet-pair technique for available bandwidth estimation in IPv6 network</title><categories>cs.NI</categories><comments>5 pages, 7 figures</comments><acm-class>C.2.1; C.2.3; C.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents experimental checking of the model for measuring
available bandwidth in IPv6. The experiment was performed using a measuring
infrastructure RIPE test box, ensuring precision accuracy. The experimental
results showed that to increase the accuracy of available bandwidth, we need to
neutralize the effect of the variable part of the delay by increasing the
number of measurements. Finally, we made the computer simulation, which allowed
us to establish a dependence between the measurement error of the available
bandwidth and the number of measurements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3537</identifier>
 <datestamp>2011-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3537</id><created>2011-02-17</created><authors><author><keyname>Feigenblat</keyname><forenames>Guy</forenames></author><author><keyname>Porat</keyname><forenames>Ely</forenames></author><author><keyname>Shiftan</keyname><forenames>Ariel</forenames></author></authors><title>Even Better Framework for min-wise Based Algorithms</title><categories>cs.DS</categories><comments>10 pages + appendix. 15 pages total</comments><msc-class>68Q85</msc-class><acm-class>F.1.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a recent paper from SODA11 \cite{kminwise} the authors introduced a
general framework for exponential time improvement of \minwise based algorithms
by defining and constructing almost \kmin independent family of hash functions.
Here we take it a step forward and reduce the space and the independent needed
for representing the functions, by defining and constructing a \dkmin
independent family of hash functions. Surprisingly, for most cases only 8-wise
independent is needed for exponential time and space improvement. Moreover, we
bypass the $O(\log{\frac{1}{\epsilon}})$ independent lower bound for
approximately \minwise functions \cite{patrascu10kwise-lb}, as we use
alternative definition. In addition, as the independent's degree is a small
constant it can be implemented efficiently.
  Informally, under this definition, all subsets of size $d$ of any fixed set
$X$ have an equal probability to have hash values among the minimal $k$ values
in $X$, where the probability is over the random choice of hash function from
the family. This property measures the randomness of the family, as choosing a
truly random function, obviously, satisfies the definition for $d=k=|X|$. We
define and give an efficient time and space construction of approximately
\dkmin independent family of hash functions. The degree of independent required
is optimal, i.e. only $O(d)$ for $2 \le d &lt; k=O(\frac{d}{\epsilon^2})$, where
$\epsilon \in (0,1)$ is the desired error bound. This construction can be used
to improve many \minwise based algorithms, such as
\cite{sizeEstimationFramework,Datar02estimatingrarity,NearDuplicate,SimilaritySearch,DBLP:conf/podc/CohenK07},
as will be discussed here. To our knowledge such definitions, for hash
functions, were never studied and no construction was given before.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3538</identifier>
 <datestamp>2011-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3538</id><created>2011-02-17</created><authors><author><keyname>Robert</keyname><forenames>Philippe</forenames></author><author><keyname>Roberts</keyname><forenames>James</forenames></author></authors><title>A Flow-aware MAC Protocol for a Passive Optical Metropolitan Area
  Network</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper introduces an original MAC protocol for a passive optical
metropolitan area network using time-domain wavelength interleaved networking
(TWIN)% as proposed recently by Bell Labs . Optical channels are shared under
the distributed control of destinations using a packet-based polling algorithm.
This MAC is inspired more by EPON dynamic bandwidth allocation than the
slotted, GPON-like access control generally envisaged for TWIN. Management of
source-destination traffic streams is flow-aware with the size of allocated
time slices being proportional to the number of active flows. This emulates a
network-wide, distributed fair queuing scheduler, bringing the well-known
implicit service differentiation and robustness advantages of this mechanism to
the metro area network. The paper presents a comprehensive performance
evaluation based on analytical modelling supported by simulations. The proposed
MAC is shown to have excellent performance in terms of both traffic capacity
and packet latency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3561</identifier>
 <datestamp>2011-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3561</id><created>2011-02-17</created><authors><author><keyname>Altman</keyname><forenames>Eitan</forenames></author><author><keyname>Kumar</keyname><forenames>Anurag</forenames></author><author><keyname>Singh</keyname><forenames>Chandramani</forenames></author><author><keyname>Sundaresan</keyname><forenames>Rajesh</forenames></author></authors><title>Spatial SINR Games of Base Station Placement and Mobile Association</title><categories>cs.NI cs.GT</categories><journal-ref>IEEE INFOCOM, April, 2009, Rio De Janeiro, Brazil</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the question of determining locations of base stations that may
belong to the same or to competing service providers. We take into account the
impact of these decisions on the behavior of intelligent mobile terminals who
can connect to the base station that offers the best utility. The signal to
interference and noise ratio is used as the quantity that determines the
association. We first study the SINR association-game: we determine the cells
corresponding to each base stations, i.e., the locations at which mobile
terminals prefer to connect to a given base station than to others. We make
some surprising observations: (i) displacing a base station a little in one
direction may result in a displacement of the boundary of the corresponding
cell to the opposite direction; (ii) A cell corresponding to a BS may be the
union of disconnected sub-cells. We then study the hierarchical equilibrium in
the combined BS location and mobile association problem: we determine where to
locate the BSs so as to maximize the revenues obtained at the induced SINR
mobile association game. We consider the cases of single frequency band and two
frequency bands of operation. Finally, we also consider hierarchical equilibria
in two frequency systems with successive interference cancellation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3563</identifier>
 <datestamp>2011-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3563</id><created>2011-02-17</created><authors><author><keyname>Semenov</keyname><forenames>Alexander</forenames></author><author><keyname>Zaikin</keyname><forenames>Oleg</forenames></author><author><keyname>Bespalov</keyname><forenames>Dmitry</forenames></author><author><keyname>Posypkin</keyname><forenames>Mikhail</forenames></author></authors><title>Parallel algorithms for SAT in application to inversion problems of some
  discrete functions</title><categories>cs.DC</categories><comments>16 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article we consider the inversion problem for polynomially computable
discrete functions. These functions describe behavior of many discrete systems
and are used in model checking, hardware verification, cryptanalysis, computer
biology and other domains. Quite often it is necessary to invert these
functions, i.e. to find an unknown preimage if an image and algorithm of
function computation are given. In general case this problem is computationally
intractable. However, many of it's special cases are very important in
practical applications. Thus development of algorithms that are applicable to
these special cases is of importance. The practical applicability of such
algorithms can be validated by their ability to solve the problems that are
considered to be computationally hard (for example cryptanalysis problems). In
this article we propose the technology of solving the inversion problem for
polynomially computable discrete functions. This technology was implemented in
distributed computing environments (parallel clusters and Grid-systems). It is
based on reducing the inversion problem for the considered function to some SAT
problem. We describe a general approach to coarse-grained parallelization for
obtained SAT problems. Efficiency of each parallelization scheme is determined
by the means of a special predictive function. The proposed technology was
validated by successful solving of cryptanalysis problems for some keystream
generators. The main practical result of this work is a complete cryptanalysis
of keystream generator A5/1 which was performed in a Grid system specially
built for this task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3569</identifier>
 <datestamp>2011-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3569</id><created>2011-02-17</created><authors><author><keyname>Haeupler</keyname><forenames>Bernhard</forenames></author><author><keyname>Kim</keyname><forenames>MinJi</forenames></author><author><keyname>M&#xe9;dard</keyname><forenames>Muriel</forenames></author></authors><title>Optimality of Network Coding in Packet Networks</title><categories>cs.IT cs.DS math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We resolve the question of optimality for a well-studied packetized
implementation of random linear network coding, called PNC. In PNC, in contrast
to the classical memoryless setting, nodes store received information in memory
to later produce coded packets that reflect this information. PNC is known to
achieve order optimal stopping times for the many-to-all multicast problem in
many settings.
  We give a reduction that captures exactly how PNC and other network coding
protocols use the memory of the nodes. More precisely, we show that any such
protocol implementation induces a transformation which maps an execution of the
protocol to an instance of the classical memoryless setting. This allows us to
prove that, for any (non-adaptive dynamic) network, PNC converges with high
probability in optimal time. In other words, it stops at exactly the first time
in which in hindsight it was possible to route information from the sources to
each receiver individually.
  Our technique also applies to variants of PNC, in which each node uses only a
finite buffer. We show that, even in this setting, PNC stops exactly within the
time in which in hindsight it was possible to route packets given the memory
constraint, i.e., that the memory used at each node never exceeds its buffer
size. This shows that PNC, even without any feedback or explicit memory
management, allows to keep minimal buffer sizes while maintaining its capacity
achieving performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3578</identifier>
 <datestamp>2011-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3578</id><created>2011-02-17</created><updated>2011-06-29</updated><authors><author><keyname>Li</keyname><forenames>Menghui</forenames></author><author><keyname>Wang</keyname><forenames>Xingang</forenames></author><author><keyname>Fan</keyname><forenames>Ying</forenames></author><author><keyname>Di</keyname><forenames>Zengru</forenames></author><author><keyname>Lai</keyname><forenames>Choy-Heng</forenames></author></authors><title>Onset of Synchronization in Weighted Complex Networks: the Effect of
  Weight-Degree Correlation</title><categories>nlin.CD cs.SI physics.soc-ph</categories><comments>9 pages, 6 figures</comments><journal-ref>CHAOS 21, 025108 (2011)</journal-ref><doi>10.1063/1.3597646</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  By numerical simulations, we investigate the onset of synchronization of
networked phase oscillators under two different weighting schemes. In scheme-I,
the link weights are correlated to the product of the degrees of the connected
nodes, so this kind of networks is named as the weight-degree correlated (WDC)
network. In scheme-II, the link weights are randomly assigned to each link
regardless of the node degrees, so this kind of networks is named as the
weight-degree uncorrelated (WDU) network. Interestingly, it is found that by
increasing a parameter that governs the weight distribution, the onset of
synchronization in WDC network is monotonically enhanced, while in WDU network
there is a reverse in the synchronization performance. We investigate this
phenomenon from the viewpoint of gradient network, and explain the contrary
roles of coupling gradient on network synchronization: gradient promotes
synchronization in WDC network, while deteriorates synchronization in WDU
network. The findings highlight the fact that, besides the link weight, the
correlation between the weight and node degree is also important to the network
dynamics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3579</identifier>
 <datestamp>2011-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3579</id><created>2011-02-17</created><authors><author><keyname>Da</keyname><forenames>Bin</forenames></author><author><keyname>Zhang</keyname><forenames>Rui</forenames></author></authors><title>Cooperative Interference Control for Spectrum Sharing in OFDMA Cellular
  Systems</title><categories>cs.IT math.IT</categories><comments>To appear in ICC2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies cooperative schemes for the inter-cell interference
control in orthogonal-frequency-divisionmultiple- access (OFDMA) cellular
systems. The downlink transmission in a simplified two-cell system is examined,
where both cells simultaneously access the same frequency band using OFDMA. The
joint power and subcarrier allocation over the two cells is investigated for
maximizing their sum throughput with both centralized and decentralized
implementations. Particularly, the decentralized allocation is achieved via a
new cooperative interference control approach, whereby the two cells
independently implement resource allocation to maximize individual throughput
in an iterative manner, subject to a set of mutual interference power
constraints. Simulation results show that the proposed decentralized resource
allocation schemes achieve the system throughput close to that by the
centralized scheme, and provide substantial throughput gains over existing
schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3584</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3584</id><created>2011-02-17</created><authors><author><keyname>Chan</keyname><forenames>Sonic H. Y.</forenames></author><author><keyname>Donner</keyname><forenames>Reik V.</forenames></author><author><keyname>L&#xe4;mmer</keyname><forenames>Stefan</forenames></author></authors><title>Urban road networks -- Spatial networks with universal geometric
  features? A case study on Germany's largest cities</title><categories>physics.data-an cs.SI physics.soc-ph</categories><comments>16 pages; 8 figures</comments><doi>10.1140/epjb/e2011-10889-3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Urban road networks have distinct geometric properties that are partially
determined by their (quasi-) two-dimensional structure. In this work, we study
these properties for 20 of the largest German cities. We find that the
small-scale geometry of all examined road networks is extremely similar. The
object-size distributions of road segments and the resulting cellular
structures are characterised by heavy tails. As a specific feature, a large
degree of rectangularity is observed in all networks, with link angle
distributions approximately described by stretched exponential functions. We
present a rigorous statistical analysis of the main geometric characteristics
and discuss their mutual interrelationships. Our results demonstrate the
fundamental importance of cost-efficiency constraints for in time evolution of
urban road networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3603</identifier>
 <datestamp>2011-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3603</id><created>2011-02-17</created><updated>2011-03-06</updated><authors><author><keyname>Byrne</keyname><forenames>Eimear</forenames></author><author><keyname>Manada</keyname><forenames>Akiko</forenames></author><author><keyname>Marinkovic</keyname><forenames>Stevan</forenames></author><author><keyname>Popovici</keyname><forenames>Emanuel</forenames></author></authors><title>A Graph Theoretical Approach for Network Coding in Wireless Body Area
  Networks</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modern medical wireless systems, such as wireless body area networks (WBANs),
are applications of wireless networks that can be used as a tool of data
transmission between patients and doctors. Accuracy of data transmission is an
important requirement for such systems. In this paper, we will propose a WBAN
which is robust against erasures and describe its properties using graph
theoretic techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3604</identifier>
 <datestamp>2011-03-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3604</id><created>2011-02-17</created><updated>2011-03-18</updated><authors><author><keyname>Byrne</keyname><forenames>Eimear</forenames></author><author><keyname>Greferath</keyname><forenames>Marcus</forenames></author><author><keyname>Pernas</keyname><forenames>Jaume</forenames></author><author><keyname>Zumbr&#xe4;gel</keyname><forenames>Jens</forenames></author></authors><title>Algebraic Decoding of Negacyclic Codes Over Z_4</title><categories>math.CO cs.IT math.IT</categories><comments>17 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article we investigate Berlekamp's negacyclic codes and discover that
these codes, when considered over the integers modulo 4, do not suffer any of
the restrictions on the minimum distance observed in Berlekamp's original
papers. The codes considered here have minimim Lee distance at least 2t+1,
where the generator polynomial of the code has roots z,z^3,...,z^{2t+1} for a
primitive 2nth root of unity z in a Galois extension of Z4. No restriction on t
is imposed. We present an algebraic decoding algorithm for this class of codes
that corrects any error pattern of Lee weight at most t. Our treatment uses
Grobner bases and the decoding complexity is quadratic in t.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3605</identifier>
 <datestamp>2011-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3605</id><created>2011-02-17</created><authors><author><keyname>Ezerman</keyname><forenames>Martianu Frederic</forenames></author><author><keyname>Kirov</keyname><forenames>Radoslav</forenames></author></authors><title>Nonbinary Quantum Codes from Two-Point Divisors on Hermitian Curves</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sarvepalli and Klappenecker showed how classical one-point codes on the
Hermitian curve can be used to construct quantum codes. Homma and Kim
determined the parameters of a larger family of codes, the two-point codes. In
quantum error-correction, the observed presence of asymmetry in some quantum
channels led to the study of asymmetric quantum codes (AQECCs) where we no
longer assume that the different types of errors are equiprobable. This paper
considers quantum codes constructed from the two-point codes. In the asymmetric
case, we show strict improvements over all possible finite fields for a range
of designed distances. We produce large dimension pure AQECC and small
dimension impure AQECC that have better parameters than AQECC from one-point
codes. Numerical results for the Hermitian curves over F16 and F64 are used to
illustrate the gain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3607</identifier>
 <datestamp>2011-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3607</id><created>2011-02-17</created><authors><author><keyname>Ducourthial</keyname><forenames>Bertrand</forenames></author><author><keyname>Khaled</keyname><forenames>Yacine</forenames></author><author><keyname>Mottelet</keyname><forenames>St&#xe9;phane</forenames></author></authors><title>Fairness issues in a chain of IEEE 802.11 stations</title><categories>cs.NI</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We study a simple general scenario of ad hoc networks based on IEEE 802.11
wireless communications, consisting in a chain of transmitters, each of them
being in the carrier sense area of its neighbors. Each transmitter always
attempts to send some data frames to one receiver in its transmission area,
forming a pair sender-receiver. This scenario includes the three pairs fairness
problem, and allows to study some fairness issues of the IEEE 802.11 medium
access mechanism. We show by simulation that interesting phenomena appear,
depending on the number n of pairs in the chain and of its parity. We also
point out a notable asymptotic behavior. We introduce a powerful modeling, by
simply considering the probability for a transmitter to send data while its
neighbors are waiting. This model leads to a non-linear system of equations,
which matches very well the simulations, and which allows to study both small
and very large chains. We then analyze the fairness issue in the chain
regarding some parameters, as well as the asymptotic behavior. By studying very
long chains, we notice good asymptotic fairness of the IEEE 802.11 medium
sharing mechanism. As an application, we show how to increase the fairness in a
chain of three pairs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3610</identifier>
 <datestamp>2011-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3610</id><created>2011-02-17</created><updated>2011-02-18</updated><authors><author><keyname>Murai</keyname><forenames>Fabricio</forenames></author><author><keyname>Rocha</keyname><forenames>Antonio A de A</forenames></author><author><keyname>Figueiredo</keyname><forenames>Daniel R.</forenames></author><author><keyname>Silva</keyname><forenames>Edmundo de Souza e</forenames></author></authors><title>Heterogeneous download times in a homogeneous BitTorrent swarm</title><categories>cs.NI</categories><acm-class>C.2.2; I.6.3; I.6.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modeling and understanding BitTorrent (BT) dynamics is a recurrent research
topic mainly due to its high complexity and tremendous practical efficiency.
Over the years, different models have uncovered various phenomena exhibited by
the system, many of which have direct impact on its performance. In this paper
we identify and characterize a phenomenon that has not been previously
observed: homogeneous peers (with respect to their upload capacities)
experience heterogeneous download rates. The consequences of this phenomenon
have direct impact on peer and system performance, such as high variability of
download times, unfairness with respect to peer arrival order, bursty
departures and content synchronization. Detailed packet-level simulations and
prototype-based experiments on the Internet were performed to characterize this
phenomenon. We also develop a mathematical model that accurately predicts the
heterogeneous download rates of the homogeneous peers as a function of their
content. Although this phenomenon is more prevalent in unpopular swarms (very
few peers), these by far represent the most common type of swarm in BT.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3615</identifier>
 <datestamp>2013-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3615</id><created>2011-02-17</created><updated>2011-06-28</updated><authors><author><keyname>Bouyer</keyname><forenames>Patricia</forenames></author><author><keyname>Markey</keyname><forenames>Nicolas</forenames></author><author><keyname>Olschewski</keyname><forenames>J&#xf6;rg</forenames></author><author><keyname>Ummels</keyname><forenames>Michael</forenames></author></authors><title>Measuring Permissiveness in Parity Games: Mean-Payoff Parity Games
  Revisited</title><categories>cs.LO cs.GT</categories><comments>30 pages, revised version</comments><report-no>LSV-2011-17</report-no><doi>10.1007/978-3-642-24372-1_11</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study nondeterministic strategies in parity games with the aim of
computing a most permissive winning strategy. Following earlier work, we
measure permissiveness in terms of the average number/weight of transitions
blocked by the strategy. Using a translation into mean-payoff parity games, we
prove that the problem of computing (the permissiveness of) a most permissive
winning strategy is in NP intersected coNP. Along the way, we provide a new
study of mean-payoff parity games. In particular, we prove that the opponent
player has a memoryless optimal strategy and give a new algorithm for solving
these games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3617</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3617</id><created>2011-02-17</created><authors><author><keyname>Pinto</keyname><forenames>Pedro C.</forenames></author><author><keyname>Barros</keyname><forenames>Joao</forenames></author><author><keyname>Win</keyname><forenames>Moe Z.</forenames></author></authors><title>Wireless Secrecy in Large-Scale Networks</title><categories>cs.IT cs.NI math.IT</categories><comments>To appear: Proc. IEEE Information Theory and Applications Workshop
  (ITA'11), San Diego, CA, Feb. 2011, pp. 1-10, Invited Paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ability to exchange secret information is critical to many commercial,
governmental, and military networks. The intrinsically secure communications
graph (iS-graph) is a random graph which describes the connections that can be
securely established over a large-scale network, by exploiting the physical
properties of the wireless medium. This paper provides an overview of the main
properties of this new class of random graphs. We first analyze the local
properties of the iS-graph, namely the degree distributions and their
dependence on fading, target secrecy rate, and eavesdropper collusion. To
mitigate the effect of the eavesdroppers, we propose two techniques that
improve secure connectivity. Then, we analyze the global properties of the
iS-graph, namely percolation on the infinite plane, and full connectivity on a
finite region. These results help clarify how the presence of eavesdroppers can
compromise secure communication in a large-scale network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3632</identifier>
 <datestamp>2011-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3632</id><created>2011-02-17</created><authors><author><keyname>D&#xfc;tting</keyname><forenames>Paul</forenames></author><author><keyname>Fischer</keyname><forenames>Felix</forenames></author><author><keyname>Parkes</keyname><forenames>David C.</forenames></author></authors><title>Simplicity-Expressiveness Tradeoffs in Mechanism Design</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A fundamental result in mechanism design theory, the so-called revelation
principle, asserts that for many questions concerning the existence of
mechanisms with a given outcome one can restrict attention to truthful direct
revelation-mechanisms. In practice, however, many mechanism use a restricted
message space. This motivates the study of the tradeoffs involved in choosing
simplified mechanisms, which can sometimes bring benefits in precluding bad or
promoting good equilibria, and other times impose costs on welfare and revenue.
We study the simplicity-expressiveness tradeoff in two representative settings,
sponsored search auctions and combinatorial auctions, each being a canonical
example for complete information and incomplete information analysis,
respectively. We observe that the amount of information available to the agents
plays an important role for the tradeoff between simplicity and expressiveness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3635</identifier>
 <datestamp>2015-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3635</id><created>2011-02-17</created><authors><author><keyname>Bordewich</keyname><forenames>Magnus</forenames></author><author><keyname>Kang</keyname><forenames>Ross J.</forenames></author></authors><title>Rapid mixing of subset Glauber dynamics on graphs of bounded tree-width</title><categories>math.CO cs.DS</categories><comments>18 pages</comments><msc-class>05C85, 68R10, 60J10, 05C31, 68W20, 68W25</msc-class><acm-class>G.2.2; F.2.2; G.3</acm-class><journal-ref>Electron. J. Combin. 21(4): #P4.19 (26 pp.), 2014</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by the `subgraphs world' view of the ferromagnetic Ising model, we
develop a general approach to studying mixing times of Glauber dynamics based
on subset expansion expressions for a class of graph polynomials. With a
canonical paths argument, we demonstrate that the chains defined within this
framework mix rapidly upon graphs of bounded tree-width. This extends known
results on rapid mixing for the Tutte polynomial, the adjacency-rank
($R_2$-)polynomial and the interlace polynomial.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3641</identifier>
 <datestamp>2015-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3641</id><created>2011-02-17</created><authors><author><keyname>Harrison</keyname><forenames>W. K.</forenames></author><author><keyname>Almeida</keyname><forenames>J.</forenames></author><author><keyname>McLaughlin</keyname><forenames>S. W.</forenames></author><author><keyname>Barros</keyname><forenames>J.</forenames></author></authors><title>Physical-Layer Security over Correlated Erasure Channels</title><categories>cs.CR</categories><comments>5 pages, 4 figures, submitted to ISIT 2011</comments><doi>10.1109/ICC.2012.6363737</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We explore the additional security obtained by noise at the physical layer in
a wiretap channel model setting. Security enhancements at the physical layer
have been proposed recently using a secrecy metric based on the degrees of
freedom that an attacker has with respect to the sent ciphertext. Prior work
focused on cases in which the wiretap channel could be modeled as statistically
independent packet erasure channels for the legitimate receiver and an
eavesdropper. In this paper, we go beyond the state-of-the-art by addressing
correlated erasure events across the two communication channels. The resulting
security enhancement is presented as a function of the correlation coefficient
and the erasure probabilities for both channels. It is shown that security
improvements are achievable by means of judicious physical-layer design even
when the eavesdropper has a better channel than the legitimate receiver. The
only case in which this assertion may not hold is when erasures are highly
correlated across channels. However, we are able to prove that correlation
cannot nullify the expected security enhancement if the channel quality of the
legitimate receiver is strictly better than that of the eavesdropper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3643</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3643</id><created>2011-02-17</created><updated>2012-03-19</updated><authors><author><keyname>Bonsma</keyname><forenames>Paul</forenames></author><author><keyname>Schulz</keyname><forenames>Jens</forenames></author><author><keyname>Wiese</keyname><forenames>Andreas</forenames></author></authors><title>A Constant Factor Approximation Algorithm for Unsplittable Flow on Paths</title><categories>cs.DS</categories><comments>37 pages, 5 figures Version 2 contains the same results as version 1,
  but the presentation has been greatly revised and improved. References have
  been added</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the unsplittable flow problem on a path, we are given a capacitated path
$P$ and $n$ tasks, each task having a demand, a profit, and start and end
vertices. The goal is to compute a maximum profit set of tasks, such that for
each edge $e$ of $P$, the total demand of selected tasks that use $e$ does not
exceed the capacity of $e$. This is a well-studied problem that has been
studied under alternative names, such as resource allocation, bandwidth
allocation, resource constrained scheduling, temporal knapsack and interval
packing.
  We present a polynomial time constant-factor approximation algorithm for this
problem. This improves on the previous best known approximation ratio of
$O(\log n)$. The approximation ratio of our algorithm is $7+\epsilon$ for any
$\epsilon&gt;0$.
  We introduce several novel algorithmic techniques, which might be of
independent interest: a framework which reduces the problem to instances with a
bounded range of capacities, and a new geometrically inspired dynamic program
which solves a special case of the maximum weight independent set of rectangles
problem to optimality. In the setting of resource augmentation, wherein the
capacities can be slightly violated, we give a $(2+\epsilon)$-approximation
algorithm. In addition, we show that the problem is strongly NP-hard even if
all edge capacities are equal and all demands are either~1,~2, or~3.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3669</identifier>
 <datestamp>2011-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3669</id><created>2011-02-17</created><updated>2011-07-21</updated><authors><author><keyname>Ma</keyname><forenames>Nan</forenames></author><author><keyname>Ramchandran</keyname><forenames>Kannan</forenames></author><author><keyname>Tse</keyname><forenames>David</forenames></author></authors><title>Efficient File Synchronization: a Distributed Source Coding Approach</title><categories>cs.IT math.IT</categories><comments>9 pages, 2 figures. A shorter version will appear in IEEE
  International Symposium on Information Theory (ISIT), 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of reconstructing a source sequence with the presence of decoder
side-information that is mis-synchronized to the source due to deletions is
studied in a distributed source coding framework. Motivated by practical
applications, the deletion process is assumed to be bursty and is modeled by a
Markov chain. The minimum rate needed to reconstruct the source sequence with
high probability is characterized in terms of an information theoretic
expression, which is interpreted as the amount of information of the deleted
content and the locations of deletions, subtracting &quot;nature's secret&quot;, that is,
the uncertainty of the locations given the source and side-information. For
small bursty deletion probability, the asymptotic expansion of the minimum rate
is computed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3670</identifier>
 <datestamp>2011-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3670</id><created>2011-02-17</created><authors><author><keyname>Canas</keyname><forenames>Guillermo D.</forenames></author><author><keyname>Gortler</keyname><forenames>Steven J.</forenames></author></authors><title>Orphan-Free Anisotropic Voronoi Diagrams</title><categories>cs.CG</categories><comments>17 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe conditions under which an appropriately-defined anisotropic
Voronoi diagram of a set of sites in Euclidean space is guaranteed to be
composed of connected cells in any number of dimensions. These conditions are
natural for problems in optimization and approximation, and algorithms already
exist to produce sets of sites that satisfy them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3673</identifier>
 <datestamp>2012-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3673</id><created>2011-02-17</created><updated>2012-03-27</updated><authors><author><keyname>Canas</keyname><forenames>Guillermo D.</forenames></author><author><keyname>Gortler</keyname><forenames>Steven J.</forenames></author></authors><title>Duals of Orphan-Free Anisotropic Voronoi Diagrams are Triangulations</title><categories>cs.CG</categories><comments>20 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that, under mild conditions on the underlying metric, duals of
appropriately defined anisotropic Voronoi diagrams are embedded triangulations.
Furthermore, they always triangulate the convex hull of the vertices, and have
other properties that parallel those of ordinary Delaunay triangulations. These
results apply to the duals of anisotropic Voronoi diagrams of any set of
vertices, so long as the diagram is orphan-free.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3676</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3676</id><created>2011-02-17</created><updated>2012-04-23</updated><authors><author><keyname>Vardoulakis</keyname><forenames>Dimitrios</forenames><affiliation>Northeastern University</affiliation></author><author><keyname>Shivers</keyname><forenames>Olin</forenames><affiliation>Northeastern University</affiliation></author></authors><title>CFA2: a Context-Free Approach to Control-Flow Analysis</title><categories>cs.PL</categories><comments>LMCS 7 (2:3) 2011</comments><proxy>LMCS</proxy><acm-class>F.3.2, D.3.4</acm-class><journal-ref>Logical Methods in Computer Science, Volume 7, Issue 2 (May 1,
  2011) lmcs:684</journal-ref><doi>10.2168/LMCS-7(2:3)2011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a functional language, the dominant control-flow mechanism is function
call and return. Most higher-order flow analyses, including k-CFA, do not
handle call and return well: they remember only a bounded number of pending
calls because they approximate programs with control-flow graphs. Call/return
mismatch introduces precision-degrading spurious control-flow paths and
increases the analysis time. We describe CFA2, the first flow analysis with
precise call/return matching in the presence of higher-order functions and tail
calls. We formulate CFA2 as an abstract interpretation of programs in
continuation-passing style and describe a sound and complete summarization
algorithm for our abstract semantics. A preliminary evaluation shows that CFA2
gives more accurate data-flow information than 0CFA and 1CFA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3680</identifier>
 <datestamp>2011-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3680</id><created>2011-02-17</created><updated>2011-04-13</updated><authors><author><keyname>Ravuri</keyname><forenames>Muralidhar</forenames></author></authors><title>Foundations for Understanding and Building Conscious Systems using
  Stable Parallel Looped Dynamics</title><categories>cs.AI q-bio.NC</categories><comments>37 pages, 9 figures - revised for clarity</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of consciousness faced several challenges for a few reasons: (a)
a lack of necessary and sufficient conditions, without which we would not know
how close we are to the solution, (b) a lack of a synthesis framework to build
conscious systems and (c) a lack of mechanisms explaining the transition
between the lower-level chemical dynamics and the higher-level abstractions. In
this paper, I address these issues using a new framework. The central result is
that a person is 'minimally' conscious if and only if he knows at least one
truth. This lets us move away from the vagueness surrounding consciousness and
instead focus equivalently on: (i) what truths are and how our brain
represents/relates them to each other and (ii) how we attain a feeling of
knowing for a truth. For the former problem, since truths are things that do
not change, I replace the abstract notion with a dynamical one called fixed
sets. These sets are guaranteed to exist for our brain and other stable
parallel looped systems. The relationships between everyday events are now
built using relationships between fixed sets, until our brain creates a unique
dynamical state called the self-sustaining threshold 'membrane' of fixed sets.
For the latter problem, I present necessary and sufficient conditions for
attaining a feeling of knowing using a definition of continuity applied to
abstractions. Combining these results, I now say that a person is minimally
conscious if and only if his brain has a self-sustaining dynamical membrane
with abstract continuous paths. A synthetic system built to satisfy this
equivalent self-sustaining membrane condition appears indistinguishable from
human consciousness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3698</identifier>
 <datestamp>2011-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3698</id><created>2011-02-17</created><updated>2011-10-13</updated><authors><author><keyname>Charlier</keyname><forenames>Emilie</forenames></author><author><keyname>Rampersad</keyname><forenames>Narad</forenames></author><author><keyname>Shallit</keyname><forenames>Jeffrey</forenames></author></authors><title>Enumeration and Decidable Properties of Automatic Sequences</title><categories>cs.FL cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that various aspects of k-automatic sequences -- such as having an
unbordered factor of length n -- are both decidable and effectively enumerable.
As a consequence it follows that many related sequences are either k-automatic
or k-regular. These include many sequences previously studied in the
literature, such as the recurrence function, the appearance function, and the
repetitivity index. We also give some new characterizations of the class of
k-regular sequences. Many results extend to other sequences defined in terms of
Pisot numeration systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3699</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3699</id><created>2011-02-17</created><authors><author><keyname>Mazzucco</keyname><forenames>Michele</forenames></author></authors><title>Towards Autonomic Service Provisioning Systems</title><categories>cs.DC cs.PF</categories><comments>11 pages, 9 Figures,
  http://www.wipo.int/pctdb/en/wo.jsp?WO=2010026362</comments><journal-ref>10th IEEE/ACM CCGrid 2010, pp 273-282</journal-ref><doi>10.1109/CCGRID.2010.125</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper discusses our experience in building SPIRE, an autonomic system
for service provision. The architecture consists of a set of hosted Web
Services subject to QoS constraints, and a certain number of servers used to
run session-based traffic. Customers pay for having their jobs run, but require
in turn certain quality guarantees: there are different SLAs specifying charges
for running jobs and penalties for failing to meet promised performance
metrics. The system is driven by an utility function, aiming at optimizing the
average earned revenue per unit time. Demand and performance statistics are
collected, while traffic parameters are estimated in order to make dynamic
decisions concerning server allocation and admission control. Different utility
functions are introduced and a number of experiments aiming at testing their
performance are discussed. Results show that revenues can be dramatically
improved by imposing suitable conditions for accepting incoming traffic; the
proposed system performs well under different traffic settings, and it
successfully adapts to changes in the operating environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3703</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3703</id><created>2011-02-17</created><authors><author><keyname>Mazzucco</keyname><forenames>Michele</forenames></author><author><keyname>Mitrani</keyname><forenames>Isi</forenames></author><author><keyname>Fisher</keyname><forenames>Mike</forenames></author><author><keyname>McKee</keyname><forenames>Paul</forenames></author></authors><title>Allocation and Admission Policies for Service Streams</title><categories>cs.PF cs.DC</categories><comments>8 pages, 5 figures, 16th International Symposium on Modeling,
  Analysis, and Simulation of Computer and Telecommunication Systems (MASCOTS
  2008), pp155-162 (Best Paper Award)</comments><journal-ref>16th International Symposium on Modeling, Analysis, and Simulation
  of Computer and Telecommunication Systems (MASCOTS 2008), pp155-162</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A service provisioning system is examined, where a number of servers are used
to offer different types of services to paying customers. A customer is charged
for the execution of a stream of jobs; the number of jobs in the stream and the
rate of their submission is specified. On the other hand, the provider promises
a certain quality of service (QoS), measured by the average waiting time of the
jobs in the stream. A penalty is paid if the agreed QoS requirement is not met.
The objective is to maximize the total average revenue per unit time. Dynamic
policies for making server allocation and stream admission decisions are
introduced and evaluated. The results of several simulations are described.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3713</identifier>
 <datestamp>2011-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3713</id><created>2011-02-17</created><authors><author><keyname>Ruths</keyname><forenames>Justin</forenames></author><author><keyname>Li</keyname><forenames>Jr-Shin</forenames></author></authors><title>Optimal Control of Inhomogeneous Ensembles</title><categories>math.OC cs.SY quant-ph</categories><comments>21 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inhomogeneity, in its many forms, appears frequently in practical physical
systems. Readily apparent in quantum systems, inhomogeneity is caused by
hardware imperfections, measurement inaccuracies, and environmental variations,
and subsequently limits the performance and efficiency achievable in current
experiments. In this paper, we provide a systematic methodology to
mathematically characterize and optimally manipulate inhomogeneous ensembles
with concepts taken from ensemble control. In particular, we develop a
computational method to solve practical quantum pulse design problems cast as
optimal ensemble control problems, based on multidimensional pseudospectral
approximations. We motivate the utility of this method by designing pulses for
both standard and novel applications. We also show the convergence of the
pseudospectral method for optimal ensemble control. The concepts developed here
are applicable beyond quantum control, such as to neuron systems, and
furthermore to systems with by parameter uncertainty, which pervade all areas
of science and engineering.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3722</identifier>
 <datestamp>2012-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3722</id><created>2011-02-17</created><updated>2012-05-07</updated><authors><author><keyname>Tsiatas</keyname><forenames>Alexander</forenames></author><author><keyname>Saniee</keyname><forenames>Iraj</forenames></author><author><keyname>Narayan</keyname><forenames>Onuttom</forenames></author><author><keyname>Andrews</keyname><forenames>Matthew</forenames></author></authors><title>Spectral analysis of communication networks using Dirichlet eigenvalues</title><categories>math.SP cs.DM</categories><comments>14 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The spectral gap of the graph Laplacian with Dirichlet boundary conditions is
computed for the graphs of several communication networks at the IP-layer,
which are subgraphs of the much larger global IP-layer network. We show that
the Dirichlet spectral gap of these networks is substantially larger than the
standard spectral gap and is likely to remain non-zero in the infinite graph
limit. We first prove this result for finite regular trees, and show that the
Dirichlet spectral gap in the infinite tree limit converges to the spectral gap
of the infinite tree. We also perform Dirichlet spectral clustering on the
IP-layer networks and show that it often yields cuts near the network core that
create genuine single-component clusters. This is much better than traditional
spectral clustering where several disjoint fragments near the periphery are
liable to be misleadingly classified as a single cluster. Spectral clustering
is often used to identify bottlenecks or congestion; since congestion in these
networks is known to peak at the core, our results suggest that Dirichlet
spectral clustering may be better at finding bona-fide bottlenecks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3730</identifier>
 <datestamp>2011-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3730</id><created>2011-02-17</created><authors><author><keyname>Mendelzon</keyname><forenames>Ariel</forenames><affiliation>Departamento de Computaci&#xf3;n, FCEyN, Universidad de Buenos Aires</affiliation></author><author><keyname>R&#xed;os</keyname><forenames>Alejandro</forenames><affiliation>Departamento de Computaci&#xf3;n, FCEyN, Universidad de Buenos Aires</affiliation></author><author><keyname>Ziliani</keyname><forenames>Beta</forenames><affiliation>Departamento de Computaci&#xf3;n, FCEyN, Universidad de Buenos Aires</affiliation></author></authors><title>Swapping: a natural bridge between named and indexed explicit
  substitution calculi</title><categories>cs.LO cs.PL</categories><comments>In Proceedings HOR 2010, arXiv:1102.3465</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 49, 2011, pp. 1-15</journal-ref><doi>10.4204/EPTCS.49.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article is devoted to the presentation of lambda_rex, an explicit
substitution calculus with de Bruijn indexes and a simple notation. By being
isomorphic to lambda_ex - a recent formalism with variable names -, lambda_rex
accomplishes simulation of beta-reduction (Sim), preservation of beta-strong
normalization (PSN) and meta-confluence (MC), among other desirable properties.
Our calculus is based on a novel presentation of lambda_dB, using a swap notion
that was originally devised by de Bruijn. Besides lambda_rex, two other indexed
calculi isomorphic to lambda_x and lambda_xgc are presented, demonstrating the
potential of our technique when applied to the design of indexed versions of
known named calculi.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3731</identifier>
 <datestamp>2011-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3731</id><created>2011-02-17</created><authors><author><keyname>Balabonski</keyname><forenames>Thibaut</forenames><affiliation>PPS, Paris, France</affiliation></author></authors><title>On the Implementation of Dynamic Patterns</title><categories>cs.LO cs.PL</categories><comments>In Proceedings HOR 2010, arXiv:1102.3465</comments><proxy>EPTCS</proxy><acm-class>F.4.1; D.3.3; I.1.3</acm-class><journal-ref>EPTCS 49, 2011, pp. 16-30</journal-ref><doi>10.4204/EPTCS.49.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The evaluation mechanism of pattern matching with dynamic patterns is
modelled in the Pure Pattern Calculus by one single meta-rule. This
contribution presents a refinement which narrows the gap between the abstract
calculus and its implementation. A calculus is designed to allow reasoning on
matching algorithms. The new calculus is proved to be confluent, and to
simulate the original Pure Pattern Calculus. A family of new, matching-driven,
reduction strategies is proposed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3732</identifier>
 <datestamp>2011-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3732</id><created>2011-02-17</created><authors><author><keyname>Rose</keyname><forenames>Kristoffer H.</forenames><affiliation>IBM T.J. Watson Research Center</affiliation></author></authors><title>Higher-order Rewriting for Executable Compiler Specifications</title><categories>cs.LO cs.PL</categories><comments>In Proceedings HOR 2010, arXiv:1102.3465</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 49, 2011, pp. 31-45</journal-ref><doi>10.4204/EPTCS.49.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we outline how a simple compiler can be completely specified
using higher order rewriting in all stages: parsing, analysis/optimization, and
code emission, specifically using the crsx.sf.net system for a small
declarative language called &quot;X&quot; inspired by XQuery (for which we are building a
production quality compiler in the same way).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3733</identifier>
 <datestamp>2011-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3733</id><created>2011-02-17</created><authors><author><keyname>Zankl</keyname><forenames>Harald</forenames></author><author><keyname>Hirokawa</keyname><forenames>Nao</forenames></author><author><keyname>Middeldorp</keyname><forenames>Aart</forenames></author></authors><title>Uncurrying for Innermost Termination and Derivational Complexity</title><categories>cs.LO</categories><comments>In Proceedings HOR 2010, arXiv:1102.3465</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 49, 2011, pp. 46-57</journal-ref><doi>10.4204/EPTCS.49.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  First-order applicative term rewriting systems provide a natural framework
for modeling higher-order aspects. In earlier work we introduced an uncurrying
transformation which is termination preserving and reflecting. In this paper we
investigate how this transformation behaves for innermost termination and
(innermost) derivational complexity. We prove that it reflects innermost
termination and innermost derivational complexity and that it preserves and
reflects polynomial derivational complexity. For the preservation of innermost
termination and innermost derivational complexity we give counterexamples.
Hence uncurrying may be used as a preprocessing transformation for innermost
termination proofs and establishing polynomial upper and lower bounds on the
derivational complexity. Additionally it may be used to establish upper bounds
on the innermost derivational complexity while it neither is sound for proving
innermost non-termination nor for obtaining lower bounds on the innermost
derivational complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3734</identifier>
 <datestamp>2011-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3734</id><created>2011-02-17</created><authors><author><keyname>Kesner</keyname><forenames>Delia</forenames><affiliation>PPS, CNRS and Universite Paris Diderot - France</affiliation></author><author><keyname>Lombardi</keyname><forenames>Carlos</forenames><affiliation>Universidad Nacional de Quilmes - Argentina</affiliation></author><author><keyname>R&#xed;os</keyname><forenames>Alejandro</forenames><affiliation>Universidad de Buenos Aires - Argentina</affiliation></author></authors><title>A standardisation proof for algebraic pattern calculi</title><categories>cs.LO cs.PL</categories><comments>In Proceedings HOR 2010, arXiv:1102.3465</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 49, 2011, pp. 58-72</journal-ref><doi>10.4204/EPTCS.49.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work gives some insights and results on standardisation for call-by-name
pattern calculi. More precisely, we define standard reductions for a pattern
calculus with constructor-based data terms and patterns. This notion is based
on reduction steps that are needed to match an argument with respect to a given
pattern. We prove the Standardisation Theorem by using the technique developed
by Takahashi and Crary for lambda-calculus. The proof is based on the fact that
any development can be specified as a sequence of head steps followed by
internal reductions, i.e. reductions in which no head steps are involved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3741</identifier>
 <datestamp>2011-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3741</id><created>2011-02-17</created><authors><author><keyname>Reich</keyname><forenames>Johannes</forenames><affiliation>SAP AG, Walldorf</affiliation></author><author><keyname>Finkbeiner</keyname><forenames>Bernd</forenames><affiliation>Universit&#xe4;t des Saarlandes</affiliation></author></authors><title>Proceedings International Workshop on Interactions, Games and Protocols</title><categories>cs.GT cs.DC</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 50, 2011</journal-ref><doi>10.4204/EPTCS.50</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The focus of the iWIGP workshop is the interrelation between interactions,
games and protocols. How does computer science deal with nondeterministic
interactions where the actions a system takes are not (completely) determined
by the interactions the system is involved in? In computer science,
nondeterministic interactions are usually described by protocols. However,
these interactions can also be viewed as games. As to be expected, games have
become an increasingly important modeling tool wherever nondeterministic
interactions are involved -- from foundations in game semantics and reactive
systems to applications in communication protocols and electronic business
applications. The goal of this workshop has been to bring researchers from
industry and academia together and to explore how a better understanding of the
interrelation between interactions, games and protocols leads to
better-designed and more reliable nondeterministic interacting systems.
  iWIGP 2011 was collocated with ETAPS 2011 in Saarbruecken, Germany. The
programme consisted of three invited talks, by Kim Larsen, Marielle Stoelinga
and Viktor Kuncak, and five refereed papers, selected by a strong programme
committee of international reputation. The refereed papers are contained in
this volume.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3745</identifier>
 <datestamp>2011-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3745</id><created>2011-02-17</created><authors><author><keyname>Zhang</keyname><forenames>Zhenghao</forenames></author></authors><title>A New Bound on the Performance of the Bandwidth Puzzle</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A bandwidth puzzle was recently proposed to defend against colluding
adversaries in peer-to-peer networks. The colluding adversaries do not do
actual work but claim to have uploaded contents for each other to gain free
credits from the system. The bandwidth puzzle guarantees that if the
adversaries can solve the puzzle, they must have spent substantial bandwidth,
the size of which is comparable to the size of the contents they claim to have
uploaded for each other. Therefore, the puzzle discourages the collusion. In
this paper, we study the performance of the bandwidth puzzle and give a lower
bound on the average number of bits the adversaries must receive to be able to
solve the puzzles with a certain probability. We show that our bound is tight
in the sense that there exists a strategy to approach this lower bound
asymptotically within a small factor. The new bound gives better security
guarantees than the existing bound, and can be used to guide better choices of
puzzle parameters to improve the system performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3749</identifier>
 <datestamp>2011-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3749</id><created>2011-02-17</created><authors><author><keyname>Gupta</keyname><forenames>Anupam</forenames></author><author><keyname>Krishnaswamy</keyname><forenames>Ravishankar</forenames></author><author><keyname>Molinaro</keyname><forenames>Marco</forenames></author><author><keyname>Ravi</keyname><forenames>R.</forenames></author></authors><title>Approximation Algorithms for Correlated Knapsacks and Non-Martingale
  Bandits</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the stochastic knapsack problem, we are given a knapsack of size B, and a
set of jobs whose sizes and rewards are drawn from a known probability
distribution. However, we know the actual size and reward only when the job
completes. How should we schedule jobs to maximize the expected total reward?
We know O(1)-approximations when we assume that (i) rewards and sizes are
independent random variables, and (ii) we cannot prematurely cancel jobs. What
can we say when either or both of these assumptions are changed?
  The stochastic knapsack problem is of interest in its own right, but
techniques developed for it are applicable to other stochastic packing
problems. Indeed, ideas for this problem have been useful for budgeted learning
problems, where one is given several arms which evolve in a specified
stochastic fashion with each pull, and the goal is to pull the arms a total of
B times to maximize the reward obtained. Much recent work on this problem focus
on the case when the evolution of the arms follows a martingale, i.e., when the
expected reward from the future is the same as the reward at the current state.
What can we say when the rewards do not form a martingale?
  In this paper, we give constant-factor approximation algorithms for the
stochastic knapsack problem with correlations and/or cancellations, and also
for budgeted learning problems where the martingale condition is not satisfied.
Indeed, we can show that previously proposed LP relaxations have large
integrality gaps. We propose new time-indexed LP relaxations, and convert the
fractional solutions into distributions over strategies, and then use the LP
values and the time ordering information from these strategies to devise a
randomized adaptive scheduling algorithm. We hope our LP formulation and
decomposition methods may provide a new way to address other correlated bandit
problems with more general contexts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3751</identifier>
 <datestamp>2013-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3751</id><created>2011-02-17</created><updated>2013-01-21</updated><authors><author><keyname>Sankar</keyname><forenames>Lalitha</forenames></author><author><keyname>Rajagopalan</keyname><forenames>S. Raj</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Utility-Privacy Tradeoff in Databases: An Information-theoretic Approach</title><categories>cs.IT math.IT</categories><comments>Revised following submission to the IEEE Transactions on Information
  Forensics and Security: Special Issue on Privacy and Trust Management in
  Cloud and Distributed Systems; updated with missing references</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ensuring the usefulness of electronic data sources while providing necessary
privacy guarantees is an important unsolved problem. This problem drives the
need for an analytical framework that can quantify the safety of personally
identifiable information (privacy) while still providing a quantifable benefit
(utility) to multiple legitimate information consumers. This paper presents an
information-theoretic framework that promises an analytical model guaranteeing
tight bounds of how much utility is possible for a given level of privacy and
vice-versa. Specific contributions include: i) stochastic data models for both
categorical and numerical data; ii) utility-privacy tradeoff regions and the
encoding (sanization) schemes achieving them for both classes and their
practical relevance; and iii) modeling of prior knowledge at the user and/or
data source and optimal encoding schemes for both cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3755</identifier>
 <datestamp>2011-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3755</id><created>2011-02-18</created><authors><author><keyname>Zhang</keyname><forenames>Peng</forenames></author><author><keyname>Qiu</keyname><forenames>Robert</forenames></author></authors><title>Cooperative Wideband Spectrum Sensing for the Centralized Cognitive
  Radio Network</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Various primary user (PU) radios have been allocated into fixed frequency
bands in the whole spectrum. A cognitive radio network (CRN) should be able to
perform the wideband spectrum sensing (WSS) to detect temporarily unoccupied
frequency bands. We summarize four occupancy features for the frequency bands.
1. The occupancy is sparse; 2. The frequency band allocation information is
fixed and common; 3. There are three categories for the frequency band usages;
4. The occupied frequency bands are common in the CRN. For the first time, we
consider all features as the prior knowledge in the compressed sensing based
cooperative WSS (CWSS) algorithm design for a centralized CRN. We propose a
modified orthogonal matching pursuit (Mod-OMP) algorithm and a modified
simultaneous orthogonal matching pursuit (Mod-SOMP) algorithm for the CWSS. We
compare the CWSS performance of Mod-OMP/Mod-SOMP with the original OMP/SOMP and
show the performance improvements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3758</identifier>
 <datestamp>2011-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3758</id><created>2011-02-18</created><authors><author><keyname>Zhao</keyname><forenames>Yue</forenames></author><author><keyname>Pottie</keyname><forenames>Gregory J.</forenames></author></authors><title>Optimal Spectrum Management in Multiuser Interference Channels</title><categories>cs.IT math.IT</categories><comments>15 pages, 8 figures, submitted to IEEE Trans. on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the non-convex problem of continuous frequency
optimal spectrum management in multiuser frequency selective interference
channels. Firstly, a simple pairwise channel condition for FDMA schemes to
achieve all Pareto optimal points of the rate region is derived. It enables
fully distributed global optimal decision making on whether any two users
should use orthogonal channels. Next, we present in detail an analytical
solution to finding the global optimum of sum-rate maximization in two-user
symmetric flat channels. Generalizing this solution to frequency selective
channels, a convex optimization is established that solves the global optimum.
Finally, we show that our method generalizes to K-user (K&gt;=2) weighted sum-rate
maximization in asymmetric frequency selective channels, and transform this
classic non-convex optimization in the primal domain to an equivalent convex
optimization. The complexity is shown to be separable in its dependence on the
channel parameters and the power constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3763</identifier>
 <datestamp>2011-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3763</id><created>2011-02-18</created><authors><author><keyname>Chu</keyname><forenames>Hsuan-Yi</forenames></author><author><keyname>Su</keyname><forenames>Hsuan-Jung</forenames></author></authors><title>On the Capacity Region of the Cognitive Interference Channel with
  Unidirectional Destination Cooperation</title><categories>cs.IT math.IT</categories><comments>submitted to ISIT 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The cognitive interference channel with unidirectional destination
cooperation (CIFC-UDC) is a variant of the cognitive interference channel
(CIFC) where the cognitive (secondary) destination not only decodes the
information sent from its sending dual but also helps enhance the communication
of the primary user. This channel is an extension of the original CIFC to
achieve a win-win solution under the coexistence condition. The CIFC-UDC
comprises a broadcast channel (BC), a relay channel (RC), as well as a
partially cooperative relay broadcast channel (PCRBC), and can be degraded to
any one of them. In this paper, we propose a new achievable rate region for the
dis-crete memoryless CIFC-UDC which improves the previous re-sults and includes
the largest known rate regions of the BC, the RC, the PCRBC and the CIFC. A new
outer bound is presented and proved to be tight for two classes of the
CIFC-UDCs, result-ing in the characterization of the capacity region.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3766</identifier>
 <datestamp>2011-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3766</id><created>2011-02-18</created><authors><author><keyname>Makino</keyname><forenames>Kazuhisa</forenames></author><author><keyname>Tamaki</keyname><forenames>Suguru</forenames></author><author><keyname>Yamamoto</keyname><forenames>Masaki</forenames></author></authors><title>Derandomizing HSSW Algorithm for 3-SAT</title><categories>cs.CC cs.DS</categories><comments>11 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a (full) derandomization of HSSW algorithm for 3-SAT, proposed by
Hofmeister, Sch\&quot;oning, Schuler, and Watanabe in [STACS'02]. Thereby, we obtain
an O(1.3303^n)-time deterministic algorithm for 3-SAT, which is currently
fastest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3774</identifier>
 <datestamp>2011-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3774</id><created>2011-02-18</created><authors><author><keyname>Thomann</keyname><forenames>Hans-Rudolf</forenames></author></authors><title>Quantum Anticipation Explorer</title><categories>cs.MS quant-ph</categories><comments>22 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantum anticipation explorer is a computer program allowing the numerical
exploration of quantum anticipation which has been analyzed in arXiv:0810.183v1
and arXiv:1003.1090v1 for H-Atom, equidistant, random and custom spectra. This
tool determines the anticipation strength at those times orthogonal evolution
is possible. This paper is the user's guide explaining its capabilities,
installation and usage, and documenting the mathematics and algorithms
implemented in the software. A zip file containing the setup and documentation
can be downloaded from
http://www.thomannconsulting.ch/public/aboutus/aboutus-en.htm free of cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3776</identifier>
 <datestamp>2011-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3776</id><created>2011-02-18</created><authors><author><keyname>Karafyllis</keyname><forenames>Iasson</forenames></author><author><keyname>Jiang</keyname><forenames>Zhong-Ping</forenames></author></authors><title>A Short Note for the Robustness Properties of Hybrid Dead-Beat Observers</title><categories>math.OC cs.CY</categories><comments>9 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A discussion of the robustness properties of the proposed observer with
respect to measurement errors is provided for the recently proposed full-order
and reduced-order, hybrid, dead-beat observer for a class of nonlinear systems,
linear in the unmeasured states.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3796</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3796</id><created>2011-02-18</created><authors><author><keyname>Ammendola</keyname><forenames>Roberto</forenames></author><author><keyname>Biagioni</keyname><forenames>Andrea</forenames></author><author><keyname>Frezza</keyname><forenames>Ottorino</forenames></author><author><keyname>Cicero</keyname><forenames>Francesca Lo</forenames></author><author><keyname>Lonardo</keyname><forenames>Alessandro</forenames></author><author><keyname>Paolucci</keyname><forenames>Pier Stanislao</forenames></author><author><keyname>Rossetti</keyname><forenames>Davide</forenames></author><author><keyname>Salamon</keyname><forenames>Andrea</forenames></author><author><keyname>Salina</keyname><forenames>Gaetano</forenames></author><author><keyname>Simula</keyname><forenames>Francesco</forenames></author><author><keyname>Tosoratto</keyname><forenames>Laura</forenames></author><author><keyname>Vicini</keyname><forenames>Piero</forenames></author></authors><title>APEnet+: high bandwidth 3D torus direct network for petaflops scale
  commodity clusters</title><categories>physics.comp-ph cs.AR</categories><comments>6 pages, 7 figures, proceeding of CHEP 2010, Taiwan, October 18-22</comments><doi>10.1088/1742-6596/331/5/052029</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe herein the APElink+ board, a PCIe interconnect adapter featuring
the latest advances in wire speed and interface technology plus hardware
support for a RDMA programming model and experimental acceleration of GPU
networking; this design allows us to build a low latency, high bandwidth PC
cluster, the APEnet+ network, the new generation of our cost-effective,
tens-of-thousands-scalable cluster network architecture. Some test results and
characterization of data transmission of a complete testbench, based on a
commercial development card mounting an Altera FPGA, are provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3813</identifier>
 <datestamp>2011-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3813</id><created>2011-02-18</created><updated>2011-02-22</updated><authors><author><keyname>Murakami</keyname><forenames>Keisuke</forenames></author><author><keyname>Uno</keyname><forenames>Takeaki</forenames></author></authors><title>Efficient Algorithms for Dualizing Large-Scale Hypergraphs</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A hypergraph ${\cal F}$ is a set family defined on vertex set $V$. The dual
of ${\cal F}$ is the set of minimal subsets $H$ of $V$ such that $F\cap H \ne
\emptyset$ for any $F\in {\cal F}$. The computation of the dual is equivalent
to many problems, such as minimal hitting set enumeration of a subset family,
minimal set cover enumeration, and the enumeration of hypergraph transversals.
Although many algorithms have been proposed for solving the problem, to the
best of our knowledge, none of them can work on large-scale input with a large
number of output minimal hitting sets. This paper focuses on developing time-
and space-efficient algorithms for solving the problem. We propose two new
algorithms with new search methods, new pruning methods, and fast techniques
for the minimality check. The computational experiments show that our
algorithms are quite fast even for large-scale input for which existing
algorithms do not terminate in a practical time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3822</identifier>
 <datestamp>2011-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3822</id><created>2011-02-18</created><authors><author><keyname>Dyer</keyname><forenames>Martin</forenames></author><author><keyname>Mohanaraj</keyname><forenames>Velumailum</forenames></author></authors><title>The Iterated Prisoner's Dilemma on a Cycle</title><categories>cs.GT</categories><comments>25 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pavlov, a well-known strategy in game theory, has been shown to have some
advantages in the Iterated Prisoner's Dilemma (IPD) game. However, this
strategy can be exploited by inveterate defectors. We modify this strategy to
mitigate the exploitation. We call the resulting strategy Rational Pavlov. This
has a parameter p which measures the &quot;degree of forgiveness&quot; of the players. We
study the evolution of cooperation in the IPD game, when n players are arranged
in a cycle, and all play this strategy. We examine the effect of varying p on
the convergence rate and prove that the convergence rate is fast, O(n log n)
time, for high values of p. We also prove that the convergence rate is
exponentially slow in n for small enough p. Our analysis leaves a gap in the
range of p, but simulations suggest that there is, in fact, a sharp phase
transition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3828</identifier>
 <datestamp>2011-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3828</id><created>2011-02-18</created><authors><author><keyname>J&#xe9;gou</keyname><forenames>Herv&#xe9;</forenames><affiliation>INRIA - IRISA</affiliation></author><author><keyname>Tavenard</keyname><forenames>Romain</forenames><affiliation>INRIA - IRISA</affiliation></author><author><keyname>Douze</keyname><forenames>Matthijs</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes / LJK Laboratoire Jean Kuntzmann, SED</affiliation></author><author><keyname>Amsaleg</keyname><forenames>Laurent</forenames><affiliation>INRIA - IRISA</affiliation></author></authors><title>Searching in one billion vectors: re-rank with source coding</title><categories>cs.IR cs.CV</categories><comments>International Conference on Acoustics, Speech and Signal Processing,
  Prague : Czech Republic (2011)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent indexing techniques inspired by source coding have been shown
successful to index billions of high-dimensional vectors in memory. In this
paper, we propose an approach that re-ranks the neighbor hypotheses obtained by
these compressed-domain indexing methods. In contrast to the usual
post-verification scheme, which performs exact distance calculation on the
short-list of hypotheses, the estimated distances are refined based on short
quantization codes, to avoid reading the full vectors from disk. We have
released a new public dataset of one billion 128-dimensional vectors and
proposed an experimental setup to evaluate high dimensional indexing algorithms
on a realistic scale. Experiments show that our method accurately and
efficiently re-ranks the neighbor hypotheses using little memory compared to
the full vectors representation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3830</identifier>
 <datestamp>2011-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3830</id><created>2011-02-18</created><authors><author><keyname>Schoenemann</keyname><forenames>Thomas</forenames></author><author><keyname>Kahl</keyname><forenames>Fredrik</forenames></author><author><keyname>Masnou</keyname><forenames>Simon</forenames></author><author><keyname>Cremers</keyname><forenames>Daniel</forenames></author></authors><title>A linear framework for region-based image segmentation and inpainting
  involving curvature penalization</title><categories>cs.CV cs.AI math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the first method to handle curvature regularity in region-based
image segmentation and inpainting that is independent of initialization.
  To this end we start from a new formulation of length-based optimization
schemes, based on surface continuation constraints, and discuss the connections
to existing schemes. The formulation is based on a \emph{cell complex} and
considers basic regions and boundary elements. The corresponding optimization
problem is cast as an integer linear program.
  We then show how the method can be extended to include curvature regularity,
again cast as an integer linear program. Here, we are considering pairs of
boundary elements to reflect curvature. Moreover, a constraint set is derived
to ensure that the boundary variables indeed reflect the boundary of the
regions described by the region variables.
  We show that by solving the linear programming relaxation one gets quite
close to the global optimum, and that curvature regularity is indeed much
better suited in the presence of long and thin objects compared to standard
length regularity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3833</identifier>
 <datestamp>2011-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3833</id><created>2011-02-18</created><authors><author><keyname>Lee</keyname><forenames>Namyoon</forenames></author><author><keyname>Jafar</keyname><forenames>Syed A.</forenames></author></authors><title>Aligned Interference Neutralization and the Degrees of Freedom of the 2
  User Interference Channel with Instantaneous Relay</title><categories>cs.IT math.IT</categories><comments>17 papes, 4 figures, Submitted to IEEE Transaction on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is well known that the classical 2 user Gaussian interference channel has
only 1 degree of freedom (DoF), which can be achieved by orthogonal time
division among the 2 users. It is also known that the use of conventional
relays, which introduce a processing delay of at least one symbol duration
relative to the direct paths between sources and destinations, does not
increase the DoF of the 2 user interference channel. The use of instantaneous
relays (relays-without-delay) has been explored for the single user
point-to-point setting and it is known that such a relay, even with memoryless
forwarding at the relay, can achieve a higher capacity than conventional
relays. In this work, we show that the 2 user interference channel with an
instantaneous relay, achieves 3/2 DoF. Thus, an instantaneous relay increases
not only the capacity but also the DoF of the 2 user interference channel. The
achievable scheme is inspired by the aligned interference neutralization scheme
recently proposed for the 2X2X2 interference channel. Remarkably the DoF gain
is achieved with memoryless relays, i.e., with relays that have no memory of
past received symbols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3852</identifier>
 <datestamp>2011-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3852</id><created>2011-02-18</created><authors><author><keyname>D&#xf6;rpinghaus</keyname><forenames>Meik</forenames></author><author><keyname>Ispas</keyname><forenames>Adrian</forenames></author><author><keyname>Meyr</keyname><forenames>Heinrich</forenames></author></authors><title>On the Gain of Joint Processing of Pilot and Data Symbols in Stationary
  Rayleigh Fading Channels</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many typical mobile communication receivers the channel is estimated based
on pilot symbols to allow for a coherent detection and decoding in a separate
processing step. Currently much work is spent on receivers which break up this
separation, e.g., by enhancing channel estimation based on reliability
information on the data symbols. In the present work, we evaluate the possible
gain of a joint processing of data and pilot symbols in comparison to the case
of a separate processing in the context of stationary Rayleigh flat-fading
channels. Therefore, we discuss the nature of the possible gain of a joint
processing of pilot and data symbols. We show that the additional information
that can be gained by a joint processing is captured in the temporal
correlation of the channel estimation error of the solely pilot based channel
estimation, which is not retrieved by the channel decoder in case of separate
processing. In addition, we derive a new lower bound on the achievable rate for
joint processing of pilot and data symbols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3862</identifier>
 <datestamp>2011-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3862</id><created>2011-02-18</created><updated>2011-04-12</updated><authors><author><keyname>Bornmann</keyname><forenames>Lutz</forenames></author><author><keyname>Waltman</keyname><forenames>Ludo</forenames></author></authors><title>The detection of &quot;hot regions&quot; in the geography of science: A
  visualization approach by using density maps</title><categories>cs.DL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spatial scientometrics has attracted a lot of attention in the very recent
past. The visualization methods (density maps) presented in this paper allow
for an analysis revealing regions of excellence around the world using computer
programs that are freely available. Based on Scopus and Web of Science data,
field-specific and field-overlapping scientific excellence can be identified in
broader regions (worldwide or for a specific continent) where high quality
papers (highly cited papers or papers published in Nature or Science) were
published. We used a geographic information system to produce our density maps.
We also briefly discuss the use of Google Earth.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3865</identifier>
 <datestamp>2011-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3865</id><created>2011-02-18</created><authors><author><keyname>Mandl</keyname><forenames>Thomas</forenames></author><author><keyname>Womser-Hacker</keyname><forenames>Christa</forenames></author></authors><title>Probability Based Clustering for Document and User Properties</title><categories>cs.HC cs.IR</categories><comments>In: Ojala, Timo (ed.): Infotech Oulo International Workshop on
  Information Retrieval (IR 2001). Oulo, Finnland. 19.- 21.9.2001. S. 100-107</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Information Retrieval systems can be improved by exploiting context
information such as user and document features. This article presents a model
based on overlapping probabilistic or fuzzy clusters for such features. The
model is applied within a fusion method which linearly combines several
retrieval systems. The fusion is based on weights for the different retrieval
systems which are learned by exploiting relevance feedback information. This
calculation can be improved by maintaining a model for each document and user
cluster. That way, the optimal retrieval system for each document or user type
can be identified and applied. The extension presented in this article allows
overlapping, probabilistic clusters of features to further refine the process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3866</identifier>
 <datestamp>2011-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3866</id><created>2011-02-18</created><authors><author><keyname>Hellweg</keyname><forenames>Heiko</forenames></author><author><keyname>Krause</keyname><forenames>J&#xfc;rgen</forenames></author><author><keyname>Mandl</keyname><forenames>Thomas</forenames></author><author><keyname>Marx</keyname><forenames>Jutta</forenames></author><author><keyname>M&#xfc;ller</keyname><forenames>Matthias N. O.</forenames></author><author><keyname>Mutschke</keyname><forenames>Peter</forenames></author><author><keyname>Str&#xf6;tgen</keyname><forenames>Robert</forenames></author></authors><title>Treatment of Semantic Heterogeneity in Information Retrieval</title><categories>cs.IR</categories><comments>Technical Report (Arbeitsbericht) GESIS - Leibniz Institute for the
  Social Sciences</comments><report-no>IZ-Arbeitsbericht Nr. 23 2001</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The first step to handle semantic heterogeneity should be the attempt to
enrich the semantic information about documents, i.e. to fill up the gaps in
the documents meta-data automatically. Section 2 describes a set of cascading
deductive and heuristic extraction rules, which were developed in the project
CARMEN for the domain of Social Sciences. The mapping between different
terminologies can be done by using intellectual, statistical and/or neural
network transfer modules. Intellectual transfers use cross-concordances between
different classification schemes or thesauri. Section 3 describes the creation,
storage and handling of such transfers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3867</identifier>
 <datestamp>2011-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3867</id><created>2011-02-18</created><authors><author><keyname>Fernandez</keyname><forenames>Luis A.</forenames></author><author><keyname>Khapalov</keyname><forenames>Alexander Y.</forenames></author></authors><title>Controllability properties for the one-dimensional Heat equation under
  multiplicative or nonnegative additive controls with local mobile support</title><categories>math.OC cs.SY</categories><msc-class>35K05, 35K20, 93B05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss several new results on nonnegative approximate controllability for
the one-dimensional Heat equation governed by either multiplicative or
nonnegative additive control, acting within a proper subset of the space domain
at every moment of time. Our methods allow us to link these two types of
controls to some extend. The main results include approximate controllability
properties both for the static and mobile control supports.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3868</identifier>
 <datestamp>2012-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3868</id><created>2011-02-18</created><authors><author><keyname>Rigo</keyname><forenames>Luis O.</forenames><suffix>Jr</suffix></author><author><keyname>Barbosa</keyname><forenames>Valmir C.</forenames></author></authors><title>Evolved preambles for MAX-SAT heuristics</title><categories>cs.AI cs.NE</categories><journal-ref>Proceedings of the International Conference on Evolutionary
  Computation Theory and Applications, 23-31, 2011</journal-ref><doi>10.5220/0003660400230031</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  MAX-SAT heuristics normally operate from random initial truth assignments to
the variables. We consider the use of what we call preambles, which are
sequences of variables with corresponding single-variable assignment actions
intended to be used to determine a more suitable initial truth assignment for a
given problem instance and a given heuristic. For a number of well established
MAX-SAT heuristics and benchmark instances, we demonstrate that preambles can
be evolved by a genetic algorithm such that the heuristics are outperformed in
a significant fraction of the cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3879</identifier>
 <datestamp>2011-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3879</id><created>2011-02-18</created><authors><author><keyname>Cooper</keyname><forenames>Colin</forenames></author><author><keyname>Dyer</keyname><forenames>Martin</forenames></author><author><keyname>Mohanaraj</keyname><forenames>Velumailum</forenames></author></authors><title>On the Imitation Strategy for Games on Graphs</title><categories>cs.GT</categories><comments>32 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In evolutionary game theory, repeated two-player games are used to study
strategy evolution in a population under natural selection. As the evolution
greatly depends on the interaction structure, there has been growing interests
in studying the games on graphs. In this setting, players occupy the vertices
of a graph and play the game only with their immediate neighbours. Various
evolutionary dynamics have been studied in this setting for different games.
Due to the complexity of the analysis, however, most of the work in this area
is experimental. This paper aims to contribute to a more complete
understanding, by providing rigorous analysis. We study the imitation dynamics
on two classes of graph: cycles and complete graphs. We focus on three well
known social dilemmas, namely the Prisoner's Dilemma, the Stag Hunt and the
Snowdrift Game. We also consider, for completeness, the so-called Harmony Game.
Our analysis shows that, on the cycle, all four games converge fast, either to
total cooperation or total defection. On the complete graph, all but the
Snowdrift game converge fast, either to cooperation or defection. The Snowdrift
game reaches a metastable state fast, where cooperators and defectors coexist.
It will converge to cooperation or defection only after spending time in this
state which is exponential in the size, n, of the graph. In exceptional cases,
it will remain in this state indefinitely. Our theoretical results are
supported by experimental investigations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3882</identifier>
 <datestamp>2011-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3882</id><created>2011-02-17</created><updated>2011-08-02</updated><authors><author><keyname>Fontanari</keyname><forenames>Claudio</forenames></author><author><keyname>Pulice</keyname><forenames>Valentina</forenames></author><author><keyname>Rimoldi</keyname><forenames>Anna</forenames></author><author><keyname>Sala</keyname><forenames>Massimiliano</forenames></author></authors><title>On weakly APN functions and 4-bit S-Boxes</title><categories>cs.CR math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  S-Boxes are important security components of block ciphers. We provide
theoretical results on necessary or sufficient criteria for an (invertible)
4-bit S-Box to be weakly APN. Thanks to a classification of 4-bit invertible
S-Boxes achieved independently by De Canni\'ere and Leander-Poschmann, we can
strengthen our results with a computer-aided proof.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3887</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3887</id><created>2011-02-18</created><authors><author><keyname>Eriksson</keyname><forenames>Brian</forenames></author><author><keyname>Dasarathy</keyname><forenames>Gautam</forenames></author><author><keyname>Singh</keyname><forenames>Aarti</forenames></author><author><keyname>Nowak</keyname><forenames>Robert</forenames></author></authors><title>Active Clustering: Robust and Efficient Hierarchical Clustering using
  Adaptively Selected Similarities</title><categories>cs.IT cs.LG math.IT stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hierarchical clustering based on pairwise similarities is a common tool used
in a broad range of scientific applications. However, in many problems it may
be expensive to obtain or compute similarities between the items to be
clustered. This paper investigates the hierarchical clustering of N items based
on a small subset of pairwise similarities, significantly less than the
complete set of N(N-1)/2 similarities. First, we show that if the intracluster
similarities exceed intercluster similarities, then it is possible to correctly
determine the hierarchical clustering from as few as 3N log N similarities. We
demonstrate this order of magnitude savings in the number of pairwise
similarities necessitates sequentially selecting which similarities to obtain
in an adaptive fashion, rather than picking them at random. We then propose an
active clustering method that is robust to a limited fraction of anomalous
similarities, and show how even in the presence of these noisy similarity
values we can resolve the hierarchical clustering using only O(N log^2 N)
pairwise similarities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3896</identifier>
 <datestamp>2011-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3896</id><created>2011-02-18</created><authors><author><keyname>Costa</keyname><forenames>V&#xed;tor Santos</forenames></author><author><keyname>Damas</keyname><forenames>Lu&#xed;s</forenames></author><author><keyname>Rocha</keyname><forenames>Ricardo</forenames></author></authors><title>The YAP Prolog System</title><categories>cs.PL</categories><comments>30 pages, 2 figures. To appear in Theory and Practice of Logic
  Programming (TPLP)</comments><acm-class>D.3.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Yet Another Prolog (YAP) is a Prolog system originally developed in the
mid-eighties and that has been under almost constant development since then.
This paper presents the general structure and design of the YAP system,
focusing on three important contributions to the Logic Programming community.
First, it describes the main techniques used in YAP to achieve an efficient
Prolog engine. Second, most Logic Programming systems have a rather limited
indexing algorithm. YAP contributes to this area by providing a dynamic
indexing mechanism, or just-in-time indexer (JITI). Third, a important
contribution of the YAP system has been the integration of both or-parallelism
and tabling in a single Logic Programming system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3901</identifier>
 <datestamp>2013-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3901</id><created>2011-02-18</created><updated>2013-08-19</updated><authors><author><keyname>Brzozowski</keyname><forenames>Janusz</forenames></author><author><keyname>Tamm</keyname><forenames>Hellis</forenames></author></authors><title>Theory of Atomata</title><categories>cs.FL</categories><comments>29 pages, 2 figures, 28 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that every regular language defines a unique nondeterministic finite
automaton (NFA), which we call &quot;\'atomaton&quot;, whose states are the &quot;atoms&quot; of
the language, that is, non-empty intersections of complemented or
uncomplemented left quotients of the language. We describe methods of
constructing the \'atomaton, and prove that it is isomorphic to the reverse
automaton of the minimal deterministic finite automaton (DFA) of the reverse
language. We study &quot;atomic&quot; NFAs in which the right language of every state is
a union of atoms. We generalize Brzozowski's double-reversal method for
minimizing a deterministic finite automaton (DFA), showing that the result of
applying the subset construction to an NFA is a minimal DFA if and only if the
reverse of the NFA is atomic. We prove that Sengoku's claim that his method
always finds a minimal NFA is false.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3902</identifier>
 <datestamp>2011-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3902</id><created>2011-02-18</created><updated>2011-05-28</updated><authors><author><keyname>Chertkov</keyname><forenames>Michael</forenames></author><author><keyname>Stepanov</keyname><forenames>Mikhail</forenames></author></authors><title>Polytope of Correct (Linear Programming) Decoding and Low-Weight
  Pseudo-Codewords</title><categories>cs.IT math.IT</categories><comments>6 pages, 2 figures, accepted for IEEE ISIT 2011</comments><report-no>LA-UR 11-01059</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze Linear Programming (LP) decoding of graphical binary codes
operating over soft-output, symmetric and log-concave channels. We show that
the error-surface, separating domain of the correct decoding from domain of the
erroneous decoding, is a polytope. We formulate the problem of finding the
lowest-weight pseudo-codeword as a non-convex optimization (maximization of a
convex function) over a polytope, with the cost function defined by the channel
and the polytope defined by the structure of the code. This formulation
suggests new provably convergent heuristics for finding the lowest weight
pseudo-codewords improving in quality upon previously discussed. The algorithm
performance is tested on the example of the Tanner [155, 64, 20] code over the
Additive White Gaussian Noise (AWGN) channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3919</identifier>
 <datestamp>2011-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3919</id><created>2011-02-18</created><authors><author><keyname>Hwang</keyname><forenames>TaeHyun</forenames></author><author><keyname>Zhang</keyname><forenames>Wei</forenames></author><author><keyname>Xie</keyname><forenames>Maoqiang</forenames></author><author><keyname>Kuang</keyname><forenames>Rui</forenames></author></authors><title>Inferring Disease and Gene Set Associations with Rank Coherence in
  Networks</title><categories>q-bio.GN cs.AI cs.LG q-bio.MN</categories><comments>16 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A computational challenge to validate the candidate disease genes identified
in a high-throughput genomic study is to elucidate the associations between the
set of candidate genes and disease phenotypes. The conventional gene set
enrichment analysis often fails to reveal associations between disease
phenotypes and the gene sets with a short list of poorly annotated genes,
because the existing annotations of disease causative genes are incomplete. We
propose a network-based computational approach called rcNet to discover the
associations between gene sets and disease phenotypes. Assuming coherent
associations between the genes ranked by their relevance to the query gene set,
and the disease phenotypes ranked by their relevance to the hidden target
disease phenotypes of the query gene set, we formulate a learning framework
maximizing the rank coherence with respect to the known disease phenotype-gene
associations. An efficient algorithm coupling ridge regression with label
propagation, and two variants are introduced to find the optimal solution of
the framework. We evaluated the rcNet algorithms and existing baseline methods
with both leave-one-out cross-validation and a task of predicting recently
discovered disease-gene associations in OMIM. The experiments demonstrated that
the rcNet algorithms achieved the best overall rankings compared to the
baselines. To further validate the reproducibility of the performance, we
applied the algorithms to identify the target diseases of novel candidate
disease genes obtained from recent studies of GWAS, DNA copy number variation
analysis, and gene expression profiling. The algorithms ranked the target
disease of the candidate genes at the top of the rank list in many cases across
all the three case studies. The rcNet algorithms are available as a webtool for
disease and gene set association analysis at
http://compbio.cs.umn.edu/dgsa_rcNet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3923</identifier>
 <datestamp>2011-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3923</id><created>2011-02-18</created><updated>2011-05-26</updated><authors><author><keyname>Foygel</keyname><forenames>Rina</forenames></author><author><keyname>Srebro</keyname><forenames>Nathan</forenames></author></authors><title>Concentration-Based Guarantees for Low-Rank Matrix Reconstruction</title><categories>cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of approximately reconstructing a partially-observed,
approximately low-rank matrix. This problem has received much attention lately,
mostly using the trace-norm as a surrogate to the rank. Here we study low-rank
matrix reconstruction using both the trace-norm, as well as the less-studied
max-norm, and present reconstruction guarantees based on existing analysis on
the Rademacher complexity of the unit balls of these norms. We show how these
are superior in several ways to recently published guarantees based on
specialized analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3930</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3930</id><created>2011-02-18</created><updated>2011-05-23</updated><authors><author><keyname>Lipowski</keyname><forenames>Adam</forenames></author><author><keyname>Lipowska</keyname><forenames>Dorota</forenames></author></authors><title>Diffusive behavior of a greedy traveling salesman</title><categories>cond-mat.stat-mech cs.DS physics.soc-ph q-bio.QM</categories><comments>accepted in Phys. Rev. E</comments><journal-ref>Physical Review E 83, 061115 (2011)</journal-ref><doi>10.1103/PhysRevE.83.061115</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using Monte Carlo simulations we examine the diffusive properties of the
greedy algorithm in the d-dimensional traveling salesman problem. Our results
show that for d=3 and 4 the average squared distance from the origin &lt;r^2&gt; is
proportional to the number of steps t. In the d=2 case such a scaling is
modified with some logarithmic corrections, which might suggest that d=2 is the
critical dimension of the problem. The distribution of lengths also shows
marked differences between d=2 and d&gt;2 versions. A simple strategy adopted by
the salesman might resemble strategies chosen by some foraging and hunting
animals, for which anomalous diffusive behavior has recently been reported and
interpreted in terms of Levy flights. Our results suggest that broad and
Levy-like distributions in such systems might appear due to dimension-dependent
properties of a search space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3931</identifier>
 <datestamp>2011-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3931</id><created>2011-02-18</created><updated>2011-04-25</updated><authors><author><keyname>Xie</keyname><forenames>J.</forenames></author><author><keyname>Sreenivasan</keyname><forenames>S.</forenames></author><author><keyname>Korniss</keyname><forenames>G.</forenames></author><author><keyname>Zhang</keyname><forenames>W.</forenames></author><author><keyname>Lim</keyname><forenames>C.</forenames></author><author><keyname>Szymanski</keyname><forenames>B. K.</forenames></author></authors><title>Social consensus through the influence of committed minorities</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><comments>9 pages, 5 figures</comments><journal-ref>Phys. Rev. E 84, 011130 (2011)</journal-ref><doi>10.1103/PhysRevE.84.011130</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show how the prevailing majority opinion in a population can be rapidly
reversed by a small fraction p of randomly distributed committed agents who
consistently proselytize the opposing opinion and are immune to influence.
Specifically, we show that when the committed fraction grows beyond a critical
value p_c \approx 10%, there is a dramatic decrease in the time, T_c, taken for
the entire population to adopt the committed opinion. In particular, for
complete graphs we show that when p &lt; p_c, T_c \sim \exp(\alpha(p)N), while for
p &gt; p_c, T_c \sim \ln N. We conclude with simulation results for
Erd\H{o}s-R\'enyi random graphs and scale-free networks which show
qualitatively similar behavior.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3932</identifier>
 <datestamp>2011-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3932</id><created>2011-02-18</created><updated>2011-07-27</updated><authors><author><keyname>Shallit</keyname><forenames>Jeffrey</forenames></author></authors><title>Fife's Theorem Revisited</title><categories>cs.FL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give another proof of a theorem of Fife - understood broadly as providing
a finite automaton that gives a complete description of all infinite binary
overlap-free words. Our proof is significantly simpler than those in the
literature. As an application we give a complete characterization of the
overlap-free words that are 2-automatic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3936</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3936</id><created>2011-02-18</created><authors><author><keyname>Mitchell</keyname><forenames>David. G. M.</forenames></author><author><keyname>Lentmaier</keyname><forenames>Michael</forenames></author><author><keyname>Costello,</keyname><forenames>Daniel J.</forenames><suffix>Jr</suffix></author></authors><title>AWGN Channel Analysis of Terminated LDPC Convolutional Codes</title><categories>cs.IT math.IT</categories><comments>Presented at the 2011 Information Theory and Applications Workshop</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It has previously been shown that ensembles of terminated protograph-based
low-density parity-check (LDPC) convolutional codes have a typical minimum
distance that grows linearly with block length and that they are capable of
achieving capacity approaching iterative decoding thresholds on the binary
erasure channel (BEC). In this paper, we review a recent result that the
dramatic threshold improvement obtained by terminating LDPC convolutional codes
extends to the additive white Gaussian noise (AWGN) channel. Also, using a
(3,6)-regular protograph-based LDPC convolutional code ensemble as an example,
we perform an asymptotic trapping set analysis of terminated LDPC convolutional
code ensembles. In addition to capacity approaching iterative decoding
thresholds and linearly growing minimum distance, we find that the smallest
non-empty trapping set of a terminated ensemble grows linearly with block
length.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3937</identifier>
 <datestamp>2011-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3937</id><created>2011-02-18</created><updated>2011-06-09</updated><authors><author><keyname>Jin</keyname><forenames>Ruoming</forenames></author><author><keyname>Lee</keyname><forenames>Victor E.</forenames></author><author><keyname>Hong</keyname><forenames>Hui</forenames></author></authors><title>Axiomatic Ranking of Network Role Similarity</title><categories>cs.SI physics.soc-ph</categories><comments>17 pages, twocolumn Version 2 of this technical report fixes minor
  errors in the Triangle Inequality proof, grammatical errors, and other typos.
  Edited and more polished version to be published in KDD'11, August 2011</comments><acm-class>H.2.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A key task in social network and other complex network analysis is role
analysis: describing and categorizing nodes according to how they interact with
other nodes. Two nodes have the same role if they interact with equivalent sets
of neighbors. The most fundamental role equivalence is automorphic equivalence.
Unfortunately, the fastest algorithms known for graph automorphism are
nonpolynomial. Moreover, since exact equivalence may be rare, a more meaningful
task is to measure the role similarity between any two nodes. This task is
closely related to the structural or link-based similarity problem that SimRank
attempts to solve. However, SimRank and most of its offshoots are not
sufficient because they do not fully recognize automorphically or structurally
equivalent nodes. In this paper we tackle two problems. First, what are the
necessary properties for a role similarity measure or metric? Second, how can
we derive a role similarity measure satisfying these properties? For the first
problem, we justify several axiomatic properties necessary for a role
similarity measure or metric: range, maximal similarity, automorphic
equivalence, transitive similarity, and the triangle inequality. For the second
problem, we present RoleSim, a new similarity metric with a simple iterative
computational method. We rigorously prove that RoleSim satisfies all the
axiomatic properties. We also introduce an iceberg RoleSim algorithm which can
guarantee to discover all pairs with RoleSim score no less than a user-defined
threshold $\theta$ without computing the RoleSim for every pair. We demonstrate
the superior interpretative power of RoleSim on both both synthetic and real
datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3939</identifier>
 <datestamp>2011-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3939</id><created>2011-02-18</created><authors><author><keyname>Dhillon</keyname><forenames>Harpreet S.</forenames></author><author><keyname>Jeong</keyname><forenames>Jeong-O</forenames></author><author><keyname>Datla</keyname><forenames>Dinesh</forenames></author><author><keyname>Benonis</keyname><forenames>Michael</forenames></author><author><keyname>Buehrer</keyname><forenames>R. Michael</forenames></author><author><keyname>Reed</keyname><forenames>Jeffrey H.</forenames></author></authors><title>A Sub-Space Method to Detect Multiple Wireless Microphone Signals in TV
  Band White Space</title><categories>cs.IT math.IT stat.AP</categories><comments>To appear in SPRINGER: Analog Integrated Circuits and Signal
  Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The main hurdle in the realization of dynamic spectrum access (DSA) systems
from physical layer perspective is the reliable sensing of low power licensed
users. One such scenario shows up in the unlicensed use of TV bands where the
TV Band Devices (TVBDs) are required to sense extremely low power wireless
microphones (WMs). The lack of technical standard among various wireless
manufacturers and the resemblance of certain WM signals to narrow-band
interference signals, such as spurious emissions, further aggravate the
problem. Due to these uncertainties, it is extremely difficult to abstract the
features of WM signals and hence develop robust sensing algorithms. To partly
counter these challenges, we develop a two-stage sub-space algorithm that
detects multiple narrow-band analog frequency-modulated signals generated by
WMs. The performance of the algorithm is verified by using experimentally
captured low power WM signals with received power ranging from -100 to -105
dBm. The problem of differentiating between the WM and other narrow-band
signals is left as a future work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3944</identifier>
 <datestamp>2014-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3944</id><created>2011-02-18</created><updated>2014-02-03</updated><authors><author><keyname>Kostina</keyname><forenames>Victoria</forenames></author><author><keyname>Verd&#xfa;</keyname><forenames>Sergio</forenames></author></authors><title>Fixed-length lossy compression in the finite blocklength regime</title><categories>cs.IT math.IT</categories><journal-ref>IEEE Transactions on Information Theory, vol. 58, no. 6, pp.
  3309-3338, June 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the minimum achievable source coding rate as a function of
blocklength $n$ and probability $\epsilon$ that the distortion exceeds a given
level $d$. Tight general achievability and converse bounds are derived that
hold at arbitrary fixed blocklength. For stationary memoryless sources with
separable distortion, the minimum rate achievable is shown to be closely
approximated by $R(d) + \sqrt{\frac{V(d)}{n}} Q^{-1}(\epsilon)$, where $R(d)$
is the rate-distortion function, $V(d)$ is the rate dispersion, a
characteristic of the source which measures its stochastic variability, and
$Q^{-1}(\epsilon)$ is the inverse of the standard Gaussian complementary cdf.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3947</identifier>
 <datestamp>2011-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3947</id><created>2011-02-18</created><authors><author><keyname>Khajehnejad</keyname><forenames>Amin</forenames></author><author><keyname>Oymak</keyname><forenames>Samet</forenames></author><author><keyname>Hassibi</keyname><forenames>Babak</forenames></author></authors><title>Subspace Expanders and Matrix Rank Minimization</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Matrix rank minimization (RM) problems recently gained extensive attention
due to numerous applications in machine learning, system identification and
graphical models. In RM problem, one aims to find the matrix with the lowest
rank that satisfies a set of linear constraints. The existing algorithms
include nuclear norm minimization (NNM) and singular value thresholding. Thus
far, most of the attention has been on i.i.d. Gaussian measurement operators.
In this work, we introduce a new class of measurement operators, and a novel
recovery algorithm, which is notably faster than NNM. The proposed operators
are based on what we refer to as subspace expanders, which are inspired by the
well known expander graphs based measurement matrices in compressed sensing. We
show that given an $n\times n$ PSD matrix of rank $r$, it can be uniquely
recovered from a minimal sampling of $O(nr)$ measurements using the proposed
structures, and the recovery algorithm can be cast as matrix inversion after a
few initial processing steps.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3949</identifier>
 <datestamp>2011-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3949</id><created>2011-02-18</created><updated>2011-08-16</updated><authors><author><keyname>Zhang</keyname><forenames>Zhilin</forenames></author><author><keyname>Rao</keyname><forenames>Bhaskar D.</forenames></author></authors><title>Sparse Signal Recovery with Temporally Correlated Source Vectors Using
  Sparse Bayesian Learning</title><categories>stat.ML cs.LG</categories><comments>The final version with some typos corrected. Codes can be downloaded
  at: http://dsp.ucsd.edu/~zhilin/TSBL_code.zip</comments><journal-ref>IEEE Journal of Selected Topics in Signal Processing, vol.5, no.
  5, pp. 912-926, 2011</journal-ref><doi>10.1109/JSTSP.2011.2159773</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the sparse signal recovery problem in the context of multiple
measurement vectors (MMV) when elements in each nonzero row of the solution
matrix are temporally correlated. Existing algorithms do not consider such
temporal correlations and thus their performance degrades significantly with
the correlations. In this work, we propose a block sparse Bayesian learning
framework which models the temporal correlations. In this framework we derive
two sparse Bayesian learning (SBL) algorithms, which have superior recovery
performance compared to existing algorithms, especially in the presence of high
temporal correlations. Furthermore, our algorithms are better at handling
highly underdetermined problems and require less row-sparsity on the solution
matrix. We also provide analysis of the global and local minima of their cost
function, and show that the SBL cost function has the very desirable property
that the global minimum is at the sparsest solution to the MMV problem.
Extensive experiments also provide some interesting results that motivate
future theoretical research on the MMV model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3968</identifier>
 <datestamp>2011-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3968</id><created>2011-02-19</created><authors><author><keyname>Voronov</keyname><forenames>V. K.</forenames><affiliation>Irkutsk State Technical University, Irkutsk, Russia</affiliation></author></authors><title>Cluster quantum computer on the basis of quasi-part</title><categories>quant-ph cs.ET cs.OH</categories><comments>4 pages</comments><report-no>EFI-94-11</report-no><msc-class>68Q01 (Primary), 68Q12 (Secondary)</msc-class><acm-class>K.7.0</acm-class><journal-ref>Natural Science, vol. 2, no. 8, August 2010, pp.923 - 927</journal-ref><doi>10.4236/ns.2010.28114</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The present paper deals with the possibility of creation of the quantum
computer in which the role of q-bits is played by quasi-particles. In such a
computer, the elementary computation block should represent a cluster created
on the basis of the paramagnetic molecules. The latter form heterogeneous spin
states in the cluster owing to the presence of interelectron correlations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3971</identifier>
 <datestamp>2011-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3971</id><created>2011-02-19</created><authors><author><keyname>Chingtham</keyname><forenames>Tejbanta Singh</forenames></author><author><keyname>Sahoo</keyname><forenames>G.</forenames></author><author><keyname>Ghose</keyname><forenames>M. K.</forenames></author></authors><title>Artificial Immune Privileged Sites as an Enhancement to Immuno-Computing
  Paradigm</title><categories>cs.CR cs.ET</categories><comments>Accepted for publication in International Journal of Intelligent
  Information Technology Application (IJIITA)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The immune system is a highly parallel and distributed intelligent system
which has learning, memory, and associative capabilities. Artificial Immune
System is an evolutionary paradigm inspired by the biological aspects of the
immune system of mammals. The immune system can inspire to form new algorithms
learning from its course of action. The human immune system has motivated
scientists and engineers for finding powerful information processing algorithms
that has solved complex engineering problems. This work is the result of an
attempt to explore a different perspective of the immune system namely the
Immune Privileged Site (IPS) which has the ability to make an exception to
different parts of the body by not triggering immune response to some of the
foreign agent in these parts of the body. While the complete system is secured
by an Immune System at certain times it may be required that the system allows
certain activities which may be harmful to other system which is useful to it
and learns over a period of time through the immune privilege model as done in
case of Immune Privilege Sites in Natural Immune System.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3975</identifier>
 <datestamp>2011-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3975</id><created>2011-02-19</created><updated>2011-02-24</updated><authors><author><keyname>Das</keyname><forenames>Abhimanyu</forenames></author><author><keyname>Kempe</keyname><forenames>David</forenames></author></authors><title>Submodular meets Spectral: Greedy Algorithms for Subset Selection,
  Sparse Approximation and Dictionary Selection</title><categories>stat.ML cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of selecting a subset of k random variables from a large
set, in order to obtain the best linear prediction of another variable of
interest. This problem can be viewed in the context of both feature selection
and sparse approximation. We analyze the performance of widely used greedy
heuristics, using insights from the maximization of submodular functions and
spectral analysis. We introduce the submodularity ratio as a key quantity to
help understand why greedy algorithms perform well even when the variables are
highly correlated. Using our techniques, we obtain the strongest known
approximation guarantees for this problem, both in terms of the submodularity
ratio and the smallest k-sparse eigenvalue of the covariance matrix. We further
demonstrate the wide applicability of our techniques by analyzing greedy
algorithms for the dictionary selection problem, and significantly improve the
previously known guarantees. Our theoretical analysis is complemented by
experiments on real-world and synthetic data sets; the experiments show that
the submodularity ratio is a stronger predictor of the performance of greedy
algorithms than other spectral parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3987</identifier>
 <datestamp>2011-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3987</id><created>2011-02-19</created><authors><author><keyname>Zhang</keyname><forenames>Xin</forenames></author><author><keyname>Liu</keyname><forenames>Guizhen</forenames></author><author><keyname>Wu</keyname><forenames>Jian-Liang</forenames></author></authors><title>k-forested choosability of graphs with bounded maximum average degree</title><categories>math.CO cs.DM</categories><comments>Please cite this paper in press as X. Zhang, G. Liu, J.-L. Wu,
  k-forested choosability of graphs with bounded maximum average degree,
  Bulletin of the Iranian Mathematical Society, to appear</comments><msc-class>05C10, 05C15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A proper vertex coloring of a simple graph is $k$-forested if the graph
induced by the vertices of any two color classes is a forest with maximum
degree less than $k$. A graph is $k$-forested $q$-choosable if for a given list
of $q$ colors associated with each vertex $v$, there exists a $k$-forested
coloring of $G$ such that each vertex receives a color from its own list. In
this paper, we prove that the $k$-forested choosability of a graph with maximum
degree $\Delta\geq k\geq 4$ is at most $\lceil\frac{\Delta}{k-1}\rceil+1$,
$\lceil\frac{\Delta}{k-1}\rceil+2$ or $\lceil\frac{\Delta}{k-1}\rceil+3$ if its
maximum average degree is less than 12/5, $8/3 or 3, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.3989</identifier>
 <datestamp>2011-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.3989</id><created>2011-02-19</created><authors><author><keyname>Liu</keyname><forenames>Chuang</forenames></author><author><keyname>Yeung</keyname><forenames>Chi Ho</forenames></author><author><keyname>Zhang</keyname><forenames>Zi-Ke</forenames></author></authors><title>Self-organization in social tagging systems</title><categories>physics.soc-ph cs.SI</categories><comments>6 pages, 6 figures</comments><journal-ref>Physical Review E 83, 066104 (2011)</journal-ref><doi>10.1103/PhysRevE.83.066104</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Individuals often imitate each other to fall into the typical group, leading
to a self-organized state of typical behaviors in a community. In this paper,
we model self-organization in social tagging systems and illustrate the
underlying interaction and dynamics. Specifically, we introduce a model in
which individuals adjust their own tagging tendency to imitate the average
tagging tendency. We found that when users are of low confidence, they tend to
imitate others and lead to a self-organized state with active tagging. On the
other hand, when users are of high confidence and are stubborn for changes,
tagging becomes inactive. We observe a phase transition at a critical level of
user confidence when the system changes from one regime to the other. The
distributions of post length obtained from the model are compared to real data
which show good agreements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4005</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4005</id><created>2011-02-19</created><authors><author><keyname>Berman</keyname><forenames>Piotr</forenames></author><author><keyname>DasGupta</keyname><forenames>Bhaskar</forenames></author></authors><title>Approximating the Online Set Multicover Problems Via Randomized
  Winnowing</title><categories>cs.DS cs.CC cs.DM</categories><comments>22 pages</comments><msc-class>68Q25, 68R05</msc-class><acm-class>F.2.2; G.2.3</acm-class><journal-ref>Theoretical Computer Science, 393 (1-3), 54-71, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the weighted online set k-multicover problem. In
this problem, we have a universe V of elements, a family S of subsets of V with
a positive real cost for every set in S and a &quot;coverage factor&quot; (positive
integer) k. A subset of elements are presented online in an arbitrary order.
When each element, say i, is presented, we are also told the collection of all
(at least k) sets and their costs to which i belongs and we need to select
additional sets from these sets containing i, if necessary, such that our
collection of selected sets contains at least k sets that contain the element
i. The goal is to minimize the total cost of the selected sets (our algorithm
and competitive ratio bounds can be extended to the case when a set can be
selected at most a pre-specified number of times instead of just once; we do
not report these extensions for simplicity and also because they have no
relevance to the biological applications that motivated our work). In this
paper, we describe a new randomized algorithm for the online multicover problem
based on a randomized version of the winnowing approach of Littlestone. This
algorithm generalizes and improves some earlier results by N. Alon, B.
Awerbuch, Y. Azar, N. Buchbinder, and J. Naor. We also discuss lower bounds on
competitive ratios for deterministic algorithms for general $k$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4016</identifier>
 <datestamp>2011-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4016</id><created>2011-02-19</created><authors><author><keyname>Andreotti</keyname><forenames>Sandro</forenames></author><author><keyname>Klau</keyname><forenames>Gunnar W.</forenames></author><author><keyname>Reinert</keyname><forenames>Knut</forenames></author></authors><title>Antilope - A Lagrangian Relaxation Approach to the de novo Peptide
  Sequencing Problem</title><categories>cs.DS q-bio.QM</categories><doi>10.1109/TCBB.2011.59</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Peptide sequencing from mass spectrometry data is a key step in proteome
research. Especially de novo sequencing, the identification of a peptide from
its spectrum alone, is still a challenge even for state-of-the-art algorithmic
approaches. In this paper we present Antilope, a new fast and flexible approach
based on mathematical programming. It builds on the spectrum graph model and
works with a variety of scoring schemes. Antilope combines Lagrangian
relaxation for solving an integer linear programming formulation with an
adaptation of Yen's k shortest paths algorithm. It shows a significant
improvement in running time compared to mixed integer optimization and performs
at the same speed like other state-of-the-art tools. We also implemented a
generic probabilistic scoring scheme that can be trained automatically for a
dataset of annotated spectra and is independent of the mass spectrometer type.
Evaluations on benchmark data show that Antilope is competitive to the popular
state-of-the-art programs PepNovo and NovoHMM both in terms of run time and
accuracy. Furthermore, it offers increased flexibility in the number of
considered ion types. Antilope will be freely available as part of the open
source proteomics library OpenMS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4021</identifier>
 <datestamp>2011-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4021</id><created>2011-02-19</created><updated>2011-09-18</updated><authors><author><keyname>Pathak</keyname><forenames>Manas A.</forenames></author><author><keyname>Sharifi</keyname><forenames>Mehrbod</forenames></author><author><keyname>Raj</keyname><forenames>Bhiksha</forenames></author></authors><title>Privacy Preserving Spam Filtering</title><categories>cs.LG cs.CR</categories><comments>9 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Email is a private medium of communication, and the inherent privacy
constraints form a major obstacle in developing effective spam filtering
methods which require access to a large amount of email data belonging to
multiple users. To mitigate this problem, we envision a privacy preserving spam
filtering system, where the server is able to train and evaluate a logistic
regression based spam classifier on the combined email data of all users
without being able to observe any emails using primitives such as homomorphic
encryption and randomization. We analyze the protocols for correctness and
security, and perform experiments of a prototype system on a large scale spam
filtering task.
  State of the art spam filters often use character n-grams as features which
result in large sparse data representation, which is not feasible to be used
directly with our training and evaluation protocols. We explore various data
independent dimensionality reduction which decrease the running time of the
protocol making it feasible to use in practice while achieving high accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4034</identifier>
 <datestamp>2012-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4034</id><created>2011-02-19</created><updated>2012-03-17</updated><authors><author><keyname>Das</keyname><forenames>Jayita</forenames></author><author><keyname>Alam</keyname><forenames>Syed M.</forenames></author><author><keyname>Rajaram</keyname><forenames>Srinath</forenames></author><author><keyname>Bhanja</keyname><forenames>Sanjukta</forenames></author></authors><title>Hybrid CMOS-MQCA Logic Architectures using Multi-Layer Spintronic
  Devices</title><categories>cs.ET cond-mat.mes-hall</categories><comments>The paper has been withdrawn</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel hybrid CMOS-MQCA architecture using multi-layer Spintronic
devices as computing elements. A feasibility study is presented with 22nm CMOS
where new approaches for spin transfer torque induced clocking and read-out
scheme for variability-tolerance are introduced. A first-of-its-kind Spintronic
device model enables circuit simulation using existing CAD infrastructure.
Approximately 70% reduction in energy consumption is observed when compared
against conventional field-induced clocking scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4037</identifier>
 <datestamp>2011-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4037</id><created>2011-02-19</created><authors><author><keyname>Kumabe</keyname><forenames>Masahiro</forenames></author><author><keyname>Mihara</keyname><forenames>H. Reiju</forenames></author></authors><title>Computability of simple games: A complete investigation of the
  sixty-four possibilities</title><categories>cs.GT cs.LO math.LO</categories><comments>25 pages</comments><msc-class>91A12, 91A13</msc-class><acm-class>F.4.1; F.1.1</acm-class><journal-ref>Journal of Mathematical Economics 47 (2011) 150-158</journal-ref><doi>10.1016/j.jmateco.2010.12.003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Classify simple games into sixteen &quot;types&quot; in terms of the four conventional
axioms: monotonicity, properness, strongness, and nonweakness. Further classify
them into sixty-four classes in terms of finiteness (existence of a finite
carrier) and algorithmic computability. For each such class, we either show
that it is empty or give an example of a game belonging to it. We observe that
if a type contains an infinite game, then it contains both computable ones and
noncomputable ones. This strongly suggests that computability is logically, as
well as conceptually, unrelated to the conventional axioms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4078</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4078</id><created>2011-02-20</created><updated>2011-03-02</updated><authors><author><keyname>Abbas</keyname><forenames>Ash Mohammad</forenames></author></authors><title>An Analytical Model for Service Profile Based Service Quality of an
  Institutional eLibrary</title><categories>cs.DL</categories><comments>6 pages, 3 figures, 1 table</comments><msc-class>68P20, 68P15</msc-class><acm-class>H.3.7; H.2.8; C.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Devising a scheme for evaluating the service quality of an institutional
electronic library is a difficult and challenging task. The challenge comes
from the fact that the services provided by an institutional electronic library
depend upon the contents requested by the users and the contents housed by the
library. Different types of users might be interested in different types of
contents. In this paper, we propose a technique for evaluating the service
quality of an institutional electronic library. Our scheme is based on the
service profiles of contents requested by the users at the server side which is
hosted at the library. Further, we propose models to analyze the service
quality of an electronic library. For analyzing the service quality, we present
two analytical models. The first one is based on the number of days by which
the item to be served by the library is delayed and the penalty points per day
for the duration for which the item is delayed. The second model is based on
the credits earned by the library if the item is served in a timely fashion,
and the penalties, thereof, if the item is delayed. These models may help in
evaluating the service quality of an electronic library and taking the
corrective measures to improve it.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4085</identifier>
 <datestamp>2011-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4085</id><created>2011-02-20</created><authors><author><keyname>Tuninetti</keyname><forenames>Daniela</forenames></author></authors><title>On the Benefits of Partial Channel State Information for Repetition
  Protocols in Block Fading Channels</title><categories>cs.IT math.IT</categories><comments>Accepted for publication on IEEE Transactions on Information Theory;
  Presented in parts at ITW 2007 and ICC 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the throughput performance of HARQ (hybrid automatic
repeat request) protocols over block fading Gaussian channels. It proposes new
protocols that use the available feedback bit(s) not only to request a
retransmission, but also to inform the transmitter about the instantaneous
channel quality. An explicit protocol construction is given for any number of
retransmissions and any number of feedback bits. The novel protocol is shown to
simultaneously realize the gains of HARQ and of power control with partial CSI
(channel state information). Remarkable throughput improvements are shown,
especially at low and moderate SNR (signal to noise ratio), with respect to
protocols that use the feedback bits for retransmission request only. In
particular, for the case of a single retransmission and a single feedback bit,
it is shown that the repetition is not needed at low $\snr$ where the
throughput improvement is due to power control only. On the other hand, at high
SNR, the repetition is useful and the performance gain comes form a combination
of power control and ability of make up for deep fades.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4086</identifier>
 <datestamp>2012-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4086</id><created>2011-02-20</created><updated>2012-09-26</updated><authors><author><keyname>Czaja</keyname><forenames>Wojciech</forenames></author><author><keyname>Ehler</keyname><forenames>Martin</forenames></author></authors><title>Schroedinger Eigenmaps for the Analysis of Bio-Medical Data</title><categories>cs.CE physics.data-an physics.med-ph q-bio.QM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce Schroedinger Eigenmaps, a new semi-supervised manifold learning
and recovery technique. This method is based on an implementation of graph
Schroedinger operators with appropriately constructed barrier potentials as
carriers of labeled information. We use our approach for the analysis of
standard bio-medical datasets and new multispectral retinal images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4099</identifier>
 <datestamp>2011-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4099</id><created>2011-02-20</created><updated>2011-08-29</updated><authors><author><keyname>Kakhaki</keyname><forenames>A. Makhdoumi</forenames></author><author><keyname>Abadi</keyname><forenames>H. Karkeh</forenames></author><author><keyname>Pad</keyname><forenames>P.</forenames></author><author><keyname>Saeedi</keyname><forenames>H.</forenames></author><author><keyname>Marvasti</keyname><forenames>F.</forenames></author><author><keyname>Alishahi</keyname><forenames>K.</forenames></author></authors><title>Capacity Achieving Linear Codes with Random Binary Sparse Generating
  Matrices</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE transaction on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we prove the existence of capacity achieving linear codes with
random binary sparse generating matrices. The results on the existence of
capacity achieving linear codes in the literature are limited to the random
binary codes with equal probability generating matrix elements and sparse
parity-check matrices. Moreover, the codes with sparse generating matrices
reported in the literature are not proved to be capacity achieving.
  As opposed to the existing results in the literature, which are based on
optimal maximum a posteriori decoders, the proposed approach is based on a
different decoder and consequently is suboptimal. We also demonstrate an
interesting trade-off between the sparsity of the generating matrix and the
error exponent (a constant which determines how exponentially fast the
probability of error decays as block length tends to infinity). An interesting
observation is that for small block sizes, less sparse generating matrices have
better performances while for large blok sizes, the performance of the random
generating matrices become independent of the sparsity. Moreover, we prove the
existence of capacity achieving linear codes with a given (arbitrarily low)
density of ones on rows of the generating matrix. In addition to proving the
existence of capacity achieving sparse codes, an important conclusion of our
paper is that for a sufficiently large code length, no search is necessary in
practice to find a deterministic matrix by proving that any arbitrarily
selected sequence of sparse generating matrices is capacity achieving with high
probability. The focus in this paper is on the binary symmetric and binary
erasure channels.her discrete memory-less symmetric channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4100</identifier>
 <datestamp>2011-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4100</id><created>2011-02-20</created><authors><author><keyname>Fernandes</keyname><forenames>Cristina G.</forenames></author><author><keyname>Stein</keyname><forenames>Maya</forenames></author></authors><title>Geodesic stability for memoryless binary long-lived consensus</title><categories>cs.DM cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The determination of the stability of the long-lived consensus problem is a
fundamental open problem in distributed systems. We concentrate on the
memoryless binary case with geodesic paths. We offer a conjecture on the
stability in this case, exhibit two classes of colourings which attain this
conjectured bound, and improve the known lower bounds for all colourings. We
also introduce a related parameter, which measures the stability only for
certain geodesics, and for which we also prove lower bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4104</identifier>
 <datestamp>2011-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4104</id><created>2011-02-20</created><authors><author><keyname>Fang</keyname><forenames>Gang</forenames></author><author><keyname>Wang</keyname><forenames>Wen</forenames></author><author><keyname>Oatley</keyname><forenames>Benjamin</forenames></author><author><keyname>Van Ness</keyname><forenames>Brian</forenames></author><author><keyname>Steinbach</keyname><forenames>Michael</forenames></author><author><keyname>Kumar</keyname><forenames>Vipin</forenames></author></authors><title>Characterizing Discriminative Patterns</title><categories>cs.DB cs.IT math.IT q-bio.GN</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Discriminative patterns are association patterns that occur with
disproportionate frequency in some classes versus others, and have been studied
under names such as emerging patterns and contrast sets. Such patterns have
demonstrated considerable value for classification and subgroup discovery, but
a detailed understanding of the types of interactions among items in a
discriminative pattern is lacking. To address this issue, we propose to
categorize discriminative patterns according to four types of item interaction:
(i) driver-passenger, (ii) coherent, (iii) independent additive and (iv)
synergistic beyond independent additive. Either of the last three is of
practical importance, with the latter two representing a gain in the
discriminative power of a pattern over its subsets. Synergistic patterns are
most restrictive, but perhaps the most interesting since they capture a
cooperative effect. For domains such as genetic research, differentiating among
these types of patterns is critical since each yields very different biological
interpretations. For general domains, the characterization provides a novel
view of the nature of the discriminative patterns in a dataset, which yields
insights beyond those provided by current approaches that focus mostly on
pattern-based classification and subgroup discovery. This paper presents a
comprehensive discussion that defines these four pattern types and investigates
their properties and their relationship to one another. In addition, these
ideas are explored for a variety of datasets (ten UCI datasets, one gene
expression dataset and two genetic-variation datasets). The results demonstrate
the existence, characteristics and statistical significance of the different
types of patterns. They also illustrate how pattern characterization can
provide novel insights into discriminative pattern mining and the
discriminative structure of different datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4106</identifier>
 <datestamp>2011-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4106</id><created>2011-02-20</created><authors><author><keyname>Kwak</keyname><forenames>Kyung Sup</forenames></author><author><keyname>Ullah</keyname><forenames>Sana</forenames></author><author><keyname>Ullah</keyname><forenames>Niamat</forenames></author></authors><title>An Overview of IEEE 802.15.6 Standard</title><categories>cs.NI</categories><comments>This paper was invited for presentation in 3rd International
  Symposium on Applied Sciences in Biomedical and Communication Technologies
  (ISABEL 2010) in Rome, Italy</comments><doi>10.1109/ISABEL.2010.5702867</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless Body Area Networks (WBAN) has emerged as a key technology to provide
real-time health monitoring of a patient and diagnose many life threatening
diseases. WBAN operates in close vicinity to, on, or inside a human body and
supports a variety of medical and non-medical applications. IEEE 802 has
established a Task Group called IEEE 802.15.6 for the standardization of WBAN.
The purpose of the group is to establish a communication standard optimized for
low-power in-body/on-body nodes to serve a variety of medical and non-medical
applications. This paper explains the most important features of the new IEEE
802.15.6 standard. The standard defines a Medium Access Control (MAC) layer
supporting several Physical (PHY) layers. We briefly overview the PHY and MAC
layers specifications together with the bandwidth efficiency of IEEE 802.15.6
standard. We also discuss the security paradigm of the standard.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4117</identifier>
 <datestamp>2011-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4117</id><created>2011-02-20</created><authors><author><keyname>Ehlers</keyname><forenames>R&#xfc;diger</forenames><affiliation>Saarland University</affiliation></author></authors><title>Experimental Aspects of Synthesis</title><categories>cs.LO</categories><comments>In Proceedings iWIGP 2011, arXiv:1102.3741</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 50, 2011, pp. 1-16</journal-ref><doi>10.4204/EPTCS.50.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss the problem of experimentally evaluating linear-time temporal
logic (LTL) synthesis tools for reactive systems. We first survey previous such
work for the currently publicly available synthesis tools, and then draw
conclusions by deriving useful schemes for future such evaluations.
  In particular, we explain why previous tools have incompatible scopes and
semantics and provide a framework that reduces the impact of this problem for
future experimental comparisons of such tools. Furthermore, we discuss which
difficulties the complex workflows that begin to appear in modern synthesis
tools induce on experimental evaluations and give answers to the question how
convincing such evaluations can still be performed in such a setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4118</identifier>
 <datestamp>2011-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4118</id><created>2011-02-20</created><authors><author><keyname>von Essen</keyname><forenames>Christian</forenames><affiliation>UJF/Verimag Grenoble, France</affiliation></author><author><keyname>Jobstmann</keyname><forenames>Barbara</forenames><affiliation>CNRS/Verimag Grenoble, France</affiliation></author></authors><title>Synthesizing Systems with Optimal Average-Case Behavior for Ratio
  Objectives</title><categories>cs.LO</categories><comments>In Proceedings iWIGP 2011, arXiv:1102.3741</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 50, 2011, pp. 17-32</journal-ref><doi>10.4204/EPTCS.50.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show how to automatically construct a system that satisfies a given
logical specification and has an optimal average behavior with respect to a
specification with ratio costs.
  When synthesizing a system from a logical specification, it is often the case
that several different systems satisfy the specification. In this case, it is
usually not easy for the user to state formally which system she prefers. Prior
work proposed to rank the correct systems by adding a quantitative aspect to
the specification. A desired preference relation can be expressed with (i) a
quantitative language, which is a function assigning a value to every possible
behavior of a system, and (ii) an environment model defining the desired
optimization criteria of the system, e.g., worst-case or average-case optimal.
  In this paper, we show how to synthesize a system that is optimal for (i) a
quantitative language given by an automaton with a ratio cost function, and
(ii) an environment model given by a labeled Markov decision process. The
objective of the system is to minimize the expected (ratio) costs. The solution
is based on a reduction to Markov Decision Processes with ratio cost functions
which do not require that the costs in the denominator are strictly positive.
We find an optimal strategy for these using a fractional linear program.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4119</identifier>
 <datestamp>2011-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4119</id><created>2011-02-20</created><authors><author><keyname>Morgenstern</keyname><forenames>Andreas</forenames><affiliation>University Kaiserslautern</affiliation></author><author><keyname>Schneider</keyname><forenames>Klaus</forenames><affiliation>University Kaiserslautern</affiliation></author></authors><title>A LTL Fragment for GR(1)-Synthesis</title><categories>cs.LO</categories><comments>In Proceedings iWIGP 2011, arXiv:1102.3741</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 50, 2011, pp. 33-45</journal-ref><doi>10.4204/EPTCS.50.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The idea of automatic synthesis of reactive programs starting from temporal
logic (LTL) specifications is quite old, but was commonly thought to be
infeasible due to the known double exponential complexity of the problem.
However, new ideas have recently renewed the interest in LTL synthesis: One
major new contribution in this area is the recent work of Piterman et al. who
showed how polynomial time synthesis can be achieved for a large class of LTL
specifications that is expressive enough to cover many practical examples.
These LTL specifications are equivalent to omega-automata having a so-called
GR(1) acceptance condition. This approach has been used to automatically
synthesize implementations of real-world applications. To this end, manually
written deterministic omega-automata having GR(1) conditions were used instead
of the original LTL specifications. However, manually generating deterministic
monitors is, of course, a hard and error-prone task. In this paper, we
therefore present algorithms to automatically translate specifications of a
remarkable large fragment of LTL to deterministic monitors having a GR(1)
acceptance condition so that the synthesis algorithms can start with more
readable LTL specifications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4120</identifier>
 <datestamp>2011-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4120</id><created>2011-02-20</created><authors><author><keyname>Gelderie</keyname><forenames>Marcus</forenames><affiliation>RWTH Aachen University</affiliation></author><author><keyname>Holtmann</keyname><forenames>Michael</forenames><affiliation>RWTH Aachen University</affiliation></author></authors><title>Memory Reduction via Delayed Simulation</title><categories>cs.GT</categories><comments>In Proceedings iWIGP 2011, arXiv:1102.3741</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 50, 2011, pp. 46-60</journal-ref><doi>10.4204/EPTCS.50.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address a central (and classical) issue in the theory of infinite games:
the reduction of the memory size that is needed to implement winning strategies
in regular infinite games (i.e., controllers that ensure correct behavior
against actions of the environment, when the specification is a regular
omega-language). We propose an approach which attacks this problem before the
construction of a strategy, by first reducing the game graph that is obtained
from the specification. For the cases of specifications represented by
&quot;request-response&quot;-requirements and general &quot;fairness&quot; conditions, we show that
an exponential gain in the size of memory is possible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4121</identifier>
 <datestamp>2011-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4121</id><created>2011-02-20</created><authors><author><keyname>Doyen</keyname><forenames>Laurent</forenames><affiliation>LSV, ENS Cachan &amp; CNRS, France</affiliation></author><author><keyname>Massart</keyname><forenames>Thierry</forenames><affiliation>Universit&#xe9; Libre de Bruxelles, Belgium</affiliation></author><author><keyname>Shirmohammadi</keyname><forenames>Mahsa</forenames><affiliation>Universit&#xe9; Libre de Bruxelles, Belgium</affiliation></author></authors><title>Synchronizing Objectives for Markov Decision Processes</title><categories>cs.LO cs.CC</categories><comments>In Proceedings iWIGP 2011, arXiv:1102.3741</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 50, 2011, pp. 61-75</journal-ref><doi>10.4204/EPTCS.50.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce synchronizing objectives for Markov decision processes (MDP).
Intuitively, a synchronizing objective requires that eventually, at every step
there is a state which concentrates almost all the probability mass. In
particular, it implies that the probabilistic system behaves in the long run
like a deterministic system: eventually, the current state of the MDP can be
identified with almost certainty.
  We study the problem of deciding the existence of a strategy to enforce a
synchronizing objective in MDPs. We show that the problem is decidable for
general strategies, as well as for blind strategies where the player cannot
observe the current state of the MDP. We also show that pure strategies are
sufficient, but memory may be necessary.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4126</identifier>
 <datestamp>2011-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4126</id><created>2011-02-20</created><updated>2011-02-22</updated><authors><author><keyname>Nagananda</keyname><forenames>K. G.</forenames></author><author><keyname>Mohapatra</keyname><forenames>Parthajit</forenames></author><author><keyname>Murthy</keyname><forenames>Chandra R.</forenames></author><author><keyname>Kishore</keyname><forenames>Shalinee</forenames></author></authors><title>Multiuser Cognitive Radio Networks: An Information Theoretic Perspective</title><categories>cs.IT math.IT</categories><comments>50 pages, 15 figures, submitted to IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Achievable rate regions and outer bounds are derived for three-user
interference channels where the transmitters cooperate in a unidirectional
manner via a noncausal message-sharing mechanism. The three-user channel
facilitates different ways of message-sharing between the primary and secondary
(or cognitive) transmitters. Three natural extensions of unidirectional
message-sharing from two users to three users are introduced: (i) Cumulative
message sharing; (ii) primary-only message sharing; and (iii) cognitive-only
message sharing. To emphasize the notion of interference management, channels
are classified based on different rate-splitting strategies at the
transmitters. Standard techniques, superposition coding and Gel'fand-Pinsker's
binning principle, are employed to derive an achievable rate region for each of
the cognitive interference channels. Simulation results for the Gaussian
channel case are presented; they enable visual comparison of the achievable
rate regions for different message-sharing schemes along with the outer bounds.
These results also provide useful insights into the effect of rate-splitting at
the transmitters, which aids in better interference management at the
receivers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4129</identifier>
 <datestamp>2011-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4129</id><created>2011-02-20</created><updated>2011-10-04</updated><authors><author><keyname>Roy</keyname><forenames>Swapnoneel</forenames></author><author><keyname>Rudra</keyname><forenames>Atri</forenames></author></authors><title>An FPTAS for the Lead-Based Multiple Video Transmission LMVT Problem</title><categories>cs.DS cs.CC cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Lead-Based Multiple Video Transmission (LMVT) problem is motivated by
applications in managing the quality of experience (QoE) of video streaming for
mobile clients. In an earlier work, the LMVT problem has been shown to be
NP-hard for a specific bit-to-lead conversion function $\phi$. In this work, we
show the problem to be NP-hard even if the function $\phi$ is linear. We then
design a fully polynomial time approximation scheme (FPTAS) for the problem.
This problem is exactly equivalent to the Santa Clause Problem on which there
has been a lot of work done off-late.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4132</identifier>
 <datestamp>2012-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4132</id><created>2011-02-21</created><updated>2012-09-17</updated><authors><author><keyname>Zhu</keyname><forenames>Jinxia</forenames></author></authors><title>Optimal dividend control for a generalized risk model with investment
  incomes and debit interest</title><categories>math.OC cs.SY q-fin.RM</categories><msc-class>91B30, 93E20, 49L25</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates dividend optimization of an insurance corporation
under a more realistic model which takes into consideration refinancing or
capital injections. The model follows the compound Poisson framework with
credit interest for positive reserve, and debit interest for negative reserve.
Ruin occurs when the reserve drops below the critical value. The company
controls the dividend pay-out dynamically with the objective to maximize the
expected total discounted dividends until ruin. We show that that the optimal
strategy is a band strategy and it is optimal to pay no dividends when the
reserve is negative.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4135</identifier>
 <datestamp>2011-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4135</id><created>2011-02-21</created><authors><author><keyname>He</keyname><forenames>Wenbo</forenames></author><author><keyname>Liu</keyname><forenames>Xue</forenames></author><author><keyname>Ren</keyname><forenames>Mai</forenames></author></authors><title>Location Cheating: A Security Challenge to Location-based Social Network
  Services</title><categories>cs.SI cs.CR</categories><comments>10 pages, 8 figures, accepted by the 31st International Conference on
  Distributed Computing Systems (ICDCS 2011)</comments><acm-class>C.2.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Location-based mobile social network services such as foursquare and Gowalla
have grown exponentially over the past several years. These location-based
services utilize the geographical position to enrich user experiences in a
variety of contexts, including location-based searching and location-based
mobile advertising. To attract more users, the location-based mobile social
network services provide real-world rewards to the user, when a user checks in
at a certain venue or location. This gives incentives for users to cheat on
their locations. In this report, we investigate the threat of location cheating
attacks, find the root cause of the vulnerability, and outline the possible
defending mechanisms. We use foursquare as an example to introduce a novel
location cheating attack, which can easily pass the current location
verification mechanism (e.g., cheater code of foursquare). We also crawl the
foursquare website. By analyzing the crawled data, we show that automated large
scale cheating is possible. Through this work, we aim to call attention to
location cheating in mobile social network services and provide insights into
the defending mechanisms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4137</identifier>
 <datestamp>2011-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4137</id><created>2011-02-21</created><authors><author><keyname>Hucher</keyname><forenames>Charlotte</forenames></author><author><keyname>Sadeghi</keyname><forenames>Parastoo</forenames></author></authors><title>Using Distributed Rotations for a Low-Complexity Dynamic
  Decode-and-Forward Relay Protocol</title><categories>cs.IT math.IT</categories><comments>5 pages, to be presented in ICC 2011 in Kyoto, Japan</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose to implement the dynamic decode-and-forward (DDF)
protocol with distributed rotations. In addition to being the first
minimum-delay implementation of the DDF protocol proposed for any number of
relays, this technique allows to exploit cooperative diversity without inducing
the high decoding complexity of a space-time code. The analysis of outage
probabilities for different number of relays and rotations shows that the
performance of this technique is close to optimal. Moreover, a lower-bound on
the diversity-multiplexing gain tradeoff (DMT) is provided in the case of a
single relay and two rotations. This lower-bound reaches the optimal DDF's DMT
when the frame-length grows to infinity, which shows that even a small number
of rotations is enough to obtain good performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4162</identifier>
 <datestamp>2011-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4162</id><created>2011-02-21</created><authors><author><keyname>Jilani</keyname><forenames>Atif A. A.</forenames></author><author><keyname>Usman</keyname><forenames>Muhammad</forenames></author><author><keyname>Nadeem</keyname><forenames>Aamer</forenames></author></authors><title>Comparative Study on DFD to UML Diagrams Transformations</title><categories>cs.SE</categories><comments>7 pages; ISSN: 2221-0741</comments><journal-ref>World of Computer Science and Information Technology
  Journal(WCSIT), Vol. 1, No.1,10-16, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most of legacy systems use nowadays were modeled and documented using
structured approach. Expansion of these systems in terms of functionality and
maintainability requires shift towards object-oriented documentation and
design, which has been widely accepted by the industry. In this paper, we
present a survey of the existing Data Flow Diagram (DFD) to Unified Modeling
language (UML) transformation techniques. We analyze transformation techniques
using a set of parameters, identified in the survey. Based on identified
parameters, we present an analysis matrix, which describes the strengths and
weaknesses of transformation techniques. It is observed that most of the
transformation approaches are rule based, which are incomplete and defined at
abstract level that does not cover in depth transformation and automation
issues. Transformation approaches are data centric, which focuses on data-store
for class diagram generation. Very few of the transformation techniques have
been applied on case study as a proof of concept, which are not comprehensive
and majority of them are partially automated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4176</identifier>
 <datestamp>2011-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4176</id><created>2011-02-21</created><authors><author><keyname>Duan</keyname><forenames>Lingjie</forenames></author><author><keyname>Gao</keyname><forenames>Lin</forenames></author><author><keyname>Huang</keyname><forenames>Jianwei</forenames></author></authors><title>Contract-Based Cooperative Spectrum Sharing</title><categories>cs.NI</categories><comments>Part of this paper has appeared in IEEE DySPAN 2011, and this version
  has been submitted to IEEE J-SAC</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Providing proper economic incentives is essential for the success of dynamic
spectrum sharing. Cooperative spectrum sharing is one effective way to achieve
this goal. In cooperative spectrum sharing, secondary users (SUs) relay
traffics for primary users (PUs), in exchange for dedicated transmission time
for the SUs' own communication needs. In this paper, we study the cooperative
spectrum sharing under incomplete information, where SUs' types (capturing
their heterogeneity in relay channel gains and evaluations of power
consumptions) are private information and not known by PUs. Inspired by the
contract theory, we model the network as a labor market. The single PU is the
employer who offers a contract to the SUs. The contract consists of a set of
contract items representing combinations of spectrum accessing time (i.e.,
reward) and relaying power (i.e., contribution). The SUs are employees, and
each of them selects the best contract item to maximize his payoff. We study
the optimal contract design for both weak and strong incomplete information
scenarios. First, we provide necessary and sufficient conditions for feasible
contracts in both scenarios. In the weak incomplete information scenario, we
further derive the optimal contract that achieves the same maximum PU's utility
as in the complete information benchmark. In the strong incomplete information
scenario, we propose a Decompose-and-Compare algorithm that achieves a
close-to-optimal contract. We future show that the PU's average utility loss
due to the suboptimal algorithm and the strong incomplete information are both
relatively small (less than 2% and 1:3%, respectively, in our numerical results
with two SU types).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4178</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4178</id><created>2011-02-21</created><authors><author><keyname>Jureta</keyname><forenames>Ivan</forenames></author><author><keyname>Borgida</keyname><forenames>Alexander</forenames></author><author><keyname>Ernst</keyname><forenames>Neil A.</forenames></author></authors><title>Mixed-Variable Requirements Roadmaps and their Role in the Requirements
  Engineering of Adaptive Systems</title><categories>cs.SE</categories><acm-class>D.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The requirements roadmap concept is introduced as a solution to the problem
of the requirements engineering of adaptive systems. The concept requires a new
general definition of the requirements problem which allows for quantitative
(numeric) variables, together with qualitative (binary boolean) propositional
variables, and distinguishes monitored from controlled variables for use in
control loops. We study the consequences of these changes, and argue that the
requirements roadmap concept bridges the gap between current general
definitions of the requirements problem and its notion of solution, and the
research into the relaxation of requirements, the evaluation of their partial
satisfaction, and the monitoring and control of requirements, all topics of
particular interest in the engineering of requirements for adaptive systems
[Cheng et al. 2009]. From the theoretical perspective, we show clearly and
formally the fundamental differences between more traditional conception of
requirements engineering (e.g., Zave &amp; Jackson [1997]) and the requirements
engineering of adaptive systems (from Fickas &amp; Feather [1995], over Letier &amp;
van Lamsweerde [2004], and up to Whittle et al. [2010] and the most recent
research). From the engineering perspective, we define a proto-framework for
early requirements engineering of adaptive systems, which illustrates the
features needed in future requirements frameworks for this class of systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4179</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4179</id><created>2011-02-21</created><authors><author><keyname>Mosincat</keyname><forenames>Adina</forenames></author></authors><title>Runtime Adaptability driven by Negotiable Quality Requirements</title><categories>cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Two of the common features of business and the web are diversity and
dynamism. Diversity results in users having different preferences for the
quality requirements of a system. Diversity also makes possible alternative
implementations for functional requirements, called variants, each of them
providing different quality. The quality provided by the system may vary due to
different variant components and changes in the environment. The challenge is
to dynamically adapt to quality variations and to find the variant that best
fulfills the multi-criteria quality requirements driven by user preferences and
current runtime conditions. For service-oriented systems this challenge is
augmented by their distributed nature and lack of control over the constituent
services and their provided quality of service (QoS). We propose a novel
approach to runtime adaptability that detects QoS changes, updates the system
model with runtime information, and uses the model to select the variant to
execute at runtime. We introduce negotiable maintenance goals to express user
quality preferences in the requirements model and automatically interpret them
quantitatively for system execution. Our lightweight selection strategy selects
the variant that best fulfills the user required multi-criteria QoS based on
updated QoS values.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4180</identifier>
 <datestamp>2011-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4180</id><created>2011-02-21</created><authors><author><keyname>Hladik</keyname><forenames>Milan</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Daney</keyname><forenames>David</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Tsigaridas</keyname><forenames>Elias</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author></authors><title>Characterizing and approximating eigenvalue sets of symmetric interval
  matrices</title><categories>cs.RO</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the eigenvalue problem for the case where the input matrix is
symmetric and its entries perturb in some given intervals. We present a
characterization of some of the exact boundary points, which allows us to
introduce an inner approximation algorithm, that in many case estimates exact
bounds. To our knowledge, this is the first algorithm that is able to guaran-
tee exactness. We illustrate our approach by several examples and numerical
experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4205</identifier>
 <datestamp>2011-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4205</id><created>2011-02-21</created><updated>2011-04-04</updated><authors><author><keyname>Thielemann</keyname><forenames>Henning</forenames></author></authors><title>An algebra for signal processing</title><categories>cs.NA cs.IT math.IT</categories><comments>15 pages, 1 figure, 1 table, Accepted at International Conference on
  Algebraic Informatics, CAI2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Our paper presents an attempt to axiomatise signal processing. Our long-term
goal is to formulate signal processing algorithms for an ideal world of exact
computation and prove properties about them, then interpret these ideal
formulations and apply them without change to real world discrete data. We give
models of the axioms that are based on Gaussian functions, that allow for exact
computations and automated tests of signal algorithm properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4225</identifier>
 <datestamp>2011-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4225</id><created>2011-02-21</created><authors><author><keyname>Dima</keyname><forenames>Catalin</forenames></author><author><keyname>Tiplea</keyname><forenames>Ferucio Laurentiu</forenames></author></authors><title>Model-checking ATL under Imperfect Information and Perfect Recall
  Semantics is Undecidable</title><categories>cs.LO cs.MA</categories><msc-class>03B44, 03B42, 68Q60</msc-class><acm-class>F.4.1; D.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a formal proof of the undecidability of the model checking problem
for alternating- time temporal logic under imperfect information and perfect
recall semantics. This problem was announced to be undecidable according to a
personal communication on multi-player games with imperfect information, but no
formal proof was ever published. Our proof is based on a direct reduction from
the non-halting problem for Turing machines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4240</identifier>
 <datestamp>2011-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4240</id><created>2011-02-21</created><authors><author><keyname>Gripon</keyname><forenames>Vincent</forenames></author><author><keyname>Berrou</keyname><forenames>Claude</forenames></author></authors><title>Sparse neural networks with large learning diversity</title><categories>cs.LG cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Coded recurrent neural networks with three levels of sparsity are introduced.
The first level is related to the size of messages, much smaller than the
number of available neurons. The second one is provided by a particular coding
rule, acting as a local constraint in the neural activity. The third one is a
characteristic of the low final connection density of the network after the
learning phase. Though the proposed network is very simple since it is based on
binary neurons and binary connections, it is able to learn a large number of
messages and recall them, even in presence of strong erasures. The performance
of the network is assessed as a classifier and as an associative memory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4241</identifier>
 <datestamp>2015-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4241</id><created>2011-02-21</created><updated>2012-10-17</updated><authors><author><keyname>Yannopoulou</keyname><forenames>Nikolitsa</forenames></author><author><keyname>Zimourtopoulos</keyname><forenames>Petros</forenames></author></authors><title>Support of Interactive 3D/4D Presentations by the Very First Ever Made
  Virtual Laboratories of Antennas</title><categories>cs.OH physics.comp-ph</categories><comments>Inadequately justified rejection (with reviewers' grades: [4, 4, 3,
  4] + [4, 4, 4, 4] + [2, 4, 4, 4] out of 3 x [5, 5, 5, 5]) from publication to
  the Proceedings of 21st International Conference Radioelektronika 2011, April
  19-20, Brno, Czech Republic - No changes in the paper since [v1] Mon, 21 Feb
  2011 14:52:34 GMT (412kb): [v3] = [v2] = [v1]</comments><journal-ref>FunkTechnikPlus # Journal, Issue 3 - Year 1, 31 January 2014, v1,
  7-18, otoiser ftp#j</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Based on the experience we have gained so far, as independent reviewers of
Radioengineering journal, we thought that may be proved useful to publicly
share with the interested author, especially the young one, some practical
implementations of our ideas for the interactive representation of data using
3D/4D movement and animation, in an attempt to motivate and support her/him in
the development of similar dynamic presentations, when s/he is looking for a
way to locate the stronger aspects of her/his research results in order to
prepare a clear, most appropriate for publication, static presentation figure.
For this purpose, we selected to demonstrate a number of presentations, from
the simplest to the most complicated, concerning well-known antenna issues with
rather hard to imagine details, as it happens perhaps in cases involving
Spherical Coordinates and Polarization, which we created to enrich the very
first ever made Virtual Laboratories of Antennas, that we distribute over the
Open Internet through our website Virtual Antennas. These presentations were
developed in a general way, without using antenna simulators, to handle output
text and image data from third-party CAS Computer Algebra Systems, such as the
Mathematica commercial software we use or the Maxima FLOSS we track its
evolution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4258</identifier>
 <datestamp>2011-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4258</id><created>2011-02-21</created><authors><author><keyname>Boyer</keyname><forenames>E.</forenames></author><author><keyname>Bronstein</keyname><forenames>A. M.</forenames></author><author><keyname>Bronstein</keyname><forenames>M. M.</forenames></author><author><keyname>Bustos</keyname><forenames>B.</forenames></author><author><keyname>Darom</keyname><forenames>T.</forenames></author><author><keyname>Horaud</keyname><forenames>R.</forenames></author><author><keyname>Hotz</keyname><forenames>I.</forenames></author><author><keyname>Keller</keyname><forenames>Y.</forenames></author><author><keyname>Keustermans</keyname><forenames>J.</forenames></author><author><keyname>Kovnatsky</keyname><forenames>A.</forenames></author><author><keyname>Litman</keyname><forenames>R.</forenames></author><author><keyname>Reininghaus</keyname><forenames>J.</forenames></author><author><keyname>Sipiran</keyname><forenames>I.</forenames></author><author><keyname>Smeets</keyname><forenames>D.</forenames></author><author><keyname>Suetens</keyname><forenames>P.</forenames></author><author><keyname>Vandermeulen</keyname><forenames>D.</forenames></author><author><keyname>Zaharescu</keyname><forenames>A.</forenames></author><author><keyname>Zobel</keyname><forenames>V.</forenames></author></authors><title>SHREC 2011: robust feature detection and description benchmark</title><categories>cs.CV</categories><comments>This is a full version of the SHREC'11 report published in 3DOR</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Feature-based approaches have recently become very popular in computer vision
and image analysis applications, and are becoming a promising direction in
shape retrieval. SHREC'11 robust feature detection and description benchmark
simulates the feature detection and description stages of feature-based shape
retrieval algorithms. The benchmark tests the performance of shape feature
detectors and descriptors under a wide variety of transformations. The
benchmark allows evaluating how algorithms cope with certain classes of
transformations and strength of the transformations that can be dealt with. The
present paper is a report of the SHREC'11 robust feature detection and
description benchmark results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4272</identifier>
 <datestamp>2011-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4272</id><created>2011-02-21</created><authors><author><keyname>Muralidharan</keyname><forenames>Vijayvaradharaj T</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>Bounds on the Achievable Rate for the Fading Relay Channel with Finite
  Input Constellations</title><categories>cs.IT math.IT</categories><comments>9 pages, 16 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the wireless Rayleigh fading relay channel with finite complex
input constellations. Assuming global knowledge of the channel state
information and perfect synchronization, upper and lower bounds on the
achievable rate, for the full-duplex relay, as well as the more practical
half-duplex relay (in which the relay cannot transmit and receive
simultaneously), are studied. Assuming the power constraint at the source node
and the relay node to be equal, the gain in rate offered by the use of relay
over the direct transmission (without the relay) is investigated. It is shown
that for the case of finite complex input constellations, the relay gain
attains the maximum at a particular SNR and at higher SNRs the relay gain tends
to become zero. Since practical schemes always use finite complex input
constellation, the above result means that the relay offers maximum advantage
over the direct transmission when we operate at a particular SNR and offers no
advantage at very high SNRs. This is contrary to the results already known for
the relay channel with Gaussian input alphabet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4293</identifier>
 <datestamp>2011-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4293</id><created>2011-02-21</created><updated>2011-07-26</updated><authors><author><keyname>Widera</keyname><forenames>Pawe&#x142;</forenames></author><author><keyname>Krasnogor</keyname><forenames>Natalio</forenames></author></authors><title>Protein Models Comparator: Scalable Bioinformatics Computing on the
  Google App Engine Platform</title><categories>cs.CE cs.DC q-bio.BM</categories><comments>10 pages, 6 figures, 5 tables</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The comparison of computer generated protein structural models is an
important element of protein structure prediction. It has many uses including
model quality evaluation, selection of the final models from a large set of
candidates or optimisation of parameters of energy functions used in
template-free modelling and refinement. Although many protein comparison
methods are available online on numerous web servers, they are not well suited
for large scale model comparison: (1) they operate with methods designed to
compare actual proteins, not the models of the same protein, (2) majority of
them offer only a single pairwise structural comparison and are unable to scale
up to a required order of thousands of comparisons. To bridge the gap between
the protein and model structure comparison we have developed the Protein Models
Comparator (pm-cmp). To be able to deliver the scalability on demand and handle
large comparison experiments the pm-cmp was implemented &quot;in the cloud&quot;.
  Protein Models Comparator is a scalable web application for a fast
distributed comparison of protein models with RMSD, GDT TS, TM-score and
Q-score measures. It runs on the Google App Engine (GAE) cloud platform and is
a showcase of how the emerging PaaS (Platform as a Service) technology could be
used to simplify the development of scalable bioinformatics services. The
functionality of pm-cmp is accessible through API which allows a full
automation of the experiment submission and results retrieval. Protein Models
Comparator is free software released on the Affero GNU Public Licence and is
available with its source code at: http://www.infobiotics.org/pm-cmp
  This article presents a new web application addressing the need for a
large-scale model-specific protein structure comparison and provides an insight
into the GAE (Google App Engine) platform and its usefulness in scientific
computing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4311</identifier>
 <datestamp>2011-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4311</id><created>2011-02-21</created><authors><author><keyname>Maleh</keyname><forenames>Ray</forenames></author></authors><title>Improved RIP Analysis of Orthogonal Matching Pursuit</title><categories>cs.DS math.FA stat.ML</categories><comments>Submitted to ACHA</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Orthogonal Matching Pursuit (OMP) has long been considered a powerful
heuristic for attacking compressive sensing problems; however, its theoretical
development is, unfortunately, somewhat lacking. This paper presents an
improved Restricted Isometry Property (RIP) based performance guarantee for
T-sparse signal reconstruction that asymptotically approaches the conjectured
lower bound given in Davenport et al. We also further extend the
state-of-the-art by deriving reconstruction error bounds for the case of
general non-sparse signals subjected to measurement noise. We then generalize
our results to the case of K-fold Orthogonal Matching Pursuit (KOMP). We finish
by presenting an empirical analysis suggesting that OMP and KOMP outperform
other compressive sensing algorithms in average case scenarios. This turns out
to be quite surprising since RIP analysis (i.e. worst case scenario) suggests
that these matching pursuits should perform roughly T^0.5 times worse than
convex optimization, CoSAMP, and Iterative Thresholding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4315</identifier>
 <datestamp>2011-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4315</id><created>2011-02-21</created><authors><author><keyname>Plyushchenko</keyname><forenames>A. N.</forenames></author><author><keyname>Shur</keyname><forenames>A. M.</forenames></author></authors><title>Almost overlap-free words and the word problem for the free Burnside
  semigroup satisfying x^2=x^3</title><categories>cs.FL math.GR</categories><comments>33 pages, submitted to Internat. J. of Algebra and Comput</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we investigate the word problem of the free Burnside semigroup
satisfying x^2=x^3 and having two generators. Elements of this semigroup are
classes of equivalent words. A natural way to solve the word problem is to
select a unique &quot;canonical&quot; representative for each equivalence class. We prove
that overlap-free words and so-called almost overlap-free words (this notion is
some generalization of the notion of overlap-free words) can serve as canonical
representatives for corresponding equivalence classes. We show that such a word
in a given class, if any, can be efficiently found. As a result, we construct a
linear-time algorithm that partially solves the word problem for the semigroup
under consideration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4326</identifier>
 <datestamp>2011-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4326</id><created>2011-02-21</created><authors><author><keyname>Tschantz</keyname><forenames>Michael Carl</forenames></author><author><keyname>Datta</keyname><forenames>Anupam</forenames></author><author><keyname>Wing</keyname><forenames>Jeannette M.</forenames></author></authors><title>On the Semantics of Purpose Requirements in Privacy Policies</title><categories>cs.CR</categories><comments>34 pages, 3 figures. Tech report, School of Computer Science,
  Carnegie Mellon University. Submitted to the 24th IEEE Computer Security
  Foundations Symposium</comments><report-no>CMU-CS-11-102</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Privacy policies often place requirements on the purposes for which a
governed entity may use personal information. For example, regulations, such as
HIPAA, require that hospital employees use medical information for only certain
purposes, such as treatment. Thus, using formal or automated methods for
enforcing privacy policies requires a semantics of purpose requirements to
determine whether an action is for a purpose or not. We provide such a
semantics using a formalism based on planning. We model planning using a
modified version of Markov Decision Processes, which exclude redundant actions
for a formal definition of redundant. We use the model to formalize when a
sequence of actions is only for or not for a purpose. This semantics enables us
to provide an algorithm for automating auditing, and to describe formally and
compare rigorously previous enforcement methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4346</identifier>
 <datestamp>2011-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4346</id><created>2011-02-21</created><updated>2011-02-24</updated><authors><author><keyname>Majdodin</keyname><forenames>Rooholah</forenames></author></authors><title>BPP is in NP and coNP</title><categories>cs.CC</categories><comments>This paper has been withdrawn</comments><msc-class>68Q15, 68Q87</msc-class><acm-class>F.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the class BPP is in NP and coNP. This paper has been withdrawn
by the author because B and B' are probabilistic and nonequalities 10 cannot be
checked in polynomial time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4360</identifier>
 <datestamp>2012-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4360</id><created>2011-02-21</created><updated>2012-08-13</updated><authors><author><keyname>Dominy</keyname><forenames>Jason</forenames></author><author><keyname>Rabitz</keyname><forenames>Herschel</forenames></author></authors><title>Dynamic Homotopy and Landscape Dynamical Set Topology in Quantum Control</title><categories>quant-ph cs.SY math.OC</categories><comments>Minor clarifications, and added new appendix addressing scalar
  control of 2-level quantum systems</comments><msc-class>81Q93, 55P05, 55P10</msc-class><journal-ref>J. Math. Phys., 53(8):082201, 2012</journal-ref><doi>10.1063/1.4742375</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We examine the topology of the subset of controls taking a given initial
state to a given final state in quantum control, where &quot;state&quot; may mean a pure
state |\psi&gt;, an ensemble density matrix \rho, or a unitary propagator U(0,T).
The analysis consists in showing that the endpoint map acting on control space
is a Hurewicz fibration for a large class of affine control systems with vector
controls. Exploiting the resulting fibration sequence and the long exact
sequence of basepoint-preserving homotopy classes of maps, we show that the
indicated subset of controls is homotopy equivalent to the loopspace of the
state manifold. This not only allows us to understand the connectedness of
&quot;dynamical sets&quot; realized as preimages of subsets of the state space through
this endpoint map, but also provides a wealth of additional topological
information about such subsets of control space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4374</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4374</id><created>2011-02-21</created><authors><author><keyname>Narayanan</keyname><forenames>Arvind</forenames></author><author><keyname>Shi</keyname><forenames>Elaine</forenames></author><author><keyname>Rubinstein</keyname><forenames>Benjamin I. P.</forenames></author></authors><title>Link Prediction by De-anonymization: How We Won the Kaggle Social
  Network Challenge</title><categories>cs.CR cs.LG</categories><comments>11 pages, 13 figures; submitted to IJCNN'2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes the winning entry to the IJCNN 2011 Social Network
Challenge run by Kaggle.com. The goal of the contest was to promote research on
real-world link prediction, and the dataset was a graph obtained by crawling
the popular Flickr social photo sharing website, with user identities scrubbed.
By de-anonymizing much of the competition test set using our own Flickr crawl,
we were able to effectively game the competition. Our attack represents a new
application of de-anonymization to gaming machine learning contests, suggesting
changes in how future competitions should be run.
  We introduce a new simulated annealing-based weighted graph matching
algorithm for the seeding step of de-anonymization. We also show how to combine
de-anonymization with link prediction---the latter is required to achieve good
performance on the portion of the test set not de-anonymized---for example by
training the predictor on the de-anonymized portion of the test set, and
combining probabilistic predictions from de-anonymization and link prediction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4411</identifier>
 <datestamp>2012-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4411</id><created>2011-02-22</created><updated>2012-08-13</updated><authors><author><keyname>Nazer</keyname><forenames>Bobak</forenames></author><author><keyname>Shkel</keyname><forenames>Yanina</forenames></author><author><keyname>Draper</keyname><forenames>Stark C.</forenames></author></authors><title>The AWGN Red Alert Problem</title><categories>cs.IT math.IT</categories><comments>13 pages, 10 figures, To appear in IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider the following unequal error protection scenario. One special
message, dubbed the &quot;red alert&quot; message, is required to have an extremely small
probability of missed detection. The remainder of the messages must keep their
average probability of error and probability of false alarm below a certain
threshold. The goal then is to design a codebook that maximizes the error
exponent of the red alert message while ensuring that the average probability
of error and probability of false alarm go to zero as the blocklength goes to
infinity. This red alert exponent has previously been characterized for
discrete memoryless channels. This paper completely characterizes the optimal
red alert exponent for additive white Gaussian noise channels with block power
constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4423</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4423</id><created>2011-02-22</created><authors><author><keyname>Biely</keyname><forenames>Martin</forenames></author><author><keyname>Robinson</keyname><forenames>Peter</forenames></author><author><keyname>Schmid</keyname><forenames>Ulrich</forenames></author></authors><title>Solving k-Set Agreement with Stable Skeleton Graphs</title><categories>cs.DC</categories><comments>to appear in 16th IEEE Workshop on Dependable Parallel, Distributed
  and Network-Centric Systems</comments><acm-class>C.2.4; F.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider the k-set agreement problem in distributed
message-passing systems using a round-based approach: Both synchrony of
communication and failures are captured just by means of the messages that
arrive within a round, resulting in round-by-round communication graphs that
can be characterized by simple communication predicates. We introduce the weak
communication predicate PSources(k) and show that it is tight for k-set
agreement, in the following sense: We (i) prove that there is no algorithm for
solving (k-1)-set agreement in systems characterized by PSources(k), and (ii)
present a novel distributed algorithm that achieves k-set agreement in runs
where PSources(k) holds. Our algorithm uses local approximations of the stable
skeleton graph, which reflects the underlying perpetual synchrony of a run. We
prove that this approximation is correct in all runs, regardless of the
communication predicate, and show that graph-theoretic properties of the stable
skeleton graph can be used to solve k-set agreement if PSources(k) holds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4429</identifier>
 <datestamp>2011-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4429</id><created>2011-02-22</created><authors><author><keyname>Oueslati</keyname><forenames>Wided</forenames></author><author><keyname>Akaichi</keyname><forenames>Jalel</forenames></author></authors><title>A Trajectory UML profile For Modeling Trajectory Data: A Mobile Hospital
  Use Case</title><categories>cs.DB</categories><comments>5 pages</comments><journal-ref>international journal of advanced research in computer science
  2011</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  A large amount of data resulting from trajectories of moving objects
activities are collected thanks to localization based services and some
associated automated processes. Trajectories data can be used either for
transactional and analysis purposes in various domains (heath care, commerce,
environment, etc.). For this reason, modeling trajectory data at the conceptual
level is an important stair leading to global vision and successful
implementations. However, current modeling tools fail to fulfill specific
moving objects activities requirements. In this paper, we propose a new profile
based on UML in order to enhance the conceptual modeling of trajectory data
related to mobile objects by new stereotypes and icons. As illustration, we
present a mobile hospital use case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4439</identifier>
 <datestamp>2011-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4439</id><created>2011-02-22</created><authors><author><keyname>Perchet</keyname><forenames>Vianney</forenames></author></authors><title>Approachability of Convex Sets in Games with Partial Monitoring</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide a necessary and sufficient condition under which a convex set is
approachable in a game with partial monitoring, i.e.\ where players do not
observe their opponents' moves but receive random signals. This condition is an
extension of Blackwell's Criterion in the full monitoring framework, where
players observe at least their payoffs. When our condition is fulfilled, we
construct explicitly an approachability strategy, derived from a strategy
satisfying some internal consistency property in an auxiliary game. We also
provide an example of a convex set, that is neither (weakly)-approachable nor
(weakly)-excludable, a situation that cannot occur in the full monitoring case.
We finally apply our result to describe an $\epsilon$-optimal strategy of the
uninformed player in a zero-sum repeated game with incomplete information on
one side.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4442</identifier>
 <datestamp>2011-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4442</id><created>2011-02-22</created><authors><author><keyname>Perchet</keyname><forenames>Vianney</forenames></author></authors><title>Internal Regret with Partial Monitoring. Calibration-Based Optimal
  Algorithms</title><categories>cs.LG cs.GT math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide consistent random algorithms for sequential decision under partial
monitoring, i.e. when the decision maker does not observe the outcomes but
receives instead random feedback signals. Those algorithms have no internal
regret in the sense that, on the set of stages where the decision maker chose
his action according to a given law, the average payoff could not have been
improved in average by using any other fixed law.
  They are based on a generalization of calibration, no longer defined in terms
of a Voronoi diagram but instead of a Laguerre diagram (a more general
concept). This allows us to bound, for the first time in this general
framework, the expected average internal -- as well as the usual external --
regret at stage $n$ by $O(n^{-1/3})$, which is known to be optimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4469</identifier>
 <datestamp>2011-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4469</id><created>2011-02-22</created><authors><author><keyname>Leith</keyname><forenames>Douglas J.</forenames></author><author><keyname>Subramanian</keyname><forenames>Vijay G.</forenames></author><author><keyname>Duffy</keyname><forenames>Ken R.</forenames></author></authors><title>Log-Convexity of Rate Region in 802.11e WLANs</title><categories>cs.NI</categories><journal-ref>IEEE Communications Letters, 14(1), pp57-59, 2010</journal-ref><doi>10.1109/LCOMM.2010.01.091154</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we establish the log-convexity of the rate region in 802.11
WLANs. This generalises previous results for Aloha networks and has immediate
implications for optimisation based approaches to the analysis and design of
802.11 wireless networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4480</identifier>
 <datestamp>2011-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4480</id><created>2011-02-22</created><updated>2011-03-05</updated><authors><author><keyname>Tabei</keyname><forenames>Yasuo</forenames></author><author><keyname>Okanohara</keyname><forenames>Daisuke</forenames></author><author><keyname>Hirose</keyname><forenames>Shuichi</forenames></author><author><keyname>Tsuda</keyname><forenames>Koji</forenames></author></authors><title>LGM: Mining Frequent Subgraphs from Linear Graphs</title><categories>cs.DS</categories><comments>This paper is going to be published in proceedings of 15th
  Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD2011)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A linear graph is a graph whose vertices are totally ordered. Biological and
linguistic sequences with interactions among symbols are naturally represented
as linear graphs. Examples include protein contact maps, RNA secondary
structures and predicate-argument structures. Our algorithm, linear graph miner
(LGM), leverages the vertex order for efficient enumeration of frequent
subgraphs. Based on the reverse search principle, the pattern space is
systematically traversed without expensive duplication checking. Disconnected
subgraph patterns are particularly important in linear graphs due to their
sequential nature. Unlike conventional graph mining algorithms detecting
connected patterns only, LGM can detect disconnected patterns as well. The
utility and efficiency of LGM are demonstrated in experiments on protein
contact maps.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4496</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4496</id><created>2011-02-22</created><updated>2013-01-23</updated><authors><author><keyname>Ivanov</keyname><forenames>Nikolay</forenames></author><author><keyname>Vakarelov</keyname><forenames>Dimiter</forenames></author></authors><title>A system of relational syllogistic incorporating full Boolean reasoning</title><categories>cs.LO</categories><comments>Available at
  http://link.springer.com/article/10.1007/s10849-012-9165-1</comments><msc-class>03B65</msc-class><journal-ref>Journal of Logic, Language and Information, 21 (2012) 433-459</journal-ref><doi>10.1007/s10849-012-9165-1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a system of relational syllogistic, based on classical
propositional logic, having primitives of the following form:
  Some A are R-related to some B;
  Some A are R-related to all B;
  All A are R-related to some B;
  All A are R-related to all B.
  Such primitives formalize sentences from natural language like `All students
read some textbooks'. Here A and B denote arbitrary sets (of objects), and R
denotes an arbitrary binary relation between objects. The language of the logic
contains only variables denoting sets, determining the class of set terms, and
variables denoting binary relations between objects, determining the class of
relational terms. Both classes of terms are closed under the standard Boolean
operations. The set of relational terms is also closed under taking the
converse of a relation. The results of the paper are the completeness theorem
with respect to the intended semantics and the computational complexity of the
satisfiability problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4498</identifier>
 <datestamp>2011-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4498</id><created>2011-02-22</created><authors><author><keyname>Levin</keyname><forenames>Mark Sh.</forenames></author></authors><title>Digraph description of k-interchange technique for optimization over
  permutations and adaptive algorithm system</title><categories>cs.DS cs.AI math.OC</categories><comments>11 pages, 6 figures</comments><msc-class>90Bxx</msc-class><journal-ref>Foundations of Computing and Decision Sciences 26(3) (2001)
  225-235</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper describes a general glance to the use of element exchange
techniques for optimization over permutations. A multi-level description of
problems is proposed which is a fundamental to understand nature and complexity
of optimization problems over permutations (e.g., ordering, scheduling,
traveling salesman problem). The description is based on permutation
neighborhoods of several kinds (e.g., by improvement of an objective function).
Our proposed operational digraph and its kinds can be considered as a way to
understand convexity and polynomial solvability for combinatorial optimization
problems over permutations. Issues of an analysis of problems and a design of
hierarchical heuristics are discussed. The discussion leads to a multi-level
adaptive algorithm system which analyzes an individual problem and
selects/designs a solving strategy (trajectory).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4518</identifier>
 <datestamp>2011-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4518</id><created>2011-02-22</created><updated>2011-02-28</updated><authors><author><keyname>Ayora</keyname><forenames>Clara</forenames></author><author><keyname>Torres</keyname><forenames>Victoria</forenames></author><author><keyname>Pelechano</keyname><forenames>Vicente</forenames></author></authors><title>BP Variability Case Studies Development using different Modeling
  Approaches</title><categories>cs.SE</categories><report-no>ProS-TR-2011-03</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Variability in Business Process modeling has already been faced by different
authors from the literature. Depending on the context in which each author
faces the modeling problem, we find different approaches (C-EPC, C-YAWL,
FEATURE-EPC, PESOA, PROVOP, or WORKLETS). In this report we present four of the
most representative approaches (C-EPC, PESOA, PROVOP and WORKLETS) which are
presented by means of the different case studies found in the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4519</identifier>
 <datestamp>2011-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4519</id><created>2011-02-22</created><updated>2011-03-23</updated><authors><author><keyname>Serpa</keyname><forenames>Nilo</forenames></author></authors><title>Theoretical Count of Function Points for Non-Measurable Items</title><categories>cs.SE</categories><comments>12 pages, 3 figures and original formalism</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies and proposes a technique of function point counting for
items classified as non-measurable. The main objective is to expand the
conventional technique of counting to ensure that this comprises consistently
the tasks involved in building portals and sites in general. In addition, it
also applies to measure the cost of continued activities related to these web
applications. The extended technique is potentially useful to measure several
products associated with information systems, including periodicals publishable
in intranets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4522</identifier>
 <datestamp>2011-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4522</id><created>2011-02-19</created><authors><author><keyname>Sadodin</keyname><forenames>S.</forenames></author><author><keyname>Kashani</keyname><forenames>T. T.</forenames></author></authors><title>Numerical investigation of a solar greenhouse tunnel drier for drying of
  copra</title><categories>cs.OH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A numerical investigation of a solar greenhouse tunnel drier (SGTD) has been
performed. In the present study, the geometry of the tunnel roof is assumed
semi-circular which is covered with a UV (200\mu) stabilized polyethylene film.
The simulated SGTD reduces moisture of copra from 52.2% to 8% in 55 h under
full load conditions. A system of partial differential equations describing
heat and moisture transfer during drying copra in the solar greenhouse dryer
was developed and this system of non-linear partial differential equations was
solved numerically using the finite difference method (FDM). The numerical
solution was programmed in Compaq Visual FORTRAN version 6.5. The simulated
results reasonably agreed with the experimental data for solar drying copra.
This model can be used to provide the design data and is also essential for
optimal design of the dryer. For instance the user is able to change the
radiation properties of the roof cover for different materials of roof cover.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4523</identifier>
 <datestamp>2011-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4523</id><created>2011-02-22</created><authors><author><keyname>Goyal</keyname><forenames>Navin</forenames></author><author><keyname>Gupta</keyname><forenames>Manoj</forenames></author></authors><title>On Dynamic Optimality for Binary Search Trees</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Does there exist O(1)-competitive (self-adjusting) binary search tree (BST)
algorithms? This is a well-studied problem. A simple offline BST algorithm
GreedyFuture was proposed independently by Lucas and Munro, and they
conjectured it to be O(1)-competitive. Recently, Demaine et al. gave a
geometric view of the BST problem. This view allowed them to give an online
algorithm GreedyArb with the same cost as GreedyFuture. However, no
o(n)-competitive ratio was known for GreedyArb. In this paper we make progress
towards proving O(1)-competitive ratio for GreedyArb by showing that it is
O(\log n)-competitive.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4527</identifier>
 <datestamp>2011-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4527</id><created>2011-02-22</created><authors><author><keyname>Kutyniok</keyname><forenames>Gitta</forenames></author></authors><title>Data Separation by Sparse Representations</title><categories>math.NA cs.IT math.IT</categories><comments>29 pages, 7 figures</comments><journal-ref>in: &quot;Compressed Sensing: Theory and Applications&quot;, Cambridge
  University Press, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, sparsity has become a key concept in various areas of applied
mathematics, computer science, and electrical engineering. One application of
this novel methodology is the separation of data, which is composed of two (or
more) morphologically distinct constituents. The key idea is to carefully
select representation systems each providing sparse approximations of one of
the components. Then the sparsest coefficient vector representing the data
within the composed - and therefore highly redundant - representation system is
computed by $\ell_1$ minimization or thresholding. This automatically enforces
separation. This paper shall serve as an introduction to and a survey about
this exciting area of research as well as a reference for the state-of-the-art
of this research field. It will appear as a chapter in a book on &quot;Compressed
Sensing: Theory and Applications&quot; edited by Yonina Eldar and Gitta Kutyniok.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4528</identifier>
 <datestamp>2011-03-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4528</id><created>2011-02-22</created><updated>2011-03-17</updated><authors><author><keyname>Serpa</keyname><forenames>Nilo</forenames></author><author><keyname>Steiner</keyname><forenames>Jose Roberto</forenames></author></authors><title>Modelling the Dynamics of the Work-Employment System by Predator-Prey
  Interactions</title><categories>cs.CE nlin.AO</categories><comments>17 pages, 11 figures and original formalism</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The broad application range of the predator-prey modelling enabled us to
apply it to represent the dynamics of the work-employment system. For the
adopted period, we conclude that this dynamics is chaotic in the beginning of
the time series and tends to less perturbed states, as time goes by, due to
public policies and hidden intrinsic system features. Basic Lotka-Volterra
approach was revised and adapted to the reality of the study. The final aim is
to provide managers with generalized theoretical elements that allow to a more
accurate understanding of the behavior of the work-employment system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4563</identifier>
 <datestamp>2011-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4563</id><created>2011-02-22</created><authors><author><keyname>Schultz</keyname><forenames>Ulrik P.</forenames></author><author><keyname>Stinckwich</keyname><forenames>Serge</forenames></author><author><keyname>Ziane</keyname><forenames>Mikal</forenames></author></authors><title>Proceedings of the first international workshop on domain-specific
  languages for robotic systems (DSLRob 2010)</title><categories>cs.RO cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The First International Workshop on Domain-Specific Languages and models for
ROBotic systems (DSLRob'10) was held at the 2010 IEEE/RSJ International
Conference on Intelligent Robots and Systems (IROS'10), October 2010 in Taipei,
Taiwan.
  The main topics of the workshop were domain-specific languages and models. A
domain-specific language (DSL) is a programming language dedicated to a
particular problem domain that offers specific notations and abstractions that
increase programmer productivity within that domain. Models offer a high-level
way for domain users to specify the functionality of their system at the right
level of abstraction. DSLs and models have historically been used for
programming complex systems. However recently they have garnered interest as a
separate field of study. Robotic systems blend hardware and software in a
holistic way that intrinsically raises many crosscutting concerns (concurrency,
uncertainty, time constraints, ...), for which reason, traditional
general-purpose languages often lead to a poor fit between the language
features and the implementation requirements. DSLs and models offer a powerful,
systematic way to overcome this problem, enabling the programmer to quickly and
precisely implement novel software solutions to complex problems within the
robotics domain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4570</identifier>
 <datestamp>2011-04-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4570</id><created>2011-02-22</created><authors><author><keyname>Wang</keyname><forenames>Zhen</forenames></author><author><keyname>Murks</keyname><forenames>Aleksandra</forenames></author><author><keyname>Du</keyname><forenames>Wen-Bo</forenames></author><author><keyname>Rong</keyname><forenames>Zhi-Hai</forenames></author><author><keyname>Perc</keyname><forenames>Matjaz</forenames></author></authors><title>Coveting thy neighbors fitness as a means to resolve social dilemmas</title><categories>q-bio.PE cs.SI physics.soc-ph</categories><comments>10 two-column pages, 5 figures; accepted for publication in Journal
  of Theoretical Biology</comments><journal-ref>J. Theor. Biol. 277 (2011) 19-26</journal-ref><doi>10.1016/j.jtbi.2011.02.016</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In spatial evolutionary games the fitness of each individual is traditionally
determined by the payoffs it obtains upon playing the game with its neighbors.
Since defection yields the highest individual benefits, the outlook for
cooperators is gloomy. While network reciprocity promotes collaborative
efforts, chances of averting the impending social decline are slim if the
temptation to defect is strong. It is therefore of interest to identify viable
mechanisms that provide additional support for the evolution of cooperation.
Inspired by the fact that the environment may be just as important as
inheritance for individual development, we introduce a simple switch that
allows a player to either keep its original payoff or use the average payoff of
all its neighbors. Depending on which payoff is higher, the influence of either
option can be tuned by means of a single parameter. We show that, in general,
taking into account the environment promotes cooperation. Yet coveting the
fitness of one's neighbors too strongly is not optimal. In fact, cooperation
thrives best only if the influence of payoffs obtained in the traditional way
is equal to that of the average payoff of the neighborhood. We present results
for the prisoner's dilemma and the snowdrift game, for different levels of
uncertainty governing the strategy adoption process, and for different
neighborhood sizes. Our approach outlines a viable route to increased levels of
cooperative behavior in structured populations, but one that requires a
thoughtful implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4573</identifier>
 <datestamp>2011-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4573</id><created>2011-02-22</created><authors><author><keyname>Kak</keyname><forenames>Subhash</forenames></author></authors><title>The Algebra of Two Dimensional Patterns</title><categories>cs.IT math.IT</categories><comments>11 pages, 14 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The article presents an algebra to represent two dimensional patterns using
reciprocals of polynomials. Such a representation will be useful in neural
network training and it provides a method of training patterns that is much
more efficient than a pixel-wise representation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4579</identifier>
 <datestamp>2011-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4579</id><created>2011-02-22</created><updated>2011-05-16</updated><authors><author><keyname>Rangineni</keyname><forenames>Sandhya</forenames></author></authors><title>New Results on Scrambling Using the Mesh Array</title><categories>cs.CR</categories><comments>9 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents new results on randomization using Kak's Mesh Array for
matrix multiplication. These results include the periods of the longest cycles
when the the array is used for scrambling and the autocorrelation function of
the binary sequence obtained from the cycles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4580</identifier>
 <datestamp>2013-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4580</id><created>2011-02-22</created><authors><author><keyname>Smith</keyname><forenames>Graeme</forenames></author><author><keyname>Smolin</keyname><forenames>John A.</forenames></author><author><keyname>Yard</keyname><forenames>Jon</forenames></author></authors><title>Gaussian bosonic synergy: quantum communication via realistic channels
  of zero quantum capacity</title><categories>quant-ph cs.IT math.IT</categories><comments>5 pages, 4 figures, one appendix</comments><journal-ref>Nature Photonics 5, 624-627 (2011)</journal-ref><doi>10.1038/nphoton.2011.203</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As with classical information, error-correcting codes enable reliable
transmission of quantum information through noisy or lossy channels. In
contrast to the classical theory, imperfect quantum channels exhibit a strong
kind of synergy: there exist pairs of discrete memoryless quantum channels,
each of zero quantum capacity, which acquire positive quantum capacity when
used together. Here we show that this &quot;superactivation&quot; phenomenon also occurs
in the more realistic setting of optical channels with attenuation and Gaussian
noise. This paves the way for its experimental realization and application in
real-world communications systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4598</identifier>
 <datestamp>2011-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4598</id><created>2011-02-22</created><updated>2011-10-19</updated><authors><author><keyname>Miszczak</keyname><forenames>J. A.</forenames></author></authors><title>Generating and using truly random quantum states in Mathematica</title><categories>quant-ph cs.MS physics.comp-ph</categories><comments>12 pages, 3 figures, see http://www.iitis.pl/~miszczak/trqs.html for
  related software</comments><journal-ref>Comput. Phys. Commun., Vol. 183, No. 1 (2012), pp. 118-124</journal-ref><doi>10.1016/j.cpc.2011.08.002</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The problem of generating random quantum states is of a great interest from
the quantum information theory point of view. In this paper we present a
package for Mathematica computing system harnessing a specific piece of
hardware, namely Quantis quantum random number generator (QRNG), for
investigating statistical properties of quantum states. The described package
implements a number of functions for generating random states, which use
Quantis QRNG as a source of randomness. It also provides procedures which can
be used in simulations not related directly to quantum information processing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4599</identifier>
 <datestamp>2011-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4599</id><created>2011-02-22</created><authors><author><keyname>Kurant</keyname><forenames>Maciej</forenames></author><author><keyname>Markopoulou</keyname><forenames>Athina</forenames></author><author><keyname>Thiran</keyname><forenames>Patrick</forenames></author></authors><title>Towards Unbiased BFS Sampling</title><categories>cs.SI cs.NI stat.ME</categories><comments>BFS, RDS, graph traversal, sampling bias correction</comments><journal-ref>arXiv:1004.1729, 2010</journal-ref><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Breadth First Search (BFS) is a widely used approach for sampling large
unknown Internet topologies. Its main advantage over random walks and other
exploration techniques is that a BFS sample is a plausible graph on its own,
and therefore we can study its topological characteristics. However, it has
been empirically observed that incomplete BFS is biased toward high-degree
nodes, which may strongly affect the measurements. In this paper, we first
analytically quantify the degree bias of BFS sampling. In particular, we
calculate the node degree distribution expected to be observed by BFS as a
function of the fraction f of covered nodes, in a random graph RG(pk) with an
arbitrary degree distribution pk. We also show that, for RG(pk), all commonly
used graph traversal techniques (BFS, DFS, Forest Fire, Snowball Sampling, RDS)
suffer from exactly the same bias. Next, based on our theoretical analysis, we
propose a practical BFS-bias correction procedure. It takes as input a
collected BFS sample together with its fraction f. Even though RG(pk) does not
capture many graph properties common in real-life graphs (such as
assortativity), our RG(pk)-based correction technique performs well on a broad
range of Internet topologies and on two large BFS samples of Facebook and Orkut
networks. Finally, we consider and evaluate a family of alternative correction
procedures, and demonstrate that, although they are unbiased for an arbitrary
topology, their large variance makes them far less effective than the
RG(pk)-based technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4602</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4602</id><created>2011-02-22</created><updated>2011-07-24</updated><authors><author><keyname>Goodrich</keyname><forenames>Michael T.</forenames></author><author><keyname>Kerschbaum</keyname><forenames>Florian</forenames></author></authors><title>Privacy-Enhanced Reputation-Feedback Methods to Reduce Feedback
  Extortion in Online Auctions</title><categories>cs.CR cs.GT</categories><comments>Longer version of a paper appearing in ACM Conference on Data and
  Application Security and Privacy (CODASPY) 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study methods for improving the utility and privacy of
reputation scores for online auctions, such as used in eBay, so as to reduce
the effectiveness of feedback extortion. The main ideas behind our techniques
are to use randomization and various schemes to escrow reputations scores until
appropriate external events occur. Depending on the degree of utility and
privacy needed, these external techniques could depend on the number and type
of reputation scores collected. Moreover, if additional privacy protection is
needed, then random sampling can be used with respect reputation scores in such
a way that reputation aggregates remain useful, but individual reputation
scores are probabilistically hidden from users. Finally, we show that if
privacy is also desired with respect to the the reputation aggregator, then we
can use zero-knowledge proofs for reputation comparisons.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4612</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4612</id><created>2011-02-22</created><updated>2013-01-25</updated><authors><author><keyname>Kasai</keyname><forenames>Kenta</forenames></author><author><keyname>Sakaniwa</keyname><forenames>Kohichi</forenames></author></authors><title>Spatially-Coupled MacKay-Neal Codes and Hsu-Anastasopoulos Codes</title><categories>cs.IT math.IT</categories><comments>Corrected typos in degree distributions \nu and \mu of MN and HA
  codes</comments><doi>10.1587/transfun.E94.A.2161</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Kudekar et al. recently proved that for transmission over the binary erasure
channel (BEC), spatial coupling of LDPC codes increases the BP threshold of the
coupled ensemble to the MAP threshold of the underlying LDPC codes. One major
drawback of the capacity-achieving spatially-coupled LDPC codes is that one
needs to increase the column and row weight of parity-check matrices of the
underlying LDPC codes.
  It is proved, that Hsu-Anastasopoulos (HA) codes and MacKay-Neal (MN) codes
achieve the capacity of memoryless binary-input symmetric-output channels under
MAP decoding with bounded column and row weight of the parity-check matrices.
The HA codes and the MN codes are dual codes each other.
  The aim of this paper is to present an empirical evidence that
spatially-coupled MN (resp. HA) codes with bounded column and row weight
achieve the capacity of the BEC. To this end, we introduce a spatial coupling
scheme of MN (resp. HA) codes. By density evolution analysis, we will show that
the resulting spatially-coupled MN (resp. HA) codes have the BP threshold close
to the Shannon limit.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4636</identifier>
 <datestamp>2011-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4636</id><created>2011-02-22</created><authors><author><keyname>Schumann</keyname><forenames>Andrew</forenames></author></authors><title>Modal Calculus of Illocutionary Logic</title><categories>cs.LO</categories><comments>15 pages</comments><journal-ref>Piotr Stalmaszczyk (Ed.), Philosophy od Language and Linguistcs.
  Volume I: The Formal Turn. Ontos Verlag: Paris, Frankfurt, 2010, pp. 261-276</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of illocutionary logic is to explain how context can affect the
meaning of certain special kinds of performative utterances. Recall that
performative utterances are understood as follows: a speaker performs the
illocutionary act (e.g. act of assertion, of conjecture, of promise) with the
illocutionary force (resp. assertion, conjecture, promise) named by an
appropriate performative verb in the way of representing himself as performing
that act. In the paper I proposed many-valued interpretation of illocutionary
forces understood as modal operators. As a result, I built up a non-Archimedean
valued logic for formalizing illocutionary acts. A formal many-valued approach
to illocutionary logic was offered for the first time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4639</identifier>
 <datestamp>2011-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4639</id><created>2011-02-22</created><updated>2011-09-07</updated><authors><author><keyname>Ghosh</keyname><forenames>Rumi</forenames></author><author><keyname>Lerman</keyname><forenames>Kristina</forenames></author><author><keyname>Surachawala</keyname><forenames>Tawan</forenames></author><author><keyname>Voevodski</keyname><forenames>Konstantin</forenames></author><author><keyname>Teng</keyname><forenames>Shang-Hua</forenames></author></authors><title>Non-Conservative Diffusion and its Application to Social Network
  Analysis</title><categories>cs.SI physics.data-an physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The random walk is fundamental to modeling dynamic processes on networks.
Metrics based on the random walk have been used in many applications from image
processing to Web page ranking. However, how appropriate are random walks to
modeling and analyzing social networks? We argue that unlike a random walk,
which conserves the quantity diffusing on a network, many interesting social
phenomena, such as the spread of information or disease on a social network,
are fundamentally non-conservative. When an individual infects her neighbor
with a virus, the total amount of infection increases. We classify diffusion
processes as conservative and non-conservative and show how these differences
impact the choice of metrics used for network analysis, as well as our
understanding of network structure and behavior. We show that Alpha-Centrality,
which mathematically describes non-conservative diffusion, leads to new
insights into the behavior of spreading processes on networks. We give a
scalable approximate algorithm for computing the Alpha-Centrality in a massive
graph. We validate our approach on real-world online social networks of Digg.
We show that a non-conservative metric, such as Alpha-Centrality, produces
better agreement with empirical measure of influence than conservative metrics,
such as PageRank. We hope that our investigation will inspire further
exploration into the realms of conservative and non-conservative metrics in
social network analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4646</identifier>
 <datestamp>2011-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4646</id><created>2011-02-22</created><authors><author><keyname>Ramalingam</keyname><forenames>Neevan</forenames></author><author><keyname>Wang</keyname><forenames>Zhengdao</forenames></author></authors><title>Superposition Noisy Network Coding</title><categories>cs.IT math.IT</categories><comments>5 pages, 3 figures, conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a superposition coding scheme for communication over a network,
which combines partial decode and forward and noisy network coding. This hybrid
scheme is termed as superposition noisy network coding. The scheme is designed
and analyzed for single relay channel, single source multicast network and
multiple source multicast network. The achievable rate region is determined for
each case. The special cases of Gaussian single relay channel and two way relay
channel are analyzed for superposition noisy network coding. The achievable
rate of the proposed scheme is higher than the existing schemes of noisy
network coding and compress-forward.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4651</identifier>
 <datestamp>2011-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4651</id><created>2011-02-22</created><updated>2011-08-09</updated><authors><author><keyname>Grcar</keyname><forenames>Joseph F.</forenames></author></authors><title>Education for Computational Science and Engineering</title><categories>math.HO cs.CY cs.GL</categories><comments>9 pages, 2 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computational science and engineering (CSE) has been misunderstood to advance
with the construction of enormous computers. To the contrary, the historical
record demonstrates that innovations in CSE come from improvements to the
mathematics embodied by computer programs. Whether scientists and engineers
become inventors who make these breakthroughs depends on circumstances and the
interdisciplinary extent of their educations. The USA currently has the largest
CSE professorate, but the data suggest this prominence is ephemeral.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4652</identifier>
 <datestamp>2011-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4652</id><created>2011-02-22</created><updated>2011-03-13</updated><authors><author><keyname>Kamilov</keyname><forenames>Ulugbek</forenames></author><author><keyname>Goyal</keyname><forenames>Vivek K</forenames></author><author><keyname>Rangan</keyname><forenames>Sundeep</forenames></author></authors><title>Optimal Quantization for Compressive Sensing under Message Passing
  Reconstruction</title><categories>cs.IT math.IT</categories><comments>5 pages, 3 figures, submitted to IEEE International Symposium on
  Information Theory (ISIT) 2011; minor corrections in v2</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the optimal quantization of compressive sensing measurements
following the work on generalization of relaxed belief propagation (BP) for
arbitrary measurement channels. Relaxed BP is an iterative reconstruction
scheme inspired by message passing algorithms on bipartite graphs. Its
asymptotic error performance can be accurately predicted and tracked through
the state evolution formalism. We utilize these results to design mean-square
optimal scalar quantizers for relaxed BP signal reconstruction and empirically
demonstrate the superior error performance of the resulting quantizers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4666</identifier>
 <datestamp>2011-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4666</id><created>2011-02-23</created><authors><author><keyname>Labart</keyname><forenames>C&#xe9;line</forenames><affiliation>LAMA</affiliation></author><author><keyname>Lelong</keyname><forenames>J&#xe9;r&#xf4;me</forenames><affiliation>LJK</affiliation></author></authors><title>A Parallel Algorithm for solving BSDEs - Application to the pricing and
  hedging of American options</title><categories>math.PR cs.DC</categories><comments>25 pages</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a parallel algorithm for solving backward stochastic differential
equations (BSDEs in short) which are very useful theoretic tools to deal with
many financial problems ranging from option pricing option to risk management.
Our algorithm based on Gobet and Labart (2010) exploits the link between BSDEs
and non linear partial differential equations (PDEs in short) and hence enables
to solve high dimensional non linear PDEs. In this work, we apply it to the
pricing and hedging of American options in high dimensional local volatility
models, which remains very computationally demanding. We have tested our
algorithm up to dimension 10 on a cluster of 512 CPUs and we obtained linear
speedups which proves the scalability of our implementation
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4681</identifier>
 <datestamp>2011-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4681</id><created>2011-02-23</created><authors><author><keyname>Cheng</keyname><forenames>Jin-San</forenames></author><author><keyname>Gao</keyname><forenames>Xiao-Shan</forenames></author><author><keyname>Guo</keyname><forenames>Leilei</forenames></author></authors><title>Root Isolation of Zero-dimensional Polynomial Systems with Linear
  Univariate Representation</title><categories>cs.SC</categories><comments>19 pages,2 figures; MM-Preprint of KLMM, Vol. 29, 92-111, Aug. 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a linear univariate representation for the roots of a
zero-dimensional polynomial equation system is presented, where the roots of
the equation system are represented as linear combinations of roots of several
univariate polynomial equations. The main advantage of this representation is
that the precision of the roots can be easily controlled. In fact, based on the
linear univariate representation, we can give the exact precisions needed for
roots of the univariate equations in order to obtain the roots of the equation
system to a given precision. As a consequence, a root isolation algorithm for a
zero-dimensional polynomial equation system can be easily derived from its
linear univariate representation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4684</identifier>
 <datestamp>2011-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4684</id><created>2011-02-23</created><authors><author><keyname>Mahe</keyname><forenames>Vincent</forenames><affiliation>INRIA - EMN</affiliation></author><author><keyname>Perez</keyname><forenames>Salvador Martinez</forenames><affiliation>INRIA - EMN</affiliation></author><author><keyname>Doux</keyname><forenames>Guillaume</forenames><affiliation>INRIA - EMN</affiliation></author><author><keyname>Bruneli&#xe8;re</keyname><forenames>Hugo</forenames><affiliation>INRIA - EMN</affiliation></author><author><keyname>Cabot</keyname><forenames>Jordi</forenames><affiliation>INRIA - EMN</affiliation></author></authors><title>P ORTOLAN: a Model-Driven Cartography Framework</title><categories>cs.OH</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Processing large amounts of data to extract useful information is an
essential task within companies. To help in this task, visualization techniques
have been commonly used due to their capacity to present data in synthesized
views, easier to understand and manage. However, achieving the right
visualization display for a data set is a complex cartography process that
involves several transformation steps to adapt the (domain) data to the
(visualization) data format expected by visualization tools. To maximize the
benefits of visualization we propose Portolan, a generic model-driven
cartography framework that facilitates the discovery of the data to visualize,
the specification of view definitions for that data and the transformations to
bridge the gap with the visualization tools. Our approach has been implemented
on top of the Eclipse EMF modeling framework and validated on three different
use cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4699</identifier>
 <datestamp>2011-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4699</id><created>2011-02-23</created><authors><author><keyname>Jain</keyname><forenames>Rahul</forenames></author><author><keyname>Zhang</keyname><forenames>Shengyu</forenames></author></authors><title>The influence lower bound via query elimination</title><categories>cs.CC</categories><comments>5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a simpler proof, via query elimination, of a result due to O'Donnell,
Saks, Schramm and Servedio, which shows a lower bound on the zero-error
randomized query complexity of a function f in terms of the maximum influence
of any variable of f. Our lower bound also applies to the two-sided error
distributional query complexity of f, and it allows an immediate extension
which can be used to prove stronger lower bounds for some functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4711</identifier>
 <datestamp>2011-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4711</id><created>2011-02-23</created><updated>2011-04-13</updated><authors><author><keyname>Liva</keyname><forenames>Gianluigi</forenames></author><author><keyname>Paolini</keyname><forenames>Enrico</forenames></author><author><keyname>Scalise</keyname><forenames>Sandro</forenames></author><author><keyname>Chiani</keyname><forenames>Marco</forenames></author></authors><title>Turbo Codes Based on Time-Variant Memory-1 Convolutional Codes over Fq</title><categories>cs.IT math.IT</categories><comments>This paper has been withdrawn by the authors. To be presented at IEEE
  ICC 2011, Kyoto, Japan. June 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Two classes of turbo codes over high-order finite fields are introduced. The
codes are derived from a particular protograph sub-ensemble of the (dv=2,dc=3)
low-density parity-check code ensemble. A first construction is derived as a
parallel concatenation of two non-binary, time-variant accumulators. The second
construction is based on the serial concatenation of a non-binary, time-variant
differentiator and of a non-binary, time-variant accumulator, and provides a
highly-structured flexible encoding scheme for (dv=2,dc=4) ensemble codes. A
cycle graph representation is provided. The proposed codes can be decoded
efficiently either as low-density parity-check codes (via belief propagation
decoding over the codes bipartite graph) or as turbo codes (via the
forward-backward algorithm applied to the component codes trellis). The
forward-backward algorithm for symbol maximum a posteriori decoding of the
component codes is illustrated and simplified by means of the fast Fourier
transform. The proposed codes provide remarkable gains (~ 1 dB) over binary
low-density parity-check and turbo codes in the moderate-short block regimes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4712</identifier>
 <datestamp>2011-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4712</id><created>2011-02-23</created><authors><author><keyname>Chuklin</keyname><forenames>Aleksandr</forenames></author></authors><title>Effective protocols for low-distance file synchronization</title><categories>cs.IT cs.CC math.IT</categories><comments>Russian language, 25 pages, survey</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Suppose that we have two similar files stored on different computers. We need
to send the file from the first computer to the second one trying to minimize
the number of bits transmitted. This article presents a survey of results known
for this communication complexity problem in the case when files are &quot;similar&quot;
in the sense of Hamming distance. We mainly systematize earlier results
obtained by various authors in 1990s and 2000s and discuss its connection with
coding theory, hashing algorithms and other domains of computer science. In
particular cases we propose some improvements of previous constructions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4727</identifier>
 <datestamp>2011-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4727</id><created>2011-02-23</created><authors><author><keyname>Levit</keyname><forenames>Vadim E.</forenames></author><author><keyname>Mandrescu</keyname><forenames>Eugen</forenames></author></authors><title>On the Core of a Unicyclic Graph</title><categories>cs.DM math.CO</categories><comments>8 pages, 5 figures</comments><msc-class>05C69 (Primary) 05C70(Secondary)</msc-class><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A set S is independent in a graph G if no two vertices from S are adjacent.
By core(G) we mean the intersection of all maximum independent sets. The
independence number alpha(G) is the cardinality of a maximum independent set,
while mu(G) is the size of a maximum matching in G. A connected graph having
only one cycle, say C, is a unicyclic graph. In this paper we prove that if G
is a unicyclic graph of order n and n-1 = alpha(G) + mu(G), then core(G)
coincides with the union of cores of all trees in G-C.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4728</identifier>
 <datestamp>2011-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4728</id><created>2011-02-23</created><updated>2011-07-13</updated><authors><author><keyname>Chen</keyname><forenames>Xu</forenames></author><author><keyname>Huang</keyname><forenames>Jianwei</forenames></author><author><keyname>Li</keyname><forenames>Husheng</forenames></author></authors><title>Adaptive Channel Recommendation For Opportunistic Spectrum Access</title><categories>cs.DC cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a dynamic spectrum access scheme where secondary users recommend
&quot;good&quot; channels to each other and access accordingly. We formulate the problem
as an average reward based Markov decision process. We show the existence of
the optimal stationary spectrum access policy, and explore its structure
properties in two asymptotic cases. Since the action space of the Markov
decision process is continuous, it is difficult to find the optimal policy by
simply discretizing the action space and use the policy iteration, value
iteration, or Q-learning methods. Instead, we propose a new algorithm based on
the Model Reference Adaptive Search method, and prove its convergence to the
optimal policy. Numerical results show that the proposed algorithms achieve up
to 18% and 100% performance improvement than the static channel recommendation
scheme in homogeneous and heterogeneous channel environments, respectively, and
is more robust to channel dynamics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4769</identifier>
 <datestamp>2011-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4769</id><created>2011-02-22</created><authors><author><keyname>Majkic</keyname><forenames>Zoran</forenames></author></authors><title>Data Base Mappings and Monads: (Co)Induction</title><categories>cs.DB cs.LO math.CT</categories><comments>31 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we presented the semantics of database mappings in the
relational DB category based on the power-view monad T and monadic algebras.
The objects in this category are the database-instances (a database-instance is
a set of n-ary relations, i.e., a set of relational tables as in standard
RDBs). The morphisms in DB category are used in order to express the semantics
of view-based Global and Local as View (GLAV) mappings between relational
databases, for example those used in Data Integration Systems. Such morphisms
in this DB category are not functions but have the complex tree structures
based on a set of complex query computations between two database-instances.
Thus DB category, as a base category for the semantics of databases and
mappings between them, is different from the Set category used dominantly for
such issues, and needs the full investigation of its properties. In this paper
we presented another contributions for an intensive exploration of properties
and semantics of this category, based on the power-view monad T and the Kleisli
category for databases. Here we stressed some Universal algebra considerations
based on monads and relationships between this DB category and the standard Set
category. Finally, we investigated the general algebraic and induction
properties for databases in this category, and we defined the initial monadic
algebras for database instances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4771</identifier>
 <datestamp>2011-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4771</id><created>2011-02-16</created><authors><author><keyname>Schipani</keyname><forenames>Davide</forenames></author><author><keyname>Elia</keyname><forenames>Michele</forenames></author><author><keyname>Rosenthal</keyname><forenames>Joachim</forenames></author></authors><title>Efficient evaluation of polynomials over finite fields</title><categories>cs.IT math.IT math.NT</categories><comments>presented at AusCTW 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A method is described which allows to evaluate efficiently a polynomial in a
(possibly trivial) extension of the finite field of its coefficients. Its
complexity is shown to be lower than that of standard techniques when the
degree of the polynomial is large with respect to the base field. Applications
to the syndrome computation in the decoding of cyclic codes, Reed-Solomon codes
in particular, are highlighted.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4772</identifier>
 <datestamp>2011-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4772</id><created>2011-02-16</created><updated>2011-12-06</updated><authors><author><keyname>Elia</keyname><forenames>Michele</forenames></author><author><keyname>Rosenthal</keyname><forenames>Joachim</forenames></author><author><keyname>Schipani</keyname><forenames>Davide</forenames></author></authors><title>Polynomial evaluation over finite fields: new algorithms and complexity
  bounds</title><categories>cs.IT math.IT math.NT</categories><comments>accepted for publication in Applicable Algebra in Engineering,
  Communication and Computing. The final publication will be available at
  springerlink.com. DOI: 10.1007/s00200-011-0160-6</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An efficient evaluation method is described for polynomials in finite fields.
Its complexity is shown to be lower than that of standard techniques when the
degree of the polynomial is large enough. Applications to the syndrome
computation in the decoding of Reed-Solomon codes are highlighted.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4773</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4773</id><created>2011-02-23</created><authors><author><keyname>Rosnes</keyname><forenames>Eirik</forenames></author><author><keyname>Amat</keyname><forenames>Alexandre Graell i</forenames></author></authors><title>Performance Analysis of 3-Dimensional Turbo Codes</title><categories>cs.IT math.IT</categories><comments>To appear in IEEE Trans. Inf. Theory</comments><journal-ref>IEEE Trans. Inf. Theory, vol. 57, no. 6, pp. 3707-3720, Jun. 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we consider the minimum distance properties and convergence
thresholds of 3-dimensional turbo codes (3D-TCs), recently introduced by Berrou
et al.. Here, we consider binary 3D-TCs while the original work of Berrou et
al. considered double-binary codes. In the first part of the paper, the minimum
distance properties are analyzed from an ensemble perspective, both in the
finite-length regime and in the asymptotic case of large block lengths. In
particular, we analyze the asymptotic weight distribution of 3D-TCs and show
numerically that their typical minimum distance dmin may, depending on the
specific parameters, asymptotically grow linearly with the block length, i.e.,
the 3D-TC ensemble is asymptotically good for some parameters. In the second
part of the paper, we derive some useful upper bounds on the dmin when using
quadratic permutation polynomial (QPP) interleavers with a quadratic inverse.
Furthermore, we give examples of interleaver lengths where an upper bound
appears to be tight. The best codes (in terms of estimated dmin) obtained by
randomly searching for good pairs of QPPs for use in the 3D-TC are compared to
a probabilistic lower bound on the dmin when selecting codes from the 3D-TC
ensemble uniformly at random. This comparison shows that the use of designed
QPP interleavers can improve the dmin significantly. For instance, we have
found a (6144,2040) 3D-TC with an estimated dmin of 147, while the
probabilistic lower bound is 69. Higher rates are obtained by puncturing
nonsystematic bits, and optimized periodic puncturing patterns for rates 1/2,
2/3, and 4/5 are found by computer search. Finally, we give iterative decoding
thresholds, computed from an extrinsic information transfer chart analysis, and
present simulation results on the additive white Gaussian noise channel to
compare the error rate performance to that of conventional turbo codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4794</identifier>
 <datestamp>2012-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4794</id><created>2011-02-23</created><updated>2011-05-30</updated><authors><author><keyname>Geiger</keyname><forenames>Bernhard C.</forenames></author><author><keyname>Feldbauer</keyname><forenames>Christian</forenames></author><author><keyname>Kubin</keyname><forenames>Gernot</forenames></author></authors><title>Information Loss in Static Nonlinearities</title><categories>cs.IT math.IT nlin.SI</categories><comments>9 pages, 6 figures; A short version of this paper is submitted to an
  IEEE conference</comments><report-no>(c) IEEE 2011</report-no><journal-ref>Proc. IEEE Int. Sym. Wireless Communication Systems, 2011, pp. 799
  - 803</journal-ref><doi>10.1109/ISWCS.2011.6125272</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, conditional entropy is used to quantify the information loss
induced by passing a continuous random variable through a memoryless nonlinear
input-output system. We derive an expression for the information loss depending
on the input density and the nonlinearity and show that the result is strongly
related to the non-injectivity of the considered system. Tight upper bounds are
presented, which can be evaluated with less difficulty than a direct evaluation
of the information loss, which involves the logarithm of a sum. Application of
our results is illustrated on a set of examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4802</identifier>
 <datestamp>2011-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4802</id><created>2011-02-23</created><authors><author><keyname>Suzuki</keyname><forenames>Kazuhiro</forenames></author></authors><title>A generalization of heterochromatic graphs</title><categories>math.CO cs.DM</categories><comments>14 pages, 4 figures</comments><msc-class>05C05, 05C15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In 2006, Suzuki, and Akbari &amp; Alipour independently presented a necessary and
sufficient condition for edge-colored graphs to have a heterochromatic spanning
tree, where a heterochromatic spanning tree is a spanning tree whose edges have
distinct colors. In this paper, we propose $f$-chromatic graphs as a
generalization of heterochromatic graphs. An edge-colored graph is
$f$-chromatic if each color $c$ appears on at most $f(c)$ edges. We also
present a necessary and sufficient condition for edge-colored graphs to have an
$f$-chromatic spanning forest with exactly $m$ components. Moreover, using this
criterion, we show that a $g$-chromatic graph $G$ of order $n$ with
$|E(G)|&gt;\binom{n-m}{2}$ has an $f$-chromatic spanning forest with exactly $m$
($1 \le m \le n-1$) components if $g(c) \le \frac{|E(G)|}{n-m}f(c)$ for any
color $c$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4803</identifier>
 <datestamp>2011-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4803</id><created>2011-02-23</created><authors><author><keyname>Langovoy</keyname><forenames>Mikhail A.</forenames></author><author><keyname>Wittich</keyname><forenames>Olaf</forenames></author></authors><title>Detection of objects in noisy images and site percolation on square
  lattices</title><categories>math.ST cs.CV math.PR stat.AP stat.ME stat.TH</categories><comments>This paper first appeared as EURANDOM Report 2009-035 on November 11,
  2009. Link to the paper at the EURANDOM repository:
  http://www.eurandom.tue.nl/reports/2009/035-report.pdf Link to the abstract
  at EURANDOM repository:
  http://www.eurandom.tue.nl/reports/2009/035-abstract.pdf</comments><report-no>EURANDOM Report 2009-035</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel probabilistic method for detection of objects in noisy
images. The method uses results from percolation and random graph theories. We
present an algorithm that allows to detect objects of unknown shapes in the
presence of random noise. Our procedure substantially differs from
wavelets-based algorithms. The algorithm has linear complexity and exponential
accuracy and is appropriate for real-time systems. We prove results on
consistency and algorithmic complexity of our procedure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4807</identifier>
 <datestamp>2012-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4807</id><created>2011-02-23</created><updated>2012-03-06</updated><authors><author><keyname>Agarwal</keyname><forenames>Alekh</forenames></author><author><keyname>Negahban</keyname><forenames>Sahand N.</forenames></author><author><keyname>Wainwright</keyname><forenames>Martin J.</forenames></author></authors><title>Noisy matrix decomposition via convex relaxation: Optimal rates in high
  dimensions</title><categories>stat.ML cs.IT cs.LG math.IT</categories><comments>41 pages, 2 figures</comments><report-no>IMS-AOS-AOS1000</report-no><msc-class>62F30, 62F30 (Primary) 62H12 (Secondary)</msc-class><journal-ref>Annals of Statistics 2012, Vol. 40, No. 2, 1171-1197</journal-ref><doi>10.1214/12-AOS1000</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze a class of estimators based on convex relaxation for solving
high-dimensional matrix decomposition problems. The observations are noisy
realizations of a linear transformation $\mathfrak{X}$ of the sum of an
approximately) low rank matrix $\Theta^\star$ with a second matrix
$\Gamma^\star$ endowed with a complementary form of low-dimensional structure;
this set-up includes many statistical models of interest, including factor
analysis, multi-task regression, and robust covariance estimation. We derive a
general theorem that bounds the Frobenius norm error for an estimate of the
pair $(\Theta^\star, \Gamma^\star)$ obtained by solving a convex optimization
problem that combines the nuclear norm with a general decomposable regularizer.
Our results utilize a &quot;spikiness&quot; condition that is related to but milder than
singular vector incoherence. We specialize our general result to two cases that
have been studied in past work: low rank plus an entrywise sparse matrix, and
low rank plus a columnwise sparse matrix. For both models, our theory yields
non-asymptotic Frobenius error bounds for both deterministic and stochastic
noise matrices, and applies to matrices $\Theta^\star$ that can be exactly or
approximately low rank, and matrices $\Gamma^\star$ that can be exactly or
approximately sparse. Moreover, for the case of stochastic noise matrices and
the identity observation operator, we establish matching lower bounds on the
minimax error. The sharpness of our predictions is confirmed by numerical
simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4810</identifier>
 <datestamp>2011-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4810</id><created>2011-02-23</created><authors><author><keyname>Banavar</keyname><forenames>Mahesh K.</forenames></author><author><keyname>Tepedelenlioglu</keyname><forenames>Cihan</forenames></author><author><keyname>Spanias</keyname><forenames>Andreas</forenames></author></authors><title>Distributed SNR Estimation using Constant Modulus Signaling over
  Gaussian Multiple-Access Channels</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE Transactions on Signal Processing. 18 pages, 8
  figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A sensor network is used for distributed joint mean and variance estimation,
in a single time snapshot. Sensors observe a signal embedded in noise, which
are phase modulated using a constant-modulus scheme and transmitted over a
Gaussian multiple-access channel to a fusion center, where the mean and
variance are estimated jointly, using an asymptotically minimum-variance
estimator, which is shown to decouple into simple individual estimators of the
mean and the variance. The constant-modulus phase modulation scheme ensures a
fixed transmit power, robust estimation across several sensing noise
distributions, as well as an SNR estimate that requires a single set of
transmissions from the sensors to the fusion center, unlike the
amplify-and-forward approach. The performance of the estimators of the mean and
variance are evaluated in terms of asymptotic variance, which is used to
evaluate the performance of the SNR estimator in the case of Gaussian, Laplace
and Cauchy sensing noise distributions. For each sensing noise distribution,
the optimal phase transmission parameters are also determined. The asymptotic
relative efficiency of the mean and variance estimators is evaluated. It is
shown that among the noise distributions considered, the estimators are
asymptotically efficient only when the noise distribution is Gaussian.
Simulation results corroborate analytical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4812</identifier>
 <datestamp>2011-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4812</id><created>2011-02-23</created><updated>2011-03-04</updated><authors><author><keyname>Stanica</keyname><forenames>Pante</forenames></author><author><keyname>Martinsen</keyname><forenames>Thor</forenames></author></authors><title>Octal Bent Generalized Boolean Functions</title><categories>math.CO cs.IT math.IT</categories><msc-class>05B10, 06E30, 94C10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we characterize (octal) bent generalized Boolean functions
defined on $\BBZ_2^n$ with values in $\BBZ_8$. Moreover, we propose several
constructions of such generalized bent functions for both $n$ even and $n$ odd.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4816</identifier>
 <datestamp>2011-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4816</id><created>2011-02-23</created><authors><author><keyname>Langovoy</keyname><forenames>Mikhail A.</forenames></author><author><keyname>Wittich</keyname><forenames>Olaf</forenames></author></authors><title>Computationally efficient algorithms for statistical image processing.
  Implementation in R</title><categories>stat.CO cs.CV stat.AP stat.ME stat.ML</categories><comments>This paper initially appeared in 2010 as EURANDOM Report 2010-053.
  Link to EURANDOM repository:
  http://www.eurandom.tue.nl/reports/2010/053-report.pdf Link to the abstract
  at EURANDOM repository:
  http://www.eurandom.tue.nl/reports/2010/053-abstract.pdf</comments><report-no>EURANDOM Report 2010-053</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the series of our earlier papers on the subject, we proposed a novel
statistical hypothesis testing method for detection of objects in noisy images.
The method uses results from percolation theory and random graph theory. We
developed algorithms that allowed to detect objects of unknown shapes in the
presence of nonparametric noise of unknown level and of unknown distribution.
No boundary shape constraints were imposed on the objects, only a weak bulk
condition for the object's interior was required. Our algorithms have linear
complexity and exponential accuracy. In the present paper, we describe an
implementation of our nonparametric hypothesis testing method. We provide a
program that can be used for statistical experiments in image processing. This
program is written in the statistical programming language R.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4821</identifier>
 <datestamp>2011-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4821</id><created>2011-02-23</created><authors><author><keyname>Gleich</keyname><forenames>David F.</forenames></author><author><keyname>Lim</keyname><forenames>Lek-Heng</forenames></author></authors><title>Rank Aggregation via Nuclear Norm Minimization</title><categories>cs.NA</categories><comments>9 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The process of rank aggregation is intimately intertwined with the structure
of skew-symmetric matrices. We apply recent advances in the theory and
algorithms of matrix completion to skew-symmetric matrices. This combination of
ideas produces a new method for ranking a set of items. The essence of our idea
is that a rank aggregation describes a partially filled skew-symmetric matrix.
We extend an algorithm for matrix completion to handle skew-symmetric data and
use that to extract ranks for each item. Our algorithm applies to both pairwise
comparison and rating data. Because it is based on matrix completion, it is
robust to both noise and incomplete data. We show a formal recovery result for
the noiseless case and present a detailed study of the algorithm on synthetic
data and Netflix ratings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4825</identifier>
 <datestamp>2011-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4825</id><created>2011-02-23</created><authors><author><keyname>Appuswamy</keyname><forenames>Rathinakumar</forenames></author><author><keyname>Franceschetti</keyname><forenames>Massimo</forenames></author></authors><title>Computing linear functions by linear coding over networks</title><categories>cs.IT math.AC math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the scenario in which a set of sources generate messages in a
network and a receiver node demands an arbitrary linear function of these
messages. We formulate an algebraic test to determine whether an arbitrary
network can compute linear functions using linear codes. We identify a class of
linear functions that can be computed using linear codes in every network that
satisfies a natural cut-based condition. Conversely, for another class of
linear functions, we show that the cut-based condition does not guarantee the
existence of a linear coding solution. For linear functions over the binary
field, the two classes are complements of each other.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4842</identifier>
 <datestamp>2011-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4842</id><created>2011-02-23</created><updated>2011-08-18</updated><authors><author><keyname>Koutis</keyname><forenames>Ioannis</forenames></author><author><keyname>Miller</keyname><forenames>Gary</forenames></author><author><keyname>Peng</keyname><forenames>Richard</forenames></author></authors><title>A nearly-mlogn time solver for SDD linear systems</title><categories>cs.DS</categories><comments>to appear in FOCS11</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an improved algorithm for solving symmetrically diagonally
dominant linear systems. On input of an $n\times n$ symmetric diagonally
dominant matrix $A$ with $m$ non-zero entries and a vector $b$ such that
$A\bar{x} = b$ for some (unknown) vector $\bar{x}$, our algorithm computes a
vector $x$ such that $||{x}-\bar{x}||_A &lt; \epsilon ||\bar{x}||_A $
{$||\cdot||_A$ denotes the A-norm} in time $${\tilde O}(m\log n \log
(1/\epsilon)).$$
  The solver utilizes in a standard way a `preconditioning' chain of
progressively sparser graphs. To claim the faster running time we make a
two-fold improvement in the algorithm for constructing the chain. The new chain
exploits previously unknown properties of the graph sparsification algorithm
given in [Koutis,Miller,Peng, FOCS 2010], allowing for stronger preconditioning
properties. We also present an algorithm of independent interest that
constructs nearly-tight low-stretch spanning trees in time
$\tilde{O}(m\log{n})$, a factor of $O(\log{n})$ faster than the algorithm in
[Abraham,Bartal,Neiman, FOCS 2008]. This speedup directly reflects on the
construction time of the preconditioning chain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4853</identifier>
 <datestamp>2011-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4853</id><created>2011-02-22</created><authors><author><keyname>Lubritto</keyname><forenames>C.</forenames></author><author><keyname>Petraglia</keyname><forenames>A.</forenames></author><author><keyname>Vetromile</keyname><forenames>C.</forenames></author><author><keyname>Curcuruto</keyname><forenames>S.</forenames></author><author><keyname>Logorelli</keyname><forenames>M.</forenames></author><author><keyname>Marsico</keyname><forenames>G.</forenames></author><author><keyname>D'Onofrio</keyname><forenames>A.</forenames></author></authors><title>Energy and environmental aspects of mobile communication systems</title><categories>physics.soc-ph cs.CY cs.NI</categories><comments>9 pages, 6 figures</comments><journal-ref>Energy, Volume 36, Issue 2, February 2011, Pages 1109-1114</journal-ref><doi>10.1016/j.energy.2010.11.039</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The reduction of the energy consumptions of a Telecommunication Power System
represents one of the critical factors of the telecommunication technologies,
both to allow a sizeable saving of economic resources and to realize
&quot;sustainable&quot; development actions. The consumption of about one hundred base
stations for mobile phones were monitored for a total of over one thousand
days, in order to study the energy consumption in relation to the
environmental, electric and logistics parameters of the stations themselves. It
was possible to survey, then, the role of the mobile communication systems in
the general national energy framework and to plot the best areas of
intervention for saving energy and improving the environmental impact, showing
the role played by air conditioning and transmission equipments. Finally, new
transmission algorithms and the use of renewable energy based techniques have
been tested.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4865</identifier>
 <datestamp>2011-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4865</id><created>2011-02-23</created><authors><author><keyname>Platonov</keyname><forenames>Anatoliy</forenames></author></authors><title>Power-Bandwidth Efficiency and Capacity of Wireless Feedback
  Communication Systems</title><categories>cs.IT math.IT</categories><comments>5 pages, 5 figures, submitted to ISIT 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper is devoted to the analysis of problems appearing in optimisation
and improvement of the power-bandwidth efficiency of digital communication
feedback systems (FCS). There is shown that unlike digital systems, adaptive
FCS with the analogue forward transmission allow full optimisation and
derivation of optimal transmission-reception algorithm approaching their
efficiency to the Shannon boundary. Differences between the forward channel
capacity and capacity of adaptive FCS as communication unit, as well as their
influence of the power-bandwidth efficiency of transmission are considered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4866</identifier>
 <datestamp>2011-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4866</id><created>2011-02-23</created><authors><author><keyname>Solomon</keyname><forenames>Shay</forenames></author></authors><title>The MST of Symmetric Disk Graphs (in Arbitrary Metrics) is Light</title><categories>cs.CG cs.DS</categories><comments>13 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider an n-point metric M = (V,delta), and a transmission range assignment
r: V \rightarrow \mathbb R^+ that maps each point v in V to the disk of radius
r(v) around it. The {symmetric disk graph} (henceforth, SDG) that corresponds
to M and r is the undirected graph over V whose edge set includes an edge (u,v)
if both r(u) and r(v) are no smaller than delta(u,v). SDGs are often used to
model wireless communication networks.
  Abu-Affash, Aschner, Carmi and Katz (SWAT 2010, \cite{AACK10}) showed that
for any {2-dimensional Euclidean} n-point metric M, the weight of the MST of
every {connected} SDG for M is O(log n) w(MST(M)), and that this bound is
tight. However, the upper bound proof of \cite{AACK10} relies heavily on basic
geometric properties of 2-dimensional Euclidean metrics, and does not extend to
higher dimensions. A natural question that arises is whether this surprising
upper bound of \cite{AACK10} can be generalized for wider families of metrics,
such as 3-dimensional Euclidean metrics.
  In this paper we generalize the upper bound of Abu-Affash et al.
\cite{AACK10} for Euclidean metrics of any dimension. Furthermore, our upper
bound extends to {arbitrary metrics} and, in particular, it applies to any of
the normed spaces ell_p. Specifically, we demonstrate that for {any} n-point
metric M, the weight of the MST of every connected SDG for M is O(log n)
w(MST(M)).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4868</identifier>
 <datestamp>2011-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4868</id><created>2011-02-23</created><updated>2011-10-05</updated><authors><author><keyname>Tang</keyname><forenames>Gongguo</forenames></author><author><keyname>Nehorai</keyname><forenames>Arye</forenames></author></authors><title>Verifiable and computable performance analysis of sparsity recovery</title><categories>cs.IT math.IT math.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we develop verifiable and computable performance analysis of
sparsity recovery. We define a family of goodness measures for arbitrary
sensing matrices as a set of optimization problems, and design algorithms with
a theoretical global convergence guarantee to compute these goodness measures.
The proposed algorithms solve a series of second-order cone programs, or linear
programs. As a by-product, we implement an efficient algorithm to verify a
sufficient condition for exact sparsity recovery in the noise-free case. We
derive performance bounds on the recovery errors in terms of these goodness
measures. We also analytically demonstrate that the developed goodness measures
are non-degenerate for a large class of random sensing matrices, as long as the
number of measurements is relatively large. Numerical experiments show that,
compared with the restricted isometry based performance bounds, our error
bounds apply to a wider range of problems and are tighter, when the sparsity
levels of the signals are relatively low.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4873</identifier>
 <datestamp>2011-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4873</id><created>2011-02-23</created><authors><author><keyname>Andris</keyname><forenames>C.</forenames></author></authors><title>Weighted Radial Variation for Node Feature Classification</title><categories>physics.data-an cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Connections created from a node-edge matrix have been traditionally difficult
to visualize and analyze because of the number of flows to be rendered in a
limited feature or cartographic space. Because analyzing connectivity patterns
is useful for understanding the complex dynamics of human and information flow
that connect non-adjacent space, techniques that allow for visual data mining
or static representations of system dynamics are a growing field of research.
Here, we create a Weighted Radial Variation (WRV) technique to classify a set
of nodes based on the configuration of their radially-emanating vector flows.
Each entity's vector is syncopated in terms of cardinality, direction, length,
and flow magnitude. The WRV process unravels each star-like entity's individual
flow vectors on a 0-360{\deg} spectrum, to form a unique signal whose
distribution depends on the flow presence at each step around the entity, and
is further characterized by flow distance and magnitude. The signals are
processed with an unsupervised classification method that clusters entities
with similar signatures in order to provide a typology for each node in the
system of spatial flows. We use a case study of U.S. county-to-county human
incoming and outgoing migration data to test our method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4876</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4876</id><created>2011-02-23</created><updated>2011-06-06</updated><authors><author><keyname>Taylor</keyname><forenames>Dane</forenames></author><author><keyname>Restrepo</keyname><forenames>Juan G.</forenames></author></authors><title>Network connectivity during mergers and growth: optimizing the addition
  of a module</title><categories>physics.soc-ph cond-mat.dis-nn cs.SI</categories><comments>7 pages, 5 figures</comments><doi>10.1103/PhysRevE.83.066112</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The principal eigenvalue $\lambda$ of a network's adjacency matrix often
determines dynamics on the network (e.g., in synchronization and spreading
processes) and some of its structural properties (e.g., robustness against
failure or attack) and is therefore a good indicator for how ``strongly'' a
network is connected. We study how $\lambda$ is modified by the addition of a
module, or community, which has broad applications, ranging from those
involving a single modification (e.g., introduction of a drug into a biological
process) to those involving repeated additions (e.g., power-grid and transit
development). We describe how to optimally connect the module to the network to
either maximize or minimize the shift in $\lambda$, noting several applications
of directing dynamics on networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4878</identifier>
 <datestamp>2011-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4878</id><created>2011-02-23</created><updated>2011-09-24</updated><authors><author><keyname>Hasegawa</keyname><forenames>Takehisa</forenames></author><author><keyname>Masuda</keyname><forenames>Naoki</forenames></author></authors><title>Robustness of networks against propagating attacks under vaccination
  strategies</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><comments>16 pages, 7 figures</comments><journal-ref>J. Stat. Mech. (2011) P09014</journal-ref><doi>10.1088/1742-5468/2011/09/P09014</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the effect of vaccination on robustness of networks against
propagating attacks that obey the susceptible-infected-removed model.By
extending the generating function formalism developed by Newman (2005), we
analytically determine the robustness of networks that depends on the
vaccination parameters. We consider the random defense where nodes are
vaccinated randomly and the degree-based defense where hubs are preferentially
vaccinated. We show that when vaccines are inefficient, the random graph is
more robust against propagating attacks than the scale-free network. When
vaccines are relatively efficient, the scale-free network with the degree-based
defense is more robust than the random graph with the random defense and the
scale-free network with the random defense.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4884</identifier>
 <datestamp>2011-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4884</id><created>2011-02-23</created><updated>2011-04-29</updated><authors><author><keyname>Fox</keyname><forenames>Kyle</forenames></author></authors><title>Upper Bounds for Maximally Greedy Binary Search Trees</title><categories>cs.DS</categories><comments>To appear, WADS 2011. rev 1: Fixed accidental upload of out-of-date
  Fig. 1; rev 2: Added figures and made updates based on reviewer comments</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  At SODA 2009, Demaine et al. presented a novel connection between binary
search trees (BSTs) and subsets of points on the plane. This connection was
independently discovered by Derryberry et al. As part of their results, Demaine
et al. considered GreedyFuture, an offline BST algorithm that greedily
rearranges the search path to minimize the cost of future searches. They showed
that GreedyFuture is actually an online algorithm in their geometric view, and
that there is a way to turn GreedyFuture into an online BST algorithm with only
a constant factor increase in total search cost. Demaine et al. conjectured
this algorithm was dynamically optimal, but no upper bounds were given in their
paper. We prove the first non-trivial upper bounds for the cost of search
operations using GreedyFuture including giving an access lemma similar to that
found in Sleator and Tarjan's classic paper on splay trees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4885</identifier>
 <datestamp>2011-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4885</id><created>2011-02-23</created><authors><author><keyname>Berend</keyname><forenames>Daniel</forenames></author><author><keyname>Sapir</keyname><forenames>Amir</forenames></author><author><keyname>Solomon</keyname><forenames>Shay</forenames></author></authors><title>The Tower of Hanoi problem on Path_h graphs</title><categories>cs.DM</categories><comments>32 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The generalized Tower of Hanoi problem with h \ge 4 pegs is known to require
a sub-exponentially fast growing number of moves in order to transfer a pile of
n disks from one peg to another. In this paper we study the Path_h variant,
where the pegs are placed along a line, and disks can be moved from a peg to
its nearest neighbor(s) only.
  Whereas in the simple variant there are h(h-1)/2 possible bi-directional
interconnections among pegs, here there are only h-1 of them. Despite the
significant reduction in the number of interconnections, the number of moves
needed to transfer a pile of n disks between any two pegs also grows
sub-exponentially as a function of n.
  We study these graphs, identify sets of mutually recursive tasks, and obtain
a relatively tight upper bound for the number of moves, depending on h, n and
the source and destination pegs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4904</identifier>
 <datestamp>2011-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4904</id><created>2011-02-23</created><authors><author><keyname>DasGupta</keyname><forenames>Bhaskar</forenames></author><author><keyname>Vera-Licona</keyname><forenames>Paola</forenames></author><author><keyname>Sontag</keyname><forenames>Eduardo</forenames></author></authors><title>Reverse Engineering of Molecular Networks from a Common Combinatorial
  Approach</title><categories>q-bio.MN cs.CE q-bio.QM</categories><comments>15 pages; in Algorithms in Computational Molecular Biology:
  Techniques, Approaches and Applications, M. Elloumi and A. Zomaya (editors),
  John Wiley &amp; Sons, Inc., January 2011</comments><msc-class>92C42, 92C37, 92B05</msc-class><acm-class>J.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The understanding of molecular cell biology requires insight into the
structure and dynamics of networks that are made up of thousands of interacting
molecules of DNA, RNA, proteins, metabolites, and other components. One of the
central goals of systems biology is the unraveling of the as yet poorly
characterized complex web of interactions among these components. This work is
made harder by the fact that new species and interactions are continuously
discovered in experimental work, necessitating the development of adaptive and
fast algorithms for network construction and updating. Thus, the
&quot;reverse-engineering&quot; of networks from data has emerged as one of the central
concern of systems biology research.
  A variety of reverse-engineering methods have been developed, based on tools
from statistics, machine learning, and other mathematical domains. In order to
effectively use these methods, it is essential to develop an understanding of
the fundamental characteristics of these algorithms. With that in mind, this
chapter is dedicated to the reverse-engineering of biological systems.
  Specifically, we focus our attention on a particular class of methods for
reverse-engineering, namely those that rely algorithmically upon the so-called
&quot;hitting-set&quot; problem, which is a classical combinatorial and computer science
problem, Each of these methods utilizes a different algorithm in order to
obtain an exact or an approximate solution of the hitting set problem. We will
explore the ultimate impact that the alternative algorithms have on the
inference of published in silico biological networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4914</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4914</id><created>2011-02-24</created><updated>2011-03-06</updated><authors><author><keyname>Kenna</keyname><forenames>Ralph</forenames><affiliation>AMRC Coventry</affiliation></author><author><keyname>Berche</keyname><forenames>Bertrand</forenames><affiliation>IJL</affiliation></author></authors><title>Statistics of statisticians: Critical mass of statistics and operational
  research groups in the UK</title><categories>math.ST cs.DL physics.soc-ph stat.TH</categories><proxy>ccsd</proxy><journal-ref>International Journal of Modern Physics: Conference Series 16
  (2012) 29-40</journal-ref><doi>10.1142/S2010194512007751</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using a recently developed model, inspired by mean field theory in
statistical physics, and data from the UK's Research Assessment Exercise, we
analyse the relationship between the quality of statistics and operational
research groups and the quantity researchers in them. Similar to other academic
disciplines, we provide evidence for a linear dependency of quality on quantity
up to an upper critical mass, which is interpreted as the average maximum
number of colleagues with whom a researcher can communicate meaningfully within
a research group. The model also predicts a lower critical mass, which research
groups should strive to achieve to avoid extinction. For statistics and
operational research, the lower critical mass is estimated to be 9 $\pm$ 3. The
upper critical mass, beyond which research quality does not significantly
depend on group size, is about twice this value.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4922</identifier>
 <datestamp>2011-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4922</id><created>2011-02-24</created><authors><author><keyname>Yin</keyname><forenames>Minghao</forenames></author><author><keyname>Huang</keyname><forenames>Ping</forenames></author></authors><title>Counting Solutions of Constraint Satisfiability Problems:Exact Phase
  Transitions and Approximate Algorithm</title><categories>cs.AI cs.CC</categories><comments>submitted to AAAI-11</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The study of phase transition phenomenon of NP complete problems plays an
important role in understanding the nature of hard problems. In this paper, we
follow this line of research by considering the problem of counting solutions
of Constraint Satisfaction Problems (#CSP). We consider the random model, i.e.
RB model. We prove that phase transition of #CSP does exist as the number of
variables approaches infinity and the critical values where phase transitions
occur are precisely located. Preliminary experimental results also show that
the critical point coincides with the theoretical derivation. Moreover, we
propose an approximate algorithm to estimate the expectation value of the
solutions number of a given CSP instance of RB model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4923</identifier>
 <datestamp>2011-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4923</id><created>2011-02-24</created><updated>2011-05-28</updated><authors><author><keyname>M.</keyname><forenames>Ashok Kumar</forenames></author><author><keyname>Sundaresan</keyname><forenames>Rajesh</forenames></author></authors><title>Further Results on Geometric Properties of a Family of Relative
  Entropies</title><categories>cs.IT math.IT</categories><comments>7 pages, Prop. 5 modified, in Proceedings of the 2011 IEEE
  International Symposium on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper extends some geometric properties of a one-parameter family of
relative entropies. These arise as redundancies when cumulants of compressed
lengths are considered instead of expected compressed lengths. These parametric
relative entropies are a generalization of the Kullback-Leibler divergence.
They satisfy the Pythagorean property and behave like squared distances. This
property, which was known for finite alphabet spaces, is now extended for
general measure spaces. Existence of projections onto convex and certain closed
sets is also established. Our results may have applications in the R\'enyi
entropy maximization rule of statistical physics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4924</identifier>
 <datestamp>2011-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4924</id><created>2011-02-24</created><authors><author><keyname>Zhou</keyname><forenames>Junping</forenames></author><author><keyname>Yin</keyname><forenames>Minghao</forenames></author></authors><title>New Worst-Case Upper Bound for #XSAT</title><categories>cs.AI</categories><comments>submitted to AAAI-10</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An algorithm running in O(1.1995n) is presented for counting models for exact
satisfiability formulae(#XSAT). This is faster than the previously best
algorithm which runs in O(1.2190n). In order to improve the efficiency of the
algorithm, a new principle, i.e. the common literals principle, is addressed to
simplify formulae. This allows us to eliminate more common literals. In
addition, we firstly inject the resolution principles into solving #XSAT
problem, and therefore this further improves the efficiency of the algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4925</identifier>
 <datestamp>2011-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4925</id><created>2011-02-24</created><updated>2011-03-25</updated><authors><author><keyname>Yin</keyname><forenames>Minghao</forenames></author></authors><title>Worst-Case Upper Bound for (1, 2)-QSAT</title><categories>cs.AI cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The rigorous theoretical analysis of the algorithm for a subclass of QSAT,
i.e. (1, 2)-QSAT, has been proposed in the literature. (1, 2)-QSAT, first
introduced in SAT'08, can be seen as quantified extended 2-CNF formulas. Until
now, within our knowledge, there exists no algorithm presenting the worst upper
bound for (1, 2)-QSAT. Therefore in this paper, we present an exact algorithm
to solve (1, 2)-QSAT. By analyzing the algorithms, we obtain a worst-case upper
bound O(1.4142m), where m is the number of clauses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4926</identifier>
 <datestamp>2011-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4926</id><created>2011-02-24</created><updated>2011-03-25</updated><authors><author><keyname>Zhou</keyname><forenames>Junping</forenames></author><author><keyname>Yin</keyname><forenames>Minghao</forenames></author></authors><title>New Worst-Case Upper Bound for X3SAT</title><categories>cs.AI cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The rigorous theoretical analyses of algorithms for exact 3-satisfiability
(X3SAT) have been proposed in the literature. As we know, previous algorithms
for solving X3SAT have been analyzed only regarding the number of variables as
the parameter. However, the time complexity for solving X3SAT instances depends
not only on the number of variables, but also on the number of clauses.
Therefore, it is significant to exploit the time complexity from the other
point of view, i.e. the number of clauses. In this paper, we present algorithms
for solving X3SAT with rigorous complexity analyses using the number of clauses
as the parameter. By analyzing the algorithms, we obtain the new worst-case
upper bounds O(1.15855m), where m is the number of clauses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4930</identifier>
 <datestamp>2011-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4930</id><created>2011-02-24</created><updated>2011-05-05</updated><authors><author><keyname>Kramer</keyname><forenames>Gerhard</forenames></author><author><keyname>Hou</keyname><forenames>Jie</forenames></author></authors><title>Short-Message Quantize-Forward Network Coding</title><categories>cs.IT math.IT</categories><journal-ref>8th International Workshop on Multi-Carrier Systems &amp; Solutions
  (invited), Herrsching, Germany, May 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent work for single-relay channels shows that quantize-forward (QF) with
long-message encoding achieves the same reliable rates as compress-forward (CF)
with short-message encoding. It is shown that short-message QF with backward or
pipelined (sliding-window) decoding also achieves the same rates. Similarly,
for many relays and sources, short-message QF with backward decoding achieves
the same rates as long-message QF. Several practical advantages of
short-message encoding are pointed out, e.g., reduced delay and simpler
modulation. Furthermore, short-message encoding lets relays use decode-forward
(DF) if their channel quality is good, thereby enabling multiinput,
multi-output (MIMO) gains that are not possible with long-message encoding.
Finally, one may combine the advantages of long- and short-message encoding by
hashing a long message to short messages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4946</identifier>
 <datestamp>2011-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4946</id><created>2011-02-24</created><authors><author><keyname>Casta&#xf1;eda</keyname><forenames>Armando</forenames></author><author><keyname>Herlihy</keyname><forenames>Maurice</forenames></author><author><keyname>Rajsbaum</keyname><forenames>Sergio</forenames></author></authors><title>An Equivariance Theorem with Applications to Renaming (Preliminary
  Version)</title><categories>cs.DC</categories><comments>20 pages, 2 figures</comments><msc-class>68Q99, 55U15, 55N91</msc-class><acm-class>D.1.3; F.1.1; F.1.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the renaming problem, each process in a distributed system is issued a
unique name from a large name space, and the processes must coordinate with one
another to choose unique names from a much smaller name space. We show that
lower bounds on the solvability of renaming in an asynchronous distributed
system can be formulated as a purely topological question about the existence
of an equivariant chain map from a topological disk to a topological annulus.
Proving the non-existence of such a map implies the non-existence of a
distributed renaming algorithm in several related models of computation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4951</identifier>
 <datestamp>2011-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4951</id><created>2011-02-24</created><authors><author><keyname>Bhattacharya</keyname><forenames>Srimanta</forenames></author><author><keyname>Ruj</keyname><forenames>Sushmita</forenames></author><author><keyname>Roy</keyname><forenames>Bimal</forenames></author></authors><title>Combinatorial Batch Codes: A Lower Bound and Optimal Constructions</title><categories>cs.DM math.CO</categories><msc-class>05C65, 05D15</msc-class><acm-class>E.4; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Batch codes, introduced by Ishai, Kushilevitz, Ostrovsky and Sahai in [1],
are methods for solving the following data storage problem: n data items are to
be stored in m servers in such a way that any k of the n items can be retrieved
by reading at most t items from each server, and that the total number of items
stored in m servers is N . A Combinatorial batch code (CBC) is a batch code
where each data item is stored without change, i.e., each stored data item is a
copy of one of the n data items. One of the basic yet challenging problems is
to find optimal CBCs, i.e., CBCs for which total storage (N) is minimal for
given values of n, m, k, and t. In [2], Paterson, Stinson and Wei exclusively
studied CBCs and gave constructions of some optimal CBCs. In this article, we
give a lower bound on the total storage (N) for CBCs. We give explicit
construction of optimal CBCs for a range of values of n. For a different range
of values of n, we give explicit construction of optimal and almost optimal
CBCs. Our results partly settle an open problem of [2].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4954</identifier>
 <datestamp>2011-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4954</id><created>2011-02-24</created><authors><author><keyname>Bugarin</keyname><forenames>Florian</forenames><affiliation>LAAS, CROMeP</affiliation></author><author><keyname>Henrion</keyname><forenames>Didier</forenames><affiliation>LAAS, CTU/FEE</affiliation></author><author><keyname>Lasserre</keyname><forenames>Jean-Bernard</forenames><affiliation>LAAS</affiliation></author></authors><title>Minimizing the sum of many rational functions</title><categories>math.OC cs.SY</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of globally minimizing the sum of many rational
functions over a given compact semialgebraic set. The number of terms can be
large (10 to 100), the degree of each term should be small (up to 10), and the
number of variables can be large (10 to 100) provided some kind of sparsity is
present. We describe a formulation of the rational optimization problem as a
generalized moment problem and its hierarchy of convex semidefinite
relaxations. Under some conditions we prove that the sequence of optimal values
converges to the globally optimal value. We show how public-domain software can
be used to model and solve such problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4967</identifier>
 <datestamp>2011-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4967</id><created>2011-02-24</created><authors><author><keyname>Ghaffar</keyname><forenames>Rizwan</forenames></author><author><keyname>Toumpakaris</keyname><forenames>Dimitris</forenames></author><author><keyname>Lee</keyname><forenames>Jungwon</forenames></author></authors><title>Achievable rates for transmission of discrete constellations over the
  Gaussian MAC channe</title><categories>cs.IT math.IT</categories><comments>Submitted to ISIT 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider the achievable rate region of the Gaussian Multiple
Access Channel (MAC) when suboptimal transmission schemes are employed.
Focusing on the two-user MAC and assuming uncoded Pulse Amplitude Modulation
(PAM), we derive a rate region that is a pentagon, and propose a strategy with
which it can be achieved. We also compare the region with outer bounds and with
orthogonal transmission.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4971</identifier>
 <datestamp>2011-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4971</id><created>2011-02-24</created><updated>2011-06-10</updated><authors><author><keyname>Madet</keyname><forenames>Antoine</forenames><affiliation>PPS</affiliation></author><author><keyname>Amadio</keyname><forenames>Roberto M.</forenames><affiliation>PPS</affiliation></author></authors><title>Elementary affine $lambda$-calculus with multithreading and side effects</title><categories>cs.PL</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Linear logic provides a framework to control the complexity of higher-order
functional programs. We present an extension of this framework to programs with
multithreading and side effects focusing on the case of elementary time. Our
main contributions are as follows. First, we provide a new combinatorial proof
of termination in elementary time for the functional case. Second, we develop
an extension of the approach to a call-by-value $lambda$-calculus with
multithreading and side effects. Third, we introduce an elementary affine type
system that guarantees the standard subject reduction and progress properties.
Finally, we illustrate the programming of iterative functions with side effects
in the presented formalism.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4972</identifier>
 <datestamp>2011-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4972</id><created>2011-02-24</created><authors><author><keyname>Guibas</keyname><forenames>Leonidas J.</forenames><affiliation>LJK</affiliation></author><author><keyname>M&#xe9;rigot</keyname><forenames>Quentin</forenames><affiliation>LJK</affiliation></author><author><keyname>Morozov</keyname><forenames>Dmitriy</forenames><affiliation>LBNL</affiliation></author></authors><title>Witnessed k-Distance</title><categories>cs.CG</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distance function to a compact set plays a central role in several areas of
computational geometry. Methods that rely on it are robust to the perturbations
of the data by the Hausdorff noise, but fail in the presence of outliers. The
recently introduced distance to a measure offers a solution by extending the
distance function framework to reasoning about the geometry of probability
measures, while maintaining theoretical guarantees about the quality of the
inferred information. A combinatorial explosion hinders working with distance
to a measure as an ordinary (power) distance function. In this paper, we
analyze an approximation scheme that keeps the representation linear in the
size of the input, while maintaining the guarantees on the inference quality
close to those for the exact (but costly) representation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4975</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4975</id><created>2011-02-24</created><authors><author><keyname>Tejedor</keyname><forenames>Vincent</forenames></author><author><keyname>B&#xe9;nichou</keyname><forenames>Olivier</forenames></author><author><keyname>Voituriez</keyname><forenames>Raphael</forenames></author></authors><title>Close or connected? Distance and connectivity effects on transport in
  networks</title><categories>cond-mat.stat-mech cs.SI physics.soc-ph</categories><comments>7 pages, 7 figures</comments><doi>10.1103/PhysRevE.83.066102</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop an analytical approach which provides the dependence of the mean
first-passage time (MFPT) for random walks on complex networks both on the
target connectivity and on the source-target distance. Our approach puts
forward two strongly different behaviors depending on the type - compact or non
compact - of the random walk. In the case of non compact exploration, we show
that the MFPT scales linearly with the inverse connectivity of the target, and
is largely independent of the starting point. On the contrary, in the compact
case the MFPT is controlled by the source-target distance, and we find that
unexpectedly the target connectivity becomes irrelevant for remote targets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4980</identifier>
 <datestamp>2011-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4980</id><created>2011-02-24</created><updated>2011-05-27</updated><authors><author><keyname>Zhang</keyname><forenames>Xin</forenames></author><author><keyname>Liu</keyname><forenames>Guizhen</forenames></author></authors><title>Group edge choosability of planar graphs without adjacent short cycles</title><categories>math.CO cs.DM</categories><comments>9 pages, a very minor revision to its first version</comments><msc-class>05C15, 05C20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we aim to introduce the group version of edge coloring and
list edge coloring, and prove that all 2-degenerate graphs along with some
planar graphs without adjacent short cycles is group
$(\Delta(G)+1)$-edge-choosable while some planar graphs with large girth and
maximum degree is group $\Delta(G)$-edge-choosable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4981</identifier>
 <datestamp>2011-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4981</id><created>2011-02-24</created><authors><author><keyname>Izumi</keyname><forenames>Taisuke</forenames><affiliation>LIP6, INRIA Rocquencourt</affiliation></author><author><keyname>Potop-Butucaru</keyname><forenames>Maria</forenames><affiliation>LIP6, INRIA Rocquencourt</affiliation></author><author><keyname>Valero</keyname><forenames>Mathieu</forenames><affiliation>LIP6, INRIA Rocquencourt</affiliation></author></authors><title>Physical expander in Virtual Tree Overlay</title><categories>cs.DS cs.DC</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a new construction of constantdegree expanders
motivated by their application in P2P overlay networks and in particular in the
design of robust trees overlay. Our key result can be stated as follows.
Consider a complete binary tree T and construct a random pairing {\Pi} between
leaf nodes and internal nodes. We prove that the graph G\Pi obtained from T by
contracting all pairs (leaf-internal nodes) achieves a constant node expansion
with high probability. The use of our result in improving the robustness of
tree overlays is straightforward. That is, if each physical node participating
to the overlay manages a random pair that couples one virtual internal node and
one virtual leaf node then the physical-node layer exhibits a constant
expansion with high probability. We encompass the difficulty of obtaining this
random tree virtualization by proposing a local, selforganizing and churn
resilient uniformly-random pairing algorithm with O(log2 n) running time. Our
algorithm has the merit to not modify the original tree virtual overlay (we
just control the mapping between physical nodes and virtual nodes). Therefore,
our scheme is general and can be applied to a large number of tree overlay
implementations. We validate its performances in dynamic environments via
extensive simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.4992</identifier>
 <datestamp>2011-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.4992</id><created>2011-02-24</created><authors><author><keyname>Zhmakin</keyname><forenames>A. I.</forenames></author></authors><title>Mathematics of Human Motion: from Animation towards Simulation (A View
  form the Outside)</title><categories>cs.GR</categories><comments>Appendix: &quot;The Animator's Eleven Commandments&quot;</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Simulation of human motion is the subject of study in a number of
disciplines: Biomechanics, Robotics, Computer Animation, Control Theory,
Neurophysiology, Medicine, Ergonomics. Since the author has never visited any
of these fields, this review is indeed a passer-by's impression. On the other
hand, he happens to be a human (who occasionally is moving) and, as everybody
else, rates himself an expert in Applied Common Sense. Thus the author hopes
that this view from the {\em outside} will be of some interest not only for the
strangers like himself, but for those who are {\em inside} as well.
  Two flaws of the text that follows are inevitable. First, some essential
issues that are too familar to the specialists to discuss them may be missing.
Second, the author probably failed to provide the uniform &quot;level-of-detail&quot; for
this wide range of topics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5013</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5013</id><created>2011-02-24</created><updated>2012-05-25</updated><authors><author><keyname>Jahn</keyname><forenames>Franz</forenames></author><author><keyname>Kufleitner</keyname><forenames>Manfred</forenames></author><author><keyname>Lauser</keyname><forenames>Alexander</forenames></author></authors><title>Regular Ideal Languages and Their Boolean Combinations</title><categories>cs.FL</categories><comments>Presented at CIAA 2012</comments><msc-class>68Q45</msc-class><acm-class>F.1.1; F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider ideals and Boolean combinations of ideals. For the regular
languages within these classes we give expressively complete automaton models.
In addition, we consider general properties of regular ideals and their Boolean
combinations. These properties include effective algebraic characterizations
and lattice identities.
  In the main part of this paper we consider the following deterministic
one-way automaton models: unions of flip automata, weak automata, and
Staiger-Wagner automata. We show that each of these models is expressively
complete for regular Boolean combination of right ideals. Right ideals over
finite words resemble the open sets in the Cantor topology over infinite words.
An omega-regular language is a Boolean combination of open sets if and only if
it is recognizable by a deterministic Staiger-Wagner automaton; and our result
can be seen as a finitary version of this classical theorem. In addition, we
also consider the canonical automaton models for right ideals, prefix-closed
languages, and factorial languages.
  In the last section, we consider a two-way automaton model which is known to
be expressively complete for two-variable first-order logic. We show that the
above concepts can be adapted to these two-way automata such that the resulting
languages are the right ideals (resp. prefix-closed languages, resp. Boolean
combinations of right ideals) definable in two-variable first-order logic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5030</identifier>
 <datestamp>2011-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5030</id><created>2011-02-24</created><authors><author><keyname>Zhang</keyname><forenames>Peng</forenames></author><author><keyname>Qiu</keyname><forenames>Robert</forenames></author><author><keyname>Guo</keyname><forenames>Nan</forenames></author></authors><title>Demonstration of Spectrum Sensing with Blindly Learned Feature</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spectrum sensing is essential in cognitive radio. By defining leading
\textit{eigenvector} as feature, we introduce a blind feature learning
algorithm (FLA) and a feature template matching (FTM) algorithm using learned
feature for spectrum sensing. We implement both algorithms on Lyrtech software
defined radio platform. Hardware experiment is performed to verify that feature
can be learned blindly. We compare FTM with a blind detector in hardware and
the results show that the detection performance for FTM is about 3 dB better.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5043</identifier>
 <datestamp>2011-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5043</id><created>2011-02-24</created><authors><author><keyname>Abbas</keyname><forenames>Ash Mohammad</forenames></author></authors><title>uRbAn: A Multipath Routing based Architecture with Energy and Mobility
  Management for Quality of Service Support in Mobile Ad hoc Networks</title><categories>cs.NI</categories><comments>6 pages, 6 figures, 1 table</comments><msc-class>68M10, 68M12</msc-class><acm-class>C.2.1; C.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Designing a wireless node that supports quality of service (QoS) in a mobile
ad hoc network is a challenging task. In this paper, we propose an architecture
of a wireless node that may be used to form a mobile ad hoc network that
supports QoS. We discuss the core functionalities required for such a node and
how those functionalities can be incorporated. A feature of our architecture is
that the node has the ability to utilize multiple paths, if available, for the
provision of QoS. However, in the absence of multiple paths it can utilize the
resources provided by a single path between the source and the destination. We
follow a modular approach where each module is expanded iteratively. We compare
the features of our architecture with the existing architectures proposed in
the literature. Our architecture has provisions of energy and mobility
management and it can be customized to design a system-on-chip (SoC).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5046</identifier>
 <datestamp>2013-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5046</id><created>2011-02-24</created><updated>2013-01-02</updated><authors><author><keyname>Seshadhri</keyname><forenames>C.</forenames></author><author><keyname>Pinar</keyname><forenames>Ali</forenames></author><author><keyname>Kolda</keyname><forenames>Tamara G.</forenames></author></authors><title>An In-Depth Analysis of Stochastic Kronecker Graphs</title><categories>cs.SI cs.DM physics.soc-ph</categories><journal-ref>Journal of the ACM 60(2):13 (32 pages), April 2013</journal-ref><doi>10.1145/2450142.2450149</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graph analysis is playing an increasingly important role in science and
industry. Due to numerous limitations in sharing real-world graphs, models for
generating massive graphs are critical for developing better algorithms. In
this paper, we analyze the stochastic Kronecker graph model (SKG), which is the
foundation of the Graph500 supercomputer benchmark due to its favorable
properties and easy parallelization. Our goal is to provide a deeper
understanding of the parameters and properties of this model so that its
functionality as a benchmark is increased. We develop a rigorous mathematical
analysis that shows this model cannot generate a power-law distribution or even
a lognormal distribution. However, we formalize an enhanced version of the SKG
model that uses random noise for smoothing. We prove both in theory and in
practice that this enhancement leads to a lognormal distribution. Additionally,
we provide a precise analysis of isolated vertices, showing that the graphs
that are produced by SKG might be quite different than intended. For example,
between 50% and 75% of the vertices in the Graph500 benchmarks will be
isolated. Finally, we show that this model tends to produce extremely small
core numbers (compared to most social networks and other real graphs) for
common parameter choices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5063</identifier>
 <datestamp>2012-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5063</id><created>2011-02-24</created><updated>2012-03-03</updated><authors><author><keyname>Anandkumar</keyname><forenames>Animashree</forenames></author><author><keyname>Hassidim</keyname><forenames>Avinatan</forenames></author><author><keyname>Kelner</keyname><forenames>Jonathan</forenames></author></authors><title>Topology Discovery of Sparse Random Graphs With Few Participants</title><categories>cs.SI physics.soc-ph stat.ME</categories><comments>A shorter version appears in ACM SIGMETRICS 2011. This version is
  scheduled to appear in J. on Random Structures and Algorithms</comments><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the task of topology discovery of sparse random graphs using
end-to-end random measurements (e.g., delay) between a subset of nodes,
referred to as the participants. The rest of the nodes are hidden, and do not
provide any information for topology discovery. We consider topology discovery
under two routing models: (a) the participants exchange messages along the
shortest paths and obtain end-to-end measurements, and (b) additionally, the
participants exchange messages along the second shortest path. For scenario
(a), our proposed algorithm results in a sub-linear edit-distance guarantee
using a sub-linear number of uniformly selected participants. For scenario (b),
we obtain a much stronger result, and show that we can achieve consistent
reconstruction when a sub-linear number of uniformly selected nodes
participate. This implies that accurate discovery of sparse random graphs is
tractable using an extremely small number of participants. We finally obtain a
lower bound on the number of participants required by any algorithm to
reconstruct the original random graph up to a given edit distance. We also
demonstrate that while consistent discovery is tractable for sparse random
graphs using a small number of participants, in general, there are graphs which
cannot be discovered by any algorithm even with a significant number of
participants, and with the availability of end-to-end information along all the
paths between the participants.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5065</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5065</id><created>2011-02-24</created><updated>2011-03-16</updated><authors><author><keyname>&#xc1;brego</keyname><forenames>Bernardo M.</forenames></author><author><keyname>Cetina</keyname><forenames>Mario</forenames></author><author><keyname>Fern&#xe1;ndez-Merchant</keyname><forenames>Silvia</forenames></author><author><keyname>Lea&#xf1;os</keyname><forenames>Jes&#xfa;s</forenames></author><author><keyname>Salazar</keyname><forenames>Gelasio</forenames></author></authors><title>On $(\le k)$-edges, crossings, and halving lines of geometric drawings
  of $K_n$</title><categories>math.CO cs.CG cs.DM</categories><comments>Second version. In the first version, the PostScript version was OK
  (24 pages long), but in the generated PDF version (27 pages long) the last 3
  pages contained superfluous figures. This is corrected in the second version</comments><msc-class>52C30, 52C10, 52C45, 05C62, 68R10, 60D05, and 52A22</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $P$ be a set of points in general position in the plane. Join all pairs
of points in $P$ with straight line segments. The number of segment-crossings
in such a drawing, denoted by $\crg(P)$, is the \emph{rectilinear crossing
number} of $P$. A \emph{halving line} of $P$ is a line passing though two
points of $P$ that divides the rest of the points of $P$ in (almost) half. The
number of halving lines of $P$ is denoted by $h(P)$. Similarly, a
$k$\emph{-edge}, $0\leq k\leq n/2-1$, is a line passing through two points of
$P$ and leaving exactly $k$ points of $P$ on one side. The number of $(\le
k)$-edges of $P$ is denoted by $E_{\leq k}(P) $. Let $\rcr(n)$, $h(n)$, and
$E_{\leq k}(n) $ denote the minimum of $\crg(P)$, the maximum of $h(P)$, and
the minimum of $E_{\leq k}(P) $, respectively, over all sets $P$ of $n$ points
in general position in the plane. We show that the previously best known lower
bound on $E_{\leq k}(n)$ is tight for $k&lt;\lceil (4n-2) /9\rceil $ and improve
it for all $k\geq \lceil (4n-2) /9 \rceil $. This in turn improves the lower
bound on $\rcr(n)$ from $0.37968\binom{n} {4}+\Theta(n^{3})$ to
{277/729}\binom{n}{4}+\Theta(n^{3})\geq 0.37997\binom{n}{4}+\Theta(n^{3})$. We
also give the exact values of $\rcr(n)$ and $h(n) $ for all $n\leq27$. Exact
values were known only for $n\leq18$ and odd $n\leq21$ for the crossing number,
and for $n\leq14$ and odd $n\leq21$ for halving lines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5079</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5079</id><created>2011-02-24</created><authors><author><keyname>Yu</keyname><forenames>Y.</forenames></author><author><keyname>Petropulu</keyname><forenames>A. P.</forenames></author><author><keyname>Poor</keyname><forenames>H. V.</forenames></author></authors><title>Measurement Matrix Design for Compressive Sensing Based MIMO Radar</title><categories>cs.IT math.IT</categories><doi>10.1109/TSP.2011.2162328</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In colocated multiple-input multiple-output (MIMO) radar using compressive
sensing (CS), a receive node compresses its received signal via a linear
transformation, referred to as measurement matrix. The samples are subsequently
forwarded to a fusion center, where an L1-optimization problem is formulated
and solved for target information. CS-based MIMO radar exploits the target
sparsity in the angle-Doppler-range space and thus achieves the high
localization performance of traditional MIMO radar but with many fewer
measurements. The measurement matrix is vital for CS recovery performance. This
paper considers the design of measurement matrices that achieve an optimality
criterion that depends on the coherence of the sensing matrix (CSM) and/or
signal-to-interference ratio (SIR). The first approach minimizes a performance
penalty that is a linear combination of CSM and the inverse SIR. The second one
imposes a structure on the measurement matrix and determines the parameters
involved so that the SIR is enhanced. Depending on the transmit waveforms, the
second approach can significantly improve SIR, while maintaining CSM comparable
to that of the Gaussian random measurement matrix (GRMM). Simulations indicate
that the proposed measurement matrices can improve detection accuracy as
compared to a GRMM.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5085</identifier>
 <datestamp>2016-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5085</id><created>2011-02-24</created><updated>2016-01-06</updated><authors><author><keyname>Bagrow</keyname><forenames>James P.</forenames></author><author><keyname>Lehmann</keyname><forenames>Sune</forenames></author><author><keyname>Ahn</keyname><forenames>Yong-Yeol</forenames></author></authors><title>Robustness and modular structure in networks</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><comments>14 pages, 9 figures</comments><journal-ref>Network Science, 3 (4): 509-525 (2015)</journal-ref><doi>10.1017/nws.2015.21</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Complex networks have recently attracted much interest due to their
prevalence in nature and our daily lives [1, 2]. A critical property of a
network is its resilience to random breakdown and failure [3-6], typically
studied as a percolation problem [7-9] or by modeling cascading failures
[10-12]. Many complex systems, from power grids and the Internet to the brain
and society [13-15], can be modeled using modular networks comprised of small,
densely connected groups of nodes [16, 17]. These modules often overlap, with
network elements belonging to multiple modules [18, 19]. Yet existing work on
robustness has not considered the role of overlapping, modular structure. Here
we study the robustness of these systems to the failure of elements. We show
analytically and empirically that it is possible for the modules themselves to
become uncoupled or non-overlapping well before the network disintegrates. If
overlapping modular organization plays a role in overall functionality,
networks may be far more vulnerable than predicted by conventional percolation
theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5087</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5087</id><created>2011-02-24</created><updated>2011-06-19</updated><authors><author><keyname>Uchikawa</keyname><forenames>Hironori</forenames></author><author><keyname>Kasai</keyname><forenames>Kenta</forenames></author><author><keyname>Sakaniwa</keyname><forenames>Kohichi</forenames></author></authors><title>Spatially Coupled LDPC Codes for Decode-and-Forward in Erasure Relay
  Channel</title><categories>cs.IT math.IT</categories><comments>7 pages, extended version of ISIT2011</comments><doi>10.1587/transfun.E94.A.2127</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider spatially-coupled protograph-based LDPC codes for the three
terminal erasure relay channel. It is observed that BP threshold value, the
maximal erasure probability of the channel for which decoding error probability
converges to zero, of spatially-coupled codes, in particular spatially-coupled
MacKay-Neal code, is close to the theoretical limit for the relay channel.
Empirical results suggest that spatially-coupled protograph-based LDPC codes
have great potential to achieve theoretical limit of a general relay channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5105</identifier>
 <datestamp>2011-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5105</id><created>2011-02-24</created><authors><author><keyname>Cygan</keyname><forenames>Marek</forenames></author><author><keyname>Grandoni</keyname><forenames>Fabrizio</forenames></author><author><keyname>Leonardi</keyname><forenames>Stefano</forenames></author><author><keyname>Mucha</keyname><forenames>Marcin</forenames></author><author><keyname>Pilipczuk</keyname><forenames>Marcin</forenames></author><author><keyname>Sankowski</keyname><forenames>Piotr</forenames></author></authors><title>Approximation Algorithms for Union and Intersection Covering Problems</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a classical covering problem, we are given a set of requests that we need
to satisfy (fully or partially), by buying a subset of items at minimum cost.
For example, in the k-MST problem we want to find the cheapest tree spanning at
least k nodes of an edge-weighted graph. Here nodes and edges represent
requests and items, respectively.
  In this paper, we initiate the study of a new family of multi-layer covering
problems. Each such problem consists of a collection of h distinct instances of
a standard covering problem (layers), with the constraint that all layers share
the same set of requests. We identify two main subfamilies of these problems: -
in a union multi-layer problem, a request is satisfied if it is satisfied in at
least one layer; - in an intersection multi-layer problem, a request is
satisfied if it is satisfied in all layers. To see some natural applications,
consider both generalizations of k-MST. Union k-MST can model a problem where
we are asked to connect a set of users to at least one of two communication
networks, e.g., a wireless and a wired network. On the other hand, intersection
k-MST can formalize the problem of connecting a subset of users to both
electricity and water.
  We present a number of hardness and approximation results for union and
intersection versions of several standard optimization problems: MST, Steiner
tree, set cover, facility location, TSP, and their partial covering variants.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5112</identifier>
 <datestamp>2014-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5112</id><created>2011-02-24</created><updated>2013-07-19</updated><authors><author><keyname>Venkataramanan</keyname><forenames>Ramji</forenames></author><author><keyname>Tatikonda</keyname><forenames>Sekhar</forenames></author><author><keyname>Ramchandran</keyname><forenames>Kannan</forenames></author></authors><title>Achievable Rates for Channels with Deletions and Insertions</title><categories>cs.IT math.IT</categories><comments>To appear in IEEE Transactions on Information Theory. For the
  deletion channel, the new capacity lower bound improves on the previous best
  bound for deletion probabilities up to 0.3</comments><journal-ref>IEEE Transactions on Information Theory, vol. 59, no.11, pp.
  6990-7013, Nov. 2013</journal-ref><doi>10.1109/TIT.2013.2278181</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers a binary channel with deletions and insertions, where
each input bit is transformed in one of the following ways: it is deleted with
probability d, or an extra bit is added after it with probability i, or it is
transmitted unmodified with probability 1-d-i. A computable lower bound on the
capacity of this channel is derived. The transformation of the input sequence
by the channel may be viewed in terms of runs as follows: some runs of the
input sequence get shorter/longer, some runs get deleted, and some new runs are
added. It is difficult for the decoder to synchronize the channel output
sequence to the transmitted codeword mainly due to deleted runs and new
inserted runs.
  The main idea is a mutual information decomposition in terms of the rate
achieved by a sub-optimal decoder that determines the positions of the deleted
and inserted runs in addition to decoding the transmitted codeword. The mutual
information between the channel input and output sequences is expressed as the
sum of the rate achieved by this decoder and the rate loss due to its
sub-optimality. Obtaining computable lower bounds on each of these quantities
yields a lower bound on the capacity. The bounds proposed in this paper provide
the first characterization of achievable rates for channels with general
insertions, and for channels with both deletions and insertions. For the
special case of the deletion channel, the proposed bound improves on the
previous best lower bound for deletion probabilities up to 0.3.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5123</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5123</id><created>2011-02-24</created><authors><author><keyname>Hassan</keyname><forenames>Amr</forenames></author><author><keyname>Fluke</keyname><forenames>Christopher J.</forenames></author></authors><title>Scientific Visualization in Astronomy: Towards the Petascale Astronomy
  Era</title><categories>astro-ph.IM cs.GR</categories><comments>25 pages, 3 figures, accepted for publication in Publications of the
  Astronomical Society of Australia (PASA)</comments><doi>10.1071/AS10031</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Astronomy is entering a new era of discovery, coincident with the
establishment of new facilities for observation and simulation that will
routinely generate petabytes of data. While an increasing reliance on automated
data analysis is anticipated, a critical role will remain for
visualization-based knowledge discovery. We have investigated scientific
visualization applications in astronomy through an examination of the
literature published during the last two decades. We identify the two most
active fields for progress - visualization of large-N particle data and
spectral data cubes - discuss open areas of research, and introduce a mapping
between astronomical sources of data and data representations used in general
purpose visualization tools. We discuss contributions using high performance
computing architectures (e.g: distributed processing and GPUs), collaborative
astronomy visualization, the use of workflow systems to store metadata about
visualization parameters, and the use of advanced interaction devices. We
examine a number of issues that may be limiting the spread of scientific
visualization research in astronomy and identify six grand challenges for
scientific visualization research in the Petascale Astronomy Era.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5126</identifier>
 <datestamp>2012-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5126</id><created>2011-02-24</created><updated>2012-09-11</updated><authors><author><keyname>Davis</keyname><forenames>Mark</forenames></author><author><keyname>Lleo</keyname><forenames>Sebastien</forenames></author></authors><title>Jump-Diffusion Risk-Sensitive Asset Management II: Jump-Diffusion Factor
  Model</title><categories>q-fin.PM cs.SY math.OC q-fin.CP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article we extend earlier work on the jump-diffusion risk-sensitive
asset management problem [SIAM J. Fin. Math. (2011) 22-54] by allowing jumps in
both the factor process and the asset prices, as well as stochastic volatility
and investment constraints. In this case, the HJB equation is a partial
integro-differential equation (PIDE). By combining viscosity solutions with a
change of notation, a policy improvement argument and classical results on
parabolic PDEs we prove that the HJB PIDE admits a unique smooth solution. A
verification theorem concludes the resolution of this problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5138</identifier>
 <datestamp>2011-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5138</id><created>2011-02-24</created><authors><author><keyname>Dikaliotis</keyname><forenames>Theodoros K.</forenames></author><author><keyname>Yao</keyname><forenames>Hongyi</forenames></author><author><keyname>Avestimehr</keyname><forenames>Salman</forenames></author><author><keyname>Jaggi</keyname><forenames>Sidharth</forenames></author><author><keyname>Ho</keyname><forenames>Tracey</forenames></author></authors><title>Low-Complexity Near-Optimal Codes for Gaussian Relay Networks</title><categories>cs.IT cs.NI math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of information flow over Gaussian relay networks.
Similar to the recent work by Avestimehr \emph{et al.} [1], we propose network
codes that achieve up to a constant gap from the capacity of such networks.
However, our proposed codes are also computationally tractable. Our main
technique is to use the codes of Avestimehr \emph{et al.} as inner codes in a
concatenated coding scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5146</identifier>
 <datestamp>2011-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5146</id><created>2011-02-24</created><authors><author><keyname>Cohen</keyname><forenames>Edith</forenames></author><author><keyname>Cormode</keyname><forenames>Graham</forenames></author><author><keyname>Duffield</keyname><forenames>Nick</forenames></author></authors><title>Structure-Aware Sampling: Flexible and Accurate Summarization</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In processing large quantities of data, a fundamental problem is to obtain a
summary which supports approximate query answering. Random sampling yields
flexible summaries which naturally support subset-sum queries with unbiased
estimators and well-understood confidence bounds.
  Classic sample-based summaries, however, are designed for arbitrary subset
queries and are oblivious to the structure in the set of keys. The particular
structure, such as hierarchy, order, or product space (multi-dimensional),
makes range queries much more relevant for most analysis of the data.
  Dedicated summarization algorithms for range-sum queries have also been
extensively studied. They can outperform existing sampling schemes in terms of
accuracy on range queries per summary size. Their accuracy, however, rapidly
degrades when, as is often the case, the query spans multiple ranges. They are
also less flexible - being targeted for range sum queries alone - and are often
quite costly to build and use.
  In this paper we propose and evaluate variance optimal sampling schemes that
are structure-aware. These summaries improve over the accuracy of existing
structure-oblivious sampling schemes on range queries while retaining the
benefits of sample-based summaries: flexible summaries, with high accuracy on
both range queries and arbitrary subset queries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5152</identifier>
 <datestamp>2013-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5152</id><created>2011-02-24</created><authors><author><keyname>Guidetti</keyname><forenames>Marco</forenames></author><author><keyname>Young</keyname><forenames>A. P.</forenames></author></authors><title>Complexity of several constraint satisfaction problems using the
  heuristic, classical, algorithm, WalkSAT</title><categories>quant-ph cond-mat.stat-mech cs.CC</categories><comments>5 pages, 4 figures</comments><doi>10.1103/PhysRevE.84.011102</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We determine the complexity of several constraint satisfaction problems using
the heuristic algorithm, WalkSAT. At large sizes N, the complexity increases
exponentially with N in all cases. Perhaps surprisingly, out of all the models
studied, the hardest for WalkSAT is the one for which there is a polynomial
time algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5161</identifier>
 <datestamp>2011-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5161</id><created>2011-02-25</created><authors><author><keyname>Chatzikokolakis</keyname><forenames>Konstantinos</forenames><affiliation>University of Eindhoven, Netherlands</affiliation></author><author><keyname>Cortier</keyname><forenames>V&#xe9;ronique</forenames><affiliation>LORIA-CNRS, France</affiliation></author></authors><title>Proceedings 8th International Workshop on Security Issues in Concurrency</title><categories>cs.CR cs.LO</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 51, 2011</journal-ref><doi>10.4204/EPTCS.51</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This volume contains the proceedings of the 8th Workshop on Security Issues
in Concurrency (SecCo 2010). The workshop was held in Paris, France on August
30th, 2010, as a satellite workshop of CONCUR'10. The aim of the SecCo workshop
series is to cover the gap between the security and the concurrency
communities. More precisely, the workshop promotes the exchange of ideas,
trying to focus on common interests and stimulating discussions on central
research questions. In particular, we called for papers dealing with security
issues (such as authentication, integrity, privacy, confidentiality, access
control, denial of service, service availability, safety aspects, fault
tolerance, trust, language-based security, probabilistic and information
theoretic models) in emerging fields like web services, mobile ad-hoc networks,
agent-based infrastructures, peer-to-peer systems, context-aware computing,
global/ubiquitous/pervasive computing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5185</identifier>
 <datestamp>2011-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5185</id><created>2011-02-25</created><authors><author><keyname>Gluzberg</keyname><forenames>Victor</forenames></author></authors><title>Universal Higher Order Grammar</title><categories>cs.CL cs.AI</categories><comments>48 pages</comments><msc-class>68T50, 03B65</msc-class><acm-class>I.2.7</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We examine the class of languages that can be defined entirely in terms of
provability in an extension of the sorted type theory (Ty_n) by embedding the
logic of phonologies, without introduction of special types for syntactic
entities. This class is proven to precisely coincide with the class of
logically closed languages that may be thought of as functions from expressions
to sets of logically equivalent Ty_n terms. For a specific sub-class of
logically closed languages that are described by finite sets of rules or rule
schemata, we find effective procedures for building a compact Ty_n
representation, involving a finite number of axioms or axiom schemata. The
proposed formalism is characterized by some useful features unavailable in a
two-component architecture of a language model. A further specialization and
extension of the formalism with a context type enable effective account of
intensional and dynamic semantics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5189</identifier>
 <datestamp>2011-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5189</id><created>2011-02-25</created><authors><author><keyname>Rebai</keyname><forenames>Ahmed Riadh</forenames></author><author><keyname>Hanafi</keyname><forenames>Sa&#xef;d</forenames></author></authors><title>An Adaptive Multimedia-Oriented Handoff Scheme for IEEE 802.11 WLANs</title><categories>cs.NI</categories><comments>20 pages, 14 figures, 4 tables</comments><journal-ref>International Journal of Wireless &amp; Mobile Networks (IJWMN) Vol.
  3, No. 1, February 2011</journal-ref><doi>10.5121/ijwmn.2011.3114</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Previous studies have shown that the actual handoff schemes employed in the
IEEE 802.11 Wireless LANs (WLANs) do not meet the strict delay constraints
placed by many multimedia applications like Voice over IP. Both the active and
the passive supported scan modes in the standard handoff procedure have
important delay that affects the Quality of Service (QoS) required by the
real-time communications over 802.11 networks. In addition, the problem is
further compounded by the fact that limited coverage areas of Access Points
(APs) occupied in 802.11 infrastructure WLANs create frequent handoffs. We
propose a new optimized and fast handoff scheme that decrease both handoff
latency and occurrence by performing a seamless prevent scan process and an
effective next-AP selection. Through simulations and performance evaluation, we
show the effectiveness of the new adaptive handoff that reduces the process
latency and adds new context-based parameters. The Results illustrate a QoS
delay-respect required by applications and an optimized AP-choice that
eliminates handoff events that are not beneficial.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5190</identifier>
 <datestamp>2011-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5190</id><created>2011-02-25</created><authors><author><keyname>Laassiri</keyname><forenames>Jalal</forenames></author><author><keyname>Elhajji</keyname><forenames>Said</forenames></author><author><keyname>Bouhdadi</keyname><forenames>Mohamed</forenames></author><author><keyname>Orhanou</keyname><forenames>Ghizlane</forenames></author><author><keyname>Balouki</keyname><forenames>Youssef</forenames></author></authors><title>Specifying Data Bases Management Systems by Using RM-ODP Engineering
  Language</title><categories>cs.DB</categories><comments>Available online at http://ijcsi.org</comments><journal-ref>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 3, No 6, May 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distributed systems can be very large and complex. The various considerations
that influence their design can result in a substantial specification, which
requires a structured framework that has to be managed successfully. The
purpose of the RMODP is to define such a framework. The Reference Model for
Open Distributed Processing (RM-ODP) provides a framework within which support
of distribution, inter-working and portability can be integrated. It defines:
an object model, architectural concepts and architecture for the development of
ODP systems in terms of five viewpoints. Which include an information
viewpoint. Since the usage of Data bases management systems (DBMS) in complex
networks is increasing considerably, we are interested, in our work, in giving
DBMS specifications through the use of the three schemas (static, dynamic,
invariant). The present paper is organized as follows. After a literature
review, we will describe then the subset of concepts considered in this work
named the database management system (DBMS) object model. In the third section,
we will be interested in the engineering language and DMBS structure by
describing essentially DBMS objects. Finally, we will present DBMS engineering
specifications and makes the connection between models and their instances.
This introduces the basic form of the semantic approach we have described here.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5191</identifier>
 <datestamp>2011-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5191</id><created>2011-02-25</created><authors><author><keyname>Orhanou</keyname><forenames>Ghizlane</forenames></author><author><keyname>Hajji</keyname><forenames>Said El</forenames></author><author><keyname>Bentaleb</keyname><forenames>Youssef</forenames></author><author><keyname>Laassiri</keyname><forenames>Jalal</forenames></author></authors><title>EPS Confidentiality and Integrity mechanisms Algorithmic Approach</title><categories>cs.CR</categories><comments>Available online at http://ijcsi.org</comments><journal-ref>IJCSI International Journal of Computer Science Issues, Vol. 7,
  Issue 4, No 4, July 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Long Term Evolution of UMTS is one of the latest steps in an advancing
series of mobile telecommunications systems. Many articles have already been
published on the LTE subject but these publications have viewed the subject
from particular perspectives. In the present paper, a different approach has
been taken. We are interested in the security features and the cryptographic
algorithms used to ensure confidentiality and integrity of the transmitted
data. A closer look is taken to the two EPS confidentiality and integrity
algorithms based on the block cipher algorithm AES: the confidentiality
algorithm EEA2 and the integrity algorithm EIA2. Furthermore, we focused on the
implementation of both algorithms in C language in respect to the
specifications requirements. We have tested our implementations according to
the testsets given by the 3rd Generation Partnership Project (3GPP)
implementation document. Some examples of the implementation tests are
presented bellow.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5193</identifier>
 <datestamp>2011-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5193</id><created>2011-02-25</created><authors><author><keyname>Tigli</keyname><forenames>Jean-Yves</forenames></author><author><keyname>Lavirotte</keyname><forenames>Stephane</forenames></author><author><keyname>Rey</keyname><forenames>Gaetan</forenames></author><author><keyname>Hourdin</keyname><forenames>Vincent</forenames></author><author><keyname>Riveill</keyname><forenames>Michel</forenames></author></authors><title>Lightweight Service Oriented Architecture for Pervasive Computing</title><categories>cs.SE</categories><comments>Available online at http://ijcsi.org</comments><journal-ref>IJCSI International Journal of Computer Science Issues, Vol. 4,
  No. 1, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pervasive computing appears like a new computing era based on networks of
objects and devices evolving in a real world, radically different from
distributed computing, based on networks of computers and data storages.
Contrary to most context-aware approaches, we work on the assumption that
pervasive software must be able to deal with a dynamic software environment
before processing contextual data. After demonstrating that SOA (Service
oriented Architecture) and its numerous principles are well adapted for
pervasive computing, we present our extended SOA model for pervasive computing,
called Service Lightweight Component Architecture (SLCA). SLCA presents various
additional principles to meet completely pervasive software constraints:
software infrastructure based on services for devices, local orchestrations
based on lightweight component architecture and finally encapsulation of those
orchestrations into composite services to address distributed composition of
services. We present a sample application of the overall approach as well as
some relevant measures about SLCA performances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5194</identifier>
 <datestamp>2011-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5194</id><created>2011-02-25</created><authors><author><keyname>Tigli</keyname><forenames>Jean-Yves</forenames></author><author><keyname>Lavirotte</keyname><forenames>Stephane</forenames></author><author><keyname>Rey</keyname><forenames>Gaetan</forenames></author><author><keyname>Hourdin</keyname><forenames>Vincent</forenames></author><author><keyname>Riveill</keyname><forenames>Michel</forenames></author></authors><title>Context-aware Authorization in Highly Dynamic Environments</title><categories>cs.CR</categories><comments>Available online at http://ijcsi.org</comments><journal-ref>IJCSI International Journal of Computer Science Issues, Vol. 4,
  No. 1, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Highly dynamic computing environments, like ubiquitous and pervasive
computing environments, require frequent adaptation of applications. Context is
a key to adapt suiting user needs. On the other hand, standard access control
trusts users once they have authenticated, despite the fact that they may reach
unauthorized contexts. We analyse how taking into account dynamic information
like context in the authorization subsystem can improve security, and how this
new access control applies to interaction patterns, like messaging or eventing.
We experiment and validate our approach using context as an authorization
factor for eventing in Web service for device (like UPnP or DPWS), in smart
home security.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5197</identifier>
 <datestamp>2011-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5197</id><created>2011-02-25</created><authors><author><keyname>Hizem</keyname><forenames>Moez</forenames></author><author><keyname>Bouallegue</keyname><forenames>Ridha</forenames></author></authors><title>Fine Synchronization through UWB TH-PPM Impulse Radios</title><categories>cs.NI</categories><comments>11 pages, 7 figures</comments><journal-ref>International Journal of Wireless &amp; Mobile Networks (IJWMN) Vol.
  3, No. 1, February 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a novel fine timing algorithm has been tested and developed to
synchronize Ultra-Wideband (UWB) signals with pulse position modulation (PPM).
By applying this algorithm, we evaluate timing algorithms in both data-aided
(DA) and non-data-aided (NDA) modes. Based on correlation operations, our
algorithm remains operational in practical UWB settings. The proposed timing
scheme consists of two complementary floors or steps. The first floor consists
on a coarse synchronization which is founded on the recently proposed
acquisition scheme based on dirty templates (TDT). In the second floor, we
investigate a new fine synchronization algorithm which gives an improved
estimate of timing offset. Simulations confirm performance improvement of our
timing synchronization compared to the original TDT algorithm in terms of mean
square error.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5204</identifier>
 <datestamp>2011-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5204</id><created>2011-02-25</created><authors><author><keyname>Si</keyname><forenames>Zhongwei</forenames></author><author><keyname>Thobaben</keyname><forenames>Ragnar</forenames></author><author><keyname>Skoglund</keyname><forenames>Mikael</forenames></author></authors><title>Bilayer LDPC Convolutional Codes for Half-Duplex Relay Channels</title><categories>cs.IT math.IT</categories><comments>5 pages, 5 figures, submitted to ISIT 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present regular bilayer LDPC convolutional codes for
half-duplex relay channels. For the binary erasure relay channel, we prove that
the proposed code construction achieves the capacities for the source-relay
link and the source-destination link provided that the channel conditions are
known when designing the code. Meanwhile, this code enables the highest
transmission rate with decode-and-forward relaying. In addition, its regular
degree distributions can easily be computed from the channel parameters, which
significantly simplifies the code optimization. Numerical results are provided
for both binary erasure channels (BEC) and AWGN channels. In BECs, we can
observe that the gaps between the decoding thresholds and the Shannon limits
are impressively small. In AWGN channels, the bilayer LDPC convolutional code
clearly outperforms its block code counterpart in terms of bit error rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5206</identifier>
 <datestamp>2014-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5206</id><created>2011-02-25</created><authors><author><keyname>Gon&#xe7;alves</keyname><forenames>Daniel</forenames></author><author><keyname>Pinlou</keyname><forenames>Alexandre</forenames></author><author><keyname>Rao</keyname><forenames>Michael</forenames></author><author><keyname>Thomass&#xe9;</keyname><forenames>St&#xe9;phan</forenames></author></authors><title>The Domination Number of Grids</title><categories>cs.DM</categories><comments>12 pages, 4 figures</comments><report-no>LIRMM RR-11007</report-no><journal-ref>SIAM Journal of Discrete Mathematics, vol. 25, pp. 1443-1453, 2011</journal-ref><doi>10.1137/11082574</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we conclude the calculation of the domination number of all
$n\times m$ grid graphs. Indeed, we prove Chang's conjecture saying that for
every $16\le n\le m$, $\gamma(G_{n,m})=\lfloor\frac{(n+2)(m+2)}{5}\rfloor -4$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5220</identifier>
 <datestamp>2012-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5220</id><created>2011-02-25</created><authors><author><keyname>Timpanaro</keyname><forenames>Andr&#xe9; M.</forenames></author><author><keyname>Prado</keyname><forenames>Carmen P. C.</forenames></author></authors><title>Coexistence of Interacting Opinions in a Generalized Sznajd Model</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><comments>13 pages, 11 figures, to be submitted to Physical Review</comments><journal-ref>Phys. Rev. E 84, 027101 (2011)</journal-ref><doi>10.1103/PhysRevE.84.027101</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Sznajd model is a sociophysics model that mimics the propagation of
opinions in a closed society, where the interactions favour groups of agreeing
people. It is based in the Ising and Potts ferromagnetic models and although
the original model used only linear chains, it has since been adapted to
general networks. This model has a very rich transient, that has been used to
model several aspects of elections, but its stationary states are always
consensus states. In order to model more complex behaviours we have, in a
recent work, introduced the idea of biases and prejudices to the Sznajd model,
by generalizing the bounded confidence rule that is common to many continuous
opinion models. In that work we have found that the mean-field version of this
model (corresponding to a complete network) allows for stationary states where
non-interacting opinions survive, but never for the coexistence of interacting
opinions. In the present work, we provide networks that allow for the
coexistence of interacting opinions. Moreover, we show that the model does not
become inactive, that is, the opinions keep changing, even in the stationary
regime. We also provide results that give some insights on how this behaviour
approaches the mean-field behaviour, as the networks are changed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5225</identifier>
 <datestamp>2012-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5225</id><created>2011-02-25</created><updated>2012-02-13</updated><authors><author><keyname>Roos</keyname><forenames>Teemu</forenames></author><author><keyname>Oulasvirta</keyname><forenames>Antti</forenames></author><author><keyname>Lepp&#xe4;nen</keyname><forenames>Laura</forenames></author><author><keyname>Modig</keyname><forenames>Arttu</forenames></author></authors><title>Let Us Dance Just a Little Bit More --- On the Information Capacity of
  the Human Motor System</title><categories>cs.IT cs.HC math.IT physics.bio-ph q-bio.NC</categories><comments>Presented at the 2012 Information Theory and Applications Workshop,
  San Diego, CA</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fitts' law is a fundamental tool in measuring the capacity of the human motor
system. However, it is, by definition, limited to aimed movements toward
spatially expanded targets. We revisit its information-theoretic basis with the
goal of generalizing it into unconstrained trained movement such as dance and
sports. The proposed new measure is based on a subject's ability to accurately
reproduce a complex movement pattern. We demonstrate our framework using
motion-capture data from professional dance performances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5239</identifier>
 <datestamp>2013-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5239</id><created>2011-02-25</created><authors><author><keyname>Kucerova</keyname><forenames>Anna</forenames></author><author><keyname>Sykora</keyname><forenames>Jan</forenames></author></authors><title>Uncertainty Updating in the Description of Coupled Heat and Moisture
  Transport in Heterogeneous Materials</title><categories>cs.NA physics.data-an</categories><journal-ref>Applied Mathematics and Computation, 219 (13), 7252-7261, 2013</journal-ref><doi>10.1016/j.amc.2011.02.078</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To assess the durability of structures, heat and moisture transport need to
be analyzed. To provide a reliable estimation of heat and moisture distribution
in a certain structure, one needs to include all available information about
the loading conditions and material parameters. Moreover, the information
should be accompanied by a corresponding evaluation of its credibility. Here,
the Bayesian inference is applied to combine different sources of information,
so as to provide a more accurate estimation of heat and moisture fields [1].
The procedure is demonstrated on the probabilistic description of heterogeneous
material where the uncertainties consist of a particular value of individual
material characteristic and spatial fluctuations. As for the heat and moisture
transfer, it is modelled in coupled setting [2].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5253</identifier>
 <datestamp>2011-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5253</id><created>2011-02-25</created><updated>2011-06-09</updated><authors><author><keyname>Jung</keyname><forenames>Peter</forenames></author></authors><title>On the Szeg\&quot;o-Asymptotics for Doubly-Dispersive Gaussian Channels</title><categories>cs.IT math.IT</categories><comments>5 pages, to be presented at ISIT 2011, minor typos corrected,
  references updated</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the time-continuous doubly-dispersive channel with additive
Gaussian noise and establish a capacity formula for the case where the channel
correlation operator is represented by a symbol which is periodic in time and
fulfills some further integrability and smoothness conditions. The key to this
result is a new Szeg\&quot;o formula for certain pseudo-differential operators. The
formula justifies the water-filling principle along time and frequency in terms
of the time--continuous time-varying transfer function (the symbol).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5266</identifier>
 <datestamp>2011-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5266</id><created>2011-02-25</created><authors><author><keyname>Burr</keyname><forenames>Michael</forenames></author><author><keyname>Krahmer</keyname><forenames>Felix</forenames></author></authors><title>SqFreeEVAL: An (almost) optimal real-root isolation algorithm</title><categories>cs.DS cs.SC</categories><msc-class>65Y20, 68W40</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let f be a univariate polynomial with real coefficients, f in R[X].
Subdivision algorithms based on algebraic techniques (e.g., Sturm or Descartes
methods) are widely used for isolating the real roots of f in a given interval.
In this paper, we consider a simple subdivision algorithm whose primitives are
purely numerical (e.g., function evaluation). The complexity of this algorithm
is adaptive because the algorithm makes decisions based on local data. The
complexity analysis of adaptive algorithms (and this algorithm in particular)
is a new challenge for computer science. In this paper, we compute the size of
the subdivision tree for the SqFreeEVAL algorithm.
  The SqFreeEVAL algorithm is an evaluation-based numerical algorithm which is
well-known in several communities. The algorithm itself is simple, but prior
attempts to compute its complexity have proven to be quite technical and have
yielded sub-optimal results. Our main result is a simple O(d(L+ln d)) bound on
the size of the subdivision tree for the SqFreeEVAL algorithm on the benchmark
problem of isolating all real roots of an integer polynomial f of degree d and
whose coefficients can be written with at most L bits.
  Our proof uses two amortization-based techniques: First, we use the algebraic
amortization technique of the standard Mahler-Davenport root bounds to
interpret the integral in terms of d and L. Second, we use a continuous
amortization technique based on an integral to bound the size of the
subdivision tree. This paper is the first to use the novel analysis technique
of continuous amortization to derive state of the art complexity bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5275</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5275</id><created>2011-02-25</created><authors><author><keyname>Rosnes</keyname><forenames>Eirik</forenames></author></authors><title>Further Results on Quadratic Permutation Polynomial-Based Interleavers
  for Turbo Codes</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Trans. Inf. Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An interleaver is a critical component for the channel coding performance of
turbo codes. Algebraic constructions are of particular interest because they
admit analytical designs and simple, practical hardware implementation. Also,
the recently proposed quadratic permutation polynomial (QPP) based interleavers
by Sun and Takeshita (IEEE Trans. Inf. Theory, Jan. 2005) provide excellent
performance for short-to-medium block lengths, and have been selected for the
3GPP LTE standard. In this work, we derive some upper bounds on the best
achievable minimum distance dmin of QPP-based conventional binary turbo codes
(with tailbiting termination, or dual termination when the interleaver length N
is sufficiently large) that are tight for larger block sizes. In particular, we
show that the minimum distance is at most 2(2^{\nu +1}+9), independent of the
interleaver length, when the QPP has a QPP inverse, where {\nu} is the degree
of the primitive feedback and monic feedforward polynomials. However, allowing
the QPP to have a larger degree inverse may give strictly larger minimum
distances (and lower multiplicities). In particular, we provide several QPPs
with an inverse degree of at least three for some of the 3GPP LTE interleaver
lengths giving a dmin with the 3GPP LTE constituent encoders which is strictly
larger than 50. For instance, we have found a QPP for N=6016 which gives an
estimated dmin of 57. Furthermore, we provide the exact minimum distance and
the corresponding multiplicity for all 3GPP LTE turbo codes (with dual
termination) which shows that the best minimum distance is 51. Finally, we
compute the best achievable minimum distance with QPP interleavers for all 3GPP
LTE interleaver lengths N &lt;= 4096, and compare the minimum distance with the
one we get when using the 3GPP LTE polynomials.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5288</identifier>
 <datestamp>2011-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5288</id><created>2011-02-25</created><updated>2011-09-09</updated><authors><author><keyname>Babacan</keyname><forenames>S. Derin</forenames></author><author><keyname>Luessi</keyname><forenames>Martin</forenames></author><author><keyname>Molina</keyname><forenames>Rafael</forenames></author><author><keyname>Katsaggelos</keyname><forenames>Aggelos K.</forenames></author></authors><title>Sparse Bayesian Methods for Low-Rank Matrix Estimation</title><categories>stat.ML cs.LG cs.SY math.OC stat.AP</categories><comments>This paper has been withdrawn by the author due to significant
  revisions in the paper. The new version will be uploaded soon</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recovery of low-rank matrices has recently seen significant activity in many
areas of science and engineering, motivated by recent theoretical results for
exact reconstruction guarantees and interesting practical applications. A
number of methods have been developed for this recovery problem. However, a
principled method for choosing the unknown target rank is generally not
provided. In this paper, we present novel recovery algorithms for estimating
low-rank matrices in matrix completion and robust principal component analysis
based on sparse Bayesian learning (SBL) principles. Starting from a matrix
factorization formulation and enforcing the low-rank constraint in the
estimates as a sparsity constraint, we develop an approach that is very
effective in determining the correct rank while providing high recovery
performance. We provide connections with existing methods in other similar
problems and empirical results and comparisons with current state-of-the-art
methods that illustrate the effectiveness of this approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5309</identifier>
 <datestamp>2011-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5309</id><created>2011-02-25</created><updated>2011-06-24</updated><authors><author><keyname>Hurwitz</keyname><forenames>Jeremy</forenames></author></authors><title>A Nearly-Quadratic Gap Between Adaptive and Non-Adaptive Property
  Testers</title><categories>cs.DS cs.CC cs.DM</categories><comments>Keywords: Sublinear-Time Algorithms, Property Testing, Dense-Graph
  Model, Adaptive vs Nonadaptive Queries, Hierarchy Theorem</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that for all integers $t\geq 8$ and arbitrarily small $\epsilon&gt;0$,
there exists a graph property $\Pi$ (which depends on $\epsilon$) such that
$\epsilon$-testing $\Pi$ has non-adaptive query complexity
$Q=\~{\Theta}(q^{2-2/t})$, where $q=\~{\Theta}(\epsilon^{-1})$ is the adaptive
query complexity. This resolves the question of how beneficial adaptivity is,
in the context of proximity-dependent properties
(\cite{benefits-of-adaptivity}). This also gives evidence that the canonical
transformation of Goldreich and Trevisan (\cite{canonical-testers}) is
essentially optimal when converting an adaptive property tester to a
non-adaptive property tester.
  To do so, we provide optimal adaptive and non-adaptive testers for the
combined property of having maximum degree $O(\epsilon N)$ and being a
\emph{blow-up collection} of an arbitrary base graph $H$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5314</identifier>
 <datestamp>2015-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5314</id><created>2011-02-25</created><updated>2012-08-02</updated><authors><author><keyname>Hajiaghayi</keyname><forenames>Mahdi</forenames></author><author><keyname>Dong</keyname><forenames>Min</forenames></author><author><keyname>Liang</keyname><forenames>Ben</forenames></author></authors><title>Jointly Optimal Channel and Power Assignment for Dual-Hop Multi-channel
  Multi-user Relaying</title><categories>cs.IT cs.PF math.IT</categories><comments>This is the full version of a paper to appear in the IEEE Journal on
  Selected Areas in Communications, Special Issue on Cooperative Networking -
  Challenges and Applications (Part II), October 2012</comments><journal-ref>IEEE Journal on Selected Areas in Communications, vol. 30,
  pp.1806-1814, October 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of jointly optimizing channel pairing, channel-user
assignment, and power allocation, to maximize the weighted sum-rate, in a
single-relay cooperative system with multiple channels and multiple users.
Common relaying strategies are considered, and transmission power constraints
are imposed on both individual transmitters and the aggregate over all
transmitters. The joint optimization problem naturally leads to a mixed-integer
program. Despite the general expectation that such problems are intractable, we
construct an efficient algorithm to find an optimal solution, which incurs
computational complexity that is polynomial in the number of channels and the
number of users. We further demonstrate through numerical experiments that the
jointly optimal solution can significantly improve system performance over its
suboptimal alternatives.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5322</identifier>
 <datestamp>2011-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5322</id><created>2011-02-25</created><authors><author><keyname>Vetter</keyname><forenames>Benjamin</forenames></author><author><keyname>Westhoff</keyname><forenames>Dirk</forenames></author></authors><title>Code Attestation with Compressed Instruction Code</title><categories>cs.CR</categories><comments>7 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Available purely software based code attestation protocols have recently been
shown to be cheatable. In this work we propose to upload compressed instruction
code to make the code attestation protocol robust against a so called
compresssion attack. The described secure code attestation protocol makes use
of recently proposed microcontroller architectures for reading out compressed
instruction code. We point out that the proposed concept only makes sense if
the provided cost/benefit ratio for the aforementioned microcontroller is
higher than an alternative hardware based solution requiring a tamperresistant
hardware module.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5328</identifier>
 <datestamp>2011-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5328</id><created>2011-02-25</created><authors><author><keyname>Agullo</keyname><forenames>Emmanuel</forenames><affiliation>INRIA Bordeaux - Sud-Ouest, LaBRI</affiliation></author><author><keyname>Dongarra</keyname><forenames>Jack</forenames><affiliation>ICL</affiliation></author><author><keyname>Nath</keyname><forenames>Rajib</forenames><affiliation>ICL</affiliation></author><author><keyname>Tomov</keyname><forenames>Stanimire</forenames><affiliation>ICL</affiliation></author></authors><title>Fully Empirical Autotuned QR Factorization For Multicore Architectures</title><categories>cs.DC</categories><proxy>ccsd</proxy><report-no>RR-7526</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tuning numerical libraries has become more difficult over time, as systems
get more sophisticated. In particular, modern multicore machines make the
behaviour of algorithms hard to forecast and model. In this paper, we tackle
the issue of tuning a dense QR factorization on multicore architectures. We
show that it is hard to rely on a model, which motivates us to design a fully
empirical approach. We exhibit few strong empirical properties that enable us
to efficiently prune the search space. Our method is automatic, fast and
reliable. The tuning process is indeed fully performed at install time in less
than one and ten minutes on five out of seven platforms. We achieve an average
performance varying from 97% to 100% of the optimum performance depending on
the platform. This work is a basis for autotuning the PLASMA library and
enabling easy performance portability across hardware systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5335</identifier>
 <datestamp>2011-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5335</id><created>2011-02-25</created><authors><author><keyname>Ghorpade</keyname><forenames>Sudhir R.</forenames></author><author><keyname>Ram</keyname><forenames>Samrith</forenames></author></authors><title>Block Companion Singer Cycles, Primitive Recursive Vector Sequences, and
  Coprime Polynomial Pairs over Finite Fields</title><categories>math.CO cs.IT math.IT</categories><comments>12 pages; to appear in: Finite Fields and Their Applications</comments><msc-class>11T35, 11T06, 20G40, 15B05</msc-class><journal-ref>Finite Fields Appl. 17 (2011), no. 5, 461-472</journal-ref><doi>10.1016/j.ffa.2011.02.008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss a conjecture concerning the enumeration of nonsingular matrices
over a finite field that are block companion and whose order is the maximum
possible in the corresponding general linear group. A special case is proved
using some recent results on the probability that a pair of polynomials with
coefficients in a finite field is coprime. Connection with an older problem of
Niederreiter about the number of splitting subspaces of a given dimension are
outlined and an asymptotic version of the conjectural formula is established.
Some applications to the enumeration of nonsingular Toeplitz matrices of a
given size over a finite field are also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5337</identifier>
 <datestamp>2011-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5337</id><created>2011-02-25</created><authors><author><keyname>Musy</keyname><forenames>Stephane</forenames></author></authors><title>Variable Length Coding over the Two-User Multiple-Access Channel</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For discrete memoryless multiple-access channels, we propose a general
definition of variable length codes with a measure of the transmission rates at
the receiver side. This gives a receiver perspective on the multiple-access
channel coding problem and allows us to characterize the region of achievable
rates when the receiver is able to decode each transmitted message at a
different instant of time.We show an outer bound on this region and derive a
simple coding scheme that can achieve, in particular settings, all rates within
the region delimited by the outer bound. In addition, we propose a random
variable length coding scheme that achieve the direct part of the block code
capacity region of a multiple-access channel without requiring any agreement
between the transmitters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5357</identifier>
 <datestamp>2011-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5357</id><created>2011-02-25</created><authors><author><keyname>Khina</keyname><forenames>A.</forenames></author><author><keyname>Kochman</keyname><forenames>Y.</forenames></author><author><keyname>Erez</keyname><forenames>U.</forenames></author></authors><title>Physical-Layer MIMO Relaying</title><categories>cs.IT math.IT</categories><comments>5 pages, 3 figures, submitted to ISIT 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The physical-layer network coding (PNC) approach provides improved
performance in many scenarios over &quot;traditional&quot; relaying techniques or network
coding. This work addresses the generalization of PNC to wireless scenarios
where network nodes have multiple antennas. We use a recent matrix
decomposition, which allows, by linear pre- and post-processing, to
simultaneously transform both channel matrices to triangular forms, where the
diagonal entries, corresponding to both channels, are equal. This
decomposition, in conjunction with precoding, allows to convert any two-input
multiple-access channel (MAC) into parallel MACs, over which single-antenna PNC
may be used. The technique is demonstrated using the two-way relay channel with
multiple antennas. For this case it is shown that, in the high signal-to-noise
regime, the scheme approaches the cut-set bound, thus establishing the
asymptotic network capacity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5361</identifier>
 <datestamp>2011-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5361</id><created>2011-02-25</created><authors><author><keyname>Adams</keyname><forenames>Sarah Spence</forenames></author><author><keyname>Brass</keyname><forenames>Zachary</forenames></author><author><keyname>Stokes</keyname><forenames>Connor</forenames></author><author><keyname>Troxell</keyname><forenames>Denise Sakai</forenames></author></authors><title>Irreversible k-threshold and majority conversion processes on complete
  multipartite graphs and graph products</title><categories>math.CO cs.DM cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In graph theoretical models of the spread of disease through populations, the
spread of opinion through social networks, and the spread of faults through
distributed computer networks, vertices are in two states, either black or
white, and these states are dynamically updated at discrete time steps
according to the rules of the particular conversion process used in the model.
This paper considers the irreversible k-threshold and majority conversion
processes. In an irreversible k-threshold (resp., majority) conversion process,
a vertex is permanently colored black in a certain time period if at least k
(resp., at least half) of its neighbors were black in the previous time period.
A k-conversion set (resp., dynamic monopoly) is a set of vertices which, if
initially colored black, will result in all vertices eventually being colored
black under a k-threshold (resp., majority) conversion process. We answer
several open problems by presenting bounds and some exact values of the minimum
number of vertices in k-conversion sets and dynamic monopolies of complete
multipartite graphs, as well as of Cartesian and tensor products of two graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5364</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5364</id><created>2011-02-25</created><authors><author><keyname>Loyka</keyname><forenames>Sergey</forenames></author><author><keyname>Levin</keyname><forenames>Georgy</forenames></author></authors><title>On Outage Probability and Diversity-Multiplexing Tradeoff in MIMO Relay
  Channels</title><categories>cs.IT math.IT</categories><comments>accepted by IEEE Trans. on Comm., 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fading MIMO relay channels are studied analytically, when the source and
destination are equipped with multiple antennas and the relays have a single
one. Compact closed-form expressions are obtained for the outage probability
under i.i.d. and correlated Rayleigh-fading links. Low-outage approximations
are derived, which reveal a number of insights, including the impact of
correlation, of the number of antennas, of relay noise and of relaying
protocol. The effect of correlation is shown to be negligible, unless the
channel becomes almost fully correlated. The SNR loss of relay fading channels
compared to the AWGN channel is quantified. The SNR-asymptotic
diversity-multiplexing tradeoff (DMT) is obtained for a broad class of fading
distributions, including, as special cases, Rayleigh, Rice, Nakagami, Weibull,
which may be non-identical, spatially correlated and/or non-zero mean. The DMT
is shown to depend not on a particular fading distribution, but rather on its
polynomial behavior near zero, and is the same for the simple
&quot;amplify-and-forward&quot; protocol and more complicated &quot;decode-and-forward&quot; one
with capacity achieving codes, i.e. the full processing capability at the relay
does not help to improve the DMT. There is however a significant difference
between the SNR-asymptotic DMT and the finite-SNR outage performance: while the
former is not improved by using an extra antenna on either side, the latter can
be significantly improved and, in particular, an extra antenna can be
traded-off for a full processing capability at the relay. The results are
extended to the multi-relay channels with selection relaying and typical outage
events are identified.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5365</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5365</id><created>2011-02-25</created><authors><author><keyname>Loyka</keyname><forenames>Sergey</forenames></author><author><keyname>Levin</keyname><forenames>Georgy</forenames></author></authors><title>Diversity-Multiplexing Tradeoff in the Low-SNR Regime</title><categories>cs.IT math.IT</categories><comments>accepted by IEEE Comm. Letters</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An extension of the popular diversity-multiplexing tradeoff framework to the
low-SNR (or wideband) regime is proposed. The concept of diversity gain is
shown to be redundant in this regime since the outage probability is
SNR-independent and depends on the multiplexing gain and the channel power gain
statistics only. The outage probability under the DMT framework is obtained in
an explicit, closed form for a broad class of channels. The low and high-SNR
regime boundaries are explicitly determined for the scalar Rayleigh-fading
channel, indicating a significant limitation of the SNR-asymptotic DMT when the
multiplexing gain is small.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5381</identifier>
 <datestamp>2011-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5381</id><created>2011-02-25</created><authors><author><keyname>Shakya</keyname><forenames>Indu</forenames></author><author><keyname>Ali</keyname><forenames>Falah H.</forenames></author><author><keyname>Stipidis</keyname><forenames>Elias</forenames></author></authors><title>Blind Adaptive Subcarrier Combining Technique for MC-CDMA Receiver in
  Mobile Rayleigh Channel</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new subcarrier combining technique is proposed for MC -CDMA receiver in
mobile Rayleigh fading channel. It exploits the structure formed by repeating
spreading sequences of users on different subcarriers to simultaneously
suppress multiple access interference (MAI) and provide implicit channel
tracking without any knowledge of the channel amplitudes or training sequences.
This is achieved by adaptively weighting each subcarrier in each symbol period
by employing a simple gradient descent algorithm to meet the constant modulus
(CM) criterion with judicious selection of step-size. Improved BER and user
capacity performance are shown with similar complexity in order of O(N)
compared with conventional maximum ratio combining and equal gain combining
techniques even under high channel Doppler rates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5385</identifier>
 <datestamp>2011-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5385</id><created>2011-02-25</created><updated>2011-03-01</updated><authors><author><keyname>Slota</keyname><forenames>Martin</forenames></author><author><keyname>Leite</keyname><forenames>Jo&#xe3;o</forenames></author></authors><title>Back and Forth Between Rules and SE-Models (Extended Version)</title><categories>cs.AI</categories><comments>25 pages; extended version of the paper accepted for LPNMR 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rules in logic programming encode information about mutual interdependencies
between literals that is not captured by any of the commonly used semantics.
This information becomes essential as soon as a program needs to be modified or
further manipulated.
  We argue that, in these cases, a program should not be viewed solely as the
set of its models. Instead, it should be viewed and manipulated as the set of
sets of models of each rule inside it. With this in mind, we investigate and
highlight relations between the SE-model semantics and individual rules. We
identify a set of representatives of rule equivalence classes induced by
SE-models, and so pinpoint the exact expressivity of this semantics with
respect to a single rule. We also characterise the class of sets of
SE-interpretations representable by a single rule. Finally, we discuss the
introduction of two notions of equivalence, both stronger than strong
equivalence [1] and weaker than strong update equivalence [2], which seem more
suitable whenever the dependency information found in rules is of interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5386</identifier>
 <datestamp>2011-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5386</id><created>2011-02-25</created><authors><author><keyname>Kudekar</keyname><forenames>Shrinivas</forenames></author><author><keyname>Johnson</keyname><forenames>Jason K.</forenames></author><author><keyname>Chertkov</keyname><forenames>Michael</forenames></author></authors><title>Linear Programming based Detectors for Two-Dimensional Intersymbol
  Interference Channels</title><categories>cs.IT math.IT</categories><comments>5 Pages, Submitted to ISIT 2011</comments><report-no>LA-UR 11-01283</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present and study linear programming based detectors for two-dimensional
intersymbol interference channels. Interesting instances of two-dimensional
intersymbol interference channels are magnetic storage, optical storage and
Wyner's cellular network model.
  We show that the optimal maximum a posteriori detection in such channels
lends itself to a natural linear programming based sub-optimal detector. We
call this the Pairwise linear program detector. Our experiments show that the
Pairwise linear program detector performs poorly. We then propose two methods
to strengthen our detector. These detectors are based on systematically
enhancing the Pairwise linear program. The first one, the Block linear program
detector adds higher order potential functions in an {\em exhaustive} manner,
as constraints, to the Pairwise linear program detector. We show by experiments
that the Block linear program detector has performance close to the optimal
detector. We then develop another detector by
  {\em adaptively} adding frustrated cycles to the Pairwise linear program
detector. Empirically, this detector also has performance close to the optimal
one and turns out to be less complex then the Block linear program detector.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5388</identifier>
 <datestamp>2011-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5388</id><created>2011-02-25</created><authors><author><keyname>Chen</keyname><forenames>Qing</forenames></author><author><keyname>Gursoy</keyname><forenames>Mustafa Cenk</forenames></author></authors><title>Energy Efficiency and Goodput Analysis in Two-Way Wireless Relay
  Networks</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study two-way relay networks (TWRNs) in which two source
nodes exchange their information via a relay node indirectly in Rayleigh fading
channels. Both Amplify-and-Forward (AF) and Decode-and-Forward (DF) techniques
have been analyzed in the TWRN employing a Markov chain model through which the
network operation is described and investigated in depth. Automatic
Repeat-reQuest (ARQ) retransmission has been applied to guarantee the
successful packet delivery. The bit energy consumption and goodput expressions
have been derived as functions of transmission rate in a given AF or DF TWRN.
Numerical results are used to identify the optimal transmission rates where the
bit energy consumption is minimized or the goodput is maximized. The network
performances are compared in terms of energy and transmission efficiency in AF
and DF modes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5389</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5389</id><created>2011-02-26</created><updated>2011-04-16</updated><authors><author><keyname>Joosten</keyname><forenames>Joost J.</forenames></author><author><keyname>Soler-Toscano</keyname><forenames>Fernando</forenames></author><author><keyname>Zenil</keyname><forenames>Hector</forenames></author></authors><title>Program-Size Versus Time Complexity, Speed-Up and Slowdown Phenomena in
  Small Turing Machines</title><categories>cs.CC cs.IT math.IT</categories><comments>Proceedings of the 3rd. International workshop on Physics and
  Computation 2010 on the Nile, Egypt, pages 175-198, 2010. Forthcoming in the
  International Journal of Unconventional Computing (IJUC)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of this paper is to undertake an experimental investigation of the
trade-offs between program-size and time computational complexity. The
investigation includes an exhaustive exploration and systematic study of the
functions computed by the set of all 2-color Turing machines with 2, 3 and 4
states--denoted by (n,2) with n the number of states--with particular attention
to the runtimes and space usages when the machines have access to larger
resources (more states). We report that the average runtime of Turing machines
computing a function almost surely increases as a function of the number of
states, indicating that machines not terminating (almost) immediately tend to
occupy all the resources at hand. We calculated all time complexity classes to
which the algorithms computing the functions found in both (2,2) and (3,2)
belong to, and made a comparison among these classes. For a selection of
functions the comparison was extended to (4,2). Our study revealed various
structures in the micro-cosmos of small Turing machines. Most notably we
observed &quot;phase-transitions&quot; in the halting-probability distribution that we
explain. Moreover, it is observed that short initial segments fully define a
function computed by a Turing machine.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5396</identifier>
 <datestamp>2011-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5396</id><created>2011-02-26</created><authors><author><keyname>Venkatesan</keyname><forenames>R. C.</forenames></author><author><keyname>Plastino</keyname><forenames>A.</forenames></author></authors><title>Deformed Statistics Free Energy Model for Source Separation using
  Unsupervised Learning</title><categories>cond-mat.stat-mech cs.IT cs.LG math.IT</categories><comments>5 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A generalized-statistics variational principle for source separation is
formulated by recourse to Tsallis' entropy subjected to the additive duality
and employing constraints described by normal averages. The variational
principle is amalgamated with Hopfield-like learning rules resulting in an
unsupervised learning model. The update rules are formulated with the aid of
q-deformed calculus. Numerical examples exemplify the efficacy of this model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5400</identifier>
 <datestamp>2011-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5400</id><created>2011-02-26</created><authors><author><keyname>Chen</keyname><forenames>Xianfu</forenames></author><author><keyname>Zhao</keyname><forenames>Zhifeng</forenames></author><author><keyname>Zhang</keyname><forenames>Honggang</forenames></author></authors><title>Power Allocation for Cognitive Wireless Mesh Networks by Applying
  Multi-agent Q-learning Approach</title><categories>cs.IT math.IT</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  As the scarce spectrum resource is becoming over-crowded, cognitive radios
(CRs) indicate great flexibility to improve the spectrum efficiency by
opportunistically accessing the authorized frequency bands. One of the critical
challenges for operating such radios in a network is how to efficiently
allocate transmission powers and frequency resource among the secondary users
(SUs) while satisfying the quality-of-service (QoS) constraints of the primary
users (PUs). In this paper, we focus on the non-cooperative power allocation
problem in cognitive wireless mesh networks (CogMesh) formed by a number of
clusters with the consideration of energy efficiency. Due to the SUs' selfish
and spontaneous properties, the problem is modeled as a stochastic learning
process. We first extend the single-agent Q-learning to a multi-user context,
and then propose a conjecture based multi-agent Qlearning algorithm to achieve
the optimal transmission strategies with only private and incomplete
information. An intelligent SU performs Q-function updates based on the
conjecture over the other SUs' stochastic behaviors. This learning algorithm
provably converges given certain restrictions that arise during learning
procedure. Simulation experiments are used to verify the performance of our
algorithm and demonstrate its effectiveness of improving the energy efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5401</identifier>
 <datestamp>2011-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5401</id><created>2011-02-26</created><authors><author><keyname>Zhuk</keyname><forenames>Sergiy</forenames></author></authors><title>Minimax state estimation for linear descriptor systems</title><categories>math.OC cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Author's Summary of the dissertation for the degree of the Candidate of
Science (physics and mathematics). The aim of the dissertation is to develop a
generalized Kalman Duality concept applicable for linear unbounded
non-invertible operators and introduce the minimax state estimation theory and
algorithms for linear differential-algebraic equations. In particular, the
dissertation pursues the following goals: - develop generalized duality concept
for the minimax state estimation theory for DAEs with unknown but bounded model
error and random observation noise with unknown but bounded correlation
operator; - derive the minimax state estimation theory for linear DAEs with
unknown but bounded model error and random observation noise with unknown but
bounded correlation operator; - describe how the DAE model propagates uncertain
parameters; - estimate the worst-case error; - construct fast estimation
algorithms in the form of filters; - develop a tool for model validation, that
is to assess how good the model describes observed phenomena.
  The dissertation contains the following new results: - generalized version of
the Kalman duality principle is proposed allowing to handle unbounded linear
model operators with non-trivial null-space; - new definitions of the minimax
estimates for DAEs based on the generalized Kalman duality principle are
proposed; - theorems of existence for minimax estimates are proved; - new
minimax state estimation algorithms (in the form of filter and in the
variational form) for DAE are proposed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5407</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5407</id><created>2011-02-26</created><updated>2011-08-15</updated><authors><author><keyname>Mondragon</keyname><forenames>R. J.</forenames></author><author><keyname>Zhou</keyname><forenames>S.</forenames></author></authors><title>Random Networks with given Rich-club Coefficient</title><categories>physics.soc-ph cs.SI</categories><comments>revised version, new figures</comments><doi>10.1140/epjb/e2012-21026-3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In complex networks it is common to model a network or generate a surrogate
network based on the conservation of the network's degree distribution. We
provide an alternative network model based on the conservation of connection
density within a set of nodes. This density is measure by the rich-club
coefficient. We present a method to generate surrogates networks with a given
rich-club coefficient. We show that by choosing a suitable local linking term,
the generated random networks can reproduce the degree distribution and the
mixing pattern of real networks. The method is easy to implement and produces
good models of real networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5415</identifier>
 <datestamp>2011-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5415</id><created>2011-02-26</created><updated>2011-09-03</updated><authors><author><keyname>Dodis</keyname><forenames>Yevgeniy</forenames></author><author><keyname>Li</keyname><forenames>Xin</forenames></author><author><keyname>Wooley</keyname><forenames>Trevor D.</forenames></author><author><keyname>Zuckerman</keyname><forenames>David</forenames></author></authors><title>Privacy Amplification and Non-Malleable Extractors Via Character Sums</title><categories>cs.CR cs.CC math.NT</categories><comments>32 pages, full version of the same paper in FOCS 2011</comments><msc-class>94A62 (Primary) 11L40 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In studying how to communicate over a public channel with an active
adversary, Dodis and Wichs introduced the notion of a non-malleable extractor.
A non-malleable extractor dramatically strengthens the notion of a strong
extractor. A strong extractor takes two inputs, a weakly-random x and a
uniformly random seed y, and outputs a string which appears uniform, even given
y. For a non-malleable extractor nmExt, the output nmExt(x,y) should appear
uniform given y as well as nmExt(x,A(y)), where A is an arbitrary function with
A(y) not equal to y.
  We show that an extractor introduced by Chor and Goldreich is non-malleable
when the entropy rate is above half. It outputs a linear number of bits when
the entropy rate is 1/2 + alpha, for any alpha&gt;0. Previously, no nontrivial
parameters were known for any non-malleable extractor. To achieve a polynomial
running time when outputting many bits, we rely on a widely-believed conjecture
about the distribution of prime numbers in arithmetic progressions. Our
analysis involves a character sum estimate, which may be of independent
interest.
  Using our non-malleable extractor, we obtain protocols for &quot;privacy
amplification&quot;: key agreement between two parties who share a weakly-random
secret. Our protocols work in the presence of an active adversary with
unlimited computational power, and have asymptotically optimal entropy loss.
When the secret has entropy rate greater than 1/2, the protocol follows from a
result of Dodis and Wichs, and takes two rounds. When the secret has entropy
rate delta for any constant delta&gt;0, our new protocol takes a constant
(polynomial in 1/delta) number of rounds. Our protocols run in polynomial time
under the above well-known conjecture about primes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5418</identifier>
 <datestamp>2011-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5418</id><created>2011-02-26</created><authors><author><keyname>Shen</keyname><forenames>Alexander</forenames></author></authors><title>Kolmogorov complexity as a language</title><categories>cs.IT math.IT math.LO</categories><comments>Invited talk prepared for CSR 2011</comments><msc-class>68Q30, 03D32</msc-class><acm-class>F.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The notion of Kolmogorov complexity (=the minimal length of a program that
generates some object) is often useful as a kind of language that allows us to
reformulate some notions and therefore provide new intuition. In this survey we
provide (with minimal comments) many different examples where notions and
statements that involve Kolmogorov complexity are compared with their
counterparts not involving complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5420</identifier>
 <datestamp>2013-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5420</id><created>2011-02-26</created><authors><author><keyname>Reppas</keyname><forenames>Andreas I.</forenames></author><author><keyname>Spiliotis</keyname><forenames>Konstantinos</forenames></author><author><keyname>Siettos</keyname><forenames>Constantinos</forenames></author></authors><title>On the effect of the path length and transitivity of small-world
  networks on epidemic dynamics</title><categories>cs.SI math.DS physics.soc-ph</categories><journal-ref>Virulence, 146-153, 2012</journal-ref><doi>10.4161/viru.19131</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show how one can trace in a systematic way the coarse-grained solutions of
individual-based stochastic epidemic models evolving on heterogeneous complex
networks with respect to their topological characteristics. In particular, we
have developed algorithms that allow the tuning of the transitivity (clustering
coefficient) and the average mean-path length allowing the investigation of the
&quot;pure&quot; impacts of the two characteristics on the emergent behavior of detailed
epidemic models. The framework could be used to shed more light into the
influence of weak and strong social ties on epidemic spread within small-world
network structures, and ultimately to provide novel systematic computational
modeling and exploration of better contagion control strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5425</identifier>
 <datestamp>2011-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5425</id><created>2011-02-26</created><authors><author><keyname>Lenzen</keyname><forenames>Christoph</forenames></author><author><keyname>Wattenhofer</keyname><forenames>Roger</forenames></author></authors><title>Tight Bounds for Parallel Randomized Load Balancing</title><categories>cs.CC cs.DC cs.DS</categories><comments>39 pages, 2 figures. Extended abstract will be published at STOC'11</comments><report-no>TIK report number 324</report-no><acm-class>F.2.2; F.2.3; F.1.2; F.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We explore the fundamental limits of distributed balls-into-bins algorithms.
We present an adaptive symmetric algorithm that achieves a bin load of two in
log* n+O(1) communication rounds using O(n) messages in total. Larger bin loads
can be traded in for smaller time complexities. We prove a matching lower bound
of (1-o(1))log* n on the time complexity of symmetric algorithms that guarantee
small bin loads at an asymptotically optimal message complexity of O(n). For
each assumption of the lower bound, we provide an algorithm violating it, in
turn achieving a constant maximum bin load in constant time.
  As an application, we consider the following problem. Given a fully connected
graph of n nodes, where each node needs to send and receive up to n messages,
and in each round each node may send one message over each link, deliver all
messages as quickly as possible to their destinations. We give a simple and
robust algorithm of time complexity O(log* n) for this task and provide a
generalization to the case where all nodes initially hold arbitrary sets of
messages. A less practical algorithm terminates within asymptotically optimal
O(1) rounds. All these bounds hold with high probability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5433</identifier>
 <datestamp>2015-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5433</id><created>2011-02-26</created><updated>2014-03-05</updated><authors><author><keyname>Ahmed</keyname><forenames>Tanbir</forenames></author><author><keyname>Kullmann</keyname><forenames>Oliver</forenames></author><author><keyname>Snevily</keyname><forenames>Hunter</forenames></author></authors><title>On the van der Waerden numbers w(2;3,t)</title><categories>math.CO cs.DS</categories><comments>Second version 25 pages, updates of numerical data, improved
  formulations, and extended discussions on SAT. Third version 42 pages, with
  SAT solver data (especially for new SAT solver) and improved representation.
  Fourth version 47 pages, with updates and added explanations</comments><msc-class>05D10</msc-class><acm-class>F.2.2; G.2.2; I.2.8</acm-class><journal-ref>Discrete Applied Mathematics 174: 27-51 (2014)</journal-ref><doi>10.1016/j.dam.2014.05.007</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present results and conjectures on the van der Waerden numbers w(2;3,t)
and on the new palindromic van der Waerden numbers pdw(2;3,t). We have computed
the new number w(2;3,19) = 349, and we provide lower bounds for 20 &lt;= t &lt;= 39,
where for t &lt;= 30 we conjecture these lower bounds to be exact. The lower
bounds for 24 &lt;= t &lt;= 30 refute the conjecture that w(2;3,t) &lt;= t^2, and we
present an improved conjecture. We also investigate regularities in the good
partitions (certificates) to better understand the lower bounds.
  Motivated by such reglarities, we introduce *palindromic van der Waerden
numbers* pdw(k; t_0,...,t_{k-1}), defined as ordinary van der Waerden numbers
w(k; t_0,...,t_{k-1}), however only allowing palindromic solutions (good
partitions), defined as reading the same from both ends. Different from the
situation for ordinary van der Waerden numbers, these &quot;numbers&quot; need actually
to be pairs of numbers. We compute pdw(2;3,t) for 3 &lt;= t &lt;= 27, and we provide
lower bounds, which we conjecture to be exact, for t &lt;= 35.
  All computations are based on SAT solving, and we discuss the various
relations between SAT solving and Ramsey theory. Especially we introduce a
novel (open-source) SAT solver, the tawSolver, which performs best on the SAT
instances studied here, and which is actually the original DLL-solver, but with
an efficient implementation and a modern heuristic typical for look-ahead
solvers (applying the theory developed in the SAT handbook article of the
second author).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5437</identifier>
 <datestamp>2013-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5437</id><created>2011-02-26</created><updated>2011-09-23</updated><authors><author><keyname>Mastronarde</keyname><forenames>Nicholas</forenames></author><author><keyname>Verde</keyname><forenames>Francesco</forenames></author><author><keyname>Darsena</keyname><forenames>Donatella</forenames></author><author><keyname>Scaglione</keyname><forenames>Anna</forenames></author><author><keyname>van der Schaar</keyname><forenames>Mihaela</forenames></author></authors><title>Transmitting important bits and sailing high radio waves: a
  decentralized cross-layer approach to cooperative video transmission</title><categories>cs.MM</categories><journal-ref>IEEE J. on Select. Areas in Communications, vol. 30, no. 9, pp.
  1597-1604, Oct. 2012</journal-ref><doi>10.1109/JSAC.2012.121002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the impact of cooperative relaying on uplink and downlink
multi-user (MU) wireless video transmissions. The objective is to maximize the
long-term sum of utilities across the video terminals in a decentralized
fashion, by jointly optimizing the packet scheduling, the resource allocation,
and the cooperation decisions, under the assumption that some nodes are willing
to act as cooperative relays. A pricing-based distributed resource allocation
framework is adopted, where the price reflects the expected future congestion
in the network. Specifically, we formulate the wireless video transmission
problem as an MU Markov decision process (MDP) that explicitly considers the
cooperation at the physical layer and the medium access control sublayer, the
video users' heterogeneous traffic characteristics, the dynamically varying
network conditions, and the coupling among the users' transmission strategies
across time due to the shared wireless resource. Although MDPs notoriously
suffer from the curse of dimensionality, our study shows that, with appropriate
simplications and approximations, the complexity of the MU-MDP can be
significantly mitigated. Our simulation results demonstrate that integrating
cooperative decisions into the MU-MDP optimization can increase the resource
price in networks that only support low transmission rates and can decrease the
price in networks that support high transmission rates. Additionally, our
results show that cooperation allows users with feeble direct signals to
achieve improvements in video quality on the order of 5-10 dB peak
signal-to-noise ratio (PSNR), with less than 0.8 dB quality loss by users with
strong direct signals, and with a moderate increase in total network energy
consumption that is significantly less than the energy that a distant node
would require to achieve an equivalent PSNR without exploiting cooperative
diversity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5438</identifier>
 <datestamp>2011-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5438</id><created>2011-02-26</created><updated>2011-04-14</updated><authors><author><keyname>Grytczuk</keyname><forenames>Jaros&#x142;aw</forenames></author><author><keyname>Kozik</keyname><forenames>Jakub</forenames></author><author><keyname>Witkowski</keyname><forenames>Marcin</forenames></author></authors><title>Nonrepetitive sequences on arithmetic progressions</title><categories>math.CO cs.DM cs.DS math.NT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A sequence $S=s_{1}s_{2}..._{n}$ is \emph{nonrepetitive} if no two adjacent
blocks of $S$ are identical. In 1906 Thue proved that there exist arbitrarily
long nonrepetitive sequences over 3-element set of symbols. We study a
generalization of nonrepetitive sequences involving arithmetic progressions. We
prove that for every $k\geqslant 1$ and every $c\geqslant 1$ there exist
arbitrarily long sequences over at most $(1+\frac{1}{c})k+18k^{c/c+1}$ symbols
whose subsequences indexed by arithmetic progressions with common differences
from the set $\{1,2,...,k\}$ are nonrepetitive. This improves a previous bound
obtained in \cite{Grytczuk Rainbow}. Our approach is based on a technique
introduced recently in \cite{GrytczukKozikMicek}, which was originally inspired
by a constructive proof of the Lov\'{a}sz Local Lemma due to Moser and Tardos
\cite{MoserTardos}. We also discuss some related problems that can be
successfully attacked by this method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5441</identifier>
 <datestamp>2011-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5441</id><created>2011-02-26</created><updated>2011-03-07</updated><authors><author><keyname>Heggernes</keyname><forenames>Pinar</forenames></author><author><keyname>Hof</keyname><forenames>Pim van 't</forenames></author><author><keyname>Lokshtanov</keyname><forenames>Daniel</forenames></author><author><keyname>Paul</keyname><forenames>Christophe</forenames></author></authors><title>Obtaining a Bipartite Graph by Contracting Few Edges</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We initiate the study of the Bipartite Contraction problem from the
perspective of parameterized complexity. In this problem we are given a graph
$G$ and an integer $k$, and the task is to determine whether we can obtain a
bipartite graph from $G$ by a sequence of at most $k$ edge contractions. Our
main result is an $f(k) n^{O(1)}$ time algorithm for Bipartite Contraction.
Despite a strong resemblance between Bipartite Contraction and the classical
Odd Cycle Transversal (OCT) problem, the methods developed to tackle OCT do not
seem to be directly applicable to Bipartite Contraction. Our algorithm is based
on a novel combination of the irrelevant vertex technique, introduced by
Robertson and Seymour, and the concept of important separators. Both techniques
have previously been used as key components of algorithms for fundamental
problems in parameterized complexity. However, to the best of our knowledge,
this is the first time the two techniques are applied in unison.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5442</identifier>
 <datestamp>2011-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5442</id><created>2011-02-26</created><authors><author><keyname>Shakya</keyname><forenames>Indu</forenames></author><author><keyname>Ali</keyname><forenames>Falah H.</forenames></author><author><keyname>Stipidis</keyname><forenames>Elias</forenames></author></authors><title>Blind Adaptive Successive Interference Cancellation for Multicarrier
  DS-CDMA</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new adaptive receiver design for the Multicarrier (MC) DS-CDMA is proposed
employing successive interference cancellation (SIC) architecture. One of the
main problems limiting the performance of SIC in MC DS-CDMA is the imperfect
estimation of multiple access interference (MAI), and hence, the limited
frequency diversity gain achieved in multipath fading channels. In this paper,
we design a blind adaptive SIC with new multiple access interference
suppression capability implemented within despreading process to improve both
detection and cancellation processes. Furthermore, dynamic scaling factors
derived from the despreader weights are used for interference cancellation
process. This method applied on each subcarrier is followed by maximum ratio or
equal gain combining to fully exploit the frequency diversity inherent in the
multicarrier CDMA systems. It is shown that this way of MAI estimation on
individual subcarrier provides significantly improved performance for a MC
DS-CDMA system compared to that with conventional matched filter (MF) and SIC
techniques at a little added complexity. Performance evaluation under severe
nearfar, fading correlation and system loading conditions are carried out to
affirm the gain of the proposed adaptive receiver design approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5448</identifier>
 <datestamp>2011-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5448</id><created>2011-02-26</created><updated>2011-02-28</updated><authors><author><keyname>Lellmann</keyname><forenames>Jan</forenames></author><author><keyname>Schn&#xf6;rr</keyname><forenames>Christoph</forenames></author></authors><title>Continuous Multiclass Labeling Approaches and Algorithms</title><categories>cs.CV math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study convex relaxations of the image labeling problem on a continuous
domain with regularizers based on metric interaction potentials. The generic
framework ensures existence of minimizers and covers a wide range of
relaxations of the originally combinatorial problem. We focus on two specific
relaxations that differ in flexibility and simplicity -- one can be used to
tightly relax any metric interaction potential, while the other one only covers
Euclidean metrics but requires less computational effort. For solving the
nonsmooth discretized problem, we propose a globally convergent
Douglas-Rachford scheme, and show that a sequence of dual iterates can be
recovered in order to provide a posteriori optimality bounds. In a quantitative
comparison to two other first-order methods, the approach shows competitive
performance on synthetical and real-world images. By combining the method with
an improved binarization technique for nonstandard potentials, we were able to
routinely recover discrete solutions within 1%--5% of the global optimum for
the combinatorial image labeling problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5449</identifier>
 <datestamp>2011-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5449</id><created>2011-02-26</created><authors><author><keyname>&#x106;iri&#x107;</keyname><forenames>Miroslav</forenames></author><author><keyname>Ignjatovi&#x107;</keyname><forenames>Jelena</forenames></author><author><keyname>Ba&#x161;i&#x107;</keyname><forenames>Milan</forenames></author><author><keyname>Jan&#x10d;i&#x107;</keyname><forenames>Ivana</forenames></author></authors><title>Nondeterministic automata: equivalence, bisimulations, and uniform
  relations</title><categories>cs.FL</categories><comments>35 pages, submitted to Computers and Mathematics with Applications</comments><msc-class>68Q45, 68Q70, 68Q85</msc-class><acm-class>F.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study the equivalence of nondeterministic automata pairing
the concept of a bisimulation with the recently introduced concept of a uniform
relation. In this symbiosis, uniform relations serve as equivalence relations
which relate states of two possibly different nondeterministic automata, and
bisimulations ensure compatibility with the transitions, initial and terminal
states of these automata. We define six types of bisimulations, but due to the
duality we discuss three of them: forward, backward-forward, and weak forward
bisimulations. For each od these three types of bisimulations we provide a
procedure which decides whether there is a bisimulation of this type between
two automata, and when it exists, the same procedure computes the greatest one.
We also show that there is a uniform forward bisimulation between two automata
if and only if the factor automata with respect to the greatest forward
bisimulation equivalences on these automata are isomorphic. We prove a similar
theorem for weak forward bisimulations, using the concept of a weak forward
isomorphism instead of an isomorphism. We also give examples that explain the
relationships between the considered types of bisimulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5450</identifier>
 <datestamp>2011-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5450</id><created>2011-02-26</created><authors><author><keyname>Goertz</keyname><forenames>Inge Li</forenames></author><author><keyname>Nagarajan</keyname><forenames>Viswanath</forenames></author><author><keyname>Ravi</keyname><forenames>R.</forenames></author></authors><title>Minimum Makespan Multi-vehicle Dial-a-Ride</title><categories>cs.DS</categories><comments>22 pages, 1 figure. Preliminary version appeared in ESA 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dial a ride problems consist of a metric space (denoting travel time between
vertices) and a set of m objects represented as source-destination pairs, where
each object requires to be moved from its source to destination vertex. We
consider the multi-vehicle Dial a ride problem, with each vehicle having
capacity k and its own depot-vertex, where the objective is to minimize the
maximum completion time (makespan) of the vehicles. We study the &quot;preemptive&quot;
version of the problem, where an object may be left at intermediate vertices
and transported by more than one vehicle, while being moved from source to
destination. Our main results are an O(log^3 n)-approximation algorithm for
preemptive multi-vehicle Dial a ride, and an improved O(log t)-approximation
for its special case when there is no capacity constraint. We also show that
the approximation ratios improve by a log-factor when the underlying metric is
induced by a fixed-minor-free graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5451</identifier>
 <datestamp>2011-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5451</id><created>2011-02-26</created><authors><author><keyname>Stamenkovi&#x107;</keyname><forenames>Aleksandar</forenames></author><author><keyname>&#x106;iri&#x107;</keyname><forenames>Miroslav</forenames></author><author><keyname>Ignjatovi&#x107;</keyname><forenames>Jelena</forenames></author></authors><title>Reduction of fuzzy automata by means of fuzzy quasi-orders</title><categories>cs.FL cs.AI</categories><comments>42 pages, submitted to Information Sciences</comments><msc-class>68Q05, 68Q45, 68Q70, 68Q85, 68T37, 03E72, 15B15</msc-class><acm-class>F.1.1; I.2.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In our recent paper we have established close relationships between state
reduction of a fuzzy recognizer and resolution of a particular system of fuzzy
relation equations. In that paper we have also studied reductions by means of
those solutions which are fuzzy equivalences. In this paper we will see that in
some cases better reductions can be obtained using the solutions of this system
that are fuzzy quasi-orders. Generally, fuzzy quasi-orders and fuzzy
equivalences are equally good in the state reduction, but we show that right
and left invariant fuzzy quasi-orders give better reductions than right and
left invariant fuzzy equivalences. We also show that alternate reductions by
means of fuzzy quasi-orders give better results than alternate reductions by
means of fuzzy equivalences. Furthermore we study a more general type of fuzzy
quasi-orders, weakly right and left invariant ones, and we show that they are
closely related to determinization of fuzzy recognizers. We also demonstrate
some applications of weakly left invariant fuzzy quasi-orders in conflict
analysis of fuzzy discrete event systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5452</identifier>
 <datestamp>2011-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5452</id><created>2011-02-26</created><updated>2011-05-05</updated><authors><author><keyname>&#x106;iri&#x107;</keyname><forenames>Miroslav</forenames></author><author><keyname>Ignjatovi&#x107;</keyname><forenames>Jelena</forenames></author><author><keyname>Damljanovi&#x107;</keyname><forenames>Nada</forenames></author><author><keyname>Ba&#x161;i&#x107;</keyname><forenames>Milan</forenames></author></authors><title>Bisimulations for fuzzy automata</title><categories>cs.FL cs.AI</categories><comments>41 pages, submitted to a journal</comments><msc-class>68Q05, 68Q45, 68Q70, 68Q85, 68T37, 03E72, 15B15,</msc-class><acm-class>F.1.1; I.2.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bisimulations have been widely used in many areas of computer science to
model equivalence between various systems, and to reduce the number of states
of these systems, whereas uniform fuzzy relations have recently been introduced
as a means to model the fuzzy equivalence between elements of two possible
different sets. Here we use the conjunction of these two concepts as a powerful
tool in the study of equivalence between fuzzy automata. We prove that a
uniform fuzzy relation between fuzzy automata $\cal A$ and $\cal B$ is a
forward bisimulation if and only if its kernel and co-kernel are forward
bisimulation fuzzy equivalences on $\cal A$ and $\cal B$ and there is a special
isomorphism between factor fuzzy automata with respect to these fuzzy
equivalences. As a consequence we get that fuzzy automata $\cal A$ and $\cal B$
are UFB-equivalent, i.e., there is a uniform forward bisimulation between them,
if and only if there is a special isomorphism between the factor fuzzy automata
of $\cal A$ and $\cal B$ with respect to their greatest forward bisimulation
fuzzy equivalences. This result reduces the problem of testing UFB-equivalence
to the problem of testing isomorphism of fuzzy automata, which is closely
related to the well-known graph isomorphism problem. We prove some similar
results for backward-forward bisimulations, and we point to fundamental
differences. Because of the duality with the studied concepts, backward and
forward-backward bisimulations are not considered separately. Finally, we give
a comprehensive overview of various concepts on deterministic,
nondeterministic, fuzzy, and weighted automata, which are related to
bisimulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5458</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5458</id><created>2011-02-26</created><authors><author><keyname>Joshi</keyname><forenames>Amruta</forenames></author><author><keyname>Cho</keyname><forenames>Junghoo</forenames></author><author><keyname>Radev</keyname><forenames>Dragomir</forenames></author><author><keyname>Hassan</keyname><forenames>Ahmed</forenames></author></authors><title>Improving Image Search based on User Created Communities</title><categories>cs.IR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tag-based retrieval of multimedia content is a difficult problem, not only
because of the shorter length of tags associated with images and videos, but
also due to mismatch in the terminologies used by searcher and content creator.
To alleviate this problem, we propose a simple concept-driven probabilistic
model for improving text-based rich-media search. While our approach is similar
to existing topic-based retrieval and cluster-based language modeling work,
there are two important differences: (1) our proposed model considers not only
the query-generation likelihood from cluster, but explicitly accounts for the
overall &quot;popularity&quot; of the cluster or underlying concept, and (2) we explore
the possibility of inferring the likely concept relevant to a rich-media
content through the user-created communities that the content belongs to.
  We implement two methods of concept extraction: a traditional cluster based
approach, and the proposed community based approach. We evaluate these two
techniques for how effectively they capture the intended meaning of a term from
the content creator and searcher, and their overall value in improving image
search. Our results show that concept-driven search, though simple, clearly
outperforms plain search. Among the two techniques for concept-driven search,
community-based approach is more successful, as the concepts generated from
user communities are found to be more intuitive and appealing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5461</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5461</id><created>2011-02-26</created><authors><author><keyname>Zhang</keyname><forenames>Zhou</forenames></author><author><keyname>Jiang</keyname><forenames>Hai</forenames></author></authors><title>Distributed Opportunistic Channel Access in Wireless Relay Networks</title><categories>cs.IT math.IT</categories><comments>20 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the problem of distributed opportunistic channel access in
wireless relaying is investigated. A relay network with multiple
source-destination pairs and multiple relays is considered. All the source
nodes contend through a random access procedure. A winner source node may give
up its transmission opportunity if its link quality is poor. In this research,
we apply the optimal stopping theory to analyze when a winner node should give
up its transmission opportunity. By assuming the winner node has information of
channel gains of links from itself to relays and from relays to its
destination, the existence and uniqueness of an optimal stopping rule are
rigorously proved. It is also found that the optimal stopping rule is a
pure-threshold strategy. The case when the winner node does not have
information of channel gains of links from relays to its destination is also
studied. Two stopping problems exist, one in the main layer (for channel access
of source nodes), and the other in the sub-layer (for channel access of relay
nodes). An intuitive stopping rule, where the sub-layer and the main layer
maximize their throughput respectively, is shown to be a semi-pure-threshold
strategy. The intuitive stopping rule turns out to be non-optimal. An optimal
stopping rule is then derived theoretically. Our research reveals that
multi-user (including multi-source and multi-relay) diversity and time
diversity can be fully utilized in a relay network by our proposed strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5462</identifier>
 <datestamp>2011-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5462</id><created>2011-02-26</created><updated>2011-03-04</updated><authors><author><keyname>Khajehnejad</keyname><forenames>M. Amin</forenames></author><author><keyname>Yoo</keyname><forenames>Juhwan</forenames></author><author><keyname>Anandkumar</keyname><forenames>Animashree</forenames></author><author><keyname>Hassibi</keyname><forenames>Babak</forenames></author></authors><title>Summary Based Structures with Improved Sublinear Recovery for Compressed
  Sensing</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new class of measurement matrices for compressed sensing,
using low order summaries over binary sequences of a given length. We prove
recovery guarantees for three reconstruction algorithms using the proposed
measurements, including $\ell_1$ minimization and two combinatorial methods. In
particular, one of the algorithms recovers $k$-sparse vectors of length $N$ in
sublinear time $\text{poly}(k\log{N})$, and requires at most
$\Omega(k\log{N}\log\log{N})$ measurements. The empirical oversampling constant
of the algorithm is significantly better than existing sublinear recovery
algorithms such as Chaining Pursuit and Sudocodes. In particular, for $10^3\leq
N\leq 10^8$ and $k=100$, the oversampling factor is between 3 to 8. We provide
preliminary insight into how the proposed constructions, and the fast recovery
scheme can be used in a number of practical applications such as market basket
analysis, and real time compressed sensing implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5463</identifier>
 <datestamp>2011-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5463</id><created>2011-02-26</created><authors><author><keyname>Burr</keyname><forenames>Michael</forenames></author><author><keyname>Choi</keyname><forenames>Sung Woo</forenames></author><author><keyname>Galehouse</keyname><forenames>Ben</forenames></author><author><keyname>Yap</keyname><forenames>Chee</forenames></author></authors><title>Complete Subdivision Algorithms, II: Isotopic Meshing of Singular
  Algebraic Curves</title><categories>cs.CG cs.DS math.AG</categories><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a real valued function f(X,Y), a box region B_0 in R^2 and a positive
epsilon, we want to compute an epsilon-isotopic polygonal approximation to the
restriction of the curve S=f^{-1}(0)={p in R^2: f(p)=0} to B_0. We focus on
subdivision algorithms because of their adaptive complexity and ease of
implementation. Plantinga and Vegter gave a numerical subdivision algorithm
that is exact when the curve S is bounded and non-singular. They used a
computational model that relied only on function evaluation and interval
arithmetic. We generalize their algorithm to any bounded (but possibly
non-simply connected) region that does not contain singularities of S. With
this generalization as a subroutine, we provide a method to detect isolated
algebraic singularities and their branching degree. This appears to be the
first complete purely numerical method to compute isotopic approximations of
algebraic curves with isolated singularities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5471</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5471</id><created>2011-02-26</created><authors><author><keyname>Ashley</keyname><forenames>Mary V.</forenames></author><author><keyname>Berger-Wolf</keyname><forenames>Tanya Y.</forenames></author><author><keyname>Chaovalitwongse</keyname><forenames>Wanpracha</forenames></author><author><keyname>DasGupta</keyname><forenames>Bhaskar</forenames></author><author><keyname>Khokhar</keyname><forenames>Ashfaq</forenames></author><author><keyname>Sheikh</keyname><forenames>Saad</forenames></author></authors><title>An Implicit Cover Problem in Wild Population Study</title><categories>cs.CC cs.DS q-bio.PE</categories><comments>11 pages</comments><msc-class>68Q17, 92D25</msc-class><acm-class>F.2.2; J.3</acm-class><journal-ref>Discrete Mathematics, Algorithms and Applications, 2 (2), 21-31,
  2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In an implicit combinatorial optimization problem, the constraints are not
enumerated explicitly but rather stated implicitly through equations, other
constraints or auxiliary algorithms. An important subclass of such problems is
the implicit set cover (or, equivalently, hitting set) problem in which the
sets are not given explicitly but rather defined implicitly For example, the
well-known minimum feedback arc set problem is such a problem. In this paper,
we consider such a cover problem that arises in the study of wild populations
in biology in which the sets are defined implicitly via the Mendelian
constraints and prove approximability results for this problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5478</identifier>
 <datestamp>2011-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5478</id><created>2011-02-27</created><authors><author><keyname>Pal</keyname><forenames>Arindam</forenames></author></authors><title>Minimum multicuts and Steiner forests for Okamura-Seymour graphs</title><categories>cs.DS cs.DM math.CO</categories><comments>6 pages, 1 figure</comments><msc-class>68R10</msc-class><acm-class>F.2.2; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of finding minimum multicuts for an undirected planar
graph, where all the terminal vertices are on the boundary of the outer face.
This is known as an Okamura-Seymour instance. We show that for such an
instance, the minimum multicut problem can be reduced to the minimum-cost
Steiner forest problem on a suitably defined dual graph. The minimum-cost
Steiner forest problem has a 2-approximation algorithm. Hence, the minimum
multicut problem has a 2-approximation algorithm for an Okamura-Seymour
instance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5482</identifier>
 <datestamp>2014-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5482</id><created>2011-02-27</created><updated>2014-06-22</updated><authors><author><keyname>Ziv</keyname><forenames>Jacob</forenames></author></authors><title>A Note on the Compaction of long Training Sequences for Universal
  Classification -a Non-Probabilistic Approach</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the central problems in the classification of individual test
sequences (e.g. genetic analysis), is that of checking for the similarity of
sample test sequences as compared with a set of much longer training sequences.
This is done by a set of classifiers for test sequences of length N, where each
of the classifiers is trained by the training sequences so as to minimize the
classification error rate when fed with each of the training sequences.
  It should be noted that the storage of long training sequences is considered
to be a serious bottleneck in the next generation sequencing for Genome
analysis
  Some popular classification algorithms adopt a probabilistic approach, by
assuming that the sequences are realizations of some variable-length Markov
process or a hidden Markov process (HMM), thus enabling the imbeding of the
training data onto a variable-length Suffix-tree, the size of which is usually
linear in $N$, the length of the test sequence.
  Despite of the fact that it is not assumed here that the sequences are
realizations of probabilistic processes (an assumption that does not seem to be
fully justified when dealing with biological data), it is demonstrated that
&quot;feature-based&quot; classifiers, where particular substrings (called &quot;features&quot; or
markers) are sought in a set of &quot;big data&quot; training sequences may be based on a
universal compaction of the training data that is contained in a set of $t$
(long) individual training sequences, onto a suffix-tree with no more than O(N)
leaves, regardless of how long the training sequence is, at only a vanishing
increase in the classification error rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5495</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5495</id><created>2011-02-27</created><updated>2011-05-31</updated><authors><author><keyname>Heraud</keyname><forenames>Sylvain</forenames></author><author><keyname>Nowak</keyname><forenames>David</forenames></author></authors><title>A Formalization of Polytime Functions</title><categories>cs.CC cs.CR cs.LO</categories><comments>13 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a deep embedding of Bellantoni and Cook's syntactic
characterization of polytime functions. We prove formally that it is correct
and complete with respect to the original characterization by Cobham that
required a bound to be proved manually. Compared to the paper proof by
Bellantoni and Cook, we have been careful in making our proof fully contructive
so that we obtain more precise bounding polynomials and more efficient
translations between the two characterizations. Another difference is that we
consider functions on bitstrings instead of functions on positive integers.
This latter change is motivated by the application of our formalization in the
context of formal security proofs in cryptography. Based on our core
formalization, we have started developing a library of polytime functions that
can be reused to build more complex ones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5496</identifier>
 <datestamp>2012-03-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5496</id><created>2011-02-27</created><updated>2012-03-20</updated><authors><author><keyname>Luss</keyname><forenames>Ronny</forenames></author><author><keyname>Rosset</keyname><forenames>Saharon</forenames></author><author><keyname>Shahar</keyname><forenames>Moni</forenames></author></authors><title>Efficient regularized isotonic regression with application to gene--gene
  interaction search</title><categories>stat.ME cs.SY math.OC stat.AP</categories><comments>Published in at http://dx.doi.org/10.1214/11-AOAS504 the Annals of
  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of
  Mathematical Statistics (http://www.imstat.org)</comments><proxy>vtex</proxy><report-no>IMS-AOAS-AOAS504</report-no><journal-ref>Annals of Applied Statistics 2012, Vol. 6, No. 1, 253-283</journal-ref><doi>10.1214/11-AOAS504</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Isotonic regression is a nonparametric approach for fitting monotonic models
to data that has been widely studied from both theoretical and practical
perspectives. However, this approach encounters computational and statistical
overfitting issues in higher dimensions. To address both concerns, we present
an algorithm, which we term Isotonic Recursive Partitioning (IRP), for isotonic
regression based on recursively partitioning the covariate space through
solution of progressively smaller &quot;best cut&quot; subproblems. This creates a
regularized sequence of isotonic models of increasing model complexity that
converges to the global isotonic regression solution. The models along the
sequence are often more accurate than the unregularized isotonic regression
model because of the complexity control they offer. We quantify this complexity
control through estimation of degrees of freedom along the path. Success of the
regularized models in prediction and IRPs favorable computational properties
are demonstrated through a series of simulated and real data experiments. We
discuss application of IRP to the problem of searching for gene--gene
interactions and epistasis, and demonstrate it on data from genome-wide
association studies of three common diseases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5497</identifier>
 <datestamp>2011-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5497</id><created>2011-02-27</created><authors><author><keyname>Hermenegildo</keyname><forenames>M. V.</forenames></author><author><keyname>Bueno</keyname><forenames>F.</forenames></author><author><keyname>Carro</keyname><forenames>M.</forenames></author><author><keyname>L&#xf3;pez-Garc&#xed;a</keyname><forenames>P.</forenames></author><author><keyname>Mera</keyname><forenames>E.</forenames></author><author><keyname>Morales</keyname><forenames>J. F.</forenames></author><author><keyname>Puebla</keyname><forenames>G.</forenames></author></authors><title>An overview of Ciao and its design philosophy</title><categories>cs.PL</categories><comments>Number of pages: 30, Number of figures: 14, Number of tables: 0.
  Accepted for publication in TPLP (CUP)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide an overall description of the Ciao multiparadigm programming
system emphasizing some of the novel aspects and motivations behind its design
and implementation. An important aspect of Ciao is that, in addition to
supporting logic programming (and, in particular, Prolog), it provides the
programmer with a large number of useful features from different programming
paradigms and styles, and that the use of each of these features (including
those of Prolog) can be turned on and off at will for each program module.
Thus, a given module may be using, e.g., higher order functions and
constraints, while another module may be using assignment, predicates, Prolog
meta-programming, and concurrency. Furthermore, the language is designed to be
extensible in a simple and modular way. Another important aspect of Ciao is its
programming environment, which provides a powerful preprocessor (with an
associated assertion language) capable of statically finding non-trivial bugs,
verifying that programs comply with specifications, and performing many types
of optimizations (including automatic parallelization). Such optimizations
produce code that is highly competitive with other dynamic languages or, with
the (experimental) optimizing compiler, even that of static languages, all
while retaining the flexibility and interactive development of a dynamic
language. This compilation architecture supports modularity and separate
compilation throughout. The environment also includes a powerful
auto-documenter and a unit testing framework, both closely integrated with the
assertion system. The paper provides an informal overview of the language and
program development environment. It aims at illustrating the design philosophy
rather than at being exhaustive, which would be impossible in a single journal
paper, pointing instead to previous Ciao literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5499</identifier>
 <datestamp>2011-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5499</id><created>2011-02-27</created><authors><author><keyname>Lu</keyname><forenames>Linyuan</forenames></author><author><keyname>Liu</keyname><forenames>Weiping</forenames></author></authors><title>Information filtering via preferential diffusion</title><categories>physics.data-an cs.IR</categories><comments>12 pages, 10 figures, 2 tables</comments><journal-ref>Physical Review E 83, 066119 (2011)</journal-ref><doi>10.1103/PhysRevE.83.066119</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recommender systems have shown great potential to address information
overload problem, namely to help users in finding interesting and relevant
objects within a huge information space. Some physical dynamics, including heat
conduction process and mass or energy diffusion on networks, have recently
found applications in personalized recommendation. Most of the previous studies
focus overwhelmingly on recommendation accuracy as the only important factor,
while overlook the significance of diversity and novelty which indeed provide
the vitality of the system. In this paper, we propose a recommendation
algorithm based on the preferential diffusion process on user-object bipartite
network. Numerical analyses on two benchmark datasets, MovieLens and Netflix,
indicate that our method outperforms the state-of-the-art methods.
Specifically, it can not only provide more accurate recommendations, but also
generate more diverse and novel recommendations by accurately recommending
unpopular objects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5500</identifier>
 <datestamp>2011-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5500</id><created>2011-02-27</created><updated>2011-03-02</updated><authors><author><keyname>Makarenko</keyname><forenames>Andrey V.</forenames></author></authors><title>Phenomenological Model for Growth of Volumes Digital Data</title><categories>cs.CY</categories><comments>11 pages, 11 figures, 1 table</comments><msc-class>37M05, 37M10</msc-class><acm-class>C.0; E.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Currently, experts from IT industry are closely monitoring the soaring total
volume of digital data. Moreover the problem is not purely technical, it
directly affects human civilization as a whole. The growth rate of the all
increasing and is already very large. Began is actively appear apocalyptic
scenarios of development IT technology, and humanity as a whole. In this paper
we propose a constructive alternative to these emotional ideas. Invited to
consider the digital industry as a complete system that is developing in close
connection with human civilization. Moreover, system self-organizing and
essentially nonlinear in its behavior. To study this system is applied
system-cybernetic approach. The mathematical model is developed, shows that in
the future rate of production of digital data is stabilize at 13.2 ZB per year.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5509</identifier>
 <datestamp>2011-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5509</id><created>2011-02-27</created><authors><author><keyname>Lahti</keyname><forenames>Leo</forenames></author></authors><title>Probabilistic analysis of the human transcriptome with side information</title><categories>stat.ML cs.CE q-bio.GN q-bio.MN q-bio.QM stat.AP stat.ME</categories><comments>Doctoral thesis. 103 pages, 11 figures</comments><report-no>TKK-ICS-D19</report-no><acm-class>G.3; I.5.3; J.3; K.8.1</acm-class><journal-ref>TKK Dissertations in Information and Computer Science TKK-ICS-D19.
  Aalto University School of Science and Technology, Department of Information
  and Computer Science, Espoo, Finland, 2010</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Understanding functional organization of genetic information is a major
challenge in modern biology. Following the initial publication of the human
genome sequence in 2001, advances in high-throughput measurement technologies
and efficient sharing of research material through community databases have
opened up new views to the study of living organisms and the structure of life.
In this thesis, novel computational strategies have been developed to
investigate a key functional layer of genetic information, the human
transcriptome, which regulates the function of living cells through protein
synthesis. The key contributions of the thesis are general exploratory tools
for high-throughput data analysis that have provided new insights to
cell-biological networks, cancer mechanisms and other aspects of genome
function.
  A central challenge in functional genomics is that high-dimensional genomic
observations are associated with high levels of complex and largely unknown
sources of variation. By combining statistical evidence across multiple
measurement sources and the wealth of background information in genomic data
repositories it has been possible to solve some the uncertainties associated
with individual observations and to identify functional mechanisms that could
not be detected based on individual measurement sources. Statistical learning
and probabilistic models provide a natural framework for such modeling tasks.
Open source implementations of the key methodological contributions have been
released to facilitate further adoption of the developed methods by the
research community.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5511</identifier>
 <datestamp>2011-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5511</id><created>2011-02-27</created><authors><author><keyname>Lip</keyname><forenames>Sean Z. W.</forenames></author></authors><title>A Fast Algorithm for the Discrete Core/Periphery Bipartitioning Problem</title><categories>physics.soc-ph cs.DS cs.SI</categories><comments>7 pages, no figures. Submitted to Social Networks</comments><msc-class>91D30</msc-class><acm-class>J.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Various methods have been proposed in the literature to determine an optimal
partitioning of the set of actors in a network into core and periphery subsets.
However, these methods either work only for relatively small input sizes, or do
not guarantee an optimal answer. In this paper, we propose a new algorithm to
solve this problem. This algorithm is efficient and exact, allowing the optimal
partitioning for networks of several thousand actors to be computed in under a
second. We also show that the optimal core can be characterized as a set
containing the actors with the highest degrees in the original network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5523</identifier>
 <datestamp>2011-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5523</id><created>2011-02-27</created><authors><author><keyname>Fouquet</keyname><forenames>Jean-Luc</forenames><affiliation>LIFO</affiliation></author><author><keyname>Vanherpe</keyname><forenames>Jean-Marie</forenames><affiliation>LIFO</affiliation></author></authors><title>A new bound for parsimonious edge-colouring of graphs with maximum
  degree three</title><categories>cs.DM</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a graph $G$ of maximum degree 3, let $\gamma(G)$ denote the largest
fraction of edges that can be 3 edge-coloured. Rizzi \cite{Riz09} showed that
$\gamma(G) \geq 1-\frac{2\strut}{\strut 3 g_{odd}(G)}$ where $g_{odd}(G)$ is
the odd girth of $G$, when $G$ is triangle-free. In \cite{FouVan10a} we
extended that result to graph with maximum degree 3. We show here that
$\gamma(G) \geq 1-\frac{2 \strut}{\strut 3 g_{odd}(G)+2}$, which leads to
$\gamma(G) \geq 15/17$ when considering graphs with odd girth at least 5,
distinct from the Petersen graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5529</identifier>
 <datestamp>2014-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5529</id><created>2011-02-27</created><updated>2014-05-01</updated><authors><author><keyname>Casteigts</keyname><forenames>Arnaud</forenames></author><author><keyname>Chaumette</keyname><forenames>Serge</forenames></author><author><keyname>Ferreira</keyname><forenames>Afonso</forenames></author></authors><title>Characterizing Topological Assumptions of Distributed Algorithms in
  Dynamic Networks</title><categories>cs.DC cs.NI</categories><comments>18 pages, 12 figures, long version of a Sirocco'09 paper</comments><acm-class>C.2.4; F.3.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Besides the complexity in time or in number of messages, a common approach
for analyzing distributed algorithms is to look at the assumptions they make on
the underlying network. We investigate this question from the perspective of
network dynamics. In particular, we ask how a given property on the evolution
of the network can be rigorously proven as necessary or sufficient for a given
algorithm. The main contribution of this paper is to propose the combination of
two existing tools in this direction: local computations by means of graph
relabelings, and evolving graphs. Such a combination makes it possible to
express fine-grained properties on the network dynamics, then examine what
impact those properties have on the execution at a precise, intertwined, level.
We illustrate the use of this framework through the analysis of three simple
algorithms, then discuss general implications of this work, which include (i)
the possibility to compare distributed algorithms on the basis of their
topological requirements, (ii) a formal hierarchy of dynamic networks based on
these requirements, and (iii) the potential for mechanization induced by our
framework, which we believe opens a door towards automated analysis and
decision support in dynamic networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5535</identifier>
 <datestamp>2011-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5535</id><created>2011-02-27</created><authors><author><keyname>Shakya</keyname><forenames>Indu</forenames></author><author><keyname>Ali</keyname><forenames>Falah H.</forenames></author><author><keyname>Stipidis</keyname><forenames>Elias</forenames></author></authors><title>Full Rate Collaborative Diversity Scheme for Multiple Access Fading
  Channels</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  User cooperation is a well-known approach to achieve diversity without
multiple antennas, however at the cost of inevitable loss of rate mostly due to
the need of additional channels for relaying. A new collaborative diversity
scheme is proposed here for multiple access fading channels to attain full rate
with near maximum diversity. This is achieved by allowing two users and their
corresponding relays to transmit/forward data on the same channel by exploiting
unique spatial-signatures of their fading channels. The base-station jointly
detects the co-channel users' data using maximum-likelihood search algorithm
over small set of possible data combinations. Full data rate with significant
diversity gain near to two-antenna Alamouti scheme is shown.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5538</identifier>
 <datestamp>2011-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5538</id><created>2011-02-27</created><updated>2011-09-15</updated><authors><author><keyname>Romashchenko</keyname><forenames>Andrei</forenames></author></authors><title>Pseudo-random graphs and bit probe schemes with one-sided error</title><categories>cs.DS cs.CC</categories><comments>19 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study probabilistic bit-probe schemes for the membership problem. Given a
set A of at most n elements from the universe of size m we organize such a
structure that queries of type &quot;Is x in A?&quot; can be answered very quickly.
H.Buhrman, P.B.Miltersen, J.Radhakrishnan, and S.Venkatesh proposed a bit-probe
scheme based on expanders. Their scheme needs space of $O(n\log m)$ bits, and
requires to read only one randomly chosen bit from the memory to answer a
query. The answer is correct with high probability with two-sided errors. In
this paper we show that for the same problem there exists a bit-probe scheme
with one-sided error that needs space of $O(n\log^2 m+\poly(\log m))$ bits. The
difference with the model of Buhrman, Miltersen, Radhakrishnan, and Venkatesh
is that we consider a bit-probe scheme with an auxiliary word. This means that
in our scheme the memory is split into two parts of different size: the main
storage of $O(n\log^2 m)$ bits and a short word of $\log^{O(1)}m$ bits that is
pre-computed once for the stored set A and `cached'. To answer a query &quot;Is x in
A?&quot; we allow to read the whole cached word and only one bit from the main
storage. For some reasonable values of parameters our space bound is better
than what can be achieved by any scheme without cached data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5540</identifier>
 <datestamp>2011-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5540</id><created>2011-02-27</created><updated>2011-08-09</updated><authors><author><keyname>Mitzenmacher</keyname><forenames>Michael</forenames></author><author><keyname>Steinke</keyname><forenames>Thomas</forenames></author><author><keyname>Thaler</keyname><forenames>Justin</forenames></author></authors><title>Hierarchical Heavy Hitters with the Space Saving Algorithm</title><categories>cs.DS</categories><comments>22 pages, 18 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Hierarchical Heavy Hitters problem extends the notion of frequent items
to data arranged in a hierarchy. This problem has applications to network
traffic monitoring, anomaly detection, and DDoS detection. We present a new
streaming approximation algorithm for computing Hierarchical Heavy Hitters that
has several advantages over previous algorithms. It improves on the worst-case
time and space bounds of earlier algorithms, is conceptually simple and
substantially easier to implement, offers improved accuracy guarantees, is
easily adopted to a distributed or parallel setting, and can be efficiently
implemented in commodity hardware such as ternary content addressable memory
(TCAMs). We present experimental results showing that for parameters of primary
practical interest, our two-dimensional algorithm is superior to existing
algorithms in terms of speed and accuracy, and competitive in terms of space,
while our one-dimensional algorithm is also superior in terms of speed and
accuracy for a more limited range of parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5549</identifier>
 <datestamp>2011-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5549</id><created>2011-02-27</created><updated>2011-10-11</updated><authors><author><keyname>Sidhu</keyname><forenames>Gagan</forenames></author></authors><title>Instant Replay: Investigating statistical Analysis in Sports</title><categories>stat.AP cs.AI physics.data-an stat.ML</categories><comments>13 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Technology has had an unquestionable impact on the way people watch sports.
Along with this technological evolution has come a higher standard to ensure a
good viewing experience for the casual sports fan. It can be argued that the
pervasion of statistical analysis in sports serves to satiate the fan's desire
for detailed sports statistics. The goal of statistical analysis in sports is a
simple one: to eliminate subjective analysis. In this paper, we review previous
work that attempts to analyze various aspects in sports by using ideas from
Markov Chains, Bayesian Inference and Markov Chain Monte Carlo (MCMC) methods.
The unifying goal of these works is to achieve an accurate representation of
the player's ability, the sport, or the environmental effects on the player's
performance. With the prevalence of cheap computation, it is possible that
using techniques in Artificial Intelligence could improve the result of
statistical analysis in sport. This is best illustrated when evaluating
football using Neuro Dynamic Programming, a Control Theory paradigm heavily
based on theory in Stochastic processes. The results from this method suggest
that statistical analysis in sports may benefit from using ideas from the area
of Control Theory or Machine Learning
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5555</identifier>
 <datestamp>2012-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5555</id><created>2011-02-27</created><updated>2012-01-22</updated><authors><author><keyname>Klyachko</keyname><forenames>Anton A.</forenames></author><author><keyname>Menshova</keyname><forenames>Ekaterina V.</forenames></author></authors><title>The identities of additive binary arithmetics</title><categories>cs.DM math.GR math.RA</categories><comments>6 pages. A Russian version of this paper is at
  http://mech.math.msu.su/department/algebra/staff/klyachko/papers.htm . V3:
  the easier direction of the proof of the main theorem is corrected and some
  minor changes are done</comments><msc-class>08A70</msc-class><journal-ref>Electronic Journal of Combinatorics, 2012, 19, #P40</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Operations of arbitrary arity expressible via addition modulo 2^n and bitwise
addition modulo 2 admit a simple description. The identities connecting these
two additions have finite basis. Moreover, the universal algebra with these two
operations is rationally equivalent to a nilpotent ring and, therefore,
generates a Specht variety.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5559</identifier>
 <datestamp>2011-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5559</id><created>2011-02-27</created><updated>2011-03-01</updated><authors><author><keyname>Qiu</keyname><forenames>Chenlu</forenames></author><author><keyname>Vaswani</keyname><forenames>Namrata</forenames></author></authors><title>Support-Predicted Modified-CS for Recursive Robust Principal Components'
  Pursuit</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work proposes a causal and recursive algorithm for solving the &quot;robust&quot;
principal components' analysis (PCA) problem. We primarily focus on robustness
to correlated outliers. In recent work, we proposed a new way to look at this
problem and showed how a key part of its solution strategy involves solving a
noisy compressive sensing(CS) problem. However, if the support size of the
outliers becomes too large, for a given dimension of the current PC space, then
the number of &quot;measurements&quot; available for CS may become too small. In this
work, we show how to address this issue by utilizing the correlation of the
outliers to predict their support at the current time; and using this as
&quot;partial support knowledge&quot; for solving Modified-CS instead of CS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5561</identifier>
 <datestamp>2011-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5561</id><created>2011-02-27</created><updated>2011-03-01</updated><authors><author><keyname>Matuz</keyname><forenames>Gabor</forenames></author><author><keyname>Lorincz</keyname><forenames>Andras</forenames></author></authors><title>Decision Making Agent Searching for Markov Models in Near-Deterministic
  World</title><categories>cs.AI cs.LG</categories><comments>Draft</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reinforcement learning has solid foundations, but becomes inefficient in
partially observed (non-Markovian) environments. Thus, a learning agent -born
with a representation and a policy- might wish to investigate to what extent
the Markov property holds. We propose a learning architecture that utilizes
combinatorial policy optimization to overcome non-Markovity and to develop
efficient behaviors, which are easy to inherit, tests the Markov property of
the behavioral states, and corrects against non-Markovity by running a
deterministic factored Finite State Model, which can be learned. We illustrate
the properties of architecture in the near deterministic Ms. Pac-Man game. We
analyze the architecture from the point of view of evolutionary, individual,
and social learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5584</identifier>
 <datestamp>2011-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5584</id><created>2011-02-27</created><authors><author><keyname>Toninho</keyname><forenames>Bernardo</forenames><affiliation>Faculdade de Ci&#xea;ncias e Tecnologia, Universidade Nova de Lisboa and Computer Science Department, Carnegie Mellon University</affiliation></author><author><keyname>Caires</keyname><forenames>Lu&#xed;s</forenames><affiliation>Departamento de Informatica / Universidade Nova de Lisboa</affiliation></author></authors><title>A Spatial-Epistemic Logic for Reasoning about Security Protocols</title><categories>cs.LO cs.CR</categories><comments>In Proceedings SecCo 2010, arXiv:1102.5161</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 51, 2011, pp. 1-15</journal-ref><doi>10.4204/EPTCS.51.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reasoning about security properties involves reasoning about where the
information of a system is located, and how it evolves over time. While most
security analysis techniques need to cope with some notions of information
locality and knowledge propagation, usually they do not provide a general
language for expressing arbitrary properties involving local knowledge and
knowledge transfer. Building on this observation, we introduce a framework for
security protocol analysis based on dynamic spatial logic specifications. Our
computational model is a variant of existing pi-calculi, while specifications
are expressed in a dynamic spatial logic extended with an epistemic operator.
We present the syntax and semantics of the model and logic, and discuss the
expressiveness of the approach, showing it complete for passive attackers. We
also prove that generic Dolev-Yao attackers may be mechanically determined for
any deterministic finite protocol, and discuss how this result may be used to
reason about security properties of open systems. We also present a
model-checking algorithm for our logic, which has been implemented as an
extension to the SLMC system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5585</identifier>
 <datestamp>2011-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5585</id><created>2011-02-27</created><authors><author><keyname>Best</keyname><forenames>Eike</forenames><affiliation>Oldenburg</affiliation></author><author><keyname>Darondeau</keyname><forenames>Philippe</forenames><affiliation>Rennes</affiliation></author><author><keyname>Gorrieri</keyname><forenames>Roberto</forenames><affiliation>Bologna</affiliation></author></authors><title>On the Decidability of Non Interference over Unbounded Petri Nets</title><categories>cs.CR cs.LO</categories><comments>In Proceedings SecCo 2010, arXiv:1102.5161</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 51, 2011, pp. 16-33</journal-ref><doi>10.4204/EPTCS.51.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Non-interference, in transitive or intransitive form, is defined here over
unbounded (Place/Transition) Petri nets. The definitions are adaptations of
similar, well-accepted definitions introduced earlier in the framework of
labelled transition systems. The interpretation of intransitive
non-interference which we propose for Petri nets is as follows. A Petri net
represents the composition of a controlled and a controller systems, possibly
sharing places and transitions. Low transitions represent local actions of the
controlled system, high transitions represent local decisions of the
controller, and downgrading transitions represent synchronized actions of both
components. Intransitive non-interference means the impossibility for the
controlled system to follow any local strategy that would force or dodge
synchronized actions depending upon the decisions taken by the controller after
the last synchronized action. The fact that both language equivalence and
bisimulation equivalence are undecidable for unbounded labelled Petri nets
might be seen as an indication that non-interference properties based on these
equivalences cannot be decided. We prove the opposite, providing results of
decidability of non-interference over a representative class of infinite state
systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5586</identifier>
 <datestamp>2011-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5586</id><created>2011-02-27</created><authors><author><keyname>H&#xe9;lou&#xeb;t</keyname><forenames>Lo&#xef;c</forenames><affiliation>INRIA Rennes</affiliation></author><author><keyname>Roumy</keyname><forenames>Aline</forenames><affiliation>INRIA Rennes</affiliation></author></authors><title>Covert channel detection using Information Theory</title><categories>cs.CR cs.IT math.IT</categories><comments>In Proceedings SecCo 2010, arXiv:1102.5161</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 51, 2011, pp. 34-51</journal-ref><doi>10.4204/EPTCS.51.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an information theory based detection framework for
covert channels. We first show that the usual notion of interference does not
characterize the notion of deliberate information flow of covert channels. We
then show that even an enhanced notion of &quot;iterated multivalued interference&quot;
can not capture flows with capacity lower than one bit of information per
channel use. We then characterize and compute the capacity of covert channels
that use control flows for a class of systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5593</identifier>
 <datestamp>2011-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5593</id><created>2011-02-27</created><updated>2011-03-03</updated><authors><author><keyname>Wang</keyname><forenames>Fanggang</forenames></author><author><keyname>Xu</keyname><forenames>Rongtao</forenames></author><author><keyname>Zhong</keyname><forenames>Zhangdui</forenames></author></authors><title>Low Complexity Kolmogorov-Smirnov Modulation Classification</title><categories>cs.IT cs.LG math.IT</categories><comments>This paper is accepted by IEEE WCNC 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Kolmogorov-Smirnov (K-S) test-a non-parametric method to measure the goodness
of fit, is applied for automatic modulation classification (AMC) in this paper.
The basic procedure involves computing the empirical cumulative distribution
function (ECDF) of some decision statistic derived from the received signal,
and comparing it with the CDFs of the signal under each candidate modulation
format. The K-S-based modulation classifier is first developed for AWGN
channel, then it is applied to OFDM-SDMA systems to cancel multiuser
interference. Regarding the complexity issue of K-S modulation classification,
we propose a low-complexity method based on the robustness of the K-S
classifier. Extensive simulation results demonstrate that compared with the
traditional cumulant-based classifiers, the proposed K-S classifier offers
superior classification performance and requires less number of signal samples
(thus is fast).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5597</identifier>
 <datestamp>2011-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5597</id><created>2011-02-28</created><authors><author><keyname>&#x158;eh{\ru}&#x159;ek</keyname><forenames>Radim</forenames></author></authors><title>Fast and Faster: A Comparison of Two Streamed Matrix Decomposition
  Algorithms</title><categories>cs.NA cs.LG</categories><journal-ref>NIPS Workshop on Low-Rank Methods for Large-Scale Machine
  Learning, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the explosion of the size of digital dataset, the limiting factor for
decomposition algorithms is the \emph{number of passes} over the input, as the
input is often stored out-of-core or even off-site. Moreover, we're only
interested in algorithms that operate in \emph{constant memory} w.r.t. to the
input size, so that arbitrarily large input can be processed. In this paper, we
present a practical comparison of two such algorithms: a distributed method
that operates in a single pass over the input vs. a streamed two-pass
stochastic algorithm. The experiments track the effect of distributed
computing, oversampling and memory trade-offs on the accuracy and performance
of the two algorithms. To ensure meaningful results, we choose the input to be
a real dataset, namely the whole of the English Wikipedia, in the application
settings of Latent Semantic Analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5599</identifier>
 <datestamp>2011-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5599</id><created>2011-02-28</created><updated>2011-03-06</updated><authors><author><keyname>Li</keyname><forenames>Zhongkui</forenames></author><author><keyname>Duan</keyname><forenames>Zhisheng</forenames></author><author><keyname>Chen</keyname><forenames>Guanrong</forenames></author></authors><title>Consensus of Discrete-Time Linear Multi-Agent Systems with Observer-Type
  Protocols</title><categories>cs.SY math.OC</categories><comments>18 pages, 6 figures; This paper is an enlarged version of the paper,
  with the same title, to appear in Discrete and Continuous Dynamical
  Systems-Series B</comments><journal-ref>Discrete and Continuous Dynamical Systems-Series B 16 (2011)
  489-505</journal-ref><doi>10.3934/dcdsb.2011.16.489</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper concerns the consensus of discrete-time multi-agent systems with
linear or linearized dynamics. An observer-type protocol based on the relative
outputs of neighboring agents is proposed. The consensus of such a multi-agent
system with a directed communication topology can be cast into the stability of
a set of matrices with the same low dimension as that of a single agent. The
notion of discrete-time consensus region is then introduced and analyzed. For
neurally stable agents, it is shown that there exists an observer-type protocol
having a bounded consensus region in the form of an open unit disk, provided
that each agent is stabilizable and detectable. An algorithm is further
presented to construct a protocol to achieve consensus with respect to all the
communication topologies containing a spanning tree. Moreover, for the case
where the agents have no poles outside the unit circle,an algorithm is proposed
to construct a protocol having an origin-centered disk of radius $\delta$
($0&lt;\delta&lt;1$) as its consensus region, where $\delta$ has to further satisfy a
constraint related to the unstable eigenvalues of a single agent for the case
where each agent has a least one eigenvalue outside the unit circle. Finally,
the consensus algorithms are applied to solve formation control problems of
multi-agent systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5603</identifier>
 <datestamp>2011-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5603</id><created>2011-02-28</created><updated>2011-06-10</updated><authors><author><keyname>Li</keyname><forenames>Zhongkui</forenames></author><author><keyname>Duan</keyname><forenames>Zhisheng</forenames></author></authors><title>Distributed Adaptive Attitude Synchronization of Multiple Spacecraft</title><categories>cs.SY math.OC</categories><comments>13 pages, 11 figures. To appear in SCIENCE CHINA Technological
  Sciences</comments><journal-ref>Science China Technological Sciences 54 (2011) 1992-1998</journal-ref><doi>10.1007/s11431-011-4475-0</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the distributed attitude synchronization problem of
multiple spacecraft with unknown inertia matrices. Two distributed adaptive
controllers are proposed for the cases with and without a virtual leader to
which a time-varying reference attitude is assigned. The first controller
achieves attitude synchronization for a group of spacecraft with a leaderless
communication topology having a directed spanning tree. The second controller
guarantees that all spacecraft track the reference attitude if the virtual
leader has a directed path to all other spacecraft. Simulation examples are
presented to illustrate the effectiveness of the results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5605</identifier>
 <datestamp>2013-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5605</id><created>2011-02-28</created><updated>2013-03-14</updated><authors><author><keyname>Cui</keyname><forenames>Peng</forenames></author></authors><title>On Unique Games with Negative Weights</title><categories>cs.CC</categories><comments>7 pages, accepted by COCOA 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the author defines Generalized Unique Game Problem (GUGP),
where weights of the edges are allowed to be negative. Two special types of
GUGP are illuminated, GUGP-NWA, where the weights of all edges are negative,
and GUGP-PWT($\rho$), where the total weight of all edges are positive and the
negative-positive ratio is at most $\rho$. The author investigates the
counterpart of the Unique Game Conjecture on GUGP-PWT($\rho$). The author shows
that Unique Game Conjecture on GUGP-PWT(1) holds true, and Unique Game
Conjecture on GUGP-PWT(1/2) holds true, if the 2-to-1 Conjecture holds true.
The author poses an open problem whether Unique Game Conjecture holds true on
GUGP-PWT($\rho$) with $0&lt;\rho&lt;1$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5635</identifier>
 <datestamp>2011-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5635</id><created>2011-02-28</created><authors><author><keyname>Geiger</keyname><forenames>Martin Josef</forenames></author><author><keyname>Sevaux</keyname><forenames>Marc</forenames></author></authors><title>Practical inventory routing: A problem definition and an optimization
  method</title><categories>cs.AI</categories><journal-ref>Proceedings of the EU/MEeting 2011 - Workshop on Client-Centered
  Logistics and International Aid, February 21-22, 2011, pages 32-35</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The global objective of this work is to provide practical optimization
methods to companies involved in inventory routing problems, taking into
account this new type of data. Also, companies are sometimes not able to deal
with changing plans every period and would like to adopt regular structures for
serving customers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5638</identifier>
 <datestamp>2013-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5638</id><created>2011-02-28</created><updated>2011-06-10</updated><authors><author><keyname>Pandya</keyname><forenames>Paritosh K.</forenames></author><author><keyname>Shah</keyname><forenames>Simoni S.</forenames></author></authors><title>On Expressive Powers of Timed Logics: Comparing Boundedness,
  Non-punctuality and Deterministic Freezing</title><categories>cs.LO</categories><comments>Major revision of the paper</comments><journal-ref>Proc. CONCUR 2011, LNCS 6901, 2011. pp 60-75</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Timed temporal logics exhibit a bewildering diversity of operators and the
resulting decidability and expressiveness properties also vary considerably. We
study the expressive power of timed logics TPTL[U,S] and MTL[U,S] as well as of
their several fragments. Extending the LTL EF games of Etessami and Wilke, we
define MTL Ehrenfeucht-Fraisse games on a pair of timed words. Using the
associated EF theorem, we show that, expressively, the timed logics
BoundedMTL[U,S], MTL[F,P] and MITL[U,S] (respectively incorporating the
restrictions of boundedness, unary modalities and non-punctuality), are all
pairwise incomparable. As our first main result, we show that MTL[U,S] is
strictly contained within the freeze logic TPTL[U,S] for both weakly and
strictly monotonic timed words, thereby extending the result of Bouyer et al
and completing the proof of the original conjecture of Alur and Henziger from
1990. We also relate the expressiveness of a recently proposed deterministic
freeze logic TTL[X,Y] (with NP-complete satisfiability) to MTL. As our second
main result, we show by an explicit reduction that TTL[X,Y] lies strictly
within the unary, non-punctual logic MITL[F,P]. This shows that deterministic
freezing with punctuality is expressible in the non-punctual MITL[F,P].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5641</identifier>
 <datestamp>2011-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5641</id><created>2011-02-28</created><authors><author><keyname>Wang</keyname><forenames>Fanggang</forenames></author><author><keyname>Wang</keyname><forenames>Xiaodong</forenames></author></authors><title>Coherent Optical DFT-Spread OFDM</title><categories>cs.IT math.IT</categories><comments>This idea was originally submitted at Nov. 28th, 2009. After many
  times of rejection and resubmission, it was finally accepted by the journal
  of Advances in Optical Technologies</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider application of the discrete Fourier transform-spread orthogonal
frequency-division multiplexing (DFT-spread OFDM) technique to high-speed fiber
optic communications. The DFT-spread OFDM is a form of single-carrier technique
that possesses almost all advantages of the multicarrier OFDM technique (such
as high spectral efficiency, flexible bandwidth allocation, low sampling rate
and low-complexity equalization). In particular, we consider the optical
DFT-spread OFDM system with polarization division multiplexing (PDM) that
employs a tone-by-tone linear minimum mean square error (MMSE) equalizer. We
show that such a system offers a much lower peak-to-average power ratio (PAPR)
performance as well as better bit error rate (BER) performance compared with
the optical OFDM system that employs amplitude clipping.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5643</identifier>
 <datestamp>2011-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5643</id><created>2011-02-28</created><authors><author><keyname>Chien</keyname><forenames>Chun-Che</forenames></author><author><keyname>Su</keyname><forenames>Hsuan-Jung</forenames></author><author><keyname>Li</keyname><forenames>Hsueh-Jyh</forenames></author></authors><title>Joint Beamforming and Power Allocation for MIMO Relay Broadcast Channel
  with Individual SINR Constraints</title><categories>cs.IT math.IT</categories><comments>30 pages, 12 figures, 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, system design for the multi-input multi-output (MIMO) relay
broadcast channel with individual signal-to-interference-plus-noise ratio
(SINR) constraints at the mobile stations (MS) is considered. By exploring the
structure of downlink (DL) uplink (UL) duality at either the base station (BS)
or the relay station (RS), we propose two schemes of joint power allocation and
beamforming design at the BS and the RS. The problem of existence of feasible
solutions under practical power constraints at the BS and the RS with given
SINR targets is considered first. Then the problem of sum power minimization is
considered. Each design problem can be solved efficiently using optimal joint
power allocation and beamforming under the framework of convex optimization. We
also show that with subchannel pairing at the RS, the transmission power can be
reduced by channel compensation at either hop. Finally, an extension to more
general multi-hop applications is provided to further improve the power
efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5647</identifier>
 <datestamp>2011-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5647</id><created>2011-02-28</created><authors><author><keyname>Gargiulo</keyname><forenames>Floriana</forenames></author><author><keyname>Lenormand</keyname><forenames>Maxime</forenames></author><author><keyname>Huet</keyname><forenames>Sylvie</forenames></author><author><keyname>Espinosa</keyname><forenames>Omar Baqueiro</forenames></author></authors><title>A commuting network model: going to the bulk</title><categories>physics.soc-ph cs.CY</categories><comments>submitted to JASSS</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The influence of commuting in socio-economic dynamics increases constantly.
Analysing and modelling the networks formed by commuters to help
decision-making regarding the land-use has become crucial. This paper presents
a simple spatial interaction simulated model with only one parameter. The
proposed algorithm considers each individual who wants to commute, starting
from their living place to all their workplaces. It decides where the location
of the workplace following the classical rule inspired from the gravity law
consisting in a compromise between the job offers and the distance to the jobs.
The further away the job offer is, the more important it must be in order to be
considered. Inversely, only the quantity of offers is important for the
decision when these offers are close. The paper also presents a comparative
analysis of the structure of the commuting networks of the four European
regions to which we apply our model. The model is calibrated and validated on
these regions. Results from the analysis shows that the model is very efficient
in reproducing most of the statistical properties of the network given by the
data sources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5670</identifier>
 <datestamp>2011-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5670</id><created>2011-02-28</created><authors><author><keyname>Lanati</keyname><forenames>Matteo</forenames></author><author><keyname>Curone</keyname><forenames>Davide</forenames></author><author><keyname>Secco</keyname><forenames>Emanuele Lindo</forenames></author><author><keyname>Magenes</keyname><forenames>Giovanni</forenames></author><author><keyname>Gamba</keyname><forenames>Paolo</forenames></author></authors><title>An Autonomous Long Range Monitoring System For Emergency Operators</title><categories>cs.OH</categories><comments>13 pages, 7 figures, 1 table</comments><journal-ref>International Journal of Wireless &amp; Mobile Networks, vol. 3, no.
  1, pp. 10-23, 2011</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Miniaturization and portability of new electronics lead up to wearable
devices embedded within garments: a European program called ProeTEX developed
multi-purpose sensors integrated within emergency operators' garments in order
to monitor their health state and the surrounding environment. This work deals
with the development of an autonomous Long Range communication System (LRS),
suitable to transmit data between operators' equipment and the local command
post, where remote monitoring software is set up. The LRS infrastructure is
based on Wi-Fi protocol and modular architecture. Field tests carried out on
the developed prototype showed a high reliability in terms of correctly
exchanged data and recovering capabilities in case of temporary disconnection,
due to the operator's movements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5673</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5673</id><created>2011-02-28</created><authors><author><keyname>Ghasemi</keyname><forenames>Akbar</forenames></author><author><keyname>Motahari</keyname><forenames>Abolfazl Seyed</forenames></author><author><keyname>Khandani</keyname><forenames>Amir Keyvan</forenames></author></authors><title>Interference Alignment for the MIMO Interference Channel with Delayed
  Local CSIT</title><categories>cs.IT math.IT</categories><comments>36 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the MIMO (multiple-input multiple-output) Gaussian interference
channel with i.i.d. fading across antennas and channel uses and with the
delayed local channel state information at the transmitters (CSIT). For the
two-user case, achievability results for the degrees of freedom (DoF) region of
this channel are provided. We also prove the tightness of our achievable DoF
region for some antenna configurations. Interestingly, there are some cases in
which the DoF region with delayed local CSIT is identical to the DoF region
with perfect CSIT and that is strictly larger than the DoF region with no CSIT.
We then consider the $K$-user MISO (multiple-input single-output) IC and show
that the degrees of freedom of this channel could be greater than one with
delayed local CSIT.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5682</identifier>
 <datestamp>2011-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5682</id><created>2011-02-28</created><authors><author><keyname>Gawrychowski</keyname><forenames>Pawe&#x142;</forenames></author><author><keyname>Je&#x17c;</keyname><forenames>Artur</forenames></author><author><keyname>Maletti</keyname><forenames>Andreas</forenames></author></authors><title>On minimising automata with errors</title><categories>cs.FL</categories><comments>12 pages plus 19-page appendix, submitted to a conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of k-minimisation for a DFA M is the computation of a smallest
DFA N (where the size |M| of a DFA M is the size of the domain of the
transition function) such that their recognized languages differ only on words
of length less than k. The previously best algorithm, which runs in time O(|M|
log^2 n) where n is the number of states, is extended to DFAs with partial
transition functions. Moreover, a faster O(|M| log n) algorithm for DFAs that
recognise finite languages is presented. In comparison to the previous
algorithm for total DFAs, the new algorithm is much simpler and allows the
calculation of a k-minimal DFA for each k in parallel. Secondly, it is
demonstrated that calculating the least number of introduced errors is hard:
Given a DFA M and numbers k and m, it is NP-hard to decide whether there exists
a k-minimal DFA N differing from DFA M on at most m words. A similar result
holds for hyper-minimisation of DFAs in general: Given a DFA M and numbers s
and m, it is NP-hard to decide whether there exists a DFA N with at most s
states such that DFA M and N differ on at msot m words.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5683</identifier>
 <datestamp>2011-06-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5683</id><created>2011-02-28</created><updated>2011-06-20</updated><authors><author><keyname>Frougny</keyname><forenames>Christiane</forenames></author><author><keyname>Pelantov&#xe1;</keyname><forenames>Edita</forenames></author><author><keyname>Svobodov&#xe1;</keyname><forenames>Milena</forenames></author></authors><title>Parallel addition in non-standard numeration systems</title><categories>math.NT cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider numeration systems where digits are integers and the base is an
algebraic number $\beta$ such that $|\beta|&gt;1$ and $\beta$ satisfies a
polynomial where one coefficient is dominant in a certain sense. For this class
of bases $\beta$, we can find an alphabet of signed-digits on which addition is
realizable by a parallel algorithm in constant time. This algorithm is a kind
of generalization of the one of Avizienis. We also discuss the question of
cardinality of the used alphabet, and we are able to modify our algorithm in
order to work with a smaller alphabet. We then prove that $\beta$ satisfies
this dominance condition if and only if it has no conjugate of modulus 1. When
the base $\beta$ is the Golden Mean, we further refine the construction to
obtain a parallel algorithm on the alphabet $\{-1,0,1\}$. This alphabet cannot
be reduced any more.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5688</identifier>
 <datestamp>2011-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5688</id><created>2011-02-28</created><authors><author><keyname>Liyakathunisa</keyname></author><author><keyname>Kumar</keyname><forenames>C. N . Ravi</forenames></author></authors><title>A novel super resolution reconstruction of low reoslution images
  progressively using dct and zonal filter based denoising</title><categories>cs.CV</categories><comments>20 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to the factors like processing power limitations and channel capabilities
images are often down sampled and transmitted at low bit rates resulting in a
low resolution compressed image. High resolution images can be reconstructed
from several blurred, noisy and down sampled low resolution images using a
computational process know as super resolution reconstruction. Super-resolution
is the process of combining multiple aliased low-quality images to produce a
high resolution, high-quality image. The problem of recovering a high
resolution image progressively from a sequence of low resolution compressed
images is considered. In this paper we propose a novel DCT based progressive
image display algorithm by stressing on the encoding and decoding process. At
the encoder we consider a set of low resolution images which are corrupted by
additive white Gaussian noise and motion blur. The low resolution images are
compressed using 8 by 8 blocks DCT and noise is filtered using our proposed
novel zonal filter. Multiframe fusion is performed in order to obtain a single
noise free image. At the decoder the image is reconstructed progressively by
transmitting the coarser image first followed by the detail image. And finally
a super resolution image is reconstructed by applying our proposed novel
adaptive interpolation technique. We have performed both objective and
subjective analysis of the reconstructed image, and the resultant image has
better super resolution factor, and a higher ISNR and PSNR. A comparative study
done with Iterative Back Projection (IBP) and Projection on to Convex Sets
(POCS),Papoulis Grechberg, FFT based Super resolution Reconstruction shows that
our method has out performed the previous contributions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5689</identifier>
 <datestamp>2011-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5689</id><created>2011-02-28</created><updated>2011-10-19</updated><authors><author><keyname>Chiu</keyname><forenames>Jiawei</forenames></author><author><keyname>Demanet</keyname><forenames>Laurent</forenames></author></authors><title>Matrix probing and its conditioning</title><categories>math.NA cs.NA math.PR math.ST stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When a matrix A with n columns is known to be well approximated by a linear
combination of basis matrices B_1,..., B_p, we can apply A to a random vector
and solve a linear system to recover this linear combination. The same
technique can be used to recover an approximation to A^-1. A basic question is
whether this linear system is invertible and well-conditioned. In this paper,
we show that if the Gram matrix of the B_j's is sufficiently well-conditioned
and each B_j has a high numerical rank, then n {proportional} p log^2 n will
ensure that the linear system is well-conditioned with high probability. Our
main application is probing linear operators with smooth pseudodifferential
symbols such as the wave equation Hessian in seismic imaging. We demonstrate
numerically that matrix probing can also produce good preconditioners for
inverting elliptic operators in variable media.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5699</identifier>
 <datestamp>2011-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5699</id><created>2011-02-28</created><authors><author><keyname>Garg</keyname><forenames>Rachit Mohan</forenames></author><author><keyname>Sood</keyname><forenames>Yamini</forenames></author><author><keyname>Tyagi</keyname><forenames>Neha</forenames></author></authors><title>Ontology based approach for video transmission over the network</title><categories>cs.MM cs.NI</categories><comments>7 pages, 2 figures, 4 tables</comments><journal-ref>The International journal of Multimedia &amp; Its Applications (IJMA)
  Vol.3, No.1, February 2011</journal-ref><doi>10.5121/ijma.2011.3106</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the increase in the bandwidth &amp; the transmission speed over the
internet, transmission of multimedia objects like video, audio, images has
become an easier work. In this paper we provide an approach that can be useful
for transmission of video objects over the internet without much fuzz. The
approach provides a ontology based framework that is used to establish an
automatic deployment of video transmission system. Further the video is
compressed using the structural flow mechanism that uses the wavelet principle
for compression of video frames. Finally the video transmission algorithm known
as RRDBFSF algorithm is provided that makes use of the concept of restrictive
flooding to avoid redundancy thereby increasing the efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5711</identifier>
 <datestamp>2011-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5711</id><created>2011-02-28</created><authors><author><keyname>Mottelet</keyname><forenames>St&#xe9;phane</forenames></author><author><keyname>Pauss</keyname><forenames>Andr&#xe9;</forenames></author></authors><title>XMLlab : multimedia publication of simulations applets using XML and
  Scilab</title><categories>cs.MS</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We present an XML-based simulation authoring environment. The proposed
description language allows to describe mathematical objects such as systems of
ordinary differential equations, partial differential equations in two
dimensions, or simple curves and surfaces. It also allows to describe the
parameters on which these objects depend. This language is independent of the
target software and allows to ensure the perennity of author's work, as well as
collaborative work and content reuse. The actual implementation of XMLlab
allows to run the generated simulations within the open source mathematical
software Scilab, either locally when Scilab is installed on the client
machines, or on thin clients running a simple web browser, when XMLlab and
Scilab are installed on a distant server running a standard HTTP server.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5713</identifier>
 <datestamp>2011-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5713</id><created>2011-02-28</created><updated>2011-08-09</updated><authors><author><keyname>Combes</keyname><forenames>Joshua</forenames></author><author><keyname>Wiseman</keyname><forenames>Howard M.</forenames></author></authors><title>Quantum feedback for rapid state preparation in the presence of control
  imperfections</title><categories>quant-ph cs.SY math.OC</categories><comments>15 pages, 6 figures and 2 tables. V2 the published version, fig. 1
  corrected and some minor changes to the text</comments><journal-ref>J. Phys. B At. Mol. Opt. Phys. 44, 154008 (2011)</journal-ref><doi>10.1088/0953-4075/44/15/154008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantum feedback control protocols can improve the operation of quantum
devices. Here we examine the performance of a purification protocol when there
are imperfections in the controls. The ideal feedback protocol produces an $x$
eigenstate from a mixed state in the minimum time, and is known as rapid state
preparation. The imperfections we examine include time delays in the feedback
loop, finite strength feedback, calibration errors, and inefficient detection.
We analyse these imperfections using the Wiseman-Milburn feedback master
equation and related formalism. We find that the protocol is most sensitive to
time delays in the feedback loop. For systems with slow dynamics, however, our
analysis suggests that inefficient detection would be the bigger problem. We
also show how system imperfections, such as dephasing and damping, can be
included in model via the feedback master equation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5720</identifier>
 <datestamp>2011-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5720</id><created>2011-02-28</created><authors><author><keyname>Pflaum</keyname><forenames>Markus J.</forenames></author><author><keyname>Tuley</keyname><forenames>John</forenames></author></authors><title>Liber Mathematicae: A Web-Based Documentation and Collaboration Project
  for Mathematics</title><categories>math.HO cs.DL</categories><comments>1 page. Presented at the &quot;Workshop on the Future of Mathematics
  Journals,&quot; MSRI, Berkeley, CA (USA) on February 15, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditionally, mathematical knowledge is published in printed media such as
books or journals. With the advent of the Internet, a new method of publication
became available. To date, however, most online mathematical publications do
not employ the full capabilities of the medium. We describe a project to
modernize online mathematics presentation and build a community-focused
environment in which the lines between &quot;author&quot; and &quot;reader&quot; are blurred,
enhancing collaboration and improving publication quality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5724</identifier>
 <datestamp>2011-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5724</id><created>2011-02-28</created><authors><author><keyname>Nazer</keyname><forenames>Bobak</forenames></author><author><keyname>Gastpar</keyname><forenames>Michael</forenames></author></authors><title>Reliable Physical Layer Network Coding</title><categories>cs.IT math.IT</categories><comments>19 pages, 14 figures, survey paper to appear in Proceedings of the
  IEEE</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When two or more users in a wireless network transmit simultaneously, their
electromagnetic signals are linearly superimposed on the channel. As a result,
a receiver that is interested in one of these signals sees the others as
unwanted interference. This property of the wireless medium is typically viewed
as a hindrance to reliable communication over a network. However, using a
recently developed coding strategy, interference can in fact be harnessed for
network coding. In a wired network, (linear) network coding refers to each
intermediate node taking its received packets, computing a linear combination
over a finite field, and forwarding the outcome towards the destinations. Then,
given an appropriate set of linear combinations, a destination can solve for
its desired packets. For certain topologies, this strategy can attain
significantly higher throughputs over routing-based strategies. Reliable
physical layer network coding takes this idea one step further: using
judiciously chosen linear error-correcting codes, intermediate nodes in a
wireless network can directly recover linear combinations of the packets from
the observed noisy superpositions of transmitted signals. Starting with some
simple examples, this survey explores the core ideas behind this new technique
and the possibilities it offers for communication over interference-limited
wireless networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5727</identifier>
 <datestamp>2011-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5727</id><created>2011-02-28</created><authors><author><keyname>Drakakis</keyname><forenames>Konstantinos</forenames></author></authors><title>Open problems in Costas arrays</title><categories>math.CO cs.DM</categories><comments>24 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A collection of open problems in Costas arrays is presented, classified into
several categories, along with the context in which they arise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5728</identifier>
 <datestamp>2011-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5728</id><created>2011-02-28</created><authors><author><keyname>Karaa</keyname><forenames>Wahiba Ben Abdessalem</forenames></author></authors><title>Named Entity Recognition Using Web Document Corpus</title><categories>cs.IR cs.LG</categories><comments>11 pages 4 figures, 2 tables</comments><msc-class>68T50, 68T05</msc-class><acm-class>H.3.3; I.2.7; I.2.6</acm-class><journal-ref>International Journal of Managing Information Technology (IJMIT)
  Vol.3, No.1, February 2011</journal-ref><doi>10.5121/ijmit.2011.3104</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a named entity recognition approach in textual corpus.
This Named Entity (NE) can be a named: location, person, organization, date,
time, etc., characterized by instances. A NE is found in texts accompanied by
contexts: words that are left or right of the NE. The work mainly aims at
identifying contexts inducing the NE's nature. As such, The occurrence of the
word &quot;President&quot; in a text, means that this word or context may be followed by
the name of a president as President &quot;Obama&quot;. Likewise, a word preceded by the
string &quot;footballer&quot; induces that this is the name of a footballer. NE
recognition may be viewed as a classification method, where every word is
assigned to a NE class, regarding the context. The aim of this study is then to
identify and classify the contexts that are most relevant to recognize a NE,
those which are frequently found with the NE. A learning approach using
training corpus: web documents, constructed from learning examples is then
suggested. Frequency representations and modified tf-idf representations are
used to calculate the context weights associated to context frequency, learning
example frequency, and document frequency in the corpus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5739</identifier>
 <datestamp>2013-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5739</id><created>2011-02-28</created><updated>2013-06-03</updated><authors><author><keyname>Banaei</keyname><forenames>Armin</forenames></author><author><keyname>Cline</keyname><forenames>Daren B. H.</forenames></author><author><keyname>Georghiades</keyname><forenames>Costas N.</forenames></author><author><keyname>Cui</keyname><forenames>Shuguang</forenames></author></authors><title>On the Random 1/2-Disk Routing Scheme in Wireless Ad Hoc Networks</title><categories>cs.NI</categories><comments>This paper has been withdrawn by the author and is replaced by an
  updated version under a new title: &quot;On Asymptotic Statistics for Geometric
  Routing Schemes in Wireless Ad-Hoc Networks&quot;</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Random 1/2-disk routing in wireless ad-hoc networks is a localized geometric
routing scheme in which each node chooses the next relay randomly among the
nodes within its transmission range and in the general direction of the
destination. We introduce a notion of convergence for geometric routing schemes
that not only considers the feasibility of packet delivery through possibly
multi-hop relaying, but also requires the packet delivery to occur in a finite
number of hops. We derive sufficient conditions that ensure the asymptotic
\emph{convergence} of the random 1/2-disk routing scheme based on this
convergence notion, and by modeling the packet distance evolution to the
destination as a Markov process, we derive bounds on the expected number of
hops that each packet traverses to reach its destination.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5750</identifier>
 <datestamp>2011-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5750</id><created>2011-02-28</created><authors><author><keyname>Rigollet</keyname><forenames>Philippe</forenames></author><author><keyname>Tong</keyname><forenames>Xin</forenames></author></authors><title>Neyman-Pearson classification, convexity and stochastic constraints</title><categories>stat.ML cs.LG math.ST stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by problems of anomaly detection, this paper implements the
Neyman-Pearson paradigm to deal with asymmetric errors in binary classification
with a convex loss. Given a finite collection of classifiers, we combine them
and obtain a new classifier that satisfies simultaneously the two following
properties with high probability: (i) its probability of type I error is below
a pre-specified level and (ii), it has probability of type II error close to
the minimum possible. The proposed classifier is obtained by solving an
optimization problem with an empirical objective and an empirical constraint.
New techniques to handle such problems are developed and have consequences on
chance constrained programming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5755</identifier>
 <datestamp>2012-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5755</id><created>2011-02-28</created><updated>2011-06-01</updated><authors><author><keyname>Al-Bashabsheh</keyname><forenames>Ali</forenames></author><author><keyname>Mao</keyname><forenames>Yongyi</forenames></author><author><keyname>Vontobel</keyname><forenames>Pascal O.</forenames></author></authors><title>Normal Factor Graphs: A Diagrammatic Approach to Linear Algebra</title><categories>cs.IT math.IT</categories><comments>ISIT2011, Saint-Petersburg, Russia</comments><doi>10.1109/ISIT.2011.6033944</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inspired by some new advances on normal factor graphs (NFGs), we introduce
NFGs as a simple and intuitive diagrammatic approach towards encoding some
concepts from linear algebra. We illustrate with examples the workings of such
an approach and settle a conjecture of Peterson on the Pfaffian.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5757</identifier>
 <datestamp>2011-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5757</id><created>2011-02-28</created><authors><author><keyname>Choudhary</keyname><forenames>Amit</forenames></author><author><keyname>Rishi</keyname><forenames>Rahul</forenames></author></authors><title>Improving the character recognition efficiency of feed forward BP neural
  network</title><categories>cs.NE</categories><comments>12 Pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work is focused on improving the character recognition capability of
feed-forward back-propagation neural network by using one, two and three hidden
layers and the modified additional momentum term. 182 English letters were
collected for this work and the equivalent binary matrix form of these
characters was applied to the neural network as training patterns. While the
network was getting trained, the connection weights were modified at each epoch
of learning. For each training sample, the error surface was examined for
minima by computing the gradient descent. We started the experiment by using
one hidden layer and the number of hidden layers was increased up to three and
it has been observed that accuracy of the network was increased with low mean
square error but at the cost of training time. The recognition accuracy was
improved further when modified additional momentum term was used.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5761</identifier>
 <datestamp>2012-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5761</id><created>2011-02-28</created><updated>2012-05-29</updated><authors><author><keyname>Garban</keyname><forenames>Christophe</forenames></author><author><keyname>Steif</keyname><forenames>Jeffrey E.</forenames></author></authors><title>Lectures on noise sensitivity and percolation</title><categories>math.PR cs.CC cs.DM math-ph math.CA math.MP</categories><comments>151 pages, 29 figures, minor corrections</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The present text provides the lecture notes for the course &quot;noise sensitivity
and percolation&quot; given at the 2010 Clay Summer School in Buzios, Brazil.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5762</identifier>
 <datestamp>2011-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5762</id><created>2011-02-28</created><authors><author><keyname>Giannopoulou</keyname><forenames>Archontia C.</forenames></author><author><keyname>Thilikos</keyname><forenames>Dimitrios M.</forenames></author></authors><title>Optimizing the Graph Minors Weak Structure Theorem</title><categories>math.CO cs.DM</categories><msc-class>05C83</msc-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  One of the major results of [N. Robertson and P. D. Seymour. Graph minors.
XIII. The disjoint paths problem. J. Combin. Theory Ser. B, 63(1):65--110,
1995], also known as the weak structure theorem, revealed the local structure
of graphs excluding some graph as a minor: each such graph $G$ either has small
treewidth or contains the subdivision of a wall that can be arranged
&quot;bidimensionally&quot; inside $G$, given that some small set of vertices are
removed. We prove an optimized version of that theorem where (i) the relation
between the treewidth of the graph and the height of the wall is linear (thus
best possible) and (ii) the number of vertices to be removed is minimized.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5769</identifier>
 <datestamp>2011-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.5769</id><created>2011-02-28</created><authors><author><keyname>Yu</keyname><forenames>Chien</forenames></author><author><keyname>Brandenburg</keyname><forenames>Teri</forenames></author></authors><title>Multimedia Database Applications: Issues and Concerns for Classroom
  Teaching</title><categories>cs.MM</categories><comments>9 pages and 22 references</comments><journal-ref>The International Journal of Multimedia &amp; Its Applications, 3(1),
  2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The abundance of multimedia data and information is challenging educators to
effectively search, browse, access, use, and store the data for their classroom
teaching. However, many educators could still be accustomed to teaching or
searching for information using conventional methods, but often the
conventional methods may not function well with multimedia data. Educators need
to efficiently interact and manage a variety of digital media files too. The
purpose of this study is to review current multimedia database applications in
teaching and learning, and further discuss some of the issues or concerns that
educators may have while incorporating multimedia data into their classrooms.
Some strategies and recommendations are also provided in order for educators to
be able to use multimedia data more effectively in their teaching environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0021</identifier>
 <datestamp>2011-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0021</id><created>2011-02-28</created><updated>2011-07-16</updated><authors><author><keyname>Pershin</keyname><forenames>Yuriy V.</forenames></author><author><keyname>Di Ventra</keyname><forenames>Massimiliano</forenames></author></authors><title>Solving mazes with memristors: a massively-parallel approach</title><categories>cond-mat.mes-hall cs.ET physics.comp-ph</categories><journal-ref>Phys. Rev. E 84, 046703 (2011)</journal-ref><doi>10.1103/PhysRevE.84.046703</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Solving mazes is not just a fun pastime. Mazes are prototype models in graph
theory, topology, robotics, traffic optimization, psychology, and in many other
areas of science and technology. However, when maze complexity increases their
solution becomes cumbersome and very time consuming. Here, we show that a
network of memristors - resistors with memory - can solve such a non-trivial
problem quite easily. In particular, maze solving by the network of memristors
occurs in a massively parallel fashion since all memristors in the network
participate simultaneously in the calculation. The result of the calculation is
then recorded into the memristors' states, and can be used and/or recovered at
a later time. Furthermore, the network of memristors finds all possible
solutions in multiple-solution mazes, and sorts out the solution paths
according to their length. Our results demonstrate not only the first
application of memristive networks to the field of massively-parallel
computing, but also a novel algorithm to solve mazes which could find
applications in different research fields.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0038</identifier>
 <datestamp>2011-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0038</id><created>2011-02-28</created><updated>2011-03-28</updated><authors><author><keyname>Zhao</keyname><forenames>Yue</forenames></author><author><keyname>Tan</keyname><forenames>Chee Wei</forenames></author><author><keyname>Avestimehr</keyname><forenames>A. Salman</forenames></author><author><keyname>Diggavi</keyname><forenames>Suhas N.</forenames></author><author><keyname>Pottie</keyname><forenames>Gregory J.</forenames></author></authors><title>On the Sum-Capacity with Successive Decoding in Interference Channels</title><categories>cs.IT math.IT</categories><comments>32 pages, 21 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate the sum-capacity of the two-user Gaussian
interference channel with Gaussian superposition coding and successive
decoding. We first examine an approximate deterministic formulation of the
problem, and introduce the complementarity conditions that capture the use of
Gaussian coding and successive decoding. In the deterministic channel problem,
we find the constrained sum-capacity and its achievable schemes with the
minimum number of messages, first in symmetric channels, and then in general
asymmetric channels. We show that the constrained sum-capacity oscillates as a
function of the cross link gain parameters between the information theoretic
sum-capacity and the sum-capacity with interference treated as noise.
Furthermore, we show that if the number of messages of either of the two users
is fewer than the minimum number required to achieve the constrained
sum-capacity, the maximum achievable sum-rate drops to that with interference
treated as noise. We provide two algorithms (a simple one and a finer one) to
translate the optimal schemes in the deterministic channel model to the
Gaussian channel model. We also derive two upper bounds on the sum-capacity of
the Gaussian Han-Kobayashi schemes, which automatically upper bound the
sum-capacity using successive decoding of Gaussian codewords. Numerical
evaluations show that, similar to the deterministic channel results, the
constrained sum-capacity in the Gaussian channels oscillates between the
sum-capacity with Han-Kobayashi schemes and that with single message schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0040</identifier>
 <datestamp>2011-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0040</id><created>2011-02-28</created><updated>2011-04-16</updated><authors><author><keyname>Dughmi</keyname><forenames>Shaddin</forenames></author><author><keyname>Roughgarden</keyname><forenames>Tim</forenames></author><author><keyname>Yan</keyname><forenames>Qiqi</forenames></author></authors><title>From Convex Optimization to Randomized Mechanisms: Toward Optimal
  Combinatorial Auctions</title><categories>cs.GT cs.DS</categories><comments>Extended abstract appears in Proceedings of the 43rd ACM Symposium on
  Theory of Computing (STOC), 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We design an expected polynomial-time, truthful-in-expectation,
(1-1/e)-approximation mechanism for welfare maximization in a fundamental class
of combinatorial auctions. Our results apply to bidders with valuations that
are m matroid rank sums (MRS), which encompass most concrete examples of
submodular functions studied in this context, including coverage functions,
matroid weighted-rank functions, and convex combinations thereof. Our
approximation factor is the best possible, even for known and explicitly given
coverage valuations, assuming P != NP. Ours is the first
truthful-in-expectation and polynomial-time mechanism to achieve a
constant-factor approximation for an NP-hard welfare maximization problem in
combinatorial auctions with heterogeneous goods and restricted valuations.
  Our mechanism is an instantiation of a new framework for designing
approximation mechanisms based on randomized rounding algorithms. A typical
such algorithm first optimizes over a fractional relaxation of the original
problem, and then randomly rounds the fractional solution to an integral one.
With rare exceptions, such algorithms cannot be converted into truthful
mechanisms. The high-level idea of our mechanism design framework is to
optimize directly over the (random) output of the rounding algorithm, rather
than over the input to the rounding algorithm. This approach leads to
truthful-in-expectation mechanisms, and these mechanisms can be implemented
efficiently when the corresponding objective function is concave. For bidders
with MRS valuations, we give a novel randomized rounding algorithm that leads
to both a concave objective function and a (1-1/e)-approximation of the optimal
welfare.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0041</identifier>
 <datestamp>2011-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0041</id><created>2011-02-28</created><updated>2011-04-16</updated><authors><author><keyname>Dughmi</keyname><forenames>Shaddin</forenames></author></authors><title>A Truthful Randomized Mechanism for Combinatorial Public Projects via
  Convex Optimization</title><categories>cs.GT cs.DS</categories><comments>Extended abstract appears in Proceedings of the 12th ACM Conference
  on Electronic Commerce (EC), 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Combinatorial Public Projects, there is a set of projects that may be
undertaken, and a set of self-interested players with a stake in the set of
projects chosen. A public planner must choose a subset of these projects,
subject to a resource constraint, with the goal of maximizing social welfare.
Combinatorial Public Projects has emerged as one of the paradigmatic problems
in Algorithmic Mechanism Design, a field concerned with solving fundamental
resource allocation problems in the presence of both selfish behavior and the
computational constraint of polynomial-time.
  We design a polynomial-time, truthful-in-expectation, (1-1/e)-approximation
mechanism for welfare maximization in a fundamental variant of combinatorial
public projects. Our results apply to combinatorial public projects when
players have valuations that are matroid rank sums (MRS), which encompass most
concrete examples of submodular functions studied in this context, including
coverage functions, matroid weighted-rank functions, and convex combinations
thereof. Our approximation factor is the best possible, assuming P != NP. Ours
is the first mechanism that achieves a constant factor approximation for a
natural NP-hard variant of combinatorial public projects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0045</identifier>
 <datestamp>2011-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0045</id><created>2011-02-28</created><authors><author><keyname>Pal</keyname><forenames>Ranjan</forenames></author><author><keyname>Hui</keyname><forenames>Pan</forenames></author></authors><title>On the Economics of Cloud Markets</title><categories>cs.NI cs.GT</categories><comments>7 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cloud computing is a paradigm that has the potential to transform and
revolutionalize the next generation IT industry by making software available to
end-users as a service. A cloud, also commonly known as a cloud network,
typically comprises of hardware (network of servers) and a collection of
softwares that is made available to end-users in a pay-as-you-go manner.
Multiple public cloud providers (ex., Amazon) co-existing in a cloud computing
market provide similar services (software as a service) to its clients, both in
terms of the nature of an application, as well as in quality of service (QoS)
provision. The decision of whether a cloud hosts (or finds it pro?table to
host) a service in the long-term would depend jointly on the price it sets, the
QoS guarantees it provides to its customers, and the satisfaction of the
advertised guarantees. In this paper, we devise and analyze three
inter-organizational economic models relevant to cloud networks. We formulate
our problems as non co-operative price and QoS games between multiple cloud
providers existing in a cloud market. We prove that a unique pure strategy Nash
equilibrium (NE) exists in two of the three models. Our analysis paves the path
for each cloud provider to 1) know what prices and QoS level to set for
end-users of a given service type, such that the provider could exist in the
cloud market, and 2) practically and dynamically provision appropriate capacity
for satisfying advertised QoS guarantees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0048</identifier>
 <datestamp>2011-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0048</id><created>2011-02-28</created><authors><author><keyname>Jia</keyname><forenames>Tao</forenames></author><author><keyname>Kulkarni</keyname><forenames>Rahul V.</forenames></author></authors><title>On the structural properties of small-world networks with finite range
  of shortcut links</title><categories>physics.soc-ph cond-mat.dis-nn cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We explore a new variant of Small-World Networks (SWNs), in which an
additional parameter ($r$) sets the length scale over which shortcuts are
uniformly distributed. When $r=0$ we have an ordered network, whereas $r=1$
corresponds to the original SWN model. These short-range SWNs have a similar
degree distribution and scaling properties as the original SWN model. We
observe the small-world phenomenon for $r \ll 1$ indicating that global
shortcuts are not necessary for the small-world effect. For short-range SWNs,
the average path length changes nonmonotonically with system size, whereas for
the original SWN model it increases monotonically. We propose an expression for
the average path length for short-range SWNs based on numerical simulations and
analytical approximations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0056</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0056</id><created>2011-02-28</created><updated>2011-06-14</updated><authors><author><keyname>Payne</keyname><forenames>Joshua L.</forenames></author><author><keyname>Harris</keyname><forenames>Kameron Decker</forenames></author><author><keyname>Dodds</keyname><forenames>Peter Sheridan</forenames></author></authors><title>Exact solutions for social and biological contagion models on mixed
  directed and undirected, degree-correlated random networks</title><categories>physics.soc-ph cond-mat.dis-nn cs.SI</categories><comments>10 pages, 3 figures</comments><doi>10.1103/PhysRevE.84.016110</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We derive analytic expressions for the possibility, probability, and expected
size of global spreading events starting from a single infected seed for a
broad collection of contagion processes acting on random networks with both
directed and undirected edges and arbitrary degree-degree correlations. Our
work extends previous theoretical developments for the undirected case, and we
provide numerical support for our findings by investigating an example class of
networks for which we are able to obtain closed-form expressions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0065</identifier>
 <datestamp>2011-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0065</id><created>2011-02-28</created><authors><author><keyname>Bai</keyname><forenames>Xin</forenames></author><author><keyname>Fusco</keyname><forenames>Dana</forenames></author></authors><title>Interdisciplinary Collaboration through Designing 3D Simulation Case
  Studies</title><categories>cs.MM</categories><doi>10.5121/ijma.2011.3109</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interdisciplinary collaboration is essential for the advance of research. As
domain subjects become more and more specialized, researchers need to cross
disciplines for insights from peers in other areas to have a broader and deeper
understand of a topic at micro- and macro-levels. We developed a 3D virtual
learning environment that served as a platform for faculty to plan curriculum,
share educational beliefs, and conduct cross-discipline research for effective
learning. Based upon the scripts designed by faculty from five disciplines,
virtual doctors, nurses, or patients interact in a 3D virtual hospital. The
teaching vignettes were then converted to video clips, allowing users to view,
pause, replay, or comment on the videos individually or in groups. Unlike many
existing platforms, we anticipated a value-added by adding a social networking
capacity to this virtual environment. The focus of this paper is on the
cost-efficiency and system design of the virtual learning environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0066</identifier>
 <datestamp>2014-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0066</id><created>2011-02-28</created><authors><author><keyname>Knepley</keyname><forenames>Matthew G.</forenames></author><author><keyname>Terrel</keyname><forenames>Andy R.</forenames></author></authors><title>Finite Element Integration on GPUs</title><categories>cs.MS math.NA</categories><comments>16 pages, 3 figures</comments><acm-class>G.4; G.1.8</acm-class><journal-ref>ACM Transactions on Mathematical Software, 39(2), 2013</journal-ref><doi>10.1145/2427023.2427027</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel finite element integration method for low order elements
on GPUs. We achieve more than 100GF for element integration on first order
discretizations of both the Laplacian and Elasticity operators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0083</identifier>
 <datestamp>2011-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0083</id><created>2011-03-01</created><authors><author><keyname>Chueh</keyname><forenames>Hao-En</forenames></author></authors><title>Mining Target-Oriented Fuzzy Correlation Rules to Optimize Telecom
  Service Management</title><categories>cs.DB</categories><comments>10 pages, 7 tables</comments><journal-ref>International Journal of Computer Science &amp; Information Technology
  (IJCSIT), Vol 3, No 1, Feb 2011, PP.74-83</journal-ref><doi>10.5121/ijcsit.2011.3106</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To optimize telecom service management, it is necessary that information
about telecom services is highly related to the most popular telecom service.
To this end, we propose an algorithm for mining target-oriented fuzzy
correlation rules. In this paper, we show that by using the fuzzy statistics
analysis and the data mining technology, the target-oriented fuzzy correlation
rules can be obtained from a given database. We conduct an experiment by using
a sample database from a telecom service provider in Taiwan. Our work can be
used to assist the telecom service provider in providing the appropriate
services to the customers for better customer relationship management.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0086</identifier>
 <datestamp>2011-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0086</id><created>2011-03-01</created><authors><author><keyname>Liu</keyname><forenames>Xin</forenames></author><author><keyname>Tredan</keyname><forenames>Gilles</forenames></author><author><keyname>Datta</keyname><forenames>Anwitaman</forenames></author></authors><title>A generic trust framework for large-scale open systems using machine
  learning</title><categories>cs.DC cs.CR cs.LG</categories><comments>30 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many large scale distributed systems and on the web, agents need to
interact with other unknown agents to carry out some tasks or transactions. The
ability to reason about and assess the potential risks in carrying out such
transactions is essential for providing a safe and reliable environment. A
traditional approach to reason about the trustworthiness of a transaction is to
determine the trustworthiness of the specific agent involved, derived from the
history of its behavior. As a departure from such traditional trust models, we
propose a generic, machine learning approach based trust framework where an
agent uses its own previous transactions (with other agents) to build a
knowledge base, and utilize this to assess the trustworthiness of a transaction
based on associated features, which are capable of distinguishing successful
transactions from unsuccessful ones. These features are harnessed using
appropriate machine learning algorithms to extract relationships between the
potential transaction and previous transactions. The trace driven experiments
using real auction dataset show that this approach provides good accuracy and
is highly efficient compared to other trust mechanisms, especially when
historical information of the specific agent is rare, incomplete or inaccurate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0087</identifier>
 <datestamp>2011-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0087</id><created>2011-03-01</created><authors><author><keyname>Ephzibah</keyname><forenames>E. P.</forenames></author></authors><title>Cost effective approach on feature selection using genetic algorithms
  and fuzzy logic for diabetes diagnosis</title><categories>cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A way to enhance the performance of a model that combines genetic algorithms
and fuzzy logic for feature selection and classification is proposed. Early
diagnosis of any disease with less cost is preferable. Diabetes is one such
disease. Diabetes has become the fourth leading cause of death in developed
countries and there is substantial evidence that it is reaching epidemic
proportions in many developing and newly industrialized nations. In medical
diagnosis, patterns consist of observable symptoms along with the results of
diagnostic tests. These tests have various associated costs and risks. In the
automated design of pattern classification, the proposed system solves the
feature subset selection problem. It is a task of identifying and selecting a
useful subset of pattern-representing features from a larger set of features.
Using fuzzy rule-based classification system, the proposed system proves to
improve the classification accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0089</identifier>
 <datestamp>2011-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0089</id><created>2011-03-01</created><authors><author><keyname>Choudhuri</keyname><forenames>Chiranjib</forenames></author><author><keyname>Mitra</keyname><forenames>Urbashi</forenames></author></authors><title>Capacity Bounds for Relay Channels with Inter-symbol Interference and
  Colored Gaussian Noise</title><categories>cs.IT math.IT</categories><comments>42 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The capacity of a relay channel with inter-symbol interference (ISI) and
additive colored Gaussian noise is examined under an input power constraint.
Prior results are used to show that the capacity of this channel can be
computed by examining the circular degraded relay channel in the limit of
infinite block length. The current work provides single letter expressions for
the achievable rates with decodeand- forward (DF) and compress-and-forward (CF)
processing employed at the relay. Additionally, the cut-set bound for the relay
channel is generalized for the ISI/colored Gaussian noise scenario. All results
hinge on showing the optimality of the decomposition of the relay channel with
ISI/colored Gaussian noise into an equivalent collection of coupled parallel,
scalar, memoryless relay channels. The region of optimality of the DF and CF
achievable rates are also discussed. Optimal power allocation strategies are
also discussed for the two lower bounds and the cut-set upper bound. As the
maximizing power allocations for DF and CF appear to be intractable, the
desired cost functions are modified and then optimized. The resulting rates are
illustrated through the computation of numerical examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0102</identifier>
 <datestamp>2011-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0102</id><created>2011-03-01</created><updated>2011-03-02</updated><authors><author><keyname>Zhou</keyname><forenames>Tianyi</forenames></author><author><keyname>Tao</keyname><forenames>Dacheng</forenames></author></authors><title>Multi-label Learning via Structured Decomposition and Group Sparsity</title><categories>cs.LG stat.ML</categories><comments>13 pages, 3 tables</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In multi-label learning, each sample is associated with several labels.
Existing works indicate that exploring correlations between labels improve the
prediction performance. However, embedding the label correlations into the
training process significantly increases the problem size. Moreover, the
mapping of the label structure in the feature space is not clear. In this
paper, we propose a novel multi-label learning method &quot;Structured Decomposition
+ Group Sparsity (SDGS)&quot;. In SDGS, we learn a feature subspace for each label
from the structured decomposition of the training data, and predict the labels
of a new sample from its group sparse representation on the multi-subspace
obtained from the structured decomposition. In particular, in the training
stage, we decompose the data matrix $X\in R^{n\times p}$ as
$X=\sum_{i=1}^kL^i+S$, wherein the rows of $L^i$ associated with samples that
belong to label $i$ are nonzero and consist a low-rank matrix, while the other
rows are all-zeros, the residual $S$ is a sparse matrix. The row space of $L_i$
is the feature subspace corresponding to label $i$. This decomposition can be
efficiently obtained via randomized optimization. In the prediction stage, we
estimate the group sparse representation of a new sample on the multi-subspace
via group \emph{lasso}. The nonzero representation coefficients tend to
concentrate on the subspaces of labels that the sample belongs to, and thus an
effective prediction can be obtained. We evaluate SDGS on several real datasets
and compare it with popular methods. Results verify the effectiveness and
efficiency of SDGS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0106</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0106</id><created>2011-03-01</created><authors><author><keyname>Kayaaslan</keyname><forenames>Enver</forenames></author><author><keyname>Pinar</keyname><forenames>Ali</forenames></author><author><keyname>Catalyurek</keyname><forenames>Umit V.</forenames></author><author><keyname>Aykanat</keyname><forenames>Cevdet</forenames></author></authors><title>Hypergraph Partitioning through Vertex Separators on Graphs</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The modeling flexibility provided by hypergraphs has drawn a lot of interest
from the combinatorial scientific community, leading to novel models and
algorithms, their applications, and development of associated tools.
Hypergraphs are now a standard tool in combinatorial scientific computing. The
modeling flexibility of hypergraphs however, comes at a cost: algorithms on
hypergraphs are inherently more complicated than those on graphs, which
sometimes translate to nontrivial increases in processing times. Neither the
modeling flexibility of hypergraphs, nor the runtime efficiency of graph
algorithms can be overlooked. Therefore, the new research thrust should be how
to cleverly trade-off between the two. This work addresses one method for this
trade-off by solving the hypergraph partitioning problem by finding vertex
separators on graphs. Specifically, we investigate how to solve the hypergraph
partitioning problem by seeking a vertex separator on its net intersection
graph (NIG), where each net of the hypergraph is represented by a vertex, and
two vertices share an edge if their nets have a common vertex. We propose a
vertex-weighting scheme to attain good node-balanced hypergraphs, since NIG
model cannot preserve node balancing information. Vertex-removal and
vertex-splitting techniques are described to optimize cutnet and connectivity
metrics, respectively, under the recursive bipartitioning paradigm. We also
developed an implementation for our GPVS-based HP formulations by adopting and
modifying a state-of-the-art GPVS tool onmetis. Experiments conducted on a
large collection of sparse matrices confirmed the validity of our proposed
techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0116</identifier>
 <datestamp>2011-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0116</id><created>2011-03-01</created><authors><author><keyname>Koutsiamanis</keyname><forenames>Remous-Aris</forenames></author><author><keyname>Efraimidis</keyname><forenames>Pavlos S.</forenames></author></authors><title>An exact and O(1) time heaviest and lightest hitters algorithm for
  sliding-window data streams</title><categories>cs.DS cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we focus on the problem of finding the heaviest-k and lightest-k
hitters in a sliding window data stream. The most recent research endeavours
have yielded an epsilon-approximate algorithm with update operations in
constant time with high probability and O(1/epsilon) query time for the
heaviest hitters case. We propose a novel algorithm which for the first time,
to our knowledge, provides exact, not approximate, results while at the same
time achieves O(1) time with high probability complexity on both update and
query operations. Furthermore, our algorithm is able to provide both the
heaviest-k and the lightest-k hitters at the same time without any overhead. In
this work, we describe the algorithm and the accompanying data structure that
supports it and perform quantitative experiments with synthetic data to verify
our theoretical predictions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0120</identifier>
 <datestamp>2011-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0120</id><created>2011-03-01</created><updated>2011-04-03</updated><authors><author><keyname>Kundu</keyname><forenames>Srimanta</forenames></author><author><keyname>Das</keyname><forenames>Nibaran</forenames></author><author><keyname>Nasipuri</keyname><forenames>Mita</forenames></author></authors><title>Automatic Detection of Ringworm using Local Binary Pattern (LBP)</title><categories>cs.CV</categories><comments>International Symposium on Medical Imaging: Perspectives on
  Perception and Diagnostics (MED-IMAGE 2010) organized in conjunction with the
  Seventh Indian Conference on Computer Vision, Graphics and Image Processing
  (ICVGIP), 9-10th December, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a novel approach for automatic recognition of ring
worm skin disease based on LBP (Local Binary Pattern) feature extracted from
the affected skin images. The proposed method is evaluated by extensive
experiments on the skin images collected from internet. The dataset is tested
using three different classifiers i.e. Bayesian, MLP and SVM. Experimental
results show that the proposed methodology efficiently discriminates between a
ring worm skin and a normal skin. It is a low cost technique and does not
require any special imaging devices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0125</identifier>
 <datestamp>2011-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0125</id><created>2011-03-01</created><authors><author><keyname>Maragathavalli</keyname><forenames>P.</forenames></author></authors><title>Search-based software test data generation using evolutionary
  computation</title><categories>cs.SE</categories><comments>11, 3</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Search-based Software Engineering has been utilized for a number of software
engineering activities. One area where Search-Based Software Engineering has
seen much application is test data generation. Evolutionary testing designates
the use of metaheuristic search methods for test case generation. The search
space is the input domain of the test object, with each individual or potential
solution, being an encoded set of inputs to that test object. The fitness
function is tailored to find test data for the type of test that is being
undertaken. Evolutionary Testing (ET) uses optimizing search techniques such as
evolutionary algorithms to generate test data. The effectiveness of GA-based
testing system is compared with a Random testing system. For simple programs
both testing systems work fine, but as the complexity of the program or the
complexity of input domain grows, GA-based testing system significantly
outperforms Random testing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0127</identifier>
 <datestamp>2011-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0127</id><created>2011-03-01</created><authors><author><keyname>Shankar</keyname><forenames>Shobha</forenames></author><author><keyname>Ananthapadmanabha</keyname><forenames>Dr. T.</forenames></author></authors><title>Fuzzy Approach to Critical Bus Ranking under Normal and Line Outage
  Contingencies</title><categories>cs.AI</categories><comments>12 pages, 7 figures, CCSIT Conference</comments><journal-ref>Advanced Computing, CCSIT Proceedings, Part III, pp. 400-406, Jan
  2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Identification of critical or weak buses for a given operating condition is
an important task in the load dispatch centre. It has become more vital in view
of the threat of voltage instability leading to voltage collapse. This paper
presents a fuzzy approach for ranking critical buses in a power system under
normal and network contingencies based on Line Flow index and voltage profiles
at load buses. The Line Flow index determines the maximum load that is possible
to be connected to a bus in order to maintain stability before the system
reaches its bifurcation point. Line Flow index (LF index) along with voltage
profiles at the load buses are represented in Fuzzy Set notation. Further they
are evaluated using fuzzy rules to compute Criticality Index. Based on this
index, critical buses are ranked. The bus with highest rank is the weakest bus
as it can withstand a small amount of load before causing voltage collapse. The
proposed method is tested on Five Bus Test System.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0133</identifier>
 <datestamp>2012-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0133</id><created>2011-03-01</created><updated>2012-05-04</updated><authors><author><keyname>Ramachandran</keyname><forenames>Santosh</forenames></author><author><keyname>Singh</keyname><forenames>Chandramani</forenames></author><author><keyname>Anand</keyname><forenames>S. V. R.</forenames></author><author><keyname>Hegde</keyname><forenames>Malati</forenames></author><author><keyname>Kumar</keyname><forenames>Anurag</forenames></author><author><keyname>Sundaresan</keyname><forenames>Rajesh</forenames></author></authors><title>Neighbor Oblivious and Finite-State Algorithms for Circumventing Local
  Minima in Geographic Forwarding</title><categories>cs.NI</categories><comments>9 pages; &quot;Neighbor oblivious link reversal over duty-cycled WSNs&quot;</comments><journal-ref>National Conference on Communications (NCC) 2010, Chennai, India,
  Jan. 29-31, 2010, pages 1 - 5</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose distributed link reversal algorithms to circumvent communication
voids in geographic routing. We also solve the attendant problem of integer
overflow in these algorithms. These are achieved in two steps. First, we derive
partial and full link reversal algorithms that do not require one-hop neighbor
information, and convert a destination-disoriented directed acyclic graph (DAG)
to a destination-oriented DAG. We embed these algorithms in the framework of
Gafni and Bertsekas (&quot;Distributed algorithms for generating loop-free routes in
networks with frequently changing topology&quot;, 1981) in order to establish their
termination properties. We also analyze certain key properties exhibited by our
neighbor oblivious link reversal algorithms, e.g., for any two neighbors, their
t-states are always consecutive integers, and for any node, its t-state size is
upper bounded by log(N). In the second step, we resolve the integer overflow
problem by analytically deriving one-bit full link reversal and two-bit partial
link reversal versions of our neighbor oblivious link reversal algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0135</identifier>
 <datestamp>2011-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0135</id><created>2011-03-01</created><updated>2011-08-09</updated><authors><author><keyname>Bjelakovi&#x107;</keyname><forenames>Igor</forenames></author><author><keyname>Boche</keyname><forenames>Holger</forenames></author><author><keyname>Sommerfeld</keyname><forenames>Jochen</forenames></author></authors><title>Capacity results for compound wiretap channels</title><categories>cs.IT math.IT</categories><comments>5 pages, no figures. Accepted for presentation at the IEEE ITW 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We derive a lower bound on the secrecy capacity of the compound wiretap
channel with channel state information at the transmitter which matches the
general upper bound on the secrecy capacity of general compound wiretap
channels given by Liang et al. and thus establishing a full coding theorem in
this case. We achieve this with a quite strong secrecy criterion and with a
decoder that is robust against the effect of randomisation in the encoding.
This relieves us from the need of decoding the randomisation parameter which is
in general not possible within this model. Moreover we prove a lower bound on
the secrecy capacity of the compound wiretap channel without channel state
information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0171</identifier>
 <datestamp>2013-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0171</id><created>2011-03-01</created><updated>2011-09-05</updated><authors><author><keyname>Ingber</keyname><forenames>Amir</forenames></author><author><keyname>Zamir</keyname><forenames>Ram</forenames></author><author><keyname>Feder</keyname><forenames>Meir</forenames></author></authors><title>Finite Dimensional Infinite Constellations</title><categories>cs.IT math.IT</categories><comments>54 pages, 13 figures. Submitted to IEEE Transactions on Information
  Theory</comments><journal-ref>IEEE Trans. on Information Theory, Vol. 59 ,Issue 3, pp.
  1630-1656, 2013</journal-ref><doi>10.1109/TIT.2012.2224145</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the setting of a Gaussian channel without power constraints, proposed by
Poltyrev, the codewords are points in an n-dimensional Euclidean space (an
infinite constellation) and the tradeoff between their density and the error
probability is considered. The capacity in this setting is the highest
achievable normalized log density (NLD) with vanishing error probability. This
capacity as well as error exponent bounds for this setting are known. In this
work we consider the optimal performance achievable in the fixed blocklength
(dimension) regime. We provide two new achievability bounds, and extend the
validity of the sphere bound to finite dimensional infinite constellations. We
also provide asymptotic analysis of the bounds: When the NLD is fixed, we
provide asymptotic expansions for the bounds that are significantly tighter
than the previously known error exponent results. When the error probability is
fixed, we show that as n grows, the gap to capacity is inversely proportional
(up to the first order) to the square-root of n where the proportion constant
is given by the inverse Q-function of the allowed error probability, times the
square root of 1/2. In an analogy to similar result in channel coding, the
dispersion of infinite constellations is 1/2nat^2 per channel use. All our
achievability results use lattices and therefore hold for the maximal error
probability as well. Connections to the error exponent of the power constrained
Gaussian channel and to the volume-to-noise ratio as a figure of merit are
discussed. In addition, we demonstrate the tightness of the results numerically
and compare to state-of-the-art coding schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0172</identifier>
 <datestamp>2011-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0172</id><created>2011-03-01</created><updated>2011-05-05</updated><authors><author><keyname>Bernecker</keyname><forenames>Thomas</forenames></author><author><keyname>Emrich</keyname><forenames>Tobias</forenames></author><author><keyname>Kriegel</keyname><forenames>Hans-Peter</forenames></author><author><keyname>Mamoulis</keyname><forenames>Nikos</forenames></author><author><keyname>Renz</keyname><forenames>Matthias</forenames></author><author><keyname>Zhang</keyname><forenames>Shiming</forenames></author><author><keyname>Z&#xfc;fle</keyname><forenames>Andreas</forenames></author></authors><title>Inverse Queries For Multidimensional Spaces</title><categories>cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditional spatial queries return, for a given query object $q$, all
database objects that satisfy a given predicate, such as epsilon range and
$k$-nearest neighbors. This paper defines and studies {\em inverse} spatial
queries, which, given a subset of database objects $Q$ and a query predicate,
return all objects which, if used as query objects with the predicate, contain
$Q$ in their result. We first show a straightforward solution for answering
inverse spatial queries for any query predicate. Then, we propose a
filter-and-refinement framework that can be used to improve efficiency. We show
how to apply this framework on a variety of inverse queries, using appropriate
space pruning strategies. In particular, we propose solutions for inverse
epsilon range queries, inverse $k$-nearest neighbor queries, and inverse
skyline queries. Our experiments show that our framework is significantly more
efficient than naive approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0205</identifier>
 <datestamp>2011-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0205</id><created>2011-03-01</created><updated>2011-05-30</updated><authors><author><keyname>Asyhari</keyname><forenames>A. Taufiq</forenames></author><author><keyname>Koch</keyname><forenames>Tobias</forenames></author><author><keyname>F&#xe0;bregas</keyname><forenames>Albert Guill&#xe9;n i</forenames></author></authors><title>Nearest Neighbour Decoding and Pilot-Aided Channel Estimation in
  Stationary Gaussian Flat-Fading Channels</title><categories>cs.IT math.IT</categories><comments>5 pages, 1 figure. To be presented at the IEEE International
  Symposium on Information Theory (ISIT), St. Petersburg, Russia, 2011.
  Replaced with version that will appear in the proceedings</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the information rates of non-coherent, stationary, Gaussian,
multiple-input multiple-output (MIMO) flat-fading channels that are achievable
with nearest neighbour decoding and pilot-aided channel estimation. In
particular, we analyse the behaviour of these achievable rates in the limit as
the signal-to-noise ratio (SNR) tends to infinity. We demonstrate that nearest
neighbour decoding and pilot-aided channel estimation achieves the capacity
pre-log - which is defined as the limiting ratio of the capacity to the
logarithm of SNR as the SNR tends to infinity - of non-coherent multiple-input
single-output (MISO) flat-fading channels, and it achieves the best so far
known lower bound on the capacity pre-log of non-coherent MIMO flat-fading
channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0215</identifier>
 <datestamp>2011-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0215</id><created>2011-03-01</created><updated>2011-07-29</updated><authors><author><keyname>Maslov</keyname><forenames>Dmitri</forenames></author><author><keyname>Saeedi</keyname><forenames>Mehdi</forenames></author></authors><title>Reversible Circuit Optimization via Leaving the Boolean Domain</title><categories>quant-ph cs.ET</categories><comments>14 pages, 8 figures</comments><acm-class>B.6; B.6.3</acm-class><journal-ref>IEEE Transactions on Computer-Aided Design of Integrated Circuits
  and Systems 30(6):806-816, 2011</journal-ref><doi>10.1109/TCAD.2011.2105555</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For years, the quantum/reversible circuit community has been convinced that:
a) the addition of auxiliary qubits is instrumental in constructing a smaller
quantum circuit; and, b) the introduction of quantum gates inside reversible
circuits may result in more efficient designs. This paper presents a systematic
approach to optimizing reversible (and quantum) circuits via the introduction
of auxiliary qubits and quantum gates inside circuit designs. This advances our
understanding of what may be achieved with a) and b).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0217</identifier>
 <datestamp>2011-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0217</id><created>2011-03-01</created><authors><author><keyname>Majkic</keyname><forenames>Zoran</forenames></author></authors><title>A New Representation Theorem for Many-valued Modal Logics</title><categories>cs.LO</categories><comments>19 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new definition of the representation theorem for many-valued
logics, with modal operators as well, and define the stronger relationship
between algebraic models of a given logic and relational structures used to
define the Kripke possible-world semantics for it. Such a new framework offers
a new semantics for many-valued logics based on the truth-invariance
entailment. Consequently, it is substantially different from current
definitions based on a matrix with a designated subset of logic values, used
for the satisfaction relation, often difficult to fix. In the case when the
many-valued modal logics are based on the set of truth-values that are complete
distributive lattices we obtain a compact autoreferential Kripke-style
canonical representation. The Kripke-style semantics for this subclass of modal
logics have the joint-irreducible subset of the carrier set of many-valued
algebras as set of possible worlds. A significant member of this subclass is
the paraconsistent fuzzy logic extended by new logic values in order to also
deal with incomplete and inconsistent information. This new theory is applied
for the case of autoepistemic intuitionistic many-valued logic, based on
Belnap's 4-valued bilattice, as a minimal extension of classical logic used to
manage incomplete and inconsistent information as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0220</identifier>
 <datestamp>2011-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0220</id><created>2011-03-01</created><authors><author><keyname>Avanesov</keyname><forenames>Tigran</forenames></author><author><keyname>Chevalier</keyname><forenames>Yannick</forenames></author><author><keyname>Rusinowitch</keyname><forenames>Micha&#xeb;l</forenames></author><author><keyname>Turuani</keyname><forenames>Mathieu</forenames></author></authors><title>Satisfiability of General Intruder Constraints with and without a Set
  Constructor</title><categories>cs.CR</categories><comments>Submitted to the Special issue of Information and Computation on
  Security and Rewriting Techniques (SecReT), 2011. 59 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many decision problems on security protocols can be reduced to solving
so-called intruder constraints in Dolev Yao model. Most constraint solving
procedures for protocol security rely on two properties of constraint systems
called monotonicity and variable origination. In this work we relax these
restrictions by giving a decision procedure for solving general intruder
constraints (that do not have these properties) that stays in NP. Our result
extends a first work by L. Mazar\'e in several directions: we allow non-atomic
keys, and an associative, commutative and idempotent symbol (for modeling
sets). We also discuss several new applications of the results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0248</identifier>
 <datestamp>2011-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0248</id><created>2011-02-24</created><authors><author><keyname>Majkic</keyname><forenames>Zoran</forenames></author></authors><title>DB Category: Denotational Semantics for View-based Database Mappings</title><categories>cs.DB cs.LO math.CT</categories><comments>40 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a categorical denotational semantics for a database mapping, based
on views, in the most general framework of a database integration/exchange.
Developed database category DB, for databases (objects) and view-based mappings
(morphisms) between them, is different from Set category: the morphisms (based
on a set of complex query computations) are not functions, while the objects
are database instances (sets of relations). The logic based schema mappings
between databases, usually written in a highly expressive logical language (ex.
LAV, GAV, GLAV mappings, or tuple generating dependency) may be functorially
translated into this &quot;computation&quot; category DB. A new approach is adopted,
based on the behavioral point of view for databases, and behavioral
equivalences for databases and their mappings are established. By introduction
of view-based observations for databases, which are computations without
side-effects, we define a fundamental (Universal algebra) monad with a
power-view endofunctor T. The resulting 2-category DB is symmetric, so that any
mapping can be represented as an object (database instance) as well, where a
higher-level mapping between mappings is a 2-cell morphism. Database category
DB has the following properties: it is equal to its dual, complete and
cocomplete. Special attention is devoted to practical examples: a query
definition, a query rewriting in GAV Database-integration environment, and the
fixpoint solution of a canonical data integration model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0260</identifier>
 <datestamp>2011-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0260</id><created>2011-03-01</created><authors><author><keyname>Otoo</keyname><forenames>Ekow</forenames></author><author><keyname>Pinar</keyname><forenames>Ali</forenames></author><author><keyname>Rotem</keyname><forenames>Doron</forenames></author></authors><title>A Linear Approximation Algorithm for 2-Dimensional Vector Packing</title><categories>cs.DS cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the 2-dimensional vector packing problem, which is a generalization
of the classical bin packing problem where each item has 2 distinct weights and
each bin has 2 corresponding capacities. The goal is to group items into
minimum number of bins, without violating the bin capacity constraints. We
propose a \Theta}(n)-time approximation algorithm that is inspired by the
O(n^2) algorithm proposed by Chang, Hwang, and Park.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0266</identifier>
 <datestamp>2011-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0266</id><created>2011-03-01</created><updated>2011-03-28</updated><authors><author><keyname>Shin</keyname><forenames>Won-Yong</forenames></author><author><keyname>Lucani</keyname><forenames>Daniel E.</forenames></author><author><keyname>Medard</keyname><forenames>Muriel</forenames></author><author><keyname>Stojanovic</keyname><forenames>Milica</forenames></author><author><keyname>Tarokh</keyname><forenames>Vahid</forenames></author></authors><title>On the Order Optimality of Large-scale Underwater Networks</title><categories>cs.IT math.IT</categories><comments>25 pages, 6 figures, Submitted to IEEE Transactions on Information
  Theory (part of this work was submitted to the 2011 IEEE International
  Symposium on Information Theory 2011)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Capacity scaling laws are analyzed in an underwater acoustic network with $n$
regularly located nodes on a square, in which both bandwidth and received
signal power can be limited significantly. A narrow-band model is assumed where
the carrier frequency is allowed to scale as a function of $n$. In the network,
we characterize an attenuation parameter that depends on the frequency scaling
as well as the transmission distance. Cut-set upper bounds on the throughput
scaling are then derived in both extended and dense networks having unit node
density and unit area, respectively. It is first analyzed that under extended
networks, the upper bound is inversely proportional to the attenuation
parameter, thus resulting in a highly power-limited network. Interestingly, it
is seen that the upper bound for extended networks is intrinsically related to
the attenuation parameter but not the spreading factor. On the other hand, in
dense networks, we show that there exists either a bandwidth or power
limitation, or both, according to the path-loss attenuation regimes, thus
yielding the upper bound that has three fundamentally different operating
regimes. Furthermore, we describe an achievable scheme based on the simple
nearest-neighbor multi-hop (MH) transmission. We show that under extended
networks, the MH scheme is order-optimal for all the operating regimes. An
achievability result is also presented in dense networks, where the operating
regimes that guarantee the order optimality are identified. It thus turns out
that frequency scaling is instrumental towards achieving the order optimality
in the regimes. Finally, these scaling results are extended to a random network
realization. As a result, vital information for fundamental limits of a variety
of underwater network scenarios is provided by showing capacity scaling laws.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0267</identifier>
 <datestamp>2011-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0267</id><created>2011-03-01</created><authors><author><keyname>Grabner</keyname><forenames>Peter J.</forenames><affiliation>LIAFA</affiliation></author><author><keyname>Steiner</keyname><forenames>Wolfgang</forenames><affiliation>LIAFA</affiliation></author></authors><title>Redundancy of minimal weight expansions in Pisot bases</title><categories>math.NT cs.DM</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by multiplication algorithms based on redundant number
representations, we study representations of an integer $n$ as a sum $n=\sum_k
\epsilon_k U_k$, where the digits $\epsilon_k$ are taken from a finite alphabet
$\Sigma$ and $(U_k)_k$ is a linear recurrent sequence of Pisot type with
$U_0=1$. The most prominent example of a base sequence $(U_k)_k$ is the
sequence of Fibonacci numbers. We prove that the representations of minimal
weight $\sum_k|\epsilon_k|$ are recognised by a finite automaton and obtain an
asymptotic formula for the average number of representations of minimal weight.
Furthermore, we relate the maximal order of magnitude of the number of
representations of a given integer to the joint spectral radius of a certain
set of matrices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0270</identifier>
 <datestamp>2011-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0270</id><created>2011-03-01</created><authors><author><keyname>Yin</keyname><forenames>Huarui</forenames></author><author><keyname>Lei</keyname></author><author><keyname>Ke</keyname></author><author><keyname>Wang</keyname><forenames>Zhengdao</forenames></author></authors><title>Interference Alignment and Degrees of Freedom Region of Cellular Sigma
  Channel</title><categories>cs.IT math.IT</categories><comments>5 page2 2figures submitted to isit 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the Degrees of Freedom (DoF) Region of a cellular network,
where the cells can have overlapping areas. Within an overlapping area, the
mobile users can access multiple base stations. We consider a case where there
are two base stations both equipped with multiple antennas. The mobile stations
are all equipped with single antenna and each mobile station can belong to
either a single cell or both cells. We completely characterize the DoF region
for the uplink channel assuming that global channel state information is
available at the transmitters. The achievability scheme is based on
interference alignment at the base stations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0305</identifier>
 <datestamp>2011-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0305</id><created>2011-03-01</created><authors><author><keyname>Zhang</keyname><forenames>Peng</forenames></author><author><keyname>Qiu</keyname><forenames>Robert</forenames></author></authors><title>GLRT-Based Spectrum Sensing with Blindly Learned Feature under Rank-1
  Assumption</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Prior knowledge can improve the performance of spectrum sensing. Instead of
using universal features as prior knowledge, we propose to blindly learn the
localized feature at the secondary user. Motivated by pattern recognition in
machine learning, we define signal feature as the leading eigenvector of the
signal's sample covariance matrix. Feature learning algorithm (FLA) for blind
feature learning and feature template matching algorithm (FTM) for spectrum
sensing are proposed. Furthermore, we implement the FLA and FTM in hardware.
Simulations and hardware experiments show that signal feature can be learned
blindly. In addition, by using signal feature as prior knowledge, the detection
performance can be improved by about 2 dB. Motivated by experimental results,
we derive several GLRT based spectrum sensing algorithms under rank-1
assumption, considering signal feature, signal power and noise power as the
available parameters. The performance of our proposed algorithms is tested on
both synthesized rank-1 signal and captured DTV data, and compared to other
state-of-the-art covariance matrix based spectrum sensing algorithms. In
general, our GLRT based algorithms have better detection performance. In
addition, algorithms with signal feature as prior knowledge are about 2 dB
better than algorithms without prior knowledge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0311</identifier>
 <datestamp>2011-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0311</id><created>2011-03-01</created><authors><author><keyname>Einolghozati</keyname><forenames>Arash</forenames></author><author><keyname>Sardari</keyname><forenames>Mohsen</forenames></author><author><keyname>Beirami</keyname><forenames>Ahmad</forenames></author><author><keyname>Fekri</keyname><forenames>Faramarz</forenames></author></authors><title>Consensus Problem under Diffusion-based Molecular Communication</title><categories>cs.IT math.IT nlin.AO</categories><comments>6 pages. To appear in CISS 2011 proceeding</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the consensus problem in a network where nodes communicate via
diffusion-based molecular communication (DbMC). In DbMC, messages are conveyed
via the variation in the concentration of molecules in the medium. Every node
acquires sensory information about the environment. Communication enables the
nodes to reach the best estimate for that measurement, e.g., the average of the
initial estimates by all nodes. We consider an iterative method for
communication among nodes that enables information spreading and averaging in
the network. We show that the consensus can be attained after a finite number
of iterations and variance of estimates of nodes can be made arbitrarily small
via communication.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0317</identifier>
 <datestamp>2011-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0317</id><created>2011-03-01</created><authors><author><keyname>Gad</keyname><forenames>Eyal En</forenames></author><author><keyname>Langberg</keyname><forenames>Michael</forenames></author><author><keyname>Schwartz</keyname><forenames>Moshe</forenames></author><author><keyname>Bruck</keyname><forenames>Jehoshua</forenames></author></authors><title>Generalized Gray Codes for Local Rank Modulation</title><categories>cs.IT math.IT</categories><comments>7 pages, 1 figure, shorter version was submitted to ISIT 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the local rank-modulation scheme in which a sliding window going
over a sequence of real-valued variables induces a sequence of permutations.
Local rank-modulation is a generalization of the rank-modulation scheme, which
has been recently suggested as a way of storing information in flash memory. We
study Gray codes for the local rank-modulation scheme in order to simulate
conventional multi-level flash cells while retaining the benefits of rank
modulation. Unlike the limited scope of previous works, we consider code
constructions for the entire range of parameters including the code length,
sliding window size, and overlap between adjacent windows. We show our
constructed codes have asymptotically-optimal rate. We also provide efficient
encoding, decoding, and next-state algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0318</identifier>
 <datestamp>2011-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0318</id><created>2011-03-01</created><authors><author><keyname>Eppstein</keyname><forenames>David</forenames></author><author><keyname>Strash</keyname><forenames>Darren</forenames></author></authors><title>Listing All Maximal Cliques in Large Sparse Real-World Graphs</title><categories>cs.DS</categories><comments>12 pages, 4 figures. To appear at the 10th International Symposium on
  Experimental Algorithms (SEA 2011)</comments><acm-class>F.2.2; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We implement a new algorithm for listing all maximal cliques in sparse graphs
due to Eppstein, L\&quot;offler, and Strash (ISAAC 2010) and analyze its performance
on a large corpus of real-world graphs. Our analysis shows that this algorithm
is the first to offer a practical solution to listing all maximal cliques in
large sparse graphs. All other theoretically-fast algorithms for sparse graphs
have been shown to be significantly slower than the algorithm of Tomita et al.
(Theoretical Computer Science, 2006) in practice. However, the algorithm of
Tomita et al. uses an adjacency matrix, which requires too much space for large
sparse graphs. Our new algorithm opens the door for fast analysis of large
sparse graphs whose adjacency matrix will not fit into working memory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0326</identifier>
 <datestamp>2011-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0326</id><created>2011-03-01</created><authors><author><keyname>D&#xf6;rpinghaus</keyname><forenames>Meik</forenames></author><author><keyname>Meyr</keyname><forenames>Heinrich</forenames></author></authors><title>On the Achievable Rate of Stationary Rayleigh Flat-Fading Channels with
  Gaussian Inputs</title><categories>cs.IT math.IT</categories><comments>submitted to the Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we consider a discrete-time stationary Rayleigh flat-fading
channel with unknown channel state information at transmitter and receiver. The
law of the channel is presumed to be known to the receiver. In addition, we
assume the power spectral density (PSD) of the fading process to be compactly
supported. For i.i.d. zero-mean proper Gaussian input distributions, we
investigate the achievable rate. One of the main contributions is the
derivation of two new upper bounds on the achievable rate with zero-mean proper
Gaussian input symbols. The first one holds only for the special case of a
rectangular PSD and depends on the SNR and the spread of the PSD. Together with
a lower bound on the achievable rate, which is achievable with i.i.d. zero-mean
proper Gaussian input symbols, we have found a set of bounds which is tight in
the sense that their difference is bounded. Furthermore, we show that the high
SNR slope is characterized by a pre-log of 1-2f_d, where f_d is the normalized
maximum Doppler frequency. This pre-log is equal to the high SNR pre-log of the
peak power constrained capacity. Furthermore, we derive an alternative upper
bound on the achievable rate with i.i.d. input symbols which is based on the
one-step channel prediction error variance. The novelty lies in the fact that
this bound is not restricted to peak power constrained input symbols like known
bounds, e.g. in [1]. Therefore, the derived upper bound can also be used to
evaluate the achievable rate with i.i.d. proper Gaussian input symbols. We
compare the derived bounds on the achievable rate with i.i.d. zero-mean proper
Gaussian input symbols with bounds on the peak power constrained capacity given
in [1-3]. Finally, we compare the achievable rate with i.i.d. zero-mean proper
Gaussian input symbols with the achievable rate using synchronized detection in
combination with a solely pilot based channel estimation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0337</identifier>
 <datestamp>2011-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0337</id><created>2011-03-01</created><authors><author><keyname>Le</keyname><forenames>Duc-Phong</forenames></author><author><keyname>Liu</keyname><forenames>Chao-Liang</forenames></author></authors><title>Refinements of Miller's Algorithm over Weierstrass Curves Revisited</title><categories>cs.DS</categories><comments>17 pages</comments><acm-class>F.2.1; G.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In 1986 Victor Miller described an algorithm for computing the Weil pairing
in his unpublished manuscript. This algorithm has then become the core of all
pairing-based cryptosystems. Many improvements of the algorithm have been
presented. Most of them involve a choice of elliptic curves of a \emph{special}
forms to exploit a possible twist during Tate pairing computation. Other
improvements involve a reduction of the number of iterations in the Miller's
algorithm. For the generic case, Blake, Murty and Xu proposed three refinements
to Miller's algorithm over Weierstrass curves. Though their refinements which
only reduce the total number of vertical lines in Miller's algorithm, did not
give an efficient computation as other optimizations, but they can be applied
for computing \emph{both} of Weil and Tate pairings on \emph{all}
pairing-friendly elliptic curves. In this paper we extend the Blake-Murty-Xu's
method and show how to perform an elimination of all vertical lines in Miller's
algorithm during Weil/Tate pairings computation on \emph{general} elliptic
curves. Experimental results show that our algorithm is faster about 25% in
comparison with the original Miller's algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0351</identifier>
 <datestamp>2011-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0351</id><created>2011-03-02</created><authors><author><keyname>Broutin</keyname><forenames>Nicolas</forenames></author><author><keyname>Devroye</keyname><forenames>Luc</forenames></author><author><keyname>Fraiman</keyname><forenames>Nicolas</forenames></author><author><keyname>Lugosi</keyname><forenames>G&#xe1;bor</forenames></author></authors><title>Connectivity threshold for Bluetooth graphs</title><categories>math.PR cs.DM cs.NI math.CO</categories><comments>21 pages, 5 figures</comments><msc-class>05C80, 60C05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the connectivity properties of random Bluetooth graphs that model
certain &quot;ad hoc&quot; wireless networks. The graphs are obtained as &quot;irrigation
subgraphs&quot; of the well-known random geometric graph model. There are two
parameters that control the model: the radius $r$ that determines the &quot;visible
neighbors&quot; of each node and the number of edges $c$ that each node is allowed
to send to these. The randomness comes from the underlying distribution of data
points in space and from the choices of each vertex. We prove that no
connectivity can take place with high probability for a range of parameters $r,
c$ and completely characterize the connectivity threshold (in $c$) for values
of $r$ close the critical value for connectivity in the underlying random
geometric graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0358</identifier>
 <datestamp>2011-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0358</id><created>2011-03-02</created><authors><author><keyname>Kim</keyname><forenames>Anthony</forenames></author></authors><title>On Network Coding Capacity - Matroidal Networks and Network Capacity
  Regions</title><categories>cs.IT math.IT</categories><comments>Master of Engineering Thesis, MIT, September 2010, 70 pages, 10
  figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One fundamental problem in the field of network coding is to determine the
network coding capacity of networks under various network coding schemes. In
this thesis, we address the problem with two approaches: matroidal networks and
capacity regions.
  In our matroidal approach, we prove the converse of the theorem which states
that, if a network is scalar-linearly solvable then it is a matroidal network
associated with a representable matroid over a finite field. As a consequence,
we obtain a correspondence between scalar-linearly solvable networks and
representable matroids over finite fields in the framework of matroidal
networks. We prove a theorem about the scalar-linear solvability of networks
and field characteristics. We provide a method for generating scalar-linearly
solvable networks that are potentially different from the networks that we
already know are scalar-linearly solvable.
  In our capacity region approach, we define a multi-dimensional object, called
the network capacity region, associated with networks that is analogous to the
rate regions in information theory. For the network routing capacity region, we
show that the region is a computable rational polytope and provide exact
algorithms and approximation heuristics for computing the region. For the
network linear coding capacity region, we construct a computable rational
polytope, with respect to a given finite field, that inner bounds the linear
coding capacity region and provide exact algorithms and approximation
heuristics for computing the polytope. The exact algorithms and approximation
heuristics we present are not polynomial time schemes and may depend on the
output size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0361</identifier>
 <datestamp>2012-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0361</id><created>2011-03-02</created><updated>2012-02-05</updated><authors><author><keyname>Kim</keyname><forenames>Anthony</forenames></author><author><keyname>Medard</keyname><forenames>Muriel</forenames></author></authors><title>Computing Bounds on Network Capacity Regions as a Polytope
  Reconstruction Problem</title><categories>cs.IT math.IT</categories><comments>Appeared in the 2011 IEEE International Symposium on Information
  Theory, 5 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We define a notion of network capacity region of networks that generalizes
the notion of network capacity defined by Cannons et al. and prove its notable
properties such as closedness, boundedness and convexity when the finite field
is fixed. We show that the network routing capacity region is a computable
rational polytope and provide exact algorithms and approximation heuristics for
computing the region. We define the semi-network linear coding capacity region,
with respect to a fixed finite field, that inner bounds the corresponding
network linear coding capacity region, show that it is a computable rational
polytope, and provide exact algorithms and approximation heuristics. We show
connections between computing these regions and a polytope reconstruction
problem and some combinatorial optimization problems, such as the minimum cost
directed Steiner tree problem. We provide an example to illustrate our results.
The algorithms are not necessarily polynomial-time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0365</identifier>
 <datestamp>2011-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0365</id><created>2011-03-02</created><authors><author><keyname>Pradeep</keyname><forenames>J.</forenames></author><author><keyname>Srinivasan</keyname><forenames>E.</forenames></author><author><keyname>Himavathi</keyname><forenames>S.</forenames></author></authors><title>Diagonal Based Feature Extraction for Handwritten Alphabets Recognition
  System using Neural Network</title><categories>stat.CO cs.NE</categories><doi>10.5121/ijcsit.2011.3103</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An off-line handwritten alphabetical character recognition system using
multilayer feed forward neural network is described in the paper. A new method,
called, diagonal based feature extraction is introduced for extracting the
features of the handwritten alphabets. Fifty data sets, each containing 26
alphabets written by various people, are used for training the neural network
and 570 different handwritten alphabetical characters are used for testing. The
proposed recognition system performs quite well yielding higher levels of
recognition accuracy compared to the systems employing the conventional
horizontal and vertical methods of feature extraction. This system will be
suitable for converting handwritten documents into structural text form and
recognizing handwritten names.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0368</identifier>
 <datestamp>2011-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0368</id><created>2011-03-02</created><updated>2011-03-14</updated><authors><author><keyname>Rocklin</keyname><forenames>Matthew</forenames></author><author><keyname>Pinar</keyname><forenames>Ali</forenames></author></authors><title>Computing an Aggregate Edge-Weight Function for Clustering Graphs with
  Multiple Edge Types</title><categories>cs.SI cs.DS physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the community detection problem on graphs in the existence of
multiple edge types. Our main motivation is that similarity between objects can
be defined by many different metrics and aggregation of these metrics into a
single one poses several important challenges, such as recovering this
aggregation function from ground-truth, investigating the space of different
clusterings, etc. In this paper, we address how to find an aggregation function
to generate a composite metric that best resonates with the ground-truth. We
describe two approaches: solving an inverse problem where we try to find
parameters that generate a graph whose clustering gives the ground-truth
clustering, and choosing parameters to maximize the quality of the ground-truth
clustering. We present experimental results on real and synthetic benchmarks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0377</identifier>
 <datestamp>2011-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0377</id><created>2011-03-02</created><authors><author><keyname>Molkaraie</keyname><forenames>Mehdi</forenames></author><author><keyname>Pakzad</keyname><forenames>Payam</forenames></author></authors><title>On Properties of the Minimum Entropy Sub-tree to Compute Lower Bounds on
  the Partition Function</title><categories>stat.AP cs.IT math.IT physics.comp-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computing the partition function and the marginals of a global probability
distribution are two important issues in any probabilistic inference problem.
In a previous work, we presented sub-tree based upper and lower bounds on the
partition function of a given probabilistic inference problem. Using the
entropies of the sub-trees we proved an inequality that compares the lower
bounds obtained from different sub-trees. In this paper we investigate the
properties of one specific lower bound, namely the lower bound computed by the
minimum entropy sub-tree. We also investigate the relationship between the
minimum entropy sub-tree and the sub-tree that gives the best lower bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0398</identifier>
 <datestamp>2011-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0398</id><created>2011-03-02</created><authors><author><keyname>Collobert</keyname><forenames>Ronan</forenames></author><author><keyname>Weston</keyname><forenames>Jason</forenames></author><author><keyname>Bottou</keyname><forenames>Leon</forenames></author><author><keyname>Karlen</keyname><forenames>Michael</forenames></author><author><keyname>Kavukcuoglu</keyname><forenames>Koray</forenames></author><author><keyname>Kuksa</keyname><forenames>Pavel</forenames></author></authors><title>Natural Language Processing (almost) from Scratch</title><categories>cs.LG cs.CL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a unified neural network architecture and learning algorithm that
can be applied to various natural language processing tasks including:
part-of-speech tagging, chunking, named entity recognition, and semantic role
labeling. This versatility is achieved by trying to avoid task-specific
engineering and therefore disregarding a lot of prior knowledge. Instead of
exploiting man-made input features carefully optimized for each task, our
system learns internal representations on the basis of vast amounts of mostly
unlabeled training data. This work is then used as a basis for building a
freely available tagging system with good performance and minimal computational
requirements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0405</identifier>
 <datestamp>2011-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0405</id><created>2011-03-02</created><authors><author><keyname>Mataracioglu</keyname><forenames>Tolga</forenames></author><author><keyname>Ozkan</keyname><forenames>Sevgi</forenames></author></authors><title>Analysis of the User Acceptance for Implementing ISO/IEC 27001:2005 in
  Turkish Public Organizations</title><categories>cs.HC cs.CR</categories><comments>12 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This study aims to develop a model for the user acceptance for implementing
the information security standard (i.e. ISO 27001) in Turkish public
organizations. The results of the surveys performed in Turkey reveal that the
legislation on information security public which organizations have to obey is
significantly related with the user acceptance during ISO 27001 implementation
process. The fundamental components of our user acceptance model are perceived
usefulness, attitude towards use, social norms, and performance expectancy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0412</identifier>
 <datestamp>2011-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0412</id><created>2011-03-02</created><updated>2011-07-29</updated><authors><author><keyname>Mori&#x107;</keyname><forenames>Filip</forenames></author><author><keyname>Pritchard</keyname><forenames>David</forenames></author></authors><title>Counting large distances in convex polygons</title><categories>math.CO cs.CG</categories><comments>Shorter version presented at EuroComb 2011</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In a convex n-gon, let d[1] &gt; d[2] &gt; ... denote the set of all distances
between pairs of vertices, and let m[i] be the number of pairs of vertices at
distance d[i] from one another. Erdos, Lovasz, and Vesztergombi conjectured
that m[1] + ... + m[k] &lt;= k*n. Using a new computational approach, we prove
their conjecture when k &lt;= 4 and n is large; we also make some progress for
arbitrary k by proving that m[1] + ... + m[k] &lt;= (2k-1)n. Our main approach
revolves around a few known facts about distances, together with a computer
program that searches all distance configurations of two disjoint convex hull
intervals up to some finite size. We thereby obtain other new bounds such as
m[3] &lt;= 3n/2 for large n.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0414</identifier>
 <datestamp>2011-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0414</id><created>2011-03-02</created><authors><author><keyname>Salzo</keyname><forenames>Saverio</forenames></author><author><keyname>Villa</keyname><forenames>Silvia</forenames></author></authors><title>Convergence analysis of a proximal Gauss-Newton method</title><categories>math.OC cs.SY math.NA</categories><msc-class>65J15, 90C30, 47J25</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An extension of the Gauss-Newton algorithm is proposed to find local
minimizers of penalized nonlinear least squares problems, under generalized
Lipschitz assumptions. Convergence results of local type are obtained, as well
as an estimate of the radius of the convergence ball. Some applications for
solving constrained nonlinear equations are discussed and the numerical
performance of the method is assessed on some significant test problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0437</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0437</id><created>2011-03-02</created><updated>2011-05-13</updated><authors><author><keyname>Bonchi</keyname><forenames>Filippo</forenames><affiliation>CNRS - ENS, Lyon</affiliation></author><author><keyname>Montanari</keyname><forenames>Ugo</forenames><affiliation>Dipartimento di informatica, Pisa</affiliation></author></authors><title>Symbolic and Asynchronous Semantics via Normalized Coalgebras</title><categories>cs.LO</categories><comments>53 pages, 13 Figures, 2 Tables. Journal version of the work published
  in the proceedings of CALCO 2009</comments><proxy>LMCS</proxy><acm-class>F.3.2</acm-class><journal-ref>Logical Methods in Computer Science, Volume 7, Issue 2 (May 16,
  2011) lmcs:671</journal-ref><doi>10.2168/LMCS-7(2:7)2011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The operational semantics of interactive systems is usually described by
labeled transition systems. Abstract semantics (that is defined in terms of
bisimilarity) is characterized by the final morphism in some category of
coalgebras. Since the behaviour of interactive systems is for many reasons
infinite, symbolic semantics were introduced as a mean to define smaller,
possibly finite, transition systems, by employing symbolic actions and avoiding
some sources of infiniteness. Unfortunately, symbolic bisimilarity has a
different shape with respect to ordinary bisimilarity, and thus the standard
coalgebraic characterization does not work. In this paper, we introduce its
coalgebraic models. We will use as motivating examples two asynchronous
formalisms: open Petri nets and asynchronous pi-calculus. Indeed, as we have
shown in a previous paper, asynchronous bisimilarity can be seen as an instance
of symbolic bisimilarity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0461</identifier>
 <datestamp>2011-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0461</id><created>2011-03-02</created><authors><author><keyname>Dash</keyname><forenames>Debashis</forenames></author><author><keyname>Sabharwal</keyname><forenames>Ashutosh</forenames></author></authors><title>Paranoid Secondary: Waterfilling in a Cognitive Interference Channel
  with Partial Information</title><categories>cs.IT math.IT</categories><comments>26 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a two-user cognitive channel, where the primary flow is sporadic,
cannot be re-designed and operating below its link capacity. To study the
impact of primary traffic uncertainty, we propose a block activity model that
captures the random on-off periods of primary's transmissions. Each block in
the model can be split into parallel Gaussian-mixture channels, such that each
channel resembles a multiple user channel (MAC) from the point of view of the
secondary user. The secondary senses the current state of the primary at the
start of each block. We show that the optimal power transmitted depends on the
sensed state and the optimal power profile is paranoid, i.e. either growing or
decaying in power as a function of time. We show that such a scheme achieves
capacity when there is no noise in the sensing. The optimal transmission for
the secondary performs rate splitting and follows a layered water-filling power
allocation for each parallel channel to achieve capacity. The secondary rate
approaches a genie-aided scheme for large block-lengths. Additionally, if the
fraction of time primary uses the channel tends to one, the paranoid scheme and
the genie-aided upper bound get arbitrarily close to a no-sensing scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0463</identifier>
 <datestamp>2013-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0463</id><created>2011-03-02</created><updated>2013-08-27</updated><authors><author><keyname>Nowlan</keyname><forenames>Michael F.</forenames></author><author><keyname>Tiwari</keyname><forenames>Nabin</forenames></author><author><keyname>Iyengar</keyname><forenames>Janardhan</forenames></author><author><keyname>Amin</keyname><forenames>Syed Obaid</forenames></author><author><keyname>Ford</keyname><forenames>Bryan</forenames></author></authors><title>Fitting Square Pegs Through Round Pipes: Unordered Delivery
  Wire-Compatible with TCP and TLS</title><categories>cs.NI cs.PF</categories><comments>16 pages, 13 figures, 1 table</comments><journal-ref>NSDI '12, San Jose, CA, April 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Internet applications increasingly employ TCP not as a stream abstraction,
but as a substrate for application-level transports, a use that converts TCP's
in-order semantics from a convenience blessing to a performance curse. As
Internet evolution makes TCP's use as a substrate likely to grow, we offer
Minion, an architecture for backward-compatible out-of-order delivery atop TCP
and TLS. Small OS API extensions allow applications to manage TCP's send buffer
and to receive TCP segments out-of-order. Atop these extensions, Minion builds
application-level protocols offering true unordered datagram delivery, within
streams preserving strict wire-compatibility with unsecured or TLS-secured TCP
connections. Minion's protocols can run on unmodified TCP stacks, but benefit
incrementally when either endpoint is upgraded, for a backward-compatible
deployment path. Experiments suggest that Minion can noticeably improve
performance of applications such as conferencing, virtual private networking,
and web browsing, while incurring minimal CPU or bandwidth costs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0464</identifier>
 <datestamp>2011-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0464</id><created>2011-03-02</created><authors><author><keyname>Tasoluk</keyname><forenames>Berker</forenames></author><author><keyname>Tanrikulu</keyname><forenames>Zuhal</forenames></author></authors><title>A Weakest Chain Approach to Assessing the Overall Effectiveness of the
  802.11 Wireless Network Security</title><categories>cs.CR cs.NI</categories><comments>8 pages, 3 tables</comments><acm-class>C.2.1; C.2.2</acm-class><journal-ref>International Journal of Wireless &amp; Mobile Networks (IJWMN) Vol.
  3, No. 1, February 2011 ISSN:0975-3834 (Online); 0975-4679 (Print)</journal-ref><doi>10.5121/ijwmn.2011.3101</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This study aims to assess wireless network security holistically and attempts
to determine the weakest link among the parts that comprise the 'secure' aspect
of the wireless networks: security protocols, wireless technologies and user
habits. The assessment of security protocols is done by determining the time
taken to break a specific protocol's encryption key, or to pass an access
control by using brute force attack techniques. Passphrase strengths as well as
encryption key strengths ranging from 40 to 256 bits are evaluated. Different
scenarios are planned and created for passphrase generation, using different
character sets and different number of characters. Then each scenario is
evaluated based on the time taken to break that passphrase. At the end of the
study, it is determined that the choice of the passphrase is the weakest part
of the entire 802.11 wireless security system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0484</identifier>
 <datestamp>2012-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0484</id><created>2011-03-02</created><authors><author><keyname>Hollanti</keyname><forenames>Camilla</forenames></author><author><keyname>Vehkalahti</keyname><forenames>Roope</forenames></author><author><keyname>Nasser</keyname><forenames>Youssef</forenames></author></authors><title>Algebraic Hybrid Satellite-Terrestrial Space-Time Codes for Digital
  Broadcasting in SFN</title><categories>cs.IT math.IT</categories><comments>14 pages, 2 figures, submitted to ISIT 2011</comments><journal-ref>Proceedings of the IEEE Workshop on Signal Processing Systems,
  SiPS 2011, October 4-7, 2011, Beirut, Lebanon</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Lately, different methods for broadcasting future digital TV in a single
frequency network (SFN) have been under an intensive study. To improve the
transmission to also cover suburban and rural areas, a hybrid scheme may be
used. In hybrid transmission, the signal is transmitted both from a satellite
and from a terrestrial site. In 2008, Y. Nasser et al. proposed to use a double
layer 3D space-time (ST) code in the hybrid 4 x 2 MIMO transmission of digital
TV. In this paper, alternative codes with simpler structure are proposed for
the 4 x 2 hybrid system, and new codes are constructed for the 3 x 2 system.
The performance of the proposed codes is analyzed through computer simulations,
showing a significant improvement over simple repetition schemes. The proposed
codes prove in addition to be very robust in the presence of power imbalance
between the two sites.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0486</identifier>
 <datestamp>2013-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0486</id><created>2011-03-02</created><updated>2012-08-07</updated><authors><author><keyname>Riener</keyname><forenames>Cordian</forenames></author><author><keyname>Theobald</keyname><forenames>Thorsten</forenames></author><author><keyname>Andr&#xe9;n</keyname><forenames>Lina Jansson</forenames></author><author><keyname>Lasserre</keyname><forenames>Jean B.</forenames></author></authors><title>Exploiting symmetries in SDP-relaxations for polynomial optimization</title><categories>math.OC cs.SY</categories><comments>(v3) Minor revision. To appear in Math. of Operations Research</comments><msc-class>90C22, 90C26, 14P05, 05E10</msc-class><journal-ref>Mathematics of Operations Research 38 (1), 122-141 (2013)</journal-ref><doi>10.1287/moor.1120.0558</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study various approaches for exploiting symmetries in
polynomial optimization problems within the framework of semi definite
programming relaxations. Our special focus is on constrained problems
especially when the symmetric group is acting on the variables. In particular,
we investigate the concept of block decomposition within the framework of
constrained polynomial optimization problems, show how the degree principle for
the symmetric group can be computationally exploited and also propose some
methods to efficiently compute in the geometric quotient.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0490</identifier>
 <datestamp>2011-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0490</id><created>2011-03-02</created><authors><author><keyname>Majkic</keyname><forenames>Zoran</forenames></author></authors><title>Sound and Complete Query Answering in Intensional P2P Data Integration</title><categories>cs.DB cs.LO</categories><comments>27 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Contemporary use of the term 'intension' derives from the traditional logical
doctrine that an idea has both an extension and an intension. In this paper we
introduce an intensional FOL (First-order-logic) for P2P systems by fusing the
Bealer's intensional algebraic FOL with the S5 possible-world semantics of the
Montague, we define the intensional equivalence relation for this logic and the
weak deductive inference for it. The notion of ontology has become widespread
in semantic Web. The meaning of concepts and views defined over some database
ontology can be considered as intensional objects which have particular
extension in some possible world: for instance in the actual world. Thus, non
invasive mapping between completely independent peer databases in a P2P systems
can be naturally specified by the set of couples of intensionally equivalent
views, which have the same meaning (intension), over two different peers. Such
a kind of mapping has very different semantics from the standard view-based
mappings based on the material implication commonly used for Data Integration.
We show how a P2P database system may be embedded into this intensional modal
FOL, and how we are able to obtain a weak non-omniscient inference, which can
be effectively implemented. For a query answering we consider non omniscient
query agents and we define object-oriented class for them which implements as
method the query rewriting algorithm. Finally, we show that this query
answering algorithm is sound and complete w.r.t. the weak deduction of the P2P
intensional logic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0494</identifier>
 <datestamp>2011-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0494</id><created>2011-03-02</created><updated>2011-11-03</updated><authors><author><keyname>Paris</keyname><forenames>Jose F.</forenames></author></authors><title>Outage Probability in {\eta}-{\mu}/{\eta}-{\mu} Interference-limited
  Scenarios</title><categories>cs.IT math.IT</categories><comments>This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper exact closed-form expressions are derived for the outage
probability (OP) in scenarios where both the signal of interest (SOI) and the
interfering signals experience {\eta}-{\mu} fading and the background noise can
be neglected. With the only assumption that the {\mu} parameter is a positive
integer number for the interfering signals, the derived expressions are given
in elementary terms for maximal ratio combining (MRC) with independent
branches. The analysis is also valid when the {\mu} parameters of the
pre-combining SOI power envelopes are positive integer or half-integer numbers
and the SOI is formed at the receiver from spatially correlated MRC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0502</identifier>
 <datestamp>2011-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0502</id><created>2011-03-02</created><authors><author><keyname>Paris</keyname><forenames>Jose F.</forenames></author></authors><title>Unified Analysis of the Average Gaussian Error Probability for a Class
  of Fading Channels</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper focuses on the analysis of average Gaussian error probabilities in
certain fading channels, i.e. we are interested in E[Q((p {\gamma})^(1/2))]
where Q(.) is the Gaussian Q-function, p is a positive real number and {\gamma}
is a nonnegative random variable. We present a unified analysis of the average
Gaussian error probability, derive a compact expression in terms of the
Lauricella FD^(n) function that is applicable to a broad class of fading
channels, and discuss the relation of this expression and expressions of this
type recently appeared in literature. As an intermediate step in our
derivations, we also obtain a compact expression for the outage probability of
the same class of fading channels. Finally, we show how this unified analysis
allows us to obtain novel performance analytical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0505</identifier>
 <datestamp>2011-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0505</id><created>2011-03-02</created><authors><author><keyname>Paris</keyname><forenames>Jose F.</forenames></author></authors><title>A Note on the Sum of Correlated Gamma Random Variables</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The sum of correlated gamma random variables appears in the analysis of many
wireless communications systems, e.g. in systems under Nakagami-m fading. In
this Letter we obtain exact expressions for the probability density function
(PDF) and the cumulative distribution function (CDF) of the sum of arbitrarily
correlated gamma variables in terms of certain Lauricella functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0510</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0510</id><created>2011-03-02</created><updated>2011-06-06</updated><authors><author><keyname>Dreyer</keyname><forenames>Derek</forenames><affiliation>MPI-SWS</affiliation></author><author><keyname>Ahmed</keyname><forenames>Amal</forenames><affiliation>Indiana University</affiliation></author><author><keyname>Birkedal</keyname><forenames>Lars</forenames><affiliation>IT University of Copenhagen</affiliation></author></authors><title>Logical Step-Indexed Logical Relations</title><categories>cs.PL cs.LO</categories><proxy>LMCS</proxy><acm-class>D.3.3, F.3.1, F.3.3</acm-class><journal-ref>Logical Methods in Computer Science, Volume 7, Issue 2 (June 7,
  2011) lmcs:698</journal-ref><doi>10.2168/LMCS-7(2:16)2011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Appel and McAllester's &quot;step-indexed&quot; logical relations have proven to be a
simple and effective technique for reasoning about programs in languages with
semantically interesting types, such as general recursive types and general
reference types. However, proofs using step-indexed models typically involve
tedious, error-prone, and proof-obscuring step-index arithmetic, so it is
important to develop clean, high-level, equational proof principles that avoid
mention of step indices. In this paper, we show how to reason about binary
step-indexed logical relations in an abstract and elegant way. Specifically, we
define a logic LSLR, which is inspired by Plotkin and Abadi's logic for
parametricity, but also supports recursively defined relations by means of the
modal &quot;later&quot; operator from Appel, Melli\`es, Richards, and Vouillon's &quot;very
modal model&quot; paper. We encode in LSLR a logical relation for reasoning
relationally about programs in call-by-value System F extended with general
recursive types. Using this logical relation, we derive a set of useful rules
with which we can prove contextual equivalence and approximation results
without counting steps.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0512</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0512</id><created>2011-03-02</created><authors><author><keyname>Kurmyshev</keyname><forenames>Evguenii</forenames></author><author><keyname>Ju&#xe1;rez</keyname><forenames>H&#xe9;ctor A.</forenames></author><author><keyname>Gonz&#xe1;lez-Silva</keyname><forenames>Ricardo A.</forenames></author></authors><title>Dynamics of bounded confidence opinion in heterogeneous social networks:
  concord against partial antagonism</title><categories>physics.soc-ph cs.SI nlin.AO nlin.PS</categories><comments>16 pages, 20 figures. Submitted for publication in Physica A</comments><doi>10.1016/j.physa.2011.03.037</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bounded confidence models of opinion dynamics have been actively studied in
recent years, in particular, opinion formation and extremism propagation along
with other aspects of social dynamics. In this work, after an analysis of
limitations of the Deffuant-Weisbuch (DW) bounded confidence, relative
agreement model, we propose the Mixed model that takes into account two
psychological types of individuals. Concord agents (C-agents) are friendly
people; they interact in a way that their opinions get closer always. Agents of
the other psychological type show partial antagonism in their interaction
(PA-agents). Opinion dynamics in heterogeneous social groups, consisting of
agents of the two types, was studied on different social networks. Limit cases
of the mixed model, pure C- and PA-societies, were also studied. We found that
group opinion formation is, qualitatively, almost independent of the topology
of networks used in this work. Opinion fragmentation, polarization and
consensus are observed in the mixed model at different proportions of PA- and
C-agents, depending on the value of initial opinion tolerance of agents. As for
the opinion formation and arising of &quot;dissidents&quot;, the opinion dynamics of the
C-agents society was found to be similar to that of the DW model, except for
the rate of opinion convergence. Nevertheless, mixed societies showed dynamics
and bifurcation patterns notably different to those of the DW model. The
influence of biased initial conditions over opinion formation in heterogeneous
social groups was also studied versus the initial value of opinion uncertainty,
varying the proportion of the PA- to C-agents. Bifurcation diagrams showed
impressive evolution of collective opinion, in particular, radical change of
left to right consensus or vice versa at an opinion uncertainty value equal to
0.7 in the model with the PA/C mixture of population near 50/50.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0516</identifier>
 <datestamp>2011-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0516</id><created>2011-03-02</created><authors><author><keyname>Levavi</keyname><forenames>Ariel</forenames></author></authors><title>Pegging Numbers For Various Tree Graphs</title><categories>math.CO cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the game of pegging, each vertex of a graph is considered a hole into
which a peg can be placed. A pegging move is performed by jumping one peg over
another peg, and then removing the peg that has been jumped over from the
graph. We define the pegging number as the smallest number of pegs needed to
reach all the vertices in a graph no matter what the distribution. Similarly,
the optimal-pegging number of a graph is defined as the smallest distribution
of pegs for which all the vertices in the graph can be reached. We obtain tight
bounds on the pegging numbers and optimal-pegging numbers of complete binary
trees and compute the optimal-pegging numbers of complete infinitary trees. As
a result of these computations, we deduce that there is a tree whose
optimal-pegging number is strictly increased by removing a leaf. We also
compute the optimal-pegging number of caterpillar graphs and the tightest upper
bound on the optimal-pegging numbers of lobster graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0534</identifier>
 <datestamp>2011-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0534</id><created>2011-03-02</created><authors><author><keyname>Cygan</keyname><forenames>Marek</forenames></author><author><keyname>Nederlof</keyname><forenames>Jesper</forenames></author><author><keyname>Pilipczuk</keyname><forenames>Marcin</forenames></author><author><keyname>Pilipczuk</keyname><forenames>Micha&#x142;</forenames></author><author><keyname>van Rooij</keyname><forenames>Johan</forenames></author><author><keyname>Wojtaszczyk</keyname><forenames>Jakub Onufry</forenames></author></authors><title>Solving connectivity problems parameterized by treewidth in single
  exponential time</title><categories>cs.DS</categories><comments>89 pages, 12 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For the vast majority of local graph problems standard dynamic programming
techniques give c^tw V^O(1) algorithms, where tw is the treewidth of the input
graph. On the other hand, for problems with a global requirement (usually
connectivity) the best-known algorithms were naive dynamic programming schemes
running in tw^O(tw) V^O(1) time.
  We breach this gap by introducing a technique we dubbed Cut&amp;Count that allows
to produce c^tw V^O(1) Monte Carlo algorithms for most connectivity-type
problems, including Hamiltonian Path, Feedback Vertex Set and Connected
Dominating Set, consequently answering the question raised by Lokshtanov, Marx
and Saurabh [SODA'11] in a surprising way. We also show that (under reasonable
complexity assumptions) the gap cannot be breached for some problems for which
Cut&amp;Count does not work, like CYCLE PACKING.
  The constant c we obtain is in all cases small (at most 4 for undirected
problems and at most 6 for directed ones), and in several cases we are able to
show that improving those constants would cause the Strong Exponential Time
Hypothesis to fail.
  Our results have numerous consequences in various fields, like FPT
algorithms, exact and approximate algorithms on planar and H-minor-free graphs
and algorithms on graphs of bounded degree. In all these fields we are able to
improve the best-known results for some problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0538</identifier>
 <datestamp>2011-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0538</id><created>2011-03-02</created><updated>2011-07-13</updated><authors><author><keyname>Bayraktar</keyname><forenames>Erhan</forenames></author><author><keyname>Sirbu</keyname><forenames>Mihai</forenames></author></authors><title>Stochatic Perron's method and verification without smoothness using
  viscosity comparison: the linear case</title><categories>math.PR cs.SY math.AP math.OC</categories><comments>To appear in the Proceedings of the American Mathematical Society;
  Key words: Perron's method, viscosity solutions, non-smooth verification,
  comparison principle</comments><msc-class>60G46 (Primary), 60H30, 35J88 (Secondary), 35J40</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a probabilistic version of the classical Perron's method to
construct viscosity solutions to linear parabolic equations associated to
stochastic differential equations. Using this method, we construct easily two
viscosity (sub and super) solutions that squeeze in between the expected
payoff. If a comparison result holds true, then there exists a unique viscosity
solution which is a martingale along the solutions of the stochastic
differential equation. The unique viscosity solution is actually equal to the
expected payoff. This amounts to a verification result (Ito's Lemma) for
non-smooth viscosity solutions of the linear parabolic equation. This is the
first step in a larger program to prove verification for viscosity solutions
and the Dynamic Programming Principle for stochastic control problems and games
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0540</identifier>
 <datestamp>2011-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0540</id><created>2011-03-02</created><authors><author><keyname>Wang</keyname><forenames>Lijun</forenames></author><author><keyname>Shao</keyname><forenames>Ling</forenames></author></authors><title>An Algorithm for Repairing Low-Quality Video Enhancement Techniques
  Based on Trained Filter</title><categories>cs.CV cs.MM</categories><comments>Part of the work is published as a journal paper titled &quot;Repairing
  imperfect video enhancement algorithms using classification-based trained
  filters&quot; in Signal, Image and Video Processing (Springer); Signal, Image and
  Video Processing, 2011</comments><doi>10.1007/s11760-010-0202-8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multifarious image enhancement algorithms have been used in different
applications. Still, some algorithms or modules are imperfect for practical
use. When the image enhancement modules have been fixed or combined by a series
of algorithms, we need to repair them as a whole part without changing the
inside. This report aims to find an algorithm based on trained filters to
repair low-quality image enhancement modules. A brief review on basic image
enhancement techniques and pixel classification methods will be presented, and
the procedure of trained filters will be described step by step. The
experiments and result comparisons for this algorithm will be described in
detail.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0561</identifier>
 <datestamp>2011-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0561</id><created>2011-03-02</created><authors><author><keyname>Kountouris</keyname><forenames>Marios</forenames></author><author><keyname>Andrews</keyname><forenames>Jeffrey G.</forenames></author></authors><title>Downlink SDMA with Limited Feedback in Interference-Limited Wireless
  Networks</title><categories>cs.IT cs.NI math.IT</categories><comments>Submitted to IEEE Transactions on Wireless Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The tremendous capacity gains promised by space division multiple access
(SDMA) depend critically on the accuracy of the transmit channel state
information. In the broadcast channel, even without any network interference,
it is known that such gains collapse due to interstream interference if the
feedback is delayed or low rate. In this paper, we investigate SDMA in the
presence of interference from many other simultaneously active transmitters
distributed randomly over the network. In particular we consider zero-forcing
beamforming in a decentralized (ad hoc) network where each receiver provides
feedback to its respective transmitter. We derive closed-form expressions for
the outage probability, network throughput, transmission capacity, and average
achievable rate and go on to quantify the degradation in network performance
due to residual self-interference as a function of key system parameters. One
particular finding is that as in the classical broadcast channel, the per-user
feedback rate must increase linearly with the number of transmit antennas and
SINR (in dB) for the full multiplexing gains to be preserved with limited
feedback. We derive the throughput-maximizing number of streams, establishing
that single-stream transmission is optimal in most practically relevant
settings. In short, SDMA does not appear to be a prudent design choice for
interference-limited wireless networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0579</identifier>
 <datestamp>2011-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0579</id><created>2011-03-02</created><updated>2011-07-12</updated><authors><author><keyname>Pasqualetti</keyname><forenames>Fabio</forenames></author><author><keyname>Carli</keyname><forenames>Ruggero</forenames></author><author><keyname>Bullo</keyname><forenames>Francesco</forenames></author></authors><title>Distributed Estimation via Iterative Projections with Application to
  Power Network Monitoring</title><categories>math.OC cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work presents a distributed method for control centers to monitor the
operating condition of a power network, i.e., to estimate the network state,
and to ultimately determine the occurrence of threatening situations. State
estimation has been recognized to be a fundamental task for network control
centers to ensure correct and safe functionalities of power grids. We consider
(static) state estimation problems, in which the state vector consists of the
voltage magnitude and angle at all network buses. We consider the state to be
linearly related to network measurements, which include power flows, current
injections, and voltages phasors at some buses. We admit the presence of
several cooperating control centers, and we design two distributed methods for
them to compute the minimum variance estimate of the state given the network
measurements. The two distributed methods rely on different modes of
cooperation among control centers: in the first method an incremental mode of
cooperation is used, whereas, in the second method, a diffusive interaction is
implemented. Our procedures, which require each control center to know only the
measurements and structure of a subpart of the whole network, are
computationally efficient and scalable with respect to the network dimension,
provided that the number of control centers also increases with the network
cardinality. Additionally, a finite-memory approximation of our diffusive
algorithm is proposed, and its accuracy is characterized. Finally, our
estimation methods are exploited to develop a distributed algorithm to detect
corrupted data among the network measurements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0596</identifier>
 <datestamp>2011-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0596</id><created>2011-03-02</created><authors><author><keyname>Cocos</keyname><forenames>Mihail</forenames></author><author><keyname>Fowers</keyname><forenames>Shawn</forenames></author></authors><title>Music By Numbers</title><categories>math.CO cs.SD</categories><msc-class>05A99</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a mathematical way of defining musical modes, we
derive a formula for the total number of modes and define the musicality of a
mode as the total number of harmonic chords whithin the mode. We also give an
algorithm for the construction of a duet of melodic lines given a sequence of
numbers and a mode. We attach the .mus files of the counterpoints obtained by
using the sequence of primes and several musical modes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0598</identifier>
 <datestamp>2011-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0598</id><created>2011-03-02</created><authors><author><keyname>Daskalakis</keyname><forenames>Constantinos</forenames></author><author><keyname>Diakonikolas</keyname><forenames>Ilias</forenames></author><author><keyname>Servedio</keyname><forenames>Rocco A.</forenames></author></authors><title>Learning transformed product distributions</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of learning an unknown product distribution $X$ over
$\{0,1\}^n$ using samples $f(X)$ where $f$ is a \emph{known} transformation
function. Each choice of a transformation function $f$ specifies a learning
problem in this framework.
  Information-theoretic arguments show that for every transformation function
$f$ the corresponding learning problem can be solved to accuracy $\eps$, using
$\tilde{O}(n/\eps^2)$ examples, by a generic algorithm whose running time may
be exponential in $n.$ We show that this learning problem can be
computationally intractable even for constant $\eps$ and rather simple
transformation functions. Moreover, the above sample complexity bound is nearly
optimal for the general problem, as we give a simple explicit linear
transformation function $f(x)=w \cdot x$ with integer weights $w_i \leq n$ and
prove that the corresponding learning problem requires $\Omega(n)$ samples.
  As our main positive result we give a highly efficient algorithm for learning
a sum of independent unknown Bernoulli random variables, corresponding to the
transformation function $f(x)= \sum_{i=1}^n x_i$. Our algorithm learns to
$\eps$-accuracy in poly$(n)$ time, using a surprising poly$(1/\eps)$ number of
samples that is independent of $n.$ We also give an efficient algorithm that
uses $\log n \cdot \poly(1/\eps)$ samples but has running time that is only
$\poly(\log n, 1/\eps).$
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0605</identifier>
 <datestamp>2011-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0605</id><created>2011-03-02</created><authors><author><keyname>Watanabe</keyname><forenames>Yusuke</forenames></author><author><keyname>Fukumizu</keyname><forenames>Kenji</forenames></author></authors><title>Loopy Belief Propagation, Bethe Free Energy and Graph Zeta Function</title><categories>cs.AI cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new approach to the theoretical analysis of Loopy Belief
Propagation (LBP) and the Bethe free energy (BFE) by establishing a formula to
connect LBP and BFE with a graph zeta function. The proposed approach is
applicable to a wide class of models including multinomial and Gaussian types.
The connection derives a number of new theoretical results on LBP and BFE. This
paper focuses two of such topics. One is the analysis of the region where the
Hessian of the Bethe free energy is positive definite, which derives the
non-convexity of BFE for graphs with multiple cycles, and a condition of
convexity on a restricted set. This analysis also gives a new condition for the
uniqueness of the LBP fixed point. The other result is to clarify the relation
between the local stability of a fixed point of LBP and local minima of the
BFE, which implies, for example, that a locally stable fixed point of the
Gaussian LBP is a local minimum of the Gaussian Bethe free energy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0632</identifier>
 <datestamp>2015-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0632</id><created>2011-03-03</created><authors><author><keyname>Ouassila</keyname><forenames>Hioual</forenames></author><author><keyname>Zizette</keyname><forenames>Boufaida</forenames></author></authors><title>An Agent Based Architecture (Using Planning) for Dynamic and Semantic
  Web Services Composition in an EBXML Context</title><categories>cs.AI</categories><comments>22 pages, 11 figures, 1 table</comments><journal-ref>International Journal of Database Management Systems ( IJDMS ),
  Vol.3, No.1, February 2011 110-131</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The process-based semantic composition of Web Services is gaining a
considerable momentum as an approach for the effective integration of
distributed, heterogeneous, and autonomous applications. To compose Web
Services semantically, we need an ontology. There are several ways of inserting
semantics in Web Services. One of them consists of using description languages
like OWL-S. In this paper, we introduce our work which consists in the
proposition of a new model and the use of semantic matching technology for
semantic and dynamic composition of ebXML business processes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0633</identifier>
 <datestamp>2011-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0633</id><created>2011-03-03</created><authors><author><keyname>Dongare</keyname><forenames>Y. V.</forenames></author><author><keyname>Dhabe</keyname><forenames>P. S.</forenames></author><author><keyname>Deshmukh</keyname><forenames>S. V.</forenames></author></authors><title>RDBNorma: - A semi-automated tool for relational database schema
  normalization up to third normal form</title><categories>cs.DB</categories><comments>22 pages and international journal</comments><journal-ref>International Journal of Database Management Systems ( IJDMS ),
  Vol.3, No.1, February 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper a tool called RDBNorma is proposed, that uses a novel approach
to represent a relational database schema and its functional dependencies in
computer memory using only one linked list and used for semi-automating the
process of relational database schema normalization up to third normal form.
This paper addresses all the issues of representing a relational schema along
with its functional dependencies using one linked list along with the
algorithms to convert a relation into second and third normal form by using
above representation. We have compared performance of RDBNorma with existing
tool called Micro using standard relational schemas collected from various
resources. It is observed that proposed tool is at least 2.89 times faster than
the Micro and requires around half of the space than Micro to represent a
relation. Comparison is done by entering all the attributes and functional
dependencies holds on a relation in the same order and implementing both the
tools in same language and on same machine.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0658</identifier>
 <datestamp>2011-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0658</id><created>2011-03-03</created><authors><author><keyname>Manickam</keyname><forenames>P.</forenames></author><author><keyname>Baskar</keyname><forenames>T. Guru</forenames></author><author><keyname>Girija</keyname><forenames>M.</forenames></author><author><keyname>Manimegalai</keyname><forenames>Dr. D.</forenames></author></authors><title>Performance Comparisons of Routing Protocols in Mobile Ad Hoc Networks</title><categories>cs.NI</categories><comments>9 Pages,10 Figures, 3 Tables</comments><journal-ref>International Journal of Wireless &amp; Mobile Networks (IJWMN) Vol.
  3, No. 1, February 2011</journal-ref><doi>10.5121/ijwmn.2011.3109</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mobile Ad hoc Network (MANET) is a collection of wireless mobile nodes that
dynamically form a network temporarily without any support of central
administration. Moreover, Every node in MANET moves arbitrarily making the
multi-hop network topology to change randomly at unpredictable times. There are
several familiar routing protocols like DSDV, AODV, DSR, etc...which have been
proposed for providing communication among all the nodes in the network. This
paper presents a performance comparison of proactive and reactive protocols
DSDV, AODV and DSR based on metrics such as throughput, packet delivery ratio
and average end-to-end delay by using the NS-2 simulator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0676</identifier>
 <datestamp>2011-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0676</id><created>2011-03-03</created><authors><author><keyname>Majkic</keyname><forenames>Zoran</forenames></author></authors><title>Probabilistic Logic: Many-valuedness and Intensionality</title><categories>cs.LO</categories><comments>15 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The probability theory is a well-studied branch of mathematics, in order to
carry out formal reasoning about probability. Thus, it is important to have a
logic, both for computation of probabilities and for reasoning about
probabilities, with a well-defined syntax and semantics. Both current
approaches, based on Nilsson's probability structures/logics, and on linear
inequalities in order to reason about probabilities, have some weak points. In
this paper we have presented the complete revision of both approaches. We have
shown that the full embedding of Nilsson'probabilistic structure into
propositional logic results in a truth-functional many-valued logic,
differently from Nilsson's intuition and current considerations about
propositional probabilistic logic. Than we have shown that the logic for
reasoning about probabilities can be naturally embedded into a 2-valued
intensional FOL with intensional abstraction, by avoiding current ad-hoc system
composed of two different 2-valued logics: one for the classical propositional
logic at lower-level, and a new one at higher-level for probabilistic
constraints with probabilistic variables. The obtained theoretical results are
applied to Probabilistic Logic Programming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0680</identifier>
 <datestamp>2011-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0680</id><created>2011-03-03</created><authors><author><keyname>Majkic</keyname><forenames>Zoran</forenames></author></authors><title>First-order Logic: Modality and Intensionality</title><categories>cs.LO cs.GL cs.IT math.IT</categories><comments>33 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Contemporary use of the term 'intension' derives from the traditional logical
Frege-Russell's doctrine that an idea (logic formula) has both an extension and
an intension. From the Montague's point of view, the meaning of an idea can be
considered as particular extensions in different possible worlds. In this paper
we analyze the minimal intensional semantic enrichment of the syntax of the FOL
language, by unification of different views: Tarskian extensional semantics of
the FOL, modal interpretation of quantifiers, and a derivation of the Tarskian
theory of truth from unified semantic theory based on a single meaning
relation. We show that not all modal predicate logics are intensional, and that
an equivalent modal Kripke's interpretation of logic quantifiers in FOL results
in a particular pure extensional modal predicate logic (as is the standard
Tarskian semantics of the FOL). This minimal intensional enrichment is obtained
by adopting the theory of properties, relations and propositions (PRP) as the
universe or domain of the FOL, composed by particulars and universals (or
concepts), with the two-step interpretation of the FOL that eliminates the weak
points of the Montague's intensional semantics. Differently from the Bealer's
intensional FOL, we show that it is not necessary the introduction of the
intensional abstraction in order to obtain the full intensional properties of
the FOL. Final result of this paper is represented by the commutative
homomorphic diagram that holds in each given possible world of this new
intensional FOL, from the free algebra of the FOL syntax, toward its
intensional algebra of concepts, and, successively, to the new extensional
relational algebra (different from Cylindric algebras), and we show that it
corresponds to the Tarski's interpretation of the standard extensional FOL in
this possible world.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0686</identifier>
 <datestamp>2011-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0686</id><created>2011-03-03</created><authors><author><keyname>Mkaouar</keyname><forenames>Mohamed</forenames></author><author><keyname>Bouaziz</keyname><forenames>Rafik</forenames></author><author><keyname>Moalla</keyname><forenames>Mohamed</forenames></author></authors><title>Querying and Manipulating Temporal Databases</title><categories>cs.DB</categories><journal-ref>International Journal of Database Management Systems (IJDMS),
  February 2011, Volume 3, Number 1</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many works have focused, for over twenty five years, on the integration of
the time dimension in databases (DB). However, the standard SQL3 does not yet
allow easy definition, manipulation and querying of temporal DBs. In this
paper, we study how we can simplify querying and manipulating temporal facts in
SQL3, using a model that integrates time in a native manner. To do this, we
propose new keywords and syntax to define different temporal versions for many
relational operators and functions used in SQL. It then becomes possible to
perform various queries and updates appropriate to temporal facts. We
illustrate the use of these proposals on many examples from a real application.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0697</identifier>
 <datestamp>2011-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0697</id><created>2011-03-03</created><authors><author><keyname>Walker</keyname><forenames>Adrian</forenames></author></authors><title>A Wiki for Business Rules in Open Vocabulary, Executable English</title><categories>cs.AI</categories><comments>9 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of business-IT alignment is of widespread economic concern.
  As one way of addressing the problem, this paper describes an online system
that functions as a kind of Wiki -- one that supports the collaborative writing
and running of business and scientific applications, as rules in open
vocabulary, executable English, using a browser.
  Since the rules are in English, they are indexed by Google and other search
engines. This is useful when looking for rules for a task that one has in mind.
  The design of the system integrates the semantics of data, with a semantics
of an inference method, and also with the meanings of English sentences. As
such, the system has functionality that may be useful for the Rules, Logic,
Proof and Trust requirements of the Semantic Web.
  The system accepts rules, and small numbers of facts, typed or copy-pasted
directly into a browser. One can then run the rules, again using a browser. For
larger amounts of data, the system uses information in the rules to
automatically generate and run SQL over networked databases. From a few highly
declarative rules, the system typically generates SQL that would be too
complicated to write reliably by hand. However, the system can explain its
results in step-by-step hypertexted English, at the business or scientific
level
  As befits a Wiki, shared use of the system is free.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0701</identifier>
 <datestamp>2014-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0701</id><created>2011-03-02</created><updated>2011-08-09</updated><authors><author><keyname>Squartini</keyname><forenames>Tiziano</forenames></author><author><keyname>Garlaschelli</keyname><forenames>Diego</forenames></author></authors><title>Analytical maximum-likelihood method to detect patterns in real networks</title><categories>physics.data-an cs.SI physics.soc-ph</categories><comments>26 pages, 10 figures</comments><journal-ref>New J. Phys. 13, 083001 (2011)</journal-ref><doi>10.1088/1367-2630/13/8/083001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In order to detect patterns in real networks, randomized graph ensembles that
preserve only part of the topology of an observed network are systematically
used as fundamental null models. However, their generation is still
problematic. The existing approaches are either computationally demanding and
beyond analytic control, or analytically accessible but highly approximate.
Here we propose a solution to this long-standing problem by introducing an
exact and fast method that allows to obtain expectation values and standard
deviations of any topological property analytically, for any binary, weighted,
directed or undirected network. Remarkably, the time required to obtain the
expectation value of any property is as short as that required to compute the
same property on the single original network. Our method reveals that the null
behavior of various correlation properties is different from what previously
believed, and highly sensitive to the particular network considered. Moreover,
our approach shows that important structural properties (such as the modularity
used in community detection problems) are currently based on incorrect
expressions, and provides the exact quantities that should replace them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0711</identifier>
 <datestamp>2012-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0711</id><created>2011-03-03</created><updated>2012-06-21</updated><authors><author><keyname>Piccioni</keyname><forenames>Marco</forenames></author><author><keyname>Oriol</keyname><forenames>Manuel</forenames></author><author><keyname>Meyer</keyname><forenames>Bertrand</forenames></author></authors><title>Class Schema Evolution for Persistent Object-Oriented Software: Model,
  Empirical Study, and Automated Support</title><categories>cs.SE cs.DB</categories><comments>14 pages, to appear in IEEE Transactions on Software Engineering
  (TSE)</comments><doi>10.1109/TSE.2011.123</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the wide support for object serialization in object-oriented programming
languages, persistent objects have become common place and most large
object-oriented software systems rely on extensive amounts of persistent data.
Such systems also evolve over time. Retrieving previously persisted objects
from classes whose schema has changed is however difficult, and may lead to
invalidating the consistency of the application. The ESCHER framework addresses
these issues through an IDE-integrated approach that handles class schema
evolution by managing versions of the code and generating transformation
functions automatically. The infrastructure also enforces class invariants to
prevent the introduction of potentially corrupt objects. This article describes
a model for class attribute changes, a measure for class evolution robustness,
four empirical studies, and the design and implementation of the ESCHER system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0733</identifier>
 <datestamp>2011-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0733</id><created>2011-03-03</created><authors><author><keyname>Banaszuk</keyname><forenames>Andrzej</forenames></author><author><keyname>Fonoberov</keyname><forenames>Vladimir A.</forenames></author><author><keyname>Frewen</keyname><forenames>Thomas A.</forenames></author><author><keyname>Kobilarov</keyname><forenames>Marin</forenames></author><author><keyname>Mathew</keyname><forenames>George</forenames></author><author><keyname>Mezic</keyname><forenames>Igor</forenames></author><author><keyname>Pinto</keyname><forenames>Alessandro</forenames></author><author><keyname>Sahai</keyname><forenames>Tuhin</forenames></author><author><keyname>Sane</keyname><forenames>Harshad</forenames></author><author><keyname>Speranzon</keyname><forenames>Alberto</forenames></author><author><keyname>Surana</keyname><forenames>Amit</forenames></author></authors><title>Scalable Approach to Uncertainty Quantification and Robust Design of
  Interconnected Dynamical Systems</title><categories>cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Development of robust dynamical systems and networks such as autonomous
aircraft systems capable of accomplishing complex missions faces challenges due
to the dynamically evolving uncertainties coming from model uncertainties,
necessity to operate in a hostile cluttered urban environment, and the
distributed and dynamic nature of the communication and computation resources.
Model-based robust design is difficult because of the complexity of the hybrid
dynamic models including continuous vehicle dynamics, the discrete models of
computations and communications, and the size of the problem. We will overview
recent advances in methodology and tools to model, analyze, and design robust
autonomous aerospace systems operating in uncertain environment, with stress on
efficient uncertainty quantification and robust design using the case studies
of the mission including model-based target tracking and search, and trajectory
planning in uncertain urban environment. To show that the methodology is
generally applicable to uncertain dynamical systems, we will also show examples
of application of the new methods to efficient uncertainty quantification of
energy usage in buildings, and stability assessment of interconnected power
networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0738</identifier>
 <datestamp>2011-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0738</id><created>2011-03-03</created><authors><author><keyname>Bag</keyname><forenames>Soumen</forenames></author><author><keyname>Harit</keyname><forenames>Gaurav</forenames></author></authors><title>A Medial Axis Based Thinning Strategy for Character Images</title><categories>cs.CV cs.DL</categories><comments>6 pages, 5 figures. In proceedings of the second National Conference
  on Computer Vision, Pattern Recognition, Image Processing and Graphics
  (NCVPRIPG), pp. 67-72, Jaipur, India, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Thinning of character images is a big challenge. Removal of strokes or
deformities in thinning is a difficult problem. In this paper, we have proposed
a medial axis based thinning strategy used for performing skeletonization of
printed and handwritten character images. In this method, we have used shape
characteristics of text to get skeleton of nearly same as the true character
shape. This approach helps to preserve the local features and true shape of the
character images. The proposed algorithm produces one pixel width thin
skeleton. As a by-product of our thinning approach, the skeleton also gets
segmented into strokes in vector form. Hence further stroke segmentation is not
required. Experiment is done on printed English and Bengali characters and we
obtain less spurious branches comparing with other thinning methods without any
post processing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0741</identifier>
 <datestamp>2011-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0741</id><created>2011-03-03</created><authors><author><keyname>Clementi</keyname><forenames>Andrea</forenames></author><author><keyname>Monti</keyname><forenames>Angelo</forenames></author><author><keyname>Pasquale</keyname><forenames>Francesco</forenames></author><author><keyname>Silvestri</keyname><forenames>Riccardo</forenames></author></authors><title>Information Spreading in Stationary Markovian Evolving Graphs</title><categories>cs.DM</categories><comments>16 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Markovian evolving graphs are dynamic-graph models where the links among a
fixed set of nodes change during time according to an arbitrary Markovian rule.
They are extremely general and they can well describe important dynamic-network
scenarios.
  We study the speed of information spreading in the &quot;stationary phase&quot; by
analyzing the completion time of the &quot;flooding mechanism&quot;. We prove a general
theorem that establishes an upper bound on flooding time in any stationary
Markovian evolving graph in terms of its node-expansion properties.
  We apply our theorem in two natural and relevant cases of such dynamic
graphs. &quot;Geometric Markovian evolving graphs&quot; where the Markovian behaviour is
yielded by &quot;n&quot; mobile radio stations, with fixed transmission radius, that
perform independent random walks over a square region of the plane.
&quot;Edge-Markovian evolving graphs&quot; where the probability of existence of any edge
at time &quot;t&quot; depends on the existence (or not) of the same edge at time &quot;t-1&quot;.
  In both cases, the obtained upper bounds hold &quot;with high probability&quot; and
they are nearly tight. In fact, they turn out to be tight for a large range of
the values of the input parameters. As for geometric Markovian evolving graphs,
our result represents the first analytical upper bound for flooding time on a
class of concrete mobile networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0744</identifier>
 <datestamp>2011-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0744</id><created>2011-03-03</created><authors><author><keyname>Materassi</keyname><forenames>D.</forenames></author><author><keyname>Innocenti</keyname><forenames>G.</forenames></author><author><keyname>Giarr&#xe9;</keyname><forenames>L.</forenames></author><author><keyname>Salapaka</keyname><forenames>M.</forenames></author></authors><title>Model Identification of a Network as Compressing Sensing</title><categories>math.DS cs.SY math.GN math.OC</categories><comments>the paper has been submitted to System and Control letters</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many applications, it is important to derive information about the
topology and the internal connections of dynamical systems interacting
together. Examples can be found in fields as diverse as Economics, Neuroscience
and Biochemistry. The paper deals with the problem of deriving a descriptive
model of a network, collecting the node outputs as time series with no use of a
priori insight on the topology, and unveiling an unknown structure as the
estimate of a &quot;sparse Wiener filter&quot;. A geometric interpretation of the problem
in a pre-Hilbert space for wide-sense stochastic processes is provided. We cast
the problem as the optimization of a cost function where a set of parameters
are used to operate a trade-off between accuracy and complexity in the final
model. The problem of reducing the complexity is addressed by fixing a certain
degree of sparsity and finding the solution that &quot;better&quot; satisfies the
constraints according to the criterion of approximation. Applications starting
from real data and numerical simulations are provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0759</identifier>
 <datestamp>2011-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0759</id><created>2011-03-03</created><authors><author><keyname>Zhou</keyname><forenames>Fangfei</forenames></author><author><keyname>Goel</keyname><forenames>Manish</forenames></author><author><keyname>Desnoyers</keyname><forenames>Peter</forenames></author><author><keyname>Sundaram</keyname><forenames>Ravi</forenames></author></authors><title>Scheduler Vulnerabilities and Attacks in Cloud Computing</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In hardware virtualization a hypervisor provides multiple Virtual Machines
(VMs) on a single physical system, each executing a separate operating system
instance. The hypervisor schedules execution of these VMs much as the scheduler
in an operating system does, balancing factors such as fairness and I/O
performance. As in an operating system, the scheduler may be vulnerable to
malicious behavior on the part of users seeking to deny service to others or
maximize their own resource usage.
  Recently, publically available cloud computing services such as Amazon EC2
have used virtualization to provide customers with virtual machines running on
the provider's hardware, typically charging by wall clock time rather than
resources consumed. Under this business model, manipulation of the scheduler
may allow theft of service at the expense of other customers, rather than
merely reallocating resources within the same administrative domain.
  We describe a flaw in the Xen scheduler allowing virtual machines to consume
almost all CPU time, in preference to other users, and demonstrate kernel-based
and user-space versions of the attack. We show results demonstrating the
vulnerability in the lab, consuming as much as 98% of CPU time regardless of
fair share, as well as on Amazon EC2, where Xen modifications protect other
users but still allow theft of service. In case of EC2, following the
responsible disclosure model, we have reported this vulnerability to Amazon;
they have since implemented a fix that we have tested and verified (See
Appendix B). We provide a novel analysis of the necessary conditions for such
attacks, and describe scheduler modifications to eliminate the vulnerability.
  We present experimental results demonstrating the effectiveness of these
defenses while imposing negligible overhead.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0769</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0769</id><created>2011-03-03</created><updated>2011-09-06</updated><authors><author><keyname>Kekatos</keyname><forenames>Vassilis</forenames></author><author><keyname>Giannakis</keyname><forenames>Georgios B.</forenames></author></authors><title>Sparse Volterra and Polynomial Regression Models: Recoverability and
  Estimation</title><categories>cs.LG cs.IT math.IT stat.ML</categories><comments>20 pages, to appear in IEEE Trans. on Signal Processing</comments><doi>10.1109/TSP.2011.2165952</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Volterra and polynomial regression models play a major role in nonlinear
system identification and inference tasks. Exciting applications ranging from
neuroscience to genome-wide association analysis build on these models with the
additional requirement of parsimony. This requirement has high interpretative
value, but unfortunately cannot be met by least-squares based or kernel
regression methods. To this end, compressed sampling (CS) approaches, already
successful in linear regression settings, can offer a viable alternative. The
viability of CS for sparse Volterra and polynomial models is the core theme of
this work. A common sparse regression task is initially posed for the two
models. Building on (weighted) Lasso-based schemes, an adaptive RLS-type
algorithm is developed for sparse polynomial regressions. The identifiability
of polynomial models is critically challenged by dimensionality. However,
following the CS principle, when these models are sparse, they could be
recovered by far fewer measurements. To quantify the sufficient number of
measurements for a given level of sparsity, restricted isometry properties
(RIP) are investigated in commonly met polynomial regression settings,
generalizing known results for their linear counterparts. The merits of the
novel (weighted) adaptive CS algorithms to sparse polynomial modeling are
verified through synthetic as well as real data tests for genotype-phenotype
analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0784</identifier>
 <datestamp>2011-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0784</id><created>2011-03-03</created><authors><author><keyname>Bollen</keyname><forenames>Johan</forenames></author><author><keyname>Goncalves</keyname><forenames>Bruno</forenames></author><author><keyname>Ruan</keyname><forenames>Guangchen</forenames></author><author><keyname>Mao</keyname><forenames>Huina</forenames></author></authors><title>Happiness is assortative in online social networks</title><categories>cs.SI cs.CL physics.soc-ph</categories><comments>17 pages, 9 figures</comments><journal-ref>Artificial Life 17(3), 237-251 (2011)</journal-ref><doi>10.1162/artl_a_00034</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Social networks tend to disproportionally favor connections between
individuals with either similar or dissimilar characteristics. This propensity,
referred to as assortative mixing or homophily, is expressed as the correlation
between attribute values of nearest neighbour vertices in a graph. Recent
results indicate that beyond demographic features such as age, sex and race,
even psychological states such as &quot;loneliness&quot; can be assortative in a social
network. In spite of the increasing societal importance of online social
networks it is unknown whether assortative mixing of psychological states takes
place in situations where social ties are mediated solely by online networking
services in the absence of physical contact. Here, we show that general
happiness or Subjective Well-Being (SWB) of Twitter users, as measured from a 6
month record of their individual tweets, is indeed assortative across the
Twitter social network. To our knowledge this is the first result that shows
assortative mixing in online networks at the level of SWB. Our results imply
that online social networks may be equally subject to the social mechanisms
that cause assortative mixing in real social networks and that such assortative
mixing takes place at the level of SWB. Given the increasing prevalence of
online social networks, their propensity to connect users with similar levels
of SWB may be an important instrument in better understanding how both positive
and negative sentiments spread through online social ties. Future research may
focus on how event-specific mood states can propagate and influence user
behavior in &quot;real life&quot;.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0795</identifier>
 <datestamp>2011-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0795</id><created>2011-03-03</created><authors><author><keyname>Planjery</keyname><forenames>Shiva Kumar</forenames></author><author><keyname>Vasic</keyname><forenames>Bane</forenames></author><author><keyname>Declercq</keyname><forenames>David</forenames></author></authors><title>Decimation-Enhanced Finite Alphabet Iterative Decoders for LDPC codes on
  the BSC</title><categories>cs.IT math.IT</categories><comments>5 pages, 2 figures, submitted to ISIT 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Finite alphabet iterative decoders (FAID) with multilevel messages that can
surpass BP in the error floor region for LDPC codes on the BSC were previously
proposed. In this paper, we propose decimation-enhanced decoders. The technique
of decimation which is incorporated into the message update rule, involves
fixing certain bits of the code to a particular value. Under appropriately
chosen rules, decimation can significantly reduce the number of iterations
required to correct a fixed number of errors, while maintaining the good
performance of the original decoder in the error floor region. At the same
time, the algorithm is much more amenable to analysis. We shall provide a
simple decimation scheme for a particularly good 7-level FAID for column-weight
three codes on the BSC, that helps to correct a fixed number of errors in fewer
iterations, and provide insights into the analysis of the decoder. We shall
also examine the conditions under which the decimation-enhanced 7-level FAID
performs at least as good as the 7-level FAID.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0800</identifier>
 <datestamp>2011-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0800</id><created>2011-03-03</created><updated>2011-05-05</updated><authors><author><keyname>Jha</keyname><forenames>Susmit</forenames></author><author><keyname>Seshia</keyname><forenames>Sanjit A.</forenames></author><author><keyname>Tiwari</keyname><forenames>Ashish</forenames></author></authors><title>Synthesizing Switching Logic to Minimize Long-Run Cost</title><categories>cs.SY math.OC</categories><comments>UC Berkeley Technical Report</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Given a multi-modal dynamical system, optimal switching logic synthesis
involves generating the conditions for switching between the system modes such
that the resulting hybrid system satisfies a quantitative specification. We
formalize and solve the problem of optimal switching logic synthesis for
quantitative specifications over long run behavior. Each trajectory of the
system, and each state of the system, is associated with a cost. Our goal is to
synthesize a system that minimizes this cost from each initial state. Our paper
generalizes earlier work on synthesis for safety as safety specifications can
be encoded as quantitative specifications. We present an approach for
specifying quantitative measures using reward and penalty functions, and
illustrate its effectiveness using several examples. We present an automated
technique to synthesize switching logic for such quantitative measures. Our
algorithm is based on reducing the synthesis problem to an unconstrained
numerical optimization problem which can be solved by any off-the-shelf
numerical optimization engines. We demonstrate the effectiveness of this
approach with experimental results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0801</identifier>
 <datestamp>2011-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0801</id><created>2011-03-03</created><authors><author><keyname>Nguyen</keyname><forenames>Dung Viet</forenames></author><author><keyname>Vasic</keyname><forenames>Bane</forenames></author><author><keyname>Marcellin</keyname><forenames>Michael W.</forenames></author></authors><title>Two-Bit Bit Flipping Decoding of LDPC Codes</title><categories>cs.IT math.IT</categories><comments>6 pages. Submitted to IEEE International Symposium on Information
  Theory 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a new class of bit flipping algorithms for
low-density parity-check (LDPC) codes over the binary symmetric channel (BSC).
Compared to the regular (parallel or serial) bit flipping algorithms, the
proposed algorithms employ one additional bit at a variable node to represent
its &quot;strength.&quot; The introduction of this additional bit increases the
guaranteed error correction capability by a factor of at least 2. An additional
bit can also be employed at a check node to capture information which is
beneficial to decoding. A framework for failure analysis of the proposed
algorithms is described. These algorithms outperform the Gallager A/B algorithm
and the min-sum algorithm at much lower complexity. Concatenation of two-bit
bit flipping algorithms show a potential to approach the performance of belief
propagation (BP) decoding in the error floor region, also at lower complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0812</identifier>
 <datestamp>2011-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0812</id><created>2011-03-03</created><authors><author><keyname>Zhou</keyname><forenames>Neng-Fa</forenames></author></authors><title>The Language Features and Architecture of B-Prolog</title><categories>cs.PL</categories><comments>30 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  B-Prolog is a high-performance implementation of the standard Prolog language
with several extensions including matching clauses, action rules for event
handling, finite-domain constraint solving, arrays and hash tables, declarative
loop constructs, and tabling. The B-Prolog system is based on the TOAM
architecture which differs from the WAM mainly in that (1) arguments are passed
old-fashionedly through the stack, (2) only one frame is used for each
predicate call, and (3) instructions are provided for encoding matching trees.
The most recent architecture, called TOAM Jr., departs further from the WAM in
that it employs no registers for arguments or temporary variables, and provides
variable-size instructions for encoding predicate calls. This paper gives an
overview of the language features and a detailed description of the TOAM Jr.
architecture, including architectural support for action rules and tabling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0825</identifier>
 <datestamp>2011-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0825</id><created>2011-03-04</created><authors><author><keyname>Cormode</keyname><forenames>Graham</forenames></author><author><keyname>Procopiuc</keyname><forenames>Magda</forenames></author><author><keyname>Srivastava</keyname><forenames>Divesh</forenames></author><author><keyname>Tran</keyname><forenames>Thanh T. L.</forenames></author></authors><title>Differentially Private Publication of Sparse Data</title><categories>cs.DB</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The problem of privately releasing data is to provide a version of a dataset
without revealing sensitive information about the individuals who contribute to
the data. The model of differential privacy allows such private release while
providing strong guarantees on the output. A basic mechanism achieves
differential privacy by adding noise to the frequency counts in the contingency
tables (or, a subset of the count data cube) derived from the dataset. However,
when the dataset is sparse in its underlying space, as is the case for most
multi-attribute relations, then the effect of adding noise is to vastly
increase the size of the published data: it implicitly creates a huge number of
dummy data points to mask the true data, making it almost impossible to work
with.
  We present techniques to overcome this roadblock and allow efficient private
release of sparse data, while maintaining the guarantees of differential
privacy. Our approach is to release a compact summary of the noisy data.
Generating the noisy data and then summarizing it would still be very costly,
so we show how to shortcut this step, and instead directly generate the summary
from the input data, without materializing the vast intermediate noisy data. We
instantiate this outline for a variety of sampling and filtering methods, and
show how to use the resulting summary for approximate, private, query
answering. Our experimental study shows that this is an effective, practical
solution, with comparable and occasionally improved utility over the costly
materialization approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0829</identifier>
 <datestamp>2011-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0829</id><created>2011-03-04</created><authors><author><keyname>Sahoo</keyname><forenames>G.</forenames></author><author><keyname>Tiwari</keyname><forenames>Rajesh Kumar</forenames></author></authors><title>Hiding Secret Information in Movie Clip: A Steganographic Approach</title><categories>cs.MM cs.CR</categories><comments>Steganography, Frame, Stego-Frame, Stego-key, and Carrier</comments><acm-class>F.2.2; I.2.7</acm-class><journal-ref>International Journal of Computing and Applications, Vol. 4, No.
  1, June 2009, pp. 87-94</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Establishing hidden communication is an important subject of discussion that
has gained increasing importance nowadays with the development of the internet.
One of the key methods for establishing hidden communication is steganography.
Modern day steganography mainly deals with hiding information within files like
image, text, html, binary files etc. These file contains small irrelevant
information that can be substituted for small secret data. To store a high
capacity secret data these carrier files are not very supportive. To overcome
the problem of storing the high capacity secret data with the utmost security
fence, we have proposed a novel methodology for concealing a voluminous data
with high levels of security wall by using movie clip as a carrier file.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0837</identifier>
 <datestamp>2011-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0837</id><created>2011-03-04</created><authors><author><keyname>Chowdhury</keyname><forenames>Mostafa Zaman</forenames></author><author><keyname>Jang</keyname><forenames>Yeong Min</forenames></author></authors><title>Priority based Interface Selection for Overlaying Heterogeneous Networks</title><categories>cs.MM cs.NI</categories><comments>7 pages, 7 figures</comments><journal-ref>The Journal of Korea Information and Communications Soceity
  (KICS,), Vol. 35, No. 7, July 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Offering of different attractive opportunities by different wireless
technologies trends the convergence of heterogeneous networks for the future
wireless communication system. To make a seamless handover among the
heterogeneous networks, the optimization of the power consumption, and optimal
selection of interface are the challenging issues for convergence networks. The
access of multi interfaces simultaneously reduces the handover latency and data
loss in heterogeneous handover. The mobile node (MN) maintains one interface
connection while other interface is used for handover process. However, it
causes much battery power consumption. In this paper we propose an efficient
interface selection scheme including interface selection algorithms, interface
selection procedures considering battery power consumption and user mobility
with other existing parameters for overlaying networks. We also propose a
priority based network selection scheme according to the service types. MN's
battery power level, provision of QoS/QoE in the target network and our
proposed priority parameters are considered as more important parameters for
our interface selection algorithm. The performances of the proposed scheme are
verified using numerical analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0842</identifier>
 <datestamp>2011-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0842</id><created>2011-03-04</created><authors><author><keyname>Belovs</keyname><forenames>Aleksandrs</forenames></author></authors><title>Span-program-based quantum algorithm for the rank problem</title><categories>quant-ph cs.DS</categories><comments>18 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, span programs have been shown to be equivalent to quantum query
algorithms. It is an open problem whether this equivalence can be utilized in
order to come up with new quantum algorithms. We address this problem by
providing span programs for some linear algebra problems.
  We develop a notion of a high level span program, that abstracts from loading
input vectors into a span program. Then we give a high level span program for
the rank problem. The last section of the paper deals with reducing a high
level span program to an ordinary span program that can be solved using known
quantum query algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0843</identifier>
 <datestamp>2013-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0843</id><created>2011-03-04</created><updated>2013-06-03</updated><authors><author><keyname>Banaei</keyname><forenames>Armin</forenames></author><author><keyname>Georghiades</keyname><forenames>Costas N.</forenames></author><author><keyname>Cui</keyname><forenames>Shuguang</forenames></author></authors><title>Large Overlaid Cognitive Radio Networks: From Throughput Scaling to
  Asymptotic Multiplexing Gain</title><categories>cs.NI</categories><comments>29 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the asymptotic performance of two multi-hop overlaid ad-hoc networks
that utilize the same temporal, spectral, and spatial resources based on random
access schemes. The primary network consists of Poisson distributed legacy
users with density \lambda^{(p)} and the secondary network consists of Poisson
distributed cognitive radio users with density \lambda^{(s)} =
(\lambda^{(p)})^{\beta} (\beta&gt;0, \beta \neq 1) that utilize the spectrum
opportunistically. Both networks are decentralized and employ ALOHA medium
access protocols where the secondary nodes are additionally equipped with
range-limited perfect spectrum sensors to monitor and protect primary
transmissions. We study the problem in two distinct regimes, namely \beta&gt;1 and
0&lt;\beta&lt;1. We show that in both cases, the two networks can achieve their
corresponding stand-alone throughput scaling even without secondary spectrum
sensing (i.e., the sensing range set to zero); this implies the need for a more
comprehensive performance metric than just throughput scaling to evaluate the
influence of the overlaid interactions. We thus introduce a new criterion,
termed the asymptotic multiplexing gain, which captures the effect of
inter-network interferences with different spectrum sensing setups. With this
metric, we clearly demonstrate that spectrum sensing can substantially improve
primary network performance when \beta&gt;1. On the contrary, spectrum sensing
turns out to be unnecessary when \beta&lt;1 and setting the secondary network's
ALOHA parameter appropriately can substantially improve primary network
performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0853</identifier>
 <datestamp>2011-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0853</id><created>2011-03-04</created><authors><author><keyname>Meier</keyname><forenames>Arne</forenames></author><author><keyname>Schneider</keyname><forenames>Thomas</forenames></author></authors><title>Generalized Satisfiability for the Description Logic ALC</title><categories>cs.LO cs.CC</categories><comments>Technical Report with complete Proofs, Conference Version appeared in
  TAMC2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The standard reasoning problem, concept satisfiability, in the basic
description logic ALC is PSPACE-complete, and it is EXPTIME-complete in the
presence of unrestricted axioms. Several fragments of ALC, notably logics in
the FL, EL, and DL-Lite families, have an easier satisfiability problem;
sometimes it is even tractable. We classify the complexity of the standard
satisfiability problems for all possible Boolean and quantifier fragments of
ALC in the presence of general axioms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0868</identifier>
 <datestamp>2013-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0868</id><created>2011-03-04</created><updated>2013-11-22</updated><authors><author><keyname>Freixas</keyname><forenames>Josep</forenames></author><author><keyname>Kurz</keyname><forenames>Sascha</forenames></author></authors><title>On minimum integer representations of weighted games</title><categories>math.CO cs.GT</categories><comments>29 pages</comments><msc-class>91A12, 90C11</msc-class><doi>10.1016/j.mathsocsci.2013.10.005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study minimum integer representations of weighted games, i.e.,
representations where the weights are integers and every other integer
representation is at least as large in each component. Those minimum integer
representations, if the exist at all, are linked with some solution concepts in
game theory. Closing existing gaps in the literature, we prove that each
weighted game with two types of voters admits a (unique) minimum integer
representation, and give new examples for more than two types of voters without
a minimum integer representation. We characterize the possible weights in
minimum integer representations and give examples for $t\ge 4$ types of voters
without a minimum integer representation preserving types, i.e., where we
additionally require that the weights are equal within equivalence classes of
voters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0875</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0875</id><created>2011-03-04</created><authors><author><keyname>Sharif</keyname><forenames>Behzad</forenames></author><author><keyname>Bresler</keyname><forenames>Yoram</forenames></author></authors><title>Generic Feasibility of Perfect Reconstruction with Short FIR Filters in
  Multi-channel Systems</title><categories>cs.IT math.IT math.NA math.PR</categories><comments>Manuscript submitted to IEEE Transactions on Signal Processing</comments><doi>10.1109/TSP.2011.2166550</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the feasibility of short finite impulse response (FIR) synthesis for
perfect reconstruction (PR) in generic FIR filter banks. Among all PR synthesis
banks, we focus on the one with the minimum filter length. For filter banks
with oversampling factors of at least two, we provide prescriptions for the
shortest filter length of the synthesis bank that would guarantee PR almost
surely. The prescribed length is as short or shorter than the analysis filters
and has an approximate inverse relationship with the oversampling factor. Our
results are in form of necessary and sufficient statements that hold
generically, hence only fail for elaborately-designed nongeneric examples. We
provide extensive numerical verification of the theoretical results and
demonstrate that the gap between the derived filter length prescriptions and
the true minimum is small. The results have potential applications in synthesis
FB design problems, where the analysis bank is given, and for analysis of
fundamental limitations in blind signals reconstruction from data collected by
unknown subsampled multi-channel systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0890</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0890</id><created>2011-03-04</created><updated>2013-05-04</updated><authors><author><keyname>Mao</keyname><forenames>Qi</forenames></author><author><keyname>Tsang</keyname><forenames>Ivor W.</forenames></author></authors><title>Efficient Multi-Template Learning for Structured Prediction</title><categories>cs.LG cs.CL</categories><journal-ref>Efficient Multi-Template Learning for Structured Prediction. IEEE
  Transactions on Neural Networks and Learning Systems, 24(2): 248 - 261, Feb
  2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Conditional random field (CRF) and Structural Support Vector Machine
(Structural SVM) are two state-of-the-art methods for structured prediction
which captures the interdependencies among output variables. The success of
these methods is attributed to the fact that their discriminative models are
able to account for overlapping features on the whole input observations. These
features are usually generated by applying a given set of templates on labeled
data, but improper templates may lead to degraded performance. To alleviate
this issue, in this paper, we propose a novel multiple template learning
paradigm to learn structured prediction and the importance of each template
simultaneously, so that hundreds of arbitrary templates could be added into the
learning model without caution. This paradigm can be formulated as a special
multiple kernel learning problem with exponential number of constraints. Then
we introduce an efficient cutting plane algorithm to solve this problem in the
primal, and its convergence is presented. We also evaluate the proposed
learning paradigm on two widely-studied structured prediction tasks,
\emph{i.e.} sequence labeling and dependency parsing. Extensive experimental
results show that the proposed method outperforms CRFs and Structural SVMs due
to exploiting the importance of each template. Our complexity analysis and
empirical results also show that our proposed method is more efficient than
OnlineMKL on very sparse and high-dimensional data. We further extend this
paradigm for structured prediction using generalized $p$-block norm
regularization with $p&gt;1$, and experiments show competitive performances when
$p \in [1,2)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0895</identifier>
 <datestamp>2011-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0895</id><created>2011-03-04</created><authors><author><keyname>Aubrun</keyname><forenames>Nathalie</forenames></author><author><keyname>Sablik</keyname><forenames>Mathieu</forenames></author></authors><title>Multidimensional effective S-adic systems are sofic</title><categories>cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article we prove that multidimensional effective S-adic systems,
obtained by applying an effective sequence of substitutions chosen among a
finite set of substitutions, are sofic subshifts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0920</identifier>
 <datestamp>2011-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0920</id><created>2011-03-04</created><authors><author><keyname>Majkic</keyname><forenames>Zoran</forenames></author></authors><title>Reduction of Many-valued into Two-valued Modal Logics</title><categories>cs.LO cs.IT math.IT</categories><comments>27 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we develop a 2-valued reduction of many-valued logics, into
2-valued multi-modal logics. Such an approach is based on the contextualization
of many-valued logics with the introduction of higher-order Herbrand
interpretation types, where we explicitly introduce the coexistence of a set of
algebraic truth values of original many-valued logic, transformed as parameters
(or possible worlds), and the set of classic two logic values. This approach is
close to the approach used in annotated logics, but offers the possibility of
using the standard semantics based on Herbrand interpretations. Moreover, it
uses the properties of the higher-order Herbrand types, as their fundamental
nature is based on autoreferential Kripke semantics where the possible worlds
are algebraic truth-values of original many-valued logic. This autoreferential
Kripke semantics, which has the possibility of flattening higher-order Herbrand
interpretations into ordinary 2-valued Herbrand interpretations, gives us a
clearer insight into the relationship between many-valued and 2-valued
multi-modal logics. This methodology is applied to the class of many-valued
Logic Programs, where reduction is done in a structural way, based on the logic
structure (logic connectives) of original many-valued logics. Following this,
we generalize the reduction to general structural many-valued logics, in an
abstract way, based on Suszko's informal non-constructive idea. In all cases,
by using developed 2-valued reductions we obtain a kind of non truth-valued
modal meta-logics, where two-valued formulae are modal sentences obtained by
application of particular modal operators to original many-valued formulae.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0921</identifier>
 <datestamp>2011-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0921</id><created>2011-03-03</created><authors><author><keyname>Limam</keyname><forenames>Hela</forenames></author><author><keyname>Akaichi</keyname><forenames>Jalel</forenames></author></authors><title>Managing and Querying Web Services Communities: A Survey</title><categories>cs.DB</categories><comments>16 pages, 2 figures</comments><journal-ref>International Journal of Database Management Systems ( IJDMS ),
  Vol.3, No.1, February 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the advance of Web Services technologies and the emergence of Web
Services into the information space, tremendous opportunities for empowering
users and organizations appear in various application domains including
electronic commerce, travel, intelligence information gathering and analysis,
health care, digital government, etc. However, the technology to organize,
search, integrate these Web Services has not kept pace with the rapid growth of
the available information space. The number of Web Services to be integrated
may be large and continuously changing. To ease and improve the process of Web
services discovery in an open environment like the Internet, it is suggested to
gather similar Web services into groups known as communities. Although Web
services are intensively investigated, the community management issues have not
been addressed yet In this paper we draw an overview of several Web services
Communities' management approaches based on some currently existing communities
platforms and frameworks. We also discuss different approaches for querying and
selecting Web services under the umbrella of Web services communities'. We
compare the current approaches among each others with respect to some key
requirements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0941</identifier>
 <datestamp>2011-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0941</id><created>2011-03-04</created><authors><author><keyname>McDonald</keyname><forenames>Daniel J.</forenames><affiliation>Carnegie Mellon University</affiliation></author><author><keyname>Shalizi</keyname><forenames>Cosma Rohilla</forenames><affiliation>Carnegie Mellon University</affiliation></author><author><keyname>Schervish</keyname><forenames>Mark</forenames><affiliation>Carnegie Mellon University</affiliation></author></authors><title>Estimating $\beta$-mixing coefficients</title><categories>stat.ML cs.LG math.PR</categories><comments>9 pages, accepted by AIStats. CMU Statistics Technical Report</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The literature on statistical learning for time series assumes the asymptotic
independence or ``mixing' of the data-generating process. These mixing
assumptions are never tested, nor are there methods for estimating mixing rates
from data. We give an estimator for the $\beta$-mixing rate based on a single
stationary sample path and show it is $L_1$-risk consistent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0942</identifier>
 <datestamp>2011-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0942</id><created>2011-03-04</created><updated>2011-06-03</updated><authors><author><keyname>McDonald</keyname><forenames>Daniel J.</forenames><affiliation>Carnegie Mellon University</affiliation></author><author><keyname>Shalizi</keyname><forenames>Cosma Rohilla</forenames><affiliation>Carnegie Mellon University</affiliation></author><author><keyname>Schervish</keyname><forenames>Mark</forenames><affiliation>Carnegie Mellon University</affiliation></author></authors><title>Generalization error bounds for stationary autoregressive models</title><categories>stat.ML cs.LG</categories><comments>10 pages, 3 figures. CMU Statistics Technical Report</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We derive generalization error bounds for stationary univariate
autoregressive (AR) models. We show that imposing stationarity is enough to
control the Gaussian complexity without further regularization. This lets us
use structural risk minimization for model selection. We demonstrate our
methods by predicting interest rate movements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0949</identifier>
 <datestamp>2011-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0949</id><created>2011-03-04</created><updated>2011-06-28</updated><authors><author><keyname>Shalizi</keyname><forenames>Cosma Rohilla</forenames></author><author><keyname>Jacobs</keyname><forenames>Abigail Z.</forenames></author><author><keyname>Klinkner</keyname><forenames>Kristina Lisa</forenames></author><author><keyname>Clauset</keyname><forenames>Aaron</forenames></author></authors><title>Adapting to Non-stationarity with Growing Expert Ensembles</title><categories>stat.ML cs.LG physics.data-an stat.ME</categories><comments>9 pages, 1 figure; CMU Statistics Technical Report. v2: Added
  empirical example, revised discussion of related work</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When dealing with time series with complex non-stationarities, low
retrospective regret on individual realizations is a more appropriate goal than
low prospective risk in expectation. Online learning algorithms provide
powerful guarantees of this form, and have often been proposed for use with
non-stationary processes because of their ability to switch between different
forecasters or ``experts''. However, existing methods assume that the set of
experts whose forecasts are to be combined are all given at the start, which is
not plausible when dealing with a genuinely historical or evolutionary system.
We show how to modify the ``fixed shares'' algorithm for tracking the best
expert to cope with a steadily growing set of experts, obtained by fitting new
models to new data as it becomes available, and obtain regret bounds for the
growing ensemble.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0966</identifier>
 <datestamp>2011-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0966</id><created>2011-03-04</created><authors><author><keyname>Arora</keyname><forenames>Dushyant</forenames></author><author><keyname>Bienkowski</keyname><forenames>Marcin</forenames></author><author><keyname>Feldmann</keyname><forenames>Anja</forenames></author><author><keyname>Schaffrath</keyname><forenames>Gregor</forenames></author><author><keyname>Schmid</keyname><forenames>Stefan</forenames></author></authors><title>Online Strategies for Intra and Inter Provider Service Migration in
  Virtual Networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Network virtualization allows one to build dynamic distributed systems in
which resources can be dynamically allocated at locations where they are most
useful. In order to fully exploit the benefits of this new technology,
protocols need to be devised which react efficiently to changes in the demand.
This paper argues that the field of online algorithms and competitive analysis
provides useful tools to deal with and reason about the uncertainty in the
request dynamics, and to design algorithms with provable performance
guarantees. As a case study, we describe a system (e.g., a gaming application)
where network virtualization is used to support thin client applications for
mobile devices to improve their QoS. By decoupling the service from the
underlying resource infrastructure, it can be migrated closer to the current
client locations while taking into account migration cost. This paper
identifies the major cost factors in such a system, and formalizes the
corresponding optimization problem. Both randomized and deterministic, gravity
center based online algorithms are presented which achieve a good tradeoff
between improved QoS and migration cost in the worst-case, both for service
migration within an infrastructure provider as well as for networks supporting
cross-provider migration. The paper reports on our simulation results and also
presents an explicit construction of an optimal offline algorithm which allows,
e.g., to evaluate the competitive ratio empirically.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0967</identifier>
 <datestamp>2011-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0967</id><created>2011-03-04</created><authors><author><keyname>Majkic</keyname><forenames>Zoran</forenames></author></authors><title>Intensionality and Two-steps Interpretations</title><categories>cs.LO cs.IT math.IT</categories><comments>15 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we considered the extension of the First-order Logic (FOL) by
Bealer's intensional abstraction operator. Contemporary use of the term
'intension' derives from the traditional logical Frege-Russell's doctrine that
an idea (logic formula) has both an extension and an intension. Although there
is divergence in formulation, it is accepted that the extension of an idea
consists of the subjects to which the idea applies, and the intension consists
of the attributes implied by the idea. From the Montague's point of view, the
meaning of an idea can be considered as particular extensions in different
possible worlds. In the case of the pure FOL we obtain commutative homomorphic
diagram that holds in each given possible world of the intensional FOL, from
the free algebra of the FOL syntax, toward its intensional algebra of concepts,
and, successively, to the new extensional relational algebra (different from
Cylindric algebras). Then we show that it corresponds to the Tarski's
interpretation of the standard extensional FOL in this possible world.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0973</identifier>
 <datestamp>2011-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0973</id><created>2011-03-04</created><authors><author><keyname>Apolloni</keyname><forenames>Andrea</forenames></author><author><keyname>Gargiulo</keyname><forenames>Floriana</forenames></author></authors><title>Diffusion processes through social groups' dynamics</title><categories>physics.soc-ph cs.SI</categories><comments>to appear in Special Edition of Advances in Complex System</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Axelrod's model describes the dissemination of a set of cultural traits in a
society constituted by individual agents. In a social context, nevertheless,
individual choices toward a specific attitude are also at the basis of the
formation of communities, groups and parties. The membership in a group changes
completely the behavior of single agents who start acting according to a social
identity. Groups act and interact among them as single entities, but still
conserve an internal dynamics. We show that, under certain conditions of social
dynamics, the introduction of group dynamics in a cultural dissemination
process avoids the flattening of the culture into a single entity and preserves
the multiplicity of cultural attitudes. We also considered diffusion processes
on this dynamical background, showing the conditions under which information as
well as innovation can spread through the population in a scenario where the
groups' choices determine the social structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0985</identifier>
 <datestamp>2011-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0985</id><created>2011-03-04</created><authors><author><keyname>Goertz</keyname><forenames>Inge Li</forenames></author><author><keyname>Nagarajan</keyname><forenames>Viswanath</forenames></author></authors><title>Locating Depots for Capacitated Vehicle Routing</title><categories>cs.DS</categories><comments>12 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a location-routing problem in the context of capacitated vehicle
routing. The input is a set of demand locations in a metric space and a fleet
of k vehicles each of capacity Q. The objective is to locate k depots, one for
each vehicle, and compute routes for the vehicles so that all demands are
satisfied and the total cost is minimized. Our main result is a constant-factor
approximation algorithm for this problem. To achieve this result, we reduce to
the k-median-forest problem, which generalizes both k-median and minimum
spanning tree, and which might be of independent interest. We give a
(3+c)-approximation algorithm for k-median-forest, which leads to a
(12+c)-approximation algorithm for the above location-routing problem, for any
constant c&gt;0. The algorithm for k-median-forest is just t-swap local search,
and we prove that it has locality gap 3+2/t; this generalizes the corresponding
result known for k-median. Finally we consider the &quot;non-uniform&quot;
k-median-forest problem which has different cost functions for the MST and
k-median parts. We show that the locality gap for this problem is unbounded
even under multi-swaps, which contrasts with the uniform case. Nevertheless, we
obtain a constant-factor approximation algorithm, using an LP based approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0995</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0995</id><created>2011-03-04</created><updated>2013-06-21</updated><authors><author><keyname>Boutsidis</keyname><forenames>Christos</forenames></author><author><keyname>Drineas</keyname><forenames>Petros</forenames></author><author><keyname>Magdon-Ismail</keyname><forenames>Malik</forenames></author></authors><title>Near-Optimal Column-Based Matrix Reconstruction</title><categories>cs.DS</categories><comments>SIAM Journal on Computing (SICOMP), invited to special issue of FOCS
  2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider low-rank reconstruction of a matrix using its columns and we
present asymptotically optimal algorithms for both spectral norm and Frobenius
norm reconstruction. The main tools we introduce to obtain our r esults are:
(i) the use of fast approximate SVD-like decompositions for column
reconstruction, and (ii) two deter ministic algorithms for selecting rows from
matrices with orthonormal columns, building upon the sparse represen tation
theorem for decompositions of the identity that appeared in \cite{BSS09}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0996</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0996</id><created>2011-03-04</created><updated>2011-11-08</updated><authors><author><keyname>Bandemer</keyname><forenames>Bernd</forenames></author><author><keyname>Gamal</keyname><forenames>Abbas El</forenames></author></authors><title>Communication with Disturbance Constraints</title><categories>cs.IT math.IT</categories><comments>25 pages, 10 figures; added vector Gaussian case, outer bound for the
  deterministic channel with two disturbance constraints, and a new example;
  submitted for publication to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by the broadcast view of the interference channel, the new problem
of communication with disturbance constraints is formulated. The
rate-disturbance region is established for the single constraint case and the
optimal encoding scheme turns out to be the same as the Han-Kobayashi scheme
for the two user-pair interference channel. This result is extended to the
Gaussian vector (MIMO) case. For the case of communication with two disturbance
constraints, inner and outer bounds on the rate-disturbance region for a
deterministic model are established. The inner bound is achieved by an encoding
scheme that involves rate splitting, Marton coding, and superposition coding,
and is shown to be optimal in several nontrivial cases. This encoding scheme
can be readily applied to discrete memoryless interference channels and
motivates a natural extension of the Han-Kobayashi scheme to more than two user
pairs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.0999</identifier>
 <datestamp>2011-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.0999</id><created>2011-03-04</created><updated>2011-05-06</updated><authors><author><keyname>Kim</keyname><forenames>MinJi</forenames></author><author><keyname>Erez</keyname><forenames>Elona</forenames></author><author><keyname>Yeh</keyname><forenames>Edmund M.</forenames></author><author><keyname>Medard</keyname><forenames>Muriel</forenames></author></authors><title>Deterministic Network Model Revisited: An Algebraic Network Coding
  Approach</title><categories>cs.IT math.IT</categories><comments>19 pages, 19 figures, submitted to Transactions on Information Theory
  (removed figures that were mistakenly included at the end of the document)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The capacity of multiuser networks has been a long-standing problem in
information theory. Recently, Avestimehr et al. have proposed a deterministic
network model to approximate multiuser wireless networks. This model, known as
the ADT network model, takes into account the broadcast nature of wireless
medium and interference.
  We show that the ADT network model can be described within the algebraic
network coding framework introduced by Koetter and Medard. We prove that the
ADT network problem can be captured by a single matrix, and show that the
min-cut of an ADT network is the rank of this matrix; thus, eliminating the
need to optimize over exponential number of cuts between two nodes to compute
the min-cut of an ADT network. We extend the capacity characterization for ADT
networks to a more general set of connections, including single
unicast/multicast connection and non-multicast connections such as multiple
multicast, disjoint multicast, and two-level multicast. We also provide
sufficiency conditions for achievability in ADT networks for any general
connection set. In addition, we show that random linear network coding, a
randomized distributed algorithm for network code construction, achieves the
capacity for the connections listed above. Furthermore, we extend the ADT
networks to those with random erasures and cycles (thus, allowing
bi-directional links).
  In addition, we propose an efficient linear code construction for the
deterministic wireless multicast relay network model. Avestimehr et al.'s
proposed code construction is not guaranteed to be efficient and may
potentially involve an infinite block length. Unlike several previous coding
schemes, we do not attempt to find flows in the network. Instead, for a layered
network, we maintain an invariant where it is required that at each stage of
the code construction, certain sets of codewords are linearly independent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1001</identifier>
 <datestamp>2011-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1001</id><created>2011-03-04</created><authors><author><keyname>Wang</keyname><forenames>Xinhua</forenames></author><author><keyname>Lin</keyname><forenames>Hai</forenames></author></authors><title>Two-step differentiator for delayed signal</title><categories>cs.SY math.DS math.OC</categories><comments>12 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a high-order differentiator for delayed measurement
signal. The proposed differentiator not only can correct the delay in signal,
but aslo can estimate the undelayed derivatives. The differentiator consists of
two-step algorithms with the delayed time instant. Conditions are given
ensuring convergence of the estimation error for the given delay in the
signals. The merits of method include its simple implementation and interesting
application. Numerical simulations illustrate the effectiveness of the proposed
differentiator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1003</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1003</id><created>2011-03-04</created><authors><author><keyname>&#xd6;zkural</keyname><forenames>Eray</forenames></author></authors><title>Teraflop-scale Incremental Machine Learning</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a long-term memory design for artificial general intelligence
based on Solomonoff's incremental machine learning methods. We use R5RS Scheme
and its standard library with a few omissions as the reference machine. We
introduce a Levin Search variant based on Stochastic Context Free Grammar
together with four synergistic update algorithms that use the same grammar as a
guiding probability distribution of programs. The update algorithms include
adjusting production probabilities, re-using previous solutions, learning
programming idioms and discovery of frequent subprograms. Experiments with two
training sequences demonstrate that our approach to incremental learning is
effective.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1013</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1013</id><created>2011-03-05</created><updated>2013-05-04</updated><authors><author><keyname>Mao</keyname><forenames>Qi</forenames></author><author><keyname>Tsang</keyname><forenames>Ivor W.</forenames></author></authors><title>A Feature Selection Method for Multivariate Performance Measures</title><categories>cs.LG</categories><journal-ref>IEEE Transactions on Pattern Analysis and Machine Intelligence,
  2012</journal-ref><doi>10.1109/TPAMI.2012.266</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Feature selection with specific multivariate performance measures is the key
to the success of many applications, such as image retrieval and text
classification. The existing feature selection methods are usually designed for
classification error. In this paper, we propose a generalized sparse
regularizer. Based on the proposed regularizer, we present a unified feature
selection framework for general loss functions. In particular, we study the
novel feature selection paradigm by optimizing multivariate performance
measures. The resultant formulation is a challenging problem for
high-dimensional data. Hence, a two-layer cutting plane algorithm is proposed
to solve this problem, and the convergence is presented. In addition, we adapt
the proposed method to optimize multivariate measures for multiple instance
learning problems. The analyses by comparing with the state-of-the-art feature
selection methods show that the proposed method is superior to others.
Extensive experiments on large-scale and high-dimensional real world datasets
show that the proposed method outperforms $l_1$-SVM and SVM-RFE when choosing a
small subset of features, and achieves significantly improved performances over
SVM$^{perf}$ in terms of $F_1$-score.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1019</identifier>
 <datestamp>2012-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1019</id><created>2011-03-05</created><updated>2012-04-08</updated><authors><author><keyname>Zhang</keyname><forenames>Qizhi</forenames></author></authors><title>On the Signature Calculus for finite fields of order square of prime
  numbers</title><categories>math.NT cs.CC</categories><comments>7 pages</comments><msc-class>11R37, 11Y40, 68W20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In [Huang-Raskind 2009], the authors proved that the discrete logarithm
problem in a prime finite field is random polynomial time equivalent to
computing the ramification signature of a real quadratic field. In this paper,
we do this for a quadratic extension of a prime field.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1026</identifier>
 <datestamp>2012-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1026</id><created>2011-03-05</created><updated>2012-04-11</updated><authors><author><keyname>Chen</keyname><forenames>Xu</forenames></author><author><keyname>Huang</keyname><forenames>Jianwei</forenames></author></authors><title>Evolutionary Game and Learning for Dynamic Spectrum Access</title><categories>cs.NI cs.DC</categories><comments>This paper has been withdrawn by the author due to title update! A
  new version with the updated title &quot;Evolutionarily Stable Spectrum Access&quot;
  will be available at Arxiv</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Efficient dynamic spectrum access mechanism is crucial for improving the
spectrum utilization. In this paper, we consider the dynamic spectrum access
mechanism design with both complete and incomplete network information. When
the network information is available, we propose an evolutionary spectrum
access mechanism. We use the replicator dynamics to study the dynamics of
channel selections, and show that the mechanism achieves an equilibrium that is
an evolutionarily stable strategy and is also max-min fair. With incomplete
network information, we propose a distributed reinforcement learning mechanism
for dynamic spectrum access. Each secondary user applies the maximum likelihood
estimation method to estimate its expected payoff based on the local
observations, and learns to adjust its mixed strategy for channel selections
adaptively over time. We study the convergence of the learning mechanism based
on the theory of stochastic approximation, and show that it globally converges
to an approximate Nash equilibrium. Numerical results show that the proposed
evolutionary spectrum access and distributed reinforcement learning mechanisms
achieve up to 82% and 70% performance improvement than a random access
mechanism, respectively, and are robust to random perturbations of channel
selections.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1040</identifier>
 <datestamp>2011-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1040</id><created>2011-03-05</created><updated>2011-03-19</updated><authors><author><keyname>Goldberg</keyname><forenames>Paul W.</forenames></author><author><keyname>Savani</keyname><forenames>Rahul</forenames></author><author><keyname>Sorensen</keyname><forenames>Troels Bjerre</forenames></author><author><keyname>Ventre</keyname><forenames>Carmine</forenames></author></authors><title>On the Approximation Performance of Fictitious Play in Finite Games</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the performance of Fictitious Play, when used as a heuristic for
finding an approximate Nash equilibrium of a 2-player game. We exhibit a class
of 2-player games having payoffs in the range [0,1] that show that Fictitious
Play fails to find a solution having an additive approximation guarantee
significantly better than 1/2. Our construction shows that for n times n games,
in the worst case both players may perpetually have mixed strategies whose
payoffs fall short of the best response by an additive quantity 1/2 -
O(1/n^(1-delta)) for arbitrarily small delta. We also show an essentially
matching upper bound of 1/2 - O(1/n).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1061</identifier>
 <datestamp>2011-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1061</id><created>2011-03-05</created><authors><author><keyname>Majkic</keyname><forenames>Zoran</forenames></author></authors><title>Temporal Probabilistic Logic Programs: State and Revision</title><categories>cs.LO</categories><comments>10 pages</comments><journal-ref>Artificial Intelligence and Pattern Recognition (AIPR-07),2007</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There are numerous applications where we have to deal with temporal
uncertainty associated with events. The Temporal Probabilistic (TP) Logic
Programs should provide support for valid-time indeterminacy of events, by
proposing the concept of an indeterminate instant, that is, an interval of
time-points (event's time-window) with an associated, lower and upper,
probability distribution. In particular, we propose the new semantics, for the
TP Logic Programs of Dekhtyar and Subrahmanian. Our semantics, based on the
possible world semantics is a generalization of the possible world semantics
for (non temporal) Probabilistic Logic Programming, and we define the new
syntax for PT-programs, with time variable explicitly represented in all atoms,
and show how the standard role of Herbrand interpretations used as possible
worlds for probability distributions is coherently extended to Temporal
Probabilistic Logic Programming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1065</identifier>
 <datestamp>2011-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1065</id><created>2011-03-05</created><updated>2011-06-09</updated><authors><author><keyname>Bro&#x17e;ek</keyname><forenames>V&#xe1;clav</forenames></author></authors><title>Optimal Strategies in Infinite-state Stochastic Reachability Games</title><categories>cs.GT</categories><proxy>EPTCS</proxy><acm-class>G.3</acm-class><journal-ref>EPTCS 54, 2011, pp. 60-73</journal-ref><doi>10.4204/EPTCS.54.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider perfect-information reachability stochastic games for 2 players
on infinite graphs. We identify a subclass of such games, and prove two
interesting properties of it: first, Player Max always has optimal strategies
in games from this subclass, and second, these games are strongly determined.
The subclass is defined by the property that the set of all values can only
have one accumulation point -- 0. Our results nicely mirror recent results for
finitely-branching games, where, on the contrary, Player Min always has optimal
strategies. However, our proof methods are substantially different, because the
roles of the players are not symmetric. We also do not restrict the branching
of the games. Finally, we apply our results in the context of recently studied
One-Counter stochastic games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1077</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1077</id><created>2011-03-05</created><authors><author><keyname>Osokin</keyname><forenames>Anton</forenames></author><author><keyname>Vetrov</keyname><forenames>Dmitry</forenames></author><author><keyname>Kolmogorov</keyname><forenames>Vladimir</forenames></author></authors><title>Submodular Decomposition Framework for Inference in Associative Markov
  Networks with Global Constraints</title><categories>cs.CV cs.DM math.OC</categories><comments>17 pages. Shorter version to appear in CVPR 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the paper we address the problem of finding the most probable state of
discrete Markov random field (MRF) with associative pairwise terms. Although of
practical importance, this problem is known to be NP-hard in general. We
propose a new type of MRF decomposition, submodular decomposition (SMD). Unlike
existing decomposition approaches SMD decomposes the initial problem into
subproblems corresponding to a specific class label while preserving the graph
structure of each subproblem. Such decomposition enables us to take into
account several types of global constraints in an efficient manner. We study
theoretical properties of the proposed approach and demonstrate its
applicability on a number of problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1091</identifier>
 <datestamp>2012-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1091</id><created>2011-03-05</created><updated>2012-05-08</updated><authors><author><keyname>Katrenic</keyname><forenames>J&#xe1;n</forenames></author><author><keyname>Semanisin</keyname><forenames>Gabriel</forenames></author></authors><title>A generalization of Hopcroft-Karp algorithm for semi-matchings and
  covers in bipartite graphs</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An $(f,g)$-semi-matching in a bipartite graph $G=(U \cup V,E)$ is a set of
edges $M \subseteq E$ such that each vertex $u\in U$ is incident with at most
$f(u)$ edges of $M$, and each vertex $v\in V$ is incident with at most $g(v)$
edges of $M$. In this paper we give an algorithm that for a graph with $n$
vertices and $m$ edges, $n\le m$, constructs a maximum $(f,g)$-semi-matching in
running time $O(m\cdot \min (\sqrt{\sum_{u\in U}f(u)}, \sqrt{\sum_{v\in
V}g(v)}))$. Using the reduction of [5], our result on maximum
$(f,g)$-semi-matching problem directly implies an algorithm for the optimal
semi-matching problem with running time $O(\sqrt{n}m \log n)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1109</identifier>
 <datestamp>2013-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1109</id><created>2011-03-06</created><updated>2013-04-01</updated><authors><author><keyname>Baswana</keyname><forenames>Surender</forenames></author><author><keyname>Gupta</keyname><forenames>Manoj</forenames></author><author><keyname>Sen</keyname><forenames>Sandeep</forenames></author></authors><title>Fully dynamic maximal matching in O(log n) update time</title><categories>cs.DS</categories><comments>16 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an algorithm for maintaining maximal matching in a graph under
addition and deletion of edges. Our data structure is randomized that takes
O(log n) expected amortized time for each edge update where n is the number of
vertices in the graph. While there is a trivial O(n) algorithm for edge update,
the previous best known result for this problem for a graph with n vertices and
m edges is O({(n+ m)}^{0.7072})which is sub-linear only for a sparse graph.
  For the related problem of maximum matching, Onak and Rubinfield designed a
randomized data structure that achieves O(log^2 n) amortized time for each
update for maintaining a c-approximate maximum matching for some large constant
c. In contrast, we can maintain a factor two approximate maximum matching in
O(log n) expected time per update as a direct corollary of the maximal matching
scheme. This in turn also implies a two approximate vertex cover maintenance
scheme that takes O(log n) expected time per update.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1112</identifier>
 <datestamp>2011-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1112</id><created>2011-03-06</created><authors><author><keyname>Zaker</keyname><forenames>Manouchehr</forenames></author></authors><title>On dynamic monopolies of graphs with general thresholds</title><categories>math.CO cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $G$ be a graph and ${\mathcal{\tau}}: V(G)\rightarrow \Bbb{N}$ be an
assignment of thresholds to the vertices of $G$. A subset of vertices $D$ is
said to be dynamic monopoly (or simply dynamo) if the vertices of $G$ can be
partitioned into subsets $D_0, D_1,..., D_k$ such that $D_0=D$ and for any
$i=1,..., k-1$ each vertex $v$ in $D_{i+1}$ has at least $t(v)$ neighbors in
$D_0\cup ...\cup D_i$. Dynamic monopolies are in fact modeling the irreversible
spread of influence such as disease or belief in social networks. We denote the
smallest size of any dynamic monopoly of $G$, with a given threshold
assignment, by $dyn(G)$. In this paper we first define the concept of a
resistant subgraph and show its relationship with dynamic monopolies. Then we
obtain some lower and upper bounds for the smallest size of dynamic monopolies
in graphs with different types of thresholds. Next we introduce
dynamo-unbounded families of graphs and prove some related results. We also
define the concept of a homogenious society that is a graph with probabilistic
thresholds satisfying some conditions and obtain a bound for the smallest size
of its dynamos. Finally we consider dynamic monopoly of line graphs and obtain
some bounds for their sizes and determine the exact values in some special
cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1124</identifier>
 <datestamp>2011-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1124</id><created>2011-03-06</created><authors><author><keyname>Ghaffari</keyname><forenames>H.</forenames></author><author><keyname>Nabovati</keyname><forenames>A.</forenames></author><author><keyname>Sharifzadeh</keyname><forenames>M.</forenames></author><author><keyname>Young</keyname><forenames>R. P.</forenames></author></authors><title>Fluid flow analysis in a rough fracture (type II) using complex networks
  and lattice Boltzmann method</title><categories>physics.flu-dyn cs.CE</categories><comments>2011 PanAm-CGS Geotechnical Conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Complexity of fluid flow in a rough fracture is induced by the complex
configurations of opening areas between the fracture planes. In this study, we
model fluid flow in an evolvable real rock joint structure, which under certain
normal load is sheared. In an experimental study, information regarding about
apertures of the rock joint during consecutive 20 mm displacements and fluid
flow (permeability) in different pressure heads have been recorded by a scanner
laser. Our aim in this study is to simulate the fluid flow in the mentioned
complex geometries using the lattice Boltzmann method (LBM), while the
characteristics of the aperture field will be compared with the modeled fluid
flow permeability To characterize the aperture, we use a new concept in the
graph theory, namely: complex networks and motif analysis of the corresponding
networks. In this approach, the similar aperture profile along the fluid flow
direction is mapped in to a network space. The modeled permeability using the
LBM shows good correlation with the experimental measured values. Furthermore,
the two main characters of the obtained networks, i.e., characteristic length
and number of edges show the same evolutionary trend with the modeled
permeability values. Analysis of motifs through the obtained networks showed
the most transient sub-graphs are much more frequent in residual stages. This
coincides with nearly stable fluid flow and high permeability values.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1127</identifier>
 <datestamp>2011-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1127</id><created>2011-03-06</created><authors><author><keyname>Stannett</keyname><forenames>Mike</forenames></author></authors><title>Computation and Spacetime Structure</title><categories>gr-qc cs.CC</categories><comments>10 pages, 2 figures. Submitted to Physics &amp; Computation 2011, Turku,
  Finland</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the relationship between computation and spacetime structure,
focussing on the role of closed timelike curves (CTCs) in promoting
computational speedup. We note first that CTC traversal can be interpreted in
two distinct ways, depending on ones understanding of spacetime. Focussing on
one interpretation leads us to develop a toy universe in which no CTC can be
traversed more than once, whence no computational speedup is possible.
Focussing on the second (and more standard) interpretation leads to the
surprising conclusion that CTCs act as perfect information repositories: just
as black holes have entropy, so do CTCs. If we also assume that P is not equal
to NP, we find that all observers agree that, even if unbounded time travel
existed in their youth, this capability eventually vanishes as they grow older.
Thus the computational assumption &quot;P is not NP&quot; is also an assumption
concerning cosmological structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1130</identifier>
 <datestamp>2012-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1130</id><created>2011-03-06</created><updated>2012-08-09</updated><authors><author><keyname>Chambrion</keyname><forenames>Thomas</forenames><affiliation>INRIA Lorraine / IECN / MMAS, IECN</affiliation></author></authors><title>Periodic excitations of bilinear quantum systems</title><categories>math.OC cs.SY math-ph math.AP math.MP quant-ph</categories><comments>Available online
  http://www.sciencedirect.com/science/article/pii/S0005109812002865</comments><proxy>ccsd</proxy><journal-ref>Automatica 48, 9 (2012) pp 2040-2046</journal-ref><doi>10.1016/j.automatica.2012.03.031</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A well-known method of transferring the population of a quantum system from
an eigenspace of the free Hamiltonian to another is to use a periodic control
law with an angular frequency equal to the difference of the eigenvalues. For
finite dimensional quantum systems, the classical theory of averaging provides
a rigorous explanation of this experimentally validated result. This paper
extends this finite dimensional result, known as the Rotating Wave
Approximation, to infinite dimensional systems and provides explicit
convergence estimates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1133</identifier>
 <datestamp>2011-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1133</id><created>2011-03-06</created><updated>2011-06-13</updated><authors><author><keyname>Allouche</keyname><forenames>J. -P.</forenames></author><author><keyname>Shallit</keyname><forenames>J.</forenames></author></authors><title>A variant of Hofstadter's sequence and finite automata</title><categories>math.NT cs.DM cs.FL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Following up on a paper of Balamohan, Kuznetsov, and Tanny, we analyze a
variant of Hofstadter's Q-sequence and show it is 2-automatic. An automaton
computing the sequence is explicitly given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1134</identifier>
 <datestamp>2011-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1134</id><created>2011-03-06</created><authors><author><keyname>Ahmed</keyname><forenames>Zeeshan</forenames></author></authors><title>Designing Flexible GUI to Increase the Acceptance Rate of Product Data
  Management Systems in Industry</title><categories>cs.HC</categories><comments>10 Pages, 4 Tables, 9 Figures</comments><journal-ref>International Journal of Computer Science &amp; Emerging Technologies
  (E-ISSN: 2044-6004), Volume 2, Issue 1, P 100-109,</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Product Data Management (PDM) desktop and web based systems maintain the
organizational technical and managerial data to increase the quality of
products by improving the processes of development, business process flows,
change management, product structure management, project tracking and resource
planning. Though PDM is heavily benefiting industry but PDM community is facing
a very serious unresolved issue in PDM system development with flexible and
user friendly graphical user interface for efficient human machine
communication. PDM systems offer different services and functionalities at a
time but the graphical user interfaces of most of the PDM systems are not
designed in a way that a user (especially a new user) can easily learn and use
them. Targeting this issue, a thorough research was conducted in field of Human
Computer Interaction; resultant data provides the information about graphical
user interface development using rich internet applications. The accomplished
goal of this research was to support the field of PDM with a proposition of a
conceptual model for the implementation of a flexible web based graphical user
interface. The proposed conceptual model was successfully designed into
implementation model and a resultant prototype putting values to the field is
now available. Describing the proposition in detail the main concept,
implementation designs and developed prototype is also discussed in this paper.
Moreover in the end, prototype is compared with respective functions of
existing PDM systems .i.e., Windchill and CIM to evaluate its effectiveness
against targeted challenge
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1156</identifier>
 <datestamp>2011-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1156</id><created>2011-03-06</created><authors><author><keyname>Merrikh-Bayat</keyname><forenames>Farnood</forenames></author><author><keyname>Bagheri-Shouraki</keyname><forenames>Saeed</forenames></author></authors><title>Efficient neuro-fuzzy system and its Memristor Crossbar-based Hardware
  Implementation</title><categories>cs.AI cs.NE</categories><comments>34 pages, 14 figures, Submitted to IEEE Transactions on Fuzzy Systems</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper a novel neuro-fuzzy system is proposed where its learning is
based on the creation of fuzzy relations by using new implication method
without utilizing any exact mathematical techniques. Then, a simple memristor
crossbar-based analog circuit is designed to implement this neuro-fuzzy system
which offers very interesting properties. In addition to high connectivity
between neurons and being fault-tolerant, all synaptic weights in our proposed
method are always non-negative and there is no need to precisely adjust them.
Finally, this structure is hierarchically expandable and can compute operations
in real time since it is implemented through analog circuits. Simulation
results show the efficiency and applicability of our neuro-fuzzy computing
system. They also indicate that this system can be a good candidate to be used
for creating artificial brain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1157</identifier>
 <datestamp>2011-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1157</id><created>2011-03-06</created><updated>2011-03-09</updated><authors><author><keyname>Di Mauro</keyname><forenames>Nicola</forenames></author><author><keyname>Basile</keyname><forenames>Teresa M. A.</forenames></author><author><keyname>Ferilli</keyname><forenames>Stefano</forenames></author><author><keyname>Esposito</keyname><forenames>Floriana</forenames></author></authors><title>GRASP and path-relinking for Coalition Structure Generation</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Artificial Intelligence with Coalition Structure Generation (CSG) one
refers to those cooperative complex problems that require to find an optimal
partition, maximising a social welfare, of a set of entities involved in a
system into exhaustive and disjoint coalitions. The solution of the CSG problem
finds applications in many fields such as Machine Learning (covering machines,
clustering), Data Mining (decision tree, discretization), Graph Theory, Natural
Language Processing (aggregation), Semantic Web (service composition), and
Bioinformatics. The problem of finding the optimal coalition structure is
NP-complete. In this paper we present a greedy adaptive search procedure
(GRASP) with path-relinking to efficiently search the space of coalition
structures. Experiments and comparisons to other algorithms prove the validity
of the proposed method in solving this hard combinatorial problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1168</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1168</id><created>2011-03-06</created><updated>2011-12-12</updated><authors><author><keyname>Xu</keyname><forenames>Yangyang</forenames></author><author><keyname>Yin</keyname><forenames>Wotao</forenames></author><author><keyname>Wen</keyname><forenames>Zaiwen</forenames></author><author><keyname>Zhang</keyname><forenames>Yin</forenames></author></authors><title>An Alternating Direction Algorithm for Matrix Completion with
  Nonnegative Factors</title><categories>cs.IT cs.NA math.IT math.NA</categories><journal-ref>Frontiers of Mathematics in China 7(2), 365-384, 2012</journal-ref><doi>10.1007/s11464-012-0194-5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces an algorithm for the nonnegative matrix
factorization-and-completion problem, which aims to find nonnegative low-rank
matrices X and Y so that the product XY approximates a nonnegative data matrix
M whose elements are partially known (to a certain accuracy). This problem
aggregates two existing problems: (i) nonnegative matrix factorization where
all entries of M are given, and (ii) low-rank matrix completion where
nonnegativity is not required. By taking the advantages of both nonnegativity
and low-rankness, one can generally obtain superior results than those of just
using one of the two properties. We propose to solve the non-convex constrained
least-squares problem using an algorithm based on the classic alternating
direction augmented Lagrangian method. Preliminary convergence properties of
the algorithm and numerical simulation results are presented. Compared to a
recent algorithm for nonnegative matrix factorization, the proposed algorithm
produces factorizations of similar quality using only about half of the matrix
entries. On tasks of recovering incomplete grayscale and hyperspectral images,
the proposed algorithm yields overall better qualities than those produced by
two recent matrix-completion algorithms that do not exploit nonnegativity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1178</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1178</id><created>2011-03-06</created><updated>2011-11-08</updated><authors><author><keyname>Oymak</keyname><forenames>Samet</forenames></author><author><keyname>Mohan</keyname><forenames>Karthik</forenames></author><author><keyname>Fazel</keyname><forenames>Maryam</forenames></author><author><keyname>Hassibi</keyname><forenames>Babak</forenames></author></authors><title>A Simplified Approach to Recovery Conditions for Low Rank Matrices</title><categories>math.OC cs.IT cs.SY math.IT</categories><comments>6 pages, This is a modified version of a paper submitted to ISIT
  2011; Proc. Intl. Symp. Info. Theory (ISIT), Aug 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recovering sparse vectors and low-rank matrices from noisy linear
measurements has been the focus of much recent research. Various reconstruction
algorithms have been studied, including $\ell_1$ and nuclear norm minimization
as well as $\ell_p$ minimization with $p&lt;1$. These algorithms are known to
succeed if certain conditions on the measurement map are satisfied. Proofs of
robust recovery for matrices have so far been much more involved than in the
vector case.
  In this paper, we show how several robust classes of recovery conditions can
be extended from vectors to matrices in a simple and transparent way, leading
to the best known restricted isometry and nullspace conditions for matrix
recovery. Our results rely on the ability to &quot;vectorize&quot; matrices through the
use of a key singular value inequality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1205</identifier>
 <datestamp>2011-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1205</id><created>2011-03-07</created><authors><author><keyname>Tomar</keyname><forenames>Minal</forenames></author><author><keyname>Singh</keyname><forenames>Pratibha</forenames></author></authors><title>A Directional Feature with Energy based Offline Signature Verification
  Network</title><categories>cs.AI</categories><comments>10 pages, 6 figures</comments><journal-ref>International Journal on Soft Computing ( IJSC ), Vol.2, No.1,
  February 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Signature used as a biometric is implemented in various systems as well as
every signature signed by each person is distinct at the same time. So, it is
very important to have a computerized signature verification system. In offline
signature verification system dynamic features are not available obviously, but
one can use a signature as an image and apply image processing techniques to
make an effective offline signature verification system. Author proposes a
intelligent network used directional feature and energy density both as inputs
to the same network and classifies the signature. Neural network is used as a
classifier for this system. The results are compared with both the very basic
energy density method and a simple directional feature method of offline
signature verification system and this proposed new network is found very
effective as compared to the above two methods, specially for less number of
training samples, which can be implemented practically.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1207</identifier>
 <datestamp>2011-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1207</id><created>2011-03-07</created><authors><author><keyname>Sharma</keyname><forenames>Ms. Deepti</forenames></author><author><keyname>Saxena</keyname><forenames>Ms. Archana B.</forenames></author></authors><title>Framework to Solve Load Balancing Problem in Heterogeneous Web Servers</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For popular websites most important concern is to handle incoming load
dynamically among web servers, so that they can respond to their client without
any wait or failure. Different websites use different strategies to distribute
load among web servers but most of the schemes concentrate on only one factor
that is number of requests, but none of the schemes consider the point that
different type of requests will require different level of processing efforts
to answer, status record of all the web servers that are associated with one
domain name and mechanism to handle a situation when one of the servers is not
working. Therefore, there is a fundamental need to develop strategy for dynamic
load allocation on web side. In this paper, an effort has been made to
introduce a cluster based frame work to solve load distribution problem. This
framework aims to distribute load among clusters on the basis of their
operational capabilities. Moreover, the experimental results are shown with the
help of example, algorithm and analysis of the algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1208</identifier>
 <datestamp>2012-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1208</id><created>2011-03-07</created><authors><author><keyname>Yamamoto</keyname><forenames>Ken</forenames></author><author><keyname>Yamazaki</keyname><forenames>Yoshihiro</forenames></author></authors><title>Fractal behind smart shopping</title><categories>cs.DM nlin.CG</categories><comments>16 pages</comments><journal-ref>Chaos, Solitons &amp; Fractals 45, 1058-1066 (2012)</journal-ref><doi>10.1016/j.chaos.2012.05.004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The 'minimal' payment - a payment method which minimizes the number of coins
in a purse - is presented. We focus on a time series of change given back to a
shopper repeating the minimal payment. The delay plot shows visually that the
set of successive change possesses a fine structure similar to the Sierpinski
gasket. We also estimate effectivity of the minimal-payment method by means of
the average number of coins in a purse, and conclude that the minimal-payment
strategy is the best to reduce the number of coins in a purse. Moreover, we
compare our results to the rule-60 cellular automaton and the Pascal-Sierpinski
gaskets, which are known as generators of the discrete Sierpinski gasket.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1224</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1224</id><created>2011-03-07</created><updated>2011-06-07</updated><authors><author><keyname>Pluchino</keyname><forenames>A.</forenames></author><author><keyname>Garofalo</keyname><forenames>C.</forenames></author><author><keyname>Rapisarda</keyname><forenames>A.</forenames></author><author><keyname>Spagano</keyname><forenames>S.</forenames></author><author><keyname>Caserta</keyname><forenames>M.</forenames></author></authors><title>Accidental Politicians: How Randomly Selected Legislators Can Improve
  Parliament Efficiency</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><comments>19 pages, 7 figures, new improved and longer version</comments><journal-ref>Physica A 390 (2011) 3944-3954</journal-ref><doi>10.1016/j.physa.2011.06.028</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a prototypical model of a Parliament with two Parties or two
Political Coalitions and we show how the introduction of a variable percentage
of randomly selected independent legislators can increase the global efficiency
of a Legislature, in terms of both the number of laws passed and the average
social welfare obtained. We also analytically find an &quot;efficiency golden rule&quot;
which allows to fix the optimal number of legislators to be selected at random
after that regular elections have established the relative proportion of the
two Parties or Coalitions. These results are in line with both the ancient
Greek democratic system and the recent discovery that the adoption of random
strategies can improve the efficiency of hierarchical organizations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1243</identifier>
 <datestamp>2014-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1243</id><created>2011-03-07</created><updated>2011-11-02</updated><authors><author><keyname>Squartini</keyname><forenames>Tiziano</forenames></author><author><keyname>Fagiolo</keyname><forenames>Giorgio</forenames></author><author><keyname>Garlaschelli</keyname><forenames>Diego</forenames></author></authors><title>Randomizing world trade. I. A binary network analysis</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI physics.data-an q-fin.GN</categories><comments>See also the companion paper (part II): arXiv:1103.1249
  [physics.soc-ph], published as Phys. Rev. E 84, 046118 (2011)</comments><journal-ref>Phys. Rev. E 84, 046117 (2011)</journal-ref><doi>10.1103/PhysRevE.84.046117</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The international trade network (ITN) has received renewed multidisciplinary
interest due to recent advances in network theory. However, it is still unclear
whether a network approach conveys additional, nontrivial information with
respect to traditional international-economics analyses that describe world
trade only in terms of local (first-order) properties. In this and in a
companion paper, we employ a recently proposed randomization method to assess
in detail the role that local properties have in shaping higher-order patterns
of the ITN in all its possible representations (binary/weighted,
directed/undirected, aggregated/disaggregated by commodity) and across several
years. Here we show that, remarkably, the properties of all binary projections
of the network can be completely traced back to the degree sequence, which is
therefore maximally informative. Our results imply that explaining the observed
degree sequence of the ITN, which has not received particular attention in
economic theory, should instead become one the main focuses of models of trade.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1249</identifier>
 <datestamp>2014-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1249</id><created>2011-03-07</created><updated>2011-11-02</updated><authors><author><keyname>Squartini</keyname><forenames>Tiziano</forenames></author><author><keyname>Fagiolo</keyname><forenames>Giorgio</forenames></author><author><keyname>Garlaschelli</keyname><forenames>Diego</forenames></author></authors><title>Randomizing world trade. II. A weighted network analysis</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI physics.data-an q-fin.GN</categories><comments>See also the companion paper (Part I): arXiv:1103.1243
  [physics.soc-ph], published as Phys. Rev. E 84, 046117 (2011)</comments><journal-ref>Phys. Rev. E 84, 046118 (2011)</journal-ref><doi>10.1103/PhysRevE.84.046118</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Based on the misleading expectation that weighted network properties always
offer a more complete description than purely topological ones, current
economic models of the International Trade Network (ITN) generally aim at
explaining local weighted properties, not local binary ones. Here we complement
our analysis of the binary projections of the ITN by considering its weighted
representations. We show that, unlike the binary case, all possible weighted
representations of the ITN (directed/undirected, aggregated/disaggregated)
cannot be traced back to local country-specific properties, which are therefore
of limited informativeness. Our two papers show that traditional macroeconomic
approaches systematically fail to capture the key properties of the ITN. In the
binary case, they do not focus on the degree sequence and hence cannot
characterize or replicate higher-order properties. In the weighted case, they
generally focus on the strength sequence, but the knowledge of the latter is
not enough in order to understand or reproduce indirect effects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1252</identifier>
 <datestamp>2013-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1252</id><created>2011-03-07</created><authors><author><keyname>Ferrara</keyname><forenames>Emilio</forenames></author><author><keyname>Baumgartner</keyname><forenames>Robert</forenames></author></authors><title>Automatic Wrapper Adaptation by Tree Edit Distance Matching</title><categories>cs.AI cs.IR</categories><comments>7 pages, 3 figures, In Proceedings of the 2nd International Workshop
  on Combinations of Intelligent Methods and Applications (CIMA 2010)</comments><journal-ref>Combinations of Intelligent Methods and Applications Smart
  Innovation, Systems and Technologies Volume 8, 2011, pp 41-54</journal-ref><doi>10.1007/978-3-642-19618-8_3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Information distributed through the Web keeps growing faster day by day, and
for this reason, several techniques for extracting Web data have been suggested
during last years. Often, extraction tasks are performed through so called
wrappers, procedures extracting information from Web pages, e.g. implementing
logic-based techniques. Many fields of application today require a strong
degree of robustness of wrappers, in order not to compromise assets of
information or reliability of data extracted. Unfortunately, wrappers may fail
in the task of extracting data from a Web page, if its structure changes,
sometimes even slightly, thus requiring the exploiting of new techniques to be
automatically held so as to adapt the wrapper to the new structure of the page,
in case of failure. In this work we present a novel approach of automatic
wrapper adaptation based on the measurement of similarity of trees through
improved tree edit distance matching techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1254</identifier>
 <datestamp>2013-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1254</id><created>2011-03-07</created><authors><author><keyname>Ferrara</keyname><forenames>Emilio</forenames></author><author><keyname>Baumgartner</keyname><forenames>Robert</forenames></author></authors><title>Design of Automatically Adaptable Web Wrappers</title><categories>cs.AI cs.IR</categories><comments>7 pages, 2 figures, In Proceedings of the 3rd International
  Conference on Agents and Artificial Intelligence (ICAART 2011)</comments><journal-ref>Proceedings of the 3rd International Conference on Agents and
  Artificial Intelligence, pp 211-216, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nowadays, the huge amount of information distributed through the Web
motivates studying techniques to be adopted in order to extract relevant data
in an efficient and reliable way. Both academia and enterprises developed
several approaches of Web data extraction, for example using techniques of
artificial intelligence or machine learning. Some commonly adopted procedures,
namely wrappers, ensure a high degree of precision of information extracted
from Web pages, and, at the same time, have to prove robustness in order not to
compromise quality and reliability of data themselves. In this paper we focus
on some experimental aspects related to the robustness of the data extraction
process and the possibility of automatically adapting wrappers. We discuss the
implementation of algorithms for finding similarities between two different
version of a Web page, in order to handle modifications, avoiding the failure
of data extraction tasks and ensuring reliability of information extracted. Our
purpose is to evaluate performances, advantages and draw-backs of our novel
system of automatic wrapper adaptation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1255</identifier>
 <datestamp>2011-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1255</id><created>2011-03-07</created><authors><author><keyname>Zimmermann</keyname><forenames>Antoine</forenames></author><author><keyname>Lopes</keyname><forenames>Nuno</forenames></author><author><keyname>Polleres</keyname><forenames>Axel</forenames></author><author><keyname>Straccia</keyname><forenames>Umberto</forenames></author></authors><title>A General Framework for Representing, Reasoning and Querying with
  Annotated Semantic Web Data</title><categories>cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a generic framework for representing and reasoning with annotated
Semantic Web data, a task becoming more important with the recent increased
amount of inconsistent and non-reliable meta-data on the web. We formalise the
annotated language, the corresponding deductive system and address the query
answering problem. Previous contributions on specific RDF annotation domains
are encompassed by our unified reasoning formalism as we show by instantiating
it on (i) temporal, (ii) fuzzy, and (iii) provenance annotations. Moreover, we
provide a generic method for combining multiple annotation domains allowing to
represent, e.g. temporally-annotated fuzzy RDF. Furthermore, we address the
development of a query language -- AnQL -- that is inspired by SPARQL,
including several features of SPARQL 1.1 (subqueries, aggregates, assignment,
solution modifiers) along with the formal definitions of their semantics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1264</identifier>
 <datestamp>2011-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1264</id><created>2011-03-07</created><authors><author><keyname>Liberti</keyname><forenames>Leo</forenames></author><author><keyname>Lavor</keyname><forenames>Carlile</forenames></author><author><keyname>Masson</keyname><forenames>Benoit</forenames></author><author><keyname>Mucherino</keyname><forenames>Antonio</forenames></author></authors><title>Polynomial cases of the Discretizable Molecular Distance Geometry
  Problem</title><categories>cs.CG cs.CE cs.DS q-bio.QM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An important application of distance geometry to biochemistry studies the
embeddings of the vertices of a weighted graph in the three-dimensional
Euclidean space such that the edge weights are equal to the Euclidean distances
between corresponding point pairs. When the graph represents the backbone of a
protein, one can exploit the natural vertex order to show that the search space
for feasible embeddings is discrete. The corresponding decision problem can be
solved using a binary tree based search procedure which is exponential in the
worst case. We discuss assumptions that bound the search tree width to a
polynomial size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1286</identifier>
 <datestamp>2013-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1286</id><created>2011-03-07</created><updated>2011-04-18</updated><authors><author><keyname>Rossi</keyname><forenames>Roberto</forenames></author><author><keyname>Tarim</keyname><forenames>S. Armagan</forenames></author><author><keyname>Kilic</keyname><forenames>Onur A.</forenames></author></authors><title>A note on Tempelmeier's {\beta}-service measure under non-stationary
  stochastic demand</title><categories>math.OC cs.SY</categories><comments>Technical report, Wageningen University, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tempelmeier (2007) considers the problem of computing replenishment cycle
policy parameters under non-stationary stochastic demand and service level
constraints. He analyses two possible service level measures: the minimum no
stock-out probability per period ({\alpha}-service level) and the so called
&quot;fill rate&quot;, that is the fraction of demand satisfied immediately from stock on
hand ({\beta}-service level). For each of these possible measures, he presents
a mixed integer programming (MIP) model to determine the optimal replenishment
cycles and corresponding order-up-to levels minimizing the expected total setup
and holding costs. His approach is essentially based on imposing service level
dependent lower bounds on cycle order-up-to levels. In this note, we argue that
Tempelmeier's strategy, in the {\beta}-service level case, while being an
interesting option for practitioners, does not comply with the standard
definition of &quot;fill rate&quot;. By means of a simple numerical example we
demonstrate that, as a consequence, his formulation might yield sub-optimal
policies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1302</identifier>
 <datestamp>2013-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1302</id><created>2011-03-07</created><updated>2013-06-27</updated><authors><author><keyname>Kuznetsov</keyname><forenames>Petr</forenames></author><author><keyname>Ravi</keyname><forenames>Srivatsan</forenames></author></authors><title>On the Cost of Concurrency in Transactional Memory</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The crux of software transactional memory (STM) is to combine an easy-to-use
programming interface with an efficient utilization of the concurrent-computing
abilities provided by modern machines. But does this combination come with an
inherent cost? We evaluate the cost of concurrency by measuring the amount of
expensive synchronization that must be employed in an STM implementation that
ensures positive concurrency, i.e., allows for concurrent transaction
processing in some executions. We focus on two popular progress conditions that
provide positive concurrency: progressiveness and permissiveness. We show that
in permissive STMs, providing a very high degree of concurrency, a transaction
performs a linear number of expensive synchronization patterns with respect to
its read-set size. In contrast, progressive STMs provide a very small degree of
concurrency but, as we demonstrate, can be implemented using at most one
expensive synchronization pattern per transaction. However, we show that even
in progressive STMs, a transaction has to &quot;protect&quot; (e.g., by using locks or
strong synchronization primitives) a linear amount of data with respect to its
write-set size. Our results suggest that looking for high degrees of
concurrency in STM implementations may bring a considerable synchronization
cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1305</identifier>
 <datestamp>2011-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1305</id><created>2011-03-07</created><authors><author><keyname>M&#xe9;ric</keyname><forenames>Hugo</forenames></author><author><keyname>Lacan</keyname><forenames>J&#xe9;r&#xf4;me</forenames></author><author><keyname>Amiot-Bazile</keyname><forenames>Caroline</forenames></author><author><keyname>Arnal</keyname><forenames>Fabrice</forenames></author><author><keyname>Boucheret</keyname><forenames>Marie-Laure</forenames></author></authors><title>Generic Approach for Hierarchical Modulation Performance Analysis:
  Application to DVB-SH</title><categories>cs.IT cs.PF math.IT</categories><comments>To appear in WTS 2011 proceedings</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Broadcasting systems have to deal with channel diversity in order to offer
the best rate to the users. Hierarchical modulation is a practical solution to
provide several rates in function of the channel quality. Unfortunately the
performance evaluation of such modulations requires time consuming simulations.
We propose in this paper a novel approach based on the channel capacity to
avoid these simulations. The method allows to study the performance in terms of
spectrum efficiency of hierarchical and also classical modulations combined
with error correcting codes. Our method will be applied to the DVB-SH standard
which considers hierarchical modulation as an optional feature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1306</identifier>
 <datestamp>2011-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1306</id><created>2011-03-07</created><authors><author><keyname>Yuksel</keyname><forenames>Melda</forenames></author><author><keyname>Liu</keyname><forenames>Xi</forenames></author><author><keyname>Erkip</keyname><forenames>Elza</forenames></author></authors><title>A Secure Communication Game with a Relay Helping the Eavesdropper</title><categories>cs.IT math.IT</categories><comments>13 pages, 11 figures, to appear in IEEE Transactions on Information
  Forensics and Security, Special Issue on Using the Physical Layer for
  Securing the Next Generation of Communication Systems. This is the journal
  version of cs.IT:0911.0089</comments><doi>10.1109/TIFS.2011.2125956</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work a four terminal complex Gaussian network composed of a source, a
destination, an eavesdropper and a jammer relay is studied under two different
set of assumptions: (i) The jammer relay does not hear the source transmission,
and (ii) The jammer relay is causally given the source message. In both cases
the jammer relay assists the eavesdropper and aims to decrease the achievable
secrecy rates. The source, on the other hand, aims to increase it. To help the
eavesdropper, the jammer relay can use pure relaying and/or send interference.
Each of the problems is formulated as a two-player, non-cooperative, zero-sum
continuous game. Assuming Gaussian strategies at the source and the jammer
relay in the first problem, the Nash equilibrium is found and shown to be
achieved with mixed strategies in general. The optimal cumulative distribution
functions (cdf) for the source and the jammer relay that achieve the value of
the game, which is the Nash equilibrium secrecy rate, are found. For the second
problem, the Nash equilibrium solution is found and the results are compared to
the case when the jammer relay is not informed about the source message.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1334</identifier>
 <datestamp>2011-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1334</id><created>2011-03-07</created><authors><author><keyname>Majkic</keyname><forenames>Zoran</forenames></author></authors><title>Binary Sequent Calculi for Truth-invariance Entailment of Finite
  Many-valued Logics</title><categories>cs.LO</categories><comments>21 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider the class of truth-functional many-valued logics
with a finite set of truth-values. The main result of this paper is the
development of a new \emph{binary} sequent calculi (each sequent is a pair of
formulae) for many valued logic with a finite set of truth values, and of
Kripke-like semantics for it that is both sound and complete. We did not use
the logic entailment based on matrix with a strict subset of designated truth
values, but a different new kind of semantics based on the generalization of
the classic 2-valued truth-invariance entailment. In order to define this
non-matrix based sequent calculi, we transform many-valued logic into positive
2-valued multi-modal logic with classic conjunction, disjunction and finite set
of modal connectives. In this algebraic framework we define an uniquely
determined axiom system, by extending the classic 2-valued distributive lattice
logic (DLL) by a new set of sequent axioms for many-valued logic connectives.
Dually, in an autoreferential Kripke-style framework we obtain a uniquely
determined frame, where each possible world is an equivalence class of
Lindenbaum algebra for a many-valued logic as well, represented by a truth
value.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1343</identifier>
 <datestamp>2012-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1343</id><created>2011-03-07</created><updated>2012-02-23</updated><authors><author><keyname>Petreczy</keyname><forenames>Mihaly</forenames></author><author><keyname>Bako</keyname><forenames>Laurent</forenames></author><author><keyname>van Schuppen</keyname><forenames>Jan H.</forenames></author></authors><title>Realization theory of discrete-time linear switched systems</title><categories>math.OC cs.SY</categories><comments>Some typos have been corrected and Algorithm 1 (realization
  algorithm) has been added, together with a theorem stating the correctness of
  the algorithm</comments><msc-class>93B15, 93B20, 93B25, 93C99</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper presents realization theory of discrete-time linear switched
systems. A discrete-time linear switched system is a hybrid system, such that
the continuous sub-system associated with each discrete state is linear. In
this paper we present necessary and sufficient conditions for an input-output
map to admit a discrete-time linear switched state-space realization. The
conditions are formulated as finite rank conditions of a generalized
Hankel-matrix. In addition, we present a characterization of minimality of
discrete-time linear switched systems in terms of reachability and
observable.Further, we prove that minimal realizations are unique up to
isomorphism. We also discuss procedures for converting a linear switched system
to a minimal one and we present an algorithm for constructing a state-space
representation from input-output data.The paper uses the theory rational formal
power series in non-commutative variables. The latter theory was successfully
applied to bilinear and state-affine systems in the past.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1349</identifier>
 <datestamp>2011-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1349</id><created>2011-03-07</created><authors><author><keyname>Petreczky</keyname><forenames>Mihaly</forenames></author><author><keyname>Bako</keyname><forenames>Laurent</forenames></author></authors><title>On the notion of persistence of excitation for linear switched systems</title><categories>math.OC cs.SY</categories><msc-class>93B15, 93B20, 93B25, 93C99</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper formulates the concept of persistence of excitation for
discrete-time linear switched systems, and provides sufficient conditions for
an input signal to be persistently exciting. Persistence of excitation is
formulated as a property of the input signal, and it is not tied to any
specific identification algorithm. The results of the paper rely on realization
theory and on the notion of Markov-parameters for linear switched systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1353</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1353</id><created>2011-03-07</created><authors><author><keyname>Kufleitner</keyname><forenames>Manfred</forenames></author><author><keyname>Lauser</keyname><forenames>Alexander</forenames></author></authors><title>Around Dot-depth One</title><categories>cs.FL cs.LO</categories><report-no>Technical report no. 2011/03, University of Stuttgart, Computer
  Science</report-no><msc-class>68Q45</msc-class><acm-class>F.4.1; F.4.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The dot-depth hierarchy is a classification of star-free languages. It is
related to the quantifier alternation hierarchy of first-order logic over
finite words. We consider fragments of languages with dot-depth 1/2 and
dot-depth 1 obtained by prohibiting the specification of prefixes or suffixes.
As it turns out, these language classes are in one-to-one correspondence with
fragments of existential first-order logic without min- or max-predicate. For
all fragments, we obtain effective algebraic characterizations. Moreover, we
give new combinatorial proofs for the decidability of the membership problem
for dot-depth 1/2 and dot-depth 1.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1359</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1359</id><created>2011-03-07</created><authors><author><keyname>Adali</keyname><forenames>Sibel</forenames></author><author><keyname>Liu</keyname><forenames>Tina</forenames></author><author><keyname>Magdon-Ismail</keyname><forenames>Malik</forenames></author></authors><title>An Analysis of Optimal Link Bombs</title><categories>cs.DM cs.SI</categories><comments>Full Version of a version which appeared in AIRweb 2005</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze the phenomenon of collusion for the purpose of boosting the
pagerank of a node in an interlinked environment. We investigate the optimal
attack pattern for a group of nodes (attackers) attempting to improve the
ranking of a specific node (the victim). We consider attacks where the
attackers can only manipulate their own outgoing links. We show that the
optimal attacks in this scenario are uncoordinated, i.e. the attackers link
directly to the victim and no one else. nodes do not link to each other. We
also discuss optimal attack patterns for a group that wants to hide itself by
not pointing directly to the victim. In these disguised attacks, the attackers
link to nodes $l$ hops away from the victim. We show that an optimal disguised
attack exists and how it can be computed. The optimal disguised attack also
allows us to find optimal link farm configurations. A link farm can be
considered a special case of our approach: the target page of the link farm is
the victim and the other nodes in the link farm are the attackers for the
purpose of improving the rank of the victim. The target page can however
control its own outgoing links for the purpose of improving its own rank, which
can be modeled as an optimal disguised attack of 1-hop on itself. Our results
are unique in the literature as we show optimality not only in the pagerank
score, but also in the rank based on the pagerank score. We further validate
our results with experiments on a variety of random graph models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1360</identifier>
 <datestamp>2011-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1360</id><created>2011-03-07</created><updated>2011-03-08</updated><authors><author><keyname>Chaudhuri</keyname><forenames>Sumanta</forenames></author><author><keyname>Guilley</keyname><forenames>Sylvain</forenames></author><author><keyname>Hoogvorst</keyname><forenames>Philippe</forenames></author><author><keyname>Danger</keyname><forenames>Jean-Luc</forenames></author><author><keyname>Beyrouthy</keyname><forenames>Taha</forenames></author><author><keyname>Razafindraibe</keyname><forenames>Alin</forenames></author><author><keyname>Fesquet</keyname><forenames>Laurent</forenames></author><author><keyname>Renaudin</keyname><forenames>Marc</forenames></author></authors><title>A Secure Asynchronous FPGA Architecture, Experimental Results and Some
  Debug Feedback</title><categories>cs.AR cs.CR</categories><comments>18 Pages, 23 figures. In detail description of a 3X3 Aysnchronous
  FPGA Tape-Out</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article presents an asynchronous FPGA architecture for implementing
cryptographic algorithms secured against physical cryptanalysis. We discuss the
suitability of asynchronous reconfigurable architectures for such applications
before proceeding to model the side channel and defining our objectives. The
logic block architecture is presented in detail. We discuss several solutions
for the interconnect architecture, and how these solutions can be ported to
other flavours of interconnect (i.e. single driver). Next We discuss in detail
a high speed asynchronous configuration chain architecture used to configure
our asynchronous FPGA with simulation results, and we present a 3 X 3 prototype
FPGA fabricated in 65 nm CMOS. Lastly we present experiments to test the high
speed asynchronous configuration chain and evaluate how far our objectives have
been achieved with proposed solutions, and we conclude with emphasis on
complementary FPGA CAD algorithms, and the effect of CMOS variation on
Side-Channel Vulnerability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1362</identifier>
 <datestamp>2012-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1362</id><created>2011-03-07</created><updated>2012-04-26</updated><authors><author><keyname>Tobin-Hochstadt</keyname><forenames>Sam</forenames></author><author><keyname>Van Horn</keyname><forenames>David</forenames></author></authors><title>Higher-Order Symbolic Execution via Contracts</title><categories>cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new approach to automated reasoning about higher-order programs
by extending symbolic execution to use behavioral contracts as symbolic values,
enabling symbolic approximation of higher-order behavior.
  Our approach is based on the idea of an abstract reduction semantics that
gives an operational semantics to programs with both concrete and symbolic
components. Symbolic components are approximated by their contract and our
semantics gives an operational interpretation of contracts-as-values. The
result is a executable semantics that soundly predicts program behavior,
including contract failures, for all possible instantiations of symbolic
components. We show that our approach scales to an expressive language of
contracts including arbitrary programs embedded as predicates, dependent
function contracts, and recursive contracts. Supporting this feature-rich
language of specifications leads to powerful symbolic reasoning using existing
program assertions.
  We then apply our approach to produce a verifier for contract correctness of
components, including a sound and computable approximation to our semantics
that facilitates fully automated contract verification. Our implementation is
capable of verifying contracts expressed in existing programs, and of
justifying valuable contract-elimination optimizations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1365</identifier>
 <datestamp>2011-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1365</id><created>2011-03-07</created><updated>2011-08-08</updated><authors><author><keyname>Amini</keyname><forenames>Hadis</forenames></author><author><keyname>Rouchon</keyname><forenames>Pierre</forenames></author><author><keyname>Mirrahimi</keyname><forenames>Mazyar</forenames></author></authors><title>Design of Strict Control-Lyapunov Functions for Quantum Systems with QND
  Measurements</title><categories>math.OC cs.SY quant-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider discrete-time quantum systems subject to Quantum Non-Demolition
(QND) measurements and controlled by an adjustable unitary evolution between
two successive QND measures. In open-loop, such QND measurements provide a
non-deterministic preparation tool exploiting the back-action of the
measurement on the quantum state. We propose here a systematic method based on
elementary graph theory and inversion of Laplacian matrices to construct strict
control-Lyapunov functions. This yields an appropriate feedback law that
stabilizes globally the system towards a chosen target state among the
open-loop stable ones, and that makes in closed-loop this preparation
deterministic. We illustrate such feedback laws through simulations
corresponding to an experimental setup with QND photon counting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1367</identifier>
 <datestamp>2011-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1367</id><created>2011-03-07</created><authors><author><keyname>Li</keyname><forenames>Chao</forenames></author><author><keyname>Miklau</keyname><forenames>Gerome</forenames></author></authors><title>Efficient Batch Query Answering Under Differential Privacy</title><categories>cs.DB</categories><comments>6 figues, 22 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Differential privacy is a rigorous privacy condition achieved by randomizing
query answers. This paper develops efficient algorithms for answering multiple
queries under differential privacy with low error. We pursue this goal by
advancing a recent approach called the matrix mechanism, which generalizes
standard differentially private mechanisms. This new mechanism works by first
answering a different set of queries (a strategy) and then inferring the
answers to the desired workload of queries. Although a few strategies are known
to work well on specific workloads, finding the strategy which minimizes error
on an arbitrary workload is intractable. We prove a new lower bound on the
optimal error of this mechanism, and we propose an efficient algorithm that
approaches this bound for a wide range of workloads.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1396</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1396</id><created>2011-03-07</created><authors><author><keyname>Schneider</keyname><forenames>Christian M.</forenames></author><author><keyname>de Arcangelis</keyname><forenames>Lucilla</forenames></author><author><keyname>Herrmann</keyname><forenames>Hans J.</forenames></author></authors><title>Scale free networks by preferential depletion</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI physics.bio-ph physics.comp-ph</categories><comments>8 pages, 4 figures</comments><doi>10.1209/0295-5075/95/16005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that not only preferential attachment but also preferential depletion
leads to scale-free networks. The resulting degree distribution exponents is
typically less than two (5/3) as opposed to the case of the growth models
studied before where the exponents are larger. Our approach applies in
particular to biological networks where in fact we find interesting agreement
with experimental measurements. We investigate the most important properties
characterizing these networks, as the cluster size distribution, the average
shortest path and the clustering coefficient.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1401</identifier>
 <datestamp>2011-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1401</id><created>2011-03-07</created><updated>2011-04-08</updated><authors><author><keyname>Urgaonkar</keyname><forenames>Rahul</forenames></author><author><keyname>Neely</keyname><forenames>Michael J.</forenames></author></authors><title>Opportunistic Cooperation in Cognitive Femtocell Networks</title><categories>math.OC cs.SY</categories><comments>Fixes proof of Lemma 2</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate opportunistic cooperation between unlicensed secondary users
and legacy primary users in a cognitive radio network. Specifically, we
consider a model of a cognitive network where a secondary user can
cooperatively transmit with the primary user in order to improve the latter's
effective transmission rate. In return, the secondary user gets more
opportunities for transmitting its own data when the primary user is idle. This
kind of interaction between the primary and secondary users is different from
the traditional dynamic spectrum access model in which the secondary users try
to avoid interfering with the primary users while seeking transmission
opportunities on vacant primary channels. In our model, the secondary users
need to balance the desire to cooperate more (to create more transmission
opportunities) with the need for maintaining sufficient energy levels for their
own transmissions. Such a model is applicable in the emerging area of cognitive
femtocell networks. We formulate the problem of maximizing the secondary user
throughput subject to a time average power constraint under these settings.
This is a constrained Markov Decision Problem and conventional solution
techniques based on dynamic programming require either extensive knowledge of
the system dynamics or learning based approaches that suffer from large
convergence times. However, using the technique of Lyapunov optimization, we
design a novel greedy and online control algorithm that overcomes these
challenges and is provably optimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1403</identifier>
 <datestamp>2011-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1403</id><created>2011-03-07</created><authors><author><keyname>Vellambi</keyname><forenames>Badri N.</forenames></author><author><keyname>Torabkhani</keyname><forenames>Nima</forenames></author><author><keyname>Fekri</keyname><forenames>Faramarz</forenames></author></authors><title>Study of Throughput and Delay in Finite-Buffer Line Networks</title><categories>cs.IT math.IT</categories><comments>5 pages, 8 figures, ITA 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we study the effects of finite buffers on the throughput and
delay of line networks with erasure links. We identify the calculation of
performance parameters such as throughput and delay to be equivalent to
determining the stationary distribution of an irreducible Markov chain. We note
that the number of states in the Markov chain grows exponentially in the size
of the buffers with the exponent scaling linearly with the number of hops in a
line network. We then propose a simplified iterative scheme to approximately
identify the steady-state distribution of the chain by decoupling the chain to
smaller chains. The approximate solution is then used to understand the effect
of buffer sizes on throughput and distribution of packet delay. Further, we
classify nodes based on congestion that yields an intelligent scheme for memory
allocation using the proposed framework. Finally, by simulations we confirm
that our framework yields an accurate prediction of the variation of the
throughput and delay distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1417</identifier>
 <datestamp>2012-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1417</id><created>2011-03-07</created><updated>2012-11-20</updated><authors><author><keyname>Javanmard</keyname><forenames>Adel</forenames></author><author><keyname>Montanari</keyname><forenames>Andrea</forenames></author></authors><title>Localization from Incomplete Noisy Distance Measurements</title><categories>math.ST cs.LG cs.SY math.OC math.PR stat.TH</categories><comments>46 pages, 8 figures, numerical experiments added. Journal version
  (v1,v2: Conference versions, ISIT 2011); Journal of Foundations of
  Computational Mathematics, 2012</comments><doi>10.1007/s10208-012-9129-5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of positioning a cloud of points in the Euclidean
space $\mathbb{R}^d$, using noisy measurements of a subset of pairwise
distances. This task has applications in various areas, such as sensor network
localization and reconstruction of protein conformations from NMR measurements.
Also, it is closely related to dimensionality reduction problems and manifold
learning, where the goal is to learn the underlying global geometry of a data
set using local (or partial) metric information. Here we propose a
reconstruction algorithm based on semidefinite programming. For a random
geometric graph model and uniformly bounded noise, we provide a precise
characterization of the algorithm's performance: In the noiseless case, we find
a radius $r_0$ beyond which the algorithm reconstructs the exact positions (up
to rigid transformations). In the presence of noise, we obtain upper and lower
bounds on the reconstruction error that match up to a factor that depends only
on the dimension $d$, and the average degree of the nodes in the graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1424</identifier>
 <datestamp>2012-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1424</id><created>2011-03-07</created><updated>2012-06-05</updated><authors><author><keyname>Abediseid</keyname><forenames>Walid</forenames></author></authors><title>On the Average Complexity of Sphere Decoding in Lattice Space-Time Coded
  MIMO Channel</title><categories>cs.IT math.IT</categories><comments>16 Pages, 4 Figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The exact average complexity analysis of the basic sphere decoder for general
space-time codes applied to multiple-input multiple-output (MIMO) wireless
channel is known to be difficult. In this work, we shed the light on the
computational complexity of sphere decoding for the quasi-static, LAttice
Space-Time (LAST) coded MIMO channel. Specifically, we drive an upper bound of
the tail distribution of the decoder's computational complexity. We show that,
when the computational complexity exceeds a certain limit, this upper bound
becomes dominated by the outage probability achieved by LAST coding and sphere
decoding schemes. We then calculate the minimum average computational
complexity that is required by the decoder to achieve near optimal performance
in terms of the system parameters. Our results indicate that there exists a
cut-off rate (multiplexing gain) for which the average complexity remains
bounded.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1431</identifier>
 <datestamp>2011-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1431</id><created>2011-03-07</created><authors><author><keyname>Chan</keyname><forenames>Timothy M.</forenames></author><author><keyname>Har-Peled</keyname><forenames>Sariel</forenames></author></authors><title>Approximation Algorithms for Maximum Independent Set of Pseudo-Disks</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present approximation algorithms for maximum independent set of
pseudo-disks in the plane, both in the weighted and unweighted cases. For the
unweighted case, we prove that a local search algorithm yields a \PTAS. For the
weighted case, we suggest a novel rounding scheme based on an \LP relaxation of
the problem, which leads to a constant-factor approximation. Most previous
algorithms for maximum independent set (in geometric settings) relied on
packing arguments that are not applicable in this case. As such, the analysis
of both algorithms requires some new combinatorial ideas, which we believe to
be of independent interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1432</identifier>
 <datestamp>2011-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1432</id><created>2011-03-07</created><updated>2011-09-13</updated><authors><author><keyname>Marjane</keyname><forenames>Abdelaziz</forenames></author><author><keyname>Mokrane</keyname><forenames>Abdellah</forenames></author><author><keyname>Allailou</keyname><forenames>Boufeldja</forenames></author></authors><title>Vectorial Feedback with Carry Registers and Memory requirements</title><categories>cs.IT cs.CR math.IT</categories><comments>12 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In \cite{marjane2010}, we have introduced vectorial conception of FCSR's in
Fibonacci mode. This conception allows us to easily analyze FCSR's over binary
finite fields $\mathbb{F}_{2^{n}}$ for $n\geq 2$. In \cite{allailou2010}, we
describe and study the corresponding Galois mode and use it to design a new
stream cipher. In this paper, we introduce the Ring mode for vectorial FCSR,
explain the analysis of such Feedback registers and illustrate with a simple
example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1433</identifier>
 <datestamp>2016-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1433</id><created>2011-03-07</created><authors><author><keyname>Goldblatt</keyname><forenames>Robert</forenames></author><author><keyname>Jackson</keyname><forenames>Marcel</forenames></author></authors><title>Well structured program equivalence is highly undecidable</title><categories>cs.LO math.LO</categories><comments>8 pages</comments><doi>10.1145/2287718.2287726</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that strict deterministic propositional dynamic logic with
intersection is highly undecidable, solving a problem in the Stanford
Encyclopedia of Philosophy. In fact we show something quite a bit stronger. We
introduce the construction of program equivalence, which returns the value
$\mathsf{T}$ precisely when two given programs are equivalent on halting
computations. We show that virtually any variant of propositional dynamic logic
has $\Pi_1^1$-hard validity problem if it can express even just the equivalence
of well-structured programs with the empty program \texttt{skip}. We also show,
in these cases, that the set of propositional statements valid over finite
models is not recursively enumerable, so there is not even an axiomatisation
for finitely valid propositions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1439</identifier>
 <datestamp>2013-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1439</id><created>2011-03-08</created><updated>2013-09-10</updated><authors><author><keyname>Mimura</keyname><forenames>Kazushi</forenames></author><author><keyname>Okada</keyname><forenames>Masato</forenames></author></authors><title>Generating Functional Analysis for Iterative CDMA Multiuser Detectors</title><categories>cs.IT cond-mat.dis-nn math.IT</categories><comments>28 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the detection dynamics of a soft parallel interference
canceller (soft-PIC), which includes a hard-PIC as a special case, for
code-division multiple-access (CDMA) multiuser detection, applied to a randomly
spread, fully synchronous base-band uncoded CDMA channel model with additive
white Gaussian noise under perfect power control in the large-system limit. We
analyze the detection dynamics of some iterative detectors, namely soft-PIC,
the Onsager-reaction-cancelling parallel interference canceller (ORC-PIC) and
the belief-propagation-based detector (BP-based detector), by the generating
functional analysis (GFA). The GFA allows us to study the asymptotic behavior
of the dynamics in the infinitely large system without assuming the
independence of messages. We study the detection dynamics and the stationary
estimates of an iterative algorithm.
  We also show the decoupling principle in iterative multiuser detection
algorithms in the large-system limit. For a generic iterative multiuser
detection algorithm with binary input, it is shown that the multiuser channel
is equivalent to a bank of independent single-user additive non-Gaussian
channels, whose signal-to-noise ratio degrades due to both the multiple-access
interference and the Onsager reaction, at each stage of the algorithm. If an
algorithm cancels the Onsager reaction, the equivalent single-user channels
coincide with an additive white Gaussian noise channel. We also discuss ORC-PIC
and the BP-based detector.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1448</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1448</id><created>2011-03-08</created><updated>2011-04-07</updated><authors><author><keyname>Al-Zubaidy</keyname><forenames>Hussein</forenames></author><author><keyname>Lambadaris</keyname><forenames>Ioannis</forenames></author><author><keyname>Viniotis</keyname><forenames>Yannis</forenames></author></authors><title>Optimal Multi-Server Allocation to Parallel Queues With Independent
  Random Queue-Server Connectivity</title><categories>cs.IT cs.NI cs.SY math.IT math.OC</categories><comments>53 single-column pages, 8 figures</comments><msc-class>93E20 Optimal stochastic control</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate an optimal scheduling problem in a discrete-time system of L
parallel queues that are served by K identical, randomly connected servers.
Each queue may be connected to a subset of the K servers during any given time
slot. This model has been widely used in studies of emerging 3G/4G wireless
systems. We introduce the class of Most Balancing (MB) policies and provide
their mathematical characterization. We prove that MB policies are optimal; we
de?ne optimality as minimization, in stochastic ordering sense, of a range of
cost functions of the queue lengths, including the process of total number of
packets in the system. We use stochastic coupling arguments for our proof. We
introduce the Least Connected Server First/Longest Connected Queue (LCSF/LCQ)
policy as an easy-to-implement approximation of MB policies. We conduct a
simulation study to compare the performance of several policies. The simulation
results show that: (a) in all cases, LCSF/LCQ approximations to the MB policies
outperform the other policies, (b) randomized policies perform fairly close to
the optimal one, and, (c) the performance advantage of the optimal policy over
the other simulated policies increases as the channel connectivity probability
decreases and as the number of servers in the system increases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1453</identifier>
 <datestamp>2011-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1453</id><created>2011-03-08</created><authors><author><keyname>Qureshi</keyname><forenames>Jalaluddin</forenames></author><author><keyname>Cai</keyname><forenames>Jianfei</forenames></author><author><keyname>Foh</keyname><forenames>Chuan Heng</forenames></author></authors><title>Cooperative Retransmissions Through Collisions</title><categories>cs.IT cs.NI math.IT</categories><comments>IEEE ICC 2011, Kyoto, Japan. 5 pages, 5 figures, 2 tables. Analog
  Network Coding, Retransmission, Access Point, WLAN, interference, collision,
  capacity, packet loss</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Interference in wireless networks is one of the key capacity-limiting
factors. Recently developed interference-embracing techniques show promising
performance on turning collisions into useful transmissions. However, the
interference-embracing techniques are hard to apply in practical applications
due to their strict requirements. In this paper, we consider utilising the
interference-embracing techniques in a common scenario of two interfering
sender-receiver pairs. By employing opportunistic listening and analog network
coding (ANC), we show that compared to traditional ARQ retransmission, a higher
retransmission throughput can be achieved by allowing two interfering senders
to cooperatively retransmit selected lost packets at the same time. This
simultaneous retransmission is facilitated by a simple handshaking procedure
without introducing additional overhead. Simulation results demonstrate the
superior performance of the proposed cooperative retransmission.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1474</identifier>
 <datestamp>2011-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1474</id><created>2011-03-08</created><authors><author><keyname>Egger</keyname><forenames>Jan</forenames></author><author><keyname>Bauer</keyname><forenames>Miriam H. A.</forenames></author><author><keyname>Kuhnt</keyname><forenames>Daniela</forenames></author><author><keyname>Carl</keyname><forenames>Barbara</forenames></author><author><keyname>Kappus</keyname><forenames>Christoph</forenames></author><author><keyname>Freisleben</keyname><forenames>Bernd</forenames></author><author><keyname>Nimsky</keyname><forenames>Christopher</forenames></author></authors><title>Evaluation of a Novel Approach for Automatic Volume Determination of
  Glioblastomas Based on Several Manual Expert Segmentations</title><categories>cs.CV physics.med-ph q-bio.TO</categories><comments>4 pages, 4 figures, BMT 2010, Rostock</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The glioblastoma multiforme is the most common malignant primary brain tumor
and is one of the highest malignant human neoplasms. During the course of
disease, the evaluation of tumor volume is an essential part of the clinical
follow-up. However, manual segmentation for acquisition of tumor volume is a
time-consuming process. In this paper, a new approach for the automatic
segmentation and volume determination of glioblastomas (glioblastoma
multiforme) is presented and evaluated. The approach uses a user-defined seed
point inside the glioma to set up a directed 3D graph. The nodes of the graph
are obtained by sampling along rays that are sent through the surface points of
a polyhedron. After the graph has been constructed, the minimal s-t cut is
calculated to separate the glioblastoma from the background. For evaluation, 12
Magnetic Resonance Imaging (MRI) data sets were manually segmented slice by
slice, by neurosurgeons with several years of experience in the resection of
gliomas. Afterwards, the manual segmentations were compared with the results of
the presented approach via the Dice Similarity Coefficient (DSC). For a better
assessment of the DSC results, the manual segmentations of the experts were
also compared with each other and evaluated via the DSC. In addition, the 12
data sets were segmented once again by one of the neurosurgeons after a period
of two weeks, to also measure the intra-physician deviation of the DSC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1475</identifier>
 <datestamp>2011-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1475</id><created>2011-03-08</created><authors><author><keyname>Bauer</keyname><forenames>Miriam H. A.</forenames></author><author><keyname>Egger</keyname><forenames>Jan</forenames></author><author><keyname>Kuhnt</keyname><forenames>Daniela</forenames></author><author><keyname>Barbieri</keyname><forenames>Sebastiano</forenames></author><author><keyname>Klein</keyname><forenames>Jan</forenames></author><author><keyname>Hahn</keyname><forenames>Horst K.</forenames></author><author><keyname>Freisleben</keyname><forenames>Bernd</forenames></author><author><keyname>Nimsky</keyname><forenames>Christopher</forenames></author></authors><title>A Semi-Automatic Graph-Based Approach for Determining the Boundary of
  Eloquent Fiber Bundles in the Human Brain</title><categories>cs.CV</categories><comments>4 pages, 3 figures, BMT 2010, Rostock</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Diffusion Tensor Imaging (DTI) allows estimating the position, orientation
and dimension of bundles of nerve pathways. This non-invasive imaging technique
takes advantage of the diffusion of water molecules and determines the
diffusion coefficients for every voxel of the data set. The identification of
the diffusion coefficients and the derivation of information about fiber
bundles is of major interest for planning and performing neurosurgical
interventions. To minimize the risk of neural deficits during brain surgery as
tumor resection (e.g. glioma), the segmentation and integration of the results
in the operating room is of prime importance. In this contribution, a robust
and efficient graph-based approach for segmentating tubular fiber bundles in
the human brain is presented. To define a cost function, the fractional
anisotropy (FA) is used, derived from the DTI data, but this value may differ
from patient to patient. Besides manually definining seed regions describing
the structure of interest, additionally a manual definition of the cost
function by the user is necessary. To improve the approach the contribution
introduces a solution for automatically determining the cost function by using
different 3D masks for each individual data set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1482</identifier>
 <datestamp>2011-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1482</id><created>2011-03-08</created><authors><author><keyname>Lange</keyname><forenames>Christoph</forenames></author><author><keyname>Kohlhase</keyname><forenames>Michael</forenames></author><author><keyname>David</keyname><forenames>Catalin</forenames></author><author><keyname>Ginev</keyname><forenames>Deyan</forenames></author><author><keyname>Kohlhase</keyname><forenames>Andrea</forenames></author><author><keyname>Matican</keyname><forenames>Bogdan</forenames></author><author><keyname>Mirea</keyname><forenames>Stefan</forenames></author><author><keyname>Zholudev</keyname><forenames>Vyacheslav</forenames></author></authors><title>The Planetary System: Executable Science, Technology, Engineering and
  Math Papers</title><categories>cs.DL cs.MS</categories><comments>Extended Semantic Web Conference (ESWC 2011), Demo Track. To be
  published in the Springer LNCS series</comments><msc-class>68T35</msc-class><acm-class>H.3.5; I.2.1; I.2.6; I.7.1; I.7.2; J.2; K.4.3</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Executable scientific papers contain not just layouted text for reading. They
contain, or link to, machine-comprehensible representations of the scientific
findings or experiments they describe. Client-side players can thus enable
readers to &quot;check, manipulate and explore the result space&quot;. We have realized
executable papers in the STEM domain with the Planetary system. Semantic
annotations associate the papers with a content commons holding the background
ontology, the annotations are exposed as Linked Data, and a frontend player
application hooks modular interactive services into the semantic annotations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1493</identifier>
 <datestamp>2011-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1493</id><created>2011-03-08</created><authors><author><keyname>Zhang</keyname><forenames>Qizhi</forenames></author></authors><title>An Improvement to the Number Field Sieve</title><categories>math.NT cs.CC</categories><comments>9 pages</comments><msc-class>11Y05, 11Y16</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We improve the &quot;sieve&quot; part of the number field sieve used in factoring
integer and computing discrete logarithm. The runtime of our method is shorter
than that of existing methods. Under some reasonable assumptions, we prove that
it is less than two-thirds of the running time of the algorithm used before
asymptotically with probability gr
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1497</identifier>
 <datestamp>2011-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1497</id><created>2011-03-08</created><authors><author><keyname>Jalender</keyname><forenames>B.</forenames></author><author><keyname>Govardhan</keyname><forenames>A.</forenames></author><author><keyname>Premchand</keyname><forenames>P.</forenames></author><author><keyname>Kiranmai</keyname><forenames>C.</forenames></author><author><keyname>Reddy</keyname><forenames>G. Suresh</forenames></author></authors><title>Drag and Drop: Influences on the Design of Reusable Software Components</title><categories>cs.SE</categories><comments>8 pages, 6 figures, International Journal on Computer Science and
  Engineering (IJCSE)</comments><journal-ref>International Journal on Computer Science and Engineering(IJCSE)
  Vol. 02, No. 07, 2010, 2386-2393</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The fundamental unit of large scale software construction is the component. A
component is the fundamental user interface object in Java. Everything you see
on the display in a java application is a component. The ability to let users
drag a component from the Interface and drop into your application is almost a
requirement of a modern, commercial user interface. The CBD approach brings
high component reusability and easy maintainability, and reduces
time-to-market. This paper describes the component repository which provides
functionality for component reuse process through the drag and drop mechanism
and it's influences on the reusable components
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1503</identifier>
 <datestamp>2011-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1503</id><created>2011-03-08</created><authors><author><keyname>Canzar</keyname><forenames>Stefan</forenames></author><author><keyname>Toussaint</keyname><forenames>Nora C.</forenames></author><author><keyname>Klau</keyname><forenames>Gunnar W.</forenames></author></authors><title>An Exact Algorithm for Side-Chain Placement in Protein Design</title><categories>cs.DS</categories><doi>10.1007/s11590-011-0308-0</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computational protein design aims at constructing novel or improved functions
on the structure of a given protein backbone and has important applications in
the pharmaceutical and biotechnical industry. The underlying combinatorial
side-chain placement problem consists of choosing a side-chain placement for
each residue position such that the resulting overall energy is minimum. The
choice of the side-chain then also determines the amino acid for this position.
Many algorithms for this NP-hard problem have been proposed in the context of
homology modeling, which, however, reach their limits when faced with large
protein design instances.
  In this paper, we propose a new exact method for the side-chain placement
problem that works well even for large instance sizes as they appear in protein
design. Our main contribution is a dedicated branch-and-bound algorithm that
combines tight upper and lower bounds resulting from a novel Lagrangian
relaxation approach for side-chain placement. Our experimental results show
that our method outperforms alternative state-of-the art exact approaches and
makes it possible to optimally solve large protein design instances routinely.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1516</identifier>
 <datestamp>2011-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1516</id><created>2011-03-08</created><authors><author><keyname>Lahimer</keyname><forenames>Asma</forenames><affiliation>LAAS</affiliation></author><author><keyname>Lopez</keyname><forenames>Pierre</forenames><affiliation>LAAS</affiliation></author><author><keyname>Haouari</keyname><forenames>Mohamed</forenames></author></authors><title>Climbing depth-bounded adjacent discrepancy search for solving hybrid
  flow shop scheduling problems with multiprocessor tasks</title><categories>cs.RO cs.AI</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers multiprocessor task scheduling in a multistage hybrid
flow-shop environment. The problem even in its simplest form is NP-hard in the
strong sense. The great deal of interest for this problem, besides its
theoretical complexity, is animated by needs of various manufacturing and
computing systems. We propose a new approach based on limited discrepancy
search to solve the problem. Our method is tested with reference to a proposed
lower bound as well as the best-known solutions in literature. Computational
results show that the developed approach is efficient in particular for
large-size problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1518</identifier>
 <datestamp>2011-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1518</id><created>2011-03-08</created><authors><author><keyname>Blond</keyname><forenames>Stevens Le</forenames><affiliation>INRIA Sophia Antipolis / INRIA Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Manils</keyname><forenames>Pere</forenames><affiliation>INRIA Sophia Antipolis / INRIA Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Abdelberi</keyname><forenames>Chaabane</forenames><affiliation>INRIA Sophia Antipolis / INRIA Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Kaafar</keyname><forenames>Mohamed Ali Dali</forenames><affiliation>INRIA Sophia Antipolis / INRIA Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Castelluccia</keyname><forenames>Claude</forenames><affiliation>INRIA Sophia Antipolis / INRIA Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Legout</keyname><forenames>Arnaud</forenames><affiliation>INRIA Sophia Antipolis / INRIA Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Dabbous</keyname><forenames>Walid</forenames><affiliation>INRIA Sophia Antipolis / INRIA Rh&#xf4;ne-Alpes</affiliation></author></authors><title>One Bad Apple Spoils the Bunch: Exploiting P2P Applications to Trace and
  Profile Tor Users</title><categories>cs.NI</categories><proxy>ccsd</proxy><journal-ref>4th USENIX Workshop on Large-Scale Exploits and Emergent Threats
  (LEET '11) (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tor is a popular low-latency anonymity network. However, Tor does not protect
against the exploitation of an insecure application to reveal the IP address
of, or trace, a TCP stream. In addition, because of the linkability of Tor
streams sent together over a single circuit, tracing one stream sent over a
circuit traces them all. Surprisingly, it is unknown whether this linkability
allows in practice to trace a significant number of streams originating from
secure (i.e., proxied) applications. In this paper, we show that linkability
allows us to trace 193% of additional streams, including 27% of HTTP streams
possibly originating from &quot;secure&quot; browsers. In particular, we traced 9% of Tor
streams carried by our instrumented exit nodes. Using BitTorrent as the
insecure application, we design two attacks tracing BitTorrent users on Tor. We
run these attacks in the wild for 23 days and reveal 10,000 IP addresses of Tor
users. Using these IP addresses, we then profile not only the BitTorrent
downloads but also the websites visited per country of origin of Tor users. We
show that BitTorrent users on Tor are over-represented in some countries as
compared to BitTorrent users outside of Tor. By analyzing the type of content
downloaded, we then explain the observed behaviors by the higher concentration
of pornographic content downloaded at the scale of a country. Finally, we
present results suggesting the existence of an underground BitTorrent ecosystem
on Tor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1529</identifier>
 <datestamp>2011-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1529</id><created>2011-03-08</created><updated>2011-05-26</updated><authors><author><keyname>Bienvenu</keyname><forenames>Laurent</forenames></author><author><keyname>Gacs</keyname><forenames>Peter</forenames></author><author><keyname>Hoyrup</keyname><forenames>Mathieu</forenames></author><author><keyname>Rojas</keyname><forenames>Cristobal</forenames></author><author><keyname>Shen</keyname><forenames>Alexander</forenames></author></authors><title>Algorithmic tests and randomness with respect to a class of measures</title><categories>math.LO cs.IT math.IT math.PR</categories><msc-class>03D32, 68Q30</msc-class><acm-class>F.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper considers quantitative versions of different randomness notions:
algorithmic test measures the amount of non-randomness (and is infinite for
non-random sequences). We start with computable measures on Cantor space (and
Martin-Lof randomness), then consider uniform randomness (test is a function of
a sequence and a measure, not necessarily computable) and arbitrary
constructive metric spaces. We also consider tests for classes of measures, in
particular Bernoulli measures on Cantor space, and show how they are related to
uniform tests and original Martin-Lof definition. We show that Hyppocratic
(blind, oracle-free) randomness is equivalent to uniform randomness for
measures in an effectively orthogonal effectively compact class. We also
consider the notions of sparse set and on-line randomness and show how they can
be expressed in our framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1530</identifier>
 <datestamp>2011-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1530</id><created>2011-03-08</created><updated>2011-03-30</updated><authors><author><keyname>Fenner</keyname><forenames>Trevor</forenames></author><author><keyname>Levene</keyname><forenames>Mark</forenames></author><author><keyname>Loizou</keyname><forenames>George</forenames></author></authors><title>A Discrete Evolutionary Model for Chess Players' Ratings</title><categories>physics.soc-ph cs.AI</categories><comments>17 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Elo system for rating chess players, also used in other games and sports,
was adopted by the World Chess Federation over four decades ago. Although not
without controversy, it is accepted as generally reliable and provides a method
for assessing players' strengths and ranking them in official tournaments.
  It is generally accepted that the distribution of players' rating data is
approximately normal but, to date, no stochastic model of how the distribution
might have arisen has been proposed. We propose such an evolutionary stochastic
model, which models the arrival of players into the rating pool, the games they
play against each other, and how the results of these games affect their
ratings. Using a continuous approximation to the discrete model, we derive the
distribution for players' ratings at time $t$ as a normal distribution, where
the variance increases in time as a logarithmic function of $t$. We validate
the model using published rating data from 2007 to 2010, showing that the
parameters obtained from the data can be recovered through simulations of the
stochastic model.
  The distribution of players' ratings is only approximately normal and has
been shown to have a small negative skew. We show how to modify our
evolutionary stochastic model to take this skewness into account, and we
validate the modified model using the published official rating data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1542</identifier>
 <datestamp>2014-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1542</id><created>2011-03-08</created><updated>2014-07-08</updated><authors><author><keyname>Cohen</keyname><forenames>David A.</forenames></author><author><keyname>Cooper</keyname><forenames>Martin C.</forenames></author><author><keyname>Creed</keyname><forenames>P&#xe1;id&#xed;</forenames></author><author><keyname>Salamon</keyname><forenames>Andr&#xe1;s Z.</forenames></author></authors><title>The tractability of CSP classes defined by forbidden patterns</title><categories>cs.AI cs.CC cs.DS</categories><journal-ref>Journal Of Artificial Intelligence Research, Volume 45, pages
  47-78, 2012</journal-ref><doi>10.1613/jair.3651</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The constraint satisfaction problem (CSP) is a general problem central to
computer science and artificial intelligence. Although the CSP is NP-hard in
general, considerable effort has been spent on identifying tractable
subclasses. The main two approaches consider structural properties
(restrictions on the hypergraph of constraint scopes) and relational properties
(restrictions on the language of constraint relations). Recently, some authors
have considered hybrid properties that restrict the constraint hypergraph and
the relations simultaneously.
  Our key contribution is the novel concept of a CSP pattern and classes of
problems defined by forbidden patterns (which can be viewed as forbidding
generic subproblems). We describe the theoretical framework which can be used
to reason about classes of problems defined by forbidden patterns. We show that
this framework generalises relational properties and allows us to capture known
hybrid tractable classes.
  Although we are not close to obtaining a dichotomy concerning the
tractability of general forbidden patterns, we are able to make some progress
in a special case: classes of problems that arise when we can only forbid
binary negative patterns (generic subproblems in which only inconsistent tuples
are specified). In this case we are able to characterise very large classes of
tractable and NP-hard forbidden patterns. This leaves the complexity of just
one case unresolved and we conjecture that this last case is tractable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1544</identifier>
 <datestamp>2011-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1544</id><created>2011-03-08</created><authors><author><keyname>Pal</keyname><forenames>Ranjan</forenames></author><author><keyname>Kailas</keyname><forenames>Aravind</forenames></author></authors><title>Cost Sharing in Social Community Networks</title><categories>cs.NI cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless social community networks (WSCNs) is an emerging technology that
operate in the unlicensed spectrum and have been created as an alternative to
cellular wireless networks for providing low-cost, high speed wireless data
access in urban areas. WSCNs is an upcoming idea that is starting to gain
attention amongst the civilian Internet users. By using \emph{special} WiFi
routers that are provided by a social community network provider (SCNP), users
can effectively share their connection with the neighborhood in return for some
monthly monetary benefits. However, deployment maps of existing WSCNs reflect
their slow progress in capturing the WiFi router market. In this paper, we look
at a router design and cost sharing problem in WSCNs to improve deployment. We
devise asimple to implement, successful a mechanism is successful if it
achieves its intended purpose. For example in this work, a successful mechanism
would help install routers in a locality}, \emph{budget-balanced},
\emph{ex-post efficient}, and \emph{individually rational} {a mechanism is
individually rational if the benefit each agent obtains is greater than its
cost.} auction-based mechanism that generates the \emph{optimal} number of
features a router should have and allocates costs to residential users in
\emph{proportion} to the feature benefits they receive. Our problem is
important to a new-entrant SCNP when it wants to design its multi-feature
routers with the goal to popularize them and increase their deployment in a
residential locality. Our proposed mechanism accounts for heterogeneous user
preferences towards different router features and comes up with the optimal
\emph{(feature-set, user costs)} router blueprint that satisfies each user in a
locality, in turn motivating them to buy routers and thereby improve
deployment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1552</identifier>
 <datestamp>2011-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1552</id><created>2011-03-08</created><authors><author><keyname>Pal</keyname><forenames>Ranjan</forenames></author><author><keyname>Golubchik</keyname><forenames>Leana</forenames></author></authors><title>Pricing and Investments in Internet Security: A Cyber-Insurance
  Perspective</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Internet users such as individuals and organizations are subject to different
types of epidemic risks such as worms, viruses, spams, and botnets. To reduce
the probability of risk, an Internet user generally invests in traditional
security mechanisms like anti-virus and anti-spam software, sometimes also
known as self-defense mechanisms. However, such software does not completely
eliminate risk. Recent works have considered the problem of residual risk
elimination by proposing the idea of cyber-insurance. In this regard, an
important research problem is the analysis of optimal user self-defense
investments and cyber-insurance contracts under the Internet environment. In
this paper, we investigate two problems and their relationship: 1) analyzing
optimal self-defense investments in the Internet, under optimal cyber-insurance
coverage, where optimality is an insurer objective and 2) designing optimal
cyber-insurance contracts for Internet users, where a contract is a (premium,
coverage) pair.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1559</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1559</id><created>2011-03-08</created><updated>2014-06-06</updated><authors><author><keyname>Rosnes</keyname><forenames>Eirik</forenames></author><author><keyname>Helmling</keyname><forenames>Michael</forenames></author><author><keyname>Amat</keyname><forenames>Alexandre Graell i</forenames></author></authors><title>Minimum Pseudoweight Analysis of 3-Dimensional Turbo Codes</title><categories>cs.IT math.IT</categories><comments>To appear in IEEE Transactions on Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we consider pseudocodewords of (relaxed) linear programming
(LP) decoding of 3-dimensional turbo codes (3D-TCs). We present a relaxed LP
decoder for 3D-TCs, adapting the relaxed LP decoder for conventional turbo
codes proposed by Feldman in his thesis. We show that the 3D-TC polytope is
proper and $C$-symmetric, and make a connection to finite graph covers of the
3D-TC factor graph. This connection is used to show that the support set of any
pseudocodeword is a stopping set of iterative decoding of 3D-TCs using maximum
a posteriori constituent decoders on the binary erasure channel. Furthermore,
we compute ensemble-average pseudoweight enumerators of 3D-TCs and perform a
finite-length minimum pseudoweight analysis for small cover degrees. Also, an
explicit description of the fundamental cone of the 3D-TC polytope is given.
Finally, we present an extensive numerical study of small-to-medium block
length 3D-TCs, which shows that 1) typically (i.e., in most cases) when the
minimum distance $d_{\rm min}$ and/or the stopping distance $h_{\rm min}$ is
high, the minimum pseudoweight (on the additive white Gaussian noise channel)
is strictly smaller than both the $d_{\rm min}$ and the $h_{\rm min}$, and 2)
the minimum pseudoweight grows with the block length, at least for
small-to-medium block lengths.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1587</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1587</id><created>2011-03-08</created><updated>2011-03-10</updated><authors><author><keyname>Li</keyname><forenames>Xin</forenames></author></authors><title>All Roads Lead To Rome</title><categories>cs.CV</categories><comments>5 pages, 1 figure, submitted</comments><journal-ref>IEEE SPM'2011 as a Column Paper for DSP Tips&amp;Tricks</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This short article presents a class of projection-based solution algorithms
to the problem considered in the pioneering work on compressed sensing -
perfect reconstruction of a phantom image from 22 radial lines in the frequency
domain. Under the framework of projection-based image reconstruction, we will
show experimentally that several old and new tools of nonlinear filtering
(including Perona-Malik diffusion, nonlinear diffusion, Translation-Invariant
thresholding and SA-DCT thresholding) all lead to perfect reconstruction of the
phantom image.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1598</identifier>
 <datestamp>2011-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1598</id><created>2011-03-08</created><authors><author><keyname>Haenggi</keyname><forenames>Martin</forenames></author></authors><title>Mean Interference in Hard-Core Wireless Networks</title><categories>cs.IT cs.NI math.IT math.PR math.ST stat.TH</categories><acm-class>G.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mat\'ern hard core processes of types I and II are the point processes of
choice to model concurrent transmitters in CSMA networks. We determine the mean
interference observed at a node of the process and compare it with the mean
interference in a Poisson point process of the same density. It turns out that
despite the similarity of the two models, they behave rather differently. For
type I, the excess interference (relative to the Poisson case) increases
exponentially in the hard-core distance, while for type II, the gap never
exceeds 1 dB.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1604</identifier>
 <datestamp>2012-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1604</id><created>2011-03-08</created><updated>2012-07-25</updated><authors><author><keyname>Gottlob</keyname><forenames>Georg</forenames></author></authors><title>On Minimal Constraint Networks</title><categories>cs.AI cs.CC cs.DB</categories><comments>Preprint - to appear in Artificial Intelligence. (Full version of the
  CP'2011 paper with same title)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a minimal binary constraint network, every tuple of a constraint relation
can be extended to a solution. The tractability or intractability of computing
a solution to such a minimal network was a long standing open question. Dechter
conjectured this computation problem to be NP-hard. We prove this conjecture.
We also prove a conjecture by Dechter and Pearl stating that for k\geq2 it is
NP-hard to decide whether a single constraint can be decomposed into an
equivalent k-ary constraint network. We show that this holds even in case of
bi-valued constraints where k\geq3, which proves another conjecture of Dechter
and Pearl. Finally, we establish the tractability frontier for this problem
with respect to the domain cardinality and the parameter k.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1622</identifier>
 <datestamp>2011-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1622</id><created>2011-03-08</created><updated>2011-03-19</updated><authors><author><keyname>Alpoge</keyname><forenames>Levent</forenames></author><author><keyname>Ang</keyname><forenames>Thomas</forenames></author><author><keyname>Schaeffer</keyname><forenames>Luke</forenames></author><author><keyname>Shallit</keyname><forenames>Jeffrey</forenames></author></authors><title>Decidability and Shortest Strings in Formal Languages</title><categories>cs.FL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a formal language L specified in various ways, we consider the problem
of determining if L is nonempty. If L is indeed nonempty, we find upper and
lower bounds on the length of the shortest string in L.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1625</identifier>
 <datestamp>2011-03-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1625</id><created>2011-03-08</created><updated>2011-03-09</updated><authors><author><keyname>Phillips</keyname><forenames>Jeff M.</forenames></author><author><keyname>Venkatasubramanian</keyname><forenames>Suresh</forenames></author></authors><title>A Gentle Introduction to the Kernel Distance</title><categories>cs.CG cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This document reviews the definition of the kernel distance, providing a
gentle introduction tailored to a reader with background in theoretical
computer science, but limited exposure to technology more common to machine
learning, functional analysis and geometric measure theory. The key aspect of
the kernel distance developed here is its interpretation as an L_2 distance
between probability measures or various shapes (e.g. point sets, curves,
surfaces) embedded in a vector space (specifically an RKHS). This structure
enables several elegant and efficient solutions to data analysis problems. We
conclude with a glimpse into the mathematical underpinnings of this measure,
highlighting its recent independent evolution in two separate fields.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1665</identifier>
 <datestamp>2014-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1665</id><created>2011-03-08</created><authors><author><keyname>Stefanatos</keyname><forenames>Dionisis</forenames></author><author><keyname>Li</keyname><forenames>Jr-Shin</forenames></author></authors><title>The Role of Singular Control in Frictionless Atom Cooling in a Harmonic
  Trapping Potential</title><categories>math.OC cond-mat.quant-gas cs.SY quant-ph</categories><msc-class>49K15, 93C15, 81V45</msc-class><journal-ref>2012 American Control Conference, Montreal, Canada, pp. 5061-5066,
  2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article we study the frictionless cooling of atoms trapped in a
harmonic potential, while minimizing the transient energy of the system. We
show that in the case of unbounded control, this goal is achieved by a singular
control, which is also the time-minimal solution for a &quot;dual&quot; problem, where
the energy is held fixed. In addition, we examine briefly how the solution is
modified when there are bounds on the control. The results presented here have
a broad range of applications, from the cooling of a Bose-Einstein condensate
confined in a harmonic trap to adiabatic quantum computing and finite time
thermodynamic processes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1672</identifier>
 <datestamp>2011-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1672</id><created>2011-03-08</created><authors><author><keyname>Karmakar</keyname><forenames>Sanjay</forenames></author><author><keyname>Varanasi</keyname><forenames>Mahesh K.</forenames></author></authors><title>The Generalized Degrees of Freedom of the MIMO Interference Channel</title><categories>cs.IT math.IT</categories><comments>5 pages, 8 figures; submitted to ISIT 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The generalized degrees of freedom (GDoF) region of the MIMO Gaussian
interference channel is obtained for the general case with an arbitrary number
of antennas at each node and where the SNR and interference-to-noise ratios
(INRs) vary with arbitrary exponents to a nominal SNR. The GDoF region reveals
various insights through the joint dependence of optimal interference
management techniques at high SNR on the SNR exponents that determine the
relative strengths of direct-link SNRs and cross-link INRs and the numbers of
antennas at the four terminals. For instance, it permits an in-depth look at
the issue of rate-splitting and partial decoding at high SNR and it reveals
that, unlike in the SISO case, treating interference as noise is not GDoF
optimal always even in the very weak interference regime. Moreover, while the
DoF-optimal strategy that relies just on transmit/receive zero-forcing
beamforming and time-sharing is not GDoF optimal (and thus has an unbounded gap
to capacity) the precise characterization of the very strong interference
regime, where single-user DoF performance can be achieved simultaneously for
both users, depends on the relative numbers of antennas at the four terminals
and thus deviates from what it is in the SISO case. For asymmetric numbers of
antennas at the four nodes the shape of the symmetric GDoF curve can be a
&quot;distorted W&quot; curve to the extent that for certain MIMO ICs it is a &quot;V&quot; curve.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1680</identifier>
 <datestamp>2011-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1680</id><created>2011-03-08</created><authors><author><keyname>Tanimoto</keyname><forenames>Shinji</forenames></author></authors><title>Epidemic thresholds in directed complex networks</title><categories>physics.soc-ph cs.SI</categories><comments>4 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The spread of a disease, a computer virus or information is discussed in a
directed complex network. We are concerned with a steady state of the spread
for the SIR and SIS dynamic models. In a scale-free directed network it is
shown that the threshold of its outbreak in both models approaches zero under a
high correlation between nodal indegrees and outdegrees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1689</identifier>
 <datestamp>2011-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1689</id><created>2011-03-08</created><authors><author><keyname>Bento</keyname><forenames>Jos&#xe9;</forenames></author><author><keyname>Ibrahimi</keyname><forenames>Morteza</forenames></author><author><keyname>Montanari</keyname><forenames>Andrea</forenames></author></authors><title>Information Theoretic Limits on Learning Stochastic Differential
  Equations</title><categories>cs.IT cs.LG math.IT math.ST q-fin.ST stat.ML stat.TH</categories><comments>6 pages, 2 figures, conference version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider the problem of learning the drift coefficient of a stochastic
differential equation from a sample path. In this paper, we assume that the
drift is parametrized by a high dimensional vector. We address the question of
how long the system needs to be observed in order to learn this vector of
parameters. We prove a general lower bound on this time complexity by using a
characterization of mutual information as time integral of conditional
variance, due to Kadota, Zakai, and Ziv. This general lower bound is applied to
specific classes of linear and non-linear stochastic differential equations. In
the linear case, the problem under consideration is the one of learning a
matrix of interaction coefficients. We evaluate our lower bound for ensembles
of sparse and dense random matrices. The resulting estimates match the
qualitative behavior of upper bounds achieved by computationally efficient
procedures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1711</identifier>
 <datestamp>2011-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1711</id><created>2011-03-09</created><authors><author><keyname>Bryce</keyname><forenames>D.</forenames></author><author><keyname>Kambhampati</keyname><forenames>S.</forenames></author><author><keyname>Smith</keyname><forenames>D. E.</forenames></author></authors><title>Planning Graph Heuristics for Belief Space Search</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 26, pages
  35-99, 2006</journal-ref><doi>10.1613/jair.1869</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Some recent works in conditional planning have proposed reachability
heuristics to improve planner scalability, but many lack a formal description
of the properties of their distance estimates. To place previous work in
context and extend work on heuristics for conditional planning, we provide a
formal basis for distance estimates between belief states. We give a definition
for the distance between belief states that relies on aggregating underlying
state distance measures. We give several techniques to aggregate state
distances and their associated properties. Many existing heuristics exhibit a
subset of the properties, but in order to provide a standardized comparison we
present several generalizations of planning graph heuristics that are used in a
single planner. We compliment our belief state distance estimate framework by
also investigating efficient planning graph data structures that incorporate
BDDs to compute the most effective heuristics.
  We developed two planners to serve as test-beds for our investigation. The
first, CAltAlt, is a conformant regression planner that uses A* search. The
second, POND, is a conditional progression planner that uses AO* search. We
show the relative effectiveness of our heuristic techniques within these
planners. We also compare the performance of these planners with several state
of the art approaches in conditional planning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1716</identifier>
 <datestamp>2011-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1716</id><created>2011-03-09</created><authors><author><keyname>Jaffres-Runser</keyname><forenames>Katia</forenames><affiliation>CITI Insa Lyon / INRIA Grenoble Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Lauradoux</keyname><forenames>C&#xe9;dric</forenames><affiliation>CITI Insa Lyon / INRIA Grenoble Rh&#xf4;ne-Alpes</affiliation></author></authors><title>Authentication planning for XOR network coding</title><categories>cs.NI</categories><proxy>ccsd</proxy><report-no>RR-7562</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper formulates the authentication planning problem when network coding
is implemented in a wireless sensor network. The planning problem aims at
minimizing the energy consumed by the security application which is guarantied
using message authentication codes. This paper proposes a binary non-linear
optimization formulation for this planning problem whose decision variables are
the authentication decision of the nodes and the MAC modes of operation. It is
illustrated for a butterfly topology. Results show that there is a real
trade-off between energy efficiency and message throughput in this context.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1717</identifier>
 <datestamp>2011-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1717</id><created>2011-03-09</created><authors><author><keyname>Moy</keyname><forenames>Matthieu</forenames><affiliation>VERIMAG - IMAG</affiliation></author></authors><title>Efficient and Playful Tools to Teach Unix to New Students</title><categories>cs.OS</categories><comments>ITiCSE, Darmstadt : Germany (2011)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Teaching Unix to new students is a common tasks in many higher schools. This
paper presents an approach to such course where the students progress
autonomously with the help of the teacher. The traditional textbook is
complemented with a wiki, and the main thread of the course is a game, in the
form of a treasure hunt. The course finishes with a lab exam, where students
have to perform practical manipulations similar to the ones performed during
the treasure hunt. The exam is graded fully automatically. This paper discusses
the motivations and advantages of the approach, and gives an overall view of
the tools we developed. The tools are available from the web, and open-source,
hence re-usable outside the Ensimag.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1724</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1724</id><created>2011-03-09</created><updated>2011-08-01</updated><authors><author><keyname>Somaraju</keyname><forenames>Ram</forenames></author><author><keyname>Mirrahimi</keyname><forenames>Mazyar</forenames></author><author><keyname>Rouchon</keyname><forenames>Pierre</forenames></author></authors><title>Approximate stabilization of an infinite dimensional quantum stochastic
  system</title><categories>math.OC cs.SY</categories><comments>Submitted to CDC 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a feedback scheme for preparation of photon number states in a
microwave cavity. Quantum Non-Demolition (QND) measurements of the cavity field
and a control signal consisting of a microwave pulse injected into the cavity
are used to drive the system towards a desired target photon number state.
Unlike previous work, we do not use the Galerkin approximation of truncating
the infinite-dimensional system Hilbert space into a finite-dimensional
subspace. We use an (unbounded) strict Lyapunov function and prove that a
feedback scheme that minimizes the expectation value of the Lyapunov function
at each time step stabilizes the system at the desired photon number state with
(a pre-specified) arbitrarily high probability. Simulations of this scheme
demonstrate that we improve the performance of the controller by reducing
&quot;leakage&quot; to high photon numbers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1725</identifier>
 <datestamp>2011-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1725</id><created>2011-03-09</created><authors><author><keyname>Choo</keyname><forenames>Wei Liang</forenames><affiliation>CITI Insa Lyon / INRIA Grenoble Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Mou&#xeb;l</keyname><forenames>Fr&#xe9;d&#xe9;ric Le</forenames><affiliation>CITI Insa Lyon / INRIA Grenoble Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Jaffr&#xe8;s-Runser</keyname><forenames>Katia</forenames><affiliation>CITI Insa Lyon / INRIA Grenoble Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Fiore</keyname><forenames>Marco</forenames><affiliation>CITI Insa Lyon / INRIA Grenoble Rh&#xf4;ne-Alpes</affiliation></author></authors><title>Adding Network Coding Capabilities to the WSNet Simulator</title><categories>cs.NI</categories><proxy>ccsd</proxy><report-no>RT-0405</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This technical report presents the implementation of a Network Coding module
in WSNet - a Wireless Sensor Network simulator. This implementation provides a
generic programming interface to allow an easy specialization of different
coding strategies: random, source/destination-oriented, intra/inter-flow, etc.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1730</identifier>
 <datestamp>2015-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1730</id><created>2011-03-09</created><authors><author><keyname>Das</keyname><forenames>Angsuman</forenames></author><author><keyname>Adhikari</keyname><forenames>Avishek</forenames></author></authors><title>An efficient multi-use multi-secret sharing scheme based on hash
  function</title><categories>cs.CR</categories><journal-ref>Applied Mathematics Letters, 23 (2010)</journal-ref><doi>10.1016/j.aml.2010.04.024</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a renewable, multi-use, multi-secret sharing scheme for
general access structure based on one-way collision resistant hash function is
presented in which each participant has to carry only one share. By applying
collision-resistant one-way hash function, the proposed scheme is secure
against conspiracy attacks even if the pseudo-secret shares are compromised.
Moreover, high complexity operations like modular multiplication,
exponentiation and inversion are avoided to increase its efficiency. Finally,
in the proposed scheme, both the combiner and the participants can verify the
correctness of the information exchanged among themselves.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1732</identifier>
 <datestamp>2011-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1732</id><created>2011-03-09</created><updated>2011-03-21</updated><authors><author><keyname>Somaraju</keyname><forenames>Ram</forenames></author><author><keyname>Mirrahimi</keyname><forenames>Mazyar</forenames></author><author><keyname>Rouchon</keyname><forenames>Pierre</forenames></author></authors><title>Semi-Global Approximate stabilization of an infinite dimensional quantum
  stochastic system</title><categories>math.OC cs.SY math-ph math.FA math.MP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study the semi-global (approximate) state feedback
stabilization of an infinite dimensional quantum stochastic system towards a
target state. A discrete-time Markov chain on an infinite-dimensional Hilbert
space is used to model the dynamics of a quantum optical cavity. We can choose
an (unbounded) strict Lyapunov function that is minimized at each time-step in
order to prove (weak-$\ast$) convergence of probability measures to a final
state that is concentrated on the target state with (a pre-specified)
probability that may be made arbitrarily close to 1. The feedback parameters
and the Lyapunov function are chosen so that the stochastic flow that describes
the Markov process may be shown to be tight (concentrated on a compact set with
probability arbitrarily close to 1). We then use Prohorov's theorem and
properties of the Lyapunov function to prove the desired convergence result.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1741</identifier>
 <datestamp>2011-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1741</id><created>2011-03-09</created><authors><author><keyname>Schneider</keyname><forenames>Christian M.</forenames></author><author><keyname>Moreira</keyname><forenames>Andre A.</forenames></author><author><keyname>Andrade</keyname><forenames>Jose S.</forenames><suffix>Jr.</suffix></author><author><keyname>Havlin</keyname><forenames>Shlomo</forenames></author><author><keyname>Herrmann</keyname><forenames>Hans J.</forenames></author></authors><title>Mitigation of Malicious Attacks on Networks</title><categories>physics.soc-ph cs.SI physics.comp-ph</categories><comments>9 pages, 9 figures</comments><journal-ref>Proc. Natl. Acad. Sci. 108(10) 3838-3841 (2011)</journal-ref><doi>10.1073/pnas.1009440108</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Terrorist attacks on transportation networks have traumatized modern
societies. With a single blast, it has become possible to paralyze airline
traffic, electric power supply, ground transportation or Internet
communication. How and at which cost can one restructure the network such that
it will become more robust against a malicious attack? We introduce a unique
measure for robustness and use it to devise a method to mitigate economically
and efficiently this risk. We demonstrate its efficiency on the European
electricity system and on the Internet as well as on complex networks models.
We show that with small changes in the network structure (low cost) the
robustness of diverse networks can be improved dramatically while their
functionality remains unchanged. Our results are useful not only for improving
significantly with low cost the robustness of existing infrastructures but also
for designing economically robust network systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1742</identifier>
 <datestamp>2011-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1742</id><created>2011-03-09</created><authors><author><keyname>M&#xe9;ric</keyname><forenames>Hugo</forenames></author><author><keyname>Lacan</keyname><forenames>J&#xe9;r&#xf4;me</forenames></author><author><keyname>Amiot-Bazile</keyname><forenames>Caroline</forenames></author><author><keyname>Arnal</keyname><forenames>Fabrice</forenames></author><author><keyname>Boucheret</keyname><forenames>Marie-Laure</forenames></author></authors><title>Generic Approach for Hierarchical Modulation Performance Analysis:
  Application to DVB-SH and DVB-S2</title><categories>cs.IT cs.PF math.IT</categories><comments>Submitted for publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Broadcasting systems have to deal with channel variability in order to offer
the best rate to the users. Hierarchical modulation is a practical solution to
provide different rates to the receivers in function of the channel quality.
Unfortunately, the performance evaluation of such modulations requires time
consuming simulations. We propose in this paper a novel approach based on the
channel capacity to avoid these simulations. The method allows to study the
performance of hierarchical and also classical modulations combined with error
correcting codes. We will also compare hierarchical modulation with time
sharing strategy in terms of achievable rates and indisponibility. Our work
will be applied to the DVB-SH and DVB-S2 standards, which both consider
hierarchical modulation as an optional feature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1756</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1756</id><created>2011-03-09</created><updated>2011-06-16</updated><authors><author><keyname>Zhong</keyname><forenames>Li-Xin</forenames></author><author><keyname>Qiu</keyname><forenames>Tian</forenames></author></authors><title>Limitation of network inhomogeneity in improving cooperation in
  coevolutionary dynamics</title><categories>physics.soc-ph cs.SI</categories><doi>10.1016/j.physa.2011.10.013</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cooperative behavior is common in nature even if selfishness is sometimes
better for an individual. Empirical and theoretical studies have shown that the
invasion and expansion of cooperators are related to an inhomogeneous
connectivity distribution. Here we study the evolution of cooperation on an
adaptive network, in which an individual is able to avoid being exploited by
rewiring its link(s). Our results indicate that the broadening of connectivity
distribution is not always beneficial for cooperation. Compared with the
Poisson-like degree distribution, the exponential-like degree distribution is
detrimental to the occurrence of a higher level of cooperation in the
continuous snowdrift game (CSG).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1758</identifier>
 <datestamp>2011-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1758</id><created>2011-03-09</created><authors><author><keyname>Itoh</keyname><forenames>Jin-ichi</forenames></author><author><keyname>V\^\ilcu</keyname><forenames>Costin</forenames></author></authors><title>Cut locus structures on graphs</title><categories>cs.DM math.CO</categories><comments>16 pages, 15 figures. First in a series of four articles</comments><msc-class>57R70, 53C20, 05C10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by a fundamental geometrical object, the cut locus, we introduce
and study a new combinatorial structure on graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1771</identifier>
 <datestamp>2011-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1771</id><created>2011-03-09</created><authors><author><keyname>Schieferdecker</keyname><forenames>Dennis</forenames></author><author><keyname>V&#xf6;lker</keyname><forenames>Markus</forenames></author><author><keyname>Wagner</keyname><forenames>Dorothea</forenames></author></authors><title>Efficient Algorithms for Distributed Detection of Holes and Boundaries
  in Wireless Networks</title><categories>cs.DS</categories><comments>extended version of accepted submission to SEA 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose two novel algorithms for distributed and location-free boundary
recognition in wireless sensor networks. Both approaches enable a node to
decide autonomously whether it is a boundary node, based solely on connectivity
information of a small neighborhood. This makes our algorithms highly
applicable for dynamic networks where nodes can move or become inoperative.
  We compare our algorithms qualitatively and quantitatively with several
previous approaches. In extensive simulations, we consider various models and
scenarios. Although our algorithms use less information than most other
approaches, they produce significantly better results. They are very robust
against variations in node degree and do not rely on simplified assumptions of
the communication model. Moreover, they are much easier to implement on real
sensor nodes than most existing approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1773</identifier>
 <datestamp>2011-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1773</id><created>2011-03-09</created><authors><author><keyname>Egger</keyname><forenames>Jan</forenames></author><author><keyname>Freisleben</keyname><forenames>Bernd</forenames></author><author><keyname>Setser</keyname><forenames>Randolph</forenames></author><author><keyname>Renapuraar</keyname><forenames>Rahul</forenames></author><author><keyname>Biermann</keyname><forenames>Christina</forenames></author><author><keyname>O'Donnell</keyname><forenames>Thomas</forenames></author></authors><title>Aorta Segmentation for Stent Simulation</title><categories>cs.CV physics.med-ph</categories><comments>10 pages, 6 figures, MICCAI Workshop on Cardiovascular Interventional
  Imaging and Biophysical Modelling (2009)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Simulation of arterial stenting procedures prior to intervention allows for
appropriate device selection as well as highlights potential complications. To
this end, we present a framework for facilitating virtual aortic stenting from
a contrast computer tomography (CT) scan. More specifically, we present a
method for both lumen and outer wall segmentation that may be employed in
determining both the appropriateness of intervention as well as the selection
and localization of the device. The more challenging recovery of the outer wall
is based on a novel minimal closure tracking algorithm. Our aortic segmentation
method has been validated on over 3000 multiplanar reformatting (MPR) planes
from 50 CT angiography data sets yielding a Dice Similarity Coefficient (DSC)
of 90.67%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1777</identifier>
 <datestamp>2011-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1777</id><created>2011-03-09</created><authors><author><keyname>Egger</keyname><forenames>Jan</forenames></author><author><keyname>Bauer</keyname><forenames>Miriam H. A.</forenames></author><author><keyname>Kuhnt</keyname><forenames>Daniela</forenames></author><author><keyname>Kappus</keyname><forenames>Christoph</forenames></author><author><keyname>Carl</keyname><forenames>Barbara</forenames></author><author><keyname>Freisleben</keyname><forenames>Bernd</forenames></author><author><keyname>Nimsky</keyname><forenames>Christopher</forenames></author></authors><title>A Flexible Semi-Automatic Approach for Glioblastoma multiforme
  Segmentation</title><categories>cs.CE physics.med-ph q-bio.TO</categories><comments>4 pages, 4 figures, BIOSIGNAL, Berlin, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Gliomas are the most common primary brain tumors, evolving from the cerebral
supportive cells. For clinical follow-up, the evaluation of the preoperative
tumor volume is essential. Volumetric assessment of tumor volume with manual
segmentation of its outlines is a time-consuming process that can be overcome
with the help of segmentation methods. In this paper, a flexible semi-automatic
approach for grade IV glioma segmentation is presented. The approach uses a
novel segmentation scheme for spherical objects that creates a directed 3D
graph. Thereafter, the minimal cost closed set on the graph is computed via a
polynomial time s-t cut, creating an optimal segmentation of the tumor. The
user can improve the results by specifying an arbitrary number of additional
seed points to support the algorithm with grey value information and
geometrical constraints. The presented method is tested on 12 magnetic
resonance imaging datasets. The ground truth of the tumor boundaries are
manually extracted by neurosurgeons. The segmented gliomas are compared with a
one click method, and the semi-automatic approach yields an average Dice
Similarity Coefficient (DSC) of 77.72% and 83.91%, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1778</identifier>
 <datestamp>2011-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1778</id><created>2011-03-09</created><authors><author><keyname>Egger</keyname><forenames>Jan</forenames></author><author><keyname>Bauer</keyname><forenames>Miriam H. A.</forenames></author><author><keyname>Kuhnt</keyname><forenames>Daniela</forenames></author><author><keyname>Freisleben</keyname><forenames>Bernd</forenames></author><author><keyname>Nimsky</keyname><forenames>Christopher</forenames></author></authors><title>Pituitary Adenoma Segmentation</title><categories>cs.CE physics.med-ph q-bio.TO</categories><comments>4 pages, 5 figures, BIOSIGNAL, Berlin, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sellar tumors are approximately 10-15% among all intracranial neoplasms. The
most common sellar lesion is the pituitary adenoma. Manual segmentation is a
time-consuming process that can be shortened by using adequate algorithms. In
this contribution, we present a segmentation method for pituitary adenoma. The
method is based on an algorithm we developed recently in previous work where
the novel segmentation scheme was successfully used for segmentation of
glioblastoma multiforme and provided an average Dice Similarity Coefficient
(DSC) of 77%. This scheme is used for automatic adenoma segmentation. In our
experimental evaluation, neurosurgeons with strong experiences in the treatment
of pituitary adenoma performed manual slice-by-slice segmentation of 10
magnetic resonance imaging (MRI) cases. Afterwards, the segmentations were
compared with the segmentation results of the proposed method via the DSC. The
average DSC for all data sets was 77.49% +/- 4.52%. Compared with a manual
segmentation that took, on the average, 3.91 +/- 0.54 minutes, the overall
segmentation in our implementation required less than 4 seconds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1784</identifier>
 <datestamp>2011-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1784</id><created>2011-03-09</created><authors><author><keyname>Wang</keyname><forenames>Kehao</forenames></author><author><keyname>Chen</keyname><forenames>Lin</forenames></author></authors><title>On the Optimality of Myopic Sensing in Multi-channel Opportunistic
  Access: the Case of Sensing Multiple Channels</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent works have developed a simple and robust myopic sensing policy for
multi-channel opportunistic communication systems where a secondary user (SU)
can access one of N i.i.d. Markovian channels. The optimality of the myopic
sensing policy in maximizing the SU's cumulated reward is established under
certain conditions on channel parameters. This paper studies the generic case
where the SU can sense more than one channel each time. By characterizing the
myopic sensing policy in this context, we establish analytically its optimality
for certain system setting when the SU is allowed to sense two channels. In the
more generic case, we construct counterexamples to show that the myopic sensing
policy, despite its simple structure, is non-optimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1791</identifier>
 <datestamp>2011-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1791</id><created>2011-03-09</created><updated>2011-10-03</updated><authors><author><keyname>Edlund</keyname><forenames>Jeffrey</forenames></author><author><keyname>Chaumont</keyname><forenames>Nicolas</forenames></author><author><keyname>Hintze</keyname><forenames>Arend</forenames></author><author><keyname>Koch</keyname><forenames>Christof</forenames></author><author><keyname>Tononi</keyname><forenames>Giulio</forenames></author><author><keyname>Adami</keyname><forenames>Christoph</forenames></author></authors><title>Integrated information increases with fitness in the evolution of
  animats</title><categories>q-bio.PE cs.AI nlin.AO q-bio.NC</categories><comments>27 pages, 8 figures, one supplementary figure. Three supplementary
  video files available on request. Version commensurate with published text in
  PLoS Comput. Biol</comments><journal-ref>PLoS Computational Biology 7 (2001) e1002236</journal-ref><doi>10.1371/journal.pcbi.1002236</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the hallmarks of biological organisms is their ability to integrate
disparate information sources to optimize their behavior in complex
environments. How this capability can be quantified and related to the
functional complexity of an organism remains a challenging problem, in
particular since organismal functional complexity is not well-defined. We
present here several candidate measures that quantify information and
integration, and study their dependence on fitness as an artificial agent
(&quot;animat&quot;) evolves over thousands of generations to solve a navigation task in
a simple, simulated environment. We compare the ability of these measures to
predict high fitness with more conventional information-theoretic processing
measures. As the animat adapts by increasing its &quot;fit&quot; to the world,
information integration and processing increase commensurately along the
evolutionary line of descent. We suggest that the correlation of fitness with
information integration and with processing measures implies that high fitness
requires both information processing as well as integration, but that
information integration may be a better measure when the task requires memory.
A correlation of measures of information integration (but also information
processing) and fitness strongly suggests that these measures reflect the
functional complexity of the animat, and that such measures can be used to
quantify functional complexity even in the absence of fitness data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1823</identifier>
 <datestamp>2011-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1823</id><created>2011-03-09</created><authors><author><keyname>Poinsot</keyname><forenames>Laurent</forenames><affiliation>LIPN</affiliation></author><author><keyname>Pott</keyname><forenames>Alexander</forenames><affiliation>IAG</affiliation></author></authors><title>Non-Boolean almost perfect nonlinear functions on non-Abelian groups</title><categories>cs.CR</categories><comments>17 pages</comments><proxy>ccsd</proxy><journal-ref>International Journal of Foundations of Computer Science 22, 6
  (2011) 1351-1367</journal-ref><doi>10.1142/S0129054111008751</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The purpose of this paper is to present the extended definitions and
characterizations of the classical notions of APN and maximum nonlinear Boolean
functions to deal with the case of mappings from a finite group K to another
one N with the possibility that one or both groups are non-Abelian.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1824</identifier>
 <datestamp>2011-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1824</id><created>2011-03-08</created><authors><author><keyname>Chaudhuri</keyname><forenames>Sumanta</forenames></author><author><keyname>Guilley</keyname><forenames>Sylvain</forenames></author></authors><title>Side-Channel Oscilloscope</title><categories>cs.CR</categories><comments>2 pages, 1 figure. a brief outline paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Side-Channel Analysis used for codebreaking could be used constructively as a
probing tool for internal gates in integrated circuits. This paper outlines
basic methods and mathematics for that purpose
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1834</identifier>
 <datestamp>2011-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1834</id><created>2011-03-09</created><authors><author><keyname>Kelk</keyname><forenames>Steven</forenames></author><author><keyname>Scornavacca</keyname><forenames>Celine</forenames></author><author><keyname>van Iersel</keyname><forenames>Leo</forenames></author></authors><title>On the elusiveness of clusters</title><categories>q-bio.PE cs.SI physics.soc-ph</categories><comments>Submitted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rooted phylogenetic networks are often used to represent conflicting
phylogenetic signals. Given a set of clusters, a network is said to represent
these clusters in the &quot;softwired&quot; sense if, for each cluster in the input set,
at least one tree embedded in the network contains that cluster. Motivated by
parsimony we might wish to construct such a network using as few reticulations
as possible, or minimizing the &quot;level&quot; of the network, i.e. the maximum number
of reticulations used in any &quot;tangled&quot; region of the network. Although these
are NP-hard problems, here we prove that, for every fixed k &gt;= 0, it is
polynomial-time solvable to construct a phylogenetic network with level equal
to k representing a cluster set, or to determine that no such network exists.
However, this algorithm does not lend itself to a practical implementation. We
also prove that the comparatively efficient Cass algorithm correctly solves
this problem (and also minimizes the reticulation number) when input clusters
are obtained from two not necessarily binary gene trees on the same set of taxa
but does not always minimize level for general cluster sets. Finally, we
describe a new algorithm which generates in polynomial-time all binary
phylogenetic networks with exactly r reticulations representing a set of input
clusters (for every fixed r &gt;= 0).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1898</identifier>
 <datestamp>2011-03-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1898</id><created>2011-03-09</created><authors><author><keyname>Pon-Barry</keyname><forenames>Heather</forenames></author><author><keyname>Shieber</keyname><forenames>Stuart M.</forenames></author></authors><title>Recognizing Uncertainty in Speech</title><categories>cs.CL</categories><comments>11 pages</comments><journal-ref>EURASIP Journal on Advances in Signal Processing, Volume 2011,
  Article ID 251753, 11 pages</journal-ref><doi>10.1155/2011/251753</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We address the problem of inferring a speaker's level of certainty based on
prosodic information in the speech signal, which has application in
speech-based dialogue systems. We show that using phrase-level prosodic
features centered around the phrases causing uncertainty, in addition to
utterance-level prosodic features, improves our model's level of certainty
classification. In addition, our models can be used to predict which phrase a
person is uncertain about. These results rely on a novel method for eliciting
utterances of varying levels of certainty that allows us to compare the utility
of contextually-based feature sets. We elicit level of certainty ratings from
both the speakers themselves and a panel of listeners, finding that there is
often a mismatch between speakers' internal states and their perceived states,
and highlighting the importance of this distinction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1917</identifier>
 <datestamp>2013-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1917</id><created>2011-03-09</created><authors><author><keyname>Egu&#xed;a</keyname><forenames>Martiniano</forenames></author><author><keyname>Soulignac</keyname><forenames>Francisco J.</forenames></author></authors><title>Hereditary biclique-Helly graphs: recognition and maximal biclique
  enumeration</title><categories>cs.DS cs.DM</categories><comments>23 pages, 4 figures</comments><msc-class>05C85, 68R10</msc-class><journal-ref>Discrete Math. Theor. Comput. Sci. 15 (2013), 55--74</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A biclique is a set of vertices that induce a bipartite complete graph. A
graph G is biclique-Helly when its family of maximal bicliques satisfies the
Helly property. If every induced subgraph of G is also biclique-Helly, then G
is hereditary biclique-Helly. A graph is C_4-dominated when every cycle of
length 4 contains a vertex that is dominated by the vertex of the cycle that is
not adjacent to it. In this paper we show that the class of hereditary
biclique-Helly graphs is formed precisely by those C_4-dominated graphs that
contain no triangles and no induced cycles of length either 5, or 6. Using this
characterization, we develop an algorithm for recognizing hereditary
biclique-Helly graphs in O(n^2+\alpha m) time and O(m) space. (Here n, m, and
\alpha = O(m^{1/2}) are the number of vertices and edges, and the arboricity of
the graph, respectively.) As a subprocedure, we show how to recognize those
C_4-dominated graphs that contain no triangles in O(\alpha m) time and O(m)
space. Finally, we show how to enumerate all the maximal bicliques of a
C_4-dominated graph with no triangles in O(n^2 + \alpha m) time and O(\alpha m)
space, and we discuss how some biclique problems can be solved in O(\alpha m)
time and O(n+m) space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1918</identifier>
 <datestamp>2016-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1918</id><created>2011-03-09</created><updated>2015-12-30</updated><authors><author><keyname>Bradonji&#x107;</keyname><forenames>Milan</forenames></author><author><keyname>Causley</keyname><forenames>Matthew</forenames></author><author><keyname>Cohen</keyname><forenames>Albert</forenames></author></authors><title>Stochastic Optimal Control for Online Seller under Reputational
  Mechanisms</title><categories>math.OC cs.SY math.PR</categories><doi>10.3390/risks3040553</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we propose and analyze a model which addresses the pulsing
behavior of sellers in an online auction (store). This pulsing behavior is
observed when sellers switch between advertising and processing states. We
assert that a seller switches her state in order to maximize her profit, and
further that this switch can be identified through the seller's reputation. We
show that for each seller there is an optimal reputation, i.e., the reputation
at which the seller should switch her state in order to maximize her total
profit. We design a stochastic behavioral model for an online seller, which
incorporates the dynamics of resource allocation and reputation. The design of
the model is optimized by using a stochastic advertising model from (16) and
used effectively in the Stochastic Optimal Control of Advertising (12). This
model of reputation is combined with the effect of online reputation on sales
price empirically verified in (9). We derive the Hamilton-Jacobi-Bellman (HJB)
differential equation, whose solution relates optimal wealth level to a
seller's reputation. We formulate both a full model, as well as a reduced model
with fewer parameters, both of which have the same qualitative description of
the optimal seller behavior. Coincidentally, the reduced model has a closed
form analytical solution that we construct.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1923</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1923</id><created>2011-03-09</created><authors><author><keyname>Rodrigues</keyname><forenames>Helena Sofia</forenames></author><author><keyname>Monteiro</keyname><forenames>M. Teresa T.</forenames></author><author><keyname>Torres</keyname><forenames>Delfim F. M.</forenames></author><author><keyname>Zinober</keyname><forenames>Alan</forenames></author></authors><title>Dengue disease, basic reproduction number and control</title><categories>math.OC cs.SY physics.med-ph q-bio.OT</categories><comments>This is a preprint of a paper whose final and definitive form has
  appeared in International Journal of Computer Mathematics (2011), DOI:
  10.1080/00207160.2011.554540</comments><msc-class>92B05, 93C95, 93D20</msc-class><journal-ref>Int. J. Comput. Math. 89 (2012), no. 3, 334--346</journal-ref><doi>10.1080/00207160.2011.554540</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dengue is one of the major international public health concerns. Although
progress is underway, developing a vaccine against the disease is challenging.
Thus, the main approach to fight the disease is vector control. A model for the
transmission of Dengue disease is presented. It consists of eight mutually
exclusive compartments representing the human and vector dynamics. It also
includes a control parameter (insecticide) in order to fight the mosquito. The
model presents three possible equilibria: two disease-free equilibria (DFE) and
another endemic equilibrium. It has been proved that a DFE is locally
asymptotically stable, whenever a certain epidemiological threshold, known as
the basic reproduction number, is less than one. We show that if we apply a
minimum level of insecticide, it is possible to maintain the basic reproduction
number below unity. A case study, using data of the outbreak that occurred in
2009 in Cape Verde, is presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1943</identifier>
 <datestamp>2011-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1943</id><created>2011-03-10</created><updated>2011-03-23</updated><authors><author><keyname>Donoho</keyname><forenames>David</forenames></author><author><keyname>Johnstone</keyname><forenames>Iain</forenames></author><author><keyname>Maleki</keyname><forenames>Arian</forenames></author><author><keyname>Montanari</keyname><forenames>Andrea</forenames></author></authors><title>Compressed Sensing over $\ell_p$-balls: Minimax Mean Square Error</title><categories>cs.IT math.IT math.ST stat.TH</categories><comments>41 pages, 11 pdf figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the compressed sensing problem, where the object $x_0 \in \bR^N$
is to be recovered from incomplete measurements $y = Ax_0 + z$; here the
sensing matrix $A$ is an $n \times N$ random matrix with iid Gaussian entries
and $n &lt; N$. A popular method of sparsity-promoting reconstruction is
$\ell^1$-penalized least-squares reconstruction (aka LASSO, Basis Pursuit).
  It is currently popular to consider the strict sparsity model, where the
object $x_0$ is nonzero in only a small fraction of entries. In this paper, we
instead consider the much more broadly applicable $\ell_p$-sparsity model,
where $x_0$ is sparse in the sense of having $\ell_p$ norm bounded by $\xi
\cdot N^{1/p}$ for some fixed $0 &lt; p \leq 1$ and $\xi &gt; 0$.
  We study an asymptotic regime in which $n$ and $N$ both tend to infinity with
limiting ratio $n/N = \delta \in (0,1)$, both in the noisy ($z \neq 0$) and
noiseless ($z=0$) cases. Under weak assumptions on $x_0$, we are able to
precisely evaluate the worst-case asymptotic minimax mean-squared
reconstruction error (AMSE) for $\ell^1$ penalized least-squares: min over
penalization parameters, max over $\ell_p$-sparse objects $x_0$. We exhibit the
asymptotically least-favorable object (hardest sparse signal to recover) and
the maximin penalization.
  Our explicit formulas unexpectedly involve quantities appearing classically
in statistical decision theory. Occurring in the present setting, they reflect
a deeper connection between penalized $\ell^1$ minimization and scalar soft
thresholding. This connection, which follows from earlier work of the authors
and collaborators on the AMP iterative thresholding algorithm, is carefully
explained.
  Our approach also gives precise results under weak-$\ell_p$ ball coefficient
constraints, as we show here.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1952</identifier>
 <datestamp>2011-03-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1952</id><created>2011-03-10</created><authors><author><keyname>Bauer</keyname><forenames>Miriam H. A.</forenames></author><author><keyname>Egger</keyname><forenames>Jan</forenames></author><author><keyname>Kuhnt</keyname><forenames>Daniela</forenames></author><author><keyname>Barbieri</keyname><forenames>Sebastiano</forenames></author><author><keyname>Klein</keyname><forenames>Jan</forenames></author><author><keyname>Hahn</keyname><forenames>Horst K.</forenames></author><author><keyname>Freisleben</keyname><forenames>Bernd</forenames></author><author><keyname>Nimsky</keyname><forenames>Christopher</forenames></author></authors><title>Ray-Based and Graph-Based Methods for Fiber Bundle Boundary Estimation</title><categories>cs.CV</categories><comments>4 pages, 6 figures, BIOSIGNAL, Berlin, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Diffusion Tensor Imaging (DTI) provides the possibility of estimating the
location and course of eloquent structures in the human brain. Knowledge about
this is of high importance for preoperative planning of neurosurgical
interventions and for intraoperative guidance by neuronavigation in order to
minimize postoperative neurological deficits. Therefore, the segmentation of
these structures as closed, three-dimensional object is necessary. In this
contribution, two methods for fiber bundle segmentation between two defined
regions are compared using software phantoms (abstract model and anatomical
phantom modeling the right corticospinal tract). One method uses evaluation
points from sampled rays as candidates for boundary points, the other method
sets up a directed and weighted (depending on a scalar measure) graph and
performs a min-cut for optimal segmentation results. Comparison is done by
using the Dice Similarity Coefficient (DSC), a measure for spatial overlap of
different segmentation results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1958</identifier>
 <datestamp>2013-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1958</id><created>2011-03-10</created><updated>2013-07-09</updated><authors><author><keyname>Trifonov</keyname><forenames>Peter</forenames></author></authors><title>On the Root Finding Step in List Decoding of Folded Reed-Solomon Codes</title><categories>cs.IT math.IT</categories><comments>Not accepted to IEEE Int. Symposium on Information Theory, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The root finding step of the Guruswami-Rudra list decoding algorithm for
folded Reed-Solomon codes is considered. It is shown that a multivariate
generalization of the Roth-Ruckenstein algorithm can be used to implement it.
This leads to an improved bound on the size of the list produced by the
decoder, as well as enables one to relax the constraints on the parameters of
folded codes. Furthermore, the class of time-domain folded Reed-Solomon codes
is introduced, which can be efficiently list decoded with the Guruswami-Rudra
algorithm, and provides greater flexibility in parameter selection than the
classical (frequency-domain) folded codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1977</identifier>
 <datestamp>2011-03-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1977</id><created>2011-03-10</created><authors><author><keyname>Pham</keyname><forenames>Manh Cuong</forenames></author><author><keyname>Klamma</keyname><forenames>Ralf</forenames></author><author><keyname>Jarke</keyname><forenames>Matthias</forenames></author></authors><title>Development of Computer Science Disciplines - A Social Network Analysis
  Approach</title><categories>cs.DL</categories><report-no>DBIS-0001</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In contrast to many other scientific disciplines, computer science considers
conference publications. Conferences have the advantage of providing fast
publication of papers and of bringing researchers together to present and
discuss the paper with peers. Previous work on knowledge mapping focused on the
map of all sciences or a particular domain based on ISI published JCR (Journal
Citation Report). Although this data covers most of important journals, it
lacks computer science conference and workshop proceedings. That results in an
imprecise and incomplete analysis of the computer science knowledge. This paper
presents an analysis on the computer science knowledge network constructed from
all types of publications, aiming at providing a complete view of computer
science research. Based on the combination of two important digital libraries
(DBLP and CiteSeerX), we study the knowledge network created at
journal/conference level using citation linkage, to identify the development of
sub-disciplines. We investigate the collaborative and citation behavior of
journals/conferences by analyzing the properties of their co-authorship and
citation subgraphs. The paper draws several important conclusions. First,
conferences constitute social structures that shape the computer science
knowledge. Second, computer science is becoming more interdisciplinary. Third,
experts are the key success factor for sustainability of journals/conferences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1991</identifier>
 <datestamp>2012-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1991</id><created>2011-03-10</created><updated>2012-10-04</updated><authors><author><keyname>Mao</keyname><forenames>Guoqiang</forenames></author><author><keyname>Anderson</keyname><forenames>Brian DO</forenames></author></authors><title>Connectivity of Large Scale Networks: Emergence of Unique Unbounded
  Component</title><categories>cs.IT cs.NI math.IT</categories><comments>This paper has been withdrawn because of a latter version was
  accepted into IEEE Transaction on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies networks where all nodes are distributed on a unit square
$A\triangleq[(-1/2,1/2)^{2}$ following a Poisson distribution with known
density $\rho$ and a pair of nodes separated by an Euclidean distance $x$ are
directly connected with probability $g(\frac{x}{r_{\rho}})$, independent of the
event that any other pair of nodes are directly connected. Here
$g:[0,\infty)\rightarrow[0,1]$ satisfies the conditions of rotational
invariance, non-increasing monotonicity, integral boundedness and
$g(x)=o(\frac{1}{x^{2}\log^{2}x})$; further,
$r_{\rho}=\sqrt{\frac{\log\rho+b}{C\rho}}$ where $C=\int_{\Re^{2}}g(\Vert
\boldsymbol{x}\Vert)d\boldsymbol{x}$ and $b$ is a constant. Denote the above
network by\textmd{}$\mathcal{G}(\mathcal{X}_{\rho},g_{r_{\rho}},A)$. We show
that as $\rho\rightarrow\infty$, asymptotically almost surely a) there is no
component in $\mathcal{G}(\mathcal{X}_{\rho},g_{r_{\rho}},A)$ of fixed and
finite order $k&gt;1$; b) the number of components with an unbounded order is one.
Therefore as $\rho\rightarrow\infty$, the network asymptotically almost surely
contains a unique unbounded component and isolated nodes only; a sufficient
condition for $\mathcal{G}(\mathcal{X}_{\rho},g_{r_{\rho}},A)$ to be
asymptotically almost surely connected is that there is no isolated node in the
network.{\normalsize{}}The contribution of these results, together with results
in a companion paper on the asymptotic distribution of isolated nodes in
\textmd{\normalsize $\mathcal{G}(\mathcal{X}_{\rho},g_{r_{\rho}},A)$}, is to
expand recent results obtained for connectivity of random geometric graphs from
the unit disk model to the more generic and more practical random connection
model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.1994</identifier>
 <datestamp>2012-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.1994</id><created>2011-03-10</created><updated>2012-10-04</updated><authors><author><keyname>Mao</keyname><forenames>Guoqiang</forenames></author><author><keyname>Anderson</keyname><forenames>Brian DO</forenames></author></authors><title>Connectivity of Large Scale Networks: Distribution of Isolated Nodes</title><categories>cs.IT cs.NI math.IT</categories><comments>This paper has been withdrawn because of a latter version was
  accepted into IEEE Transaction on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Connectivity is one of the most fundamental properties of wireless multi-hop
networks. A network is said to be connected if there is a path between any pair
of nodes. A convenient way to study the connectivity of a random network is by
investigating the condition under which the network has no isolated node. The
condition under which the network has no isolated node provides a necessary
condition for a connected network. Further the condition for a network to have
no isolated node and the condition for the network to be connected can often be
shown to asymptotically converge to be the same as the number of nodes
approaches infinity, given a suitably defined random network and connection
model. Currently analytical results on the distribution of the number of
isolated nodes only exist for the unit disk model. This study advances research
in the area by providing the asymptotic distribution of the number of isolated
nodes in random networks with nodes Poissonly distributed on a unit square
under a generic random connection model. On that basis we derive a necessary
condition for the above network to be asymptotically almost surely connected.
These results, together with results in a companion paper on the sufficient
condition for a network to be connected, expand recent results obtained for
connectivity of random geometric graphs assuming a unit disk model to results
assuming a more generic and more practical random connection model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2027</identifier>
 <datestamp>2011-03-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2027</id><created>2011-03-10</created><authors><author><keyname>Jaffar</keyname><forenames>Joxan</forenames></author><author><keyname>Navas</keyname><forenames>Jorge A.</forenames></author><author><keyname>Santosa</keyname><forenames>Andrew E.</forenames></author></authors><title>Symbolic Execution for Verification</title><categories>cs.PL cs.SE</categories><comments>15 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In previous work, we presented a symbolic execution method which starts with
a concrete model of the program but progressively abstracts away details only
when these are known to be irrelevant using interpolation. In this paper, we
extend the technique to handle unbounded loops. The central idea is to
progressively discover the strongest invariants through a process of loop
unrolling. The key feature of this technique, called the minimax algorithm, is
intelligent backtracking which directs the search for the next invariant. We
then present an analysis of the main differences between our symbolic execution
method and mainstream techniques mainly based on abstract refinement (CEGAR).
Finally, we evaluate our technique against available state-of-the-art systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2046</identifier>
 <datestamp>2012-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2046</id><created>2011-03-10</created><updated>2012-11-14</updated><authors><author><keyname>Nazaroglu</keyname><forenames>Caner</forenames></author><author><keyname>Ozgur</keyname><forenames>Ayfer</forenames></author><author><keyname>Fragouli</keyname><forenames>Christina</forenames></author></authors><title>Wireless Network Simplification: the Gaussian N-Relay Diamond Network</title><categories>cs.IT math.IT</categories><comments>Submitted to Transactions on Information Theory in October 2012. The
  new version includes discussions on the algorithmic complexity of discovering
  a high-capacity subnetwork and on the performance of amplify-and-forward</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the Gaussian N-relay diamond network, where a source wants to
communicate to a destination node through a layer of N-relay nodes. We
investigate the following question: what fraction of the capacity can we
maintain by using only k out of the N available relays? We show that
independent of the channel configurations and the operating SNR, we can always
find a subset of k relays which alone provide a rate (kC/(k+1))-G, where C is
the information theoretic cutset upper bound on the capacity of the whole
network and G is a constant that depends only on N and k (logarithmic in N and
linear in k). In particular, for k = 1, this means that half of the capacity of
any N-relay diamond network can be approximately achieved by routing
information over a single relay. We also show that this fraction is tight:
there are configurations of the N-relay diamond network where every subset of k
relays alone can at most provide approximately a fraction k/(k+1) of the total
capacity. These high-capacity k-relay subnetworks can be also discovered
efficiently. We propose an algorithm that computes a constant gap approximation
to the capacity of the Gaussian N-relay diamond network in O(N log N) running
time and discovers a high-capacity k-relay subnetwork in O(kN) running time.
  This result also provides a new approximation to the capacity of the Gaussian
N-relay diamond network which is hybrid in nature: it has both multiplicative
and additive gaps. In the intermediate SNR regime, this hybrid approximation is
tighter than existing purely additive or purely multiplicative approximations
to the capacity of this network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2056</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2056</id><created>2011-03-10</created><authors><author><keyname>Sergeyev</keyname><forenames>Yaroslav D.</forenames></author><author><keyname>Kvasov</keyname><forenames>Dmitri E.</forenames></author></authors><title>Global Search Based on Efficient Diagonal Partitions and a set of
  Lipschitz Constants</title><categories>math.OC cs.NA math.NA physics.comp-ph</categories><msc-class>90C26, 65K05, 90C56</msc-class><journal-ref>SIAM J. Optimization, Vol. 16, No. 3 (2006) 910-937</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the paper, the global optimization problem of a multidimensional
&quot;black-box&quot; function satisfying the Lipschitz condition over a hyperinterval
with an unknown Lipschitz constant is considered. A new efficient algorithm for
solving this problem is presented. At each iteration of the method a number of
possible Lipschitz constants is chosen from a set of values varying from zero
to infinity. This idea is unified with an efficient diagonal partition
strategy. A novel technique balancing usage of local and global information
during partitioning is proposed. A new procedure for finding lower bounds of
the objective function over hyperintervals is also considered. It is
demonstrated by extensive numerical experiments performed on more than 1600
multidimensional test functions that the new algorithm shows a very promising
performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2059</identifier>
 <datestamp>2012-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2059</id><created>2011-03-10</created><updated>2012-03-05</updated><authors><author><keyname>Chebotarev</keyname><forenames>Pavel</forenames></author></authors><title>The Walk Distances in Graphs</title><categories>math.CO cs.DM cs.SI math.MG</categories><comments>Accepted for publication in Discrete Applied Mathematics. 26 pages, 3
  figures</comments><msc-class>05C12, 05C50, 15B48</msc-class><doi>10.1016/j.dam.2012.02.015</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The walk distances in graphs are defined as the result of appropriate
transformations of the $\sum_{k=0}^\infty(tA)^k$ proximity measures, where $A$
is the weighted adjacency matrix of a graph and $t$ is a sufficiently small
positive parameter. The walk distances are graph-geodetic; moreover, they
converge to the shortest path distance and to the so-called long walk distance
as the parameter $t$ approaches its limiting values. We also show that the
logarithmic forest distances which are known to generalize the resistance
distance and the shortest path distance are a subclass of walk distances. On
the other hand, the long walk distance is equal to the resistance distance in a
transformed graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2063</identifier>
 <datestamp>2011-03-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2063</id><created>2011-03-10</created><authors><author><keyname>Stastny</keyname><forenames>Jiri</forenames></author><author><keyname>Prochazka</keyname><forenames>David</forenames></author><author><keyname>Koubek</keyname><forenames>Tomas</forenames></author><author><keyname>Landa</keyname><forenames>Jaromir</forenames></author></authors><title>Augmented reality usage for prototyping speed up</title><categories>cs.HC cs.GR</categories><comments>Keywords: augmented reality, prototyping, pose estimation,
  transformation matrix</comments><journal-ref>Acta Universitatis Agriculturae et Silviculturae Mendeleianae
  Brunensis, 2011, LIX, No. 2, pp. 353-360</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The first part of the article describes our approach for solution of this
problem by means of Augmented Reality. The merging of the real world model and
digital objects allows streamline the work with the model and speed up the
whole production phase significantly. The main advantage of augmented reality
is the possibility of direct manipulation with the scene using a portable
digital camera. Also adding digital objects into the scene could be done using
identification markers placed on the surface of the model. Therefore it is not
necessary to work with special input devices and lose the contact with the real
world model. Adjustments are done directly on the model. The key problem of
outlined solution is the ability of identification of an object within the
camera picture and its replacement with the digital object. The second part of
the article is focused especially on the identification of exact position and
orientation of the marker within the picture. The identification marker is
generalized into the triple of points which represents a general plane in
space. There is discussed the space identification of these points and the
description of representation of their position and orientation be means of
transformation matrix. This matrix is used for rendering of the graphical
objects (e. g. in OpenGL and Direct3D).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2068</identifier>
 <datestamp>2013-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2068</id><created>2011-03-10</created><updated>2011-09-08</updated><authors><author><keyname>Basilico</keyname><forenames>Justin D.</forenames></author><author><keyname>Munson</keyname><forenames>M. Arthur</forenames></author><author><keyname>Kolda</keyname><forenames>Tamara G.</forenames></author><author><keyname>Dixon</keyname><forenames>Kevin R.</forenames></author><author><keyname>Kegelmeyer</keyname><forenames>W. Philip</forenames></author></authors><title>COMET: A Recipe for Learning and Using Large Ensembles on Massive Data</title><categories>cs.LG cs.DC stat.ML</categories><acm-class>I.5; I.2.6; H.2.8</acm-class><journal-ref>ICDM 2011: Proceedings of the 2011 IEEE International Conference
  on Data Mining, pp. 41-50, 2011</journal-ref><doi>10.1109/ICDM.2011.39</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  COMET is a single-pass MapReduce algorithm for learning on large-scale data.
It builds multiple random forest ensembles on distributed blocks of data and
merges them into a mega-ensemble. This approach is appropriate when learning
from massive-scale data that is too large to fit on a single machine. To get
the best accuracy, IVoting should be used instead of bagging to generate the
training subset for each decision tree in the random forest. Experiments with
two large datasets (5GB and 50GB compressed) show that COMET compares favorably
(in both accuracy and training time) to learning on a subsample of data using a
serial algorithm. Finally, we propose a new Gaussian approach for lazy ensemble
evaluation which dynamically decides how many ensemble members to evaluate per
data point; this can reduce evaluation cost by 100X or more.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2071</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2071</id><created>2011-03-10</created><updated>2011-03-11</updated><authors><author><keyname>Lei</keyname><forenames>Jiang</forenames></author><author><keyname>Han</keyname><forenames>Zhu</forenames></author><author><keyname>V&#xe1;zquez-Castro</keyname><forenames>M. A.</forenames></author><author><keyname>Hj&#xf8;rungnes</keyname><forenames>Are</forenames></author></authors><title>Secure Satellite Communication Systems Design with Individual Secrecy
  Rate Constraints</title><categories>cs.IT cs.CR cs.NI math.IT</categories><comments>34 pages, 10 figures, 1 table, submitted to &quot;Transactions on
  Information Forensics and Security&quot;</comments><doi>10.1109/TIFS.2011.2148716</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study multibeam satellite secure communication through
physical (PHY) layer security techniques, i.e., joint power control and
beamforming. By first assuming that the Channel State Information (CSI) is
available and the beamforming weights are fixed, a novel secure satellite
system design is investigated to minimize the transmit power with individual
secrecy rate constraints. An iterative algorithm is proposed to obtain an
optimized power allocation strategy. Moreover, sub-optimal beamforming weights
are obtained by completely eliminating the co-channel interference and nulling
the eavesdroppers' signal simultaneously. In order to obtain jointly optimized
power allocation and beamforming strategy in some practical cases, e.g., with
certain estimation errors of the CSI, we further evaluate the impact of the
eavesdropper's CSI on the secure multibeam satellite system design. The
convergence of the iterative algorithm is proven under justifiable assumptions.
The performance is evaluated by taking into account the impact of the number of
antenna elements, number of beams, individual secrecy rate requirement, and
CSI. The proposed novel secure multibeam satellite system design can achieve
optimized power allocation to ensure the minimum individual secrecy rate
requirement. The results show that the joint beamforming scheme is more
favorable than fixed beamforming scheme, especially in the cases of a larger
number of satellite antenna elements and higher secrecy rate requirement.
Finally, we compare the results under the current satellite air-interface in
DVB-S2 and the results under Gaussian inputs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2091</identifier>
 <datestamp>2011-03-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2091</id><created>2011-02-24</created><authors><author><keyname>Chingtham</keyname><forenames>Tejbanta Singh</forenames></author><author><keyname>Sahoo</keyname><forenames>G.</forenames></author><author><keyname>Ghose</keyname><forenames>M. K.</forenames></author></authors><title>An Artificial Immune System Model for Multi-Agents Resource Sharing in
  Distributed Environments</title><categories>cs.AI</categories><journal-ref>International Journal on Computer Science and Engineering (IJCSE),
  Vol. 02, No. 05, 2010, pp 1813-1818</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Natural Immune system plays a vital role in the survival of the all living
being. It provides a mechanism to defend itself from external predates making
it consistent systems, capable of adapting itself for survival incase of
changes. The human immune system has motivated scientists and engineers for
finding powerful information processing algorithms that has solved complex
engineering tasks. This paper explores one of the various possibilities for
solving problem in a Multiagent scenario wherein multiple robots are deployed
to achieve a goal collectively. The final goal is dependent on the performance
of individual robot and its survival without having to lose its energy beyond a
predetermined threshold value by deploying an evolutionary computational
technique otherwise called the artificial immune system that imitates the
biological immune system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2102</identifier>
 <datestamp>2012-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2102</id><created>2011-03-10</created><updated>2011-05-12</updated><authors><author><keyname>Gnewuch</keyname><forenames>Michael</forenames></author><author><keyname>Wahlstr&#xf6;m</keyname><forenames>Magnus</forenames></author><author><keyname>Winzen</keyname><forenames>Carola</forenames></author></authors><title>A Randomized Algorithm Based on Threshold Accepting to Approximate the
  Star Discrepancy</title><categories>cs.DS</categories><journal-ref>SIAM Journal of Numerical Analysis 50, 781-807, 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new algorithm for estimating the star discrepancy of arbitrary
point sets. Similar to the algorithm for discrepancy approximation of Winker
and Fang [SIAM J. Numer. Anal. 34 (1997), 2028--2042] it is based on the
optimization algorithm threshold accepting. Our improvements include, amongst
others, a non-uniform sampling strategy which is more suited for
higher-dimensional inputs, and rounding steps which transform axis-parallel
boxes, on which the discrepancy is to be tested, into \emph{critical test
boxes}. These critical test boxes provably yield higher discrepancy values, and
contain the box that exhibits the maximum value of the local discrepancy. We
provide comprehensive experiments to test the new algorithm. Our randomized
algorithm computes the exact discrepancy frequently in all cases where this can
be checked (i.e., where the exact discrepancy of the point set can be computed
in feasible time). Most importantly, in higher dimension the new method behaves
clearly better than all previously known methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2110</identifier>
 <datestamp>2011-03-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2110</id><created>2011-03-01</created><authors><author><keyname>Martin</keyname><forenames>A.</forenames></author><author><keyname>Gayathri</keyname><forenames>V.</forenames></author><author><keyname>Saranya</keyname><forenames>G.</forenames></author><author><keyname>Gayathri</keyname><forenames>P.</forenames></author><author><keyname>Venkatesan</keyname><forenames>Prasanna</forenames></author></authors><title>A hybrid model for bankruptcy prediction using genetic algorithm, fuzzy
  c-means and mars</title><categories>cs.NE cs.AI</categories><comments>Bankruptcy prediction, financial ratio models, Genetic Algorithm,
  Fuzzy c-means Clustering, MARS</comments><journal-ref>International Journal on Soft Computing (IJSC), Vol.2, No.1,
  February 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bankruptcy prediction is very important for all the organization since it
affects the economy and rise many social problems with high costs. There are
large number of techniques have been developed to predict the bankruptcy, which
helps the decision makers such as investors and financial analysts. One of the
bankruptcy prediction models is the hybrid model using Fuzzy C-means clustering
and MARS, which uses static ratios taken from the bank financial statements for
prediction, which has its own theoretical advantages. The performance of
existing bankruptcy model can be improved by selecting the best features
dynamically depend on the nature of the firm. This dynamic selection can be
accomplished by Genetic Algorithm and it improves the performance of prediction
model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2165</identifier>
 <datestamp>2011-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2165</id><created>2011-03-10</created><updated>2011-05-05</updated><authors><author><keyname>Hertli</keyname><forenames>Timon</forenames></author></authors><title>3-SAT Faster and Simpler - Unique-SAT Bounds for PPSZ Hold in General</title><categories>cs.CC cs.DS</categories><comments>12 pages, no figures; critical variables are now called frozen, added
  reference to Makino et al., shortened some proofs and fixed typos</comments><acm-class>F.2.2; G.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The PPSZ algorithm by Paturi, Pudl\'ak, Saks, and Zane [1998] is the fastest
known algorithm for Unique k-SAT, where the input formula does not have more
than one satisfying assignment. For k&gt;=5 the same bounds hold for general
k-SAT. We show that this is also the case for k=3,4, using a slightly modified
PPSZ algorithm. We do the analysis by defining a cost for satisfiable CNF
formulas, which we prove to decrease in each PPSZ step by a certain amount.
This improves our previous best bounds with Moser and Scheder [2011] for 3-SAT
to O(1.308^n) and for 4-SAT to O(1.469^n).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2167</identifier>
 <datestamp>2014-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2167</id><created>2011-03-10</created><updated>2014-08-21</updated><authors><author><keyname>Belazzougui</keyname><forenames>Djamal</forenames></author></authors><title>Improved space-time tradeoffs for approximate full-text indexing with
  one edit error</title><categories>cs.DS</categories><comments>Accepted for publication in a journal (28 pages)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we are interested in indexing texts for substring matching
queries with one edit error. That is, given a text $T$ of $n$ characters over
an alphabet of size $\sigma$, we are asked to build a data structure that
answers the following query: find all the $occ$ substrings of the text that are
at edit distance at most $1$ from a given string $q$ of length $m$. In this
paper we show two new results for this problem. The first result, suitable for
an unbounded alphabet, uses $O(n\log^\epsilon n)$ (where $\epsilon$ is any
constant such that $0&lt;\epsilon&lt;1$) words of space and answers to queries in
time $O(m+occ)$. This improves simultaneously in space and time over the result
of Cole et al. The second result, suitable only for a constant alphabet, relies
on compressed text indices and comes in two variants: the first variant uses
$O(n\log^{\epsilon} n)$ bits of space and answers to queries in time
$O(m+occ)$, while the second variant uses $O(n\log\log n)$ bits of space and
answers to queries in time $O((m+occ)\log\log n)$. This second result improves
on the previously best results for constant alphabets achieved in Lam et al.
(Algorithmica 2008) and Chan et al. (Algorithmica 2010).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2172</identifier>
 <datestamp>2011-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2172</id><created>2011-03-10</created><authors><author><keyname>Altieri</keyname><forenames>Andres</forenames></author><author><keyname>Vega</keyname><forenames>Leonardo Rey</forenames></author><author><keyname>Galarza</keyname><forenames>Cecilia G.</forenames></author><author><keyname>Piantanida</keyname><forenames>Pablo</forenames></author></authors><title>Cooperative Strategies for Interference-Limited Wireless Networks</title><categories>cs.IT math.IT</categories><comments>5 pages and 4 figures. Submitted to ISIT 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider the communication of a single-user aided by a nearby relay involved
in a large wireless network where the nodes form an homogeneous Poisson point
process. Since this network is interference-limited the asymptotic error
probability is bounded from above by the outage probability experienced by the
user. We investigate the outage behavior for the well-known cooperative
schemes, namely, decode-and-forward (DF) and compress-and-forward (CF). In this
setting, the outage events are induced by both fading and the spatial proximity
of neighbor nodes who generate the strongest interference and hence the worst
communication case. Upper and lower bounds on the asymptotic error probability
which are tight in some cases are derived. It is shown that there exists a
clear trade off between the network density and the benefits of user
cooperation. These results are useful to evaluate performances and to optimize
relaying schemes in the context of large wireless networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2177</identifier>
 <datestamp>2012-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2177</id><created>2011-03-10</created><updated>2012-12-23</updated><authors><author><keyname>Dhillon</keyname><forenames>Harpreet S.</forenames></author><author><keyname>Ganti</keyname><forenames>Radha Krishna</forenames></author><author><keyname>Baccelli</keyname><forenames>Francois</forenames></author><author><keyname>Andrews</keyname><forenames>Jeffrey G.</forenames></author></authors><title>Modeling and Analysis of K-Tier Downlink Heterogeneous Cellular Networks</title><categories>cs.IT math.IT</categories><comments>IEEE Journal on Selected Areas in Communications, vol. 30, no. 3, pp.
  550 - 560, Apr. 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cellular networks are in a major transition from a carefully planned set of
large tower-mounted base-stations (BSs) to an irregular deployment of
heterogeneous infrastructure elements that often additionally includes micro,
pico, and femtocells, as well as distributed antennas. In this paper, we
develop a tractable, flexible, and accurate model for a downlink heterogeneous
cellular network (HCN) consisting of K tiers of randomly located BSs, where
each tier may differ in terms of average transmit power, supported data rate
and BS density. Assuming a mobile user connects to the strongest candidate BS,
the resulting Signal-to-Interference-plus-Noise-Ratio (SINR) is greater than 1
when in coverage, Rayleigh fading, we derive an expression for the probability
of coverage (equivalently outage) over the entire network under both open and
closed access, which assumes a strikingly simple closed-form in the high SINR
regime and is accurate down to -4 dB even under weaker assumptions. For
external validation, we compare against an actual LTE network (for tier 1) with
the other K-1 tiers being modeled as independent Poisson Point Processes. In
this case as well, our model is accurate to within 1-2 dB. We also derive the
average rate achieved by a randomly located mobile and the average load on each
tier of BSs. One interesting observation for interference-limited open access
networks is that at a given SINR, adding more tiers and/or BSs neither
increases nor decreases the probability of coverage or outage when all the
tiers have the same target-SINR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2184</identifier>
 <datestamp>2011-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2184</id><created>2011-03-10</created><authors><author><keyname>Steel</keyname><forenames>Max D.</forenames></author></authors><title>On Stability of V-Like Formations</title><categories>physics.soc-ph cs.SI nlin.AO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Group behavior has received much attention as a test case of
self-organization. There has been much written in recent years to investigate
interactions within groups of agents. These agents can be animals moving in an
interactive way, such as birds, but can also refer to situations such as people
driving in traffic. The models that describe these interactions are able to
reproduce different structures and patterns relating to the movement and
interaction of the agents involved. The advantages and necessities of this type
of analysis in any complex biological, technological, economic, or social
system are important and far-reaching. Each model that we will discuss
describes interaction between agents.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2201</identifier>
 <datestamp>2011-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2201</id><created>2011-03-11</created><updated>2011-11-19</updated><authors><author><keyname>Li</keyname><forenames>Yang D.</forenames></author></authors><title>A New Paradigm for Quantum Nonlocality</title><categories>quant-ph cs.CC</categories><comments>submitted to PRL</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bell's theorem basically states that local hidden variable theory cannot
predict the correlations produced by quantum mechanics. It is based on the
assumption that Alice and Bob can choose measurements from a measurement set
containing multiple elements. We establish a new paradigm that departs from
Bell's paradigm by assuming that there are no choices for Alice and Bob and
that the measurements Alice and Bob will make are fixed from the start. We
include a process of quantum computation in our model. To the best of our
knowledge, we are the first to connect quantum computation and nonlocality, the
two faces of entanglement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2212</identifier>
 <datestamp>2012-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2212</id><created>2011-03-11</created><updated>2012-01-10</updated><authors><author><keyname>Yin</keyname><forenames>Dongjie</forenames></author><author><keyname>Wong</keyname><forenames>Pui King</forenames></author><author><keyname>Lee</keyname><forenames>Tony T.</forenames></author></authors><title>Stability and Queueing Analysis of IEEE 802.11 Distributed Coordination
  Function</title><categories>cs.NI</categories><comments>26 pages, 7 figures, and 2 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A widely adopted two-dimensional Markov chain model of the IEEE 802.11 DCF
was introduced by Bianchi to characterize the backoff behavior of a single node
under a saturated traffic condition. Using this approach, we propose a queuing
model for the 802.11 DCF under a non-saturated traffic environment. The input
buffer of each node is modeled as a Geo/G/1 queue, and the packet service time
distribution is derived from Markov state space of 802.11 DCF with the
underlying scheduling algorithm. The DCF defines two access mechanisms, namely
the Basic access mechanism and the request-to-send/clear-to-send (RTS/CTS)
access mechanism. Based on our model, performance analyses of both schemes are
studied with probabilistic exponential backoff scheduling. We obtain the
characteristic equation of network throughput and expressions of packet
queueing delay. Specifically, we obtain the stable throughput and bounded delay
regions with respect to the retransmission factor according to the basic
queueing analysis. For both access schemes, the bounded delay region is a
subset of the stable throughput region. Our results show that the RTS/CTS
access mechanism is more stable and performs better than the Basic access
mechanism. The analysis in this paper is verified by simulation results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2215</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2215</id><created>2011-03-11</created><updated>2012-07-15</updated><authors><author><keyname>Liu</keyname><forenames>Xin</forenames></author><author><keyname>Datta</keyname><forenames>Anwitaman</forenames></author><author><keyname>Rzadca</keyname><forenames>Krzysztof</forenames></author></authors><title>Trust beyond reputation: A computational trust model based on
  stereotypes</title><categories>cs.CR cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Models of computational trust support users in taking decisions. They are
commonly used to guide users' judgements in online auction sites; or to
determine quality of contributions in Web 2.0 sites. However, most existing
systems require historical information about the past behavior of the specific
agent being judged. In contrast, in real life, to anticipate and to predict a
stranger's actions in absence of the knowledge of such behavioral history, we
often use our &quot;instinct&quot;- essentially stereotypes developed from our past
interactions with other &quot;similar&quot; persons. In this paper, we propose
StereoTrust, a computational trust model inspired by stereotypes as used in
real-life. A stereotype contains certain features of agents and an expected
outcome of the transaction. When facing a stranger, an agent derives its trust
by aggregating stereotypes matching the stranger's profile. Since stereotypes
are formed locally, recommendations stem from the trustor's own personal
experiences and perspective. Historical behavioral information, when available,
can be used to refine the analysis. According to our experiments using
Epinions.com dataset, StereoTrust compares favorably with existing trust models
that use different kinds of information and more complete historical
information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2230</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2230</id><created>2011-03-11</created><updated>2012-08-21</updated><authors><author><keyname>Erd&#xe9;lyi</keyname><forenames>G&#xe1;bor</forenames></author><author><keyname>Fellows</keyname><forenames>Michael</forenames></author><author><keyname>Rothe</keyname><forenames>J&#xf6;rg</forenames></author><author><keyname>Schend</keyname><forenames>Lena</forenames></author></authors><title>Control Complexity in Bucklin and Fallback Voting</title><categories>cs.CC cs.MA</categories><comments>50 pages; merges, extends, and supersedes the technical reports
  arXiv:1004.3398, arXiv:1004.3659, and arXiv:1005.4115</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Electoral control models ways of changing the outcome of an election via such
actions as adding/deleting/partitioning either candidates or voters. To protect
elections from such control attempts, computational complexity has been
investigated and the corresponding NP-hardness results are termed &quot;resistance.&quot;
It has been a long-running project of research in this area to classify the
major voting systems in terms of their resistance properties. We show that
fallback voting, an election system proposed by Brams and Sanver (2009) to
combine Bucklin with approval voting, is resistant to each of the common types
of control except to destructive control by either adding or deleting voters.
Thus fallback voting displays the broadest control resistance currently known
to hold among natural election systems with a polynomial-time winner problem.
We also study the control complexity of Bucklin voting and show that it
performs at least almost as well as fallback voting in terms of control
resistance. As Bucklin voting is a special case of fallback voting, each
resistance shown for Bucklin voting strengthens the corresponding resistance
for fallback voting. Such worst-case complexity analysis is at best an
indication of security against control attempts, rather than a proof. In
practice, the difficulty of control will depend on the structure of typical
instances. We investigate the parameterized control complexity of Bucklin and
fallback voting, according to several parameters that are often likely to be
small for typical instances. Our results, though still in the worst-case
complexity model, can be interpreted as significant strengthenings of the
resistance demonstrations based on NP-hardness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2240</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2240</id><created>2011-03-11</created><authors><author><keyname>Kang</keyname><forenames>Xin</forenames></author><author><keyname>Zhang</keyname><forenames>Rui</forenames></author><author><keyname>Motani</keyname><forenames>Mehul</forenames></author></authors><title>Price-Based Resource Allocation for Spectrum-Sharing Femtocell Networks:
  A Stackelberg Game Approach</title><categories>cs.IT math.IT</categories><comments>27 pages, 7 figures, Submitted to JSAC</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the price-based resource allocation strategies for
the uplink transmission of a spectrum-sharing femtocell network, in which a
central macrocell is underlaid with distributed femtocells, all operating over
the same frequency band as the macrocell. Assuming that the macrocell base
station (MBS) protects itself by pricing the interference from the femtocell
users, a Stackelberg game is formulated to study the joint utility maximization
of the macrocell and the femtocells subject to a maximum tolerable interference
power constraint at the MBS. Especially, two practical femtocell channel
models: sparsely deployed scenario for rural areas and densely deployed
scenario for urban areas, are investigated. For each scenario, two pricing
schemes: uniform pricing and non-uniform pricing, are proposed. Then, the
Stackelberg equilibriums for these proposed games are studied, and an effective
distributed interference price bargaining algorithm with guaranteed convergence
is proposed for the uniform-pricing case. Finally, numerical examples are
presented to verify the proposed studies. It is shown that the proposed
algorithms are effective in resource allocation and macrocell protection
requiring minimal network overhead for spectrum-sharing-based two-tier
femtocell networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2246</identifier>
 <datestamp>2011-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2246</id><created>2011-03-11</created><authors><author><keyname>Schmaltz</keyname><forenames>Julien</forenames></author></authors><title>Formal verification of a time-triggered hardware interface</title><categories>cs.LO</categories><comments>30 pages, 16 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a formal proof of a time-triggered hardware interface. The design
implements the bit-clock synchronization mechanism specified by the FlexRay
standard for automotive embedded systems. The design is described at the
gate-level. It can be translated to Verilog and synthesized on FPGA. The proof
is based on a general model of asynchronous communications and combines
interactive theorem proving in Isabelle/HOL and automatic model-checking using
NuSMV together with a model-reduction procedure, IHaVeIt. Our general model of
asynchronous communications defines a clear separation between analog and
digital concerns. This separation enables the combination of theorem proving
and model-checking for an efficient methodology. The analog phenomena are
formalized in the logic of Isabelle/HOL. The gate-level hardware is
automatically analyzed using IHaVeIt. Our proof reveals the correct values of a
crucial parameter of the bit-clock synchronization mechanism. Our main theorem
proves the functional correctness as well as the maximum number of cycles of
the transmission.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2251</identifier>
 <datestamp>2011-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2251</id><created>2011-03-11</created><authors><author><keyname>Briggs</keyname><forenames>Keith</forenames></author></authors><title>Asymptotic expansions for enumerating connected labelled graphs</title><categories>cs.DM math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  I compute several terms of the asymptotic expansion of the number of
connected labelled graphs with n nodes and m edges, for small k=m-n.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2252</identifier>
 <datestamp>2012-03-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2252</id><created>2011-03-11</created><updated>2011-04-25</updated><authors><author><keyname>Smilkov</keyname><forenames>Daniel</forenames></author><author><keyname>Kocarev</keyname><forenames>Ljupco</forenames></author></authors><title>Analytically solvable processes on networks</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><comments>10 pages, 3 figures</comments><doi>10.1103/PhysRevE.84.016104</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a broad class of analytically solvable processes on networks. In
the special case, they reduce to random walk and consensus process - two most
basic processes on networks. Our class differs from previous models of
interactions (such as stochastic Ising model, cellular automata, infinite
particle system, and voter model) in several ways, two most important being:
(i) the model is analytically solvable even when the dynamical equation for
each node may be different and the network may have an arbitrary finite graph
and influence structure; and (ii) in addition, when local dynamic is described
by the same evolution equation, the model is decomposable: the equilibrium
behavior of the system can be expressed as an explicit function of network
topology and node dynamics
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2264</identifier>
 <datestamp>2011-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2264</id><created>2011-03-11</created><authors><author><keyname>Smilkov</keyname><forenames>Daniel</forenames></author><author><keyname>Kocarev</keyname><forenames>Ljupco</forenames></author></authors><title>Rich-club and page-club coefficients for directed graphs</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><comments>18 pages, 6 figures</comments><journal-ref>Physica A: Statistical Mechanics and its Applications, Volume 389,
  Issue 11, 1 June 2010, Pages 2290-2299</journal-ref><doi>10.1016/j.physa.2010.02.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rich-club and page-club coefficients and their null models are introduced for
directed graphs. Null models allow for a quantitative discussion of the
rich-club and page-club phenomena. These coefficients are computed for four
directed real-world networks: Arxiv High Energy Physics paper citation network,
Web network (released from Google), Citation network among US Patents, and
Email network from a EU research institution. The results show a high
correlation between rich-club and page-club ordering. For journal paper
citation network, we identify both rich-club and page-club ordering, showing
that {}&quot;elite&quot; papers are cited by other {}&quot;elite&quot; papers. Google web network
shows partial rich-club and page-club ordering up to some point and then a
narrow declining of the corresponding normalized coefficients, indicating the
lack of rich-club ordering and the lack of page-club ordering, i.e. high
in-degree (PageRank) pages purposely avoid sharing links with other high
in-degree (PageRank) pages. For UC patents citation network, we identify
page-club and rich-club ordering providing a conclusion that {}&quot;elite&quot; patents
are cited by other {}&quot;elite&quot; patents. Finally, for e-mail communication network
we show lack of both rich-club and page-club ordering. We construct an example
of synthetic network showing page-club ordering and the lack of rich-club
ordering.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2268</identifier>
 <datestamp>2011-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2268</id><created>2011-03-08</created><authors><author><keyname>Ablayev</keyname><forenames>Farid</forenames></author><author><keyname>Coecke</keyname><forenames>Bob</forenames></author><author><keyname>Vasiliev</keyname><forenames>Alexander</forenames></author></authors><title>Proceedings CSR 2010 Workshop on High Productivity Computations</title><categories>cs.CC quant-ph</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 52, 2011</journal-ref><doi>10.4204/EPTCS.52</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This volume contains the proceedings of the Workshop on High Productivity
Computations (HPC 2010) which took place on June 21-22 in Kazan, Russia. This
workshop was held as a satellite workshop of the 5th International Computer
Science Symposium in Russia (CSR 2010).
  HPC 2010 was intended to organize the discussions about high productivity
computing means and models, including but not limited to high performance and
quantum information processing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2275</identifier>
 <datestamp>2011-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2275</id><created>2011-03-11</created><authors><author><keyname>Cygan</keyname><forenames>Marek</forenames></author><author><keyname>Kowalik</keyname><forenames>&#x141;ukasz</forenames></author></authors><title>Channel Assignment via Fast Zeta Transform</title><categories>cs.DS</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show an O*((l+1)^n)-time algorithm for the channel assignment problem,
where l is the maximum edge weight. This improves on the previous
O*((l+2)^n)-time algorithm by Kral, as well as algorithms for important special
cases, like L(2,1)-labelling. For the latter problem, our algorithm works in
O*(3^n) time. The progress is achieved by applying the fast zeta transform in
combination with the inclusion-exclusion principle.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2289</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2289</id><created>2011-03-11</created><authors><author><keyname>Saligrama</keyname><forenames>Venkatesh</forenames></author><author><keyname>Alanyali</keyname><forenames>Murat</forenames></author></authors><title>A Token Based Algorithm to Distributed Computation in Sensor Networks</title><categories>cs.NI cs.DC cs.IT cs.SY math.IT math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider distributed algorithms for data aggregation and function
computation in sensor networks. The algorithms perform pairwise computations
along edges of an underlying communication graph. A token is associated with
each sensor node, which acts as a transmission permit. Nodes with active tokens
have transmission permits; they generate messages at a constant rate and send
each message to a randomly selected neighbor. By using different strategies to
control the transmission permits we can obtain tradeoffs between message and
time complexity. Gossip corresponds to the case when all nodes have permits all
the time. We study algorithms where permits are revoked after transmission and
restored upon reception. Examples of such algorithms include Simple-Random
Walk(SRW), Coalescent-Random-Walk(CRW) and Controlled Flooding(CFLD) and their
hybrid variants. SRW has a single node permit, which is passed on in the
network. CRW, initially initially has a permit for each node but these permits
are revoked gradually. The final result for SRW and CRW resides at a single(or
few) random node(s) making a direct comparison with GOSSIP difficult. A hybrid
two-phase algorithm switching from CRW to CFLD at a suitable pre-determined
time can be employed to achieve consensus. We show that such hybrid variants
achieve significant gains in both message and time complexity. The per-node
message complexity for n-node graphs, such as 2D mesh, torii, and Random
geometric graphs, scales as $O(polylog(n))$ and the corresponding time
complexity scales as O(n). The reduced per-node message complexity leads to
reduced energy utilization in sensor networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2303</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2303</id><created>2011-03-11</created><updated>2013-09-27</updated><authors><author><keyname>Anelli</keyname><forenames>Pascal</forenames></author><author><keyname>Diana</keyname><forenames>Remi</forenames></author><author><keyname>Lochin</keyname><forenames>Emmanuel</forenames></author></authors><title>FavourQueue: a Parameterless Active Queue Management to Speed Up Short
  TCP Flows (and others too!)</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents and analyses the implementation of a novel active queue
management (AQM) named FavorQueue that aims to improve delay transfer of short
lived TCP flows over best-effort networks. The idea is to dequeue packets that
do not belong to a flow previously enqueued first. The rationale is to mitigate
the delay induced by long-lived TCP flows over the pace of short TCP data
requests and to prevent dropped packets at the beginning of a connection and
during recovery period. Although the main target of this AQM is to accelerate
short TCP traffic, we show that FavorQueue does not only improve the
performance of short TCP traffic but also improves the performance of all TCP
traffic in terms of drop ratio and latency whatever the flow size. In
particular, we demonstrate that FavorQueue reduces the loss of a retransmitted
packet, decreases the number of dropped packets recovered by RTO and improves
the latency up to 30% compared to DropTail. Finally, we show that this scheme
remains compliant with recent TCP updates such as the increase of the initial
slow-start value.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2325</identifier>
 <datestamp>2011-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2325</id><created>2011-03-11</created><authors><author><keyname>Levary</keyname><forenames>David</forenames></author><author><keyname>Eckmann</keyname><forenames>Jean-Pierre</forenames></author><author><keyname>Moses</keyname><forenames>Elisha</forenames></author><author><keyname>Tlusty</keyname><forenames>Tsvi</forenames></author></authors><title>Self reference in word definitions</title><categories>cs.CL cs.AI physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dictionaries are inherently circular in nature. A given word is linked to a
set of alternative words (the definition) which in turn point to further
descendants. Iterating through definitions in this way, one typically finds
that definitions loop back upon themselves. The graph formed by such
definitional relations is our object of study. By eliminating those links which
are not in loops, we arrive at a core subgraph of highly connected nodes.
  We observe that definitional loops are conveniently classified by length,
with longer loops usually emerging from semantic misinterpretation. By breaking
the long loops in the graph of the dictionary, we arrive at a set of
disconnected clusters. We find that the words in these clusters constitute
semantic units, and moreover tend to have been introduced into the English
language at similar times, suggesting a possible mechanism for language
evolution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2336</identifier>
 <datestamp>2011-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2336</id><created>2011-03-11</created><authors><author><keyname>Litayem</keyname><forenames>Nabil</forenames></author><author><keyname>Achballah</keyname><forenames>Ahmed Ben</forenames></author><author><keyname>Saoud</keyname><forenames>Slim Ben</forenames></author></authors><title>Building XenoBuntu Linux Distribution for Teaching and Prototyping
  Real-Time Operating Systems</title><categories>cs.OS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes the realization of a new Linux distribution based on
Ubuntu Linux and Xenomai Real-Time framework. This realization is motivated by
the eminent need of real-time systems in modern computer science courses. The
majority of the technical choices are made after qualitative comparison. The
main goal of this distribution is to offer standard Operating Systems (OS) that
include Xenomai infrastructure and the essential tools to begin hard real-time
application development inside a convivial desktop environment. The released
live/installable DVD can be adopted to emulate several classic RTOS Application
Program Interfaces (APIs), directly use and understand real-time Linux in
convivial desktop environment and prototyping real-time embedded applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2338</identifier>
 <datestamp>2012-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2338</id><created>2011-03-11</created><updated>2012-03-11</updated><authors><author><keyname>Martin</keyname><forenames>Carla D.</forenames></author><author><keyname>Porter</keyname><forenames>Mason A.</forenames></author></authors><title>The Extraordinary SVD</title><categories>math.NA cs.NA physics.comp-ph physics.data-an</categories><comments>20 pages, 5 figures (many with multiple parts); v2 actually includes
  the references (thanks to those who pointed this out!); some expository
  updates for v3; a few expository updates for v4 (such as a longer abstract,
  revised format for references, etc); to appear in American Mathematical
  Monthly; v5: corrected a couple of small grammatical and bibtex typos</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The singular value decomposition (SVD) is a popular matrix factorization that
has been used widely in applications ever since an efficient algorithm for its
computation was developed in the 1970s. In recent years, the SVD has become
even more prominent due to a surge in applications and increased computational
memory and speed.
  To illustrate the vitality of the SVD in data analysis, we highlight three of
its lesser-known yet fascinating applications: the SVD can be used to
characterize political positions of Congressmen, measure the growth rate of
crystals in igneous rock, and examine entanglement in quantum computation. We
also discuss higher-dimensional generalizations of the SVD, which have become
increasingly crucial with the newfound wealth of multidimensional data and have
launched new research initiatives in both theoretical and applied mathematics.
With its bountiful theory and applications, the SVD is truly extraordinary.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2342</identifier>
 <datestamp>2011-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2342</id><created>2011-03-11</created><authors><author><keyname>Silva</keyname><forenames>Tiago</forenames></author><author><keyname>Dutra</keyname><forenames>In&#xea;s</forenames></author></authors><title>SPPAM - Statistical PreProcessing AlgorithM</title><categories>cs.AI</categories><comments>Submited to IJCAI11 conference on January 25, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most machine learning tools work with a single table where each row is an
instance and each column is an attribute. Each cell of the table contains an
attribute value for an instance. This representation prevents one important
form of learning, which is, classification based on groups of correlated
records, such as multiple exams of a single patient, internet customer
preferences, weather forecast or prediction of sea conditions for a given day.
To some extent, relational learning methods, such as inductive logic
programming, can capture this correlation through the use of intensional
predicates added to the background knowledge. In this work, we propose SPPAM,
an algorithm that aggregates past observations in one single record. We show
that applying SPPAM to the original correlated data, before the learning task,
can produce classifiers that are better than the ones trained using all
records.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2348</identifier>
 <datestamp>2011-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2348</id><created>2011-03-11</created><authors><author><keyname>Lin</keyname><forenames>Felix Xiaozhu</forenames></author><author><keyname>Wang</keyname><forenames>Zhen</forenames></author><author><keyname>LiKamWa</keyname><forenames>Robert</forenames></author><author><keyname>Zhong</keyname><forenames>Lin</forenames></author></authors><title>Transparent Programming of Heterogeneous Smartphones for Sensing</title><categories>cs.OS cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sensing on smartphones is known to be power-hungry. It has been shown that
this problem can be solved by adding an ultra low-power processor to execute
simple, frequent sensor data processing. While very effective in saving energy,
this resulting heterogeneous, distributed architecture poses a significant
challenge to application development.
  We present Reflex, a suite of runtime and compilation techniques to conceal
the heterogeneous, distributed nature from developers. The Reflex automatically
transforms the developer's code for distributed execution with the help of the
Reflex runtime. To create a unified system illusion, Reflex features a novel
software distributed shared memory (DSM) design that leverages the extreme
architectural asymmetry between the low-power processor and the powerful
central processor to achieve both energy efficiency and performance.
  We report a complete realization of Reflex for heterogeneous smartphones with
Maemo/Linux as the central kernel. Using a tri-processor hardware prototype and
sensing applications reported in recent literature, we evaluate the Reflex
realization for programming transparency, energy efficiency, and performance.
We show that Reflex supports a programming style that is very close to
contemporary smartphone programming. It allows existing sensing applications to
be ported with minor source code changes. Reflex reduces the system power in
sensing by up to 83%, and its runtime system only consumes 10% local memory on
a typical ultra-low power processor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2351</identifier>
 <datestamp>2011-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2351</id><created>2011-03-11</created><authors><author><keyname>Grabowski</keyname><forenames>Szymon</forenames></author><author><keyname>Deorowicz</keyname><forenames>Sebastian</forenames></author></authors><title>Engineering Relative Compression of Genomes</title><categories>cs.CE cs.IT math.IT q-bio.QM</categories><comments>12 pages</comments><msc-class>68W32</msc-class><acm-class>E.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Technology progress in DNA sequencing boosts the genomic database growth at
faster and faster rate. Compression, accompanied with random access
capabilities, is the key to maintain those huge amounts of data. In this paper
we present an LZ77-style compression scheme for relative compression of
multiple genomes of the same species. While the solution bears similarity to
known algorithms, it offers significantly higher compression ratios at
compression speed over a order of magnitude greater. One of the new successful
ideas is augmenting the reference sequence with phrases from the other
sequences, making more LZ-matches available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2356</identifier>
 <datestamp>2011-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2356</id><created>2011-03-11</created><authors><author><keyname>Gelman</keyname><forenames>Evgenia</forenames></author></authors><title>Adaptive mosaic image representation for image processing</title><categories>physics.data-an cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Method for a mosaic image representation (MIR) is proposed for a selective
treatment of image fragments of different transition frequency. MIR method is
based on piecewise-constant image approximation on a non-uniform orthogonal
grid constructed by the following recurrent multigrid algorithm. A sequence of
nested uniform grids is built, such that each cell of a current grid is
subdivided into four smaller cells for the next grid designing. In each grid
the cells are selected, where the color intensity function can be approximated
by its average value with a given precision (thereafter 'good' cells). After
replacing colors of good cells by their approximating constants the
reconstructed image looks like a mosaic composed of one-colored cells.
Multigrid algorithm results in the stratification of the image space into
regions of different transition frequency. Sizes of these regions depend on the
few tuning precision parameters that characterizes adaptability of the method
to the image fragments of different non-homogeneity degree. The method is found
efficient for prominent contour (skeleton) extraction, edge detection as well
as for the Lossy Compression of single images and video sequence of images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2376</identifier>
 <datestamp>2011-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2376</id><created>2011-03-11</created><authors><author><keyname>Perlovsky</keyname><forenames>Leonid</forenames><affiliation>Harvard University and the AFRL</affiliation></author></authors><title>Language, Emotions, and Cultures: Emotional Sapir-Whorf Hypothesis</title><categories>cs.AI</categories><comments>16p, 2 figs</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An emotional version of Sapir-Whorf hypothesis suggests that differences in
language emotionalities influence differences among cultures no less than
conceptual differences. Conceptual contents of languages and cultures to
significant extent are determined by words and their semantic differences;
these could be borrowed among languages and exchanged among cultures. Emotional
differences, as suggested in the paper, are related to grammar and mostly
cannot be borrowed. Conceptual and emotional mechanisms of languages are
considered here along with their functions in the mind and cultural evolution.
A fundamental contradiction in human mind is considered: language evolution
requires reduced emotionality, but &quot;too low&quot; emotionality makes language
&quot;irrelevant to life,&quot; disconnected from sensory-motor experience. Neural
mechanisms of these processes are suggested as well as their mathematical
models: the knowledge instinct, the language instinct, the dual model
connecting language and cognition, dynamic logic, neural modeling fields.
Mathematical results are related to cognitive science, linguistics, and
psychology. Experimental evidence and theoretical arguments are discussed.
Approximate equations for evolution of human minds and cultures are obtained.
Their solutions identify three types of cultures: &quot;conceptual&quot;-pragmatic
cultures, in which emotionality of language is reduced and differentiation
overtakes synthesis resulting in fast evolution at the price of uncertainty of
values, self doubts, and internal crises; &quot;traditional-emotional&quot; cultures
where differentiation lags behind synthesis, resulting in cultural stability at
the price of stagnation; and &quot;multi-cultural&quot; societies combining fast cultural
evolution and stability. Unsolved problems and future theoretical and
experimental directions are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2404</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2404</id><created>2011-03-11</created><authors><author><keyname>Ruj</keyname><forenames>Sushmita</forenames></author><author><keyname>Cavenaghi</keyname><forenames>Marcos Antonio</forenames></author><author><keyname>Huang</keyname><forenames>Zhen</forenames></author><author><keyname>Nayak</keyname><forenames>Amiya</forenames></author><author><keyname>Stojmenovic</keyname><forenames>Ivan</forenames></author></authors><title>Data-centric Misbehavior Detection in VANETs</title><categories>cs.NI</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Detecting misbehavior (such as transmissions of false information) in
vehicular ad hoc networks (VANETs) is very important problem with wide range of
implications including safety related and congestion avoidance applications. We
discuss several limitations of existing misbehavior detection schemes (MDS)
designed for VANETs. Most MDS are concerned with detection of malicious nodes.
In most situations, vehicles would send wrong information because of selfish
reasons of their owners, e.g. for gaining access to a particular lane. Because
of this (\emph{rational behavior}), it is more important to detect false
information than to identify misbehaving nodes. We introduce the concept of
data-centric misbehavior detection and propose algorithms which detect false
alert messages and misbehaving nodes by observing their actions after sending
out the alert messages. With the data-centric MDS, each node can independently
decide whether an information received is correct or false. The decision is
based on the consistency of recent messages and new alert with reported and
estimated vehicle positions. No voting or majority decisions is needed, making
our MDS resilient to Sybil attacks. Instead of revoking all the secret
credentials of misbehaving nodes, as done in most schemes, we impose fines on
misbehaving nodes (administered by the certification authority), discouraging
them to act selfishly. This reduces the computation and communication costs
involved in revoking all the secret credentials of misbehaving nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2405</identifier>
 <datestamp>2012-12-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2405</id><created>2011-03-11</created><authors><author><keyname>Yang</keyname><forenames>Xintian</forenames><affiliation>Ohio State University</affiliation></author><author><keyname>Parthasarathy</keyname><forenames>Srinivasan</forenames><affiliation>Ohio State University</affiliation></author><author><keyname>Sadayappan</keyname><forenames>Ponnuswamy</forenames><affiliation>Ohio State University</affiliation></author></authors><title>Fast Sparse Matrix-Vector Multiplication on GPUs: Implications for Graph
  Mining</title><categories>cs.NA cs.MS</categories><comments>VLDB2011</comments><proxy>uroehm</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 4, No. 4, pp.
  231-242 (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Scaling up the sparse matrix-vector multiplication kernel on modern Graphics
Processing Units (GPU) has been at the heart of numerous studies in both
academia and industry. In this article we present a novel non-parametric,
self-tunable, approach to data representation for computing this kernel,
particularly targeting sparse matrices representing power-law graphs. Using
real data, we show how our representation scheme, coupled with a novel tiling
algorithm, can yield significant benefits over the current state of the art GPU
efforts on a number of core data mining algorithms such as PageRank, HITS and
Random Walk with Restart.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2406</identifier>
 <datestamp>2011-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2406</id><created>2011-03-11</created><authors><author><keyname>Dalvi</keyname><forenames>Nilesh</forenames><affiliation>Yahoo! Research</affiliation></author><author><keyname>Kumar</keyname><forenames>Ravi</forenames><affiliation>Yahoo! Research</affiliation></author><author><keyname>Soliman</keyname><forenames>Mohamed</forenames><affiliation>U. of Waterloo</affiliation></author></authors><title>Automatic Wrappers for Large Scale Web Extraction</title><categories>cs.DB</categories><comments>VLDB2011</comments><proxy>uroehm</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 4, No. 4, pp.
  219-230 (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a generic framework to make wrapper induction algorithms tolerant
to noise in the training data. This enables us to learn wrappers in a
completely unsupervised manner from automatically and cheaply obtained noisy
training data, e.g., using dictionaries and regular expressions. By removing
the site-level supervision that wrapper-based techniques require, we are able
to perform information extraction at web-scale, with accuracy unattained with
existing unsupervised extraction techniques. Our system is used in production
at Yahoo! and powers live applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2408</identifier>
 <datestamp>2011-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2408</id><created>2011-03-11</created><authors><author><keyname>Rao</keyname><forenames>Jun</forenames><affiliation>LinkedIn</affiliation></author><author><keyname>Shekita</keyname><forenames>Eugene J.</forenames><affiliation>IBM Research</affiliation></author><author><keyname>Tata</keyname><forenames>Sandeep</forenames><affiliation>IBM Research</affiliation></author></authors><title>Using Paxos to Build a Scalable, Consistent, and Highly Available
  Datastore</title><categories>cs.DB cs.DC</categories><comments>VLDB2011</comments><proxy>uroehm</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 4, No. 4, pp.
  243-254 (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spinnaker is an experimental datastore that is designed to run on a large
cluster of commodity servers in a single datacenter. It features key-based
range partitioning, 3-way replication, and a transactional get-put API with the
option to choose either strong or timeline consistency on reads. This paper
describes Spinnaker's Paxos-based replication protocol. The use of Paxos
ensures that a data partition in Spinnaker will be available for reads and
writes as long a majority of its replicas are alive. Unlike traditional
master-slave replication, this is true regardless of the failure sequence that
occurs. We show that Paxos replication can be competitive with alternatives
that provide weaker consistency guarantees. Compared to an eventually
consistent datastore, we show that Spinnaker can be as fast or even faster on
reads and only 5% to 10% slower on writes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2409</identifier>
 <datestamp>2011-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2409</id><created>2011-03-11</created><authors><author><keyname>Ding</keyname><forenames>Bolin</forenames><affiliation>UIUC</affiliation></author><author><keyname>K&#xf6;nig</keyname><forenames>Arnd Christian</forenames><affiliation>Microsoft Research</affiliation></author></authors><title>Fast Set Intersection in Memory</title><categories>cs.DB cs.DS</categories><comments>VLDB2011</comments><proxy>uroehm</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 4, No. 4, pp.
  255-266 (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Set intersection is a fundamental operation in information retrieval and
database systems. This paper introduces linear space data structures to
represent sets such that their intersection can be computed in a worst-case
efficient way. In general, given k (preprocessed) sets, with totally n
elements, we will show how to compute their intersection in expected time
O(n/sqrt(w)+kr), where r is the intersection size and w is the number of bits
in a machine-word. In addition,we introduce a very simple version of this
algorithm that has weaker asymptotic guarantees but performs even better in
practice; both algorithms outperform the state of the art techniques in terms
of execution time for both synthetic and real data sets and workloads.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2410</identifier>
 <datestamp>2011-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2410</id><created>2011-03-11</created><authors><author><keyname>Rastogi</keyname><forenames>Vibhor</forenames><affiliation>Yahoo! Research</affiliation></author><author><keyname>Dalvi</keyname><forenames>Nilesh</forenames><affiliation>Yahoo! Research</affiliation></author><author><keyname>Garofalakis</keyname><forenames>Minos</forenames><affiliation>Technical University of Crete</affiliation></author></authors><title>Large-Scale Collective Entity Matching</title><categories>cs.DB</categories><comments>VLDB2011</comments><proxy>uroehm</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 4, No. 4, pp.
  208-218 (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There have been several recent advancements in Machine Learning community on
the Entity Matching (EM) problem. However, their lack of scalability has
prevented them from being applied in practical settings on large real-life
datasets. Towards this end, we propose a principled framework to scale any
generic EM algorithm. Our technique consists of running multiple instances of
the EM algorithm on small neighborhoods of the data and passing messages across
neighborhoods to construct a global solution. We prove formal properties of our
framework and experimentally demonstrate the effectiveness of our approach in
scaling EM algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2411</identifier>
 <datestamp>2011-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2411</id><created>2011-03-11</created><updated>2011-03-28</updated><authors><author><keyname>Toda</keyname><forenames>Alexis Akira</forenames></author></authors><title>Unification of Maximum Entropy and Bayesian Inference via Plausible
  Reasoning</title><categories>cs.IT math.IT math.ST physics.data-an stat.TH</categories><comments>Submitted to IEEE Transactions on Information Theory on March 8, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper modifies Jaynes's axioms of plausible reasoning and derives the
minimum relative entropy principle, Bayes's rule, as well as maximum likelihood
from first principles. The new axioms, which I call the Optimum Information
Principle, is applicable whenever the decision maker is given the data and the
relevant background information. These axioms provide an answer to the question
&quot;why maximize entropy when faced with incomplete information?&quot;
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2429</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2429</id><created>2011-03-12</created><authors><author><keyname>Winzen</keyname><forenames>Carola</forenames></author></authors><title>Direction-Reversing Quasi-Random Rumor Spreading with Restarts</title><categories>cs.DS</categories><comments>19 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a recent work, Doerr and Fouz [\emph{Asymptotically Optimal Randomized
Rumor Spreading}, in ArXiv] present a new quasi-random PUSH algorithm for the
rumor spreading problem (also known as gossip spreading or message propagation
problem). Their \emph{hybrid protocol} outperforms all known PUSH protocols.
  In this work, we add to the hybrid protocol a direction-reversing element. We
show that this \emph{direction-reversing quasi-random rumor spreading protocol
with random restarts} yields a constant factor improvement over the hybrid
model, if we allow the same dose of randomness.
  Put differently, our protocol achieves the same broadcasting time as the
hybrid model by employing only (roughly) half the number of random choices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2431</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2431</id><created>2011-03-12</created><updated>2011-03-15</updated><authors><author><keyname>Marano</keyname><forenames>Stefano</forenames></author><author><keyname>Matta</keyname><forenames>Vincenzo</forenames></author><author><keyname>He</keyname><forenames>Ting</forenames></author><author><keyname>Tong</keyname><forenames>Lang</forenames></author></authors><title>The Embedding Capacity of Information Flows Under Renewal Traffic</title><categories>cs.IT math.IT</categories><comments>Sumbitted to IEEE Trans. on Information Theory on March 10, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given two independent point processes and a certain rule for matching points
between them, what is the fraction of matched points over infinitely long
streams? In many application contexts, e.g., secure networking, a meaningful
matching rule is that of a maximum causal delay, and the problem is related to
embedding a flow of packets in cover traffic such that no traffic analysis can
detect it. We study the best undetectable embedding policy and the
corresponding maximum flow rate ---that we call the embedding capacity--- under
the assumption that the cover traffic can be modeled as arbitrary renewal
processes. We find that computing the embedding capacity requires the inversion
of very structured linear systems that, for a broad range of renewal models
encountered in practice, admits a fully analytical expression in terms of the
renewal function of the processes. Our main theoretical contribution is a
simple closed form of such relationship. This result enables us to explore
properties of the embedding capacity, obtaining closed-form solutions for
selected distribution families and a suite of sufficient conditions on the
capacity ordering. We evaluate our solution on real network traces, which shows
a noticeable match for tight delay constraints. A gap between the predicted and
the actual embedding capacities appears for looser constraints, and further
investigation reveals that it is caused by inaccuracy of the renewal traffic
model rather than of the solution itself.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2447</identifier>
 <datestamp>2011-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2447</id><created>2011-03-12</created><authors><author><keyname>Wei</keyname><forenames>Fei</forenames></author><author><keyname>Yang</keyname><forenames>Huazhong</forenames></author></authors><title>Mini-step Strategy for Transient Analysis</title><categories>cs.CE</categories><comments>a preprint version, full version is submitted to an international
  journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Domain decomposition methods are widely used to solve sparse linear systems
from scientific problems, but they are not suited to solve sparse linear
systems extracted from integrated circuits. The reason is that the sparse
linear system of integrated circuits may be non-diagonal-dominant, and domain
decomposition method might be unconvergent for these non-diagonal-dominant
matrices. In this paper, we propose a mini-step strategy to do the circuit
transient analysis. Different from the traditional large-step approach, this
strategy is able to generate diagonal-dominant sparse linear systems. As a
result, preconditioned domain decomposition methods can be used to simulate the
large integrated circuits on the supercomputers and clouds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2467</identifier>
 <datestamp>2011-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2467</id><created>2011-03-12</created><authors><author><keyname>De Montis</keyname><forenames>Andrea</forenames></author><author><keyname>Caschili</keyname><forenames>Simone</forenames></author><author><keyname>Chessa</keyname><forenames>Alessandro</forenames></author></authors><title>Commuter networks and community detection: a method for planning sub
  regional areas</title><categories>physics.soc-ph cs.SI</categories><comments>19 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A major issue for policy makers and planners is the definition of the &quot;ideal&quot;
regional partition, i.e. the delimitation of sub-regional domains showing a
sufficient level of homogeneity with respect to some specific territorial
features. In Sardinia, the second major island in the Mediterranean sea,
politicians and analysts have been involved in a 50 year process of
identification of the correct pattern for the province, an intermediate
administrative body in between the Regional and the municipal administration.
In this paper, we compare some intermediate body partitions of Sardinia with
the patterns of the communities of workers and students, by applying grouping
methodologies based on the characterization of Sardinian commuters' system as a
complex weighted network. We adopt an algorithm based on the maximization of
the weighted modularity of this network to detect productive basins composed by
municipalities showing a certain degree of cohesiveness in terms of commuter
flows. The results obtained lead to conclude that new provinces in Sardinia
seem to have been designed -even unconsciously- as labour basins of
municipalities with similar commuting behaviour.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2469</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2469</id><created>2011-03-12</created><authors><author><keyname>Silva</keyname><forenames>Jorge</forenames></author><author><keyname>Chen</keyname><forenames>Minhua</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author><author><keyname>Sapiro</keyname><forenames>Guillermo</forenames></author><author><keyname>Carin</keyname><forenames>Lawrence</forenames></author></authors><title>Blind Compressed Sensing Over a Structured Union of Subspaces</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the problem of simultaneous signal recovery and
dictionary learning based on compressive measurements. Multiple signals are
analyzed jointly, with multiple sensing matrices, under the assumption that the
unknown signals come from a union of a small number of disjoint subspaces. This
problem is important, for instance, in image inpainting applications, in which
the multiple signals are constituted by (incomplete) image patches taken from
the overall image. This work extends standard dictionary learning and
block-sparse dictionary optimization, by considering compressive measurements,
e.g., incomplete data). Previous work on blind compressed sensing is also
generalized by using multiple sensing matrices and relaxing some of the
restrictions on the learned dictionary. Drawing on results developed in the
context of matrix completion, it is proven that both the dictionary and signals
can be recovered with high probability from compressed measurements. The
solution is unique up to block permutations and invertible linear
transformations of the dictionary atoms. The recovery is contingent on the
number of measurements per signal and the number of signals being sufficiently
large; bounds are derived for these quantities. In addition, this paper
presents a computationally practical algorithm that performs dictionary
learning and signal recovery, and establishes conditions for its convergence to
a local optimum. Experimental results for image inpainting demonstrate the
capabilities of the method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2490</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2490</id><created>2011-03-12</created><authors><author><keyname>Zhu</keyname><forenames>Quanyan</forenames></author><author><keyname>Pavel</keyname><forenames>Lacra</forenames></author></authors><title>Enabling Differentiated Services Using Generalized Power Control Model
  in Optical Networks</title><categories>cs.GT</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This paper considers a generalized framework to study OSNR optimization-based
end-to-end link level power control problems in optical networks. We combine
favorable features of game-theoretical approach and central cost approach to
allow different service groups within the network. We develop solutions
concepts for both cases of empty and nonempty feasible sets. In addition, we
derive and prove the convergence of a distributed iterative algorithm for
different classes of users. In the end, we use numerical examples to illustrate
the novel framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2491</identifier>
 <datestamp>2011-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2491</id><created>2011-03-12</created><authors><author><keyname>Zhu</keyname><forenames>Quanyan</forenames></author><author><keyname>Tembine</keyname><forenames>Hamidou</forenames></author><author><keyname>Basar</keyname><forenames>Tamer</forenames></author></authors><title>Heterogeneous Learning in Zero-Sum Stochastic Games with Incomplete
  Information</title><categories>cs.LG cs.GT cs.SY math.OC</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Learning algorithms are essential for the applications of game theory in a
networking environment. In dynamic and decentralized settings where the
traffic, topology and channel states may vary over time and the communication
between agents is impractical, it is important to formulate and study games of
incomplete information and fully distributed learning algorithms which for each
agent requires a minimal amount of information regarding the remaining agents.
In this paper, we address this major challenge and introduce heterogeneous
learning schemes in which each agent adopts a distinct learning pattern in the
context of games with incomplete information. We use stochastic approximation
techniques to show that the heterogeneous learning schemes can be studied in
terms of their deterministic ordinary differential equation (ODE) counterparts.
Depending on the learning rates of the players, these ODEs could be different
from the standard replicator dynamics, (myopic) best response (BR) dynamics,
logit dynamics, and fictitious play dynamics. We apply the results to a class
of security games in which the attacker and the defender adopt different
learning schemes due to differences in their rationality levels and the
information they acquire.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2493</identifier>
 <datestamp>2011-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2493</id><created>2011-03-12</created><authors><author><keyname>Zhu</keyname><forenames>Quanyan</forenames></author><author><keyname>Tembine</keyname><forenames>Hamidou</forenames></author><author><keyname>Basar</keyname><forenames>Tamer</forenames></author></authors><title>A Constrained Evolutionary Gaussian Multiple Access Channel Game</title><categories>cs.GT cs.SY math.DS math.OC</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In this paper, we formulate an evolutionary multiple access channel game with
continuous-variable actions and coupled rate constraints. We characterize Nash
equilibria of the game and show that the pure Nash equilibria are Pareto
optimal and also resilient to deviations by coalitions of any size, i.e., they
are strong equilibria. We use the concepts of price of anarchy and strong price
of anarchy to study the performance of the system. The paper also addresses how
to select one specifc equilibrium solution using the concepts of normalized
equilibrium and evolutionary stable strategies. We examine the long-run
behavior of these strategies under several classes of evolutionary game
dynamics such as Brown-von Neumann-Nash dynamics, and replicator dynamics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2496</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2496</id><created>2011-03-12</created><authors><author><keyname>Zhu</keyname><forenames>Quanyan</forenames></author><author><keyname>Tembine</keyname><forenames>Hamidou</forenames></author><author><keyname>Basar</keyname><forenames>Tamer</forenames></author></authors><title>Evolutionary Games for Multiple Access Control</title><categories>cs.GT cs.SY math.DS math.OC</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In this paper, we formulate an evolutionarymultiple access control game with
continuousvariable actions and coupled constraints. We characterize equilibria
of the game and show that the pure equilibria are Pareto optimal and also
resilient to deviations by coalitions of any size, i.e., they are strong
equilibria. We use the concepts of price of anarchy and strong price of anarchy
to study the performance of the system. The paper also addresses how to select
one specific equilibrium solution using the concepts of normalized equilibrium
and evolutionarily stable strategies. We examine the long-run behavior of these
strategies under several classes of evolutionary game dynamics, such as
Brown-von Neumann-Nash dynamics, Smith dynamics and replicator dynamics. In
addition, we examine correlated equilibrium for the single-receiver model.
Correlated strategies are based on signaling structures before making decisions
on rates. We then focus on evolutionary games for hybrid additive white
Gaussian noise multiple access channel with multiple users and multiple
receivers, where each user chooses a rate and splits it over the receivers.
Users have coupled constraints determined by the capacity regions. Building
upon the static game, we formulate a system of hybrid evolutionary game
dynamics using G-function dynamics and Smith dynamics on rate control and
channel selection, respectively. We show that the evolving game has an
equilibrium and illustrate these dynamics with numerical examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2500</identifier>
 <datestamp>2011-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2500</id><created>2011-03-13</created><updated>2011-03-15</updated><authors><author><keyname>Gurvits</keyname><forenames>Leonid</forenames></author><author><keyname>Roychowdhury</keyname><forenames>Vwani</forenames></author><author><keyname>Singh</keyname><forenames>Sudhir Kumar</forenames></author><author><keyname>Vatan</keyname><forenames>Farrokh</forenames></author></authors><title>How much of quantum mechanics is really needed to defy Extended
  Church-Turing Thesis?</title><categories>quant-ph cs.CC</categories><comments>This paper has been withdrawn</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn by the author as one of the coauthors needs
institutional permission.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2501</identifier>
 <datestamp>2011-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2501</id><created>2011-03-13</created><authors><author><keyname>Chaaban</keyname><forenames>Anas</forenames></author><author><keyname>Sezgin</keyname><forenames>Aydin</forenames></author><author><keyname>Bandemer</keyname><forenames>Bernd</forenames></author><author><keyname>Paulraj</keyname><forenames>Arogyaswami</forenames></author></authors><title>On Gaussian Multiple Access Channels with Interference: Achievable Rates
  and Upper Bounds</title><categories>cs.IT math.IT</categories><comments>submitted to MACOM 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the interaction between two interfering Gaussian 2-user multiple
access channels. The capacity region is characterized under mixed
strong--extremely strong interference and individually very strong
interference. Furthermore, the sum capacity is derived under a less restricting
definition of very strong interference. Finally, a general upper bound on the
sum capacity is provided, which is nearly tight for weak cross links.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2503</identifier>
 <datestamp>2011-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2503</id><created>2011-03-13</created><authors><author><keyname>Yang</keyname><forenames>Chunliang</forenames></author><author><keyname>Jiang</keyname><forenames>Chengling</forenames></author></authors><title>Coded Single-Tone Signaling for Resource Coordination and Interference
  Management in Femtocell Networks</title><categories>cs.IT math.IT</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Resource coordination and interference management is the key to achieving the
benefits of femtocell networks. Over-the-air signaling is one of the most
effective means for distributed dynamic resource coordination and interference
management. However, the design of this type of signal is challenging. In this
letter, we address the challenges and propose an effective solution, referred
to as coded single-tone signaling (STS). The proposed coded STS scheme
possesses certain highly desirable properties, such as no dedicated resource
requirement (no overhead), no near-and-far effect, no inter-signal interference
(no multi-user interference), low peak-to-average power ratio (deep coverage).
In addition, the proposed coded STS can fully exploit frequency diversity and
provides a means for high quality wideband channel estimation. The coded STS
design is demonstrated through a concrete numerical example. Performance of the
proposed coded STS is evaluated through simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2520</identifier>
 <datestamp>2011-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2520</id><created>2011-03-13</created><authors><author><keyname>Feige</keyname><forenames>Uriel</forenames></author><author><keyname>Tennenholtz</keyname><forenames>Moshe</forenames></author></authors><title>Mechanism design with uncertain inputs (to err is human, to forgive
  divine)</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a task of scheduling with a common deadline on a single machine.
Every player reports to a scheduler the length of his job and the scheduler
needs to finish as many jobs as possible by the deadline. For this simple
problem, there is a truthful mechanism that achieves maximum welfare in
dominant strategies. The new aspect of our work is that in our setting players
are uncertain about their own job lengths, and hence are incapable of providing
truthful reports (in the strict sense of the word). For a probabilistic model
for uncertainty our main results are as follows.
  1) Even with relatively little uncertainty, no mechanism can guarantee a
constant fraction of the maximum welfare.
  2) To remedy this situation, we introduce a new measure of economic
efficiency, based on a notion of a {\em fair share} of a player, and design
mechanisms that are $\Omega(1)$-fair. In addition to its intrinsic appeal, our
notion of fairness implies good approximation of maximum welfare in several
cases of interest.
  3) In our mechanisms the machine is sometimes left idle even though there are
jobs that want to use it. We show that this unfavorable aspect is unavoidable,
unless one gives up other favorable aspects (e.g., give up
$\Omega(1)$-fairness).
  We also consider a qualitative approach to uncertainty as an alternative to
the probabilistic quantitative model. In the qualitative approach we break away
from solution concepts such as dominant strategies (they are no longer well
defined), and instead suggest an axiomatic approach, which amounts to listing
desirable properties for mechanisms. We provide a mechanism that satisfies
these properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2539</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2539</id><created>2011-03-13</created><updated>2011-09-29</updated><authors><author><keyname>Zarrouati</keyname><forenames>Nadege</forenames></author><author><keyname>Aldea</keyname><forenames>Emanuel</forenames></author><author><keyname>Rouchon</keyname><forenames>Pierre</forenames></author></authors><title>SO(3)-invariant asymptotic observers for dense depth field estimation
  based on visual data and known camera motion</title><categories>math.OC cs.CV</categories><comments>Submitted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we use known camera motion associated to a video sequence of a
static scene in order to estimate and incrementally refine the surrounding
depth field. We exploit the SO(3)-invariance of brightness and depth fields
dynamics to customize standard image processing techniques. Inspired by the
Horn-Schunck method, we propose a SO(3)-invariant cost to estimate the depth
field. At each time step, this provides a diffusion equation on the unit
Riemannian sphere that is numerically solved to obtain a real time depth field
estimation of the entire field of view. Two asymptotic observers are derived
from the governing equations of dynamics, respectively based on optical flow
and depth estimations: implemented on noisy sequences of synthetic images as
well as on real data, they perform a more robust and accurate depth estimation.
This approach is complementary to most methods employing state observers for
range estimation, which uniquely concern single or isolated feature points.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2544</identifier>
 <datestamp>2011-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2544</id><created>2011-03-13</created><updated>2011-11-17</updated><authors><author><keyname>Kaced</keyname><forenames>Tarik</forenames></author></authors><title>Almost-perfect secret sharing</title><categories>cs.IT cs.CR math.IT</categories><comments>Acknowledgments added</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Splitting a secret s between several participants, we generate (for each
value of s) shares for all participants. The goal: authorized groups of
participants should be able to reconstruct the secret but forbidden ones get no
information about it. In this paper we introduce several notions of non-
perfect secret sharing, where some small information leak is permitted. We
study its relation to the Kolmogorov complexity version of secret sharing
(establishing some connection in both directions) and the effects of changing
the secret size (showing that we can decrease the size of the secret and the
information leak at the same time).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2545</identifier>
 <datestamp>2011-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2545</id><created>2011-03-13</created><updated>2011-09-26</updated><authors><author><keyname>Kaced</keyname><forenames>Tarik</forenames></author><author><keyname>Romashchenko</keyname><forenames>Andrei</forenames></author></authors><title>On essentially conditional information inequalities</title><categories>cs.IT cs.DM math.IT math.PR</categories><comments>v4: substantial corrections; 13 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In 1997, Z.Zhang and R.W.Yeung found the first example of a conditional
information inequality in four variables that is not &quot;Shannon-type&quot;. This
linear inequality for entropies is called conditional (or constraint) since it
holds only under condition that some linear equations are satisfied for the
involved entropies. Later, the same authors and other researchers discovered
several unconditional information inequalities that do not follow from
Shannon's inequalities for entropy.
  In this paper we show that some non Shannon-type conditional inequalities are
&quot;essentially&quot; conditional, i.e., they cannot be extended to any unconditional
inequality. We prove one new essentially conditional information inequality for
Shannon's entropy and discuss conditional information inequalities for
Kolmogorov complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2560</identifier>
 <datestamp>2011-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2560</id><created>2011-03-13</created><authors><author><keyname>Karmakar</keyname><forenames>Sanjay</forenames></author><author><keyname>Varanasi</keyname><forenames>Mahesh K.</forenames></author></authors><title>The Generalized Degrees of Freedom Region of the MIMO Interference
  Channel</title><categories>cs.IT math.IT</categories><comments>38 pages, 14 figures. Submitted to Trans. of IT</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The generalized degrees of freedom (GDoF) region of the MIMO Gaussian
interference channel (IC) is obtained for the general case of an arbitrary
number of antennas at each node and where the signal-to-noise ratios (SNR) and
interference-to-noise ratios (INR) vary with arbitrary exponents to a nominal
SNR. The GDoF region reveals various insights through the joint dependence of
optimal interference management techniques (at high SNR) on the SNR exponents
that determine the relative strengths of direct-link SNRs and cross-link INRs
and the numbers of antennas at the four terminals. For instance, it permits an
in-depth look at the issue of rate-splitting and partial decoding and it
reveals that, unlike in the scalar IC, treating interference as noise is not
always GDoF-optimal even in the very weak interference regime. Moreover, while
the DoF-optimal strategy that relies just on transmit/receive zero-forcing
beamforming and time-sharing is not GDoF optimal (and thus has an unbounded gap
to capacity), the precise characterization of the very strong interference
regime -- where single-user DoF performance can be achieved simultaneously for
both users-- depends on the relative numbers of antennas at the four terminals
and thus deviates from what it is in the SISO case. For asymmetric numbers of
antennas at the four nodes the shape of the symmetric GDoF curve can be a
&quot;distorted W&quot; curve to the extent that for certain MIMO ICs it is a &quot;V&quot; curve.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2566</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2566</id><created>2011-03-13</created><updated>2011-04-12</updated><authors><author><keyname>Byde</keyname><forenames>Andrew</forenames></author><author><keyname>Twigg</keyname><forenames>Andy</forenames></author></authors><title>Optimal query/update tradeoffs in versioned dictionaries</title><categories>cs.DS cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  External-memory dictionaries are a fundamental data structure in file systems
and databases. Versioned (or fully-persistent) dictionaries have an associated
version tree where queries can be performed at any version, updates can be
performed on leaf versions, and any version can be `cloned' by adding a child.
Various query/update tradeoffs are known for unversioned dictionaries, many of
them with matching upper and lower bounds. No fully-versioned external-memory
dictionaries are known with optimal space/query/update tradeoffs. In
particular, no versioned constructions are known that offer updates in $o(1)$
I/Os using O(N) space. We present the first cache-oblivious and cache-aware
constructions that achieve a wide range of optimal points on this tradeoff.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2573</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2573</id><created>2011-03-13</created><authors><author><keyname>Ren</keyname><forenames>Tian Peng</forenames></author><author><keyname>Guan</keyname><forenames>Yong Liang</forenames></author><author><keyname>Yuen</keyname><forenames>Chau</forenames></author><author><keyname>Zhou</keyname><forenames>Yue</forenames></author><author><keyname>Zhang</keyname><forenames>Er Yang</forenames></author></authors><title>Optimization of Fast-Decodable Full-Rate STBC with Non-Vanishing
  Determinants</title><categories>cs.IT math.IT</categories><comments>Accepted by IEEE Transactions on Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Full-rate STBC (space-time block codes) with non-vanishing determinants
achieve the optimal diversity-multiplexing tradeoff but incur high decoding
complexity. To permit fast decoding, Sezginer, Sari and Biglieri proposed an
STBC structure with special QR decomposition characteristics. In this paper, we
adopt a simplified form of this fast-decodable code structure and present a new
way to optimize the code analytically. We show that the signal constellation
topology (such as QAM, APSK, or PSK) has a critical impact on the existence of
non-vanishing determinants of the full-rate STBC. In particular, we show for
the first time that, in order for APSK-STBC to achieve non-vanishing
determinant, an APSK constellation topology with constellation points lying on
square grid and ring radius $\sqrt{m^2+n^2} (m,n\emph{\emph{integers}})$ needs
to be used. For signal constellations with vanishing determinants, we present a
methodology to analytically optimize the full-rate STBC at specific
constellation dimension.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2574</identifier>
 <datestamp>2015-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2574</id><created>2011-03-13</created><updated>2011-06-08</updated><authors><author><keyname>Leinster</keyname><forenames>Tom</forenames></author></authors><title>A multiplicative characterization of the power means</title><categories>math.FA cs.IT math.CA math.IT</categories><comments>7 pages. Version 3: references added; minor edits</comments><msc-class>26E60 (primary), 47A30, 52A21 (secondary)</msc-class><journal-ref>Bulletin of the London Mathematical Society 44 (2012), 106-112</journal-ref><doi>10.1112/blms/bdr073</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A startlingly simple characterization of the p-norms has recently been found
by Aubrun and Nechita (arXiv:1102.2618) and by Fernandez-Gonzalez, Palazuelos
and Perez-Garcia. We deduce a simple characterization of the power means of
order greater than or equal to 1.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2575</identifier>
 <datestamp>2013-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2575</id><created>2011-03-13</created><authors><author><keyname>Eppstein</keyname><forenames>David</forenames></author><author><keyname>L&#xf6;ffler</keyname><forenames>Maarten</forenames></author></authors><title>Bounds on the Complexity of Halfspace Intersections when the Bounded
  Faces have Small Dimension</title><categories>cs.CG cs.DM</categories><acm-class>F.2.2</acm-class><journal-ref>Discrete Comput. Geom. 50 (1): 1-21, 2013</journal-ref><doi>10.1007/s00454-013-9503-3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the combinatorial complexity of D-dimensional polyhedra defined as
the intersection of n halfspaces, with the property that the highest dimension
of any bounded face is much smaller than D. We show that, if d is the maximum
dimension of a bounded face, then the number of vertices of the polyhedron is
O(n^d) and the total number of bounded faces of the polyhedron is O(n^d^2). For
inputs in general position the number of bounded faces is O(n^d). For any fixed
d, we show how to compute the set of all vertices, how to determine the maximum
dimension of a bounded face of the polyhedron, and how to compute the set of
bounded faces in polynomial time, by solving a polynomial number of linear
programs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2579</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2579</id><created>2011-03-13</created><authors><author><keyname>Basar</keyname><forenames>Tamer</forenames></author><author><keyname>Zhu</keyname><forenames>Quanyan</forenames></author></authors><title>Prices of Anarchy, Information, and Cooperation in Differential Games</title><categories>cs.SY cs.GT math.OC</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The price of anarchy (PoA) has been widely used in static games to quantify
the loss of efficiency due to noncooperation. Here, we extend this concept to a
general differential games framework. In addition, we introduce the price of
information (PoI) to characterize comparative game performances under different
information structures, as well as the price of cooperation to capture the
extent of benefit or loss a player accrues as a result of altruistic behavior.
We further characterize PoA and PoI for a class of scalar linear quadratic
differential games under open-loop and closed-loop feedback information
structures. We also obtain some explicit bounds on these indices in a large
population regime.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2580</identifier>
 <datestamp>2011-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2580</id><created>2011-03-13</created><authors><author><keyname>Taneja</keyname><forenames>Inder Jeet</forenames></author></authors><title>Inequalities Among Logarithmic-Mean Measures</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we shall consider some famous means such as arithmetic,
harmonic, geometric, logarithmic means, etc. Inequalities involving logarithmic
mean with differences among other means are presented
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2581</identifier>
 <datestamp>2011-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2581</id><created>2011-03-13</created><authors><author><keyname>Ito</keyname><forenames>Hiro</forenames></author><author><keyname>Tanigawa</keyname><forenames>Shin-ichi</forenames></author><author><keyname>Yoshida</keyname><forenames>Yuichi</forenames></author></authors><title>Constant-Time Algorithms for Sparsity Matroids</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A graph $G=(V,E)$ is called $(k,\ell)$-full if $G$ contains a subgraph
$H=(V,F)$ of $k|V|-\ell$ edges such that, for any non-empty $F' \subseteq F$,
$|F'| \leq k|V(F')| - \ell$ holds. Here, $V(F')$ denotes the set of vertices
incident to $F'$. It is known that the family of edge sets of $(k,\ell)$-full
graphs forms a family of matroid, known as the sparsity matroid of $G$. In this
paper, we give a constant-time approximation algorithm for the rank of the
sparsity matroid of a degree-bounded undirected graph. This leads to a
constant-time tester for $(k,\ell)$-fullness in the bounded-degree model,
(i.e., we can decide with high probability whether an input graph satisfies a
property $P$ or far from $P$). Depending on the values of $k$ and $\ell$, it
can test various properties of a graph such as connectivity, rigidity, and how
many spanning trees can be packed. Based on this result, we also propose a
constant-time tester for $(k,\ell)$-edge-connected-orientability in the
bounded-degree model, where an undirected graph $G$ is called
$(k,\ell)$-edge-connected-orientable if there exists an orientation $\vec{G}$
of $G$ with a vertex $r \in V$ such that $\vec{G}$ contains $k$ arc-disjoint
dipaths from $r$ to each vertex $v \in V$ and $\ell$ arc-disjoint dipaths from
each vertex $v \in V$ to $r$. A tester is called a one-sided error tester for
$P$ if it always accepts a graph satisfying $P$. We show, for $k \geq 2$ and
(proper) $\ell \geq 0$, any one-sided error tester for $(k,\ell)$-fullness and
$(k,\ell)$-edge-connected-orientability requires $\Omega(n)$ queries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2590</identifier>
 <datestamp>2011-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2590</id><created>2011-03-14</created><authors><author><keyname>Wei</keyname><forenames>Yi</forenames></author><author><keyname>Sukumar</keyname><forenames>Karthik</forenames></author><author><keyname>Vecchiola</keyname><forenames>Christian</forenames></author><author><keyname>Karunamoorthy</keyname><forenames>Dileban</forenames></author><author><keyname>Buyya</keyname><forenames>Rajkumar</forenames></author></authors><title>Aneka Cloud Application Platform and Its Integration with Windows Azure</title><categories>cs.DC</categories><comments>30 pages, 24 figures</comments><acm-class>C.1.4</acm-class><journal-ref>Cloud Computing: Methodology, Systems, and Applications, L. Wang,
  Rajiv Ranjan, Jinjun Chen, and Boualem Benatallah (eds), ISBN: 9781439856413,
  CRC Press, Boca Raton, FL, USA, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Aneka is an Application Platform-as-a-Service (Aneka PaaS) for Cloud
Computing. It acts as a framework for building customized applications and
deploying them on either public or private Clouds. One of the key features of
Aneka is its support for provisioning resources on different public Cloud
providers such as Amazon EC2, Windows Azure and GoGrid. In this chapter, we
will present Aneka platform and its integration with one of the public Cloud
infrastructures, Windows Azure, which enables the usage of Windows Azure
Compute Service as a resource provider of Aneka PaaS. The integration of the
two platforms will allow users to leverage the power of Windows Azure Platform
for Aneka Cloud Computing, employing a large number of compute instances to run
their applications in parallel. Furthermore, customers of the Windows Azure
platform can benefit from the integration with Aneka PaaS by embracing the
advanced features of Aneka in terms of multiple programming models, scheduling
and management services, application execution services, accounting and pricing
services and dynamic provisioning services. Finally, in addition to the Windows
Azure Platform we will illustrate in this chapter the integration of Aneka PaaS
with other public Cloud platforms such as Amazon EC2 and GoGrid, and virtual
machine management platforms such as Xen Server. The new support of
provisioning resources on Windows Azure once again proves the adaptability,
extensibility and flexibility of Aneka.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2593</identifier>
 <datestamp>2011-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2593</id><created>2011-03-14</created><authors><author><keyname>&#x160;ubelj</keyname><forenames>Lovro</forenames></author><author><keyname>Bajec</keyname><forenames>Marko</forenames></author></authors><title>Unfolding communities in large complex networks: Combining defensive and
  offensive label propagation for core extraction</title><categories>physics.soc-ph cs.SI physics.data-an</categories><journal-ref>Phys. Rev. E 83(3), 036103 (2011)</journal-ref><doi>10.1103/PhysRevE.83.036103</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Label propagation has proven to be a fast method for detecting communities in
large complex networks. Recent developments have also improved the accuracy of
the approach, however, a general algorithm is still an open issue. We present
an advanced label propagation algorithm that combines two unique strategies of
community formation, namely, defensive preservation and offensive expansion of
communities. Two strategies are combined in a hierarchical manner, to
recursively extract the core of the network, and to identify whisker
communities. The algorithm was evaluated on two classes of benchmark networks
with planted partition and on almost 25 real-world networks ranging from
networks with tens of nodes to networks with several tens of millions of edges.
It is shown to be comparable to the current state-of-the-art community
detection algorithms and superior to all previous label propagation algorithms,
with comparable time complexity. In particular, analysis on real-world networks
has proven that the algorithm has almost linear complexity,
$\mathcal{O}(m^{1.19})$, and scales even better than basic label propagation
algorithm ($m$ is the number of edges in the network).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2596</identifier>
 <datestamp>2013-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2596</id><created>2011-03-14</created><authors><author><keyname>&#x160;ubelj</keyname><forenames>Lovro</forenames></author><author><keyname>Bajec</keyname><forenames>Marko</forenames></author></authors><title>Unfolding network communities by combining defensive and offensive label
  propagation</title><categories>physics.soc-ph cs.SI physics.data-an</categories><journal-ref>Proceedings of the ECML PKDD Workshop on the Analysis of Complex
  Networks 2010 (ACNE '10), pp. 87-104</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Label propagation has proven to be a fast method for detecting communities in
complex networks. Recent work has also improved the accuracy and stability of
the basic algorithm, however, a general approach is still an open issue. We
propose different label propagation algorithms that convey two unique
strategies of community formation, namely, defensive preservation and offensive
expansion of communities. Furthermore, the strategies are combined in an
advanced label propagation algorithm that retains the advantages of both
approaches; and are enhanced with hierarchical community extraction, prominent
for the use on larger networks. The proposed algorithms were empirically
evaluated on different benchmarks networks with planted partition and on over
30 real-world networks of various types and sizes. The results confirm the
adequacy of the propositions and give promising grounds for future analysis of
(large) complex networks. Nevertheless, the main contribution of this work is
in showing that different types of networks (with different topological
properties) favor different strategies of community formation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2601</identifier>
 <datestamp>2011-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2601</id><created>2011-03-14</created><authors><author><keyname>Faenza</keyname><forenames>Yuri</forenames></author><author><keyname>Oriolo</keyname><forenames>Gianpaolo</forenames></author><author><keyname>Snels</keyname><forenames>Claudia</forenames></author></authors><title>A fast algorithm to remove proper and homogenous pairs of cliques (while
  preserving some graph invariants)</title><categories>math.OC cs.DM math.CO</categories><comments>8 pages</comments><msc-class>05C85, 68R10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a family of reductions for removing proper and homogeneous pairs
of cliques from a graph G. This family generalizes some routines presented in
the literature, mostly in the context of claw-free graphs. These reductions can
be embedded in a simple algorithm that in at most |E(G)| steps builds a new
graph G' without proper and homogeneous pairs of cliques, and such that G and
G' agree on the value of some relevant invariant (or property).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2607</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2607</id><created>2011-03-14</created><updated>2011-03-15</updated><authors><author><keyname>Asvadi</keyname><forenames>Reza</forenames></author><author><keyname>Banihashemi</keyname><forenames>Amir H.</forenames></author><author><keyname>Ahmadian-Attari</keyname><forenames>Mahmoud</forenames></author><author><keyname>Saeedi</keyname><forenames>Hamid</forenames></author></authors><title>LLR Approximation for Wireless Channels Based on Taylor Series and Its
  Application to BICM with LDPC Codes</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Trans. Commun</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new approach for the approximation of the channel log-likelihood ratio
(LLR) for wireless channels based on Taylor series is proposed. The
approximation is applied to the uncorrelated flat Rayleigh fading channel with
unknown channel state information at the receiver. It is shown that the
proposed approximation greatly simplifies the calculation of channel LLRs, and
yet provides results almost identical to those based on the exact calculation
of channel LLRs. The results are obtained in the context of bit-interleaved
coded modulation (BICM) schemes with low-density parity-check (LDPC) codes, and
include threshold calculations and error rate performance of finite-length
codes. Compared to the existing approximations, the proposed method is either
significantly less complex, or considerably more accurate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2612</identifier>
 <datestamp>2011-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2612</id><created>2011-03-14</created><updated>2011-09-12</updated><authors><author><keyname>Girard</keyname><forenames>Antoine</forenames></author><author><keyname>Martin</keyname><forenames>Samuel</forenames></author></authors><title>Synthesis for Constrained Nonlinear Systems using Hybridization and
  Robust Controllers on Simplices</title><categories>cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose an approach to controller synthesis for a class of
constrained nonlinear systems. It is based on the use of a hybridization, that
is a hybrid abstraction of the nonlinear dynamics. This abstraction is defined
on a triangulation of the state-space where on each simplex of the
triangulation, the nonlinear dynamics is conservatively approximated by an
affine system subject to disturbances. Except for the disturbances, this
hybridization can be seen as a piecewise affine hybrid system on simplices for
which appealing control synthesis techniques have been developed in the past
decade. We extend these techniques to handle systems subject to disturbances by
synthesizing and coordinating local robust affine controllers defined on the
simplices of the triangulation. We show that the resulting hybrid controller
can be used to control successfully the original constrained nonlinear system.
Our approach, though conservative, can be fully automated and is
computationally tractable. To show its effectiveness in practical applications,
we apply our method to control a pendulum mounted on a cart.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2613</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2613</id><created>2011-03-14</created><authors><author><keyname>Kolpakov</keyname><forenames>Roman</forenames></author><author><keyname>Kucherov</keyname><forenames>Gregory</forenames></author><author><keyname>Starikovskaya</keyname><forenames>Tatiana</forenames></author></authors><title>Linear pattern matching on sparse suffix trees</title><categories>cs.DS</categories><doi>10.1109/CCP.2011.45</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Packing several characters into one computer word is a simple and natural way
to compress the representation of a string and to speed up its processing.
Exploiting this idea, we propose an index for a packed string, based on a {\em
sparse suffix tree} \cite{KU-96} with appropriately defined suffix links.
Assuming, under the standard unit-cost RAM model, that a word can store up to
$\log_{\sigma}n$ characters ($\sigma$ the alphabet size), our index takes
$O(n/\log_{\sigma}n)$ space, i.e. the same space as the packed string itself.
The resulting pattern matching algorithm runs in time $O(m+r^2+r\cdot occ)$,
where $m$ is the length of the pattern, $r$ is the actual number of characters
stored in a word and $occ$ is the number of pattern occurrences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2626</identifier>
 <datestamp>2011-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2626</id><created>2011-03-14</created><authors><author><keyname>Beimel</keyname><forenames>Amos</forenames></author><author><keyname>Nissim</keyname><forenames>Kobbi</forenames></author><author><keyname>Omri</keyname><forenames>Eran</forenames></author></authors><title>Distributed Private Data Analysis: On Simultaneously Solving How and
  What</title><categories>cs.CR cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We examine the combination of two directions in the field of privacy
concerning computations over distributed private inputs - secure function
evaluation (SFE) and differential privacy. While in both the goal is to
privately evaluate some function of the individual inputs, the privacy
requirements are significantly different. The general feasibility results for
SFE suggest a natural paradigm for implementing differentially private analyses
distributively: First choose what to compute, i.e., a differentially private
analysis; Then decide how to compute it, i.e., construct an SFE protocol for
this analysis.
  We initiate an examination whether there are advantages to a paradigm where
both decisions are made simultaneously. In particular, we investigate under
which accuracy requirements it is beneficial to adapt this paradigm for
computing a collection of functions including binary sum, gap threshold, and
approximate median queries. Our results imply that when computing the binary
sum of $n$ distributed inputs then:
  * When we require that the error is $o(\sqrt{n})$ and the number of rounds is
constant, there is no benefit in the new paradigm.
  * When we allow an error of $O(\sqrt{n})$, the new paradigm yields more
efficient protocols when we consider protocols that compute symmetric
functions.
  Our results also yield new separations between the local and global models of
computations for private data analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2635</identifier>
 <datestamp>2014-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2635</id><created>2011-03-14</created><updated>2011-03-30</updated><authors><author><keyname>Cayton</keyname><forenames>Lawrence</forenames></author></authors><title>Accelerating Nearest Neighbor Search on Manycore Systems</title><categories>cs.DB cs.CG cs.DC cs.DS cs.IR</categories><journal-ref>In Proceedings of the 2012 IEEE 26th International Parallel and
  Distributed Processing Symposium (IPDPS '12). IEEE Computer Society,
  Washington, DC, USA, 402-413</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop methods for accelerating metric similarity search that are
effective on modern hardware. Our algorithms factor into easily parallelizable
components, making them simple to deploy and efficient on multicore CPUs and
GPUs. Despite the simple structure of our algorithms, their search performance
is provably sublinear in the size of the database, with a factor dependent only
on its intrinsic dimensionality. We demonstrate that our methods provide
substantial speedups on a range of datasets and hardware platforms. In
particular, we present results on a 48-core server machine, on graphics
hardware, and on a multicore desktop.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2648</identifier>
 <datestamp>2012-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2648</id><created>2011-03-14</created><updated>2012-09-10</updated><authors><author><keyname>Masuda</keyname><forenames>Naoki</forenames></author><author><keyname>Nakamura</keyname><forenames>Mitsuhiro</forenames></author></authors><title>Coevolution of trustful buyers and cooperative sellers in the trust game</title><categories>cs.GT q-bio.PE</categories><comments>5 figures</comments><journal-ref>PLoS ONE, 7(9), e44169 (2012)</journal-ref><doi>10.1371/journal.pone.0044169</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many online marketplaces enjoy great success. Buyers and sellers in
successful markets carry out cooperative transactions even if they do not know
each other in advance and a moral hazard exists. An indispensable component
that enables cooperation in such social dilemma situations is the reputation
system. Under the reputation system, a buyer can avoid transacting with a
seller with a bad reputation. A transaction in online marketplaces is better
modeled by the trust game than other social dilemma games, including the
donation game and the prisoner's dilemma. In addition, most individuals
participate mostly as buyers or sellers; each individual does not play the two
roles with equal probability. Although the reputation mechanism is known to be
able to remove the moral hazard in games with asymmetric roles, competition
between different strategies and population dynamics of such a game are not
sufficiently understood. On the other hand, existing models of reputation-based
cooperation, also known as indirect reciprocity, are based on the symmetric
donation game. We analyze the trust game with two fixed roles, where trustees
(i.e., sellers) but not investors (i.e., buyers) possess reputation scores. We
study the equilibria and the replicator dynamics of the game. We show that the
reputation mechanism enables cooperation between unacquainted buyers and
sellers under fairly generous conditions, even when such a cooperative
equilibrium coexists with an asocial equilibrium in which buyers do not buy and
sellers cheat. In addition, we show that not many buyers may care about the
seller's reputation under cooperative equilibrium. Buyers' trusting behavior
and sellers' reputation-driven cooperative behavior coevolve to alleviate the
social dilemma.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2651</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2651</id><created>2011-03-14</created><updated>2011-09-07</updated><authors><author><keyname>Xu</keyname><forenames>Yanwei</forenames></author></authors><title>Efficient Continual Top-$k$ Keyword Search in Relational Databases</title><categories>cs.DB cs.IR</categories><comments>This paper has been withdrawn by the author due to a crucial error of
  the algorithms</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Keyword search in relational databases has been widely studied in recent
years because it does not require users neither to master a certain structured
query language nor to know the complex underlying data schemas. Most of
existing methods focus on answering snapshot keyword queries in static
databases. In practice, however, databases are updated frequently, and users
may have long-term interests on specific topics. To deal with such a situation,
it is necessary to build effective and efficient facility in database systems
to support continual keyword queries evaluation.
  In this paper, we propose an efficient method for continual keyword queries
answering over relational databases. The proposed method consists of two core
algorithms. The first one computes a set of potential top-$k$ results by
evaluating the ranges of the future relevance score for every query result and
create a light-weight state for each keyword query. The second one uses these
states to maintain the top-$k$ results of keyword queries when the database is
continually growing. Experimental results validate the effectiveness and
efficiency of the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2657</identifier>
 <datestamp>2011-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2657</id><created>2011-03-14</created><authors><author><keyname>Sergeyev</keyname><forenames>Yaroslav D.</forenames></author></authors><title>Efficient Partition of N-Dimensional Intervals in the Framework of
  One-Point-Based Algorithms</title><categories>math.OC cs.NA math.NA physics.comp-ph</categories><comments>9 pages, 2 figures</comments><msc-class>90C30, 65K10, 90-08,</msc-class><journal-ref>Journal of Optimization Theory and Applications, 124(2), 2005,
  503-510</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the problem of the minimal description of the structure of a
vector function f(x) over an $N$-dimensional interval is studied. Methods
adaptively subdividing the original interval in smaller subintervals and
evaluating f(x) at only one point within each subinterval are considered. Two
partition strategies traditionally used for solving this problem are analyzed.
A new partition strategy based on an efficient technique developed for diagonal
algorithms is proposed and studied.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2662</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2662</id><created>2011-03-14</created><updated>2011-04-15</updated><authors><author><keyname>Pamies-Juarez</keyname><forenames>Lluis</forenames></author><author><keyname>Biersack</keyname><forenames>Ernst</forenames></author></authors><title>Cost Analysis of Redundancy Schemes for Distributed Storage Systems</title><categories>cs.DC cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distributed storage infrastructures require the use of data redundancy to
achieve high data reliability. Unfortunately, the use of redundancy introduces
storage and communication overheads, which can either reduce the overall
storage capacity of the system or increase its costs. To mitigate the storage
and communication overhead, different redundancy schemes have been proposed.
However, due to the great variety of underlaying storage infrastructures and
the different application needs, optimizing these redundancy schemes for each
storage infrastructure is cumbersome. The lack of rules to determine the
optimal level of redundancy for each storage configuration leads developers in
industry to often choose simpler redundancy schemes, which are usually not the
optimal ones. In this paper we analyze the cost of different redundancy schemes
and derive a set of rules to determine which redundancy scheme minimizes the
storage and the communication costs for a given system configuration.
Additionally, we use simulation to show that theoretically-optimal schemes may
not be viable in a realistic setting where nodes can go off-line and repairs
may be delayed. In these cases, we identify which are the trade-offs between
the storage and communication overheads of the redundancy scheme and its data
reliability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2681</identifier>
 <datestamp>2011-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2681</id><created>2011-03-14</created><authors><author><keyname>Bernhardsson</keyname><forenames>Sebastian</forenames></author><author><keyname>Baek</keyname><forenames>Seung Ki</forenames></author><author><keyname>Minnhagen</keyname><forenames>Petter</forenames></author></authors><title>A Paradoxical Property of the Monkey Book</title><categories>physics.data-an cond-mat.stat-mech cs.CL cs.IR physics.soc-ph</categories><comments>5 pages, 4 figures</comments><journal-ref>J. Stat. Mech. (2011) P07013</journal-ref><doi>10.1088/1742-5468/2011/07/P07013</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A &quot;monkey book&quot; is a book consisting of a random distribution of letters and
blanks, where a group of letters surrounded by two blanks is defined as a word.
We compare the statistics of the word distribution for a monkey book with the
corresponding distribution for the general class of random books, where the
latter are books for which the words are randomly distributed. It is shown that
the word distribution statistics for the monkey book is different and quite
distinct from a typical sampled book or real book. In particular the monkey
book obeys Heaps' power law to an extraordinary good approximation, in contrast
to the word distributions for sampled and real books, which deviate from Heaps'
law in a characteristics way. The somewhat counter-intuitive conclusion is that
a &quot;monkey book&quot; obeys Heaps' power law precisely because its word-frequency
distribution is not a smooth power law, contrary to the expectation based on
simple mathematical arguments that if one is a power law, so is the other.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2686</identifier>
 <datestamp>2012-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2686</id><created>2011-03-14</created><updated>2012-01-31</updated><authors><author><keyname>Golubitsky</keyname><forenames>Oleg</forenames></author><author><keyname>Maslov</keyname><forenames>Dmitri</forenames></author></authors><title>A Study of Optimal 4-bit Reversible Toffoli Circuits and Their Synthesis</title><categories>quant-ph cs.ET</categories><comments>arXiv admin note: substantial text overlap with arXiv:1003.1914</comments><journal-ref>IEEE Transactions on Computers, 61(9):1341-1353, September 2012</journal-ref><doi>10.1109/TC.2011.144</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Optimal synthesis of reversible functions is a non-trivial problem. One of
the major limiting factors in computing such circuits is the sheer number of
reversible functions. Even restricting synthesis to 4-bit reversible functions
results in a huge search space (16! {\approx} 2^{44} functions). The output of
such a search alone, counting only the space required to list Toffoli gates for
every function, would require over 100 terabytes of storage. In this paper, we
present two algorithms: one, that synthesizes an optimal circuit for any 4-bit
reversible specification, and another that synthesizes all optimal
implementations. We employ several techniques to make the problem tractable. We
report results from several experiments, including synthesis of all optimal
4-bit permutations, synthesis of random 4-bit permutations, optimal synthesis
of all 4-bit linear reversible circuits, synthesis of existing benchmark
functions; we compose a list of the hardest permutations to synthesize, and
show distribution of optimal circuits. We further illustrate that our proposed
approach may be extended to accommodate physical constraints via reporting
LNN-optimal reversible circuits. Our results have important implications in the
design and optimization of reversible and quantum circuits, testing circuit
synthesis heuristics, and performing experiments in the area of quantum
information processing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2690</identifier>
 <datestamp>2011-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2690</id><created>2011-03-14</created><authors><author><keyname>Sy</keyname><forenames>Lam Pham</forenames></author><author><keyname>Savin</keyname><forenames>Valentin</forenames></author><author><keyname>Declercq</keyname><forenames>David</forenames></author><author><keyname>Pham</keyname><forenames>Nghia</forenames></author></authors><title>Scheduled-PEG construction of LDPC codes for Upper-Layer FEC</title><categories>cs.IT math.IT</categories><comments>WCC 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Progressive Edge Growth (PEG) algorithm is one of the most widely-used
method for constructing finite length LDPC codes. In this paper we consider the
PEG algorithm together with a scheduling distribution, which specifies the
order in which edges are established in the graph. The goal is to find a
scheduling distribution that yields &quot;the best&quot; performance in terms of decoding
overhead, performance metric specific to erasure codes and widely used for
upper-layer forward error correction (UL-FEC). We rigorously formulate this
optimization problem, and we show that it can be addressed by using genetic
optimization algorithms. We also exhibit PEG codes with optimized scheduling
distribution, whose decoding overhead is less than half of the decoding
overhead of their classical-PEG counterparts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2691</identifier>
 <datestamp>2011-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2691</id><created>2011-03-14</created><authors><author><keyname>Sy</keyname><forenames>Lam Pham</forenames></author><author><keyname>Savin</keyname><forenames>Valentin</forenames></author><author><keyname>Declercq</keyname><forenames>David</forenames></author></authors><title>Extended Non-Binary Low-Density Parity-Check Codes over Erasure Channels</title><categories>cs.IT math.IT</categories><comments>ISIT 2011, submitted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Based on the extended binary image of non-binary LDPC codes, we propose a
method for generating extra redundant bits, such as to decreases the coding
rate of a mother code. The proposed method allows for using the same decoder,
regardless of how many extra redundant bits have been produced, which
considerably increases the flexibility of the system without significantly
increasing its complexity. Extended codes are also optimized for the binary
erasure channel, by using density evolution methods. Nevertheless, the results
presented in this paper can easily be extrapolated to more general channel
models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2695</identifier>
 <datestamp>2011-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2695</id><created>2011-03-14</created><authors><author><keyname>Gaviano</keyname><forenames>Marco</forenames></author><author><keyname>Kvasov</keyname><forenames>Dmitri E.</forenames></author><author><keyname>Lera</keyname><forenames>Daniela</forenames></author><author><keyname>Sergeyev</keyname><forenames>Yaroslav D.</forenames></author></authors><title>Software for Generation of Classes of Test Functions with Known Local
  and Global Minima for Global Optimization</title><categories>math.OC cs.MS cs.NA math.NA physics.comp-ph</categories><comments>20 pages, 1 figure</comments><msc-class>65-04, 90-08, 90C26, 90C30,</msc-class><acm-class>G.1.6; G.4</acm-class><journal-ref>ACM Transactions on Mathematical Software, 29(4), (2003) 469-480</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A procedure for generating non-differentiable, continuously differentiable,
and twice continuously differentiable classes of test functions for
multiextremal multidimensional box-constrained global optimization and a
corresponding package of C subroutines are presented. Each test class consists
of 100 functions. Test functions are generated by defining a convex quadratic
function systematically distorted by polynomials in order to introduce local
minima. To determine a class, the user defines the following parameters: (i)
problem dimension, (ii) number of local minima, (iii) value of the global
minimum, (iv) radius of the attraction region of the global minimizer, (v)
distance from the global minimizer to the vertex of the quadratic function.
Then, all other necessary parameters are generated randomly for all 100
functions of the class. Full information about each test function including
locations and values of all local minima is supplied to the user. Partial
derivatives are also generated where possible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2706</identifier>
 <datestamp>2011-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2706</id><created>2011-03-14</created><updated>2011-08-08</updated><authors><author><keyname>Amini</keyname><forenames>Hadis</forenames></author><author><keyname>Mirrahimi</keyname><forenames>Mazyar</forenames></author><author><keyname>Rouchon</keyname><forenames>Pierre</forenames></author></authors><title>On stability of continuous-time quantum-filters</title><categories>math.OC cs.SY quant-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that the fidelity between the quantum state governed by a continuous
time stochastic master equation driven by a Wiener process and its associated
quantum-filter state is a sub-martingale. This result is a generalization to
non-pure quantum states where fidelity does not coincide in general with a
simple Frobenius inner product. This result implies the stability of such
filtering process but does not necessarily ensure the asymptotic convergence of
such quantum-filters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2709</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2709</id><created>2011-03-14</created><updated>2011-03-16</updated><authors><author><keyname>Goldberg</keyname><forenames>Paul W.</forenames></author></authors><title>A Survey of PPAD-Completeness for Computing Nash Equilibria</title><categories>cs.GT cs.CC</categories><comments>32 pages, 10 figures, 23rd British Combinatorial Conference</comments><msc-class>90C60, 68Q25, 91A10</msc-class><acm-class>F.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  PPAD refers to a class of computational problems for which solutions are
guaranteed to exist due to a specific combinatorial principle. The most
well-known such problem is that of computing a Nash equilibrium of a game.
Other examples include the search for market equilibria, and envy-free
allocations in the context of cake-cutting. A problem is said to be complete
for PPAD if it belongs to PPAD and can be shown to constitute one of the
hardest computational challenges within that class.
  In this paper, I give a relatively informal overview of the proofs used in
the PPAD-completeness results. The focus is on the mixed Nash equilibria
guaranteed to exist by Nash's theorem. I also give an overview of some recent
work that uses these ideas to show PSPACE-completeness for the computation of
specific equilibria found by homotopy methods. I give a brief introduction to
related problems of searching for market equilibria.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2719</identifier>
 <datestamp>2011-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2719</id><created>2011-03-14</created><updated>2011-09-28</updated><authors><author><keyname>Petersen</keyname><forenames>Alexander M.</forenames></author><author><keyname>Stanley</keyname><forenames>H. Eugene</forenames></author><author><keyname>Succi</keyname><forenames>Sauro</forenames></author></authors><title>Statistical regularities in the rank-citation profile of scientists</title><categories>physics.soc-ph cs.DL physics.data-an physics.pop-ph</categories><comments>29 pages, 17 figures, 6 tables, Submitted; Modifications in V2 in
  response to referee comments</comments><journal-ref>Scientific Reports 1, 181 (2011)</journal-ref><doi>10.1038/srep00181</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent &quot;science of science&quot; research shows that scientific impact measures
for journals and individual articles have quantifiable regularities across both
time and discipline. However, little is known about the scientific impact
distribution at the scale of an individual scientist. We analyze the aggregate
scientific production and impact of individual careers using the rank-citation
profile c_{i}(r) of 200 distinguished professors and 100 assistant professors.
For the entire range of paper rank r, we fit each c_{i}(r) to a common
distribution function that is parameterized by two scaling exponents. Since two
scientists with equivalent Hirsch h-index can have significantly different
c_{i}(r) profiles, our results demonstrate the utility of the \beta_{i} scaling
parameter in conjunction with h_{i} for quantifying individual publication
impact. We show that the total number of citations C_{i} tallied from a
scientist's N_{i} papers scales as C_{i} \sim h_{i}^{1+\beta_{i}}. Such
statistical regularities in the input-output patterns of scientists can be used
as benchmarks for theoretical models of career progress.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2724</identifier>
 <datestamp>2011-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2724</id><created>2011-03-14</created><authors><author><keyname>Mukkamala</keyname><forenames>Padmini</forenames></author><author><keyname>Pach</keyname><forenames>J&#xe1;nos</forenames></author><author><keyname>P&#xe1;lv&#xf6;lgyi</keyname><forenames>D&#xf6;m&#xf6;t&#xf6;r</forenames></author></authors><title>Lower bounds on the obstacle number of graphs</title><categories>math.CO cs.DM</categories><msc-class>05C62, 05C75, 68R10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a graph $G$, an {\em obstacle representation} of $G$ is a set of points
in the plane representing the vertices of $G$, together with a set of connected
obstacles such that two vertices of $G$ are joined by an edge if and only if
the corresponding points can be connected by a segment which avoids all
obstacles. The {\em obstacle number} of $G$ is the minimum number of obstacles
in an obstacle representation of $G$. It is shown that there are graphs on $n$
vertices with obstacle number at least $\Omega({n}/{\log n})$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2741</identifier>
 <datestamp>2011-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2741</id><created>2011-03-14</created><authors><author><keyname>Laddha</keyname><forenames>Prerana</forenames></author></authors><title>Memory Retrieval in the B-Matrix Neural Network</title><categories>cs.NE</categories><comments>8 Pages, 4 Figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is an extension to the memory retrieval procedure of the B-Matrix
approach [6],[17] to neural network learning. The B-Matrix is a part of the
interconnection matrix generated from the Hebbian neural network, and in memory
retrieval, the B-matrix is clamped with a small fragment of the memory. The
fragment gradually enlarges by means of feedback, until the entire vector is
obtained. In this paper, we propose the use of delta learning to enhance the
retrieval rate of the stored memories.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2750</identifier>
 <datestamp>2011-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2750</id><created>2011-03-14</created><authors><author><keyname>Turitsyn</keyname><forenames>Konstantin</forenames></author><author><keyname>Backhaus</keyname><forenames>Scott</forenames></author><author><keyname>Ananyev</keyname><forenames>Maxim</forenames></author><author><keyname>Chertkov</keyname><forenames>Michael</forenames></author></authors><title>Smart Finite State Devices: A Modeling Framework for Demand Response
  Technologies</title><categories>cs.SY math.OC</categories><comments>8 pages, 8 figures, submitted IEEE CDC 2011</comments><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  We introduce and analyze Markov Decision Process (MDP) machines to model
individual devices which are expected to participate in future demand-response
markets on distribution grids. We differentiate devices into the following four
types: (a) optional loads that can be shed, e.g. light dimming; (b) deferrable
loads that can be delayed, e.g. dishwashers; (c) controllable loads with
inertia, e.g. thermostatically-controlled loads, whose task is to maintain an
auxiliary characteristic (temperature) within pre-defined margins; and (d)
storage devices that can alternate between charging and generating. Our
analysis of the devices seeks to find their optimal price-taking control
strategy under a given stochastic model of the distribution market.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2756</identifier>
 <datestamp>2011-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2756</id><created>2011-03-14</created><updated>2011-12-20</updated><authors><author><keyname>Tian</keyname><forenames>Xinmei</forenames></author><author><keyname>Tao</keyname><forenames>Dacheng</forenames></author><author><keyname>Rui</keyname><forenames>Yong</forenames></author></authors><title>Sparse Transfer Learning for Interactive Video Search Reranking</title><categories>cs.IR cs.CV cs.MM stat.ML</categories><comments>17 pages</comments><doi>10.1145/0000000.0000000</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Visual reranking is effective to improve the performance of the text-based
video search. However, existing reranking algorithms can only achieve limited
improvement because of the well-known semantic gap between low level visual
features and high level semantic concepts. In this paper, we adopt interactive
video search reranking to bridge the semantic gap by introducing user's
labeling effort. We propose a novel dimension reduction tool, termed sparse
transfer learning (STL), to effectively and efficiently encode user's labeling
information. STL is particularly designed for interactive video search
reranking. Technically, it a) considers the pair-wise discriminative
information to maximally separate labeled query relevant samples from labeled
query irrelevant ones, b) achieves a sparse representation for the subspace to
encodes user's intention by applying the elastic net penalty, and c) propagates
user's labeling information from labeled samples to unlabeled samples by using
the data distribution knowledge. We conducted extensive experiments on the
TRECVID 2005, 2006 and 2007 benchmark datasets and compared STL with popular
dimension reduction algorithms. We report superior performance by using the
proposed STL based interactive video search reranking.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2774</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2774</id><created>2011-03-14</created><updated>2011-12-12</updated><authors><author><keyname>Ozols</keyname><forenames>Maris</forenames></author><author><keyname>Roetteler</keyname><forenames>Martin</forenames></author><author><keyname>Roland</keyname><forenames>J&#xe9;r&#xe9;mie</forenames></author></authors><title>Quantum rejection sampling</title><categories>quant-ph cs.CC</categories><comments>19 pages, 5 figures, minor changes and a more compact style (to
  appear in proceedings of ITCS 2012)</comments><journal-ref>Proceedings of the 3rd Conference on Innovations in Theoretical
  Computer Science (ITCS'12), ACM Press, 2012, pages 290-308</journal-ref><doi>10.1145/2090236.2090261</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rejection sampling is a well-known method to sample from a target
distribution, given the ability to sample from a given distribution. The method
has been first formalized by von Neumann (1951) and has many applications in
classical computing. We define a quantum analogue of rejection sampling: given
a black box producing a coherent superposition of (possibly unknown) quantum
states with some amplitudes, the problem is to prepare a coherent superposition
of the same states, albeit with different target amplitudes. The main result of
this paper is a tight characterization of the query complexity of this quantum
state generation problem. We exhibit an algorithm, which we call quantum
rejection sampling, and analyze its cost using semidefinite programming. Our
proof of a matching lower bound is based on the automorphism principle which
allows to symmetrize any algorithm over the automorphism group of the problem.
Our main technical innovation is an extension of the automorphism principle to
continuous groups that arise for quantum state generation problems where the
oracle encodes unknown quantum states, instead of just classical data.
Furthermore, we illustrate how quantum rejection sampling may be used as a
primitive in designing quantum algorithms, by providing three different
applications. We first show that it was implicitly used in the quantum
algorithm for linear systems of equations by Harrow, Hassidim and Lloyd.
Secondly, we show that it can be used to speed up the main step in the quantum
Metropolis sampling algorithm by Temme et al.. Finally, we derive a new quantum
algorithm for the hidden shift problem of an arbitrary Boolean function and
relate its query complexity to &quot;water-filling&quot; of the Fourier spectrum.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2787</identifier>
 <datestamp>2011-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2787</id><created>2011-03-14</created><authors><author><keyname>Barlas</keyname><forenames>Konstantinos</forenames></author><author><keyname>Koletsos</keyname><forenames>George</forenames></author><author><keyname>Stefaneas</keyname><forenames>Petros</forenames></author></authors><title>Transforming ASN.1 Specifications into CafeOBJ to assist with Property
  Checking</title><categories>cs.SE cs.LO</categories><comments>8 pages, 12 figures</comments><acm-class>D.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The adoption of algebraic specification/formal method techniques by the
networks' research community is happening slowly but steadily. We work towards
a software environment that can translate a protocol's specification, from
Abstract Syntax Notation One (ASN.1 - a very popular specification language
with many applications), into the powerful algebraic specification language
CafeOBJ. The resulting code can be used to check, validate and falsify critical
properties of systems, at the pre-coding stage of development. In this paper,
we introduce some key elements of ASN.1 and CafeOBJ and sketch some first steps
towards the implementation of such a tool including a case study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2793</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2793</id><created>2011-03-14</created><updated>2012-02-25</updated><authors><author><keyname>Zouzias</keyname><forenames>Anastasios</forenames></author></authors><title>A Matrix Hyperbolic Cosine Algorithm and Applications</title><categories>cs.DS cs.DM</categories><comments>16 pages, simplified proof and corrected acknowledging of prior work
  in (current) Section 4</comments><doi>10.1007/978-3-642-31594-7_71</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we generalize Spencer's hyperbolic cosine algorithm to the
matrix-valued setting. We apply the proposed algorithm to several problems by
analyzing its computational efficiency under two special cases of matrices; one
in which the matrices have a group structure and an other in which they have
rank-one. As an application of the former case, we present a deterministic
algorithm that, given the multiplication table of a finite group of size $n$,
it constructs an expanding Cayley graph of logarithmic degree in near-optimal
O(n^2 log^3 n) time. For the latter case, we present a fast deterministic
algorithm for spectral sparsification of positive semi-definite matrices, which
implies an improved deterministic algorithm for spectral graph sparsification
of dense graphs. In addition, we give an elementary connection between spectral
sparsification of positive semi-definite matrices and element-wise matrix
sparsification. As a consequence, we obtain improved element-wise
sparsification algorithms for diagonally dominant-like matrices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2795</identifier>
 <datestamp>2011-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2795</id><created>2011-03-14</created><authors><author><keyname>Pasqualetti</keyname><forenames>Fabio</forenames></author><author><keyname>D&#xf6;rfler</keyname><forenames>Florian</forenames></author><author><keyname>Bullo</keyname><forenames>Francesco</forenames></author></authors><title>Cyber-Physical Attacks in Power Networks: Models, Fundamental
  Limitations and Monitor Design</title><categories>math.OC cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Future power networks will be characterized by safe and reliable
functionality against physical malfunctions and cyber attacks. This paper
proposes a unified framework and advanced monitoring procedures to detect and
identify network components malfunction or measurements corruption caused by an
omniscient adversary. We model a power system under cyber-physical attack as a
linear time-invariant descriptor system with unknown inputs. Our attack model
generalizes the prototypical stealth, (dynamic) false-data injection and replay
attacks. We characterize the fundamental limitations of both static and dynamic
procedures for attack detection and identification. Additionally, we design
provably-correct (dynamic) detection and identification procedures based on
tools from geometric control theory. Finally, we illustrate the effectiveness
of our method through a comparison with existing (static) detection algorithms,
and through a numerical study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2809</identifier>
 <datestamp>2011-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2809</id><created>2011-03-14</created><authors><author><keyname>Ablayev</keyname><forenames>Farid</forenames></author><author><keyname>Vasiliev</keyname><forenames>Alexander</forenames></author></authors><title>On Computational Power of Quantum Read-Once Branching Programs</title><categories>cs.CC</categories><comments>In Proceedings HPC 2010, arXiv:1103.2268</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 52, 2011, pp. 1-12</journal-ref><doi>10.4204/EPTCS.52.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we review our current results concerning the computational
power of quantum read-once branching programs. First of all, based on the
circuit presentation of quantum branching programs and our variant of quantum
fingerprinting technique, we show that any Boolean function with linear
polynomial presentation can be computed by a quantum read-once branching
program using a relatively small (usually logarithmic in the size of input)
number of qubits. Then we show that the described class of Boolean functions is
closed under the polynomial projections.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2811</identifier>
 <datestamp>2011-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2811</id><created>2011-03-14</created><authors><author><keyname>Coecke</keyname><forenames>Bob</forenames><affiliation>Oxford University Computing Laboratory</affiliation></author><author><keyname>Edwards</keyname><forenames>Bill</forenames><affiliation>Oxford University Computing Laboratory</affiliation></author></authors><title>Three qubit entanglement within graphical Z/X-calculus</title><categories>cs.LO quant-ph</categories><comments>In Proceedings HPC 2010, arXiv:1103.2268</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 52, 2011, pp. 22-33</journal-ref><doi>10.4204/EPTCS.52.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The compositional techniques of categorical quantum mechanics are applied to
analyse 3-qubit quantum entanglement. In particular the graphical calculus of
complementary observables and corresponding phases due to Duncan and one of the
authors is used to construct representative members of the two genuinely
tripartite SLOCC classes of 3-qubit entangled states, GHZ and W. This nicely
illustrates the respectively pairwise and global tripartite entanglement found
in the W- and GHZ-class states. A new concept of supplementarity allows us to
characterise inhabitants of the W class within the abstract diagrammatic
calculus; these method extends to more general multipartite qubit states.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2812</identifier>
 <datestamp>2011-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2812</id><created>2011-03-14</created><authors><author><keyname>Coecke</keyname><forenames>Bob</forenames></author><author><keyname>Kissinger</keyname><forenames>Aleks</forenames></author><author><keyname>Merry</keyname><forenames>Alex</forenames></author><author><keyname>Roy</keyname><forenames>Shibdas</forenames></author></authors><title>The GHZ/W-calculus contains rational arithmetic</title><categories>cs.LO quant-ph</categories><comments>In Proceedings HPC 2010, arXiv:1103.2268</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 52, 2011, pp. 34-48</journal-ref><doi>10.4204/EPTCS.52.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graphical calculi for representing interacting quantum systems serve a number
of purposes: compositionally, intuitive graphical reasoning, and a logical
underpinning for automation. The power of these calculi stems from the fact
that they embody generalized symmetries of the structure of quantum operations,
which, for example, stretch well beyond the Choi-Jamiolkowski isomorphism. One
such calculus takes the GHZ and W states as its basic generators. Here we show
that this language allows one to encode standard rational calculus, with the
GHZ state as multiplication, the W state as addition, the Pauli X gate as
multiplicative inversion, and the Pauli Z gate as additive inversion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2816</identifier>
 <datestamp>2012-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2816</id><created>2011-03-14</created><updated>2011-11-02</updated><authors><author><keyname>Liu</keyname><forenames>Yi-Kai</forenames></author></authors><title>Universal low-rank matrix recovery from Pauli measurements</title><categories>quant-ph cs.IT math.IT math.ST stat.ML stat.TH</categories><comments>v2: corrected typos, added proof details, 9+8 pages, to appear in
  NIPS 2011</comments><journal-ref>Advances in Neural Information Processing Systems (NIPS) 24,
  pp.1638-1646 (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of reconstructing an unknown matrix M of rank r and
dimension d using O(rd poly log d) Pauli measurements. This has applications in
quantum state tomography, and is a non-commutative analogue of a well-known
problem in compressed sensing: recovering a sparse vector from a few of its
Fourier coefficients.
  We show that almost all sets of O(rd log^6 d) Pauli measurements satisfy the
rank-r restricted isometry property (RIP). This implies that M can be recovered
from a fixed (&quot;universal&quot;) set of Pauli measurements, using nuclear-norm
minimization (e.g., the matrix Lasso), with nearly-optimal bounds on the error.
A similar result holds for any class of measurements that use an orthonormal
operator basis whose elements have small operator norm. Our proof uses Dudley's
inequality for Gaussian processes, together with bounds on covering numbers
obtained via entropy duality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2832</identifier>
 <datestamp>2011-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2832</id><created>2011-03-14</created><authors><author><keyname>Mandel</keyname><forenames>Michael</forenames></author><author><keyname>Pascanu</keyname><forenames>Razvan</forenames></author><author><keyname>Larochelle</keyname><forenames>Hugo</forenames></author><author><keyname>Bengio</keyname><forenames>Yoshua</forenames></author></authors><title>Autotagging music with conditional restricted Boltzmann machines</title><categories>cs.LG cs.IR cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes two applications of conditional restricted Boltzmann
machines (CRBMs) to the task of autotagging music. The first consists of
training a CRBM to predict tags that a user would apply to a clip of a song
based on tags already applied by other users. By learning the relationships
between tags, this model is able to pre-process training data to significantly
improve the performance of a support vector machine (SVM) autotagging. The
second is the use of a discriminative RBM, a type of CRBM, to autotag music. By
simultaneously exploiting the relationships among tags and between tags and
audio-based features, this model is able to significantly outperform SVMs,
logistic regression, and multi-layer perceptrons. In order to be applied to
this problem, the discriminative RBM was generalized to the multi-label setting
and four different learning algorithms for it were evaluated, the first such
in-depth analysis of which we are aware.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2837</identifier>
 <datestamp>2011-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2837</id><created>2011-03-14</created><authors><author><keyname>Khajehnejad</keyname><forenames>Amin</forenames></author><author><keyname>Dimakis</keyname><forenames>Alexandros G.</forenames></author><author><keyname>Hassibi</keyname><forenames>Babak</forenames></author><author><keyname>Vigoda</keyname><forenames>Benjamin</forenames></author><author><keyname>Bradley</keyname><forenames>William</forenames></author></authors><title>Reweighted LP Decoding for LDPC Codes</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a novel algorithm for decoding binary linear codes by linear
programming. We build on the LP decoding algorithm of Feldman et al. and
introduce a post-processing step that solves a second linear program that
reweights the objective function based on the outcome of the original LP
decoder output. Our analysis shows that for some LDPC ensembles we can improve
the provable threshold guarantees compared to standard LP decoding. We also
show significant empirical performance gains for the reweighted LP decoding
algorithm with very small additional computational complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2841</identifier>
 <datestamp>2011-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2841</id><created>2011-03-15</created><updated>2011-07-11</updated><authors><author><keyname>O'Connor</keyname><forenames>Russell</forenames></author></authors><title>Functor is to Lens as Applicative is to Biplate: Introducing Multiplate</title><categories>cs.PL</categories><comments>To appear in ACM SIGPLAN 7th Workshop on Generic Programming, Tokyo,
  18th September 2011</comments><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  This paper gives two new categorical characterisations of lenses: one as a
coalgebra of the store comonad, and the other as a monoidal natural
transformation on a category of a certain class of coalgebras. The store
comonad of the first characterisation can be generalized to a Cartesian store
comonad, and the coalgebras of this Cartesian store comonad turn out to be
exactly the Biplates of the Uniplate generic programming library. On the other
hand, the monoidal natural transformations on functors can be generalized to
work on a category of more specific coalgebras. This generalization turns out
to be the type of compos from the Compos generic programming library. A
theorem, originally conjectured by van Laarhoven, proves that these two
generalizations are isomorphic, thus the core data types of the Uniplate and
Compos libraries supporting generic program on single recursive types are the
same. Both the Uniplate and Compos libraries generalize this core functionality
to support mutually recursive types in different ways. This paper proposes a
third extension to support mutually recursive data types that is as powerful as
Compos and as easy to use as Uniplate. This proposal, called Multiplate, only
requires rank 3 polymorphism in addition to the normal type class mechanism of
Haskell.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2843</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2843</id><created>2011-03-15</created><authors><author><keyname>Armbruster</keyname><forenames>Benjamin</forenames></author><author><keyname>Carlsson</keyname><forenames>John Gunnar</forenames></author></authors><title>Dynamic Network Models</title><categories>math.PR cs.DM</categories><comments>16 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze random networks that change over time. First we analyze a dynamic
Erdos-Renyi model, whose edges change over time. We describe its stationary
distribution, its convergence thereto, and the SI contact process on the
network, which has relevance for connectivity and the spread of infections.
Second, we analyze the effect of node turnover, when nodes enter and leave the
network, which has relevance for network models incorporating births, deaths,
aging, and other demographic factors.
</abstract></arXiv>
</metadata>
</record>
<resumptionToken cursor="19000" completeListSize="102538">1122234|20001</resumptionToken>
</ListRecords>
</OAI-PMH>
